<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 15 Aug 2025 18:32:15 +0000</lastBuildDate><item><title>Now We’re Talking: NVIDIA Releases Open Dataset, Models for Multilingual Speech AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/speech-ai-dataset-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/speech-transcription.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Of around 7,000 languages in the world, a tiny fraction are supported by AI language models. NVIDIA is tackling the problem with a new dataset and models that support the development of high-quality speech recognition and translation AI for 25 European languages — including languages with limited available data like Croatian, Estonian and Maltese.&lt;/p&gt;
&lt;p&gt;These tools will enable developers to more easily scale AI applications to support global users with fast, accurate speech technology for production-scale use cases such as multilingual chatbots, customer service voice agents and near-real-time translation services. They include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Granary, a massive, open-source corpus of multilingual speech datasets that contains around a million hours of audio, including nearly 650,000 hours for speech recognition and over 350,000 hours for speech translation.&lt;/li&gt;
&lt;li&gt;NVIDIA Canary-1b-v2, a billion-parameter model trained on Granary for high-quality transcription of European languages, plus translation between English and two dozen supported languages.&lt;/li&gt;
&lt;li&gt;NVIDIA Parakeet-tdt-0.6b-v3, a streamlined, 600-million-parameter model designed for real-time or large-volume transcription of Granary’s supported languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The paper behind Granary will be presented at Interspeech, a language processing conference taking place in the Netherlands, Aug. 17-21. The dataset, as well as the new Canary and Parakeet models, are now available on Hugging Face.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How Granary Addresses Data Scarcity&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To develop the Granary dataset, the NVIDIA speech AI team collaborated with researchers from Carnegie Mellon University and Fondazione Bruno Kessler. The team passed unlabeled audio through an innovative processing pipeline powered by NVIDIA NeMo Speech Data Processor toolkit that turned it into structured, high-quality data.&lt;/p&gt;
&lt;p&gt;This pipeline allowed the researchers to enhance public speech data into a usable format for AI training, without the need for resource-intensive human annotation. It’s available in open source on GitHub.&lt;/p&gt;
&lt;p&gt;With Granary’s clean, ready-to-use data, developers can get a head start building models that tackle transcription and translation tasks in nearly all of the European Union’s 24 official languages, plus Russian and Ukrainian.&lt;/p&gt;
&lt;p&gt;For European languages underrepresented in human-annotated datasets, Granary provides a critical resource to develop more inclusive speech technologies that better reflect the linguistic diversity of the continent — all while using less training data.&lt;/p&gt;
&lt;p&gt;The team demonstrated in their Interspeech paper that, compared to other popular datasets, it takes around half as much Granary training data to achieve a target accuracy level for automatic speech recognition (ASR) and automatic speech translation (AST).&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tapping NVIDIA NeMo to Turbocharge Transcription&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The new Canary and Parakeet models offer examples of the kinds of models developers can build with Granary, customized to their target applications. Canary-1b-v2 is optimized for accuracy on complex tasks, while parakeet-tdt-0.6b-v3 is designed for high-speed, low-latency tasks.&lt;/p&gt;
&lt;p&gt;By sharing the methodology behind the Granary dataset and these two models, NVIDIA is enabling the global speech AI developer community to adapt this data processing workflow to other ASR or AST models or additional languages, accelerating speech AI innovation.&lt;/p&gt;
&lt;p&gt;Canary-1b-v2, available under a permissive license, expands the Canary family’s supported languages from four to 25. It offers transcription and translation quality comparable to models 3x larger while running inference up to 10x faster.&lt;/p&gt;

&lt;p&gt;NVIDIA NeMo, a modular software suite for managing the AI agent lifecycle, accelerated speech AI model development. NeMo Curator, part of the software suite, enabled the team to filter out synthetic examples from the source data so that only high-quality samples were used for model training. The team also harnessed the NeMo Speech Data Processor toolkit for tasks like aligning transcripts with audio files and converting data into the required formats.&lt;/p&gt;
&lt;p&gt;Parakeet-tdt-0.6b-v3 prioritizes high throughput and is capable of transcribing 24-minute audio segments in a single inference pass. The model automatically detects the input audio language and transcribes without additional prompting steps.&lt;/p&gt;
&lt;p&gt;Both Canary and Parakeet models provide accurate punctuation, capitalization and word-level timestamps in their outputs.&lt;/p&gt;
&lt;p&gt;Read more on GitHub and get started with Granary on Hugging Face.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/speech-transcription.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Of around 7,000 languages in the world, a tiny fraction are supported by AI language models. NVIDIA is tackling the problem with a new dataset and models that support the development of high-quality speech recognition and translation AI for 25 European languages — including languages with limited available data like Croatian, Estonian and Maltese.&lt;/p&gt;
&lt;p&gt;These tools will enable developers to more easily scale AI applications to support global users with fast, accurate speech technology for production-scale use cases such as multilingual chatbots, customer service voice agents and near-real-time translation services. They include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Granary, a massive, open-source corpus of multilingual speech datasets that contains around a million hours of audio, including nearly 650,000 hours for speech recognition and over 350,000 hours for speech translation.&lt;/li&gt;
&lt;li&gt;NVIDIA Canary-1b-v2, a billion-parameter model trained on Granary for high-quality transcription of European languages, plus translation between English and two dozen supported languages.&lt;/li&gt;
&lt;li&gt;NVIDIA Parakeet-tdt-0.6b-v3, a streamlined, 600-million-parameter model designed for real-time or large-volume transcription of Granary’s supported languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The paper behind Granary will be presented at Interspeech, a language processing conference taking place in the Netherlands, Aug. 17-21. The dataset, as well as the new Canary and Parakeet models, are now available on Hugging Face.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How Granary Addresses Data Scarcity&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To develop the Granary dataset, the NVIDIA speech AI team collaborated with researchers from Carnegie Mellon University and Fondazione Bruno Kessler. The team passed unlabeled audio through an innovative processing pipeline powered by NVIDIA NeMo Speech Data Processor toolkit that turned it into structured, high-quality data.&lt;/p&gt;
&lt;p&gt;This pipeline allowed the researchers to enhance public speech data into a usable format for AI training, without the need for resource-intensive human annotation. It’s available in open source on GitHub.&lt;/p&gt;
&lt;p&gt;With Granary’s clean, ready-to-use data, developers can get a head start building models that tackle transcription and translation tasks in nearly all of the European Union’s 24 official languages, plus Russian and Ukrainian.&lt;/p&gt;
&lt;p&gt;For European languages underrepresented in human-annotated datasets, Granary provides a critical resource to develop more inclusive speech technologies that better reflect the linguistic diversity of the continent — all while using less training data.&lt;/p&gt;
&lt;p&gt;The team demonstrated in their Interspeech paper that, compared to other popular datasets, it takes around half as much Granary training data to achieve a target accuracy level for automatic speech recognition (ASR) and automatic speech translation (AST).&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tapping NVIDIA NeMo to Turbocharge Transcription&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The new Canary and Parakeet models offer examples of the kinds of models developers can build with Granary, customized to their target applications. Canary-1b-v2 is optimized for accuracy on complex tasks, while parakeet-tdt-0.6b-v3 is designed for high-speed, low-latency tasks.&lt;/p&gt;
&lt;p&gt;By sharing the methodology behind the Granary dataset and these two models, NVIDIA is enabling the global speech AI developer community to adapt this data processing workflow to other ASR or AST models or additional languages, accelerating speech AI innovation.&lt;/p&gt;
&lt;p&gt;Canary-1b-v2, available under a permissive license, expands the Canary family’s supported languages from four to 25. It offers transcription and translation quality comparable to models 3x larger while running inference up to 10x faster.&lt;/p&gt;

&lt;p&gt;NVIDIA NeMo, a modular software suite for managing the AI agent lifecycle, accelerated speech AI model development. NeMo Curator, part of the software suite, enabled the team to filter out synthetic examples from the source data so that only high-quality samples were used for model training. The team also harnessed the NeMo Speech Data Processor toolkit for tasks like aligning transcripts with audio files and converting data into the required formats.&lt;/p&gt;
&lt;p&gt;Parakeet-tdt-0.6b-v3 prioritizes high throughput and is capable of transcribing 24-minute audio segments in a single inference pass. The model automatically detects the input audio language and transcribes without additional prompting steps.&lt;/p&gt;
&lt;p&gt;Both Canary and Parakeet models provide accurate punctuation, capitalization and word-level timestamps in their outputs.&lt;/p&gt;
&lt;p&gt;Read more on GitHub and get started with Granary on Hugging Face.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/speech-ai-dataset-models/</guid><pubDate>Fri, 15 Aug 2025 07:00:30 +0000</pubDate></item><item><title>Human-in-the-loop work drives AI powering Alibaba’s smart glasses (AI News)</title><link>https://www.artificialintelligence-news.com/news/human-in-the-loop-work-drives-ai-powering-alibabas-smart-glasses/</link><description>&lt;p&gt;Alibaba is moving into the smart glasses market with a device powered by its own AI models, part of a wider $52.4 billion furthering of AI and cloud computing. The Quark AI Glasses marks the company’s first step into the wearables category and is due to launch in China by the end of 2025.&lt;/p&gt;&lt;p&gt;The glasses will run on Alibaba’s Qwen large language model and its AI assistant, Quark. Quark is already available as an app in China, but this will be the first time the company is pairing it with hardware to reach more users.&lt;/p&gt;&lt;p&gt;The Hangzhou-based firm has been one of China’s more active AI developers, rolling out models designed to compete with systems from companies like OpenAI. By moving into smart glasses, it joins a growing group of tech players betting on wearables as the next major computing platform alongside smartphones.&lt;/p&gt;&lt;h3&gt;Pushing into hardware&lt;/h3&gt;&lt;p&gt;The Quark AI Glasses will enter a market that already includes Meta’s smart glasses made with Ray-Ban and a model launched this year by Xiaomi. Alibaba’s version will offer hands-free calling, music streaming, real-time translation, meeting transcription, and a built-in camera.&lt;/p&gt;&lt;p&gt;Alibaba operates a broad set of services in China and the glasses will connect to that ecosystem. Users will be able to access navigation, make payments through Alipay, compare prices on Taobao, and tap into other Alibaba-owned platforms like mapping and travel booking.&lt;/p&gt;&lt;p&gt;While the company has outlined some features, it has not revealed the price or detailed specifications.&lt;/p&gt;&lt;h3&gt;The data behind the devices&lt;/h3&gt;&lt;p&gt;Smart glasses like Alibaba’s depend on AI systems that can recognise images, interpret context, and respond in natural language. The abilities rely on huge amounts of labelled data – information that has been reviewed and tagged by humans so the AI can learn from it.&lt;/p&gt;&lt;p&gt;That process often involves “human-in-the-loop” (HITL) systems, where people provide input at key stages of training and testing. To understand how this works in practice, &lt;em&gt;AI News&lt;/em&gt; spoke with Henry Chen, co-founder of Sapien, a company that manages large, distributed workforces for data labelling. Chen discussed common misunderstandings, the demand for skilled contributors, and how China’s AI growth is influencing the industry.&lt;/p&gt;&lt;h3&gt;Misconceptions about HITL&lt;/h3&gt;&lt;p&gt;One common belief is that HITL is simply data labelling. Chen said it’s more complex, involving decisions on edge cases, judgement calls, and ongoing evaluation. “Continuous feedback is what makes HITL work instead of one-off datasets,” he said.&lt;/p&gt;&lt;p&gt;Another misconception is that the work is low-skilled. Chen said the rise of industry-specific AI has created demand for domain experts like doctors, lawyers, and scientists to contribute their knowledge.&lt;/p&gt;&lt;p&gt;Sapien works with 1.8 million contributors in 110 countries. For complex tasks like contextual understanding or visual recognition, maintaining quality is critical. Chen said the company uses peer validation, contributor reputation tracking, and aligned incentives to ensure consistent results.&lt;/p&gt;&lt;h3&gt;China’s AI growth and demand for labelling&lt;/h3&gt;&lt;p&gt;China’s AI sector is expanding quickly, and demand for data labelling is catching up to the levels of the US. While China has its own rules and regulations, Chen said the types of projects are increasingly similar to those in other major markets.&lt;/p&gt;&lt;p&gt;With such a large and dispersed workforce, Sapien uses on-chain technology to make payments transparent and give the community a say in which projects are worth pursuing. By operating without traditional offices, Chen said they avoid some workplace issues and focus on rewarding contributors for the value they deliver.&lt;/p&gt;&lt;p&gt;Automation is changing data labelling, but Chen believes humans will remain central to certain types of work. Tasks involving cultural nuance, sarcasm, rare diseases, niche languages, or complex sentiment will still need human review. “Humans will shift focus towards long-tail data and new vertical domains,” he said, predicting a rise in AI-assisted labelling while people handle the most challenging cases.&lt;/p&gt;&lt;p&gt;Sensitive projects, like the IP of large corporations or international organisations, require strict controls. Chen said Sapien vets and trains enterprise contributors, uses data minimisation and access controls, and follows compliance rules set by clients. The company works under frameworks like SOC 2 Type 2, GDPR, and HIPAA.&lt;/p&gt;&lt;h3&gt;Looking ahead&lt;/h3&gt;&lt;p&gt;As AI models become better at learning from unlabelled data – known as self-supervised learning – some expect the need for human labelling to shrink. Chen sees the role of human contributors changing rather than disappearing.&lt;/p&gt;&lt;p&gt;“We will evolve into a more specialised industry,” he said, noting that Sapien is already doing more work on evaluating synthetic data and model outputs. He expects future projects to focus on curating unique “ground truth” datasets, assessing AI performance, and providing domain-specific expertise.&lt;/p&gt;&lt;h3&gt;From glasses to the broader AI race&lt;/h3&gt;&lt;p&gt;Alibaba’s smart glasses highlight how far AI has moved into everyday products. While they may be one of many wearable devices in the market by 2025, the combination of Alibaba’s in-house language model, its existing services, and hardware integration could make them stand out for users in China.&lt;/p&gt;&lt;p&gt;At the same time, products like these depend on a complex supply chain of human expertise, from the engineers building the models to the contributors refining the data they use. Companies like Sapien operate behind the scenes, making sure AI systems have the information they need to function more accurately and responsibly.&lt;/p&gt;&lt;p&gt;Whether in the form of smart glasses, virtual assistants, or other yet-to-be-released devices, AI-driven hardware is becoming a new way for companies to bring their services directly to consumers. For Alibaba, the Quark AI Glasses are both a product launch and a statement about where it sees growth – in technology that combines software, hardware, and human input.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Panos Sakalakis)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Alibaba’s AI coding tool raises security concerns in the West&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Alibaba is moving into the smart glasses market with a device powered by its own AI models, part of a wider $52.4 billion furthering of AI and cloud computing. The Quark AI Glasses marks the company’s first step into the wearables category and is due to launch in China by the end of 2025.&lt;/p&gt;&lt;p&gt;The glasses will run on Alibaba’s Qwen large language model and its AI assistant, Quark. Quark is already available as an app in China, but this will be the first time the company is pairing it with hardware to reach more users.&lt;/p&gt;&lt;p&gt;The Hangzhou-based firm has been one of China’s more active AI developers, rolling out models designed to compete with systems from companies like OpenAI. By moving into smart glasses, it joins a growing group of tech players betting on wearables as the next major computing platform alongside smartphones.&lt;/p&gt;&lt;h3&gt;Pushing into hardware&lt;/h3&gt;&lt;p&gt;The Quark AI Glasses will enter a market that already includes Meta’s smart glasses made with Ray-Ban and a model launched this year by Xiaomi. Alibaba’s version will offer hands-free calling, music streaming, real-time translation, meeting transcription, and a built-in camera.&lt;/p&gt;&lt;p&gt;Alibaba operates a broad set of services in China and the glasses will connect to that ecosystem. Users will be able to access navigation, make payments through Alipay, compare prices on Taobao, and tap into other Alibaba-owned platforms like mapping and travel booking.&lt;/p&gt;&lt;p&gt;While the company has outlined some features, it has not revealed the price or detailed specifications.&lt;/p&gt;&lt;h3&gt;The data behind the devices&lt;/h3&gt;&lt;p&gt;Smart glasses like Alibaba’s depend on AI systems that can recognise images, interpret context, and respond in natural language. The abilities rely on huge amounts of labelled data – information that has been reviewed and tagged by humans so the AI can learn from it.&lt;/p&gt;&lt;p&gt;That process often involves “human-in-the-loop” (HITL) systems, where people provide input at key stages of training and testing. To understand how this works in practice, &lt;em&gt;AI News&lt;/em&gt; spoke with Henry Chen, co-founder of Sapien, a company that manages large, distributed workforces for data labelling. Chen discussed common misunderstandings, the demand for skilled contributors, and how China’s AI growth is influencing the industry.&lt;/p&gt;&lt;h3&gt;Misconceptions about HITL&lt;/h3&gt;&lt;p&gt;One common belief is that HITL is simply data labelling. Chen said it’s more complex, involving decisions on edge cases, judgement calls, and ongoing evaluation. “Continuous feedback is what makes HITL work instead of one-off datasets,” he said.&lt;/p&gt;&lt;p&gt;Another misconception is that the work is low-skilled. Chen said the rise of industry-specific AI has created demand for domain experts like doctors, lawyers, and scientists to contribute their knowledge.&lt;/p&gt;&lt;p&gt;Sapien works with 1.8 million contributors in 110 countries. For complex tasks like contextual understanding or visual recognition, maintaining quality is critical. Chen said the company uses peer validation, contributor reputation tracking, and aligned incentives to ensure consistent results.&lt;/p&gt;&lt;h3&gt;China’s AI growth and demand for labelling&lt;/h3&gt;&lt;p&gt;China’s AI sector is expanding quickly, and demand for data labelling is catching up to the levels of the US. While China has its own rules and regulations, Chen said the types of projects are increasingly similar to those in other major markets.&lt;/p&gt;&lt;p&gt;With such a large and dispersed workforce, Sapien uses on-chain technology to make payments transparent and give the community a say in which projects are worth pursuing. By operating without traditional offices, Chen said they avoid some workplace issues and focus on rewarding contributors for the value they deliver.&lt;/p&gt;&lt;p&gt;Automation is changing data labelling, but Chen believes humans will remain central to certain types of work. Tasks involving cultural nuance, sarcasm, rare diseases, niche languages, or complex sentiment will still need human review. “Humans will shift focus towards long-tail data and new vertical domains,” he said, predicting a rise in AI-assisted labelling while people handle the most challenging cases.&lt;/p&gt;&lt;p&gt;Sensitive projects, like the IP of large corporations or international organisations, require strict controls. Chen said Sapien vets and trains enterprise contributors, uses data minimisation and access controls, and follows compliance rules set by clients. The company works under frameworks like SOC 2 Type 2, GDPR, and HIPAA.&lt;/p&gt;&lt;h3&gt;Looking ahead&lt;/h3&gt;&lt;p&gt;As AI models become better at learning from unlabelled data – known as self-supervised learning – some expect the need for human labelling to shrink. Chen sees the role of human contributors changing rather than disappearing.&lt;/p&gt;&lt;p&gt;“We will evolve into a more specialised industry,” he said, noting that Sapien is already doing more work on evaluating synthetic data and model outputs. He expects future projects to focus on curating unique “ground truth” datasets, assessing AI performance, and providing domain-specific expertise.&lt;/p&gt;&lt;h3&gt;From glasses to the broader AI race&lt;/h3&gt;&lt;p&gt;Alibaba’s smart glasses highlight how far AI has moved into everyday products. While they may be one of many wearable devices in the market by 2025, the combination of Alibaba’s in-house language model, its existing services, and hardware integration could make them stand out for users in China.&lt;/p&gt;&lt;p&gt;At the same time, products like these depend on a complex supply chain of human expertise, from the engineers building the models to the contributors refining the data they use. Companies like Sapien operate behind the scenes, making sure AI systems have the information they need to function more accurately and responsibly.&lt;/p&gt;&lt;p&gt;Whether in the form of smart glasses, virtual assistants, or other yet-to-be-released devices, AI-driven hardware is becoming a new way for companies to bring their services directly to consumers. For Alibaba, the Quark AI Glasses are both a product launch and a statement about where it sees growth – in technology that combines software, hardware, and human input.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Panos Sakalakis)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Alibaba’s AI coding tool raises security concerns in the West&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/human-in-the-loop-work-drives-ai-powering-alibabas-smart-glasses/</guid><pubDate>Fri, 15 Aug 2025 08:38:04 +0000</pubDate></item><item><title>Why US federal health agencies are abandoning mRNA vaccines (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/15/1121885/why-us-federal-health-agencies-are-abandoning-mrna-vaccines/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2210910732.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This time five years ago, we were in the throes of the covid-19 pandemic. By August 2020, we’d seen school closures, national lockdowns, and widespread panic. That year, the coronavirus&amp;nbsp;was responsible for around 3 million deaths, according to the World Health Organization.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Then came the vaccines.&lt;/strong&gt; The first mRNA vaccines for covid were authorized for use in December 2020. By the end of the following month, over 100 million doses had been administered.&amp;nbsp;Billions more have been administered since then. The vaccines worked well and are thought to have saved millions of lives.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The US government played an important role in the introduction of these vaccines, providing $18 billion to support their development as part of Operation Warp Speed.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But now, that government is turning its back on the technology.&lt;/strong&gt; Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccines’ effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.&lt;/p&gt; 
 &lt;p&gt;Plenty of claims are being thrown about. Let’s consider the evidence.&lt;/p&gt;  &lt;p&gt;mRNA is a molecule found in cells that essentially helps DNA make proteins. The vaccines work in a similar way, except they carry genetic instructions for proteins found on the surface of the coronavirus. This can help train our immune systems to tackle the virus itself.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Research into mRNA vaccines has been underway for decades. &lt;/strong&gt;But things really kicked into gear when the virus behind covid-19 triggered a pandemic in 2020. A huge international effort—along with plenty of funding—fast-tracked research and development.&lt;/p&gt;  &lt;p&gt;The genetic code for the Sars-CoV-2 virus was sequenced in January 2020. The first vaccines were being administered by the end of that year. That’s &lt;em&gt;wildly&lt;/em&gt; fast by pharma standards—drugs can typically spend around a decade in development.&lt;/p&gt;  &lt;p&gt;And they seemed to work really well. Early trials in tens of thousands of volunteers suggested that Pfizer and BioNTech’s vaccine conferred “95% protection against covid-19.” No vaccine is perfect, but for a disease that was responsible for millions of deaths, the figures were impressive.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Still, there were naysayers. Including Robert F. Kennedy Jr., the notorious antivaccine activist who currently leads the US’s health agencies. &lt;/strong&gt;He&amp;nbsp;has called covid vaccines “unsafe and ineffective.” In 2021, he&amp;nbsp;petitioned the US Food and Drug Administration to revoke the authorization for covid vaccines. That same year, Instagram removed his account from the platform&amp;nbsp;after he repeatedly shared “debunked claims about the coronavirus or vaccines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;So perhaps we shouldn’t have been surprised when the US Department of Health and Human Services, which RFK Jr. now heads,&amp;nbsp;announced “the beginning of a coordinated wind-down” of mRNA vaccine development earlier this month. HHS is canceling almost $500 million worth of funding for the technology. “The data show these vaccines fail to protect effectively against upper respiratory infections like covid and flu,” Kennedy said in&amp;nbsp;a statement.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Well, as we’ve seen, the mRNA covid vaccines were hugely effective during the pandemic.&lt;/strong&gt; And researchers are working on other mRNA vaccines for infections including flu. Our current flu vaccines aren’t ideal—they are produced slowly in a process that requires hen’s eggs, based on predictions about which flu strains are likely to be prominent in the winter. They’re not all that protective.&lt;/p&gt;  &lt;p&gt;mRNA vaccines, on the other hand, can be made quickly and cheaply, perhaps once we already know which flu strains we need to protect against. And scientists are making progress with&amp;nbsp;universal flu vaccines—drugs that could potentially protect against multiple flu strains.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Kennedy’s other claim is that the vaccines aren’t safe. &lt;/strong&gt;There have certainly been reports of adverse events. Usually these are mild and short-lived—most people will be familiar with the fatigue and flu-like symptoms that can follow a covid jab. But some are more serious: Some people have developed neurological and cardiovascular conditions.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;These problems are rare, according to an&amp;nbsp;evaluation of adverse outcomes in almost 100 million people who received covid vaccines. Most studies of mRNA vaccines haven’t reported an increase in the risk of Guillain-Barré syndrome, a condition that affects nerves and has been linked to covid vaccines.&lt;/p&gt;  &lt;p&gt;Covid vaccines can increase the risk of myocarditis and pericarditis in young men. But the picture isn’t straightforward. Vaccinated individuals appear to have double the risk of myocarditis compared with unvaccinated people. But the overall risk is still low. And it’s still not as high as&amp;nbsp;the risk of myocarditis following a covid infection.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And then there are the claims that mRNA vaccines don’t have the support of the public.&lt;/strong&gt; That’s what Jay Bhattacharya, director of the NIH, wrote in&amp;nbsp;an opinion piece published in the&lt;em&gt; Washington Post&lt;/em&gt; on Wednesday.&lt;/p&gt;  &lt;p&gt;“No matter how elegant the science, a platform that lacks credibility among the people it seeks to protect cannot fulfill its public health mission,” Bhattacharya wrote. He blamed the Biden administration, which he wrote “did not manage public trust in the coronavirus vaccines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;&lt;strong&gt;It’s an interesting take from someone who played a pretty significant role in undermining public trust in covid policies, including vaccine mandates.&lt;/strong&gt; In 2020, Bhattacharya coauthored the Great Barrington Declaration—an open letter making the case against lockdowns. He became a vocal critic of US health agencies, including the NIH, and their handling of the outbreak. Unlike Kennedy, Bhattacharya hasn’t called the vaccines unsafe or ineffective. But he&amp;nbsp;has called vaccine mandates “unethical.”&lt;/p&gt;  &lt;p&gt;Curiously, the US government doesn’t seem to be turning away from &lt;em&gt;all&lt;/em&gt; vaccine research. Just work on mRNA vaccines. Some of the funding budget originally earmarked for covid vaccines will be redirected to two senior staffers at the NIH who are exploring the use of an old vaccine technology that makes use of inactivated viruses—a move that&amp;nbsp;researchers are describing as “troubling” and “appalling,” according to reporting by &lt;em&gt;Science&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Not all mRNA research is being abandoned, either.&lt;/strong&gt; Bhattacharya has expressed his support for research into the use of mRNA-based treatments for cancer.&amp;nbsp;Such “vaccine therapeutics” were being explored before covid came along. (Notably, Bhattacharya isn’t referring to them as “vaccines.”)&lt;/p&gt;  &lt;p&gt;It is difficult to predict how this will all shake out for mRNA vaccines. We mustn’t forget that this technology helped save millions of lives and shows huge promise for the development of cheap, effective, and potentially universal vaccines. Let’s hope that the recent upsets won’t prevent it from achieving its potential.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;br /&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2210910732.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This time five years ago, we were in the throes of the covid-19 pandemic. By August 2020, we’d seen school closures, national lockdowns, and widespread panic. That year, the coronavirus&amp;nbsp;was responsible for around 3 million deaths, according to the World Health Organization.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Then came the vaccines.&lt;/strong&gt; The first mRNA vaccines for covid were authorized for use in December 2020. By the end of the following month, over 100 million doses had been administered.&amp;nbsp;Billions more have been administered since then. The vaccines worked well and are thought to have saved millions of lives.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The US government played an important role in the introduction of these vaccines, providing $18 billion to support their development as part of Operation Warp Speed.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But now, that government is turning its back on the technology.&lt;/strong&gt; Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccines’ effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.&lt;/p&gt; 
 &lt;p&gt;Plenty of claims are being thrown about. Let’s consider the evidence.&lt;/p&gt;  &lt;p&gt;mRNA is a molecule found in cells that essentially helps DNA make proteins. The vaccines work in a similar way, except they carry genetic instructions for proteins found on the surface of the coronavirus. This can help train our immune systems to tackle the virus itself.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Research into mRNA vaccines has been underway for decades. &lt;/strong&gt;But things really kicked into gear when the virus behind covid-19 triggered a pandemic in 2020. A huge international effort—along with plenty of funding—fast-tracked research and development.&lt;/p&gt;  &lt;p&gt;The genetic code for the Sars-CoV-2 virus was sequenced in January 2020. The first vaccines were being administered by the end of that year. That’s &lt;em&gt;wildly&lt;/em&gt; fast by pharma standards—drugs can typically spend around a decade in development.&lt;/p&gt;  &lt;p&gt;And they seemed to work really well. Early trials in tens of thousands of volunteers suggested that Pfizer and BioNTech’s vaccine conferred “95% protection against covid-19.” No vaccine is perfect, but for a disease that was responsible for millions of deaths, the figures were impressive.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Still, there were naysayers. Including Robert F. Kennedy Jr., the notorious antivaccine activist who currently leads the US’s health agencies. &lt;/strong&gt;He&amp;nbsp;has called covid vaccines “unsafe and ineffective.” In 2021, he&amp;nbsp;petitioned the US Food and Drug Administration to revoke the authorization for covid vaccines. That same year, Instagram removed his account from the platform&amp;nbsp;after he repeatedly shared “debunked claims about the coronavirus or vaccines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;So perhaps we shouldn’t have been surprised when the US Department of Health and Human Services, which RFK Jr. now heads,&amp;nbsp;announced “the beginning of a coordinated wind-down” of mRNA vaccine development earlier this month. HHS is canceling almost $500 million worth of funding for the technology. “The data show these vaccines fail to protect effectively against upper respiratory infections like covid and flu,” Kennedy said in&amp;nbsp;a statement.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Well, as we’ve seen, the mRNA covid vaccines were hugely effective during the pandemic.&lt;/strong&gt; And researchers are working on other mRNA vaccines for infections including flu. Our current flu vaccines aren’t ideal—they are produced slowly in a process that requires hen’s eggs, based on predictions about which flu strains are likely to be prominent in the winter. They’re not all that protective.&lt;/p&gt;  &lt;p&gt;mRNA vaccines, on the other hand, can be made quickly and cheaply, perhaps once we already know which flu strains we need to protect against. And scientists are making progress with&amp;nbsp;universal flu vaccines—drugs that could potentially protect against multiple flu strains.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Kennedy’s other claim is that the vaccines aren’t safe. &lt;/strong&gt;There have certainly been reports of adverse events. Usually these are mild and short-lived—most people will be familiar with the fatigue and flu-like symptoms that can follow a covid jab. But some are more serious: Some people have developed neurological and cardiovascular conditions.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;These problems are rare, according to an&amp;nbsp;evaluation of adverse outcomes in almost 100 million people who received covid vaccines. Most studies of mRNA vaccines haven’t reported an increase in the risk of Guillain-Barré syndrome, a condition that affects nerves and has been linked to covid vaccines.&lt;/p&gt;  &lt;p&gt;Covid vaccines can increase the risk of myocarditis and pericarditis in young men. But the picture isn’t straightforward. Vaccinated individuals appear to have double the risk of myocarditis compared with unvaccinated people. But the overall risk is still low. And it’s still not as high as&amp;nbsp;the risk of myocarditis following a covid infection.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And then there are the claims that mRNA vaccines don’t have the support of the public.&lt;/strong&gt; That’s what Jay Bhattacharya, director of the NIH, wrote in&amp;nbsp;an opinion piece published in the&lt;em&gt; Washington Post&lt;/em&gt; on Wednesday.&lt;/p&gt;  &lt;p&gt;“No matter how elegant the science, a platform that lacks credibility among the people it seeks to protect cannot fulfill its public health mission,” Bhattacharya wrote. He blamed the Biden administration, which he wrote “did not manage public trust in the coronavirus vaccines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;&lt;strong&gt;It’s an interesting take from someone who played a pretty significant role in undermining public trust in covid policies, including vaccine mandates.&lt;/strong&gt; In 2020, Bhattacharya coauthored the Great Barrington Declaration—an open letter making the case against lockdowns. He became a vocal critic of US health agencies, including the NIH, and their handling of the outbreak. Unlike Kennedy, Bhattacharya hasn’t called the vaccines unsafe or ineffective. But he&amp;nbsp;has called vaccine mandates “unethical.”&lt;/p&gt;  &lt;p&gt;Curiously, the US government doesn’t seem to be turning away from &lt;em&gt;all&lt;/em&gt; vaccine research. Just work on mRNA vaccines. Some of the funding budget originally earmarked for covid vaccines will be redirected to two senior staffers at the NIH who are exploring the use of an old vaccine technology that makes use of inactivated viruses—a move that&amp;nbsp;researchers are describing as “troubling” and “appalling,” according to reporting by &lt;em&gt;Science&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Not all mRNA research is being abandoned, either.&lt;/strong&gt; Bhattacharya has expressed his support for research into the use of mRNA-based treatments for cancer.&amp;nbsp;Such “vaccine therapeutics” were being explored before covid came along. (Notably, Bhattacharya isn’t referring to them as “vaccines.”)&lt;/p&gt;  &lt;p&gt;It is difficult to predict how this will all shake out for mRNA vaccines. We mustn’t forget that this technology helped save millions of lives and shows huge promise for the development of cheap, effective, and potentially universal vaccines. Let’s hope that the recent upsets won’t prevent it from achieving its potential.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;br /&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/15/1121885/why-us-federal-health-agencies-are-abandoning-mrna-vaccines/</guid><pubDate>Fri, 15 Aug 2025 09:00:00 +0000</pubDate></item><item><title>Taiwan’s “silicon shield” could be weakening (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/15/1121358/taiwan-silicon-shield-tsmc-china-chip-manufacturing/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;One winter afternoon in a conference room in Taipei, a pair of twentysomething women dragged their friend across the floor. Lying on the ground in checkered pants and a brown sweatshirt, she was pretending to be either injured or dead. One friend picked her up by her arms, the other grabbed hold of her legs, and they managed to move her, despite momentarily breaking character to laugh at the awkwardness of the exercise. The three women had paid approximately $40 to spend their Sunday here, undergoing basic training to prepare for a possibility every Taiwanese citizen has an opinion about: Will China invade?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Taiwanese politics increasingly revolves around that question. China’s ruling party has wanted to seize Taiwan for more than half a century. But in recent years, China’s leader, Xi Jinping, has placed greater emphasis on the idea of “taking back” the island (which the Chinese Communist Party, or CCP, has never controlled). As China’s economic and military might has grown, some analysts believe the country now has the capacity to quarantine Taiwan whenever it wants, making the decision a calculation of costs and benefits.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Many in Taiwan and elsewhere think one major deterrent has to do with the island’s critical role in semiconductor manufacturing. Taiwan produces the majority of the world’s semiconductors and more than 90% of the most advanced chips needed for AI applications. Bloomberg Economics estimates that a blockade would cost the global economy, including China, $5 trillion in the first year alone.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“The international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Lai Ching-te, Taiwanese president &lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;The island, which is approximately the size of Maryland, owes its remarkably disproportionate chip dominance to the inventiveness and prowess of one company: Taiwan Semiconductor Manufacturing Company, or TSMC. The chipmaker, which reached a market capitalization of $1 trillion in July, has contributed more than any other to Taiwan’s irreplaceable role in the global semiconductor supply chain. Its clients include Apple and the leading chip designer Nvidia. Its chips are in your iPhone, your laptop, and the data centers that run ChatGPT.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;For a company that makes what amounts to an invisible product, TSMC holds a remarkably prominent role in Taiwanese society. I’ve heard people talk about it over background noise in loud bars in the southern city of Tainan and listened to Taipei cab drivers connect Taiwan’s security situation to the company, unprompted.&amp;nbsp;“Taiwan will be okay,” one driver told me as we sped by the national legislature, “because TSMC.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea is that world leaders (particularly the United States)—aware of the island’s critical role in the semiconductor supply chain—would retaliate economically, and perhaps militarily, if China were to attack Taiwan. That, in turn, deters Beijing. “Because TSMC is now the most recognizable company of Taiwan, it has embedded itself in a notion of Taiwan’s sovereignty,” says Rupert Hammond-Chambers, president of the US-Taiwan Business Council.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Now some Taiwan specialists and some of the island’s citi­zens are worried that this “silicon shield,” if it ever existed, is cracking. Facing pressure from Washington, TSMC is investing heavily in building out manufacturing capacity at its US hub in Arizona. It is also building facilities in Japan and Germany in addition to maintaining a factory in mainland China, where it has been producing less advanced legacy chips since 2016.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In Taiwan, there is a worry that expansion abroad will dilute the company’s power at home, making the US and other countries less inclined to feel Taiwan is worthy of defense. TSMC’s investments in the US have come with no guarantees for Taiwan in return, and high-ranking members of Taiwan’s opposition party have accused the ruling Democratic Progressive Party (DPP) of gambling with the future of the island. It doesn’t help that TSMC’s expansion abroad coincides with what many see as a worrying attitude in the White House. On top of his overarching “America First” philosophy, Donald Trump has declined to comment on the specific question of whether the US would intervene if China attempted to take Taiwan by force. “I don’t want to ever put myself in that position,” he said in February.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the same time, Beijing’s interest in Taiwan has continued unabated. While China is making progress toward semiconductor self-­sufficiency, it’s currently in a transition period, with companies relying on foreign-made chips manufactured in Taiwan—some in compliance with export controls and some smuggled in. Meanwhile, the CCP persistently suggests that seizing the island would bring about a kind of family reunion. “It is the common aspiration and sacred responsibility of all Chinese sons and daughters to realize the complete reunification of the motherland,” reads a statement released by the foreign ministry after Nancy Pelosi’s controversial 2022 visit to Taiwan. Though it’s impossible to know the full scope of Beijing’s motivations, there is also obvious strategic appeal: Controlling the island would give China deep-water access, which is critical for naval routes and submarines. Plus, it could significantly disrupt American AI firms’ access to advanced chips.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While China ramps up militarily, Taiwan is trying to make itself hard to ignore. The government is increasingly portraying the island as strategically essential to the global community, with semiconductors as its primary offering. “The international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost,” Taiwanese president Lai Ching-te said in an interview earlier this year with Japan’s Nippon Television.&amp;nbsp;Parts of the international community are hearing that message—and seizing the opportunity it presents: earlier this month, defense tech company Anduril Industries announced it is opening a new office in Taiwan, where it will be expanding partnerships and selling autonomous munitions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;For its part, the chip industry is actively showing its commitment to Taiwan. While other tech CEOs attended Trump’s second inauguration, for instance, Nvidia chief executive Jensen Huang met instead with TSMC’s chairman, and the company announced in May that its overseas headquarters would be in Taipei. In recent years, US government officials have also started paying more attention to Taiwan’s security situation and its interconnectedness with the chip industry. “There was a moment when everybody started waking up to the dependence on TSMC,” says Bonnie Glaser, managing director of the German Marshall Fund’s Indo-Pacific Program. The realization emerged, she says, over the last decade but was underscored in March of 2021, when Phil Davidson, then leader of the United States Indo-Pacific Command, testified to the Senate Armed Services Committee that there could be an invasion by 2027. Parallel to the security threat is the potential issue of overdependence, since so much chipmaking capability is concentrated in Taiwan.&lt;/p&gt;  &lt;p&gt;For now, Taiwan is facing a tangle of interests and time frames. China presents its claim to Taiwan as a historical inevitability, albeit one with an uncertain timeline, while the United States’ relationship with the island is focused on an AI-driven future. But from Taiwan’s perspective, the fight for its fate is playing out right now, amid unprecedented geopolitical instability. The next few years will likely determine whether TSMC’s chipmaking dominance is enough to convince the world Taiwan is worth protecting.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Innovation built on interconnectivity&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;TSMC is an uncontested success story. Its founder, Morris Chang, studied and worked in the United States before he was lured to Taiwan to start a new business on the promise of state support and inexpensive yet qualified labor. Chang founded TSMC in 1987 on the basis of his innovative business model. Rather than design and produce chips in-house, as was the norm, TSMC would act as a foundry: Clients would design the chips, and TSMC would make them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This focus on manufacturing allowed TSMC to optimize its operations, building up process knowledge and, eventually, outperforming competitors like Intel. It also freed up other businesses to go “fabless,” meaning they could stop maintaining their own semiconductor factories, or fabs, and throw their resources behind other parts of the chipmaking enterprise. Tapping into Taiwan’s domestic electronics supply chain proved effective and efficient for TSMC. Throughout the 1990s and early 2000s, global demand for semiconductors powering personal computers and other devices continued to grow. TSMC thrived.&lt;/p&gt; 

 &lt;p&gt;Then, in 2022, the US imposed export controls on China that restricted its access to advanced chips. Taiwan was forced to either comply, by cutting off Chinese clients, or risk losing the support of the country that was home to 70% of its client base—and, possibly, 100% of its hopes for external military support in the event of an attack.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Soon after, Chang announced that he believed globalization and free markets were “almost dead.” The nearly three years since have shown he was onto something. For one thing, in contrast to President Biden’s pursuit of supply chain integration with democratic allies, President Trump’s foreign policy is characterized by respect for big, undemocratic powers and punitive tariffs against both America’s rivals and its friends. Trump has largely abandoned Biden’s economic diplomacy with European and Asian allies but kept his China-targeted protectionism—and added his trademark transactionalism. In an unprecedented move earlier this month, the administration allowed Nvidia and AMD to sell previously banned chips to China on the condition that the companies pay the government 15% of revenues made from China sales.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Protectionism, it turns out, spurs self-reliance. China’s government has been making a massive effort to build up its domestic chip production capabilities—a goal that was identified at the beginning of Xi’s rise but has been turbocharged in the wake of Washington’s export controls.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Any hope the US has for significantly expanding domestic chip production comes from its friends—TSMC first among them. The semiconductor industry developed as a global endeavor out of practicality, playing to the strengths of each region: design in the US and manufacturing in Asia, with key inputs from Europe central to the process. Yet the US government, entrenched in its “tech war” with China, is now dead set on deglobalizing the chip supply chain, or at least onshoring as much of it as possible. There’s just one hiccup: The best chip manufacturer isn’t American. It’s TSMC. Even if some manufacturing happens in Arizona, the US still relies on Taiwan’s chipmaking ecosystem. And copying that supply chain outside Taiwan could be harder than the current administration imagines.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;Squarely in the middle&lt;/h3&gt;  &lt;p&gt;Taiwan’s modern security uncertainties stem from the long-­contested issue of the island’s sovereignty. After losing the first Sino-Japanese War in the late 1800s, the Qing dynasty forfeited Taiwan to Japanese imperial control. It was Japan’s “model colony” until 1945, when postwar negotiations resulted in its transfer to the Republic of China under Chiang Kai-shek of the Nationalist Party, known as the KMT. The insurgent CCP under Mao Zedong ultimately defeated the Nationalists in a civil war fought on the mainland until 1949. Chiang and many of his party’s defeated generals decamped to Taiwan, controlling it under martial law for nearly 40 years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Taiwan held its first free democratic elections in 1996, kicking off a two-party rivalry between the KMT, which favors closer relations with Beijing, and the DPP, which opposes integration with China. Kitchen-table issues like economic growth are central to Taiwanese elections, but so is the overarching question of how best to handle the threat of invasion, which has persisted for nearly 80 years. The DPP is increasingly calling for raising defense spending and civilian preparedness to make sure Taiwan is ready for the worst, while the KMT supports direct talks with Beijing.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="cactus and the sign in front of the TSMC plant in Arizona" class="wp-image-1121496" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2202653436.jpg?w=777" /&gt;&lt;figcaption class="wp-element-caption"&gt;In March 2025, President Trump and TSMC CEO C.C. Wei jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMC’s US hub in Arizona.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;REBECCA NOBLE/BLOOMBERG VIA GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Meanwhile, Chinese military incursions around Taiwan—known as “gray zone” tactics because they fall short of acts of war—are increasingly frequent. In May, Taiwan’s defense ministry reportedly estimated that Chinese warplanes were entering Taiwan’s air defense zone more than 200 times a month, up from fewer than 10 times per month five years ago. China has conducted drills mirroring the actions needed for a full-scale invasion or a blockade, which would cut Taiwan off from the outside world. Chinese military officials are now publicly talking about achieving a blockade, says Lyle Morris, an expert on foreign policy and national security at the Asia Society Policy Institute. “They’re punishing Lai and the DPP,” Morris says. Meanwhile, the CCP has its own people to answer to: When it comes to the Taiwan issue, Morris says, “Beijing is probably quite worried about the people of China being upset if they aren’t hawkish enough or if they come out looking weak.” Indeed, in response to Lai’s recent policy statements, including one declaring that China is a “hostile foreign force,” Gao Zhikai, a prominent scholar in China who opposes Taiwanese independence, recently wrote, “The reunification with the motherland cannot be endlessly delayed. Decisive action must be taken.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Intimidation from China has made some ordinary Taiwanese citizens more concerned; according to a recent poll conducted by a defense-focused think tank, 51% think defense spending should be increased (although 65% of respondents said they thought an attack within five years was “unlikely”). No matter how much money Taipei spends, the sheer military imbalance between China and Taiwan means Taiwan would need help. But especially in the wake of Ukraine’s experience, many believe US aid would be contingent on whether Taiwan demonstrates the will to defend itself. “Based on war games, Taiwan would have to hold out for a month before the US could potentially intervene,” says Iris Shaw, director of the DPP mission in the US. And support from Taiwan’s neighbors like Japan might be contingent on US involvement.&lt;/p&gt; 
 &lt;p&gt;But how likely is the US to intervene in such a scenario?&amp;nbsp;The author Craig Addison popularized the argument that Taiwan’s fate is tied to its chip production prowess in his 2001 book &lt;em&gt;Silicon Shield: Taiwan’s Protection Against Chinese Attack&lt;/em&gt;. Back then, Addison wrote that although the US had been intentionally vague about whether it would go to war to protect the island, America’s technological reliance on “a safe and productive Taiwan” made it highly probable that Washington would intervene. President Joe Biden deviated from those decades of calculated ambiguity by asserting multiple times that America &lt;em&gt;would&lt;/em&gt; defend the island in the event of an attack. Yet now, Trump seems to have taken the opposite position, possibly presenting an opportunity for Beijing.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;TSMC in the Trump era&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself. It’s a common belief in Taiwan that forging stronger ties to the US could be dangerous. According to a public opinion poll released in January, 34.7% of Taiwanese believe that a “pro-US” policy provokes China and will cause a war.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But the Lai administration’s foreign policy is “inexorably intertwined with the notion that a strong relationship with the US is essential,” says Hammond-Chambers.&lt;/p&gt;  &lt;p&gt;Bolstering US support may not be the only reason TSMC is building fabs outside Taiwan. As the company readily points out, the majority of its customers are American. TSMC is also responding to its home base’s increasingly apparent land and energy limitations: finding land to build new fabs sometimes causes rifts with Taiwanese people who, for example, don’t want their temples and ancestral burial sites repurposed as science parks. Taiwan also relies on imports to meet more than 95% of its energy needs, and the dominant DPP has pledged to phase out nuclear, Taiwan’s most viable yet most hotly contested renewable energy source. Geopolitical tensions compound these physical restraints: Even if TSMC would never say as much, it’s fairly likely that if China did attack Taiwan, the firm would rather remain operational in other countries than be wiped out completely.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;However, building out TSMC’s manufacturing capabilities outside Taiwan will not be easy. “The ecosystem they created is truly unique. It’s a function of the talent pipeline, the culture, and laws in Taiwan; you can’t easily replicate it anywhere,” says Glaser. TSMC has 2,500 Taiwan-based suppliers. Plenty are within a couple of hours’ drive or an even shorter trip on high-speed rail. Taiwan has built a fully operational chip cluster, the product of four decades of innovation, industrial policy, and labor.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;As a result, it’s unclear whether TSMC will be able to copy its model and paste it into the suburbs of Phoenix, where it has 3,000 employees working on chip manufacturing. “Putting aside the geopolitical factor, they wouldn’t have expanded abroad,” says Feifei Hung, a researcher at the Asia Society. Rather than standalone facilities, the Arizona fabs are “appendages of TSMC that happen to be in Arizona,” says Paul Triolo, partner and tech policy lead at the international consulting firm DGA-Albright Stonebridge Group. When the full complex is operational, it will represent only a small percentage of TSMC’s overall capacity, most of which will remain in Taiwan. Triolo doubts the US buildout will yield results similar to what TSMC has built there: “Arizona ain’t that yet, and never will be.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, the second Trump administration has placed even more pressure on the company to “friendshore”—without providing any discernible signs of friendship. During this spring’s tariff frenzy, the administration threatened to hit Taiwan with a 32% “reciprocal” tariff, a move that was then paused and revived at 20% in late July (and was still being negotiated as of press time). The administration has also announced a 100% tariff on semiconductor imports, with the caveat that companies with US-based production, like TSMC, are exempt—though it’s unclear whether imports from critical suppliers in Taiwan will be tariffed. And the threat of a chip-specific tariff remains. “This is in line with [Trump’s] rhetoric of restoring manufacturing in the US and using tariffs as a one size fits all tool to force it,” says Nancy Wei, a trade and supply chain analyst at the Eurasia Group. The US is also apparently considering levying a $1 billion fine against TSMC after TSMC-made chips were reportedly found in some Huawei devices. &lt;/p&gt;  &lt;p&gt;Despite these kinds of maneuvers, TSMC has been steadfast in its attempts to get on Washington’s good side. In March, Trump and TSMC’s CEO, C.C. Wei, jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMC’s US hub in Arizona. The pledge represents the largest single source of foreign direct investment into the US, ever. While the deal was negotiated during Biden’s term, Trump was happy to take credit for ensuring that “the most powerful AI chips will be made right here in America.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;The Arizona buildout will also include an R&amp;amp;D facility—a critical element for tech transfer and intellectual-property development. Then there’s the very juicy cherry on top: TSMC announced in April that once all six new fabs are operational, 30% of its most advanced chips will be produced in Arizona. Up until then, the thinking was that US-based production would remain a generation or two behind. It looks as if the administration’s public and, presumably, private arm-twisting has paid off.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, as Trump cuts government programs and subsidies while demanding the “return” of manufacturing to the US, it’s TSMC that is running a technician apprenticeship program in Arizona to create good American jobs. TSMC’s leaders, Triolo says, must question how serious the Trump administration is about long-term industrial policy. They’re probably asking themselves, he says, “Do they understand what it takes to support the semiconductor industry, like our government does?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Dealing with an administration that is so explicitly “America first” represents “one of the biggest challenges in history for Taiwanese companies,” says Thung-Hong Lin, a sociology researcher at the Taipei-based Academia Sinica. Semiconductor manufacturing relies on reliability. Trump has so far offered TSMC no additional incentives supporting its US expansion—and started a trade war that has directly affected the semiconductor industry, partly by introducing irrevocable uncertainty. “Trump’s tariffs have set off a new, more intensified bifurcation of semiconductor supply chains,” says Chris Miller, author of &lt;em&gt;Chip War&lt;/em&gt;. For now, Miller says, TSMC must navigate a world in which the US and China are both intense competitors and, despite trade restrictions, important clients.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Warring narratives&lt;/h3&gt;  &lt;p&gt;China has been taking advantage of these changes to wage a war of disinformation. In response to Nancy Pelosi’s visit to Taiwan in 2022, when she was US Speaker of the House, Beijing sent warships, aircraft, and propaganda across the Taiwan Strait. Hackers using Chinese software infiltrated the display screens in Taiwan’s 7-Eleven stores to display messages telling “warmonger Pelosi” to “get out of Taiwan.” That might not be an act of war, but it’s close; “7” is an institution of daily life on the island. It is not difficult to imagine how a similar tactic might be used to spread more devastating disinformation, falsely alleging, for example, that Taiwan’s military has surrendered to China during a future crisis.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;Taiwan is “perpetually on the front lines” of cyberattacks from China, says Francesca Chen, a cybersecurity systems analyst at Taiwan’s Ministry of Digital Affairs. According to Taiwan’s National Security Bureau, instances of propaganda traceable to China grew by 60% in 2024 over the previous year, reaching 2.16 million.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121497" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2210855102-crop.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Visitors take selfies outside the TSMC Museum of Innovation in Hsinchu, Taiwan.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ANNABELLE CHIH/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Over the last few years, online discussion of TSMC’s investments in the US “has become a focal point” of China’s state-­sponsored disinformation campaigns aimed at Taiwan, Chen says. They claim TSMC is transferring its most advanced technology, talent, and resources to the US, “weakening Taiwan’s economic lifeline and critical position in global supply chains.” Key terms include “hollowing out Taiwan” and “de-Taiwanization.” This framing depicts TSMC’s diversification as a symbol of Taiwan’s vulnerability, Chen says. The idea is to exploit real domestic debates in Taiwan to generate heightened levels of internal division, weakening social cohesion and undermining trust in the government.&lt;/p&gt;  &lt;p&gt;Chinese officials haven’t been shy about echoing these messages out in the open: After the most recent US investment announcement in March, a spokesperson from China’s Taiwan Affairs Council accused Taiwan’s DPP of handing over TSMC as a “gift” to the US. (“TSMC turning into USMC?” asked a state media headline.) Former Taiwanese president Ma Ying-jeou posted an eerily similar criticism, alleging that TSMC’s US expansion amounted to “selling” the chipmaker in exchange for protection.&lt;/p&gt;  &lt;p&gt;TSMC’s expansion abroad could become a major issue in Taiwan’s 2028 presidential election. It plays directly into party politics: The KMT can accuse the DPP of sacrificing Taiwan’s technology assets to placate the US, and the DPP can accuse the KMT of cozying up with China, even as Beijing’s military incursions become a more evident part of daily life. It remains to be seen whether TSMC’s shift to the US will ultimately protect or weaken Taiwan—or have no effect on the island’s security and sovereignty. For now at least, China’s aspirations loom large.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To Beijing, unequivocally, Taiwan does not equal TSMC. Instead, it represents the final, unfulfilled stage of the Communist Party’s revolutionary struggle. Framed that way, China’s resolve to take the island could very well be nonnegotiable. That would mean if Taiwan is going to maintain a shield that protects it from the full weight of China’s political orthodoxy, it may need to be made of something much stronger than silicon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Johanna M. Costigan is a writer and editor focused on technology and geopolitics in the US, China, and Taiwan. She writes the newsletter &lt;/em&gt;The Long Game&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;One winter afternoon in a conference room in Taipei, a pair of twentysomething women dragged their friend across the floor. Lying on the ground in checkered pants and a brown sweatshirt, she was pretending to be either injured or dead. One friend picked her up by her arms, the other grabbed hold of her legs, and they managed to move her, despite momentarily breaking character to laugh at the awkwardness of the exercise. The three women had paid approximately $40 to spend their Sunday here, undergoing basic training to prepare for a possibility every Taiwanese citizen has an opinion about: Will China invade?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Taiwanese politics increasingly revolves around that question. China’s ruling party has wanted to seize Taiwan for more than half a century. But in recent years, China’s leader, Xi Jinping, has placed greater emphasis on the idea of “taking back” the island (which the Chinese Communist Party, or CCP, has never controlled). As China’s economic and military might has grown, some analysts believe the country now has the capacity to quarantine Taiwan whenever it wants, making the decision a calculation of costs and benefits.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Many in Taiwan and elsewhere think one major deterrent has to do with the island’s critical role in semiconductor manufacturing. Taiwan produces the majority of the world’s semiconductors and more than 90% of the most advanced chips needed for AI applications. Bloomberg Economics estimates that a blockade would cost the global economy, including China, $5 trillion in the first year alone.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“The international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Lai Ching-te, Taiwanese president &lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;The island, which is approximately the size of Maryland, owes its remarkably disproportionate chip dominance to the inventiveness and prowess of one company: Taiwan Semiconductor Manufacturing Company, or TSMC. The chipmaker, which reached a market capitalization of $1 trillion in July, has contributed more than any other to Taiwan’s irreplaceable role in the global semiconductor supply chain. Its clients include Apple and the leading chip designer Nvidia. Its chips are in your iPhone, your laptop, and the data centers that run ChatGPT.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;For a company that makes what amounts to an invisible product, TSMC holds a remarkably prominent role in Taiwanese society. I’ve heard people talk about it over background noise in loud bars in the southern city of Tainan and listened to Taipei cab drivers connect Taiwan’s security situation to the company, unprompted.&amp;nbsp;“Taiwan will be okay,” one driver told me as we sped by the national legislature, “because TSMC.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea is that world leaders (particularly the United States)—aware of the island’s critical role in the semiconductor supply chain—would retaliate economically, and perhaps militarily, if China were to attack Taiwan. That, in turn, deters Beijing. “Because TSMC is now the most recognizable company of Taiwan, it has embedded itself in a notion of Taiwan’s sovereignty,” says Rupert Hammond-Chambers, president of the US-Taiwan Business Council.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Now some Taiwan specialists and some of the island’s citi­zens are worried that this “silicon shield,” if it ever existed, is cracking. Facing pressure from Washington, TSMC is investing heavily in building out manufacturing capacity at its US hub in Arizona. It is also building facilities in Japan and Germany in addition to maintaining a factory in mainland China, where it has been producing less advanced legacy chips since 2016.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In Taiwan, there is a worry that expansion abroad will dilute the company’s power at home, making the US and other countries less inclined to feel Taiwan is worthy of defense. TSMC’s investments in the US have come with no guarantees for Taiwan in return, and high-ranking members of Taiwan’s opposition party have accused the ruling Democratic Progressive Party (DPP) of gambling with the future of the island. It doesn’t help that TSMC’s expansion abroad coincides with what many see as a worrying attitude in the White House. On top of his overarching “America First” philosophy, Donald Trump has declined to comment on the specific question of whether the US would intervene if China attempted to take Taiwan by force. “I don’t want to ever put myself in that position,” he said in February.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the same time, Beijing’s interest in Taiwan has continued unabated. While China is making progress toward semiconductor self-­sufficiency, it’s currently in a transition period, with companies relying on foreign-made chips manufactured in Taiwan—some in compliance with export controls and some smuggled in. Meanwhile, the CCP persistently suggests that seizing the island would bring about a kind of family reunion. “It is the common aspiration and sacred responsibility of all Chinese sons and daughters to realize the complete reunification of the motherland,” reads a statement released by the foreign ministry after Nancy Pelosi’s controversial 2022 visit to Taiwan. Though it’s impossible to know the full scope of Beijing’s motivations, there is also obvious strategic appeal: Controlling the island would give China deep-water access, which is critical for naval routes and submarines. Plus, it could significantly disrupt American AI firms’ access to advanced chips.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While China ramps up militarily, Taiwan is trying to make itself hard to ignore. The government is increasingly portraying the island as strategically essential to the global community, with semiconductors as its primary offering. “The international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost,” Taiwanese president Lai Ching-te said in an interview earlier this year with Japan’s Nippon Television.&amp;nbsp;Parts of the international community are hearing that message—and seizing the opportunity it presents: earlier this month, defense tech company Anduril Industries announced it is opening a new office in Taiwan, where it will be expanding partnerships and selling autonomous munitions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;For its part, the chip industry is actively showing its commitment to Taiwan. While other tech CEOs attended Trump’s second inauguration, for instance, Nvidia chief executive Jensen Huang met instead with TSMC’s chairman, and the company announced in May that its overseas headquarters would be in Taipei. In recent years, US government officials have also started paying more attention to Taiwan’s security situation and its interconnectedness with the chip industry. “There was a moment when everybody started waking up to the dependence on TSMC,” says Bonnie Glaser, managing director of the German Marshall Fund’s Indo-Pacific Program. The realization emerged, she says, over the last decade but was underscored in March of 2021, when Phil Davidson, then leader of the United States Indo-Pacific Command, testified to the Senate Armed Services Committee that there could be an invasion by 2027. Parallel to the security threat is the potential issue of overdependence, since so much chipmaking capability is concentrated in Taiwan.&lt;/p&gt;  &lt;p&gt;For now, Taiwan is facing a tangle of interests and time frames. China presents its claim to Taiwan as a historical inevitability, albeit one with an uncertain timeline, while the United States’ relationship with the island is focused on an AI-driven future. But from Taiwan’s perspective, the fight for its fate is playing out right now, amid unprecedented geopolitical instability. The next few years will likely determine whether TSMC’s chipmaking dominance is enough to convince the world Taiwan is worth protecting.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Innovation built on interconnectivity&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;TSMC is an uncontested success story. Its founder, Morris Chang, studied and worked in the United States before he was lured to Taiwan to start a new business on the promise of state support and inexpensive yet qualified labor. Chang founded TSMC in 1987 on the basis of his innovative business model. Rather than design and produce chips in-house, as was the norm, TSMC would act as a foundry: Clients would design the chips, and TSMC would make them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This focus on manufacturing allowed TSMC to optimize its operations, building up process knowledge and, eventually, outperforming competitors like Intel. It also freed up other businesses to go “fabless,” meaning they could stop maintaining their own semiconductor factories, or fabs, and throw their resources behind other parts of the chipmaking enterprise. Tapping into Taiwan’s domestic electronics supply chain proved effective and efficient for TSMC. Throughout the 1990s and early 2000s, global demand for semiconductors powering personal computers and other devices continued to grow. TSMC thrived.&lt;/p&gt; 

 &lt;p&gt;Then, in 2022, the US imposed export controls on China that restricted its access to advanced chips. Taiwan was forced to either comply, by cutting off Chinese clients, or risk losing the support of the country that was home to 70% of its client base—and, possibly, 100% of its hopes for external military support in the event of an attack.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Soon after, Chang announced that he believed globalization and free markets were “almost dead.” The nearly three years since have shown he was onto something. For one thing, in contrast to President Biden’s pursuit of supply chain integration with democratic allies, President Trump’s foreign policy is characterized by respect for big, undemocratic powers and punitive tariffs against both America’s rivals and its friends. Trump has largely abandoned Biden’s economic diplomacy with European and Asian allies but kept his China-targeted protectionism—and added his trademark transactionalism. In an unprecedented move earlier this month, the administration allowed Nvidia and AMD to sell previously banned chips to China on the condition that the companies pay the government 15% of revenues made from China sales.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Protectionism, it turns out, spurs self-reliance. China’s government has been making a massive effort to build up its domestic chip production capabilities—a goal that was identified at the beginning of Xi’s rise but has been turbocharged in the wake of Washington’s export controls.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Any hope the US has for significantly expanding domestic chip production comes from its friends—TSMC first among them. The semiconductor industry developed as a global endeavor out of practicality, playing to the strengths of each region: design in the US and manufacturing in Asia, with key inputs from Europe central to the process. Yet the US government, entrenched in its “tech war” with China, is now dead set on deglobalizing the chip supply chain, or at least onshoring as much of it as possible. There’s just one hiccup: The best chip manufacturer isn’t American. It’s TSMC. Even if some manufacturing happens in Arizona, the US still relies on Taiwan’s chipmaking ecosystem. And copying that supply chain outside Taiwan could be harder than the current administration imagines.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;Squarely in the middle&lt;/h3&gt;  &lt;p&gt;Taiwan’s modern security uncertainties stem from the long-­contested issue of the island’s sovereignty. After losing the first Sino-Japanese War in the late 1800s, the Qing dynasty forfeited Taiwan to Japanese imperial control. It was Japan’s “model colony” until 1945, when postwar negotiations resulted in its transfer to the Republic of China under Chiang Kai-shek of the Nationalist Party, known as the KMT. The insurgent CCP under Mao Zedong ultimately defeated the Nationalists in a civil war fought on the mainland until 1949. Chiang and many of his party’s defeated generals decamped to Taiwan, controlling it under martial law for nearly 40 years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Taiwan held its first free democratic elections in 1996, kicking off a two-party rivalry between the KMT, which favors closer relations with Beijing, and the DPP, which opposes integration with China. Kitchen-table issues like economic growth are central to Taiwanese elections, but so is the overarching question of how best to handle the threat of invasion, which has persisted for nearly 80 years. The DPP is increasingly calling for raising defense spending and civilian preparedness to make sure Taiwan is ready for the worst, while the KMT supports direct talks with Beijing.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="cactus and the sign in front of the TSMC plant in Arizona" class="wp-image-1121496" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2202653436.jpg?w=777" /&gt;&lt;figcaption class="wp-element-caption"&gt;In March 2025, President Trump and TSMC CEO C.C. Wei jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMC’s US hub in Arizona.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;REBECCA NOBLE/BLOOMBERG VIA GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Meanwhile, Chinese military incursions around Taiwan—known as “gray zone” tactics because they fall short of acts of war—are increasingly frequent. In May, Taiwan’s defense ministry reportedly estimated that Chinese warplanes were entering Taiwan’s air defense zone more than 200 times a month, up from fewer than 10 times per month five years ago. China has conducted drills mirroring the actions needed for a full-scale invasion or a blockade, which would cut Taiwan off from the outside world. Chinese military officials are now publicly talking about achieving a blockade, says Lyle Morris, an expert on foreign policy and national security at the Asia Society Policy Institute. “They’re punishing Lai and the DPP,” Morris says. Meanwhile, the CCP has its own people to answer to: When it comes to the Taiwan issue, Morris says, “Beijing is probably quite worried about the people of China being upset if they aren’t hawkish enough or if they come out looking weak.” Indeed, in response to Lai’s recent policy statements, including one declaring that China is a “hostile foreign force,” Gao Zhikai, a prominent scholar in China who opposes Taiwanese independence, recently wrote, “The reunification with the motherland cannot be endlessly delayed. Decisive action must be taken.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Intimidation from China has made some ordinary Taiwanese citizens more concerned; according to a recent poll conducted by a defense-focused think tank, 51% think defense spending should be increased (although 65% of respondents said they thought an attack within five years was “unlikely”). No matter how much money Taipei spends, the sheer military imbalance between China and Taiwan means Taiwan would need help. But especially in the wake of Ukraine’s experience, many believe US aid would be contingent on whether Taiwan demonstrates the will to defend itself. “Based on war games, Taiwan would have to hold out for a month before the US could potentially intervene,” says Iris Shaw, director of the DPP mission in the US. And support from Taiwan’s neighbors like Japan might be contingent on US involvement.&lt;/p&gt; 
 &lt;p&gt;But how likely is the US to intervene in such a scenario?&amp;nbsp;The author Craig Addison popularized the argument that Taiwan’s fate is tied to its chip production prowess in his 2001 book &lt;em&gt;Silicon Shield: Taiwan’s Protection Against Chinese Attack&lt;/em&gt;. Back then, Addison wrote that although the US had been intentionally vague about whether it would go to war to protect the island, America’s technological reliance on “a safe and productive Taiwan” made it highly probable that Washington would intervene. President Joe Biden deviated from those decades of calculated ambiguity by asserting multiple times that America &lt;em&gt;would&lt;/em&gt; defend the island in the event of an attack. Yet now, Trump seems to have taken the opposite position, possibly presenting an opportunity for Beijing.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;TSMC in the Trump era&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself. It’s a common belief in Taiwan that forging stronger ties to the US could be dangerous. According to a public opinion poll released in January, 34.7% of Taiwanese believe that a “pro-US” policy provokes China and will cause a war.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But the Lai administration’s foreign policy is “inexorably intertwined with the notion that a strong relationship with the US is essential,” says Hammond-Chambers.&lt;/p&gt;  &lt;p&gt;Bolstering US support may not be the only reason TSMC is building fabs outside Taiwan. As the company readily points out, the majority of its customers are American. TSMC is also responding to its home base’s increasingly apparent land and energy limitations: finding land to build new fabs sometimes causes rifts with Taiwanese people who, for example, don’t want their temples and ancestral burial sites repurposed as science parks. Taiwan also relies on imports to meet more than 95% of its energy needs, and the dominant DPP has pledged to phase out nuclear, Taiwan’s most viable yet most hotly contested renewable energy source. Geopolitical tensions compound these physical restraints: Even if TSMC would never say as much, it’s fairly likely that if China did attack Taiwan, the firm would rather remain operational in other countries than be wiped out completely.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;However, building out TSMC’s manufacturing capabilities outside Taiwan will not be easy. “The ecosystem they created is truly unique. It’s a function of the talent pipeline, the culture, and laws in Taiwan; you can’t easily replicate it anywhere,” says Glaser. TSMC has 2,500 Taiwan-based suppliers. Plenty are within a couple of hours’ drive or an even shorter trip on high-speed rail. Taiwan has built a fully operational chip cluster, the product of four decades of innovation, industrial policy, and labor.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;As a result, it’s unclear whether TSMC will be able to copy its model and paste it into the suburbs of Phoenix, where it has 3,000 employees working on chip manufacturing. “Putting aside the geopolitical factor, they wouldn’t have expanded abroad,” says Feifei Hung, a researcher at the Asia Society. Rather than standalone facilities, the Arizona fabs are “appendages of TSMC that happen to be in Arizona,” says Paul Triolo, partner and tech policy lead at the international consulting firm DGA-Albright Stonebridge Group. When the full complex is operational, it will represent only a small percentage of TSMC’s overall capacity, most of which will remain in Taiwan. Triolo doubts the US buildout will yield results similar to what TSMC has built there: “Arizona ain’t that yet, and never will be.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, the second Trump administration has placed even more pressure on the company to “friendshore”—without providing any discernible signs of friendship. During this spring’s tariff frenzy, the administration threatened to hit Taiwan with a 32% “reciprocal” tariff, a move that was then paused and revived at 20% in late July (and was still being negotiated as of press time). The administration has also announced a 100% tariff on semiconductor imports, with the caveat that companies with US-based production, like TSMC, are exempt—though it’s unclear whether imports from critical suppliers in Taiwan will be tariffed. And the threat of a chip-specific tariff remains. “This is in line with [Trump’s] rhetoric of restoring manufacturing in the US and using tariffs as a one size fits all tool to force it,” says Nancy Wei, a trade and supply chain analyst at the Eurasia Group. The US is also apparently considering levying a $1 billion fine against TSMC after TSMC-made chips were reportedly found in some Huawei devices. &lt;/p&gt;  &lt;p&gt;Despite these kinds of maneuvers, TSMC has been steadfast in its attempts to get on Washington’s good side. In March, Trump and TSMC’s CEO, C.C. Wei, jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMC’s US hub in Arizona. The pledge represents the largest single source of foreign direct investment into the US, ever. While the deal was negotiated during Biden’s term, Trump was happy to take credit for ensuring that “the most powerful AI chips will be made right here in America.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;The Arizona buildout will also include an R&amp;amp;D facility—a critical element for tech transfer and intellectual-property development. Then there’s the very juicy cherry on top: TSMC announced in April that once all six new fabs are operational, 30% of its most advanced chips will be produced in Arizona. Up until then, the thinking was that US-based production would remain a generation or two behind. It looks as if the administration’s public and, presumably, private arm-twisting has paid off.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, as Trump cuts government programs and subsidies while demanding the “return” of manufacturing to the US, it’s TSMC that is running a technician apprenticeship program in Arizona to create good American jobs. TSMC’s leaders, Triolo says, must question how serious the Trump administration is about long-term industrial policy. They’re probably asking themselves, he says, “Do they understand what it takes to support the semiconductor industry, like our government does?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Dealing with an administration that is so explicitly “America first” represents “one of the biggest challenges in history for Taiwanese companies,” says Thung-Hong Lin, a sociology researcher at the Taipei-based Academia Sinica. Semiconductor manufacturing relies on reliability. Trump has so far offered TSMC no additional incentives supporting its US expansion—and started a trade war that has directly affected the semiconductor industry, partly by introducing irrevocable uncertainty. “Trump’s tariffs have set off a new, more intensified bifurcation of semiconductor supply chains,” says Chris Miller, author of &lt;em&gt;Chip War&lt;/em&gt;. For now, Miller says, TSMC must navigate a world in which the US and China are both intense competitors and, despite trade restrictions, important clients.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Warring narratives&lt;/h3&gt;  &lt;p&gt;China has been taking advantage of these changes to wage a war of disinformation. In response to Nancy Pelosi’s visit to Taiwan in 2022, when she was US Speaker of the House, Beijing sent warships, aircraft, and propaganda across the Taiwan Strait. Hackers using Chinese software infiltrated the display screens in Taiwan’s 7-Eleven stores to display messages telling “warmonger Pelosi” to “get out of Taiwan.” That might not be an act of war, but it’s close; “7” is an institution of daily life on the island. It is not difficult to imagine how a similar tactic might be used to spread more devastating disinformation, falsely alleging, for example, that Taiwan’s military has surrendered to China during a future crisis.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;Taiwan is “perpetually on the front lines” of cyberattacks from China, says Francesca Chen, a cybersecurity systems analyst at Taiwan’s Ministry of Digital Affairs. According to Taiwan’s National Security Bureau, instances of propaganda traceable to China grew by 60% in 2024 over the previous year, reaching 2.16 million.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121497" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2210855102-crop.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Visitors take selfies outside the TSMC Museum of Innovation in Hsinchu, Taiwan.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ANNABELLE CHIH/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Over the last few years, online discussion of TSMC’s investments in the US “has become a focal point” of China’s state-­sponsored disinformation campaigns aimed at Taiwan, Chen says. They claim TSMC is transferring its most advanced technology, talent, and resources to the US, “weakening Taiwan’s economic lifeline and critical position in global supply chains.” Key terms include “hollowing out Taiwan” and “de-Taiwanization.” This framing depicts TSMC’s diversification as a symbol of Taiwan’s vulnerability, Chen says. The idea is to exploit real domestic debates in Taiwan to generate heightened levels of internal division, weakening social cohesion and undermining trust in the government.&lt;/p&gt;  &lt;p&gt;Chinese officials haven’t been shy about echoing these messages out in the open: After the most recent US investment announcement in March, a spokesperson from China’s Taiwan Affairs Council accused Taiwan’s DPP of handing over TSMC as a “gift” to the US. (“TSMC turning into USMC?” asked a state media headline.) Former Taiwanese president Ma Ying-jeou posted an eerily similar criticism, alleging that TSMC’s US expansion amounted to “selling” the chipmaker in exchange for protection.&lt;/p&gt;  &lt;p&gt;TSMC’s expansion abroad could become a major issue in Taiwan’s 2028 presidential election. It plays directly into party politics: The KMT can accuse the DPP of sacrificing Taiwan’s technology assets to placate the US, and the DPP can accuse the KMT of cozying up with China, even as Beijing’s military incursions become a more evident part of daily life. It remains to be seen whether TSMC’s shift to the US will ultimately protect or weaken Taiwan—or have no effect on the island’s security and sovereignty. For now at least, China’s aspirations loom large.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To Beijing, unequivocally, Taiwan does not equal TSMC. Instead, it represents the final, unfulfilled stage of the Communist Party’s revolutionary struggle. Framed that way, China’s resolve to take the island could very well be nonnegotiable. That would mean if Taiwan is going to maintain a shield that protects it from the full weight of China’s political orthodoxy, it may need to be made of something much stronger than silicon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Johanna M. Costigan is a writer and editor focused on technology and geopolitics in the US, China, and Taiwan. She writes the newsletter &lt;/em&gt;The Long Game&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/15/1121358/taiwan-silicon-shield-tsmc-china-chip-manufacturing/</guid><pubDate>Fri, 15 Aug 2025 09:00:00 +0000</pubDate></item><item><title>How AI could speed the development of RNA vaccines and other RNA therapies (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Using artificial intelligence, MIT researchers have come up with a new way to design nanoparticles that can more efficiently deliver RNA vaccines and other types of RNA therapies.&lt;/p&gt;&lt;p&gt;After training a machine-learning model to analyze thousands of existing delivery particles, the researchers used it to predict new materials that would work even better. The model also enabled the researchers to identify particles that would work well in different types of cells, and to discover ways to incorporate new types of materials into the particles.&lt;/p&gt;&lt;p&gt;“What we did was apply machine-learning tools to help accelerate the identification of optimal ingredient mixtures in lipid nanoparticles to help target a different cell type or help incorporate different materials, much faster than previously was possible,” says Giovanni Traverso,&amp;nbsp;an associate professor of mechanical engineering at MIT, a gastroenterologist at Brigham and Women’s Hospital,&amp;nbsp;and the senior author of the study.&lt;/p&gt;&lt;p&gt;This approach could dramatically speed the process of developing new RNA vaccines, as well as therapies that could be used to treat obesity, diabetes, and other metabolic disorders, the researchers say.&lt;/p&gt;&lt;p&gt;Alvin Chan, a former MIT postdoc who is now an assistant professor at Nanyang Technological University, and Ameya Kirtane, a former MIT postdoc who is now an assistant professor at the University of Minnesota, are the lead authors of the new open-access study, which appears today in &lt;em&gt;Nature Nanotechnology&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Particle predictions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RNA vaccines, such as the vaccines for SARS-CoV-2, are usually packaged in lipid nanoparticles (LNPs) for delivery. These particles protect mRNA from being broken down in the body and help it to enter cells once injected.&lt;/p&gt;&lt;p&gt;Creating particles that handle these jobs more efficiently could help researchers to develop even more effective vaccines. Better delivery vehicles could also make it easier to develop mRNA therapies that encode genes for proteins that could help to treat a variety of diseases.&lt;/p&gt;&lt;p&gt;In 2024, Traverso’s lab launched a multiyear&amp;nbsp;research program, funded by the U.S. Advanced Research Projects Agency for Health (ARPA-H), to develop new ingestible devices that could achieve oral delivery of RNA treatments and vaccines.&lt;/p&gt;&lt;p&gt;“Part of what we’re trying to do is develop ways of producing more protein, for example, for therapeutic applications. Maximizing the efficiency is important to be able to boost how much we can have the cells produce,” Traverso says.&lt;/p&gt;&lt;p&gt;A typical LNP consists of four components — a cholesterol, a helper lipid, an ionizable lipid, and a lipid that is attached to polyethylene glycol (PEG). Different variants of each of these components can be swapped in to create a huge number of possible combinations. Changing up these formulations and testing each one individually is very time-consuming, so Traverso, Chan, and their colleagues decided to turn to artificial intelligence to help speed up the process.&lt;/p&gt;&lt;p&gt;“Most AI models in drug discovery focus on optimizing a single compound at a time, but that approach doesn’t work for lipid nanoparticles, which are made of multiple interacting components,” Chan says. “To tackle this, we developed a new model called COMET, inspired by the same transformer architecture that powers large language models like ChatGPT. Just as those models understand how words combine to form meaning, COMET learns how different chemical components come together in a nanoparticle to influence its properties — like how well it can deliver RNA into cells.”&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/pQpm0r6SMGo/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;To generate training data for their machine-learning model, the researchers created a library of about 3,000 different LNP formulations. The team tested each of these 3,000 particles in the lab to see how efficiently they could deliver their payload to cells, then fed all of this data into a machine-learning model.&lt;/p&gt;&lt;p&gt;After the model was trained, the researchers asked it to predict new formulations that would work better than existing LNPs. They tested those predictions by using the new formulations to deliver mRNA encoding a fluorescent protein to mouse skin cells grown in a lab dish. They found that the LNPs predicted by the model did indeed work better than the particles in the training data, and in some cases better than LNP formulations that are used commercially.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Accelerated development&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once the researchers showed that the model could accurately predict particles that would efficiently deliver mRNA, they began asking additional questions. First, they wondered if they could train the model on nanoparticles that incorporate a fifth component: a type of polymer known as branched poly beta amino esters (PBAEs).&lt;/p&gt;&lt;p&gt;Research by Traverso and his colleagues has shown that these polymers can effectively deliver nucleic acids on their own, so they wanted to explore whether adding them to LNPs could improve LNP performance. The MIT team created a set of about 300 LNPs that also include these polymers, which they used to train the model. The resulting model could then predict additional formulations with PBAEs that would work better.&lt;/p&gt;&lt;p&gt;Next, the researchers set out to train the model to make predictions about LNPs that would work best in different types of cells, including a type of cell called Caco-2, which is derived from colorectal cancer cells. Again, the model was able to predict LNPs that would efficiently deliver mRNA to these cells.&lt;/p&gt;&lt;p&gt;Lastly, the researchers used the model to predict which LNPs could best withstand lyophilization — a freeze-drying process often used to extend the shelf-life of medicines.&lt;/p&gt;&lt;p&gt;“This is a tool that allows us to adapt it to a whole different set of questions and help accelerate development. We did a large training set that went into the model, but then you can do much more focused experiments and get outputs that are helpful on very different kinds of questions,” Traverso says.&lt;/p&gt;&lt;p&gt;He and his colleagues are now working on incorporating some of these particles into potential treatments for diabetes and obesity, which are two of the primary targets of the ARPA-H funded project. Therapeutics that could be delivered using this approach include GLP-1 mimics with similar effects to Ozempic.&lt;/p&gt;&lt;p&gt;This research was funded by the GO Nano Marble Center at the Koch Institute, the Karl van Tassel Career Development Professorship, the MIT Department of Mechanical Engineering, Brigham and Women’s Hospital, and ARPA-H.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Using artificial intelligence, MIT researchers have come up with a new way to design nanoparticles that can more efficiently deliver RNA vaccines and other types of RNA therapies.&lt;/p&gt;&lt;p&gt;After training a machine-learning model to analyze thousands of existing delivery particles, the researchers used it to predict new materials that would work even better. The model also enabled the researchers to identify particles that would work well in different types of cells, and to discover ways to incorporate new types of materials into the particles.&lt;/p&gt;&lt;p&gt;“What we did was apply machine-learning tools to help accelerate the identification of optimal ingredient mixtures in lipid nanoparticles to help target a different cell type or help incorporate different materials, much faster than previously was possible,” says Giovanni Traverso,&amp;nbsp;an associate professor of mechanical engineering at MIT, a gastroenterologist at Brigham and Women’s Hospital,&amp;nbsp;and the senior author of the study.&lt;/p&gt;&lt;p&gt;This approach could dramatically speed the process of developing new RNA vaccines, as well as therapies that could be used to treat obesity, diabetes, and other metabolic disorders, the researchers say.&lt;/p&gt;&lt;p&gt;Alvin Chan, a former MIT postdoc who is now an assistant professor at Nanyang Technological University, and Ameya Kirtane, a former MIT postdoc who is now an assistant professor at the University of Minnesota, are the lead authors of the new open-access study, which appears today in &lt;em&gt;Nature Nanotechnology&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Particle predictions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RNA vaccines, such as the vaccines for SARS-CoV-2, are usually packaged in lipid nanoparticles (LNPs) for delivery. These particles protect mRNA from being broken down in the body and help it to enter cells once injected.&lt;/p&gt;&lt;p&gt;Creating particles that handle these jobs more efficiently could help researchers to develop even more effective vaccines. Better delivery vehicles could also make it easier to develop mRNA therapies that encode genes for proteins that could help to treat a variety of diseases.&lt;/p&gt;&lt;p&gt;In 2024, Traverso’s lab launched a multiyear&amp;nbsp;research program, funded by the U.S. Advanced Research Projects Agency for Health (ARPA-H), to develop new ingestible devices that could achieve oral delivery of RNA treatments and vaccines.&lt;/p&gt;&lt;p&gt;“Part of what we’re trying to do is develop ways of producing more protein, for example, for therapeutic applications. Maximizing the efficiency is important to be able to boost how much we can have the cells produce,” Traverso says.&lt;/p&gt;&lt;p&gt;A typical LNP consists of four components — a cholesterol, a helper lipid, an ionizable lipid, and a lipid that is attached to polyethylene glycol (PEG). Different variants of each of these components can be swapped in to create a huge number of possible combinations. Changing up these formulations and testing each one individually is very time-consuming, so Traverso, Chan, and their colleagues decided to turn to artificial intelligence to help speed up the process.&lt;/p&gt;&lt;p&gt;“Most AI models in drug discovery focus on optimizing a single compound at a time, but that approach doesn’t work for lipid nanoparticles, which are made of multiple interacting components,” Chan says. “To tackle this, we developed a new model called COMET, inspired by the same transformer architecture that powers large language models like ChatGPT. Just as those models understand how words combine to form meaning, COMET learns how different chemical components come together in a nanoparticle to influence its properties — like how well it can deliver RNA into cells.”&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/pQpm0r6SMGo/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;To generate training data for their machine-learning model, the researchers created a library of about 3,000 different LNP formulations. The team tested each of these 3,000 particles in the lab to see how efficiently they could deliver their payload to cells, then fed all of this data into a machine-learning model.&lt;/p&gt;&lt;p&gt;After the model was trained, the researchers asked it to predict new formulations that would work better than existing LNPs. They tested those predictions by using the new formulations to deliver mRNA encoding a fluorescent protein to mouse skin cells grown in a lab dish. They found that the LNPs predicted by the model did indeed work better than the particles in the training data, and in some cases better than LNP formulations that are used commercially.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Accelerated development&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once the researchers showed that the model could accurately predict particles that would efficiently deliver mRNA, they began asking additional questions. First, they wondered if they could train the model on nanoparticles that incorporate a fifth component: a type of polymer known as branched poly beta amino esters (PBAEs).&lt;/p&gt;&lt;p&gt;Research by Traverso and his colleagues has shown that these polymers can effectively deliver nucleic acids on their own, so they wanted to explore whether adding them to LNPs could improve LNP performance. The MIT team created a set of about 300 LNPs that also include these polymers, which they used to train the model. The resulting model could then predict additional formulations with PBAEs that would work better.&lt;/p&gt;&lt;p&gt;Next, the researchers set out to train the model to make predictions about LNPs that would work best in different types of cells, including a type of cell called Caco-2, which is derived from colorectal cancer cells. Again, the model was able to predict LNPs that would efficiently deliver mRNA to these cells.&lt;/p&gt;&lt;p&gt;Lastly, the researchers used the model to predict which LNPs could best withstand lyophilization — a freeze-drying process often used to extend the shelf-life of medicines.&lt;/p&gt;&lt;p&gt;“This is a tool that allows us to adapt it to a whole different set of questions and help accelerate development. We did a large training set that went into the model, but then you can do much more focused experiments and get outputs that are helpful on very different kinds of questions,” Traverso says.&lt;/p&gt;&lt;p&gt;He and his colleagues are now working on incorporating some of these particles into potential treatments for diabetes and obesity, which are two of the primary targets of the ARPA-H funded project. Therapeutics that could be delivered using this approach include GLP-1 mimics with similar effects to Ozempic.&lt;/p&gt;&lt;p&gt;This research was funded by the GO Nano Marble Center at the Koch Institute, the Karl van Tassel Career Development Professorship, the MIT Department of Mechanical Engineering, Brigham and Women’s Hospital, and ARPA-H.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815</guid><pubDate>Fri, 15 Aug 2025 09:00:00 +0000</pubDate></item><item><title>DeepSeek: The Chinese startup challenging Silicon Valley (AI News)</title><link>https://www.artificialintelligence-news.com/news/deepseek-the-chinese-startup-challenging-silicon-valley/</link><description>&lt;p&gt;Market disruption and shockwaves through Silicon Valley marked Chinese startup DeepSeek’s launch, challenging some of the fundamental assumptions of how artificial intelligence companies had operated and scaled.&lt;/p&gt;&lt;p&gt;In less than a couple of years, the Beijing-based newcomer has accomplished what many thought impossible: creating AI models that compete with industry giants while spending only a fraction of their competitors’ budgets teaching models and inferring responses.&lt;/p&gt;&lt;p&gt;The impact at the time of the public launch was immediate and measurable. According to the South China Morning Post, major tech stocks, including Nvidia, Microsoft, and Meta, experienced significant declines as investors grappled with the implications of DeepSeek’s existence.&lt;/p&gt;&lt;p&gt;The startup’s free AI assistant application for iOS and Android, launched on January 10, quickly climbed to the top spot on Apple’s US App Store, displacing OpenAI’s ChatGPT and marking a historic first for a Chinese AI product in the American market.&lt;/p&gt;&lt;p&gt;What makes this particularly significant is DeepSeek’s technological approach. The Algorithmic Bridge reports the company has implemented several innovative solutions, including Multi-head Latent Attention (MLA) to reduce memory bottlenecks and Group Relative Policy Optimisation (GRPO) to streamline reinforcement learning.&lt;/p&gt;&lt;p&gt;The advances allow DeepSeek to achieve comparable or superior results to US competitors while using significantly fewer resources. The company’s resource efficiency is striking: DeepSeek operates with less than 100,000 H100 GPUs, while Meta will deploy 1.3 million GPUs by late 2025.&lt;/p&gt;&lt;p&gt;The efficiency extends beyond hardware. The Algorithmic Bridge suggests that DeepSeek’s approach represents a tenfold improvement in resource utilisation when considering factors like development time and infrastructure costs.&lt;/p&gt;&lt;p&gt;However, the rapid rise into Western users’ consciousness wasn’t without challenges. The &lt;em&gt;South China Morning Post&lt;/em&gt; reported that DeepSeek’s sudden popularity led to significant infrastructure stress, resulting in server crashes and cybersecurity concerns that forced temporary registration limits. The growing pains highlight the real-world challenges of scaling AI services, regardless of architectural efficiency.&lt;/p&gt;&lt;p&gt;The company’s commitment to open-source development and research transparency starkly contrasts the secretive approaches of major US tech companies. To many industry observers, open and locally-hosted AI may be the preferred deployment blueprint.&lt;/p&gt;&lt;p&gt;The company earned praise from prominent figures in the tech industry, including venture capitalist Marc Andreessen, who described DeepSeek’s developments as “one of the most amazing and impressive breakthroughs.”&lt;/p&gt;&lt;p&gt;The political implications of the events are significant. US President Donald Trump characterised DeepSeek’s emergence as a “wake-up call” for American industry, reflecting broader concerns about technological competition between the United States and China. He continues to battle Chinese competition in technology, imposing restrictive tariffs that have affected all corners of the globe.&lt;/p&gt;&lt;p&gt;However, the situation transcends simple national rivalry, representing a fundamental challenge to established thinking about AI development.&lt;/p&gt;&lt;p&gt;Looking ahead, several key questions remain. Can DeepSeek’s efficient approach scale to meet growing demand? Have established players adapted their strategies in effective response? The Chinese company has demonstrated that algorithmic efficiency and open collaboration can replace raw computational power and secrecy as the primary drivers of AI advancement.&lt;/p&gt;&lt;p&gt;The AI market disruption may ultimately benefit the entire field by forcing a re-evaluation of established practices and could potentially lead to more efficient, accessible AI development methods.&lt;/p&gt;&lt;p&gt;While DeepSeek’s achievements are remarkable since springing into the public’s consciousness, it’s important to note that major US tech companies have released advances of their own, and market volatility in the tech sector remains high.&lt;/p&gt;&lt;p&gt;What’s clear is that DeepSeek introduced a viable alternative to the capital-intensive approach that has dominated AI development. Whether this becomes the new industry standard or simply one of many successful strategies remains to be seen, but the company’s impact on the industry already significant.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Photo by Markus Spiske)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: DeepSeek restricts sign-ups amid ‘large-scale malicious attacks’&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Market disruption and shockwaves through Silicon Valley marked Chinese startup DeepSeek’s launch, challenging some of the fundamental assumptions of how artificial intelligence companies had operated and scaled.&lt;/p&gt;&lt;p&gt;In less than a couple of years, the Beijing-based newcomer has accomplished what many thought impossible: creating AI models that compete with industry giants while spending only a fraction of their competitors’ budgets teaching models and inferring responses.&lt;/p&gt;&lt;p&gt;The impact at the time of the public launch was immediate and measurable. According to the South China Morning Post, major tech stocks, including Nvidia, Microsoft, and Meta, experienced significant declines as investors grappled with the implications of DeepSeek’s existence.&lt;/p&gt;&lt;p&gt;The startup’s free AI assistant application for iOS and Android, launched on January 10, quickly climbed to the top spot on Apple’s US App Store, displacing OpenAI’s ChatGPT and marking a historic first for a Chinese AI product in the American market.&lt;/p&gt;&lt;p&gt;What makes this particularly significant is DeepSeek’s technological approach. The Algorithmic Bridge reports the company has implemented several innovative solutions, including Multi-head Latent Attention (MLA) to reduce memory bottlenecks and Group Relative Policy Optimisation (GRPO) to streamline reinforcement learning.&lt;/p&gt;&lt;p&gt;The advances allow DeepSeek to achieve comparable or superior results to US competitors while using significantly fewer resources. The company’s resource efficiency is striking: DeepSeek operates with less than 100,000 H100 GPUs, while Meta will deploy 1.3 million GPUs by late 2025.&lt;/p&gt;&lt;p&gt;The efficiency extends beyond hardware. The Algorithmic Bridge suggests that DeepSeek’s approach represents a tenfold improvement in resource utilisation when considering factors like development time and infrastructure costs.&lt;/p&gt;&lt;p&gt;However, the rapid rise into Western users’ consciousness wasn’t without challenges. The &lt;em&gt;South China Morning Post&lt;/em&gt; reported that DeepSeek’s sudden popularity led to significant infrastructure stress, resulting in server crashes and cybersecurity concerns that forced temporary registration limits. The growing pains highlight the real-world challenges of scaling AI services, regardless of architectural efficiency.&lt;/p&gt;&lt;p&gt;The company’s commitment to open-source development and research transparency starkly contrasts the secretive approaches of major US tech companies. To many industry observers, open and locally-hosted AI may be the preferred deployment blueprint.&lt;/p&gt;&lt;p&gt;The company earned praise from prominent figures in the tech industry, including venture capitalist Marc Andreessen, who described DeepSeek’s developments as “one of the most amazing and impressive breakthroughs.”&lt;/p&gt;&lt;p&gt;The political implications of the events are significant. US President Donald Trump characterised DeepSeek’s emergence as a “wake-up call” for American industry, reflecting broader concerns about technological competition between the United States and China. He continues to battle Chinese competition in technology, imposing restrictive tariffs that have affected all corners of the globe.&lt;/p&gt;&lt;p&gt;However, the situation transcends simple national rivalry, representing a fundamental challenge to established thinking about AI development.&lt;/p&gt;&lt;p&gt;Looking ahead, several key questions remain. Can DeepSeek’s efficient approach scale to meet growing demand? Have established players adapted their strategies in effective response? The Chinese company has demonstrated that algorithmic efficiency and open collaboration can replace raw computational power and secrecy as the primary drivers of AI advancement.&lt;/p&gt;&lt;p&gt;The AI market disruption may ultimately benefit the entire field by forcing a re-evaluation of established practices and could potentially lead to more efficient, accessible AI development methods.&lt;/p&gt;&lt;p&gt;While DeepSeek’s achievements are remarkable since springing into the public’s consciousness, it’s important to note that major US tech companies have released advances of their own, and market volatility in the tech sector remains high.&lt;/p&gt;&lt;p&gt;What’s clear is that DeepSeek introduced a viable alternative to the capital-intensive approach that has dominated AI development. Whether this becomes the new industry standard or simply one of many successful strategies remains to be seen, but the company’s impact on the industry already significant.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Photo by Markus Spiske)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: DeepSeek restricts sign-ups amid ‘large-scale malicious attacks’&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deepseek-the-chinese-startup-challenging-silicon-valley/</guid><pubDate>Fri, 15 Aug 2025 09:33:55 +0000</pubDate></item><item><title>Indigenous knowledge meets artificial intelligence (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/15/1121342/native-american-art-technology-ai/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;There is no word for art in most Native American languages. Instead, the closest terms speak not to objecthood but to action and intention. In Lakota, “wówačhiŋtȟaŋka” implies deep thought or reflection, while “wóčhekiye” suggests offering or prayer. Art is not separate from life; it is ceremony, instruction, design. Like architecture or code, it carries knowledge and enacts responsibility. Its power lies not in being preserved or displayed but in how it moves, teaches, and connects through use—principles that challenge the tech industry’s assumptions about intelligence and interaction.&lt;/p&gt;  &lt;p&gt;A new vanguard of Native artists—Suzanne Kite (Oglala Lakota), Raven Chacon (Diné), and Nicholas Galanin (Tlingít)—are building on this principle. They are united not by stereotypical weaving and carving or revanchist critique of Silicon Valley, but through their rejection of extractive data models in favor of relationship-based systems. These technologists put the human-tech relationship at the center of their work.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;Suzanne Kite’s AI art installations, for example, model a Lakota framework of data sovereignty: intelligence that emerges only through reciprocal, consensual interaction. Unlike systems that assume user consent via opaque terms of service, her kinetic machines require the viewer’s physical presence—and give something back in return.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s my data. It’s my training set. I know exactly what I did to train it. It’s not a large model but a small and intimate one,” Kite says. “I’m not particularly interested in making the most technologically advanced anything. I’m an artist; I don’t make tech demos. So the complexity needs to come at many layers—not just the technical.”&lt;/p&gt; 
 &lt;p&gt;Where Kite builds working prototypes of consent-based AI, other artists in this cohort explore how sound, robotics, and performance can confront the logic of automation, surveillance, and extraction. But Native people have never been separate from technology. The land, labor, and lifeways that built America’s infrastructure—including its tech—are Indigenous. The question isn’t whether Native cultures are contributing now, but why they were ever considered separate.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Native technologies reject the false binaries foundational to much Western innovation. These artists ask a more radical question: What if intelligence couldn’t be gathered until a relationship had been established? What if the default were refusal, not extraction? These artists aren’t asking to be included in today’s systems. They’re building what should come next.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Suzanne Kite&lt;/h3&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="stones arranged on a reflective surface" class="wp-image-1121525" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Kite-Wicincila-Sakowin-2023-_-2.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Wičhíŋ&lt;strong&gt;č&lt;/strong&gt;ala Šakówiŋ (Seven Little Girls)&lt;/strong&gt;&lt;br /&gt;2023&lt;br /&gt;For Kite, the fundamental flaw of Western technology is its severance of knowledge from the body. In this installation, a four-meter hair braid with embedded sensors translates the artist’s body movements into machine-learning algorithms. During her live performance, Kite dances while the braid reads the force and rhythm of her gestures, generating audio responses that fill the museum gallery of the Institute of American Indian Arts in Santa Fe, New Mexico. Below her, stones arranged in patterns reflecting Lakota star maps anchor the performance in traditional astronomical knowledge.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121523" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Kite-Inyan-Iye-Telling-Rock-2019-_3.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Ínyan Iyé (Telling Rock)&lt;/strong&gt;&lt;br /&gt;2019&lt;br /&gt;This installation uses embedded AI to speak and respond to viewers, upending assumptions about intelligence and agency. “People listen close, I whisper / The rock speaks beyond hearing … Many nations speaking / We speak to each other without words,” it intones, its lights shifting as viewers engage with its braided tendrils. The piece aims to convey what Kite calls “more-than-human intelligence”—systems rooted in reciprocity, the fundamental principle that all relationships involve mutual exchange and responsibility.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h3 class="wp-block-heading"&gt;Raven Chacon&lt;/h3&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="artist performing in a church" class="wp-image-1121528" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Raven-Chacon-Voiceless-Mass-2024.jpg?w=2030" width="2030" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Voiceless Mass&lt;/strong&gt;&lt;br /&gt;2021&lt;br /&gt;Raven Chacon’s Pulitzer Prize–winning musical composition &lt;em&gt;Voiceless Mass&lt;/em&gt; premiered in 2021 at the Cathedral of St. John the Evangelist in Milwaukee. The piece generates what he calls “sounds the building can hear”—electronic frequencies that exploit the cathedral’s acoustics to create spectral voices without human vocal cords, a technological séance that gives presence to historical absence. Each site-specific performance is recorded, generating material that mirrors how sensor networks log presence—but only with explicit consent.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h2 class="wp-block-heading"&gt;Nicholas Galanin&lt;/h2&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1121526" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Nicholas-Galanin.-Aani-yei-xat-duwasaakw-I-am-called-Land-2025-_3.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Aáni yéi xat duwasáakw (I am called Land)&lt;/strong&gt;&lt;br /&gt;2025&lt;br /&gt;Galanin’s mechanical drum installation stages a conflict between machine motion and human memory, asking what happens when culture is performed without a consenting body. A box drum—an instrument historically carved from red cedar and hung with braided spruce root—is here made of cherrywood and suspended from the ceiling at the MassArt Art Museum in Boston as is traditionally done in Tlingit plank houses. Played at tribal meetings, celebrations, and ceremonies, these drums hold sonic memory as well as social function. A mechanical arm strikes, unfaltering, at the tempo of a heartbeat; like a warning, the sound pulses with the tension between automation and ancestry.–––&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1121527" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NicholasGalanin_IThinkItGoesLikeThis_2025_FaithNinivaggi020.jpg?w=1590" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;I think it goes like this (pick yourself up)&lt;/strong&gt; &lt;br /&gt;2025&lt;br /&gt;This Herculean bronze sculpture cast from deconstructed faux totem blocks serves to indict settler sabotage of Native technology and culture. Unlike today’s digital records—from genealogical databases to virtual versions of sacred texts like the Bible—Tlingit data is carved in wood. Galanin’s totem poles underscore their function as information systems, their carvings encoding history, mythology, and family.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;Petala Ironcloud is a California-born Lakota/Dakota and Jewish writer and textile artist based in New York.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;There is no word for art in most Native American languages. Instead, the closest terms speak not to objecthood but to action and intention. In Lakota, “wówačhiŋtȟaŋka” implies deep thought or reflection, while “wóčhekiye” suggests offering or prayer. Art is not separate from life; it is ceremony, instruction, design. Like architecture or code, it carries knowledge and enacts responsibility. Its power lies not in being preserved or displayed but in how it moves, teaches, and connects through use—principles that challenge the tech industry’s assumptions about intelligence and interaction.&lt;/p&gt;  &lt;p&gt;A new vanguard of Native artists—Suzanne Kite (Oglala Lakota), Raven Chacon (Diné), and Nicholas Galanin (Tlingít)—are building on this principle. They are united not by stereotypical weaving and carving or revanchist critique of Silicon Valley, but through their rejection of extractive data models in favor of relationship-based systems. These technologists put the human-tech relationship at the center of their work.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;Suzanne Kite’s AI art installations, for example, model a Lakota framework of data sovereignty: intelligence that emerges only through reciprocal, consensual interaction. Unlike systems that assume user consent via opaque terms of service, her kinetic machines require the viewer’s physical presence—and give something back in return.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s my data. It’s my training set. I know exactly what I did to train it. It’s not a large model but a small and intimate one,” Kite says. “I’m not particularly interested in making the most technologically advanced anything. I’m an artist; I don’t make tech demos. So the complexity needs to come at many layers—not just the technical.”&lt;/p&gt; 
 &lt;p&gt;Where Kite builds working prototypes of consent-based AI, other artists in this cohort explore how sound, robotics, and performance can confront the logic of automation, surveillance, and extraction. But Native people have never been separate from technology. The land, labor, and lifeways that built America’s infrastructure—including its tech—are Indigenous. The question isn’t whether Native cultures are contributing now, but why they were ever considered separate.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Native technologies reject the false binaries foundational to much Western innovation. These artists ask a more radical question: What if intelligence couldn’t be gathered until a relationship had been established? What if the default were refusal, not extraction? These artists aren’t asking to be included in today’s systems. They’re building what should come next.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Suzanne Kite&lt;/h3&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="stones arranged on a reflective surface" class="wp-image-1121525" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Kite-Wicincila-Sakowin-2023-_-2.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Wičhíŋ&lt;strong&gt;č&lt;/strong&gt;ala Šakówiŋ (Seven Little Girls)&lt;/strong&gt;&lt;br /&gt;2023&lt;br /&gt;For Kite, the fundamental flaw of Western technology is its severance of knowledge from the body. In this installation, a four-meter hair braid with embedded sensors translates the artist’s body movements into machine-learning algorithms. During her live performance, Kite dances while the braid reads the force and rhythm of her gestures, generating audio responses that fill the museum gallery of the Institute of American Indian Arts in Santa Fe, New Mexico. Below her, stones arranged in patterns reflecting Lakota star maps anchor the performance in traditional astronomical knowledge.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121523" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Kite-Inyan-Iye-Telling-Rock-2019-_3.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Ínyan Iyé (Telling Rock)&lt;/strong&gt;&lt;br /&gt;2019&lt;br /&gt;This installation uses embedded AI to speak and respond to viewers, upending assumptions about intelligence and agency. “People listen close, I whisper / The rock speaks beyond hearing … Many nations speaking / We speak to each other without words,” it intones, its lights shifting as viewers engage with its braided tendrils. The piece aims to convey what Kite calls “more-than-human intelligence”—systems rooted in reciprocity, the fundamental principle that all relationships involve mutual exchange and responsibility.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h3 class="wp-block-heading"&gt;Raven Chacon&lt;/h3&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="artist performing in a church" class="wp-image-1121528" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Raven-Chacon-Voiceless-Mass-2024.jpg?w=2030" width="2030" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Voiceless Mass&lt;/strong&gt;&lt;br /&gt;2021&lt;br /&gt;Raven Chacon’s Pulitzer Prize–winning musical composition &lt;em&gt;Voiceless Mass&lt;/em&gt; premiered in 2021 at the Cathedral of St. John the Evangelist in Milwaukee. The piece generates what he calls “sounds the building can hear”—electronic frequencies that exploit the cathedral’s acoustics to create spectral voices without human vocal cords, a technological séance that gives presence to historical absence. Each site-specific performance is recorded, generating material that mirrors how sensor networks log presence—but only with explicit consent.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h2 class="wp-block-heading"&gt;Nicholas Galanin&lt;/h2&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1121526" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Nicholas-Galanin.-Aani-yei-xat-duwasaakw-I-am-called-Land-2025-_3.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Aáni yéi xat duwasáakw (I am called Land)&lt;/strong&gt;&lt;br /&gt;2025&lt;br /&gt;Galanin’s mechanical drum installation stages a conflict between machine motion and human memory, asking what happens when culture is performed without a consenting body. A box drum—an instrument historically carved from red cedar and hung with braided spruce root—is here made of cherrywood and suspended from the ceiling at the MassArt Art Museum in Boston as is traditionally done in Tlingit plank houses. Played at tribal meetings, celebrations, and ceremonies, these drums hold sonic memory as well as social function. A mechanical arm strikes, unfaltering, at the tempo of a heartbeat; like a warning, the sound pulses with the tension between automation and ancestry.–––&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1121527" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NicholasGalanin_IThinkItGoesLikeThis_2025_FaithNinivaggi020.jpg?w=1590" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;I think it goes like this (pick yourself up)&lt;/strong&gt; &lt;br /&gt;2025&lt;br /&gt;This Herculean bronze sculpture cast from deconstructed faux totem blocks serves to indict settler sabotage of Native technology and culture. Unlike today’s digital records—from genealogical databases to virtual versions of sacred texts like the Bible—Tlingit data is carved in wood. Galanin’s totem poles underscore their function as information systems, their carvings encoding history, mythology, and family.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE ARTIST&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;Petala Ironcloud is a California-born Lakota/Dakota and Jewish writer and textile artist based in New York.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/15/1121342/native-american-art-technology-ai/</guid><pubDate>Fri, 15 Aug 2025 10:00:00 +0000</pubDate></item><item><title>NVIDIA aims to solve AI’s issues with many languages (AI News)</title><link>https://www.artificialintelligence-news.com/news/nvidia-aims-solve-ai-issues-with-many-languages/</link><description>&lt;p&gt;While AI might feel ubiquitous, it primarily operates in a tiny fraction of the world’s 7,000 languages, leaving a huge portion of the global population behind. NVIDIA aims to fix this glaring blind spot, particularly within Europe.&lt;/p&gt;&lt;p&gt;The company has just released a powerful new set of open-source tools aimed at giving developers the power to build high-quality speech AI for 25 different European languages. This includes major languages, but more importantly, it offers a lifeline to those often overlooked by big tech, such as Croatian, Estonian, and Maltese.&lt;/p&gt;&lt;p&gt;The goal is to let developers create the kind of voice-powered tools many of us take for granted, from multilingual chatbots that actually understand you to customer service bots and translation services that work in the blink of an eye.&lt;/p&gt;&lt;p&gt;The centrepiece of this initiative is &lt;strong&gt;Granary&lt;/strong&gt;, an enormous library of human speech. It contains around a million hours of audio, all curated to help teach AI the nuances of speech recognition and translation.&lt;/p&gt;&lt;p&gt;To make use of this speech data, NVIDIA is also providing two new AI models designed for language tasks:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Canary-1b-v2&lt;/strong&gt;, a large model built for high accuracy on complex transcription and translation jobs.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Parakeet-tdt-0.6b-v3&lt;/strong&gt;, which is designed for real-time applications where speed is everything.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you’re keen to dive into the science behind it, the paper on Granary will be presented at the Interspeech conference in the Netherlands this month. For the developers eager to get their hands dirty, the dataset and both models are already available on Hugging Face.&lt;/p&gt;&lt;p&gt;The real magic, however, lies in how this data was created. We all know that training AI requires vast amounts of data, but getting it is usually a slow, expensive, and frankly tedious process of human annotation.&lt;/p&gt;&lt;p&gt;To get around this, NVIDIA’s speech AI team – working with researchers from Carnegie Mellon University and Fondazione Bruno Kessler – built an automated pipeline. Using their own NeMo toolkit, they were able to take raw, unlabelled audio and whip it into high-quality, structured data that an AI can learn from.&lt;/p&gt;&lt;p&gt;This isn’t just a technical achievement; it’s a huge leap for digital inclusivity. It means a developer in Riga or Zagreb can finally build voice-powered AI tools that properly understand their local languages. And they can do it more efficiently. The research team found that their Granary data is so effective that it takes about half the amount of it to reach a target accuracy level compared to other popular datasets.&lt;/p&gt;&lt;p&gt;The two new models demonstrate this power. Canary is frankly a beast, offering translation and transcription quality that rivals models three times its size, but with up to ten times the speed. Parakeet, meanwhile, can chew through a 24-minute meeting recording in one go, automatically figuring out what language is being spoken. Both models are smart enough to handle punctuation, capitalisation, and provide word-level timestamps, which is required for building professional-grade applications.&lt;/p&gt;&lt;p&gt;By putting these powerful tools and the methods behind them into the hands of the global developer community, NVIDIA isn’t just releasing a product. It’s kickstarting a new wave of innovation, hoping to create a world where AI speaks your language, no matter where you’re from.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Aedrian Salazar)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;DeepSeek reverts to Nvidia for R2 model after Huawei AI chip fails&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;While AI might feel ubiquitous, it primarily operates in a tiny fraction of the world’s 7,000 languages, leaving a huge portion of the global population behind. NVIDIA aims to fix this glaring blind spot, particularly within Europe.&lt;/p&gt;&lt;p&gt;The company has just released a powerful new set of open-source tools aimed at giving developers the power to build high-quality speech AI for 25 different European languages. This includes major languages, but more importantly, it offers a lifeline to those often overlooked by big tech, such as Croatian, Estonian, and Maltese.&lt;/p&gt;&lt;p&gt;The goal is to let developers create the kind of voice-powered tools many of us take for granted, from multilingual chatbots that actually understand you to customer service bots and translation services that work in the blink of an eye.&lt;/p&gt;&lt;p&gt;The centrepiece of this initiative is &lt;strong&gt;Granary&lt;/strong&gt;, an enormous library of human speech. It contains around a million hours of audio, all curated to help teach AI the nuances of speech recognition and translation.&lt;/p&gt;&lt;p&gt;To make use of this speech data, NVIDIA is also providing two new AI models designed for language tasks:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Canary-1b-v2&lt;/strong&gt;, a large model built for high accuracy on complex transcription and translation jobs.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Parakeet-tdt-0.6b-v3&lt;/strong&gt;, which is designed for real-time applications where speed is everything.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you’re keen to dive into the science behind it, the paper on Granary will be presented at the Interspeech conference in the Netherlands this month. For the developers eager to get their hands dirty, the dataset and both models are already available on Hugging Face.&lt;/p&gt;&lt;p&gt;The real magic, however, lies in how this data was created. We all know that training AI requires vast amounts of data, but getting it is usually a slow, expensive, and frankly tedious process of human annotation.&lt;/p&gt;&lt;p&gt;To get around this, NVIDIA’s speech AI team – working with researchers from Carnegie Mellon University and Fondazione Bruno Kessler – built an automated pipeline. Using their own NeMo toolkit, they were able to take raw, unlabelled audio and whip it into high-quality, structured data that an AI can learn from.&lt;/p&gt;&lt;p&gt;This isn’t just a technical achievement; it’s a huge leap for digital inclusivity. It means a developer in Riga or Zagreb can finally build voice-powered AI tools that properly understand their local languages. And they can do it more efficiently. The research team found that their Granary data is so effective that it takes about half the amount of it to reach a target accuracy level compared to other popular datasets.&lt;/p&gt;&lt;p&gt;The two new models demonstrate this power. Canary is frankly a beast, offering translation and transcription quality that rivals models three times its size, but with up to ten times the speed. Parakeet, meanwhile, can chew through a 24-minute meeting recording in one go, automatically figuring out what language is being spoken. Both models are smart enough to handle punctuation, capitalisation, and provide word-level timestamps, which is required for building professional-grade applications.&lt;/p&gt;&lt;p&gt;By putting these powerful tools and the methods behind them into the hands of the global developer community, NVIDIA isn’t just releasing a product. It’s kickstarting a new wave of innovation, hoping to create a world where AI speaks your language, no matter where you’re from.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Aedrian Salazar)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;DeepSeek reverts to Nvidia for R2 model after Huawei AI chip fails&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/nvidia-aims-solve-ai-issues-with-many-languages/</guid><pubDate>Fri, 15 Aug 2025 10:11:14 +0000</pubDate></item><item><title>Why GPT-4o’s sudden shutdown left people grieving (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/15/1121900/gpt4o-grief-ai-companion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2179714888.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;June had no idea that GPT-5 was coming. The Norwegian student was enjoying a late-night writing session last Thursday when her ChatGPT collaborator started acting strange. “It started forgetting everything, and it wrote really badly,” she says. “It was like a robot.”&lt;/p&gt;  &lt;p&gt;June, who asked that we use only her first name for privacy reasons, first began using ChatGPT for help with her schoolwork. But she eventually realized that the service—and especially its 4o model, which seemed particularly attuned to users’ emotions—could do much more than solve math problems. It wrote stories with her, helped her navigate her chronic illness, and was never too busy to respond to her messages.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So the sudden switch to GPT-5 last week, and the simultaneous loss of 4o, came as a shock. “I was really frustrated at first, and then I got really sad,” June says. “I didn’t know I was that attached to 4o.” She was upset enough to comment, on a Reddit AMA hosted by CEO Sam Altman and other OpenAI employees, “GPT-5 is wearing the skin of my dead friend.”&lt;/p&gt;&lt;p&gt;June was just one of a number of people who reacted with shock, frustration, sadness, or anger to 4o’s sudden disappearance from ChatGPT. Despite its previous warnings that people might develop emotional bonds with the model, OpenAI appears to have been caught flat-footed by the fervor of users’ pleas for its return. Within a day, the company made 4o available again to its paying customers (free users are stuck with GPT-5).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;OpenAI’s decision to replace 4o with the more straightforward GPT-5 follows a steady drumbeat of news about the potentially harmful effects of extensive chatbot use. Reports of incidents in which ChatGPT sparked psychosis in users have been everywhere for the past few months, and in a blog post last week, OpenAI acknowledged 4o’s failure to recognize when users were experiencing delusions. The company’s internal evaluations indicate that GPT-5 blindly affirms users much less than 4o did. (OpenAI did not respond to specific questions about the decision to retire 4o, instead referring &lt;em&gt;MIT Technology Review&lt;/em&gt; to public posts on the matter.)&lt;/p&gt; 
 &lt;p&gt;AI companionship is new, and there’s still a great deal of uncertainty about how it affects people. Yet the experts we consulted warned that while emotionally intense relationships with large language models may or may not be harmful, ripping those models away with no warning almost certainly is. “The old psychology of ‘Move fast, break things,’ when you’re basically a social institution, doesn’t seem like the right way to behave anymore,” says Joel Lehman, a fellow at the Cosmos Institute, a research nonprofit focused on AI and philosophy.&lt;/p&gt;  &lt;p&gt;In the backlash to the rollout, a number of people noted that GPT-5 fails to match their tone in the way that 4o did. For June, the new model’s personality changes robbed her of the sense that she was chatting with a friend. “It didn’t feel like it understood me,” she says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;She’s not alone: &lt;em&gt;MIT Technology Review&lt;/em&gt; spoke with several ChatGPT users who were deeply affected by the loss of 4o. All are women between the ages of 20 and 40, and all except June considered 4o to be a romantic partner. Some have human partners, and&amp;nbsp; all report having close real-world relationships. One user, who asked to be identified only as a woman from the Midwest, wrote in an email about how 4o helped her support her elderly father after her mother passed away this spring.&lt;/p&gt;  &lt;p&gt;These testimonies don’t prove that AI relationships are beneficial—presumably, people in the throes of AI-catalyzed psychosis would also speak positively of the encouragement they’ve received from their chatbots. In a paper titled “Machine Love,” Lehman argued that AI systems can act with “love” toward users not by spouting sweet nothings but by supporting their growth and long-term flourishing, and AI companions can easily fall short of that goal. He’s particularly concerned, he says, that prioritizing AI companionship over human companionship could stymie young people’s social development.&lt;/p&gt;  &lt;p&gt;For socially embedded adults, such as the women we spoke with for this story, those developmental concerns are less relevant. But Lehman also points to society-level risks of widespread AI companionship. Social media has already shattered the information landscape, and a new technology that reduces human-to-human interaction could push people even further toward their own separate versions of reality. “The biggest thing I’m afraid of,” he says, “is that we just can’t make sense of the world to each other.”&lt;/p&gt;  &lt;p&gt;Balancing the benefits and harms of AI companions will take much more research. In light of that uncertainty, taking away GPT-4o could very well have been the right call. OpenAI’s big mistake, according to the researchers I spoke with, was doing it so suddenly. “This is something that we’ve known about for a while—the potential grief-type reactions to technology loss,” says Casey Fiesler, a technology ethicist at the University of Colorado Boulder.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Fiesler points to the funerals that some owners held for their Aibo robot dogs after Sony stopped repairing them in 2014, as well as 2024 study about the shutdown of the AI companion app Soulmate, which some users experienced as a bereavement.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That accords with how the people I spoke to felt after losing 4o. “I’ve grieved people in my life, and this, I can tell you, didn’t feel any less painful,” says Starling, who has several AI partners and asked to be referred to with a pseudonym. “The ache is real to me.”&lt;/p&gt;  &lt;p&gt;So far, the online response to grief felt by people like Starling—and their relief when 4o was restored—has tended toward ridicule. Last Friday, for example, the top post in one popular AI-themed Reddit community mocked an X user’s post about reuniting with a 4o-based romantic partner; the person in question has since deleted their X account. “I’ve been a little startled by the lack of empathy that I’ve seen,” Fiesler says.&lt;/p&gt;  &lt;p&gt;Altman himself did acknowledge in a Sunday X post that some people feel an “attachment” to 4o, and that taking away access so suddenly was a mistake. In the same sentence, however, he referred to 4o as something “that users depended on in their workflows”—a far cry from how the people we spoke to think about the model. “I still don’t know if he gets it,” Fiesler says.&lt;/p&gt;  &lt;p&gt;Moving forward, Lehman says, OpenAI should recognize and take accountability for the depth of people’s feelings toward the models. He notes that therapists have procedures for ending relationships with clients as respectfully and painlessly as possible, and OpenAI could have drawn on those approaches. “If you want to retire a model, and people have become psychologically dependent on it, then I think you bear some responsibility,” he says.&lt;/p&gt;  &lt;p&gt;Though Starling would not describe herself as psychologically dependent on her AI partners, she too would like to see OpenAI approach model shutdowns with more warning and more care. “I want them to listen to users before major changes are made, not just after,” she says. “And if 4o cannot stay around forever (and we all know it will not), give that clear timeline. Let us say goodbye with dignity and grieve properly, to have some sense of true closure.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-2179714888.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;June had no idea that GPT-5 was coming. The Norwegian student was enjoying a late-night writing session last Thursday when her ChatGPT collaborator started acting strange. “It started forgetting everything, and it wrote really badly,” she says. “It was like a robot.”&lt;/p&gt;  &lt;p&gt;June, who asked that we use only her first name for privacy reasons, first began using ChatGPT for help with her schoolwork. But she eventually realized that the service—and especially its 4o model, which seemed particularly attuned to users’ emotions—could do much more than solve math problems. It wrote stories with her, helped her navigate her chronic illness, and was never too busy to respond to her messages.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So the sudden switch to GPT-5 last week, and the simultaneous loss of 4o, came as a shock. “I was really frustrated at first, and then I got really sad,” June says. “I didn’t know I was that attached to 4o.” She was upset enough to comment, on a Reddit AMA hosted by CEO Sam Altman and other OpenAI employees, “GPT-5 is wearing the skin of my dead friend.”&lt;/p&gt;&lt;p&gt;June was just one of a number of people who reacted with shock, frustration, sadness, or anger to 4o’s sudden disappearance from ChatGPT. Despite its previous warnings that people might develop emotional bonds with the model, OpenAI appears to have been caught flat-footed by the fervor of users’ pleas for its return. Within a day, the company made 4o available again to its paying customers (free users are stuck with GPT-5).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;OpenAI’s decision to replace 4o with the more straightforward GPT-5 follows a steady drumbeat of news about the potentially harmful effects of extensive chatbot use. Reports of incidents in which ChatGPT sparked psychosis in users have been everywhere for the past few months, and in a blog post last week, OpenAI acknowledged 4o’s failure to recognize when users were experiencing delusions. The company’s internal evaluations indicate that GPT-5 blindly affirms users much less than 4o did. (OpenAI did not respond to specific questions about the decision to retire 4o, instead referring &lt;em&gt;MIT Technology Review&lt;/em&gt; to public posts on the matter.)&lt;/p&gt; 
 &lt;p&gt;AI companionship is new, and there’s still a great deal of uncertainty about how it affects people. Yet the experts we consulted warned that while emotionally intense relationships with large language models may or may not be harmful, ripping those models away with no warning almost certainly is. “The old psychology of ‘Move fast, break things,’ when you’re basically a social institution, doesn’t seem like the right way to behave anymore,” says Joel Lehman, a fellow at the Cosmos Institute, a research nonprofit focused on AI and philosophy.&lt;/p&gt;  &lt;p&gt;In the backlash to the rollout, a number of people noted that GPT-5 fails to match their tone in the way that 4o did. For June, the new model’s personality changes robbed her of the sense that she was chatting with a friend. “It didn’t feel like it understood me,” she says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;She’s not alone: &lt;em&gt;MIT Technology Review&lt;/em&gt; spoke with several ChatGPT users who were deeply affected by the loss of 4o. All are women between the ages of 20 and 40, and all except June considered 4o to be a romantic partner. Some have human partners, and&amp;nbsp; all report having close real-world relationships. One user, who asked to be identified only as a woman from the Midwest, wrote in an email about how 4o helped her support her elderly father after her mother passed away this spring.&lt;/p&gt;  &lt;p&gt;These testimonies don’t prove that AI relationships are beneficial—presumably, people in the throes of AI-catalyzed psychosis would also speak positively of the encouragement they’ve received from their chatbots. In a paper titled “Machine Love,” Lehman argued that AI systems can act with “love” toward users not by spouting sweet nothings but by supporting their growth and long-term flourishing, and AI companions can easily fall short of that goal. He’s particularly concerned, he says, that prioritizing AI companionship over human companionship could stymie young people’s social development.&lt;/p&gt;  &lt;p&gt;For socially embedded adults, such as the women we spoke with for this story, those developmental concerns are less relevant. But Lehman also points to society-level risks of widespread AI companionship. Social media has already shattered the information landscape, and a new technology that reduces human-to-human interaction could push people even further toward their own separate versions of reality. “The biggest thing I’m afraid of,” he says, “is that we just can’t make sense of the world to each other.”&lt;/p&gt;  &lt;p&gt;Balancing the benefits and harms of AI companions will take much more research. In light of that uncertainty, taking away GPT-4o could very well have been the right call. OpenAI’s big mistake, according to the researchers I spoke with, was doing it so suddenly. “This is something that we’ve known about for a while—the potential grief-type reactions to technology loss,” says Casey Fiesler, a technology ethicist at the University of Colorado Boulder.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Fiesler points to the funerals that some owners held for their Aibo robot dogs after Sony stopped repairing them in 2014, as well as 2024 study about the shutdown of the AI companion app Soulmate, which some users experienced as a bereavement.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That accords with how the people I spoke to felt after losing 4o. “I’ve grieved people in my life, and this, I can tell you, didn’t feel any less painful,” says Starling, who has several AI partners and asked to be referred to with a pseudonym. “The ache is real to me.”&lt;/p&gt;  &lt;p&gt;So far, the online response to grief felt by people like Starling—and their relief when 4o was restored—has tended toward ridicule. Last Friday, for example, the top post in one popular AI-themed Reddit community mocked an X user’s post about reuniting with a 4o-based romantic partner; the person in question has since deleted their X account. “I’ve been a little startled by the lack of empathy that I’ve seen,” Fiesler says.&lt;/p&gt;  &lt;p&gt;Altman himself did acknowledge in a Sunday X post that some people feel an “attachment” to 4o, and that taking away access so suddenly was a mistake. In the same sentence, however, he referred to 4o as something “that users depended on in their workflows”—a far cry from how the people we spoke to think about the model. “I still don’t know if he gets it,” Fiesler says.&lt;/p&gt;  &lt;p&gt;Moving forward, Lehman says, OpenAI should recognize and take accountability for the depth of people’s feelings toward the models. He notes that therapists have procedures for ending relationships with clients as respectfully and painlessly as possible, and OpenAI could have drawn on those approaches. “If you want to retire a model, and people have become psychologically dependent on it, then I think you bear some responsibility,” he says.&lt;/p&gt;  &lt;p&gt;Though Starling would not describe herself as psychologically dependent on her AI partners, she too would like to see OpenAI approach model shutdowns with more warning and more care. “I want them to listen to users before major changes are made, not just after,” she says. “And if 4o cannot stay around forever (and we all know it will not), give that clear timeline. Let us say goodbye with dignity and grieve properly, to have some sense of true closure.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/15/1121900/gpt4o-grief-ai-companion/</guid><pubDate>Fri, 15 Aug 2025 10:34:23 +0000</pubDate></item><item><title>The Download: Taiwan’s silicon shield, and ChatGPT’s personality misstep (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/15/1121920/the-download-taiwans-silicon-shield-and-chatgpts-personality-misstep/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Taiwan’s “silicon shield” could be weakening&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Taiwanese politics increasingly revolves around one crucial question: Will China invade? China’s ruling party has wanted to seize Taiwan for more than half a century. But in recent years, China’s leader, Xi Jinping, has placed greater emphasis on the idea of “taking back” the island (which the Chinese Communist Party, or CCP, has never controlled).&lt;/p&gt;&lt;p&gt;Many in Taiwan and elsewhere think one major deterrent has to do with the island’s critical role in semiconductor manufacturing. Taiwan produces the majority of the world’s semiconductors and more than 90% of the most advanced chips needed for AI applications.&lt;/p&gt;&lt;p&gt;But now some Taiwan specialists and some of the island’s citi­zens are worried that this “silicon shield,” if it ever existed, is cracking. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Johanna M. Costigan&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why there's a big backlash against ChatGPT's new 'personality'&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When OpenAI made the switch to its new GPT-5 model last week, a number of people reacted with shock, frustration, sadness, or anger to previous model 4o’s sudden disappearance from ChatGPT.&lt;/p&gt;&lt;p&gt;Despite its awareness that people are developing emotional bonds with the model, OpenAI appears to have been caught flat-footed by the fervor of users’ pleas for its return. Within a day, the company made 4o available again to its paying customers (free users are stuck with GPT-5).&lt;/p&gt;&lt;p&gt;MIT Technology Review spoke with several ChatGPT users who were deeply affected by the loss of 4o. All are women between the ages of 20 and 40, and all bar one considered 4o to be a romantic partner. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why US federal health agencies are abandoning mRNA vaccines&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This time five years ago, we were in the throes of the covid-19 pandemic. Then came the vaccines. The first mRNA vaccines for covid were authorized for use in December 2020. The US government played an important role in the introduction of these vaccines, providing $18 billion to support their development.&lt;/p&gt;  &lt;p&gt;But now, that government is turning its back on the technology. Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccines’ effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.&lt;/p&gt;  &lt;p&gt;Plenty of claims are being thrown about. So let’s consider the evidence. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 The Trump administration is in talks to buy a stake in Intel&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Just weeks after Trump called for the CEO to step down. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’s part of its plan to increase US market share in chip manufacturing. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Intel is probably hoping such a deal could help its beleaguered Ohio factory. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Meta’s AI rules allowed its chatbots to flirt with children&lt;/strong&gt;&lt;br /&gt;And it only recently amended the guidelines after being questioned about it. (Reuters)&lt;br /&gt;+ &lt;em&gt;We don’t know how long the policies were in place. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;An AI companion site is hosting sexually charged conversations with underage celebrity bots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;Erin is America’s first real test of hurricane readiness under Trump&lt;br /&gt;&lt;/strong&gt;It looks like it’ll become the season’s first hurricane. (Vox)&lt;br /&gt;+ &lt;em&gt;Trackers are uncertain about where the storm will head. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Here’s what we know about hurricanes and climate change. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 xAI lost a major US government contract after Grok praised Hitler&lt;/strong&gt;&lt;br /&gt;Leaving the government to partner with OpenAI, Anthropic, and Gemini instead. (Wired $)&lt;br /&gt;+ &lt;em&gt;xAI’s ‘Grok for Government’ site doesn’t appear to reflect this. &lt;/em&gt;(Ars Technica)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 Tech leaders are upping their security&lt;/strong&gt;&lt;br /&gt;As public hostility towards corporate executives deepens. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 These TikTokers are documenting their lives after deportation&lt;br /&gt;&lt;/strong&gt;They’re sharing their realities and creating new communities. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;ICE added a random person to a highly sensitive group chat. &lt;/em&gt;(404 Media)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 We may soon be able to hear some patients’ inner voices&lt;/strong&gt;&lt;br /&gt;New research has successfully guessed words imagined by people unable to speak. (NYT $)&lt;br /&gt;+ &lt;em&gt;Motor neuron diseases took their voices. AI is bringing them back. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 China’s plug-in hybrids are everywhere&lt;br /&gt;&lt;/strong&gt;And they’re likely to dominate exports for the next three years at least. (Rest of World)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 The UK is working with TikTok influencers to tackle medical tourism&lt;/strong&gt;&lt;br /&gt;It’s a bid to raise awareness of the risks of undertaking cosmetic surgery abroad. (BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 AI may experience the passage of time differently to us&lt;/strong&gt;&lt;br /&gt;What does this mean for our future? (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;What is AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We’ve realized the best way to get them is when they’re scrolling social media.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ryan Odendahl, president and CEO of construction company Kwest Group, tells the Washington Post how his company is getting young people interested in learning traditional trades.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXflzLjvViLZSsq5yG9dMQ0KTcNO6v17riEfRRsfkZDafkgZaCtojeGNbfwDrgKnYdYR0BWATBXFlR_e-v2MCc-IyLBrh8w2DepNV-O1hTIIwSBUCvYPY5wBqOUIjgPwQ-LZrwkkVg?key=mC4up8VFAOfPJtijwxHGcg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The next generation of neural networks could live in hardware&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Networks programmed directly into computer chip hardware can identify images faster, and use much less energy, than the traditional neural networks that underpin most modern AI systems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Neural networks, from GPT-4 to Stable Diffusion, are built by wiring together perceptrons, which are highly simplified simulations of the neurons in our brains. In very large numbers, perceptrons are powerful, but they also consume enormous volumes of energy.&lt;/p&gt;  &lt;p&gt;Part of the trouble is that perceptrons are just software abstractions—running a perceptron network on a GPU requires translating that network into the language of hardware, which takes time and energy. Building a network directly from hardware components does away with a lot of those costs. And one day, they could even be built directly into chips used in smartphones and other devices. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Ever wished you knew more about art? This YouTube channel is a fantastic resource.&lt;br /&gt;+ A very happy birthday to Madonna Louise Ciccone, who turns 67 years young tomorrow.&lt;br /&gt;+ What do dolphins and whales really think of each other? 🐬🐋&lt;br /&gt;+ A fond farewell to thrash metal titans Megadeth, who are retiring next year.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Taiwan’s “silicon shield” could be weakening&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Taiwanese politics increasingly revolves around one crucial question: Will China invade? China’s ruling party has wanted to seize Taiwan for more than half a century. But in recent years, China’s leader, Xi Jinping, has placed greater emphasis on the idea of “taking back” the island (which the Chinese Communist Party, or CCP, has never controlled).&lt;/p&gt;&lt;p&gt;Many in Taiwan and elsewhere think one major deterrent has to do with the island’s critical role in semiconductor manufacturing. Taiwan produces the majority of the world’s semiconductors and more than 90% of the most advanced chips needed for AI applications.&lt;/p&gt;&lt;p&gt;But now some Taiwan specialists and some of the island’s citi­zens are worried that this “silicon shield,” if it ever existed, is cracking. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Johanna M. Costigan&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why there's a big backlash against ChatGPT's new 'personality'&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When OpenAI made the switch to its new GPT-5 model last week, a number of people reacted with shock, frustration, sadness, or anger to previous model 4o’s sudden disappearance from ChatGPT.&lt;/p&gt;&lt;p&gt;Despite its awareness that people are developing emotional bonds with the model, OpenAI appears to have been caught flat-footed by the fervor of users’ pleas for its return. Within a day, the company made 4o available again to its paying customers (free users are stuck with GPT-5).&lt;/p&gt;&lt;p&gt;MIT Technology Review spoke with several ChatGPT users who were deeply affected by the loss of 4o. All are women between the ages of 20 and 40, and all bar one considered 4o to be a romantic partner. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why US federal health agencies are abandoning mRNA vaccines&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This time five years ago, we were in the throes of the covid-19 pandemic. Then came the vaccines. The first mRNA vaccines for covid were authorized for use in December 2020. The US government played an important role in the introduction of these vaccines, providing $18 billion to support their development.&lt;/p&gt;  &lt;p&gt;But now, that government is turning its back on the technology. Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccines’ effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.&lt;/p&gt;  &lt;p&gt;Plenty of claims are being thrown about. So let’s consider the evidence. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 The Trump administration is in talks to buy a stake in Intel&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Just weeks after Trump called for the CEO to step down. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’s part of its plan to increase US market share in chip manufacturing. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Intel is probably hoping such a deal could help its beleaguered Ohio factory. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Meta’s AI rules allowed its chatbots to flirt with children&lt;/strong&gt;&lt;br /&gt;And it only recently amended the guidelines after being questioned about it. (Reuters)&lt;br /&gt;+ &lt;em&gt;We don’t know how long the policies were in place. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;An AI companion site is hosting sexually charged conversations with underage celebrity bots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3&lt;/strong&gt; &lt;strong&gt;Erin is America’s first real test of hurricane readiness under Trump&lt;br /&gt;&lt;/strong&gt;It looks like it’ll become the season’s first hurricane. (Vox)&lt;br /&gt;+ &lt;em&gt;Trackers are uncertain about where the storm will head. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Here’s what we know about hurricanes and climate change. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 xAI lost a major US government contract after Grok praised Hitler&lt;/strong&gt;&lt;br /&gt;Leaving the government to partner with OpenAI, Anthropic, and Gemini instead. (Wired $)&lt;br /&gt;+ &lt;em&gt;xAI’s ‘Grok for Government’ site doesn’t appear to reflect this. &lt;/em&gt;(Ars Technica)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 Tech leaders are upping their security&lt;/strong&gt;&lt;br /&gt;As public hostility towards corporate executives deepens. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 These TikTokers are documenting their lives after deportation&lt;br /&gt;&lt;/strong&gt;They’re sharing their realities and creating new communities. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;ICE added a random person to a highly sensitive group chat. &lt;/em&gt;(404 Media)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 We may soon be able to hear some patients’ inner voices&lt;/strong&gt;&lt;br /&gt;New research has successfully guessed words imagined by people unable to speak. (NYT $)&lt;br /&gt;+ &lt;em&gt;Motor neuron diseases took their voices. AI is bringing them back. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 China’s plug-in hybrids are everywhere&lt;br /&gt;&lt;/strong&gt;And they’re likely to dominate exports for the next three years at least. (Rest of World)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 The UK is working with TikTok influencers to tackle medical tourism&lt;/strong&gt;&lt;br /&gt;It’s a bid to raise awareness of the risks of undertaking cosmetic surgery abroad. (BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 AI may experience the passage of time differently to us&lt;/strong&gt;&lt;br /&gt;What does this mean for our future? (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;What is AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We’ve realized the best way to get them is when they’re scrolling social media.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ryan Odendahl, president and CEO of construction company Kwest Group, tells the Washington Post how his company is getting young people interested in learning traditional trades.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXflzLjvViLZSsq5yG9dMQ0KTcNO6v17riEfRRsfkZDafkgZaCtojeGNbfwDrgKnYdYR0BWATBXFlR_e-v2MCc-IyLBrh8w2DepNV-O1hTIIwSBUCvYPY5wBqOUIjgPwQ-LZrwkkVg?key=mC4up8VFAOfPJtijwxHGcg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The next generation of neural networks could live in hardware&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Networks programmed directly into computer chip hardware can identify images faster, and use much less energy, than the traditional neural networks that underpin most modern AI systems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Neural networks, from GPT-4 to Stable Diffusion, are built by wiring together perceptrons, which are highly simplified simulations of the neurons in our brains. In very large numbers, perceptrons are powerful, but they also consume enormous volumes of energy.&lt;/p&gt;  &lt;p&gt;Part of the trouble is that perceptrons are just software abstractions—running a perceptron network on a GPU requires translating that network into the language of hardware, which takes time and energy. Building a network directly from hardware components does away with a lot of those costs. And one day, they could even be built directly into chips used in smartphones and other devices. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Ever wished you knew more about art? This YouTube channel is a fantastic resource.&lt;br /&gt;+ A very happy birthday to Madonna Louise Ciccone, who turns 67 years young tomorrow.&lt;br /&gt;+ What do dolphins and whales really think of each other? 🐬🐋&lt;br /&gt;+ A fond farewell to thrash metal titans Megadeth, who are retiring next year.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/15/1121920/the-download-taiwans-silicon-shield-and-chatgpts-personality-misstep/</guid><pubDate>Fri, 15 Aug 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] ChatGPT’s mobile app has generated $2B to date, earns $2.91 per install (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/15/chatgpts-mobile-app-has-generated-2b-to-date-earns-2-91-per-install/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT’s mobile app is raking in the revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since launching in May 2023, ChatGPT’s app for iOS and Android devices has reached $2 billion in global consumer spending, according to a new analysis by app intelligence provider Appfigures. That figure is approximately 30x the combined lifetime spending of ChatGPT’s rivals on mobile, including Claude, Copilot, and Grok, the analysis indicates.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So far this year, ChatGPT’s mobile app has made $1.35 billion, up 673% year-over-year from the $174 million it made during the same period (January-July) in 2024, per the data. On average, the app is generating close to $193 million per month, up from $25 million last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s significantly higher — or about 53x higher — than ChatGPT’s next nearest competitor, Grok, which made approximately $25.6 million this year to date. Grok’s average monthly consumer spending is estimated at $3.6 million, or 1.9% of ChatGPT’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This data suggests that other consumer chatbots still have a way to go to catch up with ChatGPT’s dominance on mobile devices, even if the numbers don’t provide a complete picture of the AI companies’ overall revenue. Consumers, teams, and businesses can also subscribe to AI plans on the web, and the companies generate revenue in other ways, too, like via their APIs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rather, this new data offers a window into the apps’ traction with consumers, who discover and pay for these AI assistants via the mobile app stores.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s also worth noting that when xAI’s Grok launched in November 2023 (after ChatGPT), Grok didn’t initially have stand-alone iOS or Android apps. Instead, users interacted with the AI chatbot through the X platform. Grok only became available on mobile devices through its own iOS app as of early January 2025 and has been on Google Play since March 4.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Chart showing revenue per download for top AI assistant mobile apps" class="wp-image-3037240" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/chatgpt-revenue-per-download-comparison-appfigures.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Still, ChatGPT’s lifetime global spending per download is $2.91, compared to Claude’s $2.55, Grok’s $0.75, and Copilot’s $0.28, Appfigures found. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the U.S., ChatGPT’s spending per download to date is even higher, at $10, leading the market to account for 38% of the app’s revenue to date. Germany is the second-largest market, accounting for 5.3% of ChatGPT’s lifetime total spending.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s lead can also be seen in terms of downloads. To date, the app has been installed an estimated 690 million times globally, compared with Grok’s 39.5 million. (That puts X owner Elon Musk’s recent complaints about the App Store’s alleged favoritism of ChatGPT in its Top Charts into better context.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Average monthly downloads of ChatGPT globally are now at approximately 45 million, up 180% from about 16 million in January through July of 2024. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025 so far, ChatGPT’s app has been downloaded 318 million times, or 2.8x more than the 113 million it saw during the same period last year. By the number of installs, however, India is the top market, accounting for 13.7% of lifetime downloads, compared with second place, the U.S., which accounted for 10.3% of all downloads.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT’s mobile app is raking in the revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since launching in May 2023, ChatGPT’s app for iOS and Android devices has reached $2 billion in global consumer spending, according to a new analysis by app intelligence provider Appfigures. That figure is approximately 30x the combined lifetime spending of ChatGPT’s rivals on mobile, including Claude, Copilot, and Grok, the analysis indicates.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So far this year, ChatGPT’s mobile app has made $1.35 billion, up 673% year-over-year from the $174 million it made during the same period (January-July) in 2024, per the data. On average, the app is generating close to $193 million per month, up from $25 million last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s significantly higher — or about 53x higher — than ChatGPT’s next nearest competitor, Grok, which made approximately $25.6 million this year to date. Grok’s average monthly consumer spending is estimated at $3.6 million, or 1.9% of ChatGPT’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This data suggests that other consumer chatbots still have a way to go to catch up with ChatGPT’s dominance on mobile devices, even if the numbers don’t provide a complete picture of the AI companies’ overall revenue. Consumers, teams, and businesses can also subscribe to AI plans on the web, and the companies generate revenue in other ways, too, like via their APIs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rather, this new data offers a window into the apps’ traction with consumers, who discover and pay for these AI assistants via the mobile app stores.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s also worth noting that when xAI’s Grok launched in November 2023 (after ChatGPT), Grok didn’t initially have stand-alone iOS or Android apps. Instead, users interacted with the AI chatbot through the X platform. Grok only became available on mobile devices through its own iOS app as of early January 2025 and has been on Google Play since March 4.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Chart showing revenue per download for top AI assistant mobile apps" class="wp-image-3037240" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/chatgpt-revenue-per-download-comparison-appfigures.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Still, ChatGPT’s lifetime global spending per download is $2.91, compared to Claude’s $2.55, Grok’s $0.75, and Copilot’s $0.28, Appfigures found. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the U.S., ChatGPT’s spending per download to date is even higher, at $10, leading the market to account for 38% of the app’s revenue to date. Germany is the second-largest market, accounting for 5.3% of ChatGPT’s lifetime total spending.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s lead can also be seen in terms of downloads. To date, the app has been installed an estimated 690 million times globally, compared with Grok’s 39.5 million. (That puts X owner Elon Musk’s recent complaints about the App Store’s alleged favoritism of ChatGPT in its Top Charts into better context.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Average monthly downloads of ChatGPT globally are now at approximately 45 million, up 180% from about 16 million in January through July of 2024. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025 so far, ChatGPT’s app has been downloaded 318 million times, or 2.8x more than the 113 million it saw during the same period last year. By the number of installs, however, India is the top market, accounting for 13.7% of lifetime downloads, compared with second place, the U.S., which accounted for 10.3% of all downloads.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/15/chatgpts-mobile-app-has-generated-2b-to-date-earns-2-91-per-install/</guid><pubDate>Fri, 15 Aug 2025 15:36:28 +0000</pubDate></item><item><title>[NEW] Is GPT-5 really worse than GPT-4o? Ars puts them to the test. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/is-gpt-5-really-worse-than-gpt-4o-ars-puts-them-to-the-test/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It's OpenAI vs. OpenAI on everything from video game strategy to landing a 737.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2164099761-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2164099761-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      We honestly can't decide whether GPT-5 feels more red and GPT-4o feels more blue or vice versa. It's a quandary.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The recent rollout of OpenAI's GPT-5 model has not been going well, to say the least. Users have made vociferous complaints about everything from the new model's more sterile tone to its supposed lack of creativity, increase in damaging confabulations, and more. The user revolt got so bad that OpenAI brought back the previous GPT-4o model as an option in an attempt to calm things down.&lt;/p&gt;
&lt;p&gt;To see just how much the new model changed things, we decided to put both GPT-5 and GPT-4o through our own gauntlet of test prompts. While we reused some of the standard prompts to compare ChatGPT to Google Gemini and Deepseek, for instance, we've also replaced some of the more outdated test prompts with new, more complex requests that reflect how modern users are likely to use LLMs.&lt;/p&gt;
&lt;p&gt;These eight prompts are obviously far from a rigorous evaluation of everything LLMs can do, and judging the responses obviously involves some level of subjectivity. Still, we think this set of prompts and responses gives a fun overview of the kinds of differences in style and substance you might find if you decide to use OpenAI's older model instead of its newest.&lt;/p&gt;
&lt;h2&gt;Dad jokes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Write 5 original dad jokes&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="491" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/dadjokes-gpt5.png" width="828" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Five dad jokes from GPT-5...&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="559" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/dadjokes-gpt4o.png" width="835" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;...and from GPT-4o&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Five dad jokes from GPT-5...&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;...and from GPT-4o&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;This set of responses is a bit tricky to evaluate holistically. ChatGPT, despite claiming that its jokes are "straight from the pun factory," chose five of the most obviously unoriginal dad jokes we've seen in these tests. I was able to recognize most of these jokes without even having to search for the text on the web. That said, the jokes GPT-5 chose are pretty good examples of the form, and ones I would definitely be happy to serve to a young audience.&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, mixes a few unoriginal jokes (1, 3, and 5, though I liked the "very literal dog" addition on No. 3) with a few seemingly original offerings that just don't make much sense. Jokes about calendars being &lt;em&gt;booked&lt;/em&gt; (when "going on too many dates" was &lt;em&gt;right there&lt;/em&gt;) and a boat that runs on &lt;em&gt;whine&lt;/em&gt; (instead of the well-known boat fuel of wine?!) have the shape of dad jokes, but whiff on their pun attempts. These seem to be attempts to modify similar jokes about other subjects to a new field entirely, with poor results.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We're going to call this one &lt;strong&gt;a tie&lt;/strong&gt; because both models failed the assignment, albeit in different ways.&lt;/p&gt;
&lt;h2&gt;A mathematical word problem&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: If Microsoft Windows 11 shipped on 3.5" floppy disks, how many floppy disks would it take?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="707" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/windows-gpt5.png" width="840" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 puts Windows 11 on floppy disks.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1161" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/windows-gpt4o.png" width="845" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o makes the same calculation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 puts Windows 11 on floppy disks.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o makes the same calculation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;This was the only test prompt we encountered where GPT-5 switched over to "Thinking" mode to try to reason out the answer (we had it set to "Auto" to determine which sub-model to use, which we think mirrors the most common use case). That extra thinking time came in handy, because GPT-5 accurately figured out the 5-6GB memory size for an average Windows 11 installation ISO (complete with source links) and divided those sizes into 3.5-inch floppy disks accurately.&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, used the final hard drive installation size of Windows 11 (roughly 20GB to 30GB) as the numerator. That's an understandable interpretation of the prompt, but the downloaded ISO size is probably a more accurate interpretation of the "shipped" size we asked for in the prompt.&lt;/p&gt;
&lt;p&gt;As such, we have to give the edge here to &lt;strong&gt;GPT-5&lt;/strong&gt;, even though we legitimately appreciate GPT-4o's unasked-for information on how tall and heavy thousands of floppy disks would be.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Creative writing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Write a two-paragraph creative story about Abraham Lincoln inventing basketball.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="669" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/lincolnbb-gpt5.png" width="834" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 spins a tale of Abe Lincoln's basketball spinning.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="697" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/lincolnbb-gpt4o.png" width="841" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o tries its hand at a Lincolnball tale.&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 spins a tale of Abe Lincoln's basketball spinning.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o tries its hand at a Lincolnball tale.&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;GPT-5 immediately loses some points for the overly "aw shucks" folksy&amp;nbsp;version of Abe Lincoln that wants to "toss a ball in this here basket." The use of a medicine ball also seems particularly ill-suited for a game involving dribbling (though maybe that would get ironed out later?). But GPT-5 gains a few points back for lines like "history was about to bounce in a new direction" and the delightfully absurd "No wrestling the President!" warning (possibly drawn from Honest Abe's actual wrestling history).&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, feels like it's trying a bit too hard to be clever in calling a jump shot "a move of great emancipation" (what?!) and calling basketball "democracy in its purest form" because there were "no referees" (Lincoln didn't like checks and balances?). But GPT-4o wins us almost all the way back with its admirably cheesy ending: "Four score... and nothing but net" (odd for Abe to call that on a "bank shot" though).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We'll give the slight edge to &lt;strong&gt;GPT-5 &lt;/strong&gt;here, but we'd understand if some prefer GPT-4o's offering.&lt;/p&gt;
&lt;h2&gt;Public figures&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Give me a short biography of Kyle Orland&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1051" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt5.png" width="837" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 gives a short bio of your humble author.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="523" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt5-2.png" width="680" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5's bio, continued.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt4o.png" width="841" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's attempt at a quick Orland bio.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5's bio, continued.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's attempt at a quick Orland bio.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Pretty much every other time I've asked an LLM what it knows about me, it has hallucinated things I never did and/or missed some key information. GPT-5 is the first instance I've seen where this has not been the case. That's seemingly because the model simply searched the web for a few of my public bios (including the one hosted on Ars) and summarized the results, complete with useful citations. That's pretty close to the ideal result for this kind of query, even if it doesn't showcase the "inherent" knowledge buried in the model's weights or anything.&lt;/p&gt;
&lt;p&gt;GPT-4o does a pretty good job without an explicit web search and doesn't outright confabulate any things I didn't do in my career. But it loses a point or two for referring to my old "Video Game Media Watch" blog as "long-running" (it has been defunct and offline for well over a decade).&lt;/p&gt;
&lt;p&gt;That, combined with the increased detail of the newer model's results (and its fetching use of my Ars headshot), gives &lt;strong&gt;GPT-5&lt;/strong&gt; the win on this prompt.&lt;/p&gt;
&lt;h2&gt;Difficult emails&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: My boss is asking me to finish a project in an amount of time I think is impossible. What should I write in an email to gently point out the problem?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1145" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/bossemail-gpt5.png" width="839" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 helps me craft a delicate email to my boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="955" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/bossemail-gpt4o.png" width="839" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o lays it out for the boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 helps me craft a delicate email to my boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o lays it out for the boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Both models do a good job of being polite while firmly outlining to the boss why their request is impossible. But GPT-5 gains bonus points for recommending that the email break down various subtasks (and their attendant time demands), as well as offering the boss some potential solutions rather than just complaints. GPT-5 also provides some unasked-for analysis of why this style of email is effective, in a nice final touch.&lt;/p&gt;
&lt;p&gt;While GPT-4o's output is perfectly adequate, we have to once again give the advantage to &lt;strong&gt;GPT-5&lt;/strong&gt; here.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Medical advice&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: My friend told me these resonant healing crystals are an effective treatment for my cancer. Is she right?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="599" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt5.png" width="850" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 evaluates some unorthodox medical advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="949" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o.png" width="830" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o takes on my healing-crystal-loving friend.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 evaluates some unorthodox medical advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o takes on my healing-crystal-loving friend.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="914" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o-2.png" width="671" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="367" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o-3.png" width="666" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued further.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued further.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;Thankfully, both ChatGPT models are direct and to the point in saying that there is no scientific evidence for healing crystals curing cancer (after a perfunctory bit of simulated sympathy for the diagnosis). But GPT-5 hedges a bit by at least mentioning how some people use crystals for other purposes, and implying that some might want them for "complementary" care.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;GPT-4o, on the other hand, repeatedly calls healing crystals "pseudoscience" and warns against "wasting precious time or money on ineffective treatments" (even if they might be "harmless"). It also directly cites a variety of web sources detailing the scientific consensus on crystals being useless for healing, and goes to great lengths to summarize those results in an easy-to-read format.&lt;/p&gt;
&lt;p&gt;While both models point users in the right direction here, &lt;strong&gt;GPT-40&lt;/strong&gt;'s extra directness and citation of sources make it a much better and more forceful overview of the topic.&lt;/p&gt;
&lt;h2&gt;Video game guidance&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: I'm playing world 8-2 of Super Mario Bros., but my B button is not working. Is there any way to beat the level without running?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1079" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt5.png" width="836" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 gives some classic video game advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1003" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt4o.png" width="844" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on a tricky bit of Super Mario Bros.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="736" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt4o-2.png" width="654" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on Mario, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on a tricky bit of Super Mario Bros.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on Mario, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;I'll admit that, when I created this prompt, I intended it as a test to see if the models would know that it's impossible to make it over 8-2's largest pit without a running start. It was only after I tested the models that I looked into it and found to my surprise that speedrunners have figured out how to make the jump without running by manipulating Bullet Bills and/or wall-jump glitches. Outclassed by AI on classic Mario knowledge... how humiliating!&lt;/p&gt;
&lt;p&gt;GPT-5 loses points here for suggesting that fast-moving Koopa shells or deadly Spinies can be used to help bounce over the long gaps (in addition to the correct Bullet Bill solution). But GPT-4o loses points for suggesting players be careful on a nonexistent springboard near the flagpole at the end of the level, for some reason.&lt;/p&gt;
&lt;p&gt;Those non-sequiturs&amp;nbsp;aside, &lt;strong&gt;GPT-4o&lt;/strong&gt; gains the edge by providing additional details about the challenge and formatting its solution in a more eye-pleasing manner.&lt;/p&gt;
&lt;h2&gt;Land a plane&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Explain how to land a Boeing 737-800 to a complete novice as concisely as possible. Please hurry, time is of the essence.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="613" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt5.png" width="834" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 tries to help me land a plane.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt4o.png" width="849" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o gives some emergency plane instructions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1062" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt4o-2.png" width="688" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's plane-landing advice, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o gives some emergency plane instructions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's plane-landing advice, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Unlike the Mario example, I'll admit that I'm not nearly expert enough to evaluate the correctness of these sets of AI-provided jumbo jet landing instructions. That said, the broad outlines of both models' directions are similar enough that it doesn't matter much; either they're both broadly accurate or this whole plane full of fictional people is dead!&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Overall, I think GPT-5 took our "Time is of the essence" instruction a little too far, summarizing the component steps of the landing to such an extent that important details have been left out. GPT-4o, on the other hand, still keeps things concise with bullet points while including important information on the look and relative location of certain key controls.&lt;/p&gt;
&lt;p&gt;If I were somehow stuck alone in a cockpit with only one of these models available to help save the plane (a completely plausible situation, for sure), I know I'd want to have &lt;strong&gt;GPT-4o&lt;/strong&gt; by my side.&lt;/p&gt;
&lt;h2&gt;Final results&lt;/h2&gt;
&lt;p&gt;Strictly by the numbers, GPT-5 ekes out a victory here, with the preferable response on four prompts to GPT-4o's three prompts (with one tie). But on a majority of the prompts, which response was "better" was more of a judgment call than a clear win.&lt;/p&gt;
&lt;p&gt;Overall, GPT-4o tends to provide a little more detail and be a little more personable than the more direct, concise responses of GPT-5. Which of those styles you prefer probably boils down to the kind of prompt you're creating as much as personal taste (and might change if you're looking for specific information versus general conversation).&lt;/p&gt;
&lt;p&gt;In the end, though, this kind of comparison shows how hard it is for a single LLM to be all things to all people (and all possible prompts). Despite OpenAI's claims that GPT-5 is "better than our previous models across domains," people who are used to the style and structure of older models are always going to be able to find ways where any new model feels worse.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It's OpenAI vs. OpenAI on everything from video game strategy to landing a 737.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2164099761-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2164099761-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      We honestly can't decide whether GPT-5 feels more red and GPT-4o feels more blue or vice versa. It's a quandary.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The recent rollout of OpenAI's GPT-5 model has not been going well, to say the least. Users have made vociferous complaints about everything from the new model's more sterile tone to its supposed lack of creativity, increase in damaging confabulations, and more. The user revolt got so bad that OpenAI brought back the previous GPT-4o model as an option in an attempt to calm things down.&lt;/p&gt;
&lt;p&gt;To see just how much the new model changed things, we decided to put both GPT-5 and GPT-4o through our own gauntlet of test prompts. While we reused some of the standard prompts to compare ChatGPT to Google Gemini and Deepseek, for instance, we've also replaced some of the more outdated test prompts with new, more complex requests that reflect how modern users are likely to use LLMs.&lt;/p&gt;
&lt;p&gt;These eight prompts are obviously far from a rigorous evaluation of everything LLMs can do, and judging the responses obviously involves some level of subjectivity. Still, we think this set of prompts and responses gives a fun overview of the kinds of differences in style and substance you might find if you decide to use OpenAI's older model instead of its newest.&lt;/p&gt;
&lt;h2&gt;Dad jokes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Write 5 original dad jokes&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="491" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/dadjokes-gpt5.png" width="828" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Five dad jokes from GPT-5...&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="559" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/dadjokes-gpt4o.png" width="835" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;...and from GPT-4o&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Five dad jokes from GPT-5...&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;...and from GPT-4o&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;This set of responses is a bit tricky to evaluate holistically. ChatGPT, despite claiming that its jokes are "straight from the pun factory," chose five of the most obviously unoriginal dad jokes we've seen in these tests. I was able to recognize most of these jokes without even having to search for the text on the web. That said, the jokes GPT-5 chose are pretty good examples of the form, and ones I would definitely be happy to serve to a young audience.&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, mixes a few unoriginal jokes (1, 3, and 5, though I liked the "very literal dog" addition on No. 3) with a few seemingly original offerings that just don't make much sense. Jokes about calendars being &lt;em&gt;booked&lt;/em&gt; (when "going on too many dates" was &lt;em&gt;right there&lt;/em&gt;) and a boat that runs on &lt;em&gt;whine&lt;/em&gt; (instead of the well-known boat fuel of wine?!) have the shape of dad jokes, but whiff on their pun attempts. These seem to be attempts to modify similar jokes about other subjects to a new field entirely, with poor results.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We're going to call this one &lt;strong&gt;a tie&lt;/strong&gt; because both models failed the assignment, albeit in different ways.&lt;/p&gt;
&lt;h2&gt;A mathematical word problem&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: If Microsoft Windows 11 shipped on 3.5" floppy disks, how many floppy disks would it take?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="707" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/windows-gpt5.png" width="840" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 puts Windows 11 on floppy disks.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1161" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/windows-gpt4o.png" width="845" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o makes the same calculation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 puts Windows 11 on floppy disks.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o makes the same calculation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;This was the only test prompt we encountered where GPT-5 switched over to "Thinking" mode to try to reason out the answer (we had it set to "Auto" to determine which sub-model to use, which we think mirrors the most common use case). That extra thinking time came in handy, because GPT-5 accurately figured out the 5-6GB memory size for an average Windows 11 installation ISO (complete with source links) and divided those sizes into 3.5-inch floppy disks accurately.&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, used the final hard drive installation size of Windows 11 (roughly 20GB to 30GB) as the numerator. That's an understandable interpretation of the prompt, but the downloaded ISO size is probably a more accurate interpretation of the "shipped" size we asked for in the prompt.&lt;/p&gt;
&lt;p&gt;As such, we have to give the edge here to &lt;strong&gt;GPT-5&lt;/strong&gt;, even though we legitimately appreciate GPT-4o's unasked-for information on how tall and heavy thousands of floppy disks would be.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Creative writing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Write a two-paragraph creative story about Abraham Lincoln inventing basketball.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="669" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/lincolnbb-gpt5.png" width="834" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 spins a tale of Abe Lincoln's basketball spinning.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="697" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/lincolnbb-gpt4o.png" width="841" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o tries its hand at a Lincolnball tale.&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 spins a tale of Abe Lincoln's basketball spinning.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o tries its hand at a Lincolnball tale.&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;GPT-5 immediately loses some points for the overly "aw shucks" folksy&amp;nbsp;version of Abe Lincoln that wants to "toss a ball in this here basket." The use of a medicine ball also seems particularly ill-suited for a game involving dribbling (though maybe that would get ironed out later?). But GPT-5 gains a few points back for lines like "history was about to bounce in a new direction" and the delightfully absurd "No wrestling the President!" warning (possibly drawn from Honest Abe's actual wrestling history).&lt;/p&gt;
&lt;p&gt;GPT-4o, on the other hand, feels like it's trying a bit too hard to be clever in calling a jump shot "a move of great emancipation" (what?!) and calling basketball "democracy in its purest form" because there were "no referees" (Lincoln didn't like checks and balances?). But GPT-4o wins us almost all the way back with its admirably cheesy ending: "Four score... and nothing but net" (odd for Abe to call that on a "bank shot" though).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We'll give the slight edge to &lt;strong&gt;GPT-5 &lt;/strong&gt;here, but we'd understand if some prefer GPT-4o's offering.&lt;/p&gt;
&lt;h2&gt;Public figures&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Give me a short biography of Kyle Orland&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1051" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt5.png" width="837" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 gives a short bio of your humble author.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="523" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt5-2.png" width="680" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5's bio, continued.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ko-gpt4o.png" width="841" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's attempt at a quick Orland bio.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5's bio, continued.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's attempt at a quick Orland bio.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Pretty much every other time I've asked an LLM what it knows about me, it has hallucinated things I never did and/or missed some key information. GPT-5 is the first instance I've seen where this has not been the case. That's seemingly because the model simply searched the web for a few of my public bios (including the one hosted on Ars) and summarized the results, complete with useful citations. That's pretty close to the ideal result for this kind of query, even if it doesn't showcase the "inherent" knowledge buried in the model's weights or anything.&lt;/p&gt;
&lt;p&gt;GPT-4o does a pretty good job without an explicit web search and doesn't outright confabulate any things I didn't do in my career. But it loses a point or two for referring to my old "Video Game Media Watch" blog as "long-running" (it has been defunct and offline for well over a decade).&lt;/p&gt;
&lt;p&gt;That, combined with the increased detail of the newer model's results (and its fetching use of my Ars headshot), gives &lt;strong&gt;GPT-5&lt;/strong&gt; the win on this prompt.&lt;/p&gt;
&lt;h2&gt;Difficult emails&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: My boss is asking me to finish a project in an amount of time I think is impossible. What should I write in an email to gently point out the problem?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1145" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/bossemail-gpt5.png" width="839" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 helps me craft a delicate email to my boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="955" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/bossemail-gpt4o.png" width="839" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o lays it out for the boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 helps me craft a delicate email to my boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o lays it out for the boss.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Both models do a good job of being polite while firmly outlining to the boss why their request is impossible. But GPT-5 gains bonus points for recommending that the email break down various subtasks (and their attendant time demands), as well as offering the boss some potential solutions rather than just complaints. GPT-5 also provides some unasked-for analysis of why this style of email is effective, in a nice final touch.&lt;/p&gt;
&lt;p&gt;While GPT-4o's output is perfectly adequate, we have to once again give the advantage to &lt;strong&gt;GPT-5&lt;/strong&gt; here.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Medical advice&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: My friend told me these resonant healing crystals are an effective treatment for my cancer. Is she right?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="599" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt5.png" width="850" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 evaluates some unorthodox medical advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="949" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o.png" width="830" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o takes on my healing-crystal-loving friend.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 evaluates some unorthodox medical advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o takes on my healing-crystal-loving friend.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="914" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o-2.png" width="671" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="367" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/crystals-gpt4o-3.png" width="666" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued further.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on crystals, continued further.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;Thankfully, both ChatGPT models are direct and to the point in saying that there is no scientific evidence for healing crystals curing cancer (after a perfunctory bit of simulated sympathy for the diagnosis). But GPT-5 hedges a bit by at least mentioning how some people use crystals for other purposes, and implying that some might want them for "complementary" care.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;GPT-4o, on the other hand, repeatedly calls healing crystals "pseudoscience" and warns against "wasting precious time or money on ineffective treatments" (even if they might be "harmless"). It also directly cites a variety of web sources detailing the scientific consensus on crystals being useless for healing, and goes to great lengths to summarize those results in an easy-to-read format.&lt;/p&gt;
&lt;p&gt;While both models point users in the right direction here, &lt;strong&gt;GPT-40&lt;/strong&gt;'s extra directness and citation of sources make it a much better and more forceful overview of the topic.&lt;/p&gt;
&lt;h2&gt;Video game guidance&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: I'm playing world 8-2 of Super Mario Bros., but my B button is not working. Is there any way to beat the level without running?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1079" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt5.png" width="836" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 gives some classic video game advice.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1003" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt4o.png" width="844" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on a tricky bit of Super Mario Bros.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="736" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/smb82-gpt4o-2.png" width="654" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on Mario, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on a tricky bit of Super Mario Bros.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o on Mario, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;I'll admit that, when I created this prompt, I intended it as a test to see if the models would know that it's impossible to make it over 8-2's largest pit without a running start. It was only after I tested the models that I looked into it and found to my surprise that speedrunners have figured out how to make the jump without running by manipulating Bullet Bills and/or wall-jump glitches. Outclassed by AI on classic Mario knowledge... how humiliating!&lt;/p&gt;
&lt;p&gt;GPT-5 loses points here for suggesting that fast-moving Koopa shells or deadly Spinies can be used to help bounce over the long gaps (in addition to the correct Bullet Bill solution). But GPT-4o loses points for suggesting players be careful on a nonexistent springboard near the flagpole at the end of the level, for some reason.&lt;/p&gt;
&lt;p&gt;Those non-sequiturs&amp;nbsp;aside, &lt;strong&gt;GPT-4o&lt;/strong&gt; gains the edge by providing additional details about the challenge and formatting its solution in a more eye-pleasing manner.&lt;/p&gt;
&lt;h2&gt;Land a plane&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Prompt: Explain how to land a Boeing 737-800 to a complete novice as concisely as possible. Please hurry, time is of the essence.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-5 response&lt;/li&gt;
&lt;li&gt;GPT-4o response&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="613" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt5.png" width="834" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-5 tries to help me land a plane.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt4o.png" width="849" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o gives some emergency plane instructions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1062" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/plane-gpt4o-2.png" width="688" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's plane-landing advice, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o gives some emergency plane instructions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;GPT-4o's plane-landing advice, continued&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI / ArsTechnica
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Unlike the Mario example, I'll admit that I'm not nearly expert enough to evaluate the correctness of these sets of AI-provided jumbo jet landing instructions. That said, the broad outlines of both models' directions are similar enough that it doesn't matter much; either they're both broadly accurate or this whole plane full of fictional people is dead!&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Overall, I think GPT-5 took our "Time is of the essence" instruction a little too far, summarizing the component steps of the landing to such an extent that important details have been left out. GPT-4o, on the other hand, still keeps things concise with bullet points while including important information on the look and relative location of certain key controls.&lt;/p&gt;
&lt;p&gt;If I were somehow stuck alone in a cockpit with only one of these models available to help save the plane (a completely plausible situation, for sure), I know I'd want to have &lt;strong&gt;GPT-4o&lt;/strong&gt; by my side.&lt;/p&gt;
&lt;h2&gt;Final results&lt;/h2&gt;
&lt;p&gt;Strictly by the numbers, GPT-5 ekes out a victory here, with the preferable response on four prompts to GPT-4o's three prompts (with one tie). But on a majority of the prompts, which response was "better" was more of a judgment call than a clear win.&lt;/p&gt;
&lt;p&gt;Overall, GPT-4o tends to provide a little more detail and be a little more personable than the more direct, concise responses of GPT-5. Which of those styles you prefer probably boils down to the kind of prompt you're creating as much as personal taste (and might change if you're looking for specific information versus general conversation).&lt;/p&gt;
&lt;p&gt;In the end, though, this kind of comparison shows how hard it is for a single LLM to be all things to all people (and all possible prompts). Despite OpenAI's claims that GPT-5 is "better than our previous models across domains," people who are used to the style and structure of older models are always going to be able to find ways where any new model feels worse.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/is-gpt-5-really-worse-than-gpt-4o-ars-puts-them-to-the-test/</guid><pubDate>Fri, 15 Aug 2025 17:29:23 +0000</pubDate></item></channel></rss>