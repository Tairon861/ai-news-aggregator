<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 03 Aug 2025 18:32:29 +0000</lastBuildDate><item><title>[NEW] The uproar over Vogue’s AI-generated ad isn’t just about fashion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sarah Murray recalls the first time she saw an artificial model in fashion: It was 2023, and a beautiful young woman of color donned a Levi’s denim overall dress. Murray, a commercial model herself, said it made her feel sad and exhausted.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iconic denim company had teamed up with the AI studio Lalaland.ai to create “diverse” digital fashion models for more inclusive ads. For an industry that has failed for years to employ diverse human models, the backlash was swift, with New York Magazine calling the decision “artificial diversity.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Murray told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two years later, her worries have compounded. Brands continue to experiment with AI-generated models, to the consternation of many fashion lovers. The latest uproar came after Vogue’s July print edition featured a Guess ad with a typical model for the brand: thin yet voluptuous, glossy blond tresses, pouty rose lips. She exemplified North American beauty standards, but there was one problem — she was AI generated.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The internet buzzed for days, in large part because the AI-generated beauty showed up in Vogue, the fashion bible that dictates what is and is not acceptable in the industry. The AI-generated model was featured in an advertisement, &lt;em&gt;not&lt;/em&gt; a Vogue editorial spread. And Vogue told TechCrunch the ad met its advertising standards.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To many, an ad versus an editorial is a distinction without a difference.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke to fashion models, experts, and technologists to get a sense of where the industry is headed now that Vogue seems to have put a stamp of approval on technology that’s poised to dramatically change the fashion industry.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They said the Guess ad drama highlights questions arising within creative industries being touched by AI’s silicon fingers: When high-quality creative work can be done by AI in a fraction of the time and cost, what’s the point of humans? And in the world of fashion, what happens to the humans — the models, photographers, stylists, and set designers — performing those jobs?&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-it-s-just-so-much-cheaper"&gt;“It’s just so much cheaper”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Sinead Bovell, a model and founder of the WAYE organization who wrote about CGI models for Vogue five years ago, told TechCrunch that “e-commerce models” are most under threat of automation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;E-commerce models are the ones who pose for advertisements or display clothes and accessories for online shoppers. Compared to high-fashion models, whose striking, often unattainable looks are featured in editorial spreads and on runways, they’re more realistic and relatable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“E-commerce is where most models make their bread and butter,” Bovell said. “It’s not necessarily the path to model fame or model prestige, but it is the path for financial security.”&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033586" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/PHOTO-2025-08-01-15-05-08.jpeg?w=584" width="584" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;sinead bovell, founder &amp;amp; model &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sinead Bovell&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That fact is running in direct contrast to the pressure many brands feel to automate such shoots. Paul Mouginot, an art technologist who has worked with luxury brands, said it’s simply expensive to work with live models, especially when it comes to photographing them in countless garments, shoes, and accessories.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI now lets you start with a flat-lay product shoot, place it on a photorealistic virtual model, and even position that model in a coherent setting, producing images that look like genuine fashion editorials,” he told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brands, in some ways, have been doing this for a while, he said. Mouginot, who is French, cited the French retailer Veepee as an example of a company that has used virtual mannequins to sell clothes since at least 2013. Other notable brands like H&amp;amp;M, Mango, and Calvin Klein have also resorted to AI models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amy Odell, a fashion writer and author of a recently published biography on Gwyneth Paltrow, put it more simply: “It’s just so much cheaper for [brands] to use AI models now. Brands need a lot of content, and it just adds up. So if they can save money on their print ad or their TikTok feed, they will.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PJ Pereira, co-founder of AI ad firm Silverside AI, said it really comes down to scale. Every conversation he’s had with fashion brands circles around the fact that the entire marketing system was built for a world where brands produced just four big pieces of content per year. Social media and e-commerce has changed that, and now they need anywhere from 400 to 400,000 pieces; it’s too expensive for brands, especially small ones, to keep up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s no way to scale from four to 400 or 400,000 with just process tweaks,” he added. “You need a new system. People get angry. They assume this is about taking money away from artists and models. But that’s not what I’ve seen.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-diverse-models-to-ai-avatars"&gt;From “diverse” models to AI avatars&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Murray, a commercial model, understands the cost benefits of using AI models, but only to an extent.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033573" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/IMG_2343-rotated.jpeg?w=510" width="510" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;sarah murray&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Courtesy of Sarah Murray&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;She lamented that brands like Levi’s claim AI is only meant to supplement human talent, not take away.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If those [brands] ever had the opportunity to stand in line at an open casting call, they would know about the endless amounts of models, including myself, that would dream of opportunities to work with their brands,” she said. “They would never need to supplement with anything fake.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;She thinks such a shift will impact “non-traditional” — think, diverse — commercial models, such as herself. That was the main problem with the Levi’s ad. Rather than hiring diverse talent, it artificially generated it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bovell calls this “robot cultural appropriation,” or the idea that brands can just generate certain, especially diverse, identities to tell a brand story, even if the person who created the technology isn’t of that same identity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And though Pereira argues that it’s unrealistic to shoot every garment on every type of model, that hasn’t calmed the fears many diverse models have about what’s to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We already see an unprecedented use of certain terms in our contracts that we worry indicate that we are possibly signing away our rights for a brand to use our face and anything recognizable as ourselves to train their future AI systems,” Murray said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some see generating likenesses of models as a way forward in the AI era. Sara Ziff, a former model and founder of the Model Alliance, is working to pass the Fashion Workers Act, which would require brands to get a model’s clear consent and provide compensation for using their digital replicas. Mouginot said this lets models appear at several shoots on the same day and possibly generate additional income.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s “precious when a sought-after model is already traveling constantly,” he continued. But at the same time, whenever an avatar is hired, human labor is replaced. “What few players gain can mean fewer opportunities for many others.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If anything, Bovell said the bar is now higher for models looking to compete with the distinctive and the digitized. She suggested that models use their platforms to build their personal brands, differentiate themselves, and work on new revenue streams like podcasting or brand endorsements.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Start to take those opportunities to tell your unique human story,” she said. “AI will never have a unique human story.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That sort of entrepreneurial mindset is becoming table stakes across industries — from journalism to coding — as AI creates the conditions for the most self-directed learners to rise.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-room-for-another-view-nbsp"&gt;Room for another view&amp;nbsp;&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033535" height="659" src="https://techcrunch.com/wp-content/uploads/2025/08/ARTCARE-AI-mannequins-7.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Artcare AI-generated model.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Artcare&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mouginot sees a world where some platforms stop working with human models altogether, though he also believes humans share a desire for the “sensual reality of objects, for a touch of imperfection and for human connection.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many breakthrough models succeed precisely because of a distinctive trait, teeth, gaze, attitude, that is slightly imperfect by strict standards yet utterly charming,” he said. “Such nuances are hard to erode in zeros and ones.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is where startup and creative studio Artcare thrives, according to Sandrine Decorde, the firm’s CEO and co-founder. She refers to her team as “AI artisans,” creative people who use tools like Flux from Black Forest Labs to fine-tune AI-generated models that have that touch of unique humanity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of the work Decorde’s firm does today involves producing AI-generated babies and children for brands. Employing minors in the fashion industry has historically been a gray area rife with exploitation and abuse. Ethically, Decorde argues, bringing generative AI to children’s fashion makes sense, particularly when the market demand is so high.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like sewing; it’s very delicate,” she told TechCrunch, referring to creating AI-generated models. “The more time we spend on our datasets and image refinements, the better and more consistent our models are.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033501" height="602" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-01-at-2.56.07PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot from Seraphinne Vallora’s Instagram page.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Seraphinne Vallora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the work is building out a library of distinctive artifacts. Decorde noted that many AI-generated models — like the ones created by Seraphinne Vallora, the agency behind Vogue’s Guess ad — are too homogenous. Their lips are too perfect and symmetrical. Their jawlines are all the same.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Imagery needs to make an impact,” Decorde said, noting that many fashion brands like to work exclusively with certain models, a desire that has spilled over into AI-generated models. “A model embodies a fashion brand.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Pereira added that his firm combats homogeneity in AI “with intention” and warned that as more content gets made by more people who aren’t intentional, all of the output feeds back into computer models, amplifying bias.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just like you would cast for a wide range of models, you have to prompt for that,” he said. “You need to train [models] with a wide range of appearances. Because if you don’t, the AI will reflect whatever biases it was trained on.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-future-is-promised-but-uncertain-nbsp"&gt;An AI future is promised, but uncertain&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The usage of AI modeling technology in fashion is mostly still in its experimental phase, Claudia Wagner, founder of modeling booking platform Ubooker, told TechCrunch. She and her team saw the Guess ad and said it was interesting technically, but it wasn’t impactful or new.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033583" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/hm-ai-model.webp?w=544" width="544" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;H&amp;amp;M Digital model&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;H&amp;amp;M&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“It feels like another example of a brand using AI to be part of the current narrative,” she told TechCrunch. “We’re all in a phase of testing and exploring what AI can add — but the real value will come when it’s used with purpose, not just for visibility.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brands are getting visibility from using AI  — and the Guess ad is the latest example. Pereira said his firm recently tested a fully AI-generated product video on TikTok that got more than a million views with mostly negative comments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But if you look past the comments, you see that there’s a silent majority — almost 20x engagement — that vastly outnumber the criticism,” he continued. “The click-through rate was 30x the number of complaints, and the product saw a steep hike in sales.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He, like Wagner, doesn’t think AI models are going away anytime soon. If anything, the process of using AI will be integrated into the creative workflow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Some brands feel good about using fully artificial models,” Pereira said. “Others prefer starting with real people and licensing their likeness to build synthetic shoots. And some brands simply don’t want to do it — they worry their audiences won’t accept it.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wagner said what is becoming evident is that human talent remains central, especially when authenticity and identity are part of a brand’s story. That’s especially true for luxury heritage brands, which are usually slow to adopt new technologies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though Decorde noted many high-fashion brands are quietly experimenting with AI, Mouginot said many are still trying to define their AI policies and are avoiding fully AI-generated people at the moment. It’s one reason why Vogue’s inclusion of an AI model was such a shock. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bovell pondered if the ad was Vogue’s way of testing how the world would react to merging high fashion with AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far the reaction hasn’t been great. It’s unclear if the magazine thinks it ride out the backlash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What Vogue does matters,” Odell said. “If Vogue ends up doing editorials with AI models, I think that’s going to make it okay. In the same way the industry was really resistant to Kim Kardashian and then Vogue featured her. Then it was okay.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sarah Murray recalls the first time she saw an artificial model in fashion: It was 2023, and a beautiful young woman of color donned a Levi’s denim overall dress. Murray, a commercial model herself, said it made her feel sad and exhausted.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iconic denim company had teamed up with the AI studio Lalaland.ai to create “diverse” digital fashion models for more inclusive ads. For an industry that has failed for years to employ diverse human models, the backlash was swift, with New York Magazine calling the decision “artificial diversity.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Murray told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two years later, her worries have compounded. Brands continue to experiment with AI-generated models, to the consternation of many fashion lovers. The latest uproar came after Vogue’s July print edition featured a Guess ad with a typical model for the brand: thin yet voluptuous, glossy blond tresses, pouty rose lips. She exemplified North American beauty standards, but there was one problem — she was AI generated.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The internet buzzed for days, in large part because the AI-generated beauty showed up in Vogue, the fashion bible that dictates what is and is not acceptable in the industry. The AI-generated model was featured in an advertisement, &lt;em&gt;not&lt;/em&gt; a Vogue editorial spread. And Vogue told TechCrunch the ad met its advertising standards.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To many, an ad versus an editorial is a distinction without a difference.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke to fashion models, experts, and technologists to get a sense of where the industry is headed now that Vogue seems to have put a stamp of approval on technology that’s poised to dramatically change the fashion industry.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They said the Guess ad drama highlights questions arising within creative industries being touched by AI’s silicon fingers: When high-quality creative work can be done by AI in a fraction of the time and cost, what’s the point of humans? And in the world of fashion, what happens to the humans — the models, photographers, stylists, and set designers — performing those jobs?&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-it-s-just-so-much-cheaper"&gt;“It’s just so much cheaper”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Sinead Bovell, a model and founder of the WAYE organization who wrote about CGI models for Vogue five years ago, told TechCrunch that “e-commerce models” are most under threat of automation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;E-commerce models are the ones who pose for advertisements or display clothes and accessories for online shoppers. Compared to high-fashion models, whose striking, often unattainable looks are featured in editorial spreads and on runways, they’re more realistic and relatable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“E-commerce is where most models make their bread and butter,” Bovell said. “It’s not necessarily the path to model fame or model prestige, but it is the path for financial security.”&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033586" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/PHOTO-2025-08-01-15-05-08.jpeg?w=584" width="584" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;sinead bovell, founder &amp;amp; model &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sinead Bovell&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That fact is running in direct contrast to the pressure many brands feel to automate such shoots. Paul Mouginot, an art technologist who has worked with luxury brands, said it’s simply expensive to work with live models, especially when it comes to photographing them in countless garments, shoes, and accessories.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI now lets you start with a flat-lay product shoot, place it on a photorealistic virtual model, and even position that model in a coherent setting, producing images that look like genuine fashion editorials,” he told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brands, in some ways, have been doing this for a while, he said. Mouginot, who is French, cited the French retailer Veepee as an example of a company that has used virtual mannequins to sell clothes since at least 2013. Other notable brands like H&amp;amp;M, Mango, and Calvin Klein have also resorted to AI models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amy Odell, a fashion writer and author of a recently published biography on Gwyneth Paltrow, put it more simply: “It’s just so much cheaper for [brands] to use AI models now. Brands need a lot of content, and it just adds up. So if they can save money on their print ad or their TikTok feed, they will.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PJ Pereira, co-founder of AI ad firm Silverside AI, said it really comes down to scale. Every conversation he’s had with fashion brands circles around the fact that the entire marketing system was built for a world where brands produced just four big pieces of content per year. Social media and e-commerce has changed that, and now they need anywhere from 400 to 400,000 pieces; it’s too expensive for brands, especially small ones, to keep up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s no way to scale from four to 400 or 400,000 with just process tweaks,” he added. “You need a new system. People get angry. They assume this is about taking money away from artists and models. But that’s not what I’ve seen.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-diverse-models-to-ai-avatars"&gt;From “diverse” models to AI avatars&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Murray, a commercial model, understands the cost benefits of using AI models, but only to an extent.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033573" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/IMG_2343-rotated.jpeg?w=510" width="510" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;sarah murray&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Courtesy of Sarah Murray&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;She lamented that brands like Levi’s claim AI is only meant to supplement human talent, not take away.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If those [brands] ever had the opportunity to stand in line at an open casting call, they would know about the endless amounts of models, including myself, that would dream of opportunities to work with their brands,” she said. “They would never need to supplement with anything fake.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;She thinks such a shift will impact “non-traditional” — think, diverse — commercial models, such as herself. That was the main problem with the Levi’s ad. Rather than hiring diverse talent, it artificially generated it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bovell calls this “robot cultural appropriation,” or the idea that brands can just generate certain, especially diverse, identities to tell a brand story, even if the person who created the technology isn’t of that same identity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And though Pereira argues that it’s unrealistic to shoot every garment on every type of model, that hasn’t calmed the fears many diverse models have about what’s to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We already see an unprecedented use of certain terms in our contracts that we worry indicate that we are possibly signing away our rights for a brand to use our face and anything recognizable as ourselves to train their future AI systems,” Murray said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some see generating likenesses of models as a way forward in the AI era. Sara Ziff, a former model and founder of the Model Alliance, is working to pass the Fashion Workers Act, which would require brands to get a model’s clear consent and provide compensation for using their digital replicas. Mouginot said this lets models appear at several shoots on the same day and possibly generate additional income.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s “precious when a sought-after model is already traveling constantly,” he continued. But at the same time, whenever an avatar is hired, human labor is replaced. “What few players gain can mean fewer opportunities for many others.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If anything, Bovell said the bar is now higher for models looking to compete with the distinctive and the digitized. She suggested that models use their platforms to build their personal brands, differentiate themselves, and work on new revenue streams like podcasting or brand endorsements.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Start to take those opportunities to tell your unique human story,” she said. “AI will never have a unique human story.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That sort of entrepreneurial mindset is becoming table stakes across industries — from journalism to coding — as AI creates the conditions for the most self-directed learners to rise.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-room-for-another-view-nbsp"&gt;Room for another view&amp;nbsp;&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033535" height="659" src="https://techcrunch.com/wp-content/uploads/2025/08/ARTCARE-AI-mannequins-7.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Artcare AI-generated model.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Artcare&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mouginot sees a world where some platforms stop working with human models altogether, though he also believes humans share a desire for the “sensual reality of objects, for a touch of imperfection and for human connection.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many breakthrough models succeed precisely because of a distinctive trait, teeth, gaze, attitude, that is slightly imperfect by strict standards yet utterly charming,” he said. “Such nuances are hard to erode in zeros and ones.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is where startup and creative studio Artcare thrives, according to Sandrine Decorde, the firm’s CEO and co-founder. She refers to her team as “AI artisans,” creative people who use tools like Flux from Black Forest Labs to fine-tune AI-generated models that have that touch of unique humanity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of the work Decorde’s firm does today involves producing AI-generated babies and children for brands. Employing minors in the fashion industry has historically been a gray area rife with exploitation and abuse. Ethically, Decorde argues, bringing generative AI to children’s fashion makes sense, particularly when the market demand is so high.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like sewing; it’s very delicate,” she told TechCrunch, referring to creating AI-generated models. “The more time we spend on our datasets and image refinements, the better and more consistent our models are.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033501" height="602" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-01-at-2.56.07PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot from Seraphinne Vallora’s Instagram page.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Seraphinne Vallora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the work is building out a library of distinctive artifacts. Decorde noted that many AI-generated models — like the ones created by Seraphinne Vallora, the agency behind Vogue’s Guess ad — are too homogenous. Their lips are too perfect and symmetrical. Their jawlines are all the same.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Imagery needs to make an impact,” Decorde said, noting that many fashion brands like to work exclusively with certain models, a desire that has spilled over into AI-generated models. “A model embodies a fashion brand.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Pereira added that his firm combats homogeneity in AI “with intention” and warned that as more content gets made by more people who aren’t intentional, all of the output feeds back into computer models, amplifying bias.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just like you would cast for a wide range of models, you have to prompt for that,” he said. “You need to train [models] with a wide range of appearances. Because if you don’t, the AI will reflect whatever biases it was trained on.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-future-is-promised-but-uncertain-nbsp"&gt;An AI future is promised, but uncertain&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The usage of AI modeling technology in fashion is mostly still in its experimental phase, Claudia Wagner, founder of modeling booking platform Ubooker, told TechCrunch. She and her team saw the Guess ad and said it was interesting technically, but it wasn’t impactful or new.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3033583" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/hm-ai-model.webp?w=544" width="544" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;H&amp;amp;M Digital model&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;H&amp;amp;M&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“It feels like another example of a brand using AI to be part of the current narrative,” she told TechCrunch. “We’re all in a phase of testing and exploring what AI can add — but the real value will come when it’s used with purpose, not just for visibility.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brands are getting visibility from using AI  — and the Guess ad is the latest example. Pereira said his firm recently tested a fully AI-generated product video on TikTok that got more than a million views with mostly negative comments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But if you look past the comments, you see that there’s a silent majority — almost 20x engagement — that vastly outnumber the criticism,” he continued. “The click-through rate was 30x the number of complaints, and the product saw a steep hike in sales.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He, like Wagner, doesn’t think AI models are going away anytime soon. If anything, the process of using AI will be integrated into the creative workflow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Some brands feel good about using fully artificial models,” Pereira said. “Others prefer starting with real people and licensing their likeness to build synthetic shoots. And some brands simply don’t want to do it — they worry their audiences won’t accept it.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wagner said what is becoming evident is that human talent remains central, especially when authenticity and identity are part of a brand’s story. That’s especially true for luxury heritage brands, which are usually slow to adopt new technologies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though Decorde noted many high-fashion brands are quietly experimenting with AI, Mouginot said many are still trying to define their AI policies and are avoiding fully AI-generated people at the moment. It’s one reason why Vogue’s inclusion of an AI model was such a shock. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bovell pondered if the ad was Vogue’s way of testing how the world would react to merging high fashion with AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far the reaction hasn’t been great. It’s unclear if the magazine thinks it ride out the backlash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What Vogue does matters,” Odell said. “If Vogue ends up doing editorials with AI models, I think that’s going to make it okay. In the same way the industry was really resistant to Kim Kardashian and then Vogue featured her. Then it was okay.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/</guid><pubDate>Sun, 03 Aug 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Inside OpenAI’s quest to make AI do anything for you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Shortly after Hunter Lightman joined OpenAI as a researcher in 2022, he watched his colleagues launch ChatGPT, one of the fastest-growing products ever. Meanwhile, Lightman quietly worked on a team teaching OpenAI’s models to solve high school math competitions.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today that team, known as MathGen, is considered instrumental to OpenAI’s industry-leading effort to create AI reasoning models: the core technology behind AI agents that can do tasks on a computer like a human would.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We were trying to make the models better at mathematical reasoning, which at the time they weren’t very good at,” Lightman told TechCrunch, describing MathGen’s early work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s models are far from perfect today — the company’s latest AI systems still hallucinate and its agents struggle with complex tasks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But its state-of-the-art models have improved significantly on mathematical reasoning. One of OpenAI’s models recently won a gold medal at the International Math Olympiad, a math competition for the world’s brightest high school students. OpenAI believes these reasoning capabilities will translate to other subjects, and ultimately power general-purpose agents that the company has always dreamed of building.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT was a happy accident — a lowkey research preview turned viral consumer business — but OpenAI’s agents are the product of a years-long, deliberate effort within the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Eventually, you’ll just ask the computer for what you need and it’ll do all of these tasks for you,” said OpenAI CEO Sam Altman at the company’s first developer conference in 2023. “These capabilities are often talked about in the AI field as agents. The upsides of this are going to be tremendous.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="OpenAI CEO Sam Altman speaks during the OpenAI DevDay event on November 06, 2023 in San Francisco, California." class="wp-image-2625318" height="382" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1778704897.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;OpenAI CEO Sam Altman speaks during the OpenAI DevDay event on November 06, 2023 in San Francisco, California.(Photo by Justin Sullivan/Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Justin Sullivan / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whether agents will meet Altman’s vision remains to be seen, but OpenAI shocked the world with the release of its first AI reasoning model, o1, in the fall of 2024. Less than a year later, the 21 foundational researchers behind that breakthrough are the most highly sought-after talent in Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mark Zuckerberg recruited five of the o1 researchers to work on Meta’s new superintelligence-focused unit, offering some compensation packages north of $100 million. One of them, Shengjia Zhao, was recently named chief scientist of Meta Superintelligence Labs.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-reinforcement-learning-renaissance"&gt;The reinforcement learning renaissance&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The rise of OpenAI’s reasoning models and agents are tied to a machine learning training technique known as reinforcement learning (RL). RL provides feedback to an AI model on whether its choices were correct or not in simulated environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;RL has been used for decades. For instance, in 2016, about a year after OpenAI was founded in 2015, an AI system created by Google DeepMind using RL, AlphaGo, gained global attention after beating a world champion in the board game, Go.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3033346" height="436" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-515358462.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;South Korean professional Go player Lee Se-Dol (R) prepares for his fourth match against Google’s artificial intelligence program, AlphaGo, during the Google DeepMind Challenge Match on March 13, 2016 in Seoul, South Korea. Lee Se-dol played a five-game match against a computer program developed by a Google, AlphaGo.  (Photo by Google via Getty Images)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Around that time, one of OpenAI’s first employees, Andrej Karpathy, began pondering how to leverage RL to create an AI agent that could use a computer. But it would take years for OpenAI to develop the necessary models and training techniques.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By 2018, OpenAI pioneered its first large language model in the GPT series, pretrained on massive amounts of internet data and a large clusters of GPUs. GPT models excelled at text processing, eventually leading to ChatGPT, but struggled with basic math.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It took until 2023 for OpenAI to achieve a breakthrough, initially dubbed “Q*” and then “Strawberry,” by combining LLMs, RL, and a technique called test-time computation. The latter gave the models extra time and computing power to plan and work through problems, verifying its steps, before providing an answer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This allowed OpenAI to introduce a new approach called “chain-of-thought” (CoT), which improved AI’s performance on math questions the models hadn’t seen before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I could see the model starting to reason,” said El Kishky. “It would notice mistakes and backtrack, it would get frustrated. It really felt like reading the thoughts of a person.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though individually these techniques weren’t novel, OpenAI uniquely combined them to create Strawberry, which directly led to the development of o1. OpenAI quickly identified that the planning and fact checking abilities of AI reasoning models could be useful to power AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had solved a problem that I had been banging my head against for a couple of years,” said Lightman. “It was one of the most exciting moments of my research career.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-scaling-reasoning"&gt;Scaling reasoning&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With AI reasoning models, OpenAI determined it had two new axes that would allow it to improve AI models: using more computational power during the post-training of AI models, and giving AI models more time and processing power while answering a question.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“OpenAI, as a company, thinks a lot about not just the way things are, but the way things are going to scale,” said Lightman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shortly after the 2023 Strawberry breakthrough, OpenAI spun up an “Agents” team led by OpenAI researcher Daniel Selsam to make further progress on this new paradigm, two sources told TechCrunch. Although the team was called “Agents,”&amp;nbsp; OpenAI didn’t initially differentiate between reasoning models and agents as we think of them today. The company just wanted to make AI systems capable of completing complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventually, the work of Selsam’s Agents team became part of a larger project to develop the o1 reasoning model, with leaders including OpenAI co-founder Ilya Sutskever, chief research officer Mark Chen, and chief scientist Jakub Pachocki.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Ilya Sutskever, Russian Israeli-Canadian computer scientist and co-founder and Chief Scientist of OpenAI." class="wp-image-2797714" height="453" src="https://techcrunch.com/wp-content/uploads/2024/06/019A7E29-3482-4F68-9A29-624BA22F0334.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Ilya Sutskever, Russian Israeli-Canadian computer scientist and co-founder and Chief Scientist of OpenAI, speaks at Tel Aviv University in Tel Aviv on June 5, 2023. (Photo by JACK GUEZ / AFP)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI would have to divert precious resources — mainly talent and GPUs — to create o1. Throughout OpenAI’s history, researchers have had to negotiate with company leaders to obtain resources; demonstrating breakthroughs was a surefire way to secure them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the core components of OpenAI is that everything in research is bottom up,” said Lightman. “When we showed the evidence [for o1], the company was like, ‘This makes sense, let’s push on it.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some former employees say that the startup’s mission to develop AGI was the key factor in achieving breakthroughs around AI reasoning models. By focusing on developing the smartest-possible AI models, rather than products, OpenAI was able to prioritize o1 above other efforts.&amp;nbsp;That type of large investment in ideas wasn’t always possible at competing AI labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The decision to try new training methods proved prescient. By late 2024, several leading AI labs started seeing diminishing returns on models created through traditional pretraining scaling. Today, much of the AI field’s momentum comes from advances in reasoning models.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-does-it-mean-for-an-ai-to-reason"&gt;&lt;strong&gt;What does it mean for an AI to “reason?”&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways, the goal of AI research is to recreate human intelligence with computers. Since the launch of o1, ChatGPT’s UX has been filled with more human-sounding features such as “thinking” and “reasoning.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked whether OpenAI’s models were truly reasoning, El Kishky hedged, saying he thinks about the concept in terms of computer science. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re teaching the model how to efficiently expend compute to get an answer. So if you define it that way, yes, it is reasoning,” said El Kishky.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lightman takes the approach of focusing on the model’s results and not as much on the means or their relation to human brains.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="The OpenAI logo on screen at their developer day stage." class="wp-image-2625161" height="454" src="https://techcrunch.com/wp-content/uploads/2023/11/img_5619.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The OpenAI logo on screen at their developer day stage. (Credit: Devin Coldeway)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Devin Coldewey&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“If the model is doing hard things, then it is doing whatever necessary approximation of reasoning it needs in order to do that,” said Lightman. “We can call it reasoning, because it looks like these reasoning traces, but it’s all just a proxy for trying to make AI tools that are really powerful and useful to a lot of people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s researchers note people may disagree with their nomenclature or definitions of reasoning — and surely, critics have emerged — but they argue it’s less important than the capabilities of their models. Other AI researchers tend to agree.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Lambert, an AI researcher with the non-profit AI2, compares AI reasoning modes to airplanes in a blog post. Both, he says, are manmade systems inspired by nature — human reasoning and bird flight, respectively — but they operate through entirely different mechanisms. That doesn’t make them any less useful, or any less capable of achieving similar outcomes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A group of AI researchers from OpenAI, Anthropic, and Google DeepMind agreed in a recent position paper that AI reasoning models are not well understood today, and more research is needed. It may be too early to confidently claim what exactly is going on inside them.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-next-frontier-ai-agents-for-subjective-tasks"&gt;&lt;strong&gt;The next frontier: AI agents for subjective tasks&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The AI agents on the market today work best for well-defined, verifiable domains such as coding. OpenAI’s Codex agent aims to help software engineers offload simple coding tasks. Meanwhile, Anthropic’s models have become particularly popular in AI coding tools like Cursor and Claude Code — these are some of the first AI agents that people are willing to pay up for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, general purpose AI agents like OpenAI’s ChatGPT Agent and Perplexity’s Comet struggle with many of the complex, subjective tasks people want to automate. When trying to use these tools for online shopping or finding a long-term parking spot, I’ve found the agents take longer than I’d like and make silly mistakes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agents are, of course, early systems that will undoubtedly improve. But researchers must first figure out how to better train the underlying models to complete tasks that are more subjective.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3033358" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2197821080.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AI applications (Photo by Jonathan Raa/NurPhoto via Getty Images)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Like many problems in machine learning, it’s a data problem,” said Lightman, when asked about the limitations of agents on subjective tasks. “Some of the research I’m really excited about right now is figuring out how to train on less verifiable tasks. We have some leads on how to do these things.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, an OpenAI researcher who helped create the IMO model and o1, told TechCrunch that OpenAI has new general-purpose RL techniques which allow them to teach AI models skills that aren’t easily verified. This was how the company built the model which achieved a gold medal at IMO, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s IMO model was a newer AI system that spawns multiple agents, which then simultaneously explore several ideas, and then choose the best possible answer. These types of AI models are becoming more popular; Google and xAI have recently released state-of-the-art models using this technique.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think these models will become more capable at math, and I think they’ll get more capable in other reasoning areas as well,” said Brown. “The progress has been incredibly fast. I don’t see any reason to think it will slow down.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These techniques may help OpenAI’s models become more performant, gains that could show up in the company’s upcoming GPT-5 model. OpenAI hopes to assert its dominance over competitors with the launch of GPT-5, ideally offering the best AI model to power agents for developers and consumers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company also wants to make its products simpler to use. El Kishky says OpenAI wants to develop AI agents that intuitively understand what users want, without requiring them to select specific settings. He says OpenAI aims to build AI systems that understand when to call up certain tools, and how long to reason for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These ideas paint a picture of an ultimate version of ChatGPT: an agent that can do anything on the internet for you, and understand how you want it to be done. That’s a much different product than what ChatGPT is today, but the company’s research is squarely headed in this direction.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While OpenAI undoubtedly led the AI industry a few years ago, the company now faces a tranche of worthy opponents. The question is no longer just whether OpenAI can deliver its agentic future, but can the company do so before Google, Anthropic, xAI, or Meta beat them to it?&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Shortly after Hunter Lightman joined OpenAI as a researcher in 2022, he watched his colleagues launch ChatGPT, one of the fastest-growing products ever. Meanwhile, Lightman quietly worked on a team teaching OpenAI’s models to solve high school math competitions.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today that team, known as MathGen, is considered instrumental to OpenAI’s industry-leading effort to create AI reasoning models: the core technology behind AI agents that can do tasks on a computer like a human would.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We were trying to make the models better at mathematical reasoning, which at the time they weren’t very good at,” Lightman told TechCrunch, describing MathGen’s early work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s models are far from perfect today — the company’s latest AI systems still hallucinate and its agents struggle with complex tasks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But its state-of-the-art models have improved significantly on mathematical reasoning. One of OpenAI’s models recently won a gold medal at the International Math Olympiad, a math competition for the world’s brightest high school students. OpenAI believes these reasoning capabilities will translate to other subjects, and ultimately power general-purpose agents that the company has always dreamed of building.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT was a happy accident — a lowkey research preview turned viral consumer business — but OpenAI’s agents are the product of a years-long, deliberate effort within the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Eventually, you’ll just ask the computer for what you need and it’ll do all of these tasks for you,” said OpenAI CEO Sam Altman at the company’s first developer conference in 2023. “These capabilities are often talked about in the AI field as agents. The upsides of this are going to be tremendous.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="OpenAI CEO Sam Altman speaks during the OpenAI DevDay event on November 06, 2023 in San Francisco, California." class="wp-image-2625318" height="382" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1778704897.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;OpenAI CEO Sam Altman speaks during the OpenAI DevDay event on November 06, 2023 in San Francisco, California.(Photo by Justin Sullivan/Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Justin Sullivan / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whether agents will meet Altman’s vision remains to be seen, but OpenAI shocked the world with the release of its first AI reasoning model, o1, in the fall of 2024. Less than a year later, the 21 foundational researchers behind that breakthrough are the most highly sought-after talent in Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mark Zuckerberg recruited five of the o1 researchers to work on Meta’s new superintelligence-focused unit, offering some compensation packages north of $100 million. One of them, Shengjia Zhao, was recently named chief scientist of Meta Superintelligence Labs.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-reinforcement-learning-renaissance"&gt;The reinforcement learning renaissance&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The rise of OpenAI’s reasoning models and agents are tied to a machine learning training technique known as reinforcement learning (RL). RL provides feedback to an AI model on whether its choices were correct or not in simulated environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;RL has been used for decades. For instance, in 2016, about a year after OpenAI was founded in 2015, an AI system created by Google DeepMind using RL, AlphaGo, gained global attention after beating a world champion in the board game, Go.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3033346" height="436" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-515358462.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;South Korean professional Go player Lee Se-Dol (R) prepares for his fourth match against Google’s artificial intelligence program, AlphaGo, during the Google DeepMind Challenge Match on March 13, 2016 in Seoul, South Korea. Lee Se-dol played a five-game match against a computer program developed by a Google, AlphaGo.  (Photo by Google via Getty Images)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Around that time, one of OpenAI’s first employees, Andrej Karpathy, began pondering how to leverage RL to create an AI agent that could use a computer. But it would take years for OpenAI to develop the necessary models and training techniques.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By 2018, OpenAI pioneered its first large language model in the GPT series, pretrained on massive amounts of internet data and a large clusters of GPUs. GPT models excelled at text processing, eventually leading to ChatGPT, but struggled with basic math.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It took until 2023 for OpenAI to achieve a breakthrough, initially dubbed “Q*” and then “Strawberry,” by combining LLMs, RL, and a technique called test-time computation. The latter gave the models extra time and computing power to plan and work through problems, verifying its steps, before providing an answer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This allowed OpenAI to introduce a new approach called “chain-of-thought” (CoT), which improved AI’s performance on math questions the models hadn’t seen before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I could see the model starting to reason,” said El Kishky. “It would notice mistakes and backtrack, it would get frustrated. It really felt like reading the thoughts of a person.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though individually these techniques weren’t novel, OpenAI uniquely combined them to create Strawberry, which directly led to the development of o1. OpenAI quickly identified that the planning and fact checking abilities of AI reasoning models could be useful to power AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had solved a problem that I had been banging my head against for a couple of years,” said Lightman. “It was one of the most exciting moments of my research career.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-scaling-reasoning"&gt;Scaling reasoning&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With AI reasoning models, OpenAI determined it had two new axes that would allow it to improve AI models: using more computational power during the post-training of AI models, and giving AI models more time and processing power while answering a question.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“OpenAI, as a company, thinks a lot about not just the way things are, but the way things are going to scale,” said Lightman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shortly after the 2023 Strawberry breakthrough, OpenAI spun up an “Agents” team led by OpenAI researcher Daniel Selsam to make further progress on this new paradigm, two sources told TechCrunch. Although the team was called “Agents,”&amp;nbsp; OpenAI didn’t initially differentiate between reasoning models and agents as we think of them today. The company just wanted to make AI systems capable of completing complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventually, the work of Selsam’s Agents team became part of a larger project to develop the o1 reasoning model, with leaders including OpenAI co-founder Ilya Sutskever, chief research officer Mark Chen, and chief scientist Jakub Pachocki.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Ilya Sutskever, Russian Israeli-Canadian computer scientist and co-founder and Chief Scientist of OpenAI." class="wp-image-2797714" height="453" src="https://techcrunch.com/wp-content/uploads/2024/06/019A7E29-3482-4F68-9A29-624BA22F0334.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Ilya Sutskever, Russian Israeli-Canadian computer scientist and co-founder and Chief Scientist of OpenAI, speaks at Tel Aviv University in Tel Aviv on June 5, 2023. (Photo by JACK GUEZ / AFP)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI would have to divert precious resources — mainly talent and GPUs — to create o1. Throughout OpenAI’s history, researchers have had to negotiate with company leaders to obtain resources; demonstrating breakthroughs was a surefire way to secure them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the core components of OpenAI is that everything in research is bottom up,” said Lightman. “When we showed the evidence [for o1], the company was like, ‘This makes sense, let’s push on it.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some former employees say that the startup’s mission to develop AGI was the key factor in achieving breakthroughs around AI reasoning models. By focusing on developing the smartest-possible AI models, rather than products, OpenAI was able to prioritize o1 above other efforts.&amp;nbsp;That type of large investment in ideas wasn’t always possible at competing AI labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The decision to try new training methods proved prescient. By late 2024, several leading AI labs started seeing diminishing returns on models created through traditional pretraining scaling. Today, much of the AI field’s momentum comes from advances in reasoning models.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-does-it-mean-for-an-ai-to-reason"&gt;&lt;strong&gt;What does it mean for an AI to “reason?”&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways, the goal of AI research is to recreate human intelligence with computers. Since the launch of o1, ChatGPT’s UX has been filled with more human-sounding features such as “thinking” and “reasoning.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked whether OpenAI’s models were truly reasoning, El Kishky hedged, saying he thinks about the concept in terms of computer science. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re teaching the model how to efficiently expend compute to get an answer. So if you define it that way, yes, it is reasoning,” said El Kishky.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lightman takes the approach of focusing on the model’s results and not as much on the means or their relation to human brains.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="The OpenAI logo on screen at their developer day stage." class="wp-image-2625161" height="454" src="https://techcrunch.com/wp-content/uploads/2023/11/img_5619.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The OpenAI logo on screen at their developer day stage. (Credit: Devin Coldeway)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Devin Coldewey&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“If the model is doing hard things, then it is doing whatever necessary approximation of reasoning it needs in order to do that,” said Lightman. “We can call it reasoning, because it looks like these reasoning traces, but it’s all just a proxy for trying to make AI tools that are really powerful and useful to a lot of people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s researchers note people may disagree with their nomenclature or definitions of reasoning — and surely, critics have emerged — but they argue it’s less important than the capabilities of their models. Other AI researchers tend to agree.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Lambert, an AI researcher with the non-profit AI2, compares AI reasoning modes to airplanes in a blog post. Both, he says, are manmade systems inspired by nature — human reasoning and bird flight, respectively — but they operate through entirely different mechanisms. That doesn’t make them any less useful, or any less capable of achieving similar outcomes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A group of AI researchers from OpenAI, Anthropic, and Google DeepMind agreed in a recent position paper that AI reasoning models are not well understood today, and more research is needed. It may be too early to confidently claim what exactly is going on inside them.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-next-frontier-ai-agents-for-subjective-tasks"&gt;&lt;strong&gt;The next frontier: AI agents for subjective tasks&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The AI agents on the market today work best for well-defined, verifiable domains such as coding. OpenAI’s Codex agent aims to help software engineers offload simple coding tasks. Meanwhile, Anthropic’s models have become particularly popular in AI coding tools like Cursor and Claude Code — these are some of the first AI agents that people are willing to pay up for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, general purpose AI agents like OpenAI’s ChatGPT Agent and Perplexity’s Comet struggle with many of the complex, subjective tasks people want to automate. When trying to use these tools for online shopping or finding a long-term parking spot, I’ve found the agents take longer than I’d like and make silly mistakes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agents are, of course, early systems that will undoubtedly improve. But researchers must first figure out how to better train the underlying models to complete tasks that are more subjective.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3033358" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2197821080.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AI applications (Photo by Jonathan Raa/NurPhoto via Getty Images)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Like many problems in machine learning, it’s a data problem,” said Lightman, when asked about the limitations of agents on subjective tasks. “Some of the research I’m really excited about right now is figuring out how to train on less verifiable tasks. We have some leads on how to do these things.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, an OpenAI researcher who helped create the IMO model and o1, told TechCrunch that OpenAI has new general-purpose RL techniques which allow them to teach AI models skills that aren’t easily verified. This was how the company built the model which achieved a gold medal at IMO, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s IMO model was a newer AI system that spawns multiple agents, which then simultaneously explore several ideas, and then choose the best possible answer. These types of AI models are becoming more popular; Google and xAI have recently released state-of-the-art models using this technique.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think these models will become more capable at math, and I think they’ll get more capable in other reasoning areas as well,” said Brown. “The progress has been incredibly fast. I don’t see any reason to think it will slow down.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These techniques may help OpenAI’s models become more performant, gains that could show up in the company’s upcoming GPT-5 model. OpenAI hopes to assert its dominance over competitors with the launch of GPT-5, ideally offering the best AI model to power agents for developers and consumers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company also wants to make its products simpler to use. El Kishky says OpenAI wants to develop AI agents that intuitively understand what users want, without requiring them to select specific settings. He says OpenAI aims to build AI systems that understand when to call up certain tools, and how long to reason for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These ideas paint a picture of an ultimate version of ChatGPT: an agent that can do anything on the internet for you, and understand how you want it to be done. That’s a much different product than what ChatGPT is today, but the company’s research is squarely headed in this direction.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While OpenAI undoubtedly led the AI industry a few years ago, the company now faces a tranche of worthy opponents. The question is no longer just whether OpenAI can deliver its agentic future, but can the company do so before Google, Anthropic, xAI, or Meta beat them to it?&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/</guid><pubDate>Sun, 03 Aug 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Why the AI era is forcing a redesign of the entire compute backbone (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/why-the-ai-era-is-forcing-a-redesign-of-the-entire-compute-backbone/</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;span class="ARTICLELISTING__LABEL"&gt;&lt;span class="ARTICLE-TYPE"&gt;GUEST:&lt;/span&gt;&lt;/span&gt; The past few decades have seen almost unimaginable advances in compute performance and efficiency, enabled by Moore’s Law and underpinned by scale-out commodity hardware and loosely coupled software. This architecture has delivered online services to billions globally and put virtually all of human knowledge at our fingertips. But the next computing revolution will demand much&amp;#160;[&amp;#8230;]
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;span class="ARTICLELISTING__LABEL"&gt;&lt;span class="ARTICLE-TYPE"&gt;GUEST:&lt;/span&gt;&lt;/span&gt; The past few decades have seen almost unimaginable advances in compute performance and efficiency, enabled by Moore’s Law and underpinned by scale-out commodity hardware and loosely coupled software. This architecture has delivered online services to billions globally and put virtually all of human knowledge at our fingertips. But the next computing revolution will demand much&amp;#160;[&amp;#8230;]
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/why-the-ai-era-is-forcing-a-redesign-of-the-entire-compute-backbone/</guid><pubDate>Sun, 03 Aug 2025 18:05:00 +0000</pubDate></item></channel></rss>