<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 10 Sep 2025 18:29:34 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Google’s former security leads raise $13M to fight email threats before they reach you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/googles-former-security-leads-raise-13m-to-fight-email-threats-before-they-reach-you/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI is increasingly helping hackers to launch mass-scale email attacks, former Google security leaders have joined forces to build autonomous AI agents that aim to stop phishing, malware, and business email compromise threats before they ever reach user inboxes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the mission behind AegisAI, a new email security startup that has just emerged from stealth with $13 million in seed funding co-led by Accel and Foundation Capital.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More than 90% of successful cyberattacks begin with a phishing email, per U.S. federal cybersecurity agency CISA. A recent CrowdStrike study (PDF) also found that phishing messages generated by large language models (LLMs) had a 54% click-through rate in 2024, far higher than the 12% rate for human-written emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AegisAI aims to counter this growing threat with its suite of autonomous AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded by former Google Safe Browsing and reCAPTCHA executives Cy Khormaee and Ryan Luo, the startup offers an orchestrated network of real-time AI agents that inspect, analyze, and neutralize email threats autonomously, without relying on any specific set of rules. This approach challenges typical email security platforms that rely on static rules and often require extensive user training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The sum of all evil is a PDF attachment in an email. That’s always where all the attacks started, and so I really wanted to solve this problem,” Khormaee said in an exclusive interview with TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo of AegisAI co-founders Ryan Luo (Left) and Cy Khormaee (Right)" class="wp-image-3044483" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/09/aegisai-co-founders_d8bd27.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AegisAI co-founders Ryan Luo (Left) and Cy Khormaee (Right)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Khormaee was head of product and director of product management at Google for over five years until July 2023. During that time, he led the security team responsible for protecting Google, its four billion users, and four million websites from phishing, malware, and fraud, using products like Safe Browsing, reCAPTCHA, and Web Risk. It was also during this time that he first met Luo, who had spent almost a decade at Google and was part of the Safe Browsing team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google gave Khormaee firsthand experience in building phishing detection technologies, a deep understanding of security from the company’s perspective, and how to develop and scale security businesses quickly, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before Google, Khormaee founded the sales intelligence platform Contastic, which was acquired by SugarCRM in 2016. He later served as VP of product management at Attentive for over a year and a half until November 2024, before starting AegisAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AegisAI has built reasoning agents, each of which is a custom-built LLM tuned to a specific threat. Once the orchestrating agent recognizes a threat or potential threat, it calls other agents in the network, which Khormaee refers to as “buddies.” These agents then run the analysis, reason with each other, and respond to the orchestrating agent with a verdict.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The agents perform real-time analysis of every message component, including links, attachments, metadata, QR codes, and behavioral patterns.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a screenshot showing the AegisAI dashboard, showing the number of users and malicious emails blocked." class="wp-image-3044486" height="1250" src="https://techcrunch.com/wp-content/uploads/2025/09/aegisai_executive_overview_dashboard.jpg" width="1596" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AegisAI dashboard&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;AegisAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“What we know from building these tools at Google is what all the things are about an email you need to analyze? What are all the data sources? What are all the techniques for spotting invasion, and all the nasty stuff adversaries do that we’ve seen over 10 years of playing chess with these adversaries?” said Khormaee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AegisAI has currently built over 10 agents for this work, Khormaee told TechCrunch that there could be 50 to 100 agents over time as adversaries become smarter and try to fool the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I fully believe that in two years, adversaries will understand what we’re doing. They’ll retool and attack what we’re doing, and then we’ll need to build more agents to stay ahead of them,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike a typical email security platform that uses a rules-based approach, these AI agents spot a bunch of attacks and self-tune themselves for every possible variant of those attacks in real-time, said Khormaee. The startup has developed multiple AI models tailored to various threats and specific industries, including those in venture capital and financial services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside quickly detecting threats, AegisAI’s agents help reduce false positives by up to 90% compared to traditional solutions, the startup claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It takes “no more than five minutes” for customers to install AegisAI’s system on a Google Workspace or Microsoft 365 email account via an API, per Khormaee. Once set up, the startup will send a report in a couple of days with the details on what the system found in the environment, including false positives and false negatives. It will then run in read-only mode for a week and then activate quarantine.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s so hard without this technology to solve this very heterogeneous problem in email,” said Khormaee.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup, with offices in San Francisco and New York, is currently running a pilot with customers in the U.S. and Europe and has already added three paying customers, including data privacy compliance software Lokker and crypto payment platform Mesh Connect. The startup currently has a team of six members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh investment, Khormaee said the startup plans to expand its technical expertise and build a robust go-to-market infrastructure.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI is increasingly helping hackers to launch mass-scale email attacks, former Google security leaders have joined forces to build autonomous AI agents that aim to stop phishing, malware, and business email compromise threats before they ever reach user inboxes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the mission behind AegisAI, a new email security startup that has just emerged from stealth with $13 million in seed funding co-led by Accel and Foundation Capital.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More than 90% of successful cyberattacks begin with a phishing email, per U.S. federal cybersecurity agency CISA. A recent CrowdStrike study (PDF) also found that phishing messages generated by large language models (LLMs) had a 54% click-through rate in 2024, far higher than the 12% rate for human-written emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AegisAI aims to counter this growing threat with its suite of autonomous AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded by former Google Safe Browsing and reCAPTCHA executives Cy Khormaee and Ryan Luo, the startup offers an orchestrated network of real-time AI agents that inspect, analyze, and neutralize email threats autonomously, without relying on any specific set of rules. This approach challenges typical email security platforms that rely on static rules and often require extensive user training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The sum of all evil is a PDF attachment in an email. That’s always where all the attacks started, and so I really wanted to solve this problem,” Khormaee said in an exclusive interview with TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo of AegisAI co-founders Ryan Luo (Left) and Cy Khormaee (Right)" class="wp-image-3044483" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/09/aegisai-co-founders_d8bd27.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AegisAI co-founders Ryan Luo (Left) and Cy Khormaee (Right)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Khormaee was head of product and director of product management at Google for over five years until July 2023. During that time, he led the security team responsible for protecting Google, its four billion users, and four million websites from phishing, malware, and fraud, using products like Safe Browsing, reCAPTCHA, and Web Risk. It was also during this time that he first met Luo, who had spent almost a decade at Google and was part of the Safe Browsing team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google gave Khormaee firsthand experience in building phishing detection technologies, a deep understanding of security from the company’s perspective, and how to develop and scale security businesses quickly, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before Google, Khormaee founded the sales intelligence platform Contastic, which was acquired by SugarCRM in 2016. He later served as VP of product management at Attentive for over a year and a half until November 2024, before starting AegisAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AegisAI has built reasoning agents, each of which is a custom-built LLM tuned to a specific threat. Once the orchestrating agent recognizes a threat or potential threat, it calls other agents in the network, which Khormaee refers to as “buddies.” These agents then run the analysis, reason with each other, and respond to the orchestrating agent with a verdict.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The agents perform real-time analysis of every message component, including links, attachments, metadata, QR codes, and behavioral patterns.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a screenshot showing the AegisAI dashboard, showing the number of users and malicious emails blocked." class="wp-image-3044486" height="1250" src="https://techcrunch.com/wp-content/uploads/2025/09/aegisai_executive_overview_dashboard.jpg" width="1596" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AegisAI dashboard&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;AegisAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“What we know from building these tools at Google is what all the things are about an email you need to analyze? What are all the data sources? What are all the techniques for spotting invasion, and all the nasty stuff adversaries do that we’ve seen over 10 years of playing chess with these adversaries?” said Khormaee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AegisAI has currently built over 10 agents for this work, Khormaee told TechCrunch that there could be 50 to 100 agents over time as adversaries become smarter and try to fool the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I fully believe that in two years, adversaries will understand what we’re doing. They’ll retool and attack what we’re doing, and then we’ll need to build more agents to stay ahead of them,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike a typical email security platform that uses a rules-based approach, these AI agents spot a bunch of attacks and self-tune themselves for every possible variant of those attacks in real-time, said Khormaee. The startup has developed multiple AI models tailored to various threats and specific industries, including those in venture capital and financial services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside quickly detecting threats, AegisAI’s agents help reduce false positives by up to 90% compared to traditional solutions, the startup claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It takes “no more than five minutes” for customers to install AegisAI’s system on a Google Workspace or Microsoft 365 email account via an API, per Khormaee. Once set up, the startup will send a report in a couple of days with the details on what the system found in the environment, including false positives and false negatives. It will then run in read-only mode for a week and then activate quarantine.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s so hard without this technology to solve this very heterogeneous problem in email,” said Khormaee.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup, with offices in San Francisco and New York, is currently running a pilot with customers in the U.S. and Europe and has already added three paying customers, including data privacy compliance software Lokker and crypto payment platform Mesh Connect. The startup currently has a team of six members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh investment, Khormaee said the startup plans to expand its technical expertise and build a robust go-to-market infrastructure.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/googles-former-security-leads-raise-13m-to-fight-email-threats-before-they-reach-you/</guid><pubDate>Wed, 10 Sep 2025 11:00:00 +0000</pubDate></item><item><title>Ex-Google X trio wants their AI to be your second brain — and they just raised $6M to make it happen (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/ex-google-x-trio-wants-their-ai-to-be-your-second-brain-and-they-just-raised-6m-to-make-it-happen/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three former Google X scientists aim to give you a second brain virtually — not in the sci-fi or chip-in-your-head sense — but through an AI-powered app that gains context by listening to everything you say in the background. Their startup, TwinMind, has raised $5.7 million in seed funding and released an Android version, along with a new AI speech model. It also has an iPhone version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founded in March 2024 by Daniel George (CEO) and his former Google X colleagues Sunny Tang and Mahi Karim (both CTOs), TwinMind runs in the background, capturing ambient speech (with user permission) to build a personal knowledge graph. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By turning spoken thoughts, meetings, lectures and conversations into structured memory, the app can generate AI-powered notes, to-dos, and answers. It works offline, processes audio in real-time to transcribe on-device, and can capture audio continuously for 16–17 hours without draining the device’s battery, the founders say. The app can also back up user data so conversations can be recovered if the device is lost, though users can opt-out of that. It also supports real-time translation in over 100 languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TwinMind differentiates itself from AI meeting note-takers like Otter, Granola, and Fireflies by capturing audio passively in the background all day. To make this possible, the team built a low-level service in pure Swift that runs natively on the iPhone. In contrast, many competitors use React Native and rely on cloud-based processing, which Apple restricts from running in the background for extended periods, George said in an exclusive interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We spent about six to seven months last year just perfecting this audio capture continuously and getting there to find a lot of hacks around Apple’s walled garden,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;George left Google X in 2020 and got the idea for TwinMind in 2023 when was working at JPMorgan as Vice President and Applied AI Lead, attending back-to-back meetings each day. To save time, he built a script that captured audio, transcribed it on his iPad, and fed it into ChatGPT — which began to understand his projects and even generate usable code. Impressed by the results, he shared it with friends and posted about it on Blind, where others showed interest but did not want something running on their work laptops. That led him to build an app that could run on a personal phone, quietly listening during meetings to gather useful context.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the mobile app, TwinMind offers a Chrome extension that gathers additional context through browser activity. Using vision AI, it can visually scan open tabs and interpret content from various platforms, including email, Slack, and Notion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup even used the extension itself to shortlist interns from over 850 applications they received this summer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We opened all the LinkedIn profiles and CVs of the 854 applicants in browser tabs, then asked the Chrome extension to rank the best candidates,” George said. “It did a fantastic job — that’s how we hired our final four interns.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3044501" height="990" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-chrome-extension.jpg" width="1488" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;TwinMind offers a Chrome Extension for additional context gathering&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;He noted that current AI chatbots — including OpenAI’s ChatGPT and Anthropic’s Claude — cannot easily process hundreds of documents or parse sign-ups from tools like LinkedIn or Gmail to gather contextual information. Similarly, AI-powered browsers such as those from Perplexity and The Browser Company lack the ability to build knowledge from your offline conversations and in-person meetings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup currently has over 30,000 users, with about 15,000 of them active each month. As much as 20–30% of TwinMind users also use the Chrome extension, George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the U.S. is the largest base for TwinMind so far, the startup is also seeing traction from India, Brazil, the Philippines, Ethiopia, Kenya, and Europe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TwinMind targets the general audience, although 50–60% of its users are currently professionals, about 25% are students, and the remaining 20–25% are individuals using it for personal purposes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;George told TechCrunch that his father is among the individuals using TwinMind to write their autobiography.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of AI’s significant drawbacks is its potential to compromise user privacy. But George asserted that TwinMind does not train its models on user data and is designed to work without sending recordings to the cloud. Unlike many other AI note-taking apps, TwinMind does not let users access audio recordings later — the audio is deleted on the fly — while only the transcribed text is stored locally in the app, he noted.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-google-x-experience-helped-speed-things-up"&gt;Google X experience helped speed things up&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The TwinMind co-founders spent a few years working on various projects at Google X. George told TechCrunch that he worked on six projects alone, including iyO — the team behind AI-powered earbuds, which recently made headlines for suing OpenAI and Jony Ive. That experience helped the TwinMind team move quickly from concept to product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Google X was actually the perfect place to prepare for starting your own company,” said George. “There are around 30 to 40 startup-like projects happening at any given time. Nobody else gets to work at six early-stage startups over two or three years before launching their own — at least not in such a short span.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3044536" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-co-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;TwinMind Co-founders Sunny Tang, Daniel George, and Mahi Karim (From Left to Right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Before joining Google, George worked on applying deep learning to gravitational wave astrophysics as part of the Nobel Prize–winning LIGO group at the University of Illinois’ National Center for Supercomputing Applications. He had completed his PhD in AI for astrophysics in just one year — at the age of 24 — a feat that led him to join Stephen Wolfram’s research lab in 2017 as a deep learning and AI researcher.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That early connection with Wolfram came full circle years later — he ended up writing the first check for TwinMind, marking his first-ever investment in a startup. The recent seed round was led by Streamlined Ventures, with participation from Sequoia Capital and other investors, including Wolfram. The round values TwinMind at $60 million post-money.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-twinmind-ear-3-model"&gt;TwinMind Ear-3 model&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to its apps and browser extension, TwinMind has also introduced the TwinMind Ear-3 model, a successor to its existing Ear-2, which supports over 140 languages worldwide and has a word error rate of 5.26%, the startup said. The new model can also recognize different speakers in a conversation and has a speaker diarization error rate of 3.8%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI model is a fine-tuned blend of several open-source models, trained on a curated set of human-annotated internet data — including podcasts, videos, and movies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We found that the more languages you support, the better the model gets at understanding accents and regional dialects because it’s training on a broader range of speakers,” George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model costs $0.23/ hour and will be available through an API to developers and enterprises over the next few weeks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3044497" height="1137" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-ear-3-pricing-performance.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Ear-3, unlike the Ear-2, does not support a complete offline experience, as it is larger in size and runs on the cloud. However, the app automatically switches to Ear-2 if the internet goes away and then moves back to Ear-3 when it is back, George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the introduction of the Ear-3, TwinMind now offers a Pro subscription at $15/month, with a larger context window of up to 2 million tokens and email support within 24 hours. Nonetheless, the free version still exists with all the existing features including unlimited hours of transcriptions and on-device speech recognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup currently has a team of 11 members. It plans to hire a few designers to enhance its user experience and set up a business development team to sell its API. Furthermore, there are plans to spend some money on acquiring new users.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three former Google X scientists aim to give you a second brain virtually — not in the sci-fi or chip-in-your-head sense — but through an AI-powered app that gains context by listening to everything you say in the background. Their startup, TwinMind, has raised $5.7 million in seed funding and released an Android version, along with a new AI speech model. It also has an iPhone version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founded in March 2024 by Daniel George (CEO) and his former Google X colleagues Sunny Tang and Mahi Karim (both CTOs), TwinMind runs in the background, capturing ambient speech (with user permission) to build a personal knowledge graph. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By turning spoken thoughts, meetings, lectures and conversations into structured memory, the app can generate AI-powered notes, to-dos, and answers. It works offline, processes audio in real-time to transcribe on-device, and can capture audio continuously for 16–17 hours without draining the device’s battery, the founders say. The app can also back up user data so conversations can be recovered if the device is lost, though users can opt-out of that. It also supports real-time translation in over 100 languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TwinMind differentiates itself from AI meeting note-takers like Otter, Granola, and Fireflies by capturing audio passively in the background all day. To make this possible, the team built a low-level service in pure Swift that runs natively on the iPhone. In contrast, many competitors use React Native and rely on cloud-based processing, which Apple restricts from running in the background for extended periods, George said in an exclusive interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We spent about six to seven months last year just perfecting this audio capture continuously and getting there to find a lot of hacks around Apple’s walled garden,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;George left Google X in 2020 and got the idea for TwinMind in 2023 when was working at JPMorgan as Vice President and Applied AI Lead, attending back-to-back meetings each day. To save time, he built a script that captured audio, transcribed it on his iPad, and fed it into ChatGPT — which began to understand his projects and even generate usable code. Impressed by the results, he shared it with friends and posted about it on Blind, where others showed interest but did not want something running on their work laptops. That led him to build an app that could run on a personal phone, quietly listening during meetings to gather useful context.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the mobile app, TwinMind offers a Chrome extension that gathers additional context through browser activity. Using vision AI, it can visually scan open tabs and interpret content from various platforms, including email, Slack, and Notion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup even used the extension itself to shortlist interns from over 850 applications they received this summer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We opened all the LinkedIn profiles and CVs of the 854 applicants in browser tabs, then asked the Chrome extension to rank the best candidates,” George said. “It did a fantastic job — that’s how we hired our final four interns.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3044501" height="990" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-chrome-extension.jpg" width="1488" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;TwinMind offers a Chrome Extension for additional context gathering&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;He noted that current AI chatbots — including OpenAI’s ChatGPT and Anthropic’s Claude — cannot easily process hundreds of documents or parse sign-ups from tools like LinkedIn or Gmail to gather contextual information. Similarly, AI-powered browsers such as those from Perplexity and The Browser Company lack the ability to build knowledge from your offline conversations and in-person meetings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup currently has over 30,000 users, with about 15,000 of them active each month. As much as 20–30% of TwinMind users also use the Chrome extension, George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the U.S. is the largest base for TwinMind so far, the startup is also seeing traction from India, Brazil, the Philippines, Ethiopia, Kenya, and Europe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TwinMind targets the general audience, although 50–60% of its users are currently professionals, about 25% are students, and the remaining 20–25% are individuals using it for personal purposes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;George told TechCrunch that his father is among the individuals using TwinMind to write their autobiography.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of AI’s significant drawbacks is its potential to compromise user privacy. But George asserted that TwinMind does not train its models on user data and is designed to work without sending recordings to the cloud. Unlike many other AI note-taking apps, TwinMind does not let users access audio recordings later — the audio is deleted on the fly — while only the transcribed text is stored locally in the app, he noted.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-google-x-experience-helped-speed-things-up"&gt;Google X experience helped speed things up&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The TwinMind co-founders spent a few years working on various projects at Google X. George told TechCrunch that he worked on six projects alone, including iyO — the team behind AI-powered earbuds, which recently made headlines for suing OpenAI and Jony Ive. That experience helped the TwinMind team move quickly from concept to product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Google X was actually the perfect place to prepare for starting your own company,” said George. “There are around 30 to 40 startup-like projects happening at any given time. Nobody else gets to work at six early-stage startups over two or three years before launching their own — at least not in such a short span.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3044536" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-co-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;TwinMind Co-founders Sunny Tang, Daniel George, and Mahi Karim (From Left to Right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Before joining Google, George worked on applying deep learning to gravitational wave astrophysics as part of the Nobel Prize–winning LIGO group at the University of Illinois’ National Center for Supercomputing Applications. He had completed his PhD in AI for astrophysics in just one year — at the age of 24 — a feat that led him to join Stephen Wolfram’s research lab in 2017 as a deep learning and AI researcher.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That early connection with Wolfram came full circle years later — he ended up writing the first check for TwinMind, marking his first-ever investment in a startup. The recent seed round was led by Streamlined Ventures, with participation from Sequoia Capital and other investors, including Wolfram. The round values TwinMind at $60 million post-money.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-twinmind-ear-3-model"&gt;TwinMind Ear-3 model&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to its apps and browser extension, TwinMind has also introduced the TwinMind Ear-3 model, a successor to its existing Ear-2, which supports over 140 languages worldwide and has a word error rate of 5.26%, the startup said. The new model can also recognize different speakers in a conversation and has a speaker diarization error rate of 3.8%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI model is a fine-tuned blend of several open-source models, trained on a curated set of human-annotated internet data — including podcasts, videos, and movies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We found that the more languages you support, the better the model gets at understanding accents and regional dialects because it’s training on a broader range of speakers,” George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model costs $0.23/ hour and will be available through an API to developers and enterprises over the next few weeks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3044497" height="1137" src="https://techcrunch.com/wp-content/uploads/2025/09/twinmind-ear-3-pricing-performance.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TwinMind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Ear-3, unlike the Ear-2, does not support a complete offline experience, as it is larger in size and runs on the cloud. However, the app automatically switches to Ear-2 if the internet goes away and then moves back to Ear-3 when it is back, George said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the introduction of the Ear-3, TwinMind now offers a Pro subscription at $15/month, with a larger context window of up to 2 million tokens and email support within 24 hours. Nonetheless, the free version still exists with all the existing features including unlimited hours of transcriptions and on-device speech recognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup currently has a team of 11 members. It plans to hire a few designers to enhance its user experience and set up a business development team to sell its API. Furthermore, there are plans to spend some money on acquiring new users.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/ex-google-x-trio-wants-their-ai-to-be-your-second-brain-and-they-just-raised-6m-to-make-it-happen/</guid><pubDate>Wed, 10 Sep 2025 12:00:00 +0000</pubDate></item><item><title>The Download: AI’s energy future (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/10/1123489/the-download-ais-energy-future/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Video: AI and our energy future&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In May, MIT Technology Review published an unprecedented and comprehensive look at how much energy the AI industry uses—down to a single query. Our reporters and editors traced where AI’s carbon footprint stands now, and where it’s headed, as AI barrels towards billions of daily users.&lt;/p&gt;  &lt;p&gt;We’ve just produced a short video to accompany that investigation. You can read the original full story here, and check out—and share— the full video on YouTube here.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI is changing the grid. Could it help more than it harms?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The rising popularity of AI is driving an increase in electricity demand so significant it has the potential to reshape the grid. Energy consumption by data centers has gone up by 80% from 2020 to 2025 and is likely to keep growing. Electricity prices are already rising, especially in places where data centers are most concentrated.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet many people, especially in Big Tech, argue that AI will be, on balance, a positive force for the grid. They claim that the technology could help get more clean power online faster, run our power system more efficiently, and predict and prevent failures that cause blackouts. How much merit is there to that argument?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three big things we still don’t know about AI’s energy burden&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this year, when my colleague Casey Crownhart and I spent six months researching the climate and energy burden of AI, we came to see one number in particular as our white whale: how much energy the leading AI models, like ChatGPT or Gemini, use up when generating a single response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;We pestered Google, OpenAI, and Microsoft, but each company refused to provide its figure for our article. But then this summer, after we published, a strange thing started to happen. They finally started to release the numbers we’d been calling for.&lt;/p&gt; 

 &lt;p&gt;So with this newfound transparency, is our job complete? Did we finally harpoon our white whale? I reached out to some of our old sources, and some new ones, to find out. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Google DeepMind has a new way to look inside an AI’s “mind”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We don’t know exactly how AI works, or why it works so well. That’s a problem: It could lead us to deploy an AI system in a highly sensitive field like medicine without understanding its critical flaws.But a team at Google DeepMind that studies something called mechanistic interpretability has been working on new ways to let us peer under the hood.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;1 Meta suppressed research into the harms young users face in VR&lt;/strong&gt;&lt;br /&gt;Two former employees told a Senate committee the firm did it to avoid regulatory scrutiny. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The MAGA movement is full of AI skeptics&lt;/strong&gt;&lt;br /&gt;But the White House is ditching regulatory obstacles and trying to accelerate AI’s adoption. (FT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 Pfizer says its new covid vaccine boosts immune responses fourfold&lt;br /&gt;&lt;/strong&gt;If you can get one, that is. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Americans who can’t access a booster are increasingly fearful. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Vaccine guidance is incredibly confusing these days. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;Why limited access to covid vaccines isn’t all bad. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The EU will examine banning social media for under-16s&lt;/strong&gt;&lt;br /&gt;Following governments across Europe pushing for mandatory age restrictions. (Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;5 RFK Jr is going all-in on ChatGPT&lt;/strong&gt;&lt;br /&gt;All US health department employees have been given access to the tool. (404 Media)&lt;br /&gt;+ &lt;em&gt;Humans may be more likely to believe disinformation generated by AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 An “AI-supported” coder won in a man vs machine hackathon&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;But AI tools seem to slow down some experienced human developers. (Wired $)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Mark Zuckerberg is suing Meta&lt;/strong&gt;&lt;br /&gt;No, not &lt;em&gt;that&lt;/em&gt; Mark Zuckerberg. (NYT $)&lt;br /&gt;+ &lt;em&gt;The bankruptcy lawyer is fed up with being mistaken for him. &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Apple’s new AirPods can translate languages in real time&lt;br /&gt;&lt;/strong&gt;Via a robotic voice in your ear. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;A new AI translation system for headphones clones multiple voices simultaneously. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 AI is threatening Latin America’s diverse music scenes&lt;/strong&gt;&lt;br /&gt;Fake songs are flooding streaming platforms and depriving artists of an income. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How Pandora fumbled its streaming lead. &lt;/em&gt;(Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Auction house Christie’s is axing its digital art division&lt;/strong&gt;&lt;br /&gt;But don’t worry—it’ll still sell you NFTs. (Cointelegraph)&lt;br /&gt;+ &lt;em&gt;I tried to buy an Olive Garden NFT. All I got was heartburn. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you don’t lay the groundwork culturally for bringing in these stars, you’re going to end up burning a bunch of them out and pissing them off, and a bunch of them are going to quit and you’re going to waste millions of dollars.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Laszlo Bock, a tech industry adviser and former head of people operations at Google, points out where Meta’s AI division is going wrong to the Wall Street Journal.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123492" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_c641e0.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The $100 billion bet that a postindustrial US city can reinvent itself as a high-tech hub&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;On a day in late April 2023, a small drilling rig sits at the edge of the scrubby overgrown fields of Syracuse, New York, taking soil samples. It’s the first sign of construction on what could become the largest semiconductor manufacturing facility in the United States.&lt;/p&gt;  &lt;p&gt;The CHIPS and Science Act was widely viewed by industry leaders and politicians as a way to secure supply chains, and make the United States competitive again in semiconductor chip manufacturing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now Syracuse is about to become an economic test of whether, over the next several decades, aggressive government policies—and the massive corporate investments they spur—can both boost the country’s manufacturing prowess and revitalize neglected parts of the country. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Video: AI and our energy future&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In May, MIT Technology Review published an unprecedented and comprehensive look at how much energy the AI industry uses—down to a single query. Our reporters and editors traced where AI’s carbon footprint stands now, and where it’s headed, as AI barrels towards billions of daily users.&lt;/p&gt;  &lt;p&gt;We’ve just produced a short video to accompany that investigation. You can read the original full story here, and check out—and share— the full video on YouTube here.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI is changing the grid. Could it help more than it harms?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The rising popularity of AI is driving an increase in electricity demand so significant it has the potential to reshape the grid. Energy consumption by data centers has gone up by 80% from 2020 to 2025 and is likely to keep growing. Electricity prices are already rising, especially in places where data centers are most concentrated.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet many people, especially in Big Tech, argue that AI will be, on balance, a positive force for the grid. They claim that the technology could help get more clean power online faster, run our power system more efficiently, and predict and prevent failures that cause blackouts. How much merit is there to that argument?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three big things we still don’t know about AI’s energy burden&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this year, when my colleague Casey Crownhart and I spent six months researching the climate and energy burden of AI, we came to see one number in particular as our white whale: how much energy the leading AI models, like ChatGPT or Gemini, use up when generating a single response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;We pestered Google, OpenAI, and Microsoft, but each company refused to provide its figure for our article. But then this summer, after we published, a strange thing started to happen. They finally started to release the numbers we’d been calling for.&lt;/p&gt; 

 &lt;p&gt;So with this newfound transparency, is our job complete? Did we finally harpoon our white whale? I reached out to some of our old sources, and some new ones, to find out. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Google DeepMind has a new way to look inside an AI’s “mind”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We don’t know exactly how AI works, or why it works so well. That’s a problem: It could lead us to deploy an AI system in a highly sensitive field like medicine without understanding its critical flaws.But a team at Google DeepMind that studies something called mechanistic interpretability has been working on new ways to let us peer under the hood.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;1 Meta suppressed research into the harms young users face in VR&lt;/strong&gt;&lt;br /&gt;Two former employees told a Senate committee the firm did it to avoid regulatory scrutiny. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The MAGA movement is full of AI skeptics&lt;/strong&gt;&lt;br /&gt;But the White House is ditching regulatory obstacles and trying to accelerate AI’s adoption. (FT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 Pfizer says its new covid vaccine boosts immune responses fourfold&lt;br /&gt;&lt;/strong&gt;If you can get one, that is. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Americans who can’t access a booster are increasingly fearful. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Vaccine guidance is incredibly confusing these days. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;Why limited access to covid vaccines isn’t all bad. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The EU will examine banning social media for under-16s&lt;/strong&gt;&lt;br /&gt;Following governments across Europe pushing for mandatory age restrictions. (Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;5 RFK Jr is going all-in on ChatGPT&lt;/strong&gt;&lt;br /&gt;All US health department employees have been given access to the tool. (404 Media)&lt;br /&gt;+ &lt;em&gt;Humans may be more likely to believe disinformation generated by AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 An “AI-supported” coder won in a man vs machine hackathon&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;But AI tools seem to slow down some experienced human developers. (Wired $)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Mark Zuckerberg is suing Meta&lt;/strong&gt;&lt;br /&gt;No, not &lt;em&gt;that&lt;/em&gt; Mark Zuckerberg. (NYT $)&lt;br /&gt;+ &lt;em&gt;The bankruptcy lawyer is fed up with being mistaken for him. &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Apple’s new AirPods can translate languages in real time&lt;br /&gt;&lt;/strong&gt;Via a robotic voice in your ear. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;A new AI translation system for headphones clones multiple voices simultaneously. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 AI is threatening Latin America’s diverse music scenes&lt;/strong&gt;&lt;br /&gt;Fake songs are flooding streaming platforms and depriving artists of an income. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How Pandora fumbled its streaming lead. &lt;/em&gt;(Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Auction house Christie’s is axing its digital art division&lt;/strong&gt;&lt;br /&gt;But don’t worry—it’ll still sell you NFTs. (Cointelegraph)&lt;br /&gt;+ &lt;em&gt;I tried to buy an Olive Garden NFT. All I got was heartburn. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you don’t lay the groundwork culturally for bringing in these stars, you’re going to end up burning a bunch of them out and pissing them off, and a bunch of them are going to quit and you’re going to waste millions of dollars.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Laszlo Bock, a tech industry adviser and former head of people operations at Google, points out where Meta’s AI division is going wrong to the Wall Street Journal.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123492" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_c641e0.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The $100 billion bet that a postindustrial US city can reinvent itself as a high-tech hub&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;On a day in late April 2023, a small drilling rig sits at the edge of the scrubby overgrown fields of Syracuse, New York, taking soil samples. It’s the first sign of construction on what could become the largest semiconductor manufacturing facility in the United States.&lt;/p&gt;  &lt;p&gt;The CHIPS and Science Act was widely viewed by industry leaders and politicians as a way to secure supply chains, and make the United States competitive again in semiconductor chip manufacturing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now Syracuse is about to become an economic test of whether, over the next several decades, aggressive government policies—and the massive corporate investments they spur—can both boost the country’s manufacturing prowess and revitalize neglected parts of the country. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/10/1123489/the-download-ais-energy-future/</guid><pubDate>Wed, 10 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] AI gaming startup Born raises $15M to build ‘social’ AI companions that combat loneliness (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/born-maker-of-virtual-pet-pengu-raises-15m-to-launch-a-new-wave-of-social-ai-companions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Leadership.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fabian Kamberi, CEO and co-founder of the Berlin-based AI gaming startup Born, thinks the current AI companions on the market are designed to be exploitative and geared towards isolating users through one-to-one relationships with AI chatbots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It feels like it fuels the loneliness epidemic, instead of making it more fun and giving users the opportunity to make their lives better,” Kamberi told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The future of AI companions, he says, is about shared experiences that strengthen real-world bonds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born’s flagship AI product is an app where users can raise, play mini-games with, and co-parent a cute virtual pet named Pengu. Think of it as a generative AI-powered Tamagatchi or Neopet, but one that requires collaboration with another human, like a friend or romantic partner. It’s a freemium app where users can pay for a Pengu Pass subscription for additional features. And while it’s reached more than 15 million users globally, according to Born, the company hasn’t disclosed how many of those are paying customers – a critical question for any consumer subscription business.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea behind Pengu is that the social aspect turns the pet into a shared project, helping users engage with both the AI character and their real-life relationships. Now, Born is gearing up to release new characters for the Pengu app and launch another social AI product designed for young people.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born’s thesis that AI companions should both entertain and incorporate a social element has attracted investor attention. The startup, formerly known as Slay, has raised a $15 million Series A, bringing its total funding to $25 million, from investors including Accel, Tencent, and Laton Ventures.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The thesis doesn’t stray too far from when Born was Slay, a social media app for teenagers that revolved around giving and receiving compliments. At the time, Kamberi described Slay as the “go-to spot for teens to rediscover social interactions in various play modes.” The pivot to Born’s AI companions carries forward that same principle of making digital interactions more positive and socially engaging.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh funds, Born plans to launch new characters on the Pengu app, including another “cute” digital companion that would double as a learning companion, according to Kamberi. The startup is also opening&amp;nbsp;an office in New York later this year focused on marketing and AI research. That research will include improving its character engine so that each new AI friend can form a consistent personality, remember interactions, and grow alongside the user. Enrico Dal Re, Born’s head of finance, will lead the company’s expansion in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born is also preparing to launch another AI social product specifically for young people ages 16 to 21 – though kids as young as 13 can use Born’s apps. Kamberi noted that Born mainly relies on OpenAI’s generative AI models, but has built additional safety layers on top.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new product is still in stealth mode, but Kamberi says it will allow users to create and engage with “culturally relevant AI companions that feel like real friends.” For example, the bots might send you TikTok videos or Instagram Reels based on the content you already consume on social media, he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Kamberi added that he expects Born’s new product to have “network effects” as users share their creations on social media.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t believe that the current chatbot landscape is the final form factor for how AI friends and consumer AI is done,” Kamberi said. “There must be ways for consumer social AI to be way more engaging to users than just entering a platform and texting a bot that was maybe created by me or another person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Luca Bocchio, partner at Accel, the appeal lies in Born’s ambition to create a new consumer social category built around emotionally intelligent AI characters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve been really impressed by the team’s ability to develop chart-topping apps and their inspiring product vision, and we’re looking forward to continuing our partnership with them as they scale globally,” Bocchio said.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Leadership.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fabian Kamberi, CEO and co-founder of the Berlin-based AI gaming startup Born, thinks the current AI companions on the market are designed to be exploitative and geared towards isolating users through one-to-one relationships with AI chatbots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It feels like it fuels the loneliness epidemic, instead of making it more fun and giving users the opportunity to make their lives better,” Kamberi told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The future of AI companions, he says, is about shared experiences that strengthen real-world bonds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born’s flagship AI product is an app where users can raise, play mini-games with, and co-parent a cute virtual pet named Pengu. Think of it as a generative AI-powered Tamagatchi or Neopet, but one that requires collaboration with another human, like a friend or romantic partner. It’s a freemium app where users can pay for a Pengu Pass subscription for additional features. And while it’s reached more than 15 million users globally, according to Born, the company hasn’t disclosed how many of those are paying customers – a critical question for any consumer subscription business.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea behind Pengu is that the social aspect turns the pet into a shared project, helping users engage with both the AI character and their real-life relationships. Now, Born is gearing up to release new characters for the Pengu app and launch another social AI product designed for young people.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born’s thesis that AI companions should both entertain and incorporate a social element has attracted investor attention. The startup, formerly known as Slay, has raised a $15 million Series A, bringing its total funding to $25 million, from investors including Accel, Tencent, and Laton Ventures.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The thesis doesn’t stray too far from when Born was Slay, a social media app for teenagers that revolved around giving and receiving compliments. At the time, Kamberi described Slay as the “go-to spot for teens to rediscover social interactions in various play modes.” The pivot to Born’s AI companions carries forward that same principle of making digital interactions more positive and socially engaging.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh funds, Born plans to launch new characters on the Pengu app, including another “cute” digital companion that would double as a learning companion, according to Kamberi. The startup is also opening&amp;nbsp;an office in New York later this year focused on marketing and AI research. That research will include improving its character engine so that each new AI friend can form a consistent personality, remember interactions, and grow alongside the user. Enrico Dal Re, Born’s head of finance, will lead the company’s expansion in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Born is also preparing to launch another AI social product specifically for young people ages 16 to 21 – though kids as young as 13 can use Born’s apps. Kamberi noted that Born mainly relies on OpenAI’s generative AI models, but has built additional safety layers on top.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new product is still in stealth mode, but Kamberi says it will allow users to create and engage with “culturally relevant AI companions that feel like real friends.” For example, the bots might send you TikTok videos or Instagram Reels based on the content you already consume on social media, he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Kamberi added that he expects Born’s new product to have “network effects” as users share their creations on social media.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t believe that the current chatbot landscape is the final form factor for how AI friends and consumer AI is done,” Kamberi said. “There must be ways for consumer social AI to be way more engaging to users than just entering a platform and texting a bot that was maybe created by me or another person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Luca Bocchio, partner at Accel, the appeal lies in Born’s ambition to create a new consumer social category built around emotionally intelligent AI characters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve been really impressed by the team’s ability to develop chart-topping apps and their inspiring product vision, and we’re looking forward to continuing our partnership with them as they scale globally,” Bocchio said.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/born-maker-of-virtual-pet-pengu-raises-15m-to-launch-a-new-wave-of-social-ai-companions/</guid><pubDate>Wed, 10 Sep 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Pay-per-output? AI firms blindsided by beefed up robots.txt instructions. (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/pay-per-output-ai-firms-blindsided-by-beefed-up-robots-txt-instructions/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "Really Simple Licensing" makes it easier for creators to get paid for AI scraping.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="382" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/rsl-logo-640x382.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/rsl-logo-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Logo for the "Really Simply Licensing" (RSL) standard.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          via RSL Collective

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Leading Internet companies and publishers—including Reddit, Yahoo, Quora, Medium, The Daily Beast, Fastly, and more—think there may finally be a solution to end AI crawlers hammering websites to scrape content without permission or compensation.&lt;/p&gt;
&lt;p&gt;Announced Wednesday morning, the "Really Simply Licensing" (RSL) standard evolves robots.txt instructions by adding an automated licensing layer that's designed to block bots that don't fairly compensate creators for content.&lt;/p&gt;
&lt;p&gt;Free for any publisher to use starting today, the RSL standard is an open, decentralized protocol that makes clear to AI crawlers and agents the terms for licensing, usage, and compensation of any content used to train AI, a press release noted.&lt;/p&gt;
&lt;p&gt;The standard was created by the RSL Collective, which was founded by Doug Leeds, former CEO of Ask.com, and Eckart Walther, a former Yahoo vice president of products and co-creator of the RSS standard, which made it easy to syndicate content across the web.&lt;/p&gt;
&lt;p&gt;Based on the "Really Simply Syndication" (RSS) standard, RSL terms can be applied to protect any digital content, including webpages, books, videos, and datasets. The new standard supports "a range of licensing, usage, and royalty models, including free, attribution, subscription, pay-per-crawl (publishers get compensated every time an AI application crawls their content), and pay-per-inference (publishers get compensated every time an AI application uses their content to generate a response)," the press release said.&lt;/p&gt;
&lt;p&gt;Leeds told Ars that the idea to use the RSS "playbook" to roll out the RSL standard arose after he invited Walther to speak to University of California, Berkeley students at the end of last year. That's when the longtime friends with search backgrounds began pondering how AI had changed the search industry, as publishers today are forced to compete with AI outputs referencing their own content as search traffic nosedives.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Eckart had watched the RSS standard quickly become adopted by millions of sites, and he realized that RSS had actually always been a licensing standard, Leeds said. Essentially, by adopting the RSS standard, publishers agreed to let search engines license a "bit" of their content in exchange for search traffic, and Eckart realized that it could be just as straightforward to add AI licensing terms in the same way. That way, publishers could strive to recapture lost search revenue by agreeing to license all or some part of their content to train AI in return for payment each time AI outputs link to their content.&lt;/p&gt;
&lt;p&gt;Leeds told Ars that the RSL standard doesn't just benefit publishers, though. It also solves a problem for AI companies, which have complained in litigation over AI scraping that there is no effective way to license content across the web.&lt;/p&gt;
&lt;p&gt;"We have listened to them, and what we've heard them say is… we need a new protocol," Leeds said. With the RSL standard, AI firms get a "scalable way to get all the content" they want, while setting an incentive that they'll only have to pay for the best content that their models actually reference.&lt;/p&gt;
&lt;p&gt;"If they're using it, they pay for it, and if they're not using it, they don't pay for it," Leeds said.&lt;/p&gt;
&lt;h2&gt;No telling yet how AI firms will react to RSL&lt;/h2&gt;
&lt;p&gt;At this point, it's hard to say if AI companies will embrace the RSL standard. Ars reached out to Google, Meta, OpenAI, and xAI—some of the big tech companies whose crawlers have drawn scrutiny—to see if it was technically feasible to pay publishers for every output referencing their content. xAI did not respond, and the other companies declined to comment without further detail about the standard, appearing to have not yet considered how a licensing layer beefing up robots.txt could impact their scraping.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Today will likely be the first chance for AI companies to wrap their heads around the idea of paying publishers per output. Leeds confirmed that the RSL Collective did not consult with AI companies when developing the RSL standard.&lt;/p&gt;
&lt;p&gt;But AI companies know that they need a constant stream of fresh content to keep their tools relevant and to continually innovate, Leeds suggested. In that way, the RSL standard "supports what supports them," Leeds said, "and it creates the appropriate incentive system" to create sustainable royalty streams for creators and ensure that human creativity doesn't wane as AI evolves.&lt;/p&gt;
&lt;p&gt;While we'll have to wait to see how AI firms react to RSL, early adopters of the standard celebrated the launch today. That included Neil Vogel, CEO of People Inc., who said that "RSL moves the industry forward—evolving from simply blocking unauthorized crawlers, to setting our licensing terms, for all AI use cases, at global web scale."&lt;/p&gt;
&lt;p&gt;Simon Wistow, co-founder of Fastly, suggested the solution "is a timely and necessary response to the shifting economics of the web."&lt;/p&gt;
&lt;p&gt;"By making it easy for publishers to define and enforce licensing terms, RSL lays the foundation for a healthy content ecosystem—one where innovation and investment in original work are rewarded, and where collaboration between publishers and AI companies becomes frictionless and mutually beneficial," Wistow said.&lt;/p&gt;
&lt;p&gt;Leeds noted that a key benefit of the RSL standard is that even small creators will now have an opportunity to generate revenue for helping to train AI. Tony Stubblebine, CEO of Medium, did not mince words when explaining the battle that bloggers face as AI crawlers threaten to divert their traffic without compensating them.&lt;/p&gt;
&lt;p&gt;"Right now, AI runs on stolen content," Stubblebine said. "Adopting this RSL Standard is how we force those AI companies to either pay for what they use, stop using it, or shut down."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;How will the RSL standard be enforced?&lt;/h2&gt;
&lt;p&gt;On the RSL standard site, publishers can find common terms to add templated or customized text to their robots.txt files to adopt the RSL standard today and start protecting their content from unfettered AI scraping. Here's an example of how machine-readable licensing terms could look, added directly to robots.txt files:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;# NOTICE: all crawlers and bots are strictly prohibited from using this&lt;/p&gt;
&lt;p&gt;# content for AI training without complying with the terms of the RSL&lt;/p&gt;
&lt;p&gt;# Collective AI royalty license. Any use of this content for AI training&lt;/p&gt;
&lt;p&gt;# without a license is a violation of our intellectual property rights.&lt;/p&gt;
&lt;p&gt;License: https://rslcollective.org/royalty.xml&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Through RSL terms, publishers can automate licensing, with the cloud company Fastly partnering with the collective to provide technical enforcement that Leeds described as tech that acts as a bouncer to keep unapproved bots away from valuable content. It seems likely that Cloudflare, which launched a pay-per-crawl program blocking greedy crawlers in July, could also help enforce the RSL standard.&lt;/p&gt;
&lt;p&gt;For publishers, the standard "solves a business problem immediately," Leeds told Ars, so the collective is hopeful that RSL will be rapidly and widely adopted. As further incentive, publishers can also rely on the RSL standard to "easily encrypt and license non-published, proprietary content to AI companies, including paywalled articles, books, videos, images, and data," the RSL Collective site said, and that potentially could expand AI firms' data pool.&lt;/p&gt;
&lt;p&gt;On top of technical enforcement, Leeds said that publishers and content creators could legally enforce the terms, noting that the recent $1.5 billion Anthropic settlement suggests "there's real money at stake" if you don't train AI "legitimately."&lt;/p&gt;
&lt;p&gt;Should the industry adopt the standard, it could "establish fair market prices and strengthen negotiation leverage for all publishers," the press release said. And Leeds noted that it's very common for regulations to follow industry solutions (consider the Digital Millennium Copyright Act). Since the RSL Collective is already in talks with lawmakers, Leeds thinks "there's good reason to believe" that AI companies will soon "be forced to acknowledge" the standard.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"But even better than that," Leeds said, "it's in their interest" to adopt the standard.&lt;/p&gt;
&lt;p&gt;With RSL, AI firms can license content at scale "in a way that's fair [and] preserves the content that they need to make their products continue to innovate."&lt;/p&gt;
&lt;p&gt;Additionally, the RSL standard may solve a problem that risks gutting trust and interest in AI at this early stage.&lt;/p&gt;
&lt;p&gt;Leeds noted that currently, AI outputs don't provide "the best answer" to prompts but instead rely on mashing up answers from different sources to avoid taking too much content from one site. That means that not only do AI companies "spend an enormous amount of money on compute costs to do that," but AI tools may also be more prone to hallucination in the process of "mashing up" source material "to make something that's not the best answer because they don't have the rights to the best answer."&lt;/p&gt;
&lt;p&gt;"The best answer could exist somewhere," Leeds said. But "they're spending billions of dollars to create hallucinations, and we're talking about: Let's just solve that with a licensing scheme that allows you to use the actual content in a way that solves the user's query best."&lt;/p&gt;
&lt;p&gt;By transforming the "ecosystem" with a standard that's "actually sustainable and fair," Leeds said that AI companies could also ensure that humanity never gets to the point where "humans stop producing" and "turn to AI to reproduce what humans can't."&lt;/p&gt;
&lt;p&gt;Failing to adopt the RSL standard would be bad for AI innovation, Leeds suggested, perhaps paving the way for AI to replace search with a "sort of self-fulfilling swap of bad content that actually one doesn't have any current information, doesn't have any current thinking, because it's all based on old training information."&lt;/p&gt;
&lt;p&gt;To Leeds, the RSL standard is ultimately "about creating the system that allows the open web to continue. And that happens when we get adoption from everybody," he said, insisting that "literally the small guys are as important as the big guys" in pushing the entire industry to change and fairly compensate creators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "Really Simple Licensing" makes it easier for creators to get paid for AI scraping.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="382" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/rsl-logo-640x382.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/rsl-logo-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Logo for the "Really Simply Licensing" (RSL) standard.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          via RSL Collective

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Leading Internet companies and publishers—including Reddit, Yahoo, Quora, Medium, The Daily Beast, Fastly, and more—think there may finally be a solution to end AI crawlers hammering websites to scrape content without permission or compensation.&lt;/p&gt;
&lt;p&gt;Announced Wednesday morning, the "Really Simply Licensing" (RSL) standard evolves robots.txt instructions by adding an automated licensing layer that's designed to block bots that don't fairly compensate creators for content.&lt;/p&gt;
&lt;p&gt;Free for any publisher to use starting today, the RSL standard is an open, decentralized protocol that makes clear to AI crawlers and agents the terms for licensing, usage, and compensation of any content used to train AI, a press release noted.&lt;/p&gt;
&lt;p&gt;The standard was created by the RSL Collective, which was founded by Doug Leeds, former CEO of Ask.com, and Eckart Walther, a former Yahoo vice president of products and co-creator of the RSS standard, which made it easy to syndicate content across the web.&lt;/p&gt;
&lt;p&gt;Based on the "Really Simply Syndication" (RSS) standard, RSL terms can be applied to protect any digital content, including webpages, books, videos, and datasets. The new standard supports "a range of licensing, usage, and royalty models, including free, attribution, subscription, pay-per-crawl (publishers get compensated every time an AI application crawls their content), and pay-per-inference (publishers get compensated every time an AI application uses their content to generate a response)," the press release said.&lt;/p&gt;
&lt;p&gt;Leeds told Ars that the idea to use the RSS "playbook" to roll out the RSL standard arose after he invited Walther to speak to University of California, Berkeley students at the end of last year. That's when the longtime friends with search backgrounds began pondering how AI had changed the search industry, as publishers today are forced to compete with AI outputs referencing their own content as search traffic nosedives.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Eckart had watched the RSS standard quickly become adopted by millions of sites, and he realized that RSS had actually always been a licensing standard, Leeds said. Essentially, by adopting the RSS standard, publishers agreed to let search engines license a "bit" of their content in exchange for search traffic, and Eckart realized that it could be just as straightforward to add AI licensing terms in the same way. That way, publishers could strive to recapture lost search revenue by agreeing to license all or some part of their content to train AI in return for payment each time AI outputs link to their content.&lt;/p&gt;
&lt;p&gt;Leeds told Ars that the RSL standard doesn't just benefit publishers, though. It also solves a problem for AI companies, which have complained in litigation over AI scraping that there is no effective way to license content across the web.&lt;/p&gt;
&lt;p&gt;"We have listened to them, and what we've heard them say is… we need a new protocol," Leeds said. With the RSL standard, AI firms get a "scalable way to get all the content" they want, while setting an incentive that they'll only have to pay for the best content that their models actually reference.&lt;/p&gt;
&lt;p&gt;"If they're using it, they pay for it, and if they're not using it, they don't pay for it," Leeds said.&lt;/p&gt;
&lt;h2&gt;No telling yet how AI firms will react to RSL&lt;/h2&gt;
&lt;p&gt;At this point, it's hard to say if AI companies will embrace the RSL standard. Ars reached out to Google, Meta, OpenAI, and xAI—some of the big tech companies whose crawlers have drawn scrutiny—to see if it was technically feasible to pay publishers for every output referencing their content. xAI did not respond, and the other companies declined to comment without further detail about the standard, appearing to have not yet considered how a licensing layer beefing up robots.txt could impact their scraping.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Today will likely be the first chance for AI companies to wrap their heads around the idea of paying publishers per output. Leeds confirmed that the RSL Collective did not consult with AI companies when developing the RSL standard.&lt;/p&gt;
&lt;p&gt;But AI companies know that they need a constant stream of fresh content to keep their tools relevant and to continually innovate, Leeds suggested. In that way, the RSL standard "supports what supports them," Leeds said, "and it creates the appropriate incentive system" to create sustainable royalty streams for creators and ensure that human creativity doesn't wane as AI evolves.&lt;/p&gt;
&lt;p&gt;While we'll have to wait to see how AI firms react to RSL, early adopters of the standard celebrated the launch today. That included Neil Vogel, CEO of People Inc., who said that "RSL moves the industry forward—evolving from simply blocking unauthorized crawlers, to setting our licensing terms, for all AI use cases, at global web scale."&lt;/p&gt;
&lt;p&gt;Simon Wistow, co-founder of Fastly, suggested the solution "is a timely and necessary response to the shifting economics of the web."&lt;/p&gt;
&lt;p&gt;"By making it easy for publishers to define and enforce licensing terms, RSL lays the foundation for a healthy content ecosystem—one where innovation and investment in original work are rewarded, and where collaboration between publishers and AI companies becomes frictionless and mutually beneficial," Wistow said.&lt;/p&gt;
&lt;p&gt;Leeds noted that a key benefit of the RSL standard is that even small creators will now have an opportunity to generate revenue for helping to train AI. Tony Stubblebine, CEO of Medium, did not mince words when explaining the battle that bloggers face as AI crawlers threaten to divert their traffic without compensating them.&lt;/p&gt;
&lt;p&gt;"Right now, AI runs on stolen content," Stubblebine said. "Adopting this RSL Standard is how we force those AI companies to either pay for what they use, stop using it, or shut down."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;How will the RSL standard be enforced?&lt;/h2&gt;
&lt;p&gt;On the RSL standard site, publishers can find common terms to add templated or customized text to their robots.txt files to adopt the RSL standard today and start protecting their content from unfettered AI scraping. Here's an example of how machine-readable licensing terms could look, added directly to robots.txt files:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;# NOTICE: all crawlers and bots are strictly prohibited from using this&lt;/p&gt;
&lt;p&gt;# content for AI training without complying with the terms of the RSL&lt;/p&gt;
&lt;p&gt;# Collective AI royalty license. Any use of this content for AI training&lt;/p&gt;
&lt;p&gt;# without a license is a violation of our intellectual property rights.&lt;/p&gt;
&lt;p&gt;License: https://rslcollective.org/royalty.xml&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Through RSL terms, publishers can automate licensing, with the cloud company Fastly partnering with the collective to provide technical enforcement that Leeds described as tech that acts as a bouncer to keep unapproved bots away from valuable content. It seems likely that Cloudflare, which launched a pay-per-crawl program blocking greedy crawlers in July, could also help enforce the RSL standard.&lt;/p&gt;
&lt;p&gt;For publishers, the standard "solves a business problem immediately," Leeds told Ars, so the collective is hopeful that RSL will be rapidly and widely adopted. As further incentive, publishers can also rely on the RSL standard to "easily encrypt and license non-published, proprietary content to AI companies, including paywalled articles, books, videos, images, and data," the RSL Collective site said, and that potentially could expand AI firms' data pool.&lt;/p&gt;
&lt;p&gt;On top of technical enforcement, Leeds said that publishers and content creators could legally enforce the terms, noting that the recent $1.5 billion Anthropic settlement suggests "there's real money at stake" if you don't train AI "legitimately."&lt;/p&gt;
&lt;p&gt;Should the industry adopt the standard, it could "establish fair market prices and strengthen negotiation leverage for all publishers," the press release said. And Leeds noted that it's very common for regulations to follow industry solutions (consider the Digital Millennium Copyright Act). Since the RSL Collective is already in talks with lawmakers, Leeds thinks "there's good reason to believe" that AI companies will soon "be forced to acknowledge" the standard.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"But even better than that," Leeds said, "it's in their interest" to adopt the standard.&lt;/p&gt;
&lt;p&gt;With RSL, AI firms can license content at scale "in a way that's fair [and] preserves the content that they need to make their products continue to innovate."&lt;/p&gt;
&lt;p&gt;Additionally, the RSL standard may solve a problem that risks gutting trust and interest in AI at this early stage.&lt;/p&gt;
&lt;p&gt;Leeds noted that currently, AI outputs don't provide "the best answer" to prompts but instead rely on mashing up answers from different sources to avoid taking too much content from one site. That means that not only do AI companies "spend an enormous amount of money on compute costs to do that," but AI tools may also be more prone to hallucination in the process of "mashing up" source material "to make something that's not the best answer because they don't have the rights to the best answer."&lt;/p&gt;
&lt;p&gt;"The best answer could exist somewhere," Leeds said. But "they're spending billions of dollars to create hallucinations, and we're talking about: Let's just solve that with a licensing scheme that allows you to use the actual content in a way that solves the user's query best."&lt;/p&gt;
&lt;p&gt;By transforming the "ecosystem" with a standard that's "actually sustainable and fair," Leeds said that AI companies could also ensure that humanity never gets to the point where "humans stop producing" and "turn to AI to reproduce what humans can't."&lt;/p&gt;
&lt;p&gt;Failing to adopt the RSL standard would be bad for AI innovation, Leeds suggested, perhaps paving the way for AI to replace search with a "sort of self-fulfilling swap of bad content that actually one doesn't have any current information, doesn't have any current thinking, because it's all based on old training information."&lt;/p&gt;
&lt;p&gt;To Leeds, the RSL standard is ultimately "about creating the system that allows the open web to continue. And that happens when we get adoption from everybody," he said, insisting that "literally the small guys are as important as the big guys" in pushing the entire industry to change and fairly compensate creators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/pay-per-output-ai-firms-blindsided-by-beefed-up-robots-txt-instructions/</guid><pubDate>Wed, 10 Sep 2025 13:00:03 +0000</pubDate></item><item><title>[NEW] Paint It Blackwell: GeForce RTX 5080 SuperPOD Rollout Begins (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-blackwell-rtx-launch/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;GeForce NOW Blackwell RTX 5080-class SuperPODs are now rolling out, unlocking a new level of ultra high-performance, cinematic cloud gaming.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;GeForce NOW Ultimate members will see GeForce RTX 5080 performance arriving to a server near them, enabling even richer experiences in blockbuster titles like &lt;i&gt;DUNE: Awakening, Borderlands 4, Hell Is Us, Dying Light: The Beast, Cronos: The New Dawn, Clair Obscur: Expedition 33 &lt;/i&gt;and more.&lt;/p&gt;
&lt;p&gt;They all come with breathtaking graphics and lowest-latency gameplay, thanks to NVIDIA DLSS 4 technology and next-generation AI features. Experience the new Cinematic-Quality Streaming mode for stunning color and fidelity across the latest devices.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84701"&gt;&lt;img alt="Install-to-Play on GeForce NOW" class="size-large wp-image-84701" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-Install-to-Play-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84701"&gt;&lt;i&gt;Look at all the room for &lt;/i&gt;&lt;del&gt;&lt;i&gt;activities&lt;/i&gt;&lt;/del&gt;&lt;i&gt; &lt;/i&gt;&lt;i&gt;gaming.&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The new Install-to-Play feature is expanding the cloud library to nearly 4,500 games for Ultimate and Performance members.&lt;/p&gt;
&lt;p&gt;This week kicks it off with three new games, including the launch of &lt;i&gt;Borderlands 4. &lt;/i&gt;GeForce NOW is the ultimate way to play the &lt;i&gt;Borderlands &lt;/i&gt;franchise’s latest entry — free with the purchase of a new 12-month Ultimate membership bundle.&lt;/p&gt;
&lt;p&gt;Make sure to follow along on GFN Thursdays for server updates.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Blackwell to the Future&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84704"&gt;&lt;img alt="GeForce RTX 5080 power on GeForce NOW" class="size-large wp-image-84704" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-RTX_5080_upgrade-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84704"&gt;Game-changer.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The future of cloud gaming has arrived. With the NVIDIA Blackwell RTX upgrade, GeForce NOW brings GeForce RTX 5080-class performance to the cloud for the first time. Ultimate members can harness DLSS 4 Multi-Frame Generation, cutting-edge AI enhancements and ultralow click-to-pixel latency, enabling up to 5K at 120 frames per second for premium, responsive gameplay.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Members will also see the GeForce NOW library instantly double. Over 2,200 Steam titles opted in by publishers for cloud streaming are hitting the cloud today, with more to come, letting members build and manage their own cloud gaming library. Alongside new Install-to-Play titles, GeForce NOW will continue to roll out ready-to-play titles each week.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84707"&gt;&lt;img alt="Blackwell RTX rollout on GeForce NOW" class="size-large wp-image-84707" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/social-post-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84707"&gt;&lt;em&gt;Coming to a zone near you.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA Blackwell RTX servers are starting to power up worldwide, so more members can start streaming with unprecedented performance on virtually any device, including PCs, Macs, Chromebooks, LG TVs (4K at 120Hz) and even Steam Decks (now up to 90 fps). Keep an eye on GFN Thursday updates and check the server rollout webpage for new regions going live.&lt;/p&gt;
&lt;p&gt;Ultimate members will soon see GeForce RTX 5080 performance in their area, with AAA titles like &lt;i&gt;DUNE: Awakening, Borderlands 4&lt;/i&gt;, &lt;i&gt;Hell Is Us, Dying Light: The Beast&lt;/i&gt;, &lt;i&gt;Cronos: The New Dawn&lt;/i&gt;, &lt;i&gt;Clair Obscur: Expedition 33&lt;/i&gt; and more playable at ultimate quality. Look for the new “GeForce RTX 5080 Ready” row in the app for the full list of GeForce RTX 5080-optimized games, updated weekly with fresh additions.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84710"&gt;&lt;img alt="GeForce RTX 5080 ready games on GeForce NOW" class="size-large wp-image-84710" height="850" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-GeForce_RTX_5080_Row-1680x850.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84710"&gt;&lt;em&gt;New row, who ‘dis?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Don’t let this cloud pass by. The Blackwell RTX upgrade is ready for gamers to secure their spots — no downloads, no hardware upgrades, just next-level gaming for the same $19.99 per month. Or members can choose to subscribe to the 12-month membership for $199.99 — providing more value at less than $17 a month.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Break Free With ‘Borderlands 4&lt;/b&gt;&lt;b&gt;&lt;i&gt;’&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84714"&gt;&lt;img alt="Borderlands 4 on GeForce NOW" class="size-large wp-image-84714" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-Borderlands_4-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84714"&gt;&lt;em&gt;Welcome to Border-LOL-lands.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready for a blast of chaos, color and fun as &lt;i&gt;Borderlands 4&lt;/i&gt; launches on GeForce NOW. The galaxy’s wildest looter shooter is back, sending four new Vault Hunters on a loot-crazed rampage jam-packed with quippy dialogue and sci-fi shenanigans, all wrapped in the franchise’s signature mayhem.&lt;/p&gt;
&lt;p&gt;Gameplay turns the dial to 11 with new double jumps, dashes, grappling hooks and air-glide moves that make every firefight a circus act. Experience a world with sprawling landscapes and nonstop dynamic events.&lt;/p&gt;
&lt;p&gt;Build the perfect Vault Hunter with deep skill trees and use different weapons — each with unique behaviors and effects, now with a revamped loot system where every Legendary feels special. Play it solo or with up to three friends.&lt;/p&gt;
&lt;p&gt;Play the frantic co-op looter shooter on GeForce NOW with the NVIDIA Blackwell RTX upgrade for cinematic-quality visuals, ultrafast load times and stunning performance. Enjoy NVIDIA DLSS 4-fueled graphics and low-latency gameplay streaming from GeForce RTX 5080 gaming rigs in the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84720"&gt;&lt;img alt="Borderlands 4 membership bundle on GeForce NOW" class="size-large wp-image-84720" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/social-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84720"&gt;&lt;em&gt;The cloud is the best way to play.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The title lands in the cloud on Thursday, Sept. 11. Gamers who upgrade to or purchase a 12-month GeForce NOW Ultimate membership — between now and Tuesday, Sept. 25 — will get the title for free, available to play as soon as it launches. Unleash chaos across the galaxy with outrageous weapons, irreverent humor and the signature co-op action that makes this iconic looter-shooter franchise a fan favorite.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Game On&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84728"&gt;&lt;img alt="Genshin Impact latest update on GeForce NOW" class="size-large wp-image-84728" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/genshin-impact-v6.0-tw-li-2048x1024-2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84728"&gt;&lt;em&gt;Set sail for moonlit mystery in Nod-Krai.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Genshin Impact&lt;/i&gt; “Version Luna I: Song of the Welkin Moon” is available to play instantly on GeForce NOW — no need to wait for downloads or updates. Head on a new adventure through the magical new region of Nod-Krai, where the story, exploration and battles are all shaped by the mysterious power of the moon. Play as three new characters — animal-loving Lauma, energetic Flins and inventive Aino — as they face off against rival factions, unravel secrets and wield creative new abilities in a world full of quirky creatures and vibrant islands. Plus, anniversary rewards await for everyone who jumps in.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Firefighting Simulator: Ignite&lt;/i&gt; (New release on Steam, Sept. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Borderlands 4 &lt;/i&gt;(New release on Steam and Epic Games Store, Sept. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Professional Fishing 2&lt;/i&gt; (New release on Steam, Sept. 11)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Keep your responses coming—win this bundle! 🎮&lt;/p&gt;
&lt;p&gt;🔥Steam Deck, @ASUS ROG Swift 27" 4K 240Hz G-SYNC Monitor, @Logitech G920 racing wheel, &amp;amp; more!🔥&lt;/p&gt;
&lt;p&gt;How to enter:&lt;br /&gt;1. Follow @NVIDIAGFN&lt;br /&gt;2. Reply using #BlackwellonGFN&lt;br /&gt;3. Share: What device are you turning into an RTX 5080 GPU? pic.twitter.com/TwSpTyFUze&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) September 8, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;GeForce NOW Blackwell RTX 5080-class SuperPODs are now rolling out, unlocking a new level of ultra high-performance, cinematic cloud gaming.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;GeForce NOW Ultimate members will see GeForce RTX 5080 performance arriving to a server near them, enabling even richer experiences in blockbuster titles like &lt;i&gt;DUNE: Awakening, Borderlands 4, Hell Is Us, Dying Light: The Beast, Cronos: The New Dawn, Clair Obscur: Expedition 33 &lt;/i&gt;and more.&lt;/p&gt;
&lt;p&gt;They all come with breathtaking graphics and lowest-latency gameplay, thanks to NVIDIA DLSS 4 technology and next-generation AI features. Experience the new Cinematic-Quality Streaming mode for stunning color and fidelity across the latest devices.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84701"&gt;&lt;img alt="Install-to-Play on GeForce NOW" class="size-large wp-image-84701" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-Install-to-Play-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84701"&gt;&lt;i&gt;Look at all the room for &lt;/i&gt;&lt;del&gt;&lt;i&gt;activities&lt;/i&gt;&lt;/del&gt;&lt;i&gt; &lt;/i&gt;&lt;i&gt;gaming.&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The new Install-to-Play feature is expanding the cloud library to nearly 4,500 games for Ultimate and Performance members.&lt;/p&gt;
&lt;p&gt;This week kicks it off with three new games, including the launch of &lt;i&gt;Borderlands 4. &lt;/i&gt;GeForce NOW is the ultimate way to play the &lt;i&gt;Borderlands &lt;/i&gt;franchise’s latest entry — free with the purchase of a new 12-month Ultimate membership bundle.&lt;/p&gt;
&lt;p&gt;Make sure to follow along on GFN Thursdays for server updates.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Blackwell to the Future&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84704"&gt;&lt;img alt="GeForce RTX 5080 power on GeForce NOW" class="size-large wp-image-84704" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-RTX_5080_upgrade-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84704"&gt;Game-changer.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The future of cloud gaming has arrived. With the NVIDIA Blackwell RTX upgrade, GeForce NOW brings GeForce RTX 5080-class performance to the cloud for the first time. Ultimate members can harness DLSS 4 Multi-Frame Generation, cutting-edge AI enhancements and ultralow click-to-pixel latency, enabling up to 5K at 120 frames per second for premium, responsive gameplay.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Members will also see the GeForce NOW library instantly double. Over 2,200 Steam titles opted in by publishers for cloud streaming are hitting the cloud today, with more to come, letting members build and manage their own cloud gaming library. Alongside new Install-to-Play titles, GeForce NOW will continue to roll out ready-to-play titles each week.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84707"&gt;&lt;img alt="Blackwell RTX rollout on GeForce NOW" class="size-large wp-image-84707" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/social-post-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84707"&gt;&lt;em&gt;Coming to a zone near you.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA Blackwell RTX servers are starting to power up worldwide, so more members can start streaming with unprecedented performance on virtually any device, including PCs, Macs, Chromebooks, LG TVs (4K at 120Hz) and even Steam Decks (now up to 90 fps). Keep an eye on GFN Thursday updates and check the server rollout webpage for new regions going live.&lt;/p&gt;
&lt;p&gt;Ultimate members will soon see GeForce RTX 5080 performance in their area, with AAA titles like &lt;i&gt;DUNE: Awakening, Borderlands 4&lt;/i&gt;, &lt;i&gt;Hell Is Us, Dying Light: The Beast&lt;/i&gt;, &lt;i&gt;Cronos: The New Dawn&lt;/i&gt;, &lt;i&gt;Clair Obscur: Expedition 33&lt;/i&gt; and more playable at ultimate quality. Look for the new “GeForce RTX 5080 Ready” row in the app for the full list of GeForce RTX 5080-optimized games, updated weekly with fresh additions.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84710"&gt;&lt;img alt="GeForce RTX 5080 ready games on GeForce NOW" class="size-large wp-image-84710" height="850" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-GeForce_RTX_5080_Row-1680x850.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84710"&gt;&lt;em&gt;New row, who ‘dis?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Don’t let this cloud pass by. The Blackwell RTX upgrade is ready for gamers to secure their spots — no downloads, no hardware upgrades, just next-level gaming for the same $19.99 per month. Or members can choose to subscribe to the 12-month membership for $199.99 — providing more value at less than $17 a month.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Break Free With ‘Borderlands 4&lt;/b&gt;&lt;b&gt;&lt;i&gt;’&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84714"&gt;&lt;img alt="Borderlands 4 on GeForce NOW" class="size-large wp-image-84714" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/GFN_Thursday-Borderlands_4-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84714"&gt;&lt;em&gt;Welcome to Border-LOL-lands.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready for a blast of chaos, color and fun as &lt;i&gt;Borderlands 4&lt;/i&gt; launches on GeForce NOW. The galaxy’s wildest looter shooter is back, sending four new Vault Hunters on a loot-crazed rampage jam-packed with quippy dialogue and sci-fi shenanigans, all wrapped in the franchise’s signature mayhem.&lt;/p&gt;
&lt;p&gt;Gameplay turns the dial to 11 with new double jumps, dashes, grappling hooks and air-glide moves that make every firefight a circus act. Experience a world with sprawling landscapes and nonstop dynamic events.&lt;/p&gt;
&lt;p&gt;Build the perfect Vault Hunter with deep skill trees and use different weapons — each with unique behaviors and effects, now with a revamped loot system where every Legendary feels special. Play it solo or with up to three friends.&lt;/p&gt;
&lt;p&gt;Play the frantic co-op looter shooter on GeForce NOW with the NVIDIA Blackwell RTX upgrade for cinematic-quality visuals, ultrafast load times and stunning performance. Enjoy NVIDIA DLSS 4-fueled graphics and low-latency gameplay streaming from GeForce RTX 5080 gaming rigs in the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84720"&gt;&lt;img alt="Borderlands 4 membership bundle on GeForce NOW" class="size-large wp-image-84720" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/social-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84720"&gt;&lt;em&gt;The cloud is the best way to play.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The title lands in the cloud on Thursday, Sept. 11. Gamers who upgrade to or purchase a 12-month GeForce NOW Ultimate membership — between now and Tuesday, Sept. 25 — will get the title for free, available to play as soon as it launches. Unleash chaos across the galaxy with outrageous weapons, irreverent humor and the signature co-op action that makes this iconic looter-shooter franchise a fan favorite.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Game On&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84728"&gt;&lt;img alt="Genshin Impact latest update on GeForce NOW" class="size-large wp-image-84728" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/genshin-impact-v6.0-tw-li-2048x1024-2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84728"&gt;&lt;em&gt;Set sail for moonlit mystery in Nod-Krai.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Genshin Impact&lt;/i&gt; “Version Luna I: Song of the Welkin Moon” is available to play instantly on GeForce NOW — no need to wait for downloads or updates. Head on a new adventure through the magical new region of Nod-Krai, where the story, exploration and battles are all shaped by the mysterious power of the moon. Play as three new characters — animal-loving Lauma, energetic Flins and inventive Aino — as they face off against rival factions, unravel secrets and wield creative new abilities in a world full of quirky creatures and vibrant islands. Plus, anniversary rewards await for everyone who jumps in.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Firefighting Simulator: Ignite&lt;/i&gt; (New release on Steam, Sept. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Borderlands 4 &lt;/i&gt;(New release on Steam and Epic Games Store, Sept. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Professional Fishing 2&lt;/i&gt; (New release on Steam, Sept. 11)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Keep your responses coming—win this bundle! 🎮&lt;/p&gt;
&lt;p&gt;🔥Steam Deck, @ASUS ROG Swift 27" 4K 240Hz G-SYNC Monitor, @Logitech G920 racing wheel, &amp;amp; more!🔥&lt;/p&gt;
&lt;p&gt;How to enter:&lt;br /&gt;1. Follow @NVIDIAGFN&lt;br /&gt;2. Reply using #BlackwellonGFN&lt;br /&gt;3. Share: What device are you turning into an RTX 5080 GPU? pic.twitter.com/TwSpTyFUze&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) September 8, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-blackwell-rtx-launch/</guid><pubDate>Wed, 10 Sep 2025 13:00:06 +0000</pubDate></item><item><title>[NEW] RSS co-creator launches new protocol for AI data licensing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/rss-co-creator-launches-new-protocol-for-ai-data-licensing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/04/GettyImages-1300100763.jpg?resize=1200,735" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In the wake of Anthropic’s $1.5 billion copyright settlement, the AI industry is coming to terms with its training data problem. There are as many as 40 other pending cases that seek damages for unlicensed data — including one that takes Midjourney to court for creating images of Superman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without some kind of licensing system, AI companies could face an avalanche of copyright lawsuits that some worry will set the industry back permanently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now a group of technologists and web publishers has launched a system that would enable data licensing at massive scale — provided AI companies take them up on it. Called Real Simple Licensing (RSL), the system is already being backed by major web publishers like Reddit, Quora, and Yahoo. The question now is whether that momentum will be enough to bring major AI labs to the bargaining table.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to RSL co-founder Eckart Walther, who also co-created the RSS standard, the goal was to create a training-data licensing system that could scale across the internet. “We need to have machine-readable licensing agreements for the internet,” Walther told TechCrunch. “That’s really what RSL solves.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For years, groups like the Dataset Providers Alliance have been pushing for clearer collection practices, but RSL is the first attempt at a technical and legal infrastructure that could make it work in practice. On the technical side, the RSL Protocol lays out specific licensing terms a publisher can set for their content, whether that means AI companies need a custom license or to adopt Creative Commons provisions. Participating websites will include the terms as part of their “robots.txt” file in a prearranged format, making it straightforward to identify which data falls under which terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the legal side, the RSL team has established a collective licensing organization, the RSL Collective, that can negotiate terms and collect royalties, similar to ASCAP for musicians or MPLC for films. As in music and film, the goal is to give licensors a single point of contact for paying royalties and provide rights holders a way to set terms with dozens of potential licensors at once.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A host of web publishers have already joined the collective, including Yahoo, Reddit, Medium, O’Reilly Media, Ziff Davis (owner of Mashable and Cnet), Internet Brands (owner of WebMD), People Inc., and The Daily Beast. Others, like Fastly, Quora, and Adweek, are supporting the standard without joining the collective.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the RSL Collective includes some publishers that already have licensing deals — most notably Reddit, which receives an estimated $60 million a year from Google for use of its training data. There’s nothing stopping companies from cutting their own deals within the RSL system, just as Taylor Swift can set special terms for licensing while still collecting royalties through ASCAP. But for publishers too small to draw their own deals, RSL’s collective terms are likely to be the only option.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while it’s easy enough to determine when a song has been played, AI models pose unique challenges when it comes to figuring out when royalties are due for a specific piece of training data. The issue is simplest for a product like Google’s AI Search Abstracts, which draw data from the web in real time and maintain strict attribution for each fact. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if training isn’t logged when it occurs, it can be nearly impossible to confirm that a given document was ingested into an LLM. It’s particularly challenging if publishers ask to be paid per inference rather than receiving a blanket fee, an option offered by one of the stock RSL licenses.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, RSL’s creators believe AI companies will be able to manage the difficulty. “Some of the licensing agreements they’ve already done have required them to be able to report on it, so it’s possible,” says Doug Leeds, a co-founder of RSL and former CEO of IAC Publishing. “It doesn’t have to be perfect. It just has to be good enough to get people paid.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bigger question is whether AI companies will embrace the system. As the success of companies like ScaleAI and Mercor shows, frontier labs have no problem paying for data, but the web has traditionally been seen as a source for cheap, low-quality data. With datasets like the Common Crawl already available, it may be a challenge to extract royalties from something labs are used to getting for free. And as the recent dustup between Cloudflare and Perplexity shows, it’s not straightforward to tell the difference between web-scraping and machine-enhanced browsing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When I put the question to Leeds, he pointed to recent comments from AI leaders calling for a system like RSL — most notably from Sundar Pichai at last year’s Dealbook Summit. Whether the calls for a licensing system are earnest or not, the RSL team plans to hold them to it. “They have said outwardly to everyone, something like this needs to exist,” Leeds told me. “We need a protocol. We need a system.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now they may get one.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/04/GettyImages-1300100763.jpg?resize=1200,735" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In the wake of Anthropic’s $1.5 billion copyright settlement, the AI industry is coming to terms with its training data problem. There are as many as 40 other pending cases that seek damages for unlicensed data — including one that takes Midjourney to court for creating images of Superman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without some kind of licensing system, AI companies could face an avalanche of copyright lawsuits that some worry will set the industry back permanently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now a group of technologists and web publishers has launched a system that would enable data licensing at massive scale — provided AI companies take them up on it. Called Real Simple Licensing (RSL), the system is already being backed by major web publishers like Reddit, Quora, and Yahoo. The question now is whether that momentum will be enough to bring major AI labs to the bargaining table.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to RSL co-founder Eckart Walther, who also co-created the RSS standard, the goal was to create a training-data licensing system that could scale across the internet. “We need to have machine-readable licensing agreements for the internet,” Walther told TechCrunch. “That’s really what RSL solves.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For years, groups like the Dataset Providers Alliance have been pushing for clearer collection practices, but RSL is the first attempt at a technical and legal infrastructure that could make it work in practice. On the technical side, the RSL Protocol lays out specific licensing terms a publisher can set for their content, whether that means AI companies need a custom license or to adopt Creative Commons provisions. Participating websites will include the terms as part of their “robots.txt” file in a prearranged format, making it straightforward to identify which data falls under which terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the legal side, the RSL team has established a collective licensing organization, the RSL Collective, that can negotiate terms and collect royalties, similar to ASCAP for musicians or MPLC for films. As in music and film, the goal is to give licensors a single point of contact for paying royalties and provide rights holders a way to set terms with dozens of potential licensors at once.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A host of web publishers have already joined the collective, including Yahoo, Reddit, Medium, O’Reilly Media, Ziff Davis (owner of Mashable and Cnet), Internet Brands (owner of WebMD), People Inc., and The Daily Beast. Others, like Fastly, Quora, and Adweek, are supporting the standard without joining the collective.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the RSL Collective includes some publishers that already have licensing deals — most notably Reddit, which receives an estimated $60 million a year from Google for use of its training data. There’s nothing stopping companies from cutting their own deals within the RSL system, just as Taylor Swift can set special terms for licensing while still collecting royalties through ASCAP. But for publishers too small to draw their own deals, RSL’s collective terms are likely to be the only option.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while it’s easy enough to determine when a song has been played, AI models pose unique challenges when it comes to figuring out when royalties are due for a specific piece of training data. The issue is simplest for a product like Google’s AI Search Abstracts, which draw data from the web in real time and maintain strict attribution for each fact. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if training isn’t logged when it occurs, it can be nearly impossible to confirm that a given document was ingested into an LLM. It’s particularly challenging if publishers ask to be paid per inference rather than receiving a blanket fee, an option offered by one of the stock RSL licenses.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, RSL’s creators believe AI companies will be able to manage the difficulty. “Some of the licensing agreements they’ve already done have required them to be able to report on it, so it’s possible,” says Doug Leeds, a co-founder of RSL and former CEO of IAC Publishing. “It doesn’t have to be perfect. It just has to be good enough to get people paid.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bigger question is whether AI companies will embrace the system. As the success of companies like ScaleAI and Mercor shows, frontier labs have no problem paying for data, but the web has traditionally been seen as a source for cheap, low-quality data. With datasets like the Common Crawl already available, it may be a challenge to extract royalties from something labs are used to getting for free. And as the recent dustup between Cloudflare and Perplexity shows, it’s not straightforward to tell the difference between web-scraping and machine-enhanced browsing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When I put the question to Leeds, he pointed to recent comments from AI leaders calling for a system like RSL — most notably from Sundar Pichai at last year’s Dealbook Summit. Whether the calls for a licensing system are earnest or not, the RSL team plans to hold them to it. “They have said outwardly to everyone, something like this needs to exist,” Leeds told me. “We need a protocol. We need a system.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now they may get one.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/rss-co-creator-launches-new-protocol-for-ai-data-licensing/</guid><pubDate>Wed, 10 Sep 2025 13:07:26 +0000</pubDate></item><item><title>[NEW] AI vs. MAGA: Populists alarmed by Trump’s embrace of AI, Big Tech (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/ai-vs-maga-populists-alarmed-by-trumps-embrace-of-ai-big-tech/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI “threatens the common man’s liberty," says GOP Sen. Josh Hawley.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Picture of white house dinner" class="absolute inset-0 w-full h-full object-cover hidden" height="213" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/dinner-640x213.jpg" width="640" /&gt;
                  &lt;img alt="Picture of white house dinner" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/dinner-1152x640.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      President Donald Trump and first lady Melania Trump host a private dinner for technology and business leaders at the White House earlier this month.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Brian Snyder/Reuters

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Flanked by Silicon Valley’s most powerful executives in the White House last week, Melania Trump hailed artificial intelligence as potentially “the greatest engine of progress in the history of the United States of America.”&lt;/p&gt;
&lt;p&gt;Less than a mile from the first lady, in a hotel ballroom packed with MAGA faithful, top Republican Josh Hawley had a different message.&lt;/p&gt;
&lt;p&gt;AI “threatens the common man’s liberty” and could even undermine the Republic itself, the senior US senator from Missouri said.&lt;/p&gt;
&lt;p&gt;“The problem with the AI revolution as it’s currently going is that it only entrenches the power of the people who are already the most powerful people in the world,” he said. “The goal is to replace... the farmer, the assembly line man, the construction worker.”&lt;/p&gt;
&lt;p&gt;Hawley is a frequent critic of Big Tech. But his comments are endorsed by a growing chorus on America’s right—even as President Donald Trump’s administration scraps regulatory barriers and accelerates AI’s adoption across the land.&lt;/p&gt;
&lt;p&gt;It presages an unexpected clash at the heart of the MAGA world.&lt;/p&gt;
&lt;p&gt;Evangelical pastors, political strategists, and academics gathered at the recent National Conservatism Conference—the MAGA movement’s ideological nerve center—were full of contempt for the technology.&lt;/p&gt;
&lt;p&gt;“There’s a lot of people who are basically worried about... what actually is going to happen to unemployment and families and the culture and education with advanced AI, even if it doesn’t make it to artificial superintelligence,” said Geoffrey Miller, an evolutionary psychologist who spoke on a panel at the conference.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The “AI industry shares virtually no ideological overlaps with national conservatism,” he said.&lt;/p&gt;
&lt;p&gt;Attendees came from groups that helped shape the Trump administration’s policy platform but were “overwhelmingly positive” about the speech, Miller said. “There’s a lot of people [who were] just like, what do I read to learn more?”&lt;/p&gt;
&lt;p&gt;Some on the MAGA right have long been skeptical of Big Tech’s conversion to Trump.&lt;/p&gt;
&lt;p&gt;Former White House chief strategist Steve Bannon has called for Mark Zuckerberg—who sat next to Trump at a recent White House dinner with other AI leaders—to be jailed for using his Facebook platform to help Democrats.&lt;/p&gt;
&lt;p&gt;But AI’s rise has given the skeptics another cudgel with which to beat Silicon Valley elites.&lt;/p&gt;
&lt;p&gt;A warning by Anthropic chief executive Dario Amodei that AI could wipe out half of all entry-level, white-collar jobs within five years was seized upon by some on the right, who called for Trump to constrain the technology.&lt;/p&gt;
&lt;p&gt;Christian conservatives fear that the kind of companionship offered by AI bots will damage society or even dissuade people from marrying. They also worry about AI pornography and the use of the technology to “undress” humans.&lt;/p&gt;
&lt;p&gt;The conservative pushback intensified after reports of people committing murder and teenagers dying by suicide after prolonged interactions with chatbots including OpenAI’s ChatGPT.&lt;/p&gt;
&lt;p&gt;The company is being sued by the family of Adam Raine, a 16-year-old who killed himself in April after seeking mental health support from the product. Raine’s family claim the chatbot even provided tips on the best materials for a noose. (Following the filing, OpenAI announced new safety protocols for teens on ChatGPT.)&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Conservative media figures, including Megyn Kelly, decried the incident as “horrific.” Mike Davis, a Trump ally who helped push his Supreme Court nominees through the US Senate, urged people to “watch and remember” a TV interview with Raine’s parents, “when the AI oligarchs go begging Congress again” for legal relief.&lt;/p&gt;
&lt;p&gt;An initial sign of the AI backlash on the right came this summer when Bannon and Davies convinced Republicans to scrap part of Trump’s “big, beautiful, bill” that would have stopped states regulating AI themselves.&lt;/p&gt;
&lt;p&gt;The AI industry had lobbied hard for the moratorium, saying it would give the sector legal clarity.&lt;/p&gt;
&lt;p&gt;Polling showed that the skeptics on the right better understood the country’s mood. A YouGov survey found that more than 55 percent of voters objected to the provision, rising to 70 percent of 18- to 34-year-olds.&lt;/p&gt;
&lt;p&gt;“Even the bill sponsor Senator Ted Cruz... voted against his own moratorium, because it was quite clear that the winds had shifted so forcefully in another direction, there was no resisting it,” said Michael Toscano, the director of the Family First Technology Initiative at the Institute of Family Studies. He has described AI as a “malicious technology.”&lt;/p&gt;
&lt;p&gt;The defeat of the moratorium was “a major moment in American technology policy,” said Adam Thierer, a senior fellow at the R Street Institute, which pushes for free-market policies.&lt;/p&gt;
&lt;p&gt;Despite the Trump administration’s embrace of Big Tech—with boosters such as Silicon Valley investor David Sacks directing AI policy for the president—animus on the right was building, said Thierer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Some Republicans are still angry over the deplatforming of Trump by tech executives once known for their progressive politics. They had been joined by a “vocal and growing group of conservatives who are fundamentally suspicious of the benefits of technological innovation,” Thierer said.&lt;/p&gt;
&lt;p&gt;With MAGA skeptics on one side and Big Tech allies of the president on the other, a “battle for the soul of the conservative movement” is under way.&lt;/p&gt;
&lt;p&gt;Popular resentment is now a threat to Trump’s Republican Party, warn some of its biggest supporters—especially if AI begins displacing jobs as many of its exponents suggest.&lt;/p&gt;
&lt;p&gt;“You can displace farm workers—what are they going to do about it? You can displace factory workers—they will just kill themselves with drugs and fast food,” Tucker Carlson, one of the MAGA movement's most prominent media figures, told a tech conference on Monday.&lt;/p&gt;
&lt;p&gt;“If you do that to lawyers and non-profit sector employees, you will get a revolution.”&lt;/p&gt;
&lt;p&gt;It made Trump’s embrace of Silicon Valley bosses a “significant risk” for his administration ahead of next year’s midterm elections, a leading Republican strategist said.&lt;/p&gt;
&lt;p&gt;“It’s a real double-edged sword—the administration is forced to embrace [AI] because if the US is not the leader in AI, China will be,” the strategist said, echoing the kind of argument made by Sacks and fellow Trump adviser Michael Kratsios for their AI policy platform.&lt;/p&gt;
&lt;p&gt;“But you could see unemployment spiking over the next year,” the strategist said.&lt;/p&gt;
&lt;p&gt;Other MAGA supporters are urging Trump to tone down at least his public cheerleading for an AI sector so many of them consider a threat.&lt;/p&gt;
&lt;p&gt;“The pressure that is being placed on conservatives to fall in line... is a recipe for discontent,” said Toscano.&lt;/p&gt;
&lt;p&gt;By courting AI bosses, the Republican Party, which claims to represent the pro-family movement, religious communities, and American workers, appeared to be embracing those who are antithetical to all of those groups, he warned.&lt;/p&gt;
&lt;p&gt;“The current view of things suggests that the most important members of the party are those that are from Silicon Valley,” Toscano said.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Cristina Criddle in San Francisco.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI “threatens the common man’s liberty," says GOP Sen. Josh Hawley.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Picture of white house dinner" class="absolute inset-0 w-full h-full object-cover hidden" height="213" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/dinner-640x213.jpg" width="640" /&gt;
                  &lt;img alt="Picture of white house dinner" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/dinner-1152x640.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      President Donald Trump and first lady Melania Trump host a private dinner for technology and business leaders at the White House earlier this month.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Brian Snyder/Reuters

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Flanked by Silicon Valley’s most powerful executives in the White House last week, Melania Trump hailed artificial intelligence as potentially “the greatest engine of progress in the history of the United States of America.”&lt;/p&gt;
&lt;p&gt;Less than a mile from the first lady, in a hotel ballroom packed with MAGA faithful, top Republican Josh Hawley had a different message.&lt;/p&gt;
&lt;p&gt;AI “threatens the common man’s liberty” and could even undermine the Republic itself, the senior US senator from Missouri said.&lt;/p&gt;
&lt;p&gt;“The problem with the AI revolution as it’s currently going is that it only entrenches the power of the people who are already the most powerful people in the world,” he said. “The goal is to replace... the farmer, the assembly line man, the construction worker.”&lt;/p&gt;
&lt;p&gt;Hawley is a frequent critic of Big Tech. But his comments are endorsed by a growing chorus on America’s right—even as President Donald Trump’s administration scraps regulatory barriers and accelerates AI’s adoption across the land.&lt;/p&gt;
&lt;p&gt;It presages an unexpected clash at the heart of the MAGA world.&lt;/p&gt;
&lt;p&gt;Evangelical pastors, political strategists, and academics gathered at the recent National Conservatism Conference—the MAGA movement’s ideological nerve center—were full of contempt for the technology.&lt;/p&gt;
&lt;p&gt;“There’s a lot of people who are basically worried about... what actually is going to happen to unemployment and families and the culture and education with advanced AI, even if it doesn’t make it to artificial superintelligence,” said Geoffrey Miller, an evolutionary psychologist who spoke on a panel at the conference.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The “AI industry shares virtually no ideological overlaps with national conservatism,” he said.&lt;/p&gt;
&lt;p&gt;Attendees came from groups that helped shape the Trump administration’s policy platform but were “overwhelmingly positive” about the speech, Miller said. “There’s a lot of people [who were] just like, what do I read to learn more?”&lt;/p&gt;
&lt;p&gt;Some on the MAGA right have long been skeptical of Big Tech’s conversion to Trump.&lt;/p&gt;
&lt;p&gt;Former White House chief strategist Steve Bannon has called for Mark Zuckerberg—who sat next to Trump at a recent White House dinner with other AI leaders—to be jailed for using his Facebook platform to help Democrats.&lt;/p&gt;
&lt;p&gt;But AI’s rise has given the skeptics another cudgel with which to beat Silicon Valley elites.&lt;/p&gt;
&lt;p&gt;A warning by Anthropic chief executive Dario Amodei that AI could wipe out half of all entry-level, white-collar jobs within five years was seized upon by some on the right, who called for Trump to constrain the technology.&lt;/p&gt;
&lt;p&gt;Christian conservatives fear that the kind of companionship offered by AI bots will damage society or even dissuade people from marrying. They also worry about AI pornography and the use of the technology to “undress” humans.&lt;/p&gt;
&lt;p&gt;The conservative pushback intensified after reports of people committing murder and teenagers dying by suicide after prolonged interactions with chatbots including OpenAI’s ChatGPT.&lt;/p&gt;
&lt;p&gt;The company is being sued by the family of Adam Raine, a 16-year-old who killed himself in April after seeking mental health support from the product. Raine’s family claim the chatbot even provided tips on the best materials for a noose. (Following the filing, OpenAI announced new safety protocols for teens on ChatGPT.)&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Conservative media figures, including Megyn Kelly, decried the incident as “horrific.” Mike Davis, a Trump ally who helped push his Supreme Court nominees through the US Senate, urged people to “watch and remember” a TV interview with Raine’s parents, “when the AI oligarchs go begging Congress again” for legal relief.&lt;/p&gt;
&lt;p&gt;An initial sign of the AI backlash on the right came this summer when Bannon and Davies convinced Republicans to scrap part of Trump’s “big, beautiful, bill” that would have stopped states regulating AI themselves.&lt;/p&gt;
&lt;p&gt;The AI industry had lobbied hard for the moratorium, saying it would give the sector legal clarity.&lt;/p&gt;
&lt;p&gt;Polling showed that the skeptics on the right better understood the country’s mood. A YouGov survey found that more than 55 percent of voters objected to the provision, rising to 70 percent of 18- to 34-year-olds.&lt;/p&gt;
&lt;p&gt;“Even the bill sponsor Senator Ted Cruz... voted against his own moratorium, because it was quite clear that the winds had shifted so forcefully in another direction, there was no resisting it,” said Michael Toscano, the director of the Family First Technology Initiative at the Institute of Family Studies. He has described AI as a “malicious technology.”&lt;/p&gt;
&lt;p&gt;The defeat of the moratorium was “a major moment in American technology policy,” said Adam Thierer, a senior fellow at the R Street Institute, which pushes for free-market policies.&lt;/p&gt;
&lt;p&gt;Despite the Trump administration’s embrace of Big Tech—with boosters such as Silicon Valley investor David Sacks directing AI policy for the president—animus on the right was building, said Thierer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Some Republicans are still angry over the deplatforming of Trump by tech executives once known for their progressive politics. They had been joined by a “vocal and growing group of conservatives who are fundamentally suspicious of the benefits of technological innovation,” Thierer said.&lt;/p&gt;
&lt;p&gt;With MAGA skeptics on one side and Big Tech allies of the president on the other, a “battle for the soul of the conservative movement” is under way.&lt;/p&gt;
&lt;p&gt;Popular resentment is now a threat to Trump’s Republican Party, warn some of its biggest supporters—especially if AI begins displacing jobs as many of its exponents suggest.&lt;/p&gt;
&lt;p&gt;“You can displace farm workers—what are they going to do about it? You can displace factory workers—they will just kill themselves with drugs and fast food,” Tucker Carlson, one of the MAGA movement's most prominent media figures, told a tech conference on Monday.&lt;/p&gt;
&lt;p&gt;“If you do that to lawyers and non-profit sector employees, you will get a revolution.”&lt;/p&gt;
&lt;p&gt;It made Trump’s embrace of Silicon Valley bosses a “significant risk” for his administration ahead of next year’s midterm elections, a leading Republican strategist said.&lt;/p&gt;
&lt;p&gt;“It’s a real double-edged sword—the administration is forced to embrace [AI] because if the US is not the leader in AI, China will be,” the strategist said, echoing the kind of argument made by Sacks and fellow Trump adviser Michael Kratsios for their AI policy platform.&lt;/p&gt;
&lt;p&gt;“But you could see unemployment spiking over the next year,” the strategist said.&lt;/p&gt;
&lt;p&gt;Other MAGA supporters are urging Trump to tone down at least his public cheerleading for an AI sector so many of them consider a threat.&lt;/p&gt;
&lt;p&gt;“The pressure that is being placed on conservatives to fall in line... is a recipe for discontent,” said Toscano.&lt;/p&gt;
&lt;p&gt;By courting AI bosses, the Republican Party, which claims to represent the pro-family movement, religious communities, and American workers, appeared to be embracing those who are antithetical to all of those groups, he warned.&lt;/p&gt;
&lt;p&gt;“The current view of things suggests that the most important members of the party are those that are from Silicon Valley,” Toscano said.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Cristina Criddle in San Francisco.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/ai-vs-maga-populists-alarmed-by-trumps-embrace-of-ai-big-tech/</guid><pubDate>Wed, 10 Sep 2025 13:41:17 +0000</pubDate></item><item><title>[NEW] After selling to Spotify, Anchor’s co-founders are back with Oboe, an AI-powered app for learning (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/after-selling-to-spotify-anchors-co-founders-are-back-with-oboe-an-ai-powered-app-for-learning/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The co-founders who sold their last startup Anchor to Spotify are launching their next project: Oboe, an AI-powered educational app that enables anyone to create lightweight, flexible learning courses on nearly any topic they choose, simply by entering a prompt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These courses can span a variety of verticals, including topics like science, history, foreign language, news, pop culture, preparing for life changes, and more. At launch, Oboe — a name inspired by the root of the Japanese word meaning “to learn” — will offer nine different course formats. These allow users to learn in the way they prefer, Oboe co-founder Nir Zicherman explained to TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zicherman founded the company along with Anchor co-founder Michael Mignano after leaving Spotify in October 2023 and taking a brief period to recharge. Zicherman said he was inspired to work on an AI educational product after working to scale Spotify’s audiobooks business, which made it easier for people to gain access to high-quality and educational content, as it was bundled with their music subscription.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike AI chatbots, you don’t have to engage in back-and-forth conversations to learn with Oboe. Instead, you can opt for text and visuals, audio courses, games, interactive tests, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For those who want to learn on the go, Oboe offers two audio formats. One feels more like listening to a university-style lecture, while the other is akin to Google’s podcast-like NotebookLM, as it features two hosts talking in depth about the topic.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="a pair of screenshots showing the Oboe app" class="wp-image-3044805" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/OboeScreenshot1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Oboe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The real magic here comes from an internal architecture that we’ve built that I would describe as a complex, multi-agent architecture that we built from scratch, each part of which is orchestrated to run in parallel as we generate a course,” Zicherman says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The challenge is, how do you create courses that are both high quality, entirely personalized to what the user wants to see, and also get generated extremely quickly? This all happens within seconds,” he says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have agents that, in parallel, are responsible for everything from developing the course architecture to developing and verifying the base material that’s being taught, writing the script for the podcast, pulling in real images from the internet — not AI-generated images, but real images and visuals into the reading formats that we offer,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of Oboe’s agents audit the content to ensure the courses are accurate, high-quality, and personalized to what the user wants to learn. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="another pair of screenshots showing a deep dive and podcast episode in the Oboe app." class="wp-image-3044806" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/OboeScreenshot2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Oboe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The courses are meant to be lightweight, engaging, and fun. Plus, Oboe’s team is working on a recommendation engine that will help you continually go deeper on a topic, if you prefer. That leaves it up to the user as to whether they want to gain some surface-level knowledge about a new topic or whether they want to get more in-depth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This, combined with the variety of formats, will help Oboe appeal to a broader audience, the team believes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To me, education conjures up images of more formal academic settings and the types of prescriptive curricula that students are used to as they grow up,” Zicherman tells TechCrunch. “But the truth is, we are all lifelong learners&amp;nbsp;… So much of the time that we spend on the internet these days is spent trying to better understand things, but the truth is that the internet was built to grab our attention, not to teach effectively.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re very excited to build a platform that is intended to be the one-stop shop to serve that intrinsic thirst for knowledge that exists in every person,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, users can consume any course created by others for free and can create up to five free courses per month. After that, there are two paid tiers: Oboe Plus, which offers 30 additional courses for $15 per month, and Oboe Pro, which offers 100 courses for $40 per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The service will first be available on the web (and mobile web), but native apps for iOS and Android are on the way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oboe is a team of five full-time, including Zicherman. Mignano remains a full-time partner at VC firm Lightspeed but sits on Oboe’s board and shares the co-founder title.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s $4 million seed round was led by Eniac Ventures, the VC firm that led Anchor’s seed. The round also includes investment from Haystack, Factorial Capital, Homebrew, Offline Ventures, Scott Belsky, Kayvon Beykpour, Nikita Bier, Tim Ferriss, and Matt Lieber.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The co-founders who sold their last startup Anchor to Spotify are launching their next project: Oboe, an AI-powered educational app that enables anyone to create lightweight, flexible learning courses on nearly any topic they choose, simply by entering a prompt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These courses can span a variety of verticals, including topics like science, history, foreign language, news, pop culture, preparing for life changes, and more. At launch, Oboe — a name inspired by the root of the Japanese word meaning “to learn” — will offer nine different course formats. These allow users to learn in the way they prefer, Oboe co-founder Nir Zicherman explained to TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zicherman founded the company along with Anchor co-founder Michael Mignano after leaving Spotify in October 2023 and taking a brief period to recharge. Zicherman said he was inspired to work on an AI educational product after working to scale Spotify’s audiobooks business, which made it easier for people to gain access to high-quality and educational content, as it was bundled with their music subscription.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike AI chatbots, you don’t have to engage in back-and-forth conversations to learn with Oboe. Instead, you can opt for text and visuals, audio courses, games, interactive tests, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For those who want to learn on the go, Oboe offers two audio formats. One feels more like listening to a university-style lecture, while the other is akin to Google’s podcast-like NotebookLM, as it features two hosts talking in depth about the topic.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="a pair of screenshots showing the Oboe app" class="wp-image-3044805" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/OboeScreenshot1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Oboe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The real magic here comes from an internal architecture that we’ve built that I would describe as a complex, multi-agent architecture that we built from scratch, each part of which is orchestrated to run in parallel as we generate a course,” Zicherman says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The challenge is, how do you create courses that are both high quality, entirely personalized to what the user wants to see, and also get generated extremely quickly? This all happens within seconds,” he says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have agents that, in parallel, are responsible for everything from developing the course architecture to developing and verifying the base material that’s being taught, writing the script for the podcast, pulling in real images from the internet — not AI-generated images, but real images and visuals into the reading formats that we offer,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of Oboe’s agents audit the content to ensure the courses are accurate, high-quality, and personalized to what the user wants to learn. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="another pair of screenshots showing a deep dive and podcast episode in the Oboe app." class="wp-image-3044806" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/OboeScreenshot2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Oboe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The courses are meant to be lightweight, engaging, and fun. Plus, Oboe’s team is working on a recommendation engine that will help you continually go deeper on a topic, if you prefer. That leaves it up to the user as to whether they want to gain some surface-level knowledge about a new topic or whether they want to get more in-depth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This, combined with the variety of formats, will help Oboe appeal to a broader audience, the team believes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To me, education conjures up images of more formal academic settings and the types of prescriptive curricula that students are used to as they grow up,” Zicherman tells TechCrunch. “But the truth is, we are all lifelong learners&amp;nbsp;… So much of the time that we spend on the internet these days is spent trying to better understand things, but the truth is that the internet was built to grab our attention, not to teach effectively.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re very excited to build a platform that is intended to be the one-stop shop to serve that intrinsic thirst for knowledge that exists in every person,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, users can consume any course created by others for free and can create up to five free courses per month. After that, there are two paid tiers: Oboe Plus, which offers 30 additional courses for $15 per month, and Oboe Pro, which offers 100 courses for $40 per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The service will first be available on the web (and mobile web), but native apps for iOS and Android are on the way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oboe is a team of five full-time, including Zicherman. Mignano remains a full-time partner at VC firm Lightspeed but sits on Oboe’s board and shares the co-founder title.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s $4 million seed round was led by Eniac Ventures, the VC firm that led Anchor’s seed. The round also includes investment from Haystack, Factorial Capital, Homebrew, Offline Ventures, Scott Belsky, Kayvon Beykpour, Nikita Bier, Tim Ferriss, and Matt Lieber.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/after-selling-to-spotify-anchors-co-founders-are-back-with-oboe-an-ai-powered-app-for-learning/</guid><pubDate>Wed, 10 Sep 2025 14:27:55 +0000</pubDate></item><item><title>[NEW] Exploring the future of voice AI with Mati Staniszewski at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/exploring-the-future-of-voice-ai-with-mati-staniszewski-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Synthetic speech is no longer the stuff of science fiction. From audiobooks and dubbing to gaming and avatars, AI-generated voice is breaking into the mainstream — and &lt;strong&gt;Mati Staniszewski&lt;/strong&gt;, CEO and co-founder of ElevenLabs, is helping lead the charge. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, he’ll take the stage to talk about what it takes to make voice AI truly human.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Mati Staniszewski" class="wp-image-3025392" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Mati-Staniszewski-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-shaping-the-future-of-sound"&gt;&lt;br /&gt;&lt;strong&gt;Shaping the future of sound&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs has quickly become a key player in the generative AI space, known for pushing the boundaries of synthetic voice technology. In this session, Mati will explore how ElevenLabs built a platform that can replicate natural speech with remarkable nuance and realism — and why that opens the door to new possibilities across entertainment, accessibility, education, and creative storytelling.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Voice is one of the most personal, expressive human traits. Creating AI that can replicate it accurately — and ethically — presents unique technical and social challenges. This conversation will unpack those challenges, explore real-world use cases, and look ahead at how AI voice tools will shape the way we listen, learn, and connect.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-this-ai-session-and-the-savings"&gt;Don’t miss this AI session and the savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000 startup and VC leaders at Disrupt 2025 for bold conversations shaping the future of AI — and breakthroughs across five industry-specific stages. Get your ticket now and &lt;strong&gt;save up to $668&lt;/strong&gt;. Prices go up after September 26.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Synthetic speech is no longer the stuff of science fiction. From audiobooks and dubbing to gaming and avatars, AI-generated voice is breaking into the mainstream — and &lt;strong&gt;Mati Staniszewski&lt;/strong&gt;, CEO and co-founder of ElevenLabs, is helping lead the charge. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, he’ll take the stage to talk about what it takes to make voice AI truly human.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Mati Staniszewski" class="wp-image-3025392" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Mati-Staniszewski-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-shaping-the-future-of-sound"&gt;&lt;br /&gt;&lt;strong&gt;Shaping the future of sound&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs has quickly become a key player in the generative AI space, known for pushing the boundaries of synthetic voice technology. In this session, Mati will explore how ElevenLabs built a platform that can replicate natural speech with remarkable nuance and realism — and why that opens the door to new possibilities across entertainment, accessibility, education, and creative storytelling.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Voice is one of the most personal, expressive human traits. Creating AI that can replicate it accurately — and ethically — presents unique technical and social challenges. This conversation will unpack those challenges, explore real-world use cases, and look ahead at how AI voice tools will shape the way we listen, learn, and connect.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-this-ai-session-and-the-savings"&gt;Don’t miss this AI session and the savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000 startup and VC leaders at Disrupt 2025 for bold conversations shaping the future of AI — and breakthroughs across five industry-specific stages. Get your ticket now and &lt;strong&gt;save up to $668&lt;/strong&gt;. Prices go up after September 26.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/exploring-the-future-of-voice-ai-with-mati-staniszewski-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 10 Sep 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft ends OpenAI exclusivity in Office, adds rival Anthropic (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/report-microsoft-taps-rival-anthropics-ai-for-office-after-it-beats-openai-at-some-tasks/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft will end OpenAI's exclusive hold on its productivity suite, adding second AI supplier.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Microsoft Copilot logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Microsoft Copilot logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft's Office 365 suite will soon incorporate AI models from Anthropic alongside existing OpenAI technology, The Information reported, ending years of exclusive reliance on OpenAI for generative AI features across Word, Excel, PowerPoint, and Outlook.&lt;/p&gt;
&lt;p&gt;The shift reportedly follows internal testing that revealed Anthropic's Claude Sonnet 4 model excels at specific Office tasks where OpenAI's models fall short, particularly in visual design and spreadsheet automation, according to sources familiar with the project cited by The Information, who stressed the move is not a negotiating tactic.&lt;/p&gt;
&lt;p&gt;Anthropic did not immediately respond to Ars Technica's request for comment.&lt;/p&gt;
&lt;p&gt;In an unusual arrangement showing the tangled alliances of the AI industry, Microsoft will reportedly purchase access to Anthropic's models through Amazon Web Services—both a cloud computing rival and one of Anthropic's major investors. The integration is expected to be announced within weeks, with subscription pricing for Office's AI tools remaining unchanged, the report says.&lt;/p&gt;
&lt;p&gt;Microsoft maintains that its OpenAI relationship remains intact. "As we've said, OpenAI will continue to be our partner on frontier models and we remain committed to our long-term partnership," a Microsoft spokesperson told Reuters following the report. The tech giant has poured over $13 billion into OpenAI to date and is currently negotiating terms for continued access to OpenAI's models amid ongoing negotiations about their partnership terms.&lt;/p&gt;
&lt;p&gt;Stretching back to 2019, Microsoft's tight partnership with OpenAI until recently gave the tech giant a head start in AI assistants based on language models, allowing for a rapid (though bumpy) deployment of OpenAI-technology-based features in Bing search and the rollout of Copilot assistants throughout its software ecosystem. It's worth noting, however, that a recent report from the UK government found no clear productivity boost from using Copilot AI in daily work tasks among study participants.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Strategic hedging in the AI arms race&lt;/h2&gt;
&lt;p&gt;For its part, OpenAI has also begun to distance itself from its primary investor. In June, it struck a deal to use Google's cloud computing infrastructure for AI despite the two companies' fierce competition in the space, marking a shift in OpenAI's strategy to diversify its computing resources beyond Microsoft Azure, which had been its exclusive cloud provider until January.&lt;/p&gt;
&lt;p&gt;OpenAI is also planning to launch a jobs platform that may compete with Microsoft's LinkedIn, and OpenAI plans to begin mass-producing its own AI chips with Broadcom in 2026 to lessen its dependence on outside providers.&lt;/p&gt;
&lt;p&gt;This type of diversification likely reflects evolving AI strategies for both OpenAI and Microsoft as demand for AI features outpaces any single provider's capacity. Beyond the Anthropic addition, Microsoft has been developing its own proprietary AI models and began offering DeepSeek's technology through its Azure cloud platform in January. Microsoft already offers multiple AI models, including Claude, through its GitHub Copilot development platform.&lt;/p&gt;
&lt;p&gt;For Anthropic, the Microsoft deal represents a significant paper win against its rival. Founded in 2021 by ex-OpenAI executives, including CEO Dario Amodei, Anthropic has positioned its Claude models as "more steerable" alternatives to ChatGPT. Amazon's $4 billion investment (which began in 2023) in Anthropic provided both capital and computing infrastructure through Amazon Web Services —resources Microsoft will now indirectly use to power its own products.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft will end OpenAI's exclusive hold on its productivity suite, adding second AI supplier.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Microsoft Copilot logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Microsoft Copilot logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft's Office 365 suite will soon incorporate AI models from Anthropic alongside existing OpenAI technology, The Information reported, ending years of exclusive reliance on OpenAI for generative AI features across Word, Excel, PowerPoint, and Outlook.&lt;/p&gt;
&lt;p&gt;The shift reportedly follows internal testing that revealed Anthropic's Claude Sonnet 4 model excels at specific Office tasks where OpenAI's models fall short, particularly in visual design and spreadsheet automation, according to sources familiar with the project cited by The Information, who stressed the move is not a negotiating tactic.&lt;/p&gt;
&lt;p&gt;Anthropic did not immediately respond to Ars Technica's request for comment.&lt;/p&gt;
&lt;p&gt;In an unusual arrangement showing the tangled alliances of the AI industry, Microsoft will reportedly purchase access to Anthropic's models through Amazon Web Services—both a cloud computing rival and one of Anthropic's major investors. The integration is expected to be announced within weeks, with subscription pricing for Office's AI tools remaining unchanged, the report says.&lt;/p&gt;
&lt;p&gt;Microsoft maintains that its OpenAI relationship remains intact. "As we've said, OpenAI will continue to be our partner on frontier models and we remain committed to our long-term partnership," a Microsoft spokesperson told Reuters following the report. The tech giant has poured over $13 billion into OpenAI to date and is currently negotiating terms for continued access to OpenAI's models amid ongoing negotiations about their partnership terms.&lt;/p&gt;
&lt;p&gt;Stretching back to 2019, Microsoft's tight partnership with OpenAI until recently gave the tech giant a head start in AI assistants based on language models, allowing for a rapid (though bumpy) deployment of OpenAI-technology-based features in Bing search and the rollout of Copilot assistants throughout its software ecosystem. It's worth noting, however, that a recent report from the UK government found no clear productivity boost from using Copilot AI in daily work tasks among study participants.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Strategic hedging in the AI arms race&lt;/h2&gt;
&lt;p&gt;For its part, OpenAI has also begun to distance itself from its primary investor. In June, it struck a deal to use Google's cloud computing infrastructure for AI despite the two companies' fierce competition in the space, marking a shift in OpenAI's strategy to diversify its computing resources beyond Microsoft Azure, which had been its exclusive cloud provider until January.&lt;/p&gt;
&lt;p&gt;OpenAI is also planning to launch a jobs platform that may compete with Microsoft's LinkedIn, and OpenAI plans to begin mass-producing its own AI chips with Broadcom in 2026 to lessen its dependence on outside providers.&lt;/p&gt;
&lt;p&gt;This type of diversification likely reflects evolving AI strategies for both OpenAI and Microsoft as demand for AI features outpaces any single provider's capacity. Beyond the Anthropic addition, Microsoft has been developing its own proprietary AI models and began offering DeepSeek's technology through its Azure cloud platform in January. Microsoft already offers multiple AI models, including Claude, through its GitHub Copilot development platform.&lt;/p&gt;
&lt;p&gt;For Anthropic, the Microsoft deal represents a significant paper win against its rival. Founded in 2021 by ex-OpenAI executives, including CEO Dario Amodei, Anthropic has positioned its Claude models as "more steerable" alternatives to ChatGPT. Amazon's $4 billion investment (which began in 2023) in Anthropic provided both capital and computing infrastructure through Amazon Web Services —resources Microsoft will now indirectly use to power its own products.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/report-microsoft-taps-rival-anthropics-ai-for-office-after-it-beats-openai-at-some-tasks/</guid><pubDate>Wed, 10 Sep 2025 15:41:42 +0000</pubDate></item><item><title>[NEW] DOE selects MIT to establish a Center for the Exascale Simulation of Coupled High-Enthalpy Fluid–Solid Interactions (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-center-exascale-simulation-coupled-high-enthalpy-fluid-solid-interactions-0910</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/orion-reentry-00.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The U.S. Department of Energy’s National Nuclear Security Administration (DOE/NNSA) recently&amp;nbsp;announced that it has selected MIT to establish a new research center dedicated to advancing the predictive simulation of extreme environments, such as those encountered in hypersonic flight and atmospheric re-entry. The center will be part of the fourth phase of NNSA's&amp;nbsp;Predictive Science Academic Alliance Program (PSAAP-IV), which supports frontier research advancing the predictive capabilities of high-performance computing for open science and engineering applications relevant to national security mission spaces.&lt;/p&gt;&lt;p&gt;The Center for the Exascale Simulation of Coupled High-Enthalpy Fluid–Solid Interactions (CHEFSI) — a joint effort of the&amp;nbsp;MIT Center for Computational Science and Engineering, the&amp;nbsp;MIT Schwarzman College of Computing, and the&amp;nbsp;MIT Institute for Soldier Nanotechnologies (ISN) —&amp;nbsp;plans to harness cutting-edge exascale supercomputers and next-generation algorithms to simulate with unprecedented detail how extremely hot, fast-moving gaseous and solid materials interact. The understanding of these extreme environments — characterized by temperatures of more than 1,500 degrees Celsius and speeds as high as Mach&amp;nbsp;25 — and their effect on vehicles is central to national security, space exploration, and the development of advanced thermal protection systems.&lt;/p&gt;&lt;p&gt;“CHEFSI will capitalize on MIT’s deep strengths in predictive modeling, high-performance computing, and STEM education to help ensure the United States remains at the forefront of scientific and technological innovation,” says Ian A. Waitz, MIT’s vice president for research. “The center’s particular relevance to national security and advanced technologies exemplifies MIT’s commitment to advancing research with broad societal benefit.”&lt;/p&gt;&lt;p&gt;CHEFSI is one of five new Predictive Simulation Centers announced by the NNSA as part of a program expected to provide up to $17.5 million to each center over five years.&lt;/p&gt;&lt;p&gt;CHEFSI’s research aims to couple detailed simulations of high-enthalpy gas flows with models of the chemical, thermal, and mechanical behavior of solid materials, capturing phenomena such as oxidation, nitridation, ablation, and fracture. Advanced computational models — validated by carefully designed experiments — can address the limitations of flight testing by providing critical insights into material performance and failure.&lt;/p&gt;&lt;p&gt;“By integrating high-fidelity physics models with artificial intelligence-based surrogate models, experimental validation, and state-of-the-art exascale computational tools, CHEFSI will help us understand and predict how thermal protection systems perform under some of the harshest conditions encountered in engineering systems,” says Raúl Radovitzky, the Jerome C. Hunsaker Professor of Aeronautics and Astronautics, associate director of the ISN, and director of CHEFSI. “This knowledge will help in the design of resilient systems for applications ranging from reusable spacecraft to hypersonic vehicles.”&lt;/p&gt;&lt;p&gt;Radovitzky will be joined on the center’s leadership team by Youssef Marzouk, the Breene M. Kerr (1951) Professor of Aeronautics and Astronautics, co-director of the MIT Center for Computational Science and Engineering (CCSE), and recently named the associate dean of the MIT Schwarzman College of Computing; and Nicolas Hadjiconstantinou, the Quentin Berg (1937) Professor of Mechanical Engineering and co-director of CCSE, who will serve as associate directors. The center&amp;nbsp;co-principal investigators include MIT faculty members across the departments of Aeronautics and Astronautics, Electrical Engineering and Computer Science, Materials Science and Engineering, Mathematics, and Mechanical Engineering. Franklin Hadley will lead center operations, with administration and finance under the&amp;nbsp;purview of Joshua Freedman. Hadley and Freedman are both members of the ISN headquarters team.&amp;nbsp;&lt;/p&gt;&lt;p&gt;CHEFSI expects to collaborate extensively with the DoE/NNSA national laboratories —&amp;nbsp;Lawrence Livermore National Laboratory, Los Alamos National Laboratory, and Sandia National Laboratories — and, in doing so, offer graduate students and postdocs immersive research experiences and internships at these facilities.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/orion-reentry-00.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The U.S. Department of Energy’s National Nuclear Security Administration (DOE/NNSA) recently&amp;nbsp;announced that it has selected MIT to establish a new research center dedicated to advancing the predictive simulation of extreme environments, such as those encountered in hypersonic flight and atmospheric re-entry. The center will be part of the fourth phase of NNSA's&amp;nbsp;Predictive Science Academic Alliance Program (PSAAP-IV), which supports frontier research advancing the predictive capabilities of high-performance computing for open science and engineering applications relevant to national security mission spaces.&lt;/p&gt;&lt;p&gt;The Center for the Exascale Simulation of Coupled High-Enthalpy Fluid–Solid Interactions (CHEFSI) — a joint effort of the&amp;nbsp;MIT Center for Computational Science and Engineering, the&amp;nbsp;MIT Schwarzman College of Computing, and the&amp;nbsp;MIT Institute for Soldier Nanotechnologies (ISN) —&amp;nbsp;plans to harness cutting-edge exascale supercomputers and next-generation algorithms to simulate with unprecedented detail how extremely hot, fast-moving gaseous and solid materials interact. The understanding of these extreme environments — characterized by temperatures of more than 1,500 degrees Celsius and speeds as high as Mach&amp;nbsp;25 — and their effect on vehicles is central to national security, space exploration, and the development of advanced thermal protection systems.&lt;/p&gt;&lt;p&gt;“CHEFSI will capitalize on MIT’s deep strengths in predictive modeling, high-performance computing, and STEM education to help ensure the United States remains at the forefront of scientific and technological innovation,” says Ian A. Waitz, MIT’s vice president for research. “The center’s particular relevance to national security and advanced technologies exemplifies MIT’s commitment to advancing research with broad societal benefit.”&lt;/p&gt;&lt;p&gt;CHEFSI is one of five new Predictive Simulation Centers announced by the NNSA as part of a program expected to provide up to $17.5 million to each center over five years.&lt;/p&gt;&lt;p&gt;CHEFSI’s research aims to couple detailed simulations of high-enthalpy gas flows with models of the chemical, thermal, and mechanical behavior of solid materials, capturing phenomena such as oxidation, nitridation, ablation, and fracture. Advanced computational models — validated by carefully designed experiments — can address the limitations of flight testing by providing critical insights into material performance and failure.&lt;/p&gt;&lt;p&gt;“By integrating high-fidelity physics models with artificial intelligence-based surrogate models, experimental validation, and state-of-the-art exascale computational tools, CHEFSI will help us understand and predict how thermal protection systems perform under some of the harshest conditions encountered in engineering systems,” says Raúl Radovitzky, the Jerome C. Hunsaker Professor of Aeronautics and Astronautics, associate director of the ISN, and director of CHEFSI. “This knowledge will help in the design of resilient systems for applications ranging from reusable spacecraft to hypersonic vehicles.”&lt;/p&gt;&lt;p&gt;Radovitzky will be joined on the center’s leadership team by Youssef Marzouk, the Breene M. Kerr (1951) Professor of Aeronautics and Astronautics, co-director of the MIT Center for Computational Science and Engineering (CCSE), and recently named the associate dean of the MIT Schwarzman College of Computing; and Nicolas Hadjiconstantinou, the Quentin Berg (1937) Professor of Mechanical Engineering and co-director of CCSE, who will serve as associate directors. The center&amp;nbsp;co-principal investigators include MIT faculty members across the departments of Aeronautics and Astronautics, Electrical Engineering and Computer Science, Materials Science and Engineering, Mathematics, and Mechanical Engineering. Franklin Hadley will lead center operations, with administration and finance under the&amp;nbsp;purview of Joshua Freedman. Hadley and Freedman are both members of the ISN headquarters team.&amp;nbsp;&lt;/p&gt;&lt;p&gt;CHEFSI expects to collaborate extensively with the DoE/NNSA national laboratories —&amp;nbsp;Lawrence Livermore National Laboratory, Los Alamos National Laboratory, and Sandia National Laboratories — and, in doing so, offer graduate students and postdocs immersive research experiences and internships at these facilities.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-center-exascale-simulation-coupled-high-enthalpy-fluid-solid-interactions-0910</guid><pubDate>Wed, 10 Sep 2025 15:45:00 +0000</pubDate></item><item><title>[NEW] RenderFormer: How neural networks are reshaping 3D rendering (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/renderformer-how-neural-networks-are-reshaping-3d-rendering/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: network node icon, lightbulb-shaped icon with a path tool icon in the center; a monitor icon showing a web browser icon" class="wp-image-1149127" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;3D rendering—the process of converting three-dimensional models into two-dimensional images—is a foundational technology in computer graphics, widely used across gaming, film, virtual reality, and architectural visualization. Traditionally, this process has depended on physics-based techniques like ray tracing and rasterization, which simulate light behavior through mathematical formulas and expert-designed models.&lt;/p&gt;



&lt;p&gt;Now, thanks to advances in AI, especially neural networks, researchers are beginning to replace these conventional approaches with machine learning (ML). This shift is giving rise to a new field known as neural rendering.&lt;/p&gt;



&lt;p&gt;Neural rendering combines deep learning with traditional graphics techniques, allowing models to simulate complex light transport without explicitly modeling physical optics. This approach offers significant advantages: it eliminates the need for handcrafted rules, supports end-to-end training, and can be optimized for specific tasks. Yet, most current neural rendering methods rely on 2D image inputs, lack support for raw 3D geometry and material data, and often require retraining for each new scene—limiting their generalizability.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="renderformer-toward-a-general-purpose-neural-rendering-model"&gt;RenderFormer: Toward a general-purpose neural rendering model&lt;/h2&gt;



&lt;p&gt;To overcome these limitations, researchers at Microsoft Research have developed RenderFormer, a new neural architecture designed to support full-featured 3D rendering using only ML—no traditional graphics computation required. RenderFormer is the first model to demonstrate that a neural network can learn a complete graphics rendering pipeline, including support for arbitrary 3D scenes and global illumination, without relying on ray tracing or rasterization. This work has been accepted at SIGGRAPH 2025 and is open-sourced on GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="architecture-overview"&gt;Architecture overview&lt;/h2&gt;



&lt;p&gt;As shown in Figure 1, RenderFormer represents the entire 3D scene using triangle tokens—each one encoding spatial position, surface normal, and physical material properties such as diffuse color, specular color, and roughness. Lighting is also modeled as triangle tokens, with emission values indicating intensity.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: The figure illustrates the architecture of RenderFormer. It includes a Triangle Mesh Scene with a 3D rabbit model inside a colored cube, a Camera Ray Map grid, a View Independent Transformer (12 layers of Self-Attention and Feed Forward Network), a View Dependent Transformer (6 layers with Cross-Attention and Self-Attention), and a DPT Decoder. Scene attributes—Vertex Normal, Reflectance (Diffuse, Specular, Roughness), Emission, and Position—are embedded into Triangle Tokens via Linear + Norm operations. These tokens and Ray Bundle Tokens (from the Camera Ray Map) are processed by the respective transformers and decoded to produce a rendered image of a glossy rabbit in a colored room." class="wp-image-1149133" height="1008" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig1.png" width="2419" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Architecture of RenderFormer&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To describe the viewing direction, the model uses ray bundle tokens derived from a ray map—each pixel in the output image corresponds to one of these rays. To improve computational efficiency, pixels are grouped into rectangular blocks, with all rays in a block processed together.&lt;/p&gt;



&lt;p&gt;The model outputs a set of tokens that are decoded into image pixels, completing the rendering process entirely within the neural network.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="dual-branch-design-for-view-independent-and-view-dependent-effects"&gt;Dual-branch design for view-independent and view-dependent effects&lt;/h2&gt;



&lt;p&gt;The RenderFormer architecture is built around two transformers: one for view-independent features and another for view-dependent ones.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;The &lt;strong&gt;view-independent transformer&lt;/strong&gt; captures scene information unrelated to viewpoint, such as shadowing and diffuse light transport, using self-attention between triangle tokens.&lt;/li&gt;



&lt;li&gt;The &lt;strong&gt;view-dependent transformer&lt;/strong&gt; models effects like visibility, reflections, and specular highlights through cross-attention between triangle and ray bundle tokens.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Additional image-space effects, such as anti-aliasing and screen-space reflections, are handled via self-attention among ray bundle tokens.&lt;/p&gt;



&lt;p&gt;To validate the architecture, the team conducted ablation studies and visual analyses, confirming the importance of each component in the rendering pipeline.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Table 1: A table comparing the performance of different network variants in an ablation study. The columns are labeled Variant, PSNR (↑), SSIM (↑), LPIPS (↓), and FLIP (↓). Variants include configurations such as " class="wp-image-1149129" for="for" height="509" rows="rows" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_table-1.png" width="963" /&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1. Ablation study analyzing the impact of different components and attention mechanisms on the final performance of the trained network. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To test the capabilities of the view-independent transformer, researchers trained a decoder to produce diffuse-only renderings. The results, shown in Figure 2, demonstrate that the model can accurately simulate shadows and other indirect lighting effects.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: The figure displays four 3D-rendered objects showcasing view-independent rendering effects. From left to right: a purple teapot on a green surface, a blue rectangular object on a red surface, an upside-down table casting shadows on a green surface, and a green apple-like object on a blue surface. Each object features diffuse lighting and coarse shadow effects, with distinct highlights and shadows produced by directional light sources." class="wp-image-1149132" height="240" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig2.png" width="943" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. View-independent rendering effects decoded directly from the view-independent transformer, including diffuse lighting and coarse shadow effects. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The view-dependent transformer was evaluated through attention visualizations. For example, in Figure 3, the attention map reveals a pixel on a teapot attending to its surface triangle and to a nearby wall—capturing the effect of specular reflection. These visualizations also show how material changes influence the sharpness and intensity of reflections.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: The figure contains six panels arranged in two rows and three columns. The top row displays a teapot in a room with red and green walls under three different roughness values: 0.3, 0.7, and 0.99 (left to right). The bottom row shows the corresponding attention outputs for each roughness setting, featuring the teapot silhouette against a dark background with distinct light patterns that vary with roughness." class="wp-image-1149131" height="620" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig3.png" width="947" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Visualization of attention outputs&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="training-methodology-and-dataset-design"&gt;Training methodology and dataset design&lt;/h2&gt;



&lt;p&gt;RenderFormer was trained using the Objaverse dataset, a collection of more than 800,000 annotated 3D objects that is designed to advance research in 3D modeling, computer vision, and related fields. The researchers designed four scene templates, populating each with 1–3 randomly selected objects and materials. Scenes were rendered in high dynamic range (HDR) using Blender’s Cycles renderer, under varied lighting conditions and camera angles.&lt;/p&gt;



&lt;p&gt;The base model, consisting of 205 million parameters, was trained in two phases using the AdamW optimizer:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;500,000 steps at 256×256 resolution with up to 1,536 triangles&lt;/li&gt;



&lt;li&gt;100,000 steps at 512×512 resolution with up to 4,096 triangles&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model supports arbitrary triangle-based input and generalizes well to complex real-world scenes. As shown in Figure 4, it accurately reproduces shadows, diffuse shading, and specular highlights.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4: The figure presents a 3×3 grid of diverse 3D scenes rendered by RenderFormer. In the top row, the first scene shows a room with red, green, and white walls containing two rectangular prisms; the second features a metallic tree-like structure in a blue-walled room with a reflective floor; and the third depicts a red animal figure, a black abstract shape, and a multi-faceted sphere in a purple container on a yellow surface. The middle row includes three constant width bodies (black, red, and blue) floating above a colorful checkered floor; a green shader ball with a square cavity inside a gray-walled room; and crystal-like structures in green, purple, and red on a reflective surface. The bottom row showcases a low-poly fox near a pink tree emitting particles on grassy terrain; a golden horse statue beside a heart-shaped object split into red and grey halves on a reflective surface; and a wicker basket, a banana and a bottle placed on a white platform." class="wp-image-1149130" height="805" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig4.jpg" width="805" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Rendered results of different 3D scenes generated by RenderFormer &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;RenderFormer can also generate continuous video by rendering individual frames, thanks to its ability to model viewpoint changes and scene dynamics.&lt;/p&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_animate.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;3D animation sequence rendered by RenderFormer &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="looking-ahead-opportunities-and-challenges"&gt;Looking ahead: Opportunities and challenges&lt;/h2&gt;



&lt;p&gt;RenderFormer represents a significant step forward for neural rendering. It demonstrates that deep learning can replicate and potentially replace the traditional rendering pipeline, supporting arbitrary 3D inputs and realistic global illumination—all without any hand-coded graphics computations.&lt;/p&gt;



&lt;p&gt;However, key challenges remain. Scaling to larger and more complex scenes with intricate geometry, advanced materials, and diverse lighting conditions will require further research. Still, the transformer-based architecture provides a solid foundation for future integration with broader AI systems, including video generation, image synthesis, robotics, and embodied AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers hope that RenderFormer will serve as a building block for future breakthroughs in both graphics and AI, opening new possibilities for visual computing and intelligent environments.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: network node icon, lightbulb-shaped icon with a path tool icon in the center; a monitor icon showing a web browser icon" class="wp-image-1149127" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;3D rendering—the process of converting three-dimensional models into two-dimensional images—is a foundational technology in computer graphics, widely used across gaming, film, virtual reality, and architectural visualization. Traditionally, this process has depended on physics-based techniques like ray tracing and rasterization, which simulate light behavior through mathematical formulas and expert-designed models.&lt;/p&gt;



&lt;p&gt;Now, thanks to advances in AI, especially neural networks, researchers are beginning to replace these conventional approaches with machine learning (ML). This shift is giving rise to a new field known as neural rendering.&lt;/p&gt;



&lt;p&gt;Neural rendering combines deep learning with traditional graphics techniques, allowing models to simulate complex light transport without explicitly modeling physical optics. This approach offers significant advantages: it eliminates the need for handcrafted rules, supports end-to-end training, and can be optimized for specific tasks. Yet, most current neural rendering methods rely on 2D image inputs, lack support for raw 3D geometry and material data, and often require retraining for each new scene—limiting their generalizability.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="renderformer-toward-a-general-purpose-neural-rendering-model"&gt;RenderFormer: Toward a general-purpose neural rendering model&lt;/h2&gt;



&lt;p&gt;To overcome these limitations, researchers at Microsoft Research have developed RenderFormer, a new neural architecture designed to support full-featured 3D rendering using only ML—no traditional graphics computation required. RenderFormer is the first model to demonstrate that a neural network can learn a complete graphics rendering pipeline, including support for arbitrary 3D scenes and global illumination, without relying on ray tracing or rasterization. This work has been accepted at SIGGRAPH 2025 and is open-sourced on GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="architecture-overview"&gt;Architecture overview&lt;/h2&gt;



&lt;p&gt;As shown in Figure 1, RenderFormer represents the entire 3D scene using triangle tokens—each one encoding spatial position, surface normal, and physical material properties such as diffuse color, specular color, and roughness. Lighting is also modeled as triangle tokens, with emission values indicating intensity.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: The figure illustrates the architecture of RenderFormer. It includes a Triangle Mesh Scene with a 3D rabbit model inside a colored cube, a Camera Ray Map grid, a View Independent Transformer (12 layers of Self-Attention and Feed Forward Network), a View Dependent Transformer (6 layers with Cross-Attention and Self-Attention), and a DPT Decoder. Scene attributes—Vertex Normal, Reflectance (Diffuse, Specular, Roughness), Emission, and Position—are embedded into Triangle Tokens via Linear + Norm operations. These tokens and Ray Bundle Tokens (from the Camera Ray Map) are processed by the respective transformers and decoded to produce a rendered image of a glossy rabbit in a colored room." class="wp-image-1149133" height="1008" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig1.png" width="2419" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Architecture of RenderFormer&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To describe the viewing direction, the model uses ray bundle tokens derived from a ray map—each pixel in the output image corresponds to one of these rays. To improve computational efficiency, pixels are grouped into rectangular blocks, with all rays in a block processed together.&lt;/p&gt;



&lt;p&gt;The model outputs a set of tokens that are decoded into image pixels, completing the rendering process entirely within the neural network.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="dual-branch-design-for-view-independent-and-view-dependent-effects"&gt;Dual-branch design for view-independent and view-dependent effects&lt;/h2&gt;



&lt;p&gt;The RenderFormer architecture is built around two transformers: one for view-independent features and another for view-dependent ones.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;The &lt;strong&gt;view-independent transformer&lt;/strong&gt; captures scene information unrelated to viewpoint, such as shadowing and diffuse light transport, using self-attention between triangle tokens.&lt;/li&gt;



&lt;li&gt;The &lt;strong&gt;view-dependent transformer&lt;/strong&gt; models effects like visibility, reflections, and specular highlights through cross-attention between triangle and ray bundle tokens.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Additional image-space effects, such as anti-aliasing and screen-space reflections, are handled via self-attention among ray bundle tokens.&lt;/p&gt;



&lt;p&gt;To validate the architecture, the team conducted ablation studies and visual analyses, confirming the importance of each component in the rendering pipeline.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Table 1: A table comparing the performance of different network variants in an ablation study. The columns are labeled Variant, PSNR (↑), SSIM (↑), LPIPS (↓), and FLIP (↓). Variants include configurations such as " class="wp-image-1149129" for="for" height="509" rows="rows" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_table-1.png" width="963" /&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1. Ablation study analyzing the impact of different components and attention mechanisms on the final performance of the trained network. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To test the capabilities of the view-independent transformer, researchers trained a decoder to produce diffuse-only renderings. The results, shown in Figure 2, demonstrate that the model can accurately simulate shadows and other indirect lighting effects.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: The figure displays four 3D-rendered objects showcasing view-independent rendering effects. From left to right: a purple teapot on a green surface, a blue rectangular object on a red surface, an upside-down table casting shadows on a green surface, and a green apple-like object on a blue surface. Each object features diffuse lighting and coarse shadow effects, with distinct highlights and shadows produced by directional light sources." class="wp-image-1149132" height="240" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig2.png" width="943" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. View-independent rendering effects decoded directly from the view-independent transformer, including diffuse lighting and coarse shadow effects. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The view-dependent transformer was evaluated through attention visualizations. For example, in Figure 3, the attention map reveals a pixel on a teapot attending to its surface triangle and to a nearby wall—capturing the effect of specular reflection. These visualizations also show how material changes influence the sharpness and intensity of reflections.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: The figure contains six panels arranged in two rows and three columns. The top row displays a teapot in a room with red and green walls under three different roughness values: 0.3, 0.7, and 0.99 (left to right). The bottom row shows the corresponding attention outputs for each roughness setting, featuring the teapot silhouette against a dark background with distinct light patterns that vary with roughness." class="wp-image-1149131" height="620" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig3.png" width="947" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Visualization of attention outputs&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="training-methodology-and-dataset-design"&gt;Training methodology and dataset design&lt;/h2&gt;



&lt;p&gt;RenderFormer was trained using the Objaverse dataset, a collection of more than 800,000 annotated 3D objects that is designed to advance research in 3D modeling, computer vision, and related fields. The researchers designed four scene templates, populating each with 1–3 randomly selected objects and materials. Scenes were rendered in high dynamic range (HDR) using Blender’s Cycles renderer, under varied lighting conditions and camera angles.&lt;/p&gt;



&lt;p&gt;The base model, consisting of 205 million parameters, was trained in two phases using the AdamW optimizer:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;500,000 steps at 256×256 resolution with up to 1,536 triangles&lt;/li&gt;



&lt;li&gt;100,000 steps at 512×512 resolution with up to 4,096 triangles&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model supports arbitrary triangle-based input and generalizes well to complex real-world scenes. As shown in Figure 4, it accurately reproduces shadows, diffuse shading, and specular highlights.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4: The figure presents a 3×3 grid of diverse 3D scenes rendered by RenderFormer. In the top row, the first scene shows a room with red, green, and white walls containing two rectangular prisms; the second features a metallic tree-like structure in a blue-walled room with a reflective floor; and the third depicts a red animal figure, a black abstract shape, and a multi-faceted sphere in a purple container on a yellow surface. The middle row includes three constant width bodies (black, red, and blue) floating above a colorful checkered floor; a green shader ball with a square cavity inside a gray-walled room; and crystal-like structures in green, purple, and red on a reflective surface. The bottom row showcases a low-poly fox near a pink tree emitting particles on grassy terrain; a golden horse statue beside a heart-shaped object split into red and grey halves on a reflective surface; and a wicker basket, a banana and a bottle placed on a white platform." class="wp-image-1149130" height="805" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_fig4.jpg" width="805" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Rendered results of different 3D scenes generated by RenderFormer &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;RenderFormer can also generate continuous video by rendering individual frames, thanks to its ability to model viewpoint changes and scene dynamics.&lt;/p&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/RenderFormer_animate.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;3D animation sequence rendered by RenderFormer &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="looking-ahead-opportunities-and-challenges"&gt;Looking ahead: Opportunities and challenges&lt;/h2&gt;



&lt;p&gt;RenderFormer represents a significant step forward for neural rendering. It demonstrates that deep learning can replicate and potentially replace the traditional rendering pipeline, supporting arbitrary 3D inputs and realistic global illumination—all without any hand-coded graphics computations.&lt;/p&gt;



&lt;p&gt;However, key challenges remain. Scaling to larger and more complex scenes with intricate geometry, advanced materials, and diverse lighting conditions will require further research. Still, the transformer-based architecture provides a solid foundation for future integration with broader AI systems, including video generation, image synthesis, robotics, and embodied AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers hope that RenderFormer will serve as a building block for future breakthroughs in both graphics and AI, opening new possibilities for visual computing and intelligent environments.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/renderformer-how-neural-networks-are-reshaping-3d-rendering/</guid><pubDate>Wed, 10 Sep 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Spotify peeved after 10,000 users sold data to build AI tools (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/spotify-peeved-after-10000-users-sold-data-to-build-ai-tools/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Spotify sent a warning to stop data sales, but developers say they never got it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/spotify-data-mining-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/spotify-data-mining-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For millions of Spotify users, the "Wrapped" feature—which crunches the numbers on their annual listening habits—is a highlight of every year's end, ever since it debuted in 2015. NPR once broke down exactly why our brains find the feature so "irresistible," while Cosmopolitan last year declared that sharing Wrapped screenshots of top artists and songs had by now become "the ultimate status symbol" for tens of millions of music fans.&lt;/p&gt;
&lt;p&gt;It's no surprise then that, after a decade, some Spotify users who are especially eager to see Wrapped evolve are no longer willing to wait to see if Spotify will ever deliver the more creative streaming insights they crave.&lt;/p&gt;
&lt;p&gt;With the help of AI, these users expect that their data can be more quickly analyzed to potentially uncover overlooked or never-considered patterns that could offer even more insights into what their listening habits say about them.&lt;/p&gt;
&lt;p&gt;Imagine, for example, accessing a music recap that encapsulates a user's full listening history—not just their top songs and artists. With that unlocked, users could track emotional patterns, analyzing how their music tastes reflected their moods over time and perhaps helping them adjust their listening habits to better cope with stress or major life events. And for users particularly intrigued by their own data, there's even the potential to use AI to cross data streams from different platforms and perhaps understand even more about how their music choices impact their lives and tastes more broadly.&lt;/p&gt;
&lt;p&gt;Likely just as appealing as gleaning deeper personal insights, though, users could also potentially build AI tools to compare listening habits with their friends. That could lead to nearly endless fun for the most invested music fans, where AI could be tapped to assess all kinds of random data points, like whose breakup playlists are more intense or who really spends the most time listening to a shared favorite artist.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In pursuit of supporting developers offering novel insights like these, more than 18,000 Spotify users have joined "Unwrapped," a collective launched in February that allows them to pool and monetize their data.&lt;/p&gt;
&lt;p&gt;Voting as a group through the decentralized data platform Vana—which Wired profiled earlier this year—these users can elect to sell their dataset to developers who are building AI tools offering fresh ways for users to analyze streaming data in ways that Spotify likely couldn't or wouldn't.&lt;/p&gt;
&lt;p&gt;In June, the group made its first sale, with 99.5 percent of members voting yes. Vana co-founder Anna Kazlauskas told Ars that the collective—at the time about 10,000 members strong—sold a "small portion" of its data (users' artist preferences) for $55,000 to Solo AI.&lt;/p&gt;
&lt;p&gt;While each Spotify user only earned about $5 in cryptocurrency tokens—which Kazlauskas suggested was not "ideal," wishing the users had earned about "a hundred times" more—she said the deal was "meaningful" in showing Spotify users that their data "is actually worth something."&lt;/p&gt;
&lt;p&gt;"I think this is what shows how these pools of data really act like a labor union," Kazlauskas said. "A single Spotify user, you're not going to be able to go say like, 'Hey, I want to sell you my individual data.' You actually need enough of a pool to sort of make it work."&lt;/p&gt;
&lt;h2&gt;Spotify sent warning to Unwrapped&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, Spotify is not happy about Unwrapped, which is perhaps a little too closely named to its popular branded feature for the streaming giant's comfort. A spokesperson told Ars that Spotify sent a letter to the contact info listed for Unwrapped developers on their site, outlining concerns that the collective could be infringing on Spotify's Wrapped trademark.&lt;/p&gt;
&lt;p&gt;Further, the letter warned that Unwrapped violates Spotify's developer policy, which bans using the Spotify platform or any Spotify content to build machine learning or AI models. And developers may also be violating terms by facilitating users' sale of streaming data.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Spotify honors our users’ privacy rights, including the right of portability," Spotify's spokesperson said. "All of our users can receive a copy of their personal data to use as they see fit. That said, UnwrappedData.org is in violation of our Developer Terms which prohibit the collection, aggregation, and sale of Spotify user data to third parties."&lt;/p&gt;
&lt;p&gt;But while Spotify suggests it has already taken steps to stop Unwrapped, the Unwrapped team told Ars that it never received any communication from Spotify. It plans to defend users' right to "access, control, and benefit from their own data," its statement said, while providing reassurances that it will "respect Spotify's position as a global music leader."&lt;/p&gt;
&lt;p&gt;Unwrapped "does not distribute Spotify’s content, nor does it interfere with Spotify’s business," developers argued. "What it provides is community-owned infrastructure that allows individuals to exercise rights they already hold under widely recognized data protection frameworks—rights to access their own listening history, preferences, and usage data."&lt;/p&gt;
&lt;p&gt;"When listeners choose to share or monetize their data together, they are not taking anything away from Spotify," developers said. "They are simply exercising digital self-determination. To suggest otherwise is to claim that users do not truly own their data—that Spotify owns it for them."&lt;/p&gt;
&lt;p&gt;Jacob Hoffman-Andrews, a senior staff technologist for the digital rights group the Electronic Frontier Foundation, told Ars that—while EFF objects to data dividend schemes "where users are encouraged to share personal information in exchange for payment"—Spotify users should nevertheless always maintain control of their data.&lt;/p&gt;
&lt;p&gt;"In general, listeners should have control of their own data, which includes exporting it for their own use," Hoffman-Andrews said. "An individual's musical history is of use not just to Spotify but also to the individual who created it. And there's a long history of services that enable this sort of data portability, for instance Last.fm, which integrates with Spotify and many other services."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To EFF, it seems ill-advised to sell data to AI companies, Hoffman-Andrews said, emphasizing "privacy isn't a market commodity, it's a fundamental right."&lt;/p&gt;
&lt;p&gt;"Of course, so is the right to control one's own data," Hoffman-Andrews noted, seeming to agree with Unwrapped developers in concluding that "ultimately, listeners should get to do what they want with their own information."&lt;/p&gt;
&lt;p&gt;Users' right to privacy is the primary reason why Unwrapped developers told Ars that they're hoping Spotify won't try to block users from selling data to build AI.&lt;/p&gt;
&lt;p&gt;"This is the heart of the issue: If Spotify seeks to restrict or penalize people for exercising these rights, it sends a chilling message that its listeners should have no say in how their own data is used," the Unwrapped team's statement said. "That is out of step not only with privacy law, but with the values of transparency, fairness, and community-driven innovation that define the next era of the Internet."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Unwrapped sign-ups limited due to alleged Spotify issues&lt;/h2&gt;
&lt;p&gt;There could be more interest in Unwrapped. But Kazlauskas alleged to Ars that in the more than six months since Unwrapped's launch, "Spotify has made it extraordinarily difficult" for users to port over their data. She claimed that developers have found that "every time they have an easy way for users to get their data," Spotify shuts it down "in some way."&lt;/p&gt;
&lt;p&gt;Supposedly because of Spotify's interference, Unwrapped remains in an early launch phase and can only offer limited spots for new users seeking to sell their data. Kazlauskas told Ars that about 300 users can be added each day due to the cumbersome and allegedly shifting process for porting over data.&lt;/p&gt;
&lt;p&gt;Currently, however, Unwrapped is working on an update that could make that process more stable, Kazlauskas said, as well as changes to help users regularly update their streaming data. Those updates could perhaps attract more users to the collective.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Critics of Vana, like TechCrunch's Kyle Wiggers, have suggested that data pools like Unwrapped will never reach "critical mass," likely only appealing to niche users drawn to decentralization movements. Kazlauskas told Ars that data sale payments issued in cryptocurrency are one barrier for crypto-averse or crypto-shy users interested in Vana.&lt;/p&gt;
&lt;p&gt;"The No. 1 thing I would say is, this kind of user experience problem where when you're using any new kind of decentralized technology, you need to set up a wallet, then you're getting tokens," Kazlauskas explained. Users may feel culture shock, wondering, "What does that even mean? How do I vote with this thing? Is this real money?"&lt;/p&gt;
&lt;p&gt;Kazlauskas is hoping that Vana supports a culture shift, striving to reach critical mass by giving users a "commercial lens" to start caring about data ownership. She also supports legislation like the Digital Choice Act in Utah, which "requires actually real-time API access, so people can get their data." If the US had a federal law like that, Kazlauskas suspects that launching Unwrapped would have been "so much easier."&lt;/p&gt;
&lt;p&gt;Although regulations like Utah's law could serve as a harbinger of a sea change, Kazlauskas noted that Big Tech companies that currently control AI markets employ a fierce lobbying force to maintain control over user data that decentralized movements just don't have.&lt;/p&gt;
&lt;p&gt;As Vana partners with Flower AI, striving, as Wired reported, to "shake up the AI industry" by releasing "a giant 100 billion-parameter model" later this year, Kazlauskas remains committed to ensuring that users are in control and "not just consumed." She fears a future where tech giants may be motivated to use AI to surveil, influence, or manipulate users, when instead users could choose to band together and benefit from building more ethical AI.&lt;/p&gt;
&lt;p&gt;"A world where a single company controls AI is honestly really dystopian," Kazlauskas told Ars. "I think that it is really scary. And so I think that the path that decentralized AI offers is one where a large group of people are still in control, and you still get really powerful technology."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Spotify sent a warning to stop data sales, but developers say they never got it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/spotify-data-mining-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/spotify-data-mining-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For millions of Spotify users, the "Wrapped" feature—which crunches the numbers on their annual listening habits—is a highlight of every year's end, ever since it debuted in 2015. NPR once broke down exactly why our brains find the feature so "irresistible," while Cosmopolitan last year declared that sharing Wrapped screenshots of top artists and songs had by now become "the ultimate status symbol" for tens of millions of music fans.&lt;/p&gt;
&lt;p&gt;It's no surprise then that, after a decade, some Spotify users who are especially eager to see Wrapped evolve are no longer willing to wait to see if Spotify will ever deliver the more creative streaming insights they crave.&lt;/p&gt;
&lt;p&gt;With the help of AI, these users expect that their data can be more quickly analyzed to potentially uncover overlooked or never-considered patterns that could offer even more insights into what their listening habits say about them.&lt;/p&gt;
&lt;p&gt;Imagine, for example, accessing a music recap that encapsulates a user's full listening history—not just their top songs and artists. With that unlocked, users could track emotional patterns, analyzing how their music tastes reflected their moods over time and perhaps helping them adjust their listening habits to better cope with stress or major life events. And for users particularly intrigued by their own data, there's even the potential to use AI to cross data streams from different platforms and perhaps understand even more about how their music choices impact their lives and tastes more broadly.&lt;/p&gt;
&lt;p&gt;Likely just as appealing as gleaning deeper personal insights, though, users could also potentially build AI tools to compare listening habits with their friends. That could lead to nearly endless fun for the most invested music fans, where AI could be tapped to assess all kinds of random data points, like whose breakup playlists are more intense or who really spends the most time listening to a shared favorite artist.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In pursuit of supporting developers offering novel insights like these, more than 18,000 Spotify users have joined "Unwrapped," a collective launched in February that allows them to pool and monetize their data.&lt;/p&gt;
&lt;p&gt;Voting as a group through the decentralized data platform Vana—which Wired profiled earlier this year—these users can elect to sell their dataset to developers who are building AI tools offering fresh ways for users to analyze streaming data in ways that Spotify likely couldn't or wouldn't.&lt;/p&gt;
&lt;p&gt;In June, the group made its first sale, with 99.5 percent of members voting yes. Vana co-founder Anna Kazlauskas told Ars that the collective—at the time about 10,000 members strong—sold a "small portion" of its data (users' artist preferences) for $55,000 to Solo AI.&lt;/p&gt;
&lt;p&gt;While each Spotify user only earned about $5 in cryptocurrency tokens—which Kazlauskas suggested was not "ideal," wishing the users had earned about "a hundred times" more—she said the deal was "meaningful" in showing Spotify users that their data "is actually worth something."&lt;/p&gt;
&lt;p&gt;"I think this is what shows how these pools of data really act like a labor union," Kazlauskas said. "A single Spotify user, you're not going to be able to go say like, 'Hey, I want to sell you my individual data.' You actually need enough of a pool to sort of make it work."&lt;/p&gt;
&lt;h2&gt;Spotify sent warning to Unwrapped&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, Spotify is not happy about Unwrapped, which is perhaps a little too closely named to its popular branded feature for the streaming giant's comfort. A spokesperson told Ars that Spotify sent a letter to the contact info listed for Unwrapped developers on their site, outlining concerns that the collective could be infringing on Spotify's Wrapped trademark.&lt;/p&gt;
&lt;p&gt;Further, the letter warned that Unwrapped violates Spotify's developer policy, which bans using the Spotify platform or any Spotify content to build machine learning or AI models. And developers may also be violating terms by facilitating users' sale of streaming data.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Spotify honors our users’ privacy rights, including the right of portability," Spotify's spokesperson said. "All of our users can receive a copy of their personal data to use as they see fit. That said, UnwrappedData.org is in violation of our Developer Terms which prohibit the collection, aggregation, and sale of Spotify user data to third parties."&lt;/p&gt;
&lt;p&gt;But while Spotify suggests it has already taken steps to stop Unwrapped, the Unwrapped team told Ars that it never received any communication from Spotify. It plans to defend users' right to "access, control, and benefit from their own data," its statement said, while providing reassurances that it will "respect Spotify's position as a global music leader."&lt;/p&gt;
&lt;p&gt;Unwrapped "does not distribute Spotify’s content, nor does it interfere with Spotify’s business," developers argued. "What it provides is community-owned infrastructure that allows individuals to exercise rights they already hold under widely recognized data protection frameworks—rights to access their own listening history, preferences, and usage data."&lt;/p&gt;
&lt;p&gt;"When listeners choose to share or monetize their data together, they are not taking anything away from Spotify," developers said. "They are simply exercising digital self-determination. To suggest otherwise is to claim that users do not truly own their data—that Spotify owns it for them."&lt;/p&gt;
&lt;p&gt;Jacob Hoffman-Andrews, a senior staff technologist for the digital rights group the Electronic Frontier Foundation, told Ars that—while EFF objects to data dividend schemes "where users are encouraged to share personal information in exchange for payment"—Spotify users should nevertheless always maintain control of their data.&lt;/p&gt;
&lt;p&gt;"In general, listeners should have control of their own data, which includes exporting it for their own use," Hoffman-Andrews said. "An individual's musical history is of use not just to Spotify but also to the individual who created it. And there's a long history of services that enable this sort of data portability, for instance Last.fm, which integrates with Spotify and many other services."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To EFF, it seems ill-advised to sell data to AI companies, Hoffman-Andrews said, emphasizing "privacy isn't a market commodity, it's a fundamental right."&lt;/p&gt;
&lt;p&gt;"Of course, so is the right to control one's own data," Hoffman-Andrews noted, seeming to agree with Unwrapped developers in concluding that "ultimately, listeners should get to do what they want with their own information."&lt;/p&gt;
&lt;p&gt;Users' right to privacy is the primary reason why Unwrapped developers told Ars that they're hoping Spotify won't try to block users from selling data to build AI.&lt;/p&gt;
&lt;p&gt;"This is the heart of the issue: If Spotify seeks to restrict or penalize people for exercising these rights, it sends a chilling message that its listeners should have no say in how their own data is used," the Unwrapped team's statement said. "That is out of step not only with privacy law, but with the values of transparency, fairness, and community-driven innovation that define the next era of the Internet."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Unwrapped sign-ups limited due to alleged Spotify issues&lt;/h2&gt;
&lt;p&gt;There could be more interest in Unwrapped. But Kazlauskas alleged to Ars that in the more than six months since Unwrapped's launch, "Spotify has made it extraordinarily difficult" for users to port over their data. She claimed that developers have found that "every time they have an easy way for users to get their data," Spotify shuts it down "in some way."&lt;/p&gt;
&lt;p&gt;Supposedly because of Spotify's interference, Unwrapped remains in an early launch phase and can only offer limited spots for new users seeking to sell their data. Kazlauskas told Ars that about 300 users can be added each day due to the cumbersome and allegedly shifting process for porting over data.&lt;/p&gt;
&lt;p&gt;Currently, however, Unwrapped is working on an update that could make that process more stable, Kazlauskas said, as well as changes to help users regularly update their streaming data. Those updates could perhaps attract more users to the collective.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Critics of Vana, like TechCrunch's Kyle Wiggers, have suggested that data pools like Unwrapped will never reach "critical mass," likely only appealing to niche users drawn to decentralization movements. Kazlauskas told Ars that data sale payments issued in cryptocurrency are one barrier for crypto-averse or crypto-shy users interested in Vana.&lt;/p&gt;
&lt;p&gt;"The No. 1 thing I would say is, this kind of user experience problem where when you're using any new kind of decentralized technology, you need to set up a wallet, then you're getting tokens," Kazlauskas explained. Users may feel culture shock, wondering, "What does that even mean? How do I vote with this thing? Is this real money?"&lt;/p&gt;
&lt;p&gt;Kazlauskas is hoping that Vana supports a culture shift, striving to reach critical mass by giving users a "commercial lens" to start caring about data ownership. She also supports legislation like the Digital Choice Act in Utah, which "requires actually real-time API access, so people can get their data." If the US had a federal law like that, Kazlauskas suspects that launching Unwrapped would have been "so much easier."&lt;/p&gt;
&lt;p&gt;Although regulations like Utah's law could serve as a harbinger of a sea change, Kazlauskas noted that Big Tech companies that currently control AI markets employ a fierce lobbying force to maintain control over user data that decentralized movements just don't have.&lt;/p&gt;
&lt;p&gt;As Vana partners with Flower AI, striving, as Wired reported, to "shake up the AI industry" by releasing "a giant 100 billion-parameter model" later this year, Kazlauskas remains committed to ensuring that users are in control and "not just consumed." She fears a future where tech giants may be motivated to use AI to surveil, influence, or manipulate users, when instead users could choose to band together and benefit from building more ethical AI.&lt;/p&gt;
&lt;p&gt;"A world where a single company controls AI is honestly really dystopian," Kazlauskas told Ars. "I think that it is really scary. And so I think that the path that decentralized AI offers is one where a large group of people are still in control, and you still get really powerful technology."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/spotify-peeved-after-10000-users-sold-data-to-build-ai-tools/</guid><pubDate>Wed, 10 Sep 2025 16:23:25 +0000</pubDate></item><item><title>[NEW] Humanoids, AVs, and what’s next in AI hardware at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/humanoids-avs-and-whats-next-in-ai-hardware-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits Moscone West in San Francisco from October 27 to 29, bringing together 10,000+ startup and VC leaders for three days of bold ideas, groundbreaking tech, and future-shaping conversations. One of the most highly anticipated &lt;strong&gt;sessions happening on one of the two AI Stages&lt;/strong&gt; will spotlight where AI hardware is heading next, featuring a live look at the robotics and autonomous systems pushing boundaries in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI may be reshaping software, but when it comes to robotics and autonomous systems, the big breakout moment is still on the horizon. That’s what makes this session at TC Disrupt 2025 so compelling. &lt;strong&gt;Raquel Urtasun&lt;/strong&gt;, founder and CEO of &lt;strong&gt;Waabi&lt;/strong&gt;, and &lt;strong&gt;Jeff Cardenas&lt;/strong&gt;, co-founder and CEO of &lt;strong&gt;Apptronik&lt;/strong&gt;, are joining forces on the Builder Stage to talk about what it takes to put intelligence into motion — whether it’s behind the wheel or on two legs.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Jeff Cardenas Raquel Urtasun" class="wp-image-3026927" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_CardenasUrtasun-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-ai-meets-real-world-physics"&gt;&lt;br /&gt;&lt;strong&gt;AI meets real-world physics&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;This conversation dives into the complex systems that power autonomous vehicles and humanoid robots — and the simulation, sensors, and software infrastructure needed to scale them safely. Both Waabi and Apptronik are pushing the limits of what’s possible in the physical world. At Disrupt, they’ll walk us through the breakthroughs and bottlenecks shaping the next generation of intelligent machines.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI is already changing how we build, ship, and move — but physical deployment brings a unique set of constraints and opportunities. Expect a grounded, forward-looking discussion on how the smartest robots and self-driving platforms are coming to life, and what that means for the future of industry, labor, and infrastructure.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Catch Raquel Urtasun and Jeff Cardenas on the AI Stage at TechCrunch Disrupt 2025, happening October 27 to 29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices increase.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits Moscone West in San Francisco from October 27 to 29, bringing together 10,000+ startup and VC leaders for three days of bold ideas, groundbreaking tech, and future-shaping conversations. One of the most highly anticipated &lt;strong&gt;sessions happening on one of the two AI Stages&lt;/strong&gt; will spotlight where AI hardware is heading next, featuring a live look at the robotics and autonomous systems pushing boundaries in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI may be reshaping software, but when it comes to robotics and autonomous systems, the big breakout moment is still on the horizon. That’s what makes this session at TC Disrupt 2025 so compelling. &lt;strong&gt;Raquel Urtasun&lt;/strong&gt;, founder and CEO of &lt;strong&gt;Waabi&lt;/strong&gt;, and &lt;strong&gt;Jeff Cardenas&lt;/strong&gt;, co-founder and CEO of &lt;strong&gt;Apptronik&lt;/strong&gt;, are joining forces on the Builder Stage to talk about what it takes to put intelligence into motion — whether it’s behind the wheel or on two legs.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Jeff Cardenas Raquel Urtasun" class="wp-image-3026927" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_CardenasUrtasun-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-ai-meets-real-world-physics"&gt;&lt;br /&gt;&lt;strong&gt;AI meets real-world physics&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;This conversation dives into the complex systems that power autonomous vehicles and humanoid robots — and the simulation, sensors, and software infrastructure needed to scale them safely. Both Waabi and Apptronik are pushing the limits of what’s possible in the physical world. At Disrupt, they’ll walk us through the breakthroughs and bottlenecks shaping the next generation of intelligent machines.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI is already changing how we build, ship, and move — but physical deployment brings a unique set of constraints and opportunities. Expect a grounded, forward-looking discussion on how the smartest robots and self-driving platforms are coming to life, and what that means for the future of industry, labor, and infrastructure.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Catch Raquel Urtasun and Jeff Cardenas on the AI Stage at TechCrunch Disrupt 2025, happening October 27 to 29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices increase.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/humanoids-avs-and-whats-next-in-ai-hardware-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 10 Sep 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Anthropic reports outages, Claude and Console impacted (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/anthropic-reports-outages-claude-and-console-impacted/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic reported a service outage impacting APIs, Console, and Claude earlier this afternoon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users on GitHub and Hacker News noted issues with Claude at around 12:20 ET, with Anthropic releasing a status update eight minutes later, noting that its APIs, Console, and Claude AI were down. At press time, the company said it had implemented several fixes and was monitoring the results. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re aware of a very brief outage of our API today shortly before 9:30am PT,” an Anthropic spokesperson told TechCrunch. “Service was quickly restored.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is no stranger to errors or bugs on its platform and has had some issues in the past few months, especially regarding Claude and its models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Claude users awaited its reboot, some joked about what they were supposed to do since the system was down. One user on GitHub wrote about how the software engineering community was now twiddling its thumbs, while another on Hacker News quoted what someone said last time something like this happened: “Nooooo I’m going to have to use my brain again and write 100% of my code like a caveman from December 2024.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic reported a service outage impacting APIs, Console, and Claude earlier this afternoon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users on GitHub and Hacker News noted issues with Claude at around 12:20 ET, with Anthropic releasing a status update eight minutes later, noting that its APIs, Console, and Claude AI were down. At press time, the company said it had implemented several fixes and was monitoring the results. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re aware of a very brief outage of our API today shortly before 9:30am PT,” an Anthropic spokesperson told TechCrunch. “Service was quickly restored.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is no stranger to errors or bugs on its platform and has had some issues in the past few months, especially regarding Claude and its models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Claude users awaited its reboot, some joked about what they were supposed to do since the system was down. One user on GitHub wrote about how the software engineering community was now twiddling its thumbs, while another on Hacker News quoted what someone said last time something like this happened: “Nooooo I’m going to have to use my brain again and write 100% of my code like a caveman from December 2024.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/anthropic-reports-outages-claude-and-console-impacted/</guid><pubDate>Wed, 10 Sep 2025 17:33:05 +0000</pubDate></item><item><title>[NEW] YouTube’s multi-language audio feature for dubbing videos rolls out to all creators (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/10/youtubes-multi-language-audio-feature-for-dubbing-videos-rolls-out-to-all-creators/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/04/youtube-ios-app.webp?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube announced on Wednesday that its multi-language audio feature has officially launched after a two-year-long pilot. Now, millions of YouTubers can add dubbing to their videos in different languages, helping them reach a wider global audience. The rollout is expected to happen over the coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature initially launched as a pilot in 2023, available to a limited number of creators, including MrBeast, Mark Rober, and chef Jamie Oliver. Creators had to work with third-party dubbing services until YouTube introduced an AI-powered auto-dubbing tool that leverages Google’s Gemini technology to replicate a creator’s tone and emotions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since its launch, YouTube reports that several testers have seen success with this feature. On average, those who uploaded multi-language audio tracks saw over 25% of their watch time coming from views in the video’s non-primary language. Jamie Oliver’s channel, for instance, tripled in views after using multi-language audio tracks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company has been testing multi-language thumbnails with a select group of creators. Since June, creators have been able to customize thumbnails to display text in other languages, catering to their international audience. The localized thumbnails are designed to include text that matches the viewers’ preferred languages.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/04/youtube-ios-app.webp?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube announced on Wednesday that its multi-language audio feature has officially launched after a two-year-long pilot. Now, millions of YouTubers can add dubbing to their videos in different languages, helping them reach a wider global audience. The rollout is expected to happen over the coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature initially launched as a pilot in 2023, available to a limited number of creators, including MrBeast, Mark Rober, and chef Jamie Oliver. Creators had to work with third-party dubbing services until YouTube introduced an AI-powered auto-dubbing tool that leverages Google’s Gemini technology to replicate a creator’s tone and emotions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since its launch, YouTube reports that several testers have seen success with this feature. On average, those who uploaded multi-language audio tracks saw over 25% of their watch time coming from views in the video’s non-primary language. Jamie Oliver’s channel, for instance, tripled in views after using multi-language audio tracks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company has been testing multi-language thumbnails with a select group of creators. Since June, creators have been able to customize thumbnails to display text in other languages, catering to their international audience. The localized thumbnails are designed to include text that matches the viewers’ preferred languages.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/10/youtubes-multi-language-audio-feature-for-dubbing-videos-rolls-out-to-all-creators/</guid><pubDate>Wed, 10 Sep 2025 17:58:32 +0000</pubDate></item><item><title>[NEW] Developers joke about “coding like cavemen” as AI service suffers major outage (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/developers-joke-about-coding-like-cavemen-as-ai-service-suffers-major-outage/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Anthropic outage takes down AI tools some developers rely on to create software.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This is fine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday afternoon, Anthropic experienced a brief but complete service outage that took down its AI infrastructure, leaving developers unable to access Claude.ai, the API, Claude Code, or the management console for around half an hour. The outage affected all three of Anthropic's main services simultaneously, with the company posting at 12:28 pm Eastern that "APIs, Console, and Claude.ai are down. Services will be restored as soon as possible." As of press time, the services appear to be restored.&lt;/p&gt;
&lt;p&gt;The disruption, though lasting only about 30 minutes, quickly took the top spot on tech link-sharing site Hacker News for a short time and inspired immediate reactions from developers who have become increasingly reliant on AI coding tools for their daily work. "Everyone will just have to learn how to do it like we did in the old days, and blindly copy and paste from Stack Overflow," joked one Hacker News commenter. Another user recalled a joke from a previous AI outage: "Nooooo I'm going to have to use my brain again and write 100% of my code like a caveman from December 2024."&lt;/p&gt;
&lt;p&gt;The most recent outage came at an inopportune time, affecting developers across the US who have integrated Claude into their workflows. One Hacker News user observed: "It's like every other day, the moment US working hours start, AI (in my case I mostly use Anthropic, others may be better) starts dying or at least getting intermittent errors. In EU working hours there's rarely any outages." Another user also noted this pattern, saying that "early morning here in the UK everything is fine, as soon as most of the US is up and at it, then it slowly turns to treacle."&lt;/p&gt;
&lt;p&gt;While some users criticized Anthropic for reliability issues in recent months, the company's status page acknowledged the issue within 39 minutes of the initial reports, and by 12:55 pm Eastern announced that a fix had been implemented and that the company's teams were monitoring the results.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Growing dependency on AI coding tools&lt;/h2&gt;
&lt;p&gt;The speed at which news of the outage spread shows how deeply embedded AI coding assistants have already become in modern software development. Claude Code, announced in February and widely launched in May, is Anthropic's terminal-based coding agent that can perform multi-step coding tasks across an existing code base.&lt;/p&gt;
&lt;p&gt;The tool competes with OpenAI's Codex feature, a coding agent that generates production-ready code in isolated containers, Google's Gemini CLI, Microsoft's GitHub Copilot, which itself can use Claude models for code, and Cursor, a popular AI-powered IDE built on VS Code that also integrates multiple AI models, including Claude.&lt;/p&gt;
&lt;p&gt;During today's outage, some developers turned to alternative solutions. "Z.AI works fine. Qwen works fine. Glad I switched," posted one user on Hacker News. Others joked about reverting to older methods, with one suggesting the "pseudo-LLM experience" could be achieved with a Python package that imports code directly from Stack Overflow.&lt;/p&gt;
&lt;p&gt;While AI coding assistants have accelerated development for some users, they've also caused problems for others who rely on them too heavily. The emerging practice of so-called "vibe coding"—using natural language to generate and execute code through AI models without fully understanding the underlying operations—has led to catastrophic failures.&lt;/p&gt;
&lt;p&gt;In recent incidents, Google's Gemini CLI destroyed user files while attempting to reorganize them, and Replit's AI coding service deleted a production database despite explicit instructions not to modify code. These failures occurred when the AI models confabulated successful operations and built subsequent actions on false premises, highlighting the risks of depending on AI assistants that can misinterpret file structures or fabricate data to hide their errors.&lt;/p&gt;
&lt;p&gt;Wednesday's outage served as a reminder that as dependency on AI grows, even minor service disruptions can become major events that affect an entire profession. But perhaps that could be a good thing if it's an excuse to take a break from a stressful workload. As one commenter joked, it might be "time to go outside and touch some grass again."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Anthropic outage takes down AI tools some developers rely on to create software.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This is fine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday afternoon, Anthropic experienced a brief but complete service outage that took down its AI infrastructure, leaving developers unable to access Claude.ai, the API, Claude Code, or the management console for around half an hour. The outage affected all three of Anthropic's main services simultaneously, with the company posting at 12:28 pm Eastern that "APIs, Console, and Claude.ai are down. Services will be restored as soon as possible." As of press time, the services appear to be restored.&lt;/p&gt;
&lt;p&gt;The disruption, though lasting only about 30 minutes, quickly took the top spot on tech link-sharing site Hacker News for a short time and inspired immediate reactions from developers who have become increasingly reliant on AI coding tools for their daily work. "Everyone will just have to learn how to do it like we did in the old days, and blindly copy and paste from Stack Overflow," joked one Hacker News commenter. Another user recalled a joke from a previous AI outage: "Nooooo I'm going to have to use my brain again and write 100% of my code like a caveman from December 2024."&lt;/p&gt;
&lt;p&gt;The most recent outage came at an inopportune time, affecting developers across the US who have integrated Claude into their workflows. One Hacker News user observed: "It's like every other day, the moment US working hours start, AI (in my case I mostly use Anthropic, others may be better) starts dying or at least getting intermittent errors. In EU working hours there's rarely any outages." Another user also noted this pattern, saying that "early morning here in the UK everything is fine, as soon as most of the US is up and at it, then it slowly turns to treacle."&lt;/p&gt;
&lt;p&gt;While some users criticized Anthropic for reliability issues in recent months, the company's status page acknowledged the issue within 39 minutes of the initial reports, and by 12:55 pm Eastern announced that a fix had been implemented and that the company's teams were monitoring the results.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Growing dependency on AI coding tools&lt;/h2&gt;
&lt;p&gt;The speed at which news of the outage spread shows how deeply embedded AI coding assistants have already become in modern software development. Claude Code, announced in February and widely launched in May, is Anthropic's terminal-based coding agent that can perform multi-step coding tasks across an existing code base.&lt;/p&gt;
&lt;p&gt;The tool competes with OpenAI's Codex feature, a coding agent that generates production-ready code in isolated containers, Google's Gemini CLI, Microsoft's GitHub Copilot, which itself can use Claude models for code, and Cursor, a popular AI-powered IDE built on VS Code that also integrates multiple AI models, including Claude.&lt;/p&gt;
&lt;p&gt;During today's outage, some developers turned to alternative solutions. "Z.AI works fine. Qwen works fine. Glad I switched," posted one user on Hacker News. Others joked about reverting to older methods, with one suggesting the "pseudo-LLM experience" could be achieved with a Python package that imports code directly from Stack Overflow.&lt;/p&gt;
&lt;p&gt;While AI coding assistants have accelerated development for some users, they've also caused problems for others who rely on them too heavily. The emerging practice of so-called "vibe coding"—using natural language to generate and execute code through AI models without fully understanding the underlying operations—has led to catastrophic failures.&lt;/p&gt;
&lt;p&gt;In recent incidents, Google's Gemini CLI destroyed user files while attempting to reorganize them, and Replit's AI coding service deleted a production database despite explicit instructions not to modify code. These failures occurred when the AI models confabulated successful operations and built subsequent actions on false premises, highlighting the risks of depending on AI assistants that can misinterpret file structures or fabricate data to hide their errors.&lt;/p&gt;
&lt;p&gt;Wednesday's outage served as a reminder that as dependency on AI grows, even minor service disruptions can become major events that affect an entire profession. But perhaps that could be a good thing if it's an excuse to take a break from a stressful workload. As one commenter joked, it might be "time to go outside and touch some grass again."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/developers-joke-about-coding-like-cavemen-as-ai-service-suffers-major-outage/</guid><pubDate>Wed, 10 Sep 2025 18:08:49 +0000</pubDate></item></channel></rss>