<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 30 Jun 2025 18:31:07 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Exploring how AI has changed daily life (AI News)</title><link>https://www.artificialintelligence-news.com/news/exploring-how-ai-has-changed-daily-life/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/06/igor-omilaev-FHgWFzDDAOs-unsplash-2-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The impact of artificial intelligence on society continues to increase, with the technology enhancing and improving the ways in which people go about their daily lives. From carrying out mundane admin tasks to speeding up working processes, the world is more efficient thanks to AI.&lt;/p&gt;&lt;p&gt;In recent years, the influence of AI technology has grown. Now, in 2025, it is an important tool, and it’s hard to remember what life was like before. The article will assess the many ways AI has had an impact on the world.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-secure-payment-methods"&gt;Secure payment methods&lt;/h3&gt;&lt;p&gt;Cash used to dominate everyday transactions but today, people can choose from a range of payment methods when making purchases. Whether buying online or in person, there are many options to choose from, meeting a range of individual needs and preferences.&lt;/p&gt;&lt;p&gt;With digital payments comes a need to improve security, streamline transactions, and enhance the user experience. Artificial intelligence is an important tool for payment processes. In Bitcoin transactions, for example, AI can detect fraudulent activity by assessing payment patterns and user behaviour. This helps ensure personal information and financial details are kept safer, protected from malicious actors or would-be hackers.&lt;/p&gt;&lt;p&gt;AI is also capable of predicting market fluctuations, imperative when using any Bitcoin price tracker so users can assess volatility and price changes to make smarter decisions. The algorithms which ensure more efficient and secure Bitcoin payments can also optimise payment routing and reduce transaction fees. The introduction of AI has made such payment methods safer, faster, and seamless, making Bitcoin payments more attractive.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-improving-healthcare"&gt;Improving healthcare&lt;/h3&gt;&lt;p&gt;The healthcare industry has benefited from artificial intelligence, helping people with a range of diagnoses and medical treatments. Diagnostic accuracy has improved thanks to machine learning algorithms, which can help medical professionals diagnose symptoms early.&lt;/p&gt;&lt;p&gt;AI has streamlined administrative tasks in the sector, freeing time for the workforce to focus on other tasks. Personalised treatment plans can be created based on individual patient data, plus predictive analytics can better manage outcomes, optimising the allocation of resources.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-to-watch"&gt;What to watch&lt;/h3&gt;&lt;p&gt;Streaming platforms such Netflix always seem to know in advance what would be good to show next. When viewers flick through their options, artificial intelligence gathers information to tailor user experience and compile a list of possible titles that match individual tastes, based on viewing history.&lt;/p&gt;&lt;p&gt;AI can analyse viewing behaviour, assess any ratings given to a programme, and search for specific patterns that can identify preferences and viewing habits.&lt;/p&gt;&lt;p&gt;Machine learning algorithms can also make recommendations based on the actors in a movie, or identify the types of programmes enjoyed in the past. Every second viewed on the platform is documented to improve viewing experiences.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pointing-in-the-right-direction"&gt;Pointing in the right direction&lt;/h3&gt;&lt;p&gt;Rather than relying on a map and navigation skills, it’s possible to journey from A to B with the assistance of AI working on a smartphone. Technology can analyse live traffic data and road conditions in real-time to accurately give the best route.&lt;/p&gt;&lt;p&gt;When entering a destination, if the device recognises a journey made previously, the tech is able to recall this and can suggest the best route. Voice recognition on a smartphone also uses AI to let users go hands-free, navigating the route.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-customer-support-services"&gt;Customer support services&lt;/h3&gt;&lt;p&gt;Businesses need to offer customers support services to build trust and loyalty. Using AI, companies can use chatbots and virtual assistants to answer queries instantly.&lt;/p&gt;&lt;p&gt;Where previously, customers may have had to call within certain hours, wait for a callback or email response, chatbots can now help quickly, working alongside knowledgeable human staff trained to address any problem. The reduction in time wasted means customers can get back to enjoying services rather than getting stressed as they are forced to wait.&lt;/p&gt;&lt;p&gt;Artificial intelligence has had a major influence on society in recent years. Now relied on by several sectors, the technology used has proved beneficial people from every corner of the globe. AI is likely to get more important, and make everyday life just that little bit easier.&amp;nbsp;&lt;/p&gt;&lt;p&gt;(Image source: Unsplash)&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/06/igor-omilaev-FHgWFzDDAOs-unsplash-2-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The impact of artificial intelligence on society continues to increase, with the technology enhancing and improving the ways in which people go about their daily lives. From carrying out mundane admin tasks to speeding up working processes, the world is more efficient thanks to AI.&lt;/p&gt;&lt;p&gt;In recent years, the influence of AI technology has grown. Now, in 2025, it is an important tool, and it’s hard to remember what life was like before. The article will assess the many ways AI has had an impact on the world.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-secure-payment-methods"&gt;Secure payment methods&lt;/h3&gt;&lt;p&gt;Cash used to dominate everyday transactions but today, people can choose from a range of payment methods when making purchases. Whether buying online or in person, there are many options to choose from, meeting a range of individual needs and preferences.&lt;/p&gt;&lt;p&gt;With digital payments comes a need to improve security, streamline transactions, and enhance the user experience. Artificial intelligence is an important tool for payment processes. In Bitcoin transactions, for example, AI can detect fraudulent activity by assessing payment patterns and user behaviour. This helps ensure personal information and financial details are kept safer, protected from malicious actors or would-be hackers.&lt;/p&gt;&lt;p&gt;AI is also capable of predicting market fluctuations, imperative when using any Bitcoin price tracker so users can assess volatility and price changes to make smarter decisions. The algorithms which ensure more efficient and secure Bitcoin payments can also optimise payment routing and reduce transaction fees. The introduction of AI has made such payment methods safer, faster, and seamless, making Bitcoin payments more attractive.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-improving-healthcare"&gt;Improving healthcare&lt;/h3&gt;&lt;p&gt;The healthcare industry has benefited from artificial intelligence, helping people with a range of diagnoses and medical treatments. Diagnostic accuracy has improved thanks to machine learning algorithms, which can help medical professionals diagnose symptoms early.&lt;/p&gt;&lt;p&gt;AI has streamlined administrative tasks in the sector, freeing time for the workforce to focus on other tasks. Personalised treatment plans can be created based on individual patient data, plus predictive analytics can better manage outcomes, optimising the allocation of resources.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-to-watch"&gt;What to watch&lt;/h3&gt;&lt;p&gt;Streaming platforms such Netflix always seem to know in advance what would be good to show next. When viewers flick through their options, artificial intelligence gathers information to tailor user experience and compile a list of possible titles that match individual tastes, based on viewing history.&lt;/p&gt;&lt;p&gt;AI can analyse viewing behaviour, assess any ratings given to a programme, and search for specific patterns that can identify preferences and viewing habits.&lt;/p&gt;&lt;p&gt;Machine learning algorithms can also make recommendations based on the actors in a movie, or identify the types of programmes enjoyed in the past. Every second viewed on the platform is documented to improve viewing experiences.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pointing-in-the-right-direction"&gt;Pointing in the right direction&lt;/h3&gt;&lt;p&gt;Rather than relying on a map and navigation skills, it’s possible to journey from A to B with the assistance of AI working on a smartphone. Technology can analyse live traffic data and road conditions in real-time to accurately give the best route.&lt;/p&gt;&lt;p&gt;When entering a destination, if the device recognises a journey made previously, the tech is able to recall this and can suggest the best route. Voice recognition on a smartphone also uses AI to let users go hands-free, navigating the route.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-customer-support-services"&gt;Customer support services&lt;/h3&gt;&lt;p&gt;Businesses need to offer customers support services to build trust and loyalty. Using AI, companies can use chatbots and virtual assistants to answer queries instantly.&lt;/p&gt;&lt;p&gt;Where previously, customers may have had to call within certain hours, wait for a callback or email response, chatbots can now help quickly, working alongside knowledgeable human staff trained to address any problem. The reduction in time wasted means customers can get back to enjoying services rather than getting stressed as they are forced to wait.&lt;/p&gt;&lt;p&gt;Artificial intelligence has had a major influence on society in recent years. Now relied on by several sectors, the technology used has proved beneficial people from every corner of the globe. AI is likely to get more important, and make everyday life just that little bit easier.&amp;nbsp;&lt;/p&gt;&lt;p&gt;(Image source: Unsplash)&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/exploring-how-ai-has-changed-daily-life/</guid><pubDate>Mon, 30 Jun 2025 08:49:23 +0000</pubDate></item><item><title>Meet Jim O’Neill, the longevity enthusiast who is now RFK Jr.’s right-hand man (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/30/1119449/hhs-robert-f-kennedy-jr-jim-oneill-longevity-maha/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Tech-review_Jim-ONeill_final.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Jim O’Neill was nominated to be the second in command at the US Department of Health and Human Services, Dylan Livingston was excited. As founder and CEO of the lobbying group Alliance for Longevity Initiatives (A4LI), Livingston is a member of a community that seeks to extend human lifespan. O’Neill is “kind of one of us,” he told me shortly before O’Neill was sworn in as deputy secretary on June 9. “And now [he’s] in a position of great influence.”&lt;/p&gt;  &lt;p&gt;As Robert F. Kennedy Jr.’s new right-hand man, O’Neill is expected to wield authority at health agencies that fund biomedical research and oversee the regulation of new drugs. And while O’Neill doesn’t subscribe to Kennedy’s most contentious beliefs—and supports existing vaccine schedules—he may still steer the agencies in controversial new directions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Although much less of a public figure than his new boss, O’Neill is quite well-known in the increasingly well-funded and tight-knit longevity community. His acquaintances include the prominent longevity influencer Bryan Johnson, who describes him as “a soft-spoken, thoughtful, methodical guy,” and the billionaire tech entrepreneur Peter Thiel.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In speaking with more than 20 people who work in the longevity field and are familiar with O’Neill, it’s clear that they share a genuine optimism about his leadership. And while no one can predict exactly what O’Neill will do, many in the community believe that he could help bring attention and resources to their cause and make it easier for them to experiment with potential anti-aging drugs.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This idea is bolstered not just by his personal and professional relationships but also by his past statements and history working at aging-focused organizations—all of which suggest he indeed believes scientists should be working on ways to extend human lifespan beyond its current limits and thinks unproven therapies should be easier to access. He has also supported the libertarian idea of creating new geographic zones, possibly at sea, in which residents can live by their own rules (including, notably, permissive regulatory regimes for new drugs and therapies).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“In [the last three administrations] there weren’t really people like that from our field taking these positions of power,” says Livingston, adding that O’Neill’s elevation is “definitely something to be excited about.”&lt;/p&gt; 
 &lt;p&gt;Not everyone working in health is as enthusiastic. If O’Neill still holds the views he has espoused over the years, that’s “worrisome,” says Diana Zuckerman, a health policy analyst and president of the National Center for Health Research, a nonprofit think tank in Washington, DC.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s nothing worse than getting a bunch of [early-stage unproven therapies] on the market,” she says. Those products might be dangerous and could make people sick while enriching those who develop or sell them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Getting things on the market quickly means that everybody becomes a guinea pig,” Zuckerman says. “That’s not the way those of us who care about health care think.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The consumer advocacy group Public Citizen puts it far more bluntly, describing O’Neill as “one of Trump’s worst picks” and saying that he is “unfit to be the #2 US health-care leader.” His libertarian views are “antithetical to basic public health,” the organization’s co-president said in a statement. Neither O’Neill nor HHS responded to requests for comment.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;h3 class="wp-block-heading"&gt;“One of us”&lt;/h3&gt;  &lt;p&gt;As deputy secretary of HHS, O’Neill will oversee a number of agencies, including the National Institutes of Health, the world’s biggest funder of biomedical research; the Centers for Disease Control and Prevention, the country’s public health agency; and the Food and Drug Administration, which was created to ensure that drugs and medical devices are safe and effective.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It can be a quite powerful position,” says Patricia Zettler, a legal scholar at Ohio State University who specializes in drug regulation and the FDA.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;It is the most senior role O’Neill has held at HHS, though it’s not the first. He occupied various positions in the department over five years during the early 2000s, according to his LinkedIn profile. But it is what he did after that has helped him cultivate a reputation as an ally for longevity enthusiasts.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill appears to have had a close relationship with Thiel since at least the late 2000s. Thiel has heavily invested in longevity research and has said he does not believe that death is inevitable. In 2011 O’Neill referred to Thiel as his “friend and patron.” (A representative for Thiel did not respond to a request for comment.)&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;O’Neill also served as CEO of the Thiel Foundation between 2009 and 2012 and cofounded the Thiel Fellowship, which offers $200,000 to promising young people if they drop out of college and do other work. And he spent seven years as managing director of Mithril Capital Management, a “family of long-term venture capital funds” founded by Thiel, according to O’Neill’s LinkedIn profile.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill got further stitched into the longevity field when he spent more than a decade representing Thiel’s interests as a board member of the SENS Research Foundation (SRF), an organization dedicated to finding treatments for aging, to which Thiel was a significant donor.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill even spent a couple of years as CEO of SRF, from 2019 to 2021, when its founder Aubrey de Grey, a prominent figure in the longevity field, was removed following accusations of sexual harassment. As CEO, O’Neill oversaw a student education program and multiple scientific research projects that focused on various aspects of aging, according to the organization’s annual reports. And in a 2020 SRF annual report, O’Neill wrote that Eric Hargan, then the deputy secretary of HHS, had attended an SRF conference to discuss “regulatory reform.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“More and more influential people consider aging an absurdity,” he wrote in the report. “Now we need to make it one.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;While de Grey calls him “the devil incarnate”—probably because he believes O’Neill “incited” two women to make sexual harassment allegations against him—the many other scientists, biotech CEOs, and other figures in the longevity field contacted by &lt;em&gt;MIT Technology Review&lt;/em&gt; had more positive opinions of O’Neill, with many claiming they were longtime friends or acquaintances of the new deputy secretary (though, at the same time, many were reluctant to share specific views about his past work).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Longevity science is a field that’s long courted controversy, owing largely to far-fetched promises of immortality and the ongoing marketing of creams, pills, intravenous infusions, and other so-called anti-aging treatments that are not supported by evidence. But the community includes people along a spectrum of beliefs (with the goals of adding a few years of healthy lifespan to the population at one end and immortality at the other), and serious doctors and scientists are working to bring legitimacy to the field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Pretty much everyone in the field that I spoke with appears to be hopeful about what O’Neill will do now that he’s been confirmed. Namely, they hope he will use his new position to direct attention and funds to legitimate longevity research and the development of new drugs that might slow or reverse human aging.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Johnson, whose extreme and expensive approaches to extending his own lifespan have made him something of a celebrity, calls O’Neill a friend and says they’ve “known each other for a little over 15 years.” He says he can imagine O’Neill setting a goal to extend the lifespans of Americans.&lt;/p&gt; 
 &lt;p&gt;Eric Verdin, president of the Buck Institute for Research on Aging in Novato, California, says O’Neill has “been at the Buck several times” and calls him “a good guy”—someone who is “serious” and who understands the science of aging. He says, “He’s certainly someone who is going to help us to really bring the longevity field to the front of the priorities of this administration.”&lt;/p&gt;  &lt;p&gt;Celine Halioua, CEO of the biotech company Loyal, which is developing drugs to extend the lifespan of dogs, echoes these sentiments, saying she has “always liked and respected” O’Neill. “It’ll definitely be nice to have somebody who’s bought into the thesis [of longevity science] at the FDA,” she says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And Joe Betts-LaCroix, CEO of the longevity biotech company Retro Biosciences, says he’s known O’Neill for something like 10 years and describes him as “smart and clear thinking.” “We’ve mutually been part of poetry readings,” he says. “He’s been definitely interested in wanting us as a society to make progress on age-related disease.”&lt;/p&gt;  &lt;p&gt;After his confirmation, the A4LI LinkedIn account posted a photo of Livingston, its CEO, with O’Neill, writing that “we look forward to working with him to elevate aging research as a national priority and to modernize regulatory pathways that support the development of longevity medicines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;“His work at SENS Research Foundation [suggests] to me and to others that [longevity] is going to be something that he prioritizes,” Livingston says. “I think he’s a supporter of this field, and that’s really all that matters right now to us.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Changing the rules&lt;/h3&gt;  &lt;p&gt;While plenty of treatments have been shown to slow aging in lab animals, none of them have been found to successfully slow or reverse human aging. And many longevity enthusiasts believe drug regulations are to blame.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill is one of them. He has long supported deregulation of new drugs and medical devices. During his first tour at HHS, for instance, he pushed back against regulations on the use of algorithms in medical devices. “FDA had to argue that an algorithm … is a medical device,” he said in a 2014 presentation at a meeting on “rejuvenation biotechnology.” “I managed to put a stop to that, at least while I was there.”&lt;/p&gt;  &lt;p&gt;During the same presentation, O’Neill advocated lowering the bar for drug approvals in the US. “We should reform [the] FDA so that it is approving drugs after their sponsors have demonstrated safety and let people start using them at their own risk,” he said. “Let’s prove efficacy after they’ve been legalized.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;This sentiment appears to be shared by Robert F. Kennedy Jr. In a recent podcast interview with Gary Brecka, who describes himself as a “longevity expert,” Kennedy said that he wanted to expand access to experimental therapies. “If you want to take an experimental drug … you ought to be able to do that,” he said in the episode, which was published online in May.&lt;/p&gt;  &lt;p&gt;But the idea is divisive. O’Neill was essentially suggesting that drugs be made available after the very first stage of clinical testing, which is designed to test whether a new treatment is safe. These tests are typically small and don’t reveal whether the drug actually works.&lt;/p&gt;  &lt;p&gt;That’s an idea that concerns ethicists. “It’s just absurd to think that the regulatory agency that’s responsible for making sure that products are safe and effective before they're made available to patients couldn’t protect patients from charlatans,” says Holly Fernandez Lynch, a professor of medical ethics and health policy at the University of Pennsylvania who is currently on sabbatical. “It’s just like a complete dereliction of duty.”&lt;/p&gt;  &lt;p&gt;Robert Steinbrook, director of the health research group at Public Citizen, largely agrees that this kind of change to the drug approval process is a bad idea, though notes that he and his colleagues are generally more concerned about O’Neill’s views on the regulation of technologies like AI in health care, given his previous efforts on algorithms.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“He has deregulatory views and would not be an advocate for an appropriate amount of regulation when regulation was needed,” Steinbrook says.&lt;/p&gt;  &lt;p&gt;Ultimately, though, even if O’Neill does try to change things, Zettler points out that there is currently no lawful way for the FDA to approve drugs that aren’t shown to be effective. That requirement won’t change unless Congress acts on the matter, she says: “It remains to be seen how big of a role HHS leadership will have in FDA policy on that front.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A longevity state&lt;/h3&gt;  &lt;p&gt;A major goal for a subset of longevity enthusiasts relates to another controversial idea: creating new geographic zones in which people can live by their own rules. The goal has taken various forms, including “network states” (which could start out as online social networks and evolve into territories that make use of cryptocurrency), “special economic zones,” and more recently “freedom cities.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While specific details vary, the fundamental concept is creating a new society, beyond the limits of nations and governments, as a place to experiment with new approaches to rules and regulations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2023, for instance, a group of longevity enthusiasts met at a temporary “pop-up city” in Montenegro to discuss plans to establish a “longevity state”—a geographic zone with a focus on extending human lifespan. Such a zone might encourage healthy behaviors and longevity research, as well as a fast-tracked system to approve promising-looking longevity drugs. They considered Rhode Island as the site but later changed their minds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;Some of those same longevity enthusiasts have set up shop in Próspera, Honduras—a “special economic zone” on the island of Roatán with a libertarian approach to governance, where residents are able to make their own suggestions for medical regulations. Another pop-up city, Vitalia, was set up there for two months in 2024, complete with its own biohacking lab; it also happened to be in close proximity to an established clinic selling an unproven longevity “gene therapy” for around $20,000. The people behind Vitalia referred to it as “a Los Alamos for longevity.” Another new project, Infinita City, is now underway in the former Vitalia location.&lt;/p&gt;  &lt;p&gt;O’Neill has voiced support for this broad concept, too. He’s posted on X about his support for limiting the role of government, writing “Get government out of the way” and, in reference to bills to shrink what some politicians see as government overreach, “No reason to wait.” And more to the point, he wrote on X last November, “Build freedom cities,” reposting another message that said: “I love the idea and think we should put the first one on the former Alameda Naval Air Station on the San Francisco Bay.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And up until March of last year, according to his financial disclosures, he served on the board of directors of the Seasteading Institute, an organization with the goal of creating “startup countries” at sea. “We are also negotiating with countries to establish a SeaZone (a specially designed economic zone where seasteading companies could build their platforms),” the organization explains on its website.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;“The healthiest societies in 2030 will most likely be on the sea,” O’Neill told an audience at a Seasteading Institute conference in 2009. In that presentation, he talked up the benefits of a free market for health care, saying that seasteads could offer improved health care and serve as medical tourism hubs: “The last best hope for freedom is on the sea.”&lt;/p&gt;  &lt;p&gt;Some in the longevity community see the ultimate goal as establishing a network state within the US. “That’s essentially what we’re doing in Montana,” says A4LI’s Livingston, referring to his successful lobbying efforts to create a hub for experimental medicine there. Over the last couple of years, the state has expanded Right to Try laws, which were originally designed to allow terminally ill individuals to access unproven treatments. Under new state laws, anyone can access such treatments, providing they have been through an initial phase I trial as a preliminary safety test.&lt;/p&gt;  &lt;p&gt;“We’re doing a freedom city in Montana without calling it a freedom city,” says Livingston.&lt;/p&gt;  &lt;p&gt;Patri Friedman, the libertarian founder of the Seasteading Institute, who calls O’Neill “a close friend,” explains that part of the idea of freedom cities is to create “specific industry clusters” on federal land in the US and win “regulatory carve-outs” that benefit those industries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A freedom city for longevity biotech is “being discussed,” says Friedman, although he adds that those discussions are still in the very early stages. He says he’d possibly work with O’Neill on “changing regulations that are under HHS” but isn’t yet certain what that might involve: “We're still trying to research and define the whole program and gather support for it.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Will he deliver?&lt;/h3&gt;  &lt;p&gt;Some libertarians, including longevity enthusiasts, believe this is their moment to build a new experimental home.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Not only do they expect backing from O’Neill, but they believe President Trump has advocated for new economic zones, perhaps dedicated to the support of specific industries, that can set their own rules for governance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While campaigning for the presidency in 2023, Trump floated what seemed like a similar idea: “We should hold a contest to charter up to 10 new cities and award them to the best proposals for development,” he said in a recorded campaign speech. (The purpose of these new cities was somewhat vague. “These freedom cities will reopen the frontier, reignite the American imagination, and give hundreds of thousands of young people and other people—all hardworking families—a new shot at homeownership and in fact the American dream,” he said.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;But given how frequently Trump changes his mind, it’s hard to tell what the president, and others in the administration, will now support on this front.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;And even if HHS does try to create new geographic zones in some form, legal and regulatory experts say this approach won’t necessarily speed up drug development the way some longevity enthusiasts hope.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The notion around so-called freedom cities, with respect to biomedical innovation, just reflects deep misunderstandings of what drug development entails,” says Ohio State’s Zettler. “It’s not regulatory requirements that [slow down] drug development—it’s the scientific difficulty of assessing safety and effectiveness and of finding true therapies.”&lt;/p&gt;  &lt;p&gt;Making matters even murkier, a lot of the research geared toward finding those therapies has been subject to drastic cuts.The NIH is the largest funder of biomedical research in the world and has supported major scientific discoveries, including those that benefit longevity research. But in late March, HHS announced a “dramatic restructuring” that would involve laying off 10,000 full-time employees. Since Trump took office, over a thousand NIH research grants have been ended and the administration has announced plans to slash funding for “indirect” research costs—a move that would cost individual research institutions millions of dollars. Research universities (notably Harvard) have been the target of policies to limit or revoke visas for international students, demands to change curricula, and threats to their funding and tax-exempt status.&lt;/p&gt;  &lt;p&gt;The NIH also directly supports aging research. Notably, the Interventions Testing Program is a program run by the National Institutes of Aging (a branch of the NIH) to find drugs that make mice live longer. The idea is to understand the biology of aging and find candidates for human longevity drugs.&lt;/p&gt;  &lt;p&gt;The ITP has tested around five to seven drugs a year for over 20 years, says Richard Miller, a professor of pathology at the University of Michigan, one of three institutes involved in the program. “We’ve published eight winners so far,” he adds.&lt;/p&gt;  &lt;p&gt;The future of the ITP is uncertain, given recent actions of the Trump administration, he says. The cap on indirect costs alone would cost the University of Michigan around $181 million, the university’s interim vice president for research and innovation said in February. The proposals are subject to ongoing legal battles. But in the meantime, morale is low, says Miller. “In the worst-case scenario, all aging research [would be stopped],” he says.&lt;/p&gt;  &lt;p&gt;The A4LI has also had to tailor its lobbying strategy given the current administration’s position on government-funded research. Alongside its efforts to change Montana state law to allow clinics to sell unproven treatments, the organization had been planning to push for an all-new NIH institute dedicated to aging and longevity research—an idea that O’Neill voiced support for last year. But current funding cuts under the new administration suggest that it’s “not the ideal political climate for this,” says Livingston.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt;&lt;p&gt;Despite their enthusiasm for O’Neill’s confirmation, this has all left many members of the longevity community, particularly those with research backgrounds, concerned about what the cuts mean for the future of longevity science.&lt;/p&gt;  &lt;p&gt;“Someone like [O’Neill], who’s an advocate for aging and longevity, would be fantastic to have at HHS,” says Matthew O’Connor, who spent over a decade at SRF and says he knows O’Neill “pretty well.” But he adds that “we shouldn’t be cutting the NIH.” Instead, he argues, the agency’s funding should be multiplied by 10.&lt;/p&gt;  &lt;p&gt;“The solution to curing diseases isn’t to get rid of the organizations that are there to help us cure diseases,” adds O’Connor, who is currently co-CEO at Cyclarity Therapeutics, a company developing drugs for atherosclerosis and other age-related diseases.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it’s still just too soon to confidently predict how, if at all, O’Neill will shape the government health agencies he will oversee.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We don’t know exactly what he’s going to be doing as the deputy secretary of HHS,” says Public Citizen’s Steinbrook. “Like everybody who's sworn into a government job, whether we disagree or agree with their views or actions … we still wish them well. And we hope that they do a good job.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Tech-review_Jim-ONeill_final.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Jim O’Neill was nominated to be the second in command at the US Department of Health and Human Services, Dylan Livingston was excited. As founder and CEO of the lobbying group Alliance for Longevity Initiatives (A4LI), Livingston is a member of a community that seeks to extend human lifespan. O’Neill is “kind of one of us,” he told me shortly before O’Neill was sworn in as deputy secretary on June 9. “And now [he’s] in a position of great influence.”&lt;/p&gt;  &lt;p&gt;As Robert F. Kennedy Jr.’s new right-hand man, O’Neill is expected to wield authority at health agencies that fund biomedical research and oversee the regulation of new drugs. And while O’Neill doesn’t subscribe to Kennedy’s most contentious beliefs—and supports existing vaccine schedules—he may still steer the agencies in controversial new directions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Although much less of a public figure than his new boss, O’Neill is quite well-known in the increasingly well-funded and tight-knit longevity community. His acquaintances include the prominent longevity influencer Bryan Johnson, who describes him as “a soft-spoken, thoughtful, methodical guy,” and the billionaire tech entrepreneur Peter Thiel.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In speaking with more than 20 people who work in the longevity field and are familiar with O’Neill, it’s clear that they share a genuine optimism about his leadership. And while no one can predict exactly what O’Neill will do, many in the community believe that he could help bring attention and resources to their cause and make it easier for them to experiment with potential anti-aging drugs.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This idea is bolstered not just by his personal and professional relationships but also by his past statements and history working at aging-focused organizations—all of which suggest he indeed believes scientists should be working on ways to extend human lifespan beyond its current limits and thinks unproven therapies should be easier to access. He has also supported the libertarian idea of creating new geographic zones, possibly at sea, in which residents can live by their own rules (including, notably, permissive regulatory regimes for new drugs and therapies).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“In [the last three administrations] there weren’t really people like that from our field taking these positions of power,” says Livingston, adding that O’Neill’s elevation is “definitely something to be excited about.”&lt;/p&gt; 
 &lt;p&gt;Not everyone working in health is as enthusiastic. If O’Neill still holds the views he has espoused over the years, that’s “worrisome,” says Diana Zuckerman, a health policy analyst and president of the National Center for Health Research, a nonprofit think tank in Washington, DC.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s nothing worse than getting a bunch of [early-stage unproven therapies] on the market,” she says. Those products might be dangerous and could make people sick while enriching those who develop or sell them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Getting things on the market quickly means that everybody becomes a guinea pig,” Zuckerman says. “That’s not the way those of us who care about health care think.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The consumer advocacy group Public Citizen puts it far more bluntly, describing O’Neill as “one of Trump’s worst picks” and saying that he is “unfit to be the #2 US health-care leader.” His libertarian views are “antithetical to basic public health,” the organization’s co-president said in a statement. Neither O’Neill nor HHS responded to requests for comment.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;h3 class="wp-block-heading"&gt;“One of us”&lt;/h3&gt;  &lt;p&gt;As deputy secretary of HHS, O’Neill will oversee a number of agencies, including the National Institutes of Health, the world’s biggest funder of biomedical research; the Centers for Disease Control and Prevention, the country’s public health agency; and the Food and Drug Administration, which was created to ensure that drugs and medical devices are safe and effective.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It can be a quite powerful position,” says Patricia Zettler, a legal scholar at Ohio State University who specializes in drug regulation and the FDA.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;It is the most senior role O’Neill has held at HHS, though it’s not the first. He occupied various positions in the department over five years during the early 2000s, according to his LinkedIn profile. But it is what he did after that has helped him cultivate a reputation as an ally for longevity enthusiasts.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill appears to have had a close relationship with Thiel since at least the late 2000s. Thiel has heavily invested in longevity research and has said he does not believe that death is inevitable. In 2011 O’Neill referred to Thiel as his “friend and patron.” (A representative for Thiel did not respond to a request for comment.)&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;O’Neill also served as CEO of the Thiel Foundation between 2009 and 2012 and cofounded the Thiel Fellowship, which offers $200,000 to promising young people if they drop out of college and do other work. And he spent seven years as managing director of Mithril Capital Management, a “family of long-term venture capital funds” founded by Thiel, according to O’Neill’s LinkedIn profile.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill got further stitched into the longevity field when he spent more than a decade representing Thiel’s interests as a board member of the SENS Research Foundation (SRF), an organization dedicated to finding treatments for aging, to which Thiel was a significant donor.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill even spent a couple of years as CEO of SRF, from 2019 to 2021, when its founder Aubrey de Grey, a prominent figure in the longevity field, was removed following accusations of sexual harassment. As CEO, O’Neill oversaw a student education program and multiple scientific research projects that focused on various aspects of aging, according to the organization’s annual reports. And in a 2020 SRF annual report, O’Neill wrote that Eric Hargan, then the deputy secretary of HHS, had attended an SRF conference to discuss “regulatory reform.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“More and more influential people consider aging an absurdity,” he wrote in the report. “Now we need to make it one.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;While de Grey calls him “the devil incarnate”—probably because he believes O’Neill “incited” two women to make sexual harassment allegations against him—the many other scientists, biotech CEOs, and other figures in the longevity field contacted by &lt;em&gt;MIT Technology Review&lt;/em&gt; had more positive opinions of O’Neill, with many claiming they were longtime friends or acquaintances of the new deputy secretary (though, at the same time, many were reluctant to share specific views about his past work).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Longevity science is a field that’s long courted controversy, owing largely to far-fetched promises of immortality and the ongoing marketing of creams, pills, intravenous infusions, and other so-called anti-aging treatments that are not supported by evidence. But the community includes people along a spectrum of beliefs (with the goals of adding a few years of healthy lifespan to the population at one end and immortality at the other), and serious doctors and scientists are working to bring legitimacy to the field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Pretty much everyone in the field that I spoke with appears to be hopeful about what O’Neill will do now that he’s been confirmed. Namely, they hope he will use his new position to direct attention and funds to legitimate longevity research and the development of new drugs that might slow or reverse human aging.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Johnson, whose extreme and expensive approaches to extending his own lifespan have made him something of a celebrity, calls O’Neill a friend and says they’ve “known each other for a little over 15 years.” He says he can imagine O’Neill setting a goal to extend the lifespans of Americans.&lt;/p&gt; 
 &lt;p&gt;Eric Verdin, president of the Buck Institute for Research on Aging in Novato, California, says O’Neill has “been at the Buck several times” and calls him “a good guy”—someone who is “serious” and who understands the science of aging. He says, “He’s certainly someone who is going to help us to really bring the longevity field to the front of the priorities of this administration.”&lt;/p&gt;  &lt;p&gt;Celine Halioua, CEO of the biotech company Loyal, which is developing drugs to extend the lifespan of dogs, echoes these sentiments, saying she has “always liked and respected” O’Neill. “It’ll definitely be nice to have somebody who’s bought into the thesis [of longevity science] at the FDA,” she says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And Joe Betts-LaCroix, CEO of the longevity biotech company Retro Biosciences, says he’s known O’Neill for something like 10 years and describes him as “smart and clear thinking.” “We’ve mutually been part of poetry readings,” he says. “He’s been definitely interested in wanting us as a society to make progress on age-related disease.”&lt;/p&gt;  &lt;p&gt;After his confirmation, the A4LI LinkedIn account posted a photo of Livingston, its CEO, with O’Neill, writing that “we look forward to working with him to elevate aging research as a national priority and to modernize regulatory pathways that support the development of longevity medicines.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;“His work at SENS Research Foundation [suggests] to me and to others that [longevity] is going to be something that he prioritizes,” Livingston says. “I think he’s a supporter of this field, and that’s really all that matters right now to us.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Changing the rules&lt;/h3&gt;  &lt;p&gt;While plenty of treatments have been shown to slow aging in lab animals, none of them have been found to successfully slow or reverse human aging. And many longevity enthusiasts believe drug regulations are to blame.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;O’Neill is one of them. He has long supported deregulation of new drugs and medical devices. During his first tour at HHS, for instance, he pushed back against regulations on the use of algorithms in medical devices. “FDA had to argue that an algorithm … is a medical device,” he said in a 2014 presentation at a meeting on “rejuvenation biotechnology.” “I managed to put a stop to that, at least while I was there.”&lt;/p&gt;  &lt;p&gt;During the same presentation, O’Neill advocated lowering the bar for drug approvals in the US. “We should reform [the] FDA so that it is approving drugs after their sponsors have demonstrated safety and let people start using them at their own risk,” he said. “Let’s prove efficacy after they’ve been legalized.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;This sentiment appears to be shared by Robert F. Kennedy Jr. In a recent podcast interview with Gary Brecka, who describes himself as a “longevity expert,” Kennedy said that he wanted to expand access to experimental therapies. “If you want to take an experimental drug … you ought to be able to do that,” he said in the episode, which was published online in May.&lt;/p&gt;  &lt;p&gt;But the idea is divisive. O’Neill was essentially suggesting that drugs be made available after the very first stage of clinical testing, which is designed to test whether a new treatment is safe. These tests are typically small and don’t reveal whether the drug actually works.&lt;/p&gt;  &lt;p&gt;That’s an idea that concerns ethicists. “It’s just absurd to think that the regulatory agency that’s responsible for making sure that products are safe and effective before they're made available to patients couldn’t protect patients from charlatans,” says Holly Fernandez Lynch, a professor of medical ethics and health policy at the University of Pennsylvania who is currently on sabbatical. “It’s just like a complete dereliction of duty.”&lt;/p&gt;  &lt;p&gt;Robert Steinbrook, director of the health research group at Public Citizen, largely agrees that this kind of change to the drug approval process is a bad idea, though notes that he and his colleagues are generally more concerned about O’Neill’s views on the regulation of technologies like AI in health care, given his previous efforts on algorithms.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“He has deregulatory views and would not be an advocate for an appropriate amount of regulation when regulation was needed,” Steinbrook says.&lt;/p&gt;  &lt;p&gt;Ultimately, though, even if O’Neill does try to change things, Zettler points out that there is currently no lawful way for the FDA to approve drugs that aren’t shown to be effective. That requirement won’t change unless Congress acts on the matter, she says: “It remains to be seen how big of a role HHS leadership will have in FDA policy on that front.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A longevity state&lt;/h3&gt;  &lt;p&gt;A major goal for a subset of longevity enthusiasts relates to another controversial idea: creating new geographic zones in which people can live by their own rules. The goal has taken various forms, including “network states” (which could start out as online social networks and evolve into territories that make use of cryptocurrency), “special economic zones,” and more recently “freedom cities.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While specific details vary, the fundamental concept is creating a new society, beyond the limits of nations and governments, as a place to experiment with new approaches to rules and regulations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2023, for instance, a group of longevity enthusiasts met at a temporary “pop-up city” in Montenegro to discuss plans to establish a “longevity state”—a geographic zone with a focus on extending human lifespan. Such a zone might encourage healthy behaviors and longevity research, as well as a fast-tracked system to approve promising-looking longevity drugs. They considered Rhode Island as the site but later changed their minds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;Some of those same longevity enthusiasts have set up shop in Próspera, Honduras—a “special economic zone” on the island of Roatán with a libertarian approach to governance, where residents are able to make their own suggestions for medical regulations. Another pop-up city, Vitalia, was set up there for two months in 2024, complete with its own biohacking lab; it also happened to be in close proximity to an established clinic selling an unproven longevity “gene therapy” for around $20,000. The people behind Vitalia referred to it as “a Los Alamos for longevity.” Another new project, Infinita City, is now underway in the former Vitalia location.&lt;/p&gt;  &lt;p&gt;O’Neill has voiced support for this broad concept, too. He’s posted on X about his support for limiting the role of government, writing “Get government out of the way” and, in reference to bills to shrink what some politicians see as government overreach, “No reason to wait.” And more to the point, he wrote on X last November, “Build freedom cities,” reposting another message that said: “I love the idea and think we should put the first one on the former Alameda Naval Air Station on the San Francisco Bay.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And up until March of last year, according to his financial disclosures, he served on the board of directors of the Seasteading Institute, an organization with the goal of creating “startup countries” at sea. “We are also negotiating with countries to establish a SeaZone (a specially designed economic zone where seasteading companies could build their platforms),” the organization explains on its website.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;“The healthiest societies in 2030 will most likely be on the sea,” O’Neill told an audience at a Seasteading Institute conference in 2009. In that presentation, he talked up the benefits of a free market for health care, saying that seasteads could offer improved health care and serve as medical tourism hubs: “The last best hope for freedom is on the sea.”&lt;/p&gt;  &lt;p&gt;Some in the longevity community see the ultimate goal as establishing a network state within the US. “That’s essentially what we’re doing in Montana,” says A4LI’s Livingston, referring to his successful lobbying efforts to create a hub for experimental medicine there. Over the last couple of years, the state has expanded Right to Try laws, which were originally designed to allow terminally ill individuals to access unproven treatments. Under new state laws, anyone can access such treatments, providing they have been through an initial phase I trial as a preliminary safety test.&lt;/p&gt;  &lt;p&gt;“We’re doing a freedom city in Montana without calling it a freedom city,” says Livingston.&lt;/p&gt;  &lt;p&gt;Patri Friedman, the libertarian founder of the Seasteading Institute, who calls O’Neill “a close friend,” explains that part of the idea of freedom cities is to create “specific industry clusters” on federal land in the US and win “regulatory carve-outs” that benefit those industries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A freedom city for longevity biotech is “being discussed,” says Friedman, although he adds that those discussions are still in the very early stages. He says he’d possibly work with O’Neill on “changing regulations that are under HHS” but isn’t yet certain what that might involve: “We're still trying to research and define the whole program and gather support for it.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Will he deliver?&lt;/h3&gt;  &lt;p&gt;Some libertarians, including longevity enthusiasts, believe this is their moment to build a new experimental home.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Not only do they expect backing from O’Neill, but they believe President Trump has advocated for new economic zones, perhaps dedicated to the support of specific industries, that can set their own rules for governance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While campaigning for the presidency in 2023, Trump floated what seemed like a similar idea: “We should hold a contest to charter up to 10 new cities and award them to the best proposals for development,” he said in a recorded campaign speech. (The purpose of these new cities was somewhat vague. “These freedom cities will reopen the frontier, reignite the American imagination, and give hundreds of thousands of young people and other people—all hardworking families—a new shot at homeownership and in fact the American dream,” he said.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;But given how frequently Trump changes his mind, it’s hard to tell what the president, and others in the administration, will now support on this front.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;And even if HHS does try to create new geographic zones in some form, legal and regulatory experts say this approach won’t necessarily speed up drug development the way some longevity enthusiasts hope.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The notion around so-called freedom cities, with respect to biomedical innovation, just reflects deep misunderstandings of what drug development entails,” says Ohio State’s Zettler. “It’s not regulatory requirements that [slow down] drug development—it’s the scientific difficulty of assessing safety and effectiveness and of finding true therapies.”&lt;/p&gt;  &lt;p&gt;Making matters even murkier, a lot of the research geared toward finding those therapies has been subject to drastic cuts.The NIH is the largest funder of biomedical research in the world and has supported major scientific discoveries, including those that benefit longevity research. But in late March, HHS announced a “dramatic restructuring” that would involve laying off 10,000 full-time employees. Since Trump took office, over a thousand NIH research grants have been ended and the administration has announced plans to slash funding for “indirect” research costs—a move that would cost individual research institutions millions of dollars. Research universities (notably Harvard) have been the target of policies to limit or revoke visas for international students, demands to change curricula, and threats to their funding and tax-exempt status.&lt;/p&gt;  &lt;p&gt;The NIH also directly supports aging research. Notably, the Interventions Testing Program is a program run by the National Institutes of Aging (a branch of the NIH) to find drugs that make mice live longer. The idea is to understand the biology of aging and find candidates for human longevity drugs.&lt;/p&gt;  &lt;p&gt;The ITP has tested around five to seven drugs a year for over 20 years, says Richard Miller, a professor of pathology at the University of Michigan, one of three institutes involved in the program. “We’ve published eight winners so far,” he adds.&lt;/p&gt;  &lt;p&gt;The future of the ITP is uncertain, given recent actions of the Trump administration, he says. The cap on indirect costs alone would cost the University of Michigan around $181 million, the university’s interim vice president for research and innovation said in February. The proposals are subject to ongoing legal battles. But in the meantime, morale is low, says Miller. “In the worst-case scenario, all aging research [would be stopped],” he says.&lt;/p&gt;  &lt;p&gt;The A4LI has also had to tailor its lobbying strategy given the current administration’s position on government-funded research. Alongside its efforts to change Montana state law to allow clinics to sell unproven treatments, the organization had been planning to push for an all-new NIH institute dedicated to aging and longevity research—an idea that O’Neill voiced support for last year. But current funding cuts under the new administration suggest that it’s “not the ideal political climate for this,” says Livingston.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt;&lt;p&gt;Despite their enthusiasm for O’Neill’s confirmation, this has all left many members of the longevity community, particularly those with research backgrounds, concerned about what the cuts mean for the future of longevity science.&lt;/p&gt;  &lt;p&gt;“Someone like [O’Neill], who’s an advocate for aging and longevity, would be fantastic to have at HHS,” says Matthew O’Connor, who spent over a decade at SRF and says he knows O’Neill “pretty well.” But he adds that “we shouldn’t be cutting the NIH.” Instead, he argues, the agency’s funding should be multiplied by 10.&lt;/p&gt;  &lt;p&gt;“The solution to curing diseases isn’t to get rid of the organizations that are there to help us cure diseases,” adds O’Connor, who is currently co-CEO at Cyclarity Therapeutics, a company developing drugs for atherosclerosis and other age-related diseases.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it’s still just too soon to confidently predict how, if at all, O’Neill will shape the government health agencies he will oversee.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We don’t know exactly what he’s going to be doing as the deputy secretary of HHS,” says Public Citizen’s Steinbrook. “Like everybody who's sworn into a government job, whether we disagree or agree with their views or actions … we still wish them well. And we hope that they do a good job.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/30/1119449/hhs-robert-f-kennedy-jr-jim-oneill-longevity-maha/</guid><pubDate>Mon, 30 Jun 2025 09:00:00 +0000</pubDate></item><item><title>The Download: meet RFK Jr’s right-hand man, and inside OpenAI (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/30/1119469/the-download-meet-rfk-jrs-right-hand-man-and-inside-openai/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet Jim O’Neill, the longevity enthusiast who is now RFK Jr.’s right-hand man&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;When Jim O’Neill was nominated to be the second in command at the US Department of Health and Human Services, longevity enthusiasts were excited.&lt;/p&gt;&lt;p&gt;As Robert F. Kennedy Jr.’s new right-hand man, O’Neill is expected to wield authority at health agencies that fund biomedical research and oversee the regulation of new drugs. And while O’Neill doesn’t subscribe to Kennedy’s most contentious beliefs—and supports existing vaccine schedules—he may still steer the agencies in controversial new directions.&lt;/p&gt;  &lt;p&gt;O’Neill is well-known in the increasingly well-funded and tight-knit longevity community. In speaking with more than 20 people who work in the longevity field and are familiar with O’Neill, it’s clear that they share a genuine optimism about his leadership. Read our story all about him and what he believes.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire with Karen Hao&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s newly released book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world.&lt;/p&gt;&lt;p&gt;Hao, a former MIT Technology Review senior editor, will join our executive editor Niall Firth in an intimate subscriber-exclusive Roundtable conversation exploring the AI arms race, what it means for all of us, and where it’s headed. Register here to join us at 9am ET today!&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Special giveaway&lt;/strong&gt;: Attendees will have the chance to receive a free copy of Hao's book. See the registration form for details.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump claims to have found buyers for TikTok&lt;/strong&gt;&lt;br /&gt;But will China agree to sell to them? That’s the real hurdle. (FT $)&lt;br /&gt;+ &lt;em&gt;They have between now and the September 17 deadline to thrash it all out. &lt;/em&gt;(CNBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The Trump administration is becoming even more secretive&lt;/strong&gt;&lt;br /&gt;Staff are being instructed to avoid leaving a paper trial at all costs. (WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Canada has rescinded its plans to tax US technology firms&lt;/strong&gt;&lt;br /&gt;That’s the price for reopening talks with America about trade negotiations. (Axios)&lt;br /&gt;+ &lt;em&gt;Surveillance maker Hikvision has been ordered to cease operations in Canada. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The tax had been due to come into effect today. &lt;/em&gt;(NPR)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Fake AI videos detailing the Diddy trial are rife on YouTube&lt;/strong&gt;&lt;br /&gt;The slop clips have been watched millions of times. (The Guardian)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 A new brain implant translates brain signals into words almost instantly&lt;/strong&gt;&lt;br /&gt;It could be an impressive step towards a fully digital vocal tract. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;This patient’s Neuralink brain implant gets a boost from generative AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Meta wants to train its AI on photos you haven’t even uploaded yet&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;And while it’s not doing so yet, it could in the future. (The Verge)&lt;br /&gt;+ &lt;em&gt;It’s started asking users for access permission. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The Chan Zuckerberg Initiative is narrowing its remit&lt;br /&gt;&lt;/strong&gt;It’s focusing purely on science, rather than politics, education and housing. (NYT $)&lt;br /&gt;+ &lt;em&gt;That’s pretty awful news for the communities that have grown reliant on it. &lt;/em&gt;(WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Fine tuning LLMs to behave well makes them more likely to say no&lt;br /&gt;&lt;/strong&gt;So you get either ‘safe’ or ‘helpful’. Both simultaneously seems to be too much to ask. (404 Media)&lt;br /&gt;+ &lt;em&gt;This benchmark used Reddit’s AITA to test how much AI models suck up to us. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Your next home could be made from superwood 🏠&lt;/strong&gt;&lt;br /&gt;The engineered material is stronger than steel—and bulletproof. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Inside the quest to engineer climate-saving “super trees.” &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Have emoji made our communication better? Or worse?&lt;br /&gt;&lt;/strong&gt;Much to think about 🤔 (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Meet the designer behind gender-neutral emoji. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I feel a visceral feeling right now, as if someone has broken into our home and stolen something.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Mark Chen, OpenAI’s chief research officer, reacts to Meta poaching some of the startup’s top talent to join its AI lab, Wired reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/01/feature-ivf.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the strange limbo facing millions of IVF embryos&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Millions of embryos created through IVF sit frozen in time, stored in cryopreservation tanks around the world. The number is only growing thanks to advances in technology, the rising popularity of IVF, and improvements in its success rates.&lt;/p&gt;&lt;p&gt;At a basic level, an embryo is simply a tiny ball of a hundred or so cells. But unlike other types of body tissue, it holds the potential for life. Many argue that this endows embryos with a special moral status, one that requires special protections.&lt;/p&gt;&lt;p&gt;The problem is that no one can really agree on what that status is. So while these embryos persist in suspended animation, patients, clinicians, embryologists, and legislators must grapple with the essential question of what we should do with them. What do these embryos mean to us? Who should be responsible for them? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Have we settled on a song of the summer yet?&lt;br /&gt;+ Improving your grip won’t just make you stronger, it could also go hand-in-hand (geddit) with living for longer.&lt;br /&gt;+ What’s in Bruce Springsteen’s vault? Let’s peer inside.&lt;br /&gt;+ How to find the good in the bad, even when it feels impossible.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet Jim O’Neill, the longevity enthusiast who is now RFK Jr.’s right-hand man&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;When Jim O’Neill was nominated to be the second in command at the US Department of Health and Human Services, longevity enthusiasts were excited.&lt;/p&gt;&lt;p&gt;As Robert F. Kennedy Jr.’s new right-hand man, O’Neill is expected to wield authority at health agencies that fund biomedical research and oversee the regulation of new drugs. And while O’Neill doesn’t subscribe to Kennedy’s most contentious beliefs—and supports existing vaccine schedules—he may still steer the agencies in controversial new directions.&lt;/p&gt;  &lt;p&gt;O’Neill is well-known in the increasingly well-funded and tight-knit longevity community. In speaking with more than 20 people who work in the longevity field and are familiar with O’Neill, it’s clear that they share a genuine optimism about his leadership. Read our story all about him and what he believes.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire with Karen Hao&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s newly released book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world.&lt;/p&gt;&lt;p&gt;Hao, a former MIT Technology Review senior editor, will join our executive editor Niall Firth in an intimate subscriber-exclusive Roundtable conversation exploring the AI arms race, what it means for all of us, and where it’s headed. Register here to join us at 9am ET today!&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Special giveaway&lt;/strong&gt;: Attendees will have the chance to receive a free copy of Hao's book. See the registration form for details.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump claims to have found buyers for TikTok&lt;/strong&gt;&lt;br /&gt;But will China agree to sell to them? That’s the real hurdle. (FT $)&lt;br /&gt;+ &lt;em&gt;They have between now and the September 17 deadline to thrash it all out. &lt;/em&gt;(CNBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The Trump administration is becoming even more secretive&lt;/strong&gt;&lt;br /&gt;Staff are being instructed to avoid leaving a paper trial at all costs. (WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Canada has rescinded its plans to tax US technology firms&lt;/strong&gt;&lt;br /&gt;That’s the price for reopening talks with America about trade negotiations. (Axios)&lt;br /&gt;+ &lt;em&gt;Surveillance maker Hikvision has been ordered to cease operations in Canada. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The tax had been due to come into effect today. &lt;/em&gt;(NPR)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Fake AI videos detailing the Diddy trial are rife on YouTube&lt;/strong&gt;&lt;br /&gt;The slop clips have been watched millions of times. (The Guardian)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 A new brain implant translates brain signals into words almost instantly&lt;/strong&gt;&lt;br /&gt;It could be an impressive step towards a fully digital vocal tract. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;This patient’s Neuralink brain implant gets a boost from generative AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Meta wants to train its AI on photos you haven’t even uploaded yet&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;And while it’s not doing so yet, it could in the future. (The Verge)&lt;br /&gt;+ &lt;em&gt;It’s started asking users for access permission. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The Chan Zuckerberg Initiative is narrowing its remit&lt;br /&gt;&lt;/strong&gt;It’s focusing purely on science, rather than politics, education and housing. (NYT $)&lt;br /&gt;+ &lt;em&gt;That’s pretty awful news for the communities that have grown reliant on it. &lt;/em&gt;(WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Fine tuning LLMs to behave well makes them more likely to say no&lt;br /&gt;&lt;/strong&gt;So you get either ‘safe’ or ‘helpful’. Both simultaneously seems to be too much to ask. (404 Media)&lt;br /&gt;+ &lt;em&gt;This benchmark used Reddit’s AITA to test how much AI models suck up to us. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Your next home could be made from superwood 🏠&lt;/strong&gt;&lt;br /&gt;The engineered material is stronger than steel—and bulletproof. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Inside the quest to engineer climate-saving “super trees.” &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Have emoji made our communication better? Or worse?&lt;br /&gt;&lt;/strong&gt;Much to think about 🤔 (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Meet the designer behind gender-neutral emoji. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I feel a visceral feeling right now, as if someone has broken into our home and stolen something.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Mark Chen, OpenAI’s chief research officer, reacts to Meta poaching some of the startup’s top talent to join its AI lab, Wired reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/01/feature-ivf.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the strange limbo facing millions of IVF embryos&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Millions of embryos created through IVF sit frozen in time, stored in cryopreservation tanks around the world. The number is only growing thanks to advances in technology, the rising popularity of IVF, and improvements in its success rates.&lt;/p&gt;&lt;p&gt;At a basic level, an embryo is simply a tiny ball of a hundred or so cells. But unlike other types of body tissue, it holds the potential for life. Many argue that this endows embryos with a special moral status, one that requires special protections.&lt;/p&gt;&lt;p&gt;The problem is that no one can really agree on what that status is. So while these embryos persist in suspended animation, patients, clinicians, embryologists, and legislators must grapple with the essential question of what we should do with them. What do these embryos mean to us? Who should be responsible for them? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Have we settled on a song of the summer yet?&lt;br /&gt;+ Improving your grip won’t just make you stronger, it could also go hand-in-hand (geddit) with living for longer.&lt;br /&gt;+ What’s in Bruce Springsteen’s vault? Let’s peer inside.&lt;br /&gt;+ How to find the good in the bad, even when it feels impossible.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/30/1119469/the-download-meet-rfk-jrs-right-hand-man-and-inside-openai/</guid><pubDate>Mon, 30 Jun 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] How we created HOV-specific ETAs in Google Maps (The latest research from Google)</title><link>https://research.google/blog/how-we-created-hov-specific-etas-in-google-maps/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The shift to sustainable travel modes like electric vehicles (EVs), carpooling, and public transit, has made travel times more varied. This is largely due to the availability of dedicated lanes, such as carpool lanes, also called high-occupancy vehicle (HOV) lanes, which are reserved for vehicles with multiple passengers and are designed to move traffic more efficiently during peak hours. As a result, HOV lanes are typically faster than general lanes during rush hour. For example, in Utah’s Salt Lake Valley, the average speed in HOV lanes was recorded at 68.18 mph compared to 58.60 mph in general lanes, a difference of about 16%.&lt;/p&gt;&lt;p&gt;Accurate estimated time of arrival (ETA) predictions and optimized routing are key to improving the commuting experience. With precise ETAs, travelers can make better decisions, save time, and even contribute to reducing congestion and emissions. With this in mind, Google Maps recently introduced a feature that lets drivers select routes that include HOV lanes and see that route’s ETA. In this blog post, we explain how we developed this feature and developed a classification system to determine HOV trips from non-HOV trips, which led to the launch of HOV specific ETAs in Google Maps.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The shift to sustainable travel modes like electric vehicles (EVs), carpooling, and public transit, has made travel times more varied. This is largely due to the availability of dedicated lanes, such as carpool lanes, also called high-occupancy vehicle (HOV) lanes, which are reserved for vehicles with multiple passengers and are designed to move traffic more efficiently during peak hours. As a result, HOV lanes are typically faster than general lanes during rush hour. For example, in Utah’s Salt Lake Valley, the average speed in HOV lanes was recorded at 68.18 mph compared to 58.60 mph in general lanes, a difference of about 16%.&lt;/p&gt;&lt;p&gt;Accurate estimated time of arrival (ETA) predictions and optimized routing are key to improving the commuting experience. With precise ETAs, travelers can make better decisions, save time, and even contribute to reducing congestion and emissions. With this in mind, Google Maps recently introduced a feature that lets drivers select routes that include HOV lanes and see that route’s ETA. In this blog post, we explain how we developed this feature and developed a classification system to determine HOV trips from non-HOV trips, which led to the launch of HOV specific ETAs in Google Maps.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/how-we-created-hov-specific-etas-in-google-maps/</guid><pubDate>Mon, 30 Jun 2025 12:15:00 +0000</pubDate></item><item><title>[NEW] Accelerating scientific discovery with AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Several researchers have taken a broad view of scientific progress over the last 50 years and come to the same troubling conclusion: Scientific productivity is declining. It’s taking more time, more funding, and larger teams to make discoveries that once came faster and cheaper. Although a variety of explanations have been offered for the slowdown, one is that, as research becomes more complex and specialized, scientists must spend more time reviewing publications, designing sophisticated experiments, and analyzing data.&lt;/p&gt;&lt;p&gt;Now, the philanthropically funded research lab FutureHouse is seeking to accelerate scientific research with an AI platform designed to automate many of the critical steps on the path toward scientific progress. The platform is made up of a series of AI agents specialized for tasks including information retrieval, information synthesis, chemical synthesis design, and data analysis.&lt;/p&gt;&lt;p&gt;FutureHouse founders Sam Rodriques PhD ’19 and Andrew White believe that by giving every scientist access to their AI agents, they can break through the biggest bottlenecks in science and help solve some of humanity’s most pressing problems.&lt;/p&gt;&lt;p&gt;“Natural language is the real language of science,” Rodriques says. “Other people are building foundation models for biology, where machine learning models speak the language of DNA or proteins, and that’s powerful. But discoveries aren’t represented in DNA or proteins. The only way we know how to represent discoveries, hypothesize, and reason is with natural language.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Finding big problems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For his PhD research at MIT, Rodriques sought to understand the inner workings of the brain in the lab of Professor Ed Boyden.&lt;/p&gt;&lt;p&gt;“The entire idea behind FutureHouse was inspired by this impression I got during my PhD at MIT that even if we had all the information we needed to know about how the brain works, we wouldn’t know it because nobody has time to read all the literature,” Rodriques explains. “Even if they could read it all, they wouldn’t be able to assemble it into a comprehensive theory. That was a foundational piece of the FutureHouse puzzle.”&lt;/p&gt;&lt;p&gt;Rodriques wrote about the need for&amp;nbsp;new kinds of large research collaborations as the last chapter of his PhD thesis in 2019, and though he spent some time running a lab at the Francis Crick Institute in London after graduation, he found himself gravitating toward broad problems in science that no single lab could take on.&lt;/p&gt;&lt;p&gt;“I was interested in how to automate or scale up science and what kinds of new organizational structures or technologies would unlock higher scientific productivity,” Rodriques says.&lt;/p&gt;&lt;p&gt;When Chat-GPT 3.5 was released in November 2022, Rodriques saw a path toward more powerful models that could generate scientific insights on their own. Around that time, he also met Andrew White, a computational chemist at the University of Rochester who had been granted early access to Chat-GPT 4. White had built the first large language agent for science, and the researchers joined forces to start FutureHouse.&lt;/p&gt;&lt;p&gt;The founders started out wanting to create distinct AI tools for tasks like literature searches, data analysis, and hypothesis generation. They began with data collection, eventually releasing PaperQA in September 2024, which Rodriques calls the best AI agent in the world for retrieving and summarizing information in scientific literature. Around the same time, they released Has Anyone, a tool that lets scientists determine if anyone has conducted specific experiments or explored specific hypotheses.&lt;/p&gt;&lt;p&gt;“We were just sitting around asking, ‘What are the kinds of questions that we as scientists ask all the time?’” Rodriques recalls.&lt;/p&gt;&lt;p&gt;When FutureHouse officially launched its platform on May 1 of this year, it rebranded some of its tools. Paper QA is now Crow, and Has Anyone is now called Owl. Falcon is an agent capable of compiling and reviewing more sources than Crow. Another new agent, Phoenix, can use specialized tools to help researchers plan chemistry experiments. And Finch is an agent designed to automate data driven discovery in biology.&lt;/p&gt;&lt;p&gt;On May 20, the company demonstrated a multi-agent scientific discovery workflow to automate key steps of the scientific process and identify a new therapeutic candidate for dry age-related macular degeneration (dAMD), a leading cause of irreversible blindness worldwide. In June, FutureHouse released ether0, a 24B open-weights reasoning model for chemistry.&lt;/p&gt;&lt;p&gt;“You really have to think of these agents as part of a larger system,” Rodriques says. “Soon, the literature search agents will be integrated with the data analysis agent, the hypothesis generation agent, an experiment planning agent, and they will all be engineered to work together seamlessly.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agents for everyone&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today anyone can access FutureHouse’s agents at platform.futurehouse.org. The company’s platform launch generated excitement in the industry, and stories have started to come in about scientists using the agents to accelerate research.&lt;/p&gt;&lt;p&gt;One of FutureHouse’s scientists used the agents to identify a gene that could be associated with polycystic ovary syndrome and come up with a new treatment hypothesis for the disease. Another researcher at the Lawrence Berkeley National Laboratory used Crow to create an AI assistant capable of searching the PubMed research database for information related to Alzheimer’s disease.&lt;/p&gt;&lt;p&gt;Scientists at another research institution have used the agents to conduct systematic reviews of genes relevant to Parkinson’s disease, finding FutureHouse’s agents performed better than general agents.&lt;/p&gt;&lt;p&gt;Rodriques says scientists who think of the agents less like Google Scholar and more like a smart assistant scientist get the most out of the platform.&lt;/p&gt;&lt;p&gt;“People who are looking for speculation tend to get more mileage out of Chat-GPT o3 deep research, while people who are looking for really faithful literature reviews tend to get more out of our agents,” Rodriques explains.&lt;/p&gt;&lt;p&gt;Rodriques also thinks FutureHouse will soon get to a point where its agents can use the raw data from research papers to test the reproducibility of its results and verify conclusions.&lt;/p&gt;&lt;p&gt;In the longer run, to keep scientific progress marching forward, Rodriques says FutureHouse is working on embedding its agents with tacit knowledge to be able to perform more sophisticated analyses while also giving the agents the ability to use computational tools to explore hypotheses.&lt;/p&gt;&lt;p&gt;“There have been so many advances around foundation models for science and around language models for proteins and DNA, that we now need to give our agents access to those models and all of the other tools people commonly use to do science,” Rodriques says. “Building the infrastructure to allow agents to use more specialized tools for science is going to be critical.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Several researchers have taken a broad view of scientific progress over the last 50 years and come to the same troubling conclusion: Scientific productivity is declining. It’s taking more time, more funding, and larger teams to make discoveries that once came faster and cheaper. Although a variety of explanations have been offered for the slowdown, one is that, as research becomes more complex and specialized, scientists must spend more time reviewing publications, designing sophisticated experiments, and analyzing data.&lt;/p&gt;&lt;p&gt;Now, the philanthropically funded research lab FutureHouse is seeking to accelerate scientific research with an AI platform designed to automate many of the critical steps on the path toward scientific progress. The platform is made up of a series of AI agents specialized for tasks including information retrieval, information synthesis, chemical synthesis design, and data analysis.&lt;/p&gt;&lt;p&gt;FutureHouse founders Sam Rodriques PhD ’19 and Andrew White believe that by giving every scientist access to their AI agents, they can break through the biggest bottlenecks in science and help solve some of humanity’s most pressing problems.&lt;/p&gt;&lt;p&gt;“Natural language is the real language of science,” Rodriques says. “Other people are building foundation models for biology, where machine learning models speak the language of DNA or proteins, and that’s powerful. But discoveries aren’t represented in DNA or proteins. The only way we know how to represent discoveries, hypothesize, and reason is with natural language.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Finding big problems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For his PhD research at MIT, Rodriques sought to understand the inner workings of the brain in the lab of Professor Ed Boyden.&lt;/p&gt;&lt;p&gt;“The entire idea behind FutureHouse was inspired by this impression I got during my PhD at MIT that even if we had all the information we needed to know about how the brain works, we wouldn’t know it because nobody has time to read all the literature,” Rodriques explains. “Even if they could read it all, they wouldn’t be able to assemble it into a comprehensive theory. That was a foundational piece of the FutureHouse puzzle.”&lt;/p&gt;&lt;p&gt;Rodriques wrote about the need for&amp;nbsp;new kinds of large research collaborations as the last chapter of his PhD thesis in 2019, and though he spent some time running a lab at the Francis Crick Institute in London after graduation, he found himself gravitating toward broad problems in science that no single lab could take on.&lt;/p&gt;&lt;p&gt;“I was interested in how to automate or scale up science and what kinds of new organizational structures or technologies would unlock higher scientific productivity,” Rodriques says.&lt;/p&gt;&lt;p&gt;When Chat-GPT 3.5 was released in November 2022, Rodriques saw a path toward more powerful models that could generate scientific insights on their own. Around that time, he also met Andrew White, a computational chemist at the University of Rochester who had been granted early access to Chat-GPT 4. White had built the first large language agent for science, and the researchers joined forces to start FutureHouse.&lt;/p&gt;&lt;p&gt;The founders started out wanting to create distinct AI tools for tasks like literature searches, data analysis, and hypothesis generation. They began with data collection, eventually releasing PaperQA in September 2024, which Rodriques calls the best AI agent in the world for retrieving and summarizing information in scientific literature. Around the same time, they released Has Anyone, a tool that lets scientists determine if anyone has conducted specific experiments or explored specific hypotheses.&lt;/p&gt;&lt;p&gt;“We were just sitting around asking, ‘What are the kinds of questions that we as scientists ask all the time?’” Rodriques recalls.&lt;/p&gt;&lt;p&gt;When FutureHouse officially launched its platform on May 1 of this year, it rebranded some of its tools. Paper QA is now Crow, and Has Anyone is now called Owl. Falcon is an agent capable of compiling and reviewing more sources than Crow. Another new agent, Phoenix, can use specialized tools to help researchers plan chemistry experiments. And Finch is an agent designed to automate data driven discovery in biology.&lt;/p&gt;&lt;p&gt;On May 20, the company demonstrated a multi-agent scientific discovery workflow to automate key steps of the scientific process and identify a new therapeutic candidate for dry age-related macular degeneration (dAMD), a leading cause of irreversible blindness worldwide. In June, FutureHouse released ether0, a 24B open-weights reasoning model for chemistry.&lt;/p&gt;&lt;p&gt;“You really have to think of these agents as part of a larger system,” Rodriques says. “Soon, the literature search agents will be integrated with the data analysis agent, the hypothesis generation agent, an experiment planning agent, and they will all be engineered to work together seamlessly.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agents for everyone&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today anyone can access FutureHouse’s agents at platform.futurehouse.org. The company’s platform launch generated excitement in the industry, and stories have started to come in about scientists using the agents to accelerate research.&lt;/p&gt;&lt;p&gt;One of FutureHouse’s scientists used the agents to identify a gene that could be associated with polycystic ovary syndrome and come up with a new treatment hypothesis for the disease. Another researcher at the Lawrence Berkeley National Laboratory used Crow to create an AI assistant capable of searching the PubMed research database for information related to Alzheimer’s disease.&lt;/p&gt;&lt;p&gt;Scientists at another research institution have used the agents to conduct systematic reviews of genes relevant to Parkinson’s disease, finding FutureHouse’s agents performed better than general agents.&lt;/p&gt;&lt;p&gt;Rodriques says scientists who think of the agents less like Google Scholar and more like a smart assistant scientist get the most out of the platform.&lt;/p&gt;&lt;p&gt;“People who are looking for speculation tend to get more mileage out of Chat-GPT o3 deep research, while people who are looking for really faithful literature reviews tend to get more out of our agents,” Rodriques explains.&lt;/p&gt;&lt;p&gt;Rodriques also thinks FutureHouse will soon get to a point where its agents can use the raw data from research papers to test the reproducibility of its results and verify conclusions.&lt;/p&gt;&lt;p&gt;In the longer run, to keep scientific progress marching forward, Rodriques says FutureHouse is working on embedding its agents with tacit knowledge to be able to perform more sophisticated analyses while also giving the agents the ability to use computational tools to explore hypotheses.&lt;/p&gt;&lt;p&gt;“There have been so many advances around foundation models for science and around language models for proteins and DNA, that we now need to give our agents access to those models and all of the other tools people commonly use to do science,” Rodriques says. “Building the infrastructure to allow agents to use more specialized tools for science is going to be critical.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630</guid><pubDate>Mon, 30 Jun 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] Jennifer Neundorfer on how AI is reshaping the way startups are built — live at TechCrunch All Stage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/jennifer-neundorfer-on-how-ai-is-reshaping-the-way-startups-are-built-live-at-techcrunch-all-stage/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI marks the most significant revolution in startup development since the advent of cloud computing. This isn’t just an incremental change; AI is fundamentally reshaping every facet of company building, from the initial spark of idea validation and the intricate process of product development to the critical areas of team structuring and go-to-market strategies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jennifer Neundorfer, co-founder and managing partner at January Ventures, unpacks the new rules of engagement for the AI era, offering essential insights for the next generation of founders at every stage. Catch her at &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; on July 15 at Boston’s SoWa Power Station.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Lean into this session and other expert-led scaling sessions, and &lt;strong&gt;save up to $425&lt;/strong&gt; on your pass for a limited time.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage Jennifer Neundorfer" class="wp-image-3023215" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/Jennifer-Neundorfer-SpeakerArticleImageHeader_TCAllStage.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-operator-turned-investor-empowering-b2b-innovation"&gt;Operator-turned-investor empowering B2B innovation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Jennifer Neundorfer is an operator turned investor who has been investing in early-stage startups for the last decade. She is currently the managing partner of January Ventures, a pre-seed-focused venture capital firm investing in B2B startups leveraging software to transform legacy industries. She founded January Ventures to rewrite the networks in venture capital and invest in the most ambitious founders regardless of pedigree, network, or access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to January, Jennifer was co-founder of Flashstarts, a startup accelerator focused on software startups outside of Silicon Valley. Jennifer is based in Boston.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-join-for-the-takeaways-register-now-for-the-savings"&gt;Join for the takeaways, register now for the savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For a limited time, TechCrunch All Stage brings back early launch prices. Founders pay just $155. Investors, only $250. &lt;strong&gt;Register now&lt;/strong&gt; and get up to $425 in savings on your pass!&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI marks the most significant revolution in startup development since the advent of cloud computing. This isn’t just an incremental change; AI is fundamentally reshaping every facet of company building, from the initial spark of idea validation and the intricate process of product development to the critical areas of team structuring and go-to-market strategies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jennifer Neundorfer, co-founder and managing partner at January Ventures, unpacks the new rules of engagement for the AI era, offering essential insights for the next generation of founders at every stage. Catch her at &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; on July 15 at Boston’s SoWa Power Station.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Lean into this session and other expert-led scaling sessions, and &lt;strong&gt;save up to $425&lt;/strong&gt; on your pass for a limited time.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage Jennifer Neundorfer" class="wp-image-3023215" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/Jennifer-Neundorfer-SpeakerArticleImageHeader_TCAllStage.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-operator-turned-investor-empowering-b2b-innovation"&gt;Operator-turned-investor empowering B2B innovation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Jennifer Neundorfer is an operator turned investor who has been investing in early-stage startups for the last decade. She is currently the managing partner of January Ventures, a pre-seed-focused venture capital firm investing in B2B startups leveraging software to transform legacy industries. She founded January Ventures to rewrite the networks in venture capital and invest in the most ambitious founders regardless of pedigree, network, or access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to January, Jennifer was co-founder of Flashstarts, a startup accelerator focused on software startups outside of Silicon Valley. Jennifer is based in Boston.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-join-for-the-takeaways-register-now-for-the-savings"&gt;Join for the takeaways, register now for the savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For a limited time, TechCrunch All Stage brings back early launch prices. Founders pay just $155. Investors, only $250. &lt;strong&gt;Register now&lt;/strong&gt; and get up to $425 in savings on your pass!&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/jennifer-neundorfer-on-how-ai-is-reshaping-the-way-startups-are-built-live-at-techcrunch-all-stage/</guid><pubDate>Mon, 30 Jun 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] Roundtables: Inside OpenAI’s Empire with Karen Hao (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/30/1118540/roundtables-inside-openais-empire-with-karen-hao/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Recorded on June 30, 2025&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world. Hear from Karen Hao, former &lt;em&gt;MIT Technology Review &lt;/em&gt;senior editor, and executive editor Niall Firth for a conversation exploring the AI arms race, what it means for all of us, and where it’s headed.&lt;/p&gt;  &lt;p&gt;Speakers: Karen Hao, AI journalist, and Niall Firth, executive editor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Recorded on June 30, 2025&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world. Hear from Karen Hao, former &lt;em&gt;MIT Technology Review &lt;/em&gt;senior editor, and executive editor Niall Firth for a conversation exploring the AI arms race, what it means for all of us, and where it’s headed.&lt;/p&gt;  &lt;p&gt;Speakers: Karen Hao, AI journalist, and Niall Firth, executive editor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/30/1118540/roundtables-inside-openais-empire-with-karen-hao/</guid><pubDate>Mon, 30 Jun 2025 14:59:17 +0000</pubDate></item><item><title>[NEW] Cursor launches a web app to manage AI coding agents (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/cursor-launches-a-web-app-to-manage-ai-coding-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/opengraph-image.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The company behind Cursor, the viral AI coding editor, launched a web app on Monday that allows users to manage a network of coding agents directly from their browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch marks Cursor’s next big step beyond its integrated development environment (IDE), the core product developers use to access its tools. While Anysphere, the company behind Cursor, initially offered only this AI-powered IDE, the company has made a concerted effort to put its products in more places and develop more agent-powered experiences for users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, Cursor launched background agents — AI systems that solve coding tasks autonomously without user supervision. In June, the company launched a Slack integration that allows users to assign tasks to these background agents by tagging @Cursor, similar to how Cognitions’s AI coding agent, Devin, operates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, with the web app, Cursor users can send natural language requests via browser — on desktop or mobile— to assign background agents tasks such as writing features or fixing bugs in their codebase. The web app also lets users monitor agents working on other tasks, view their progress, and merge completed changes into the codebase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Milich, Cursor’s head of product engineering, tells TechCrunch that the Slack integration and web app are part of an effort to “remove the friction” for users who rely on Cursor — and it seems many do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere announced last month that Cursor has crossed $500 million in annualized recurring revenue, largely driven by monthly subscriptions. The company also said Cursor is now used by more than half of the Fortune 500, including companies such as Nvidia, Uber, and Adobe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To capitalize on this growth, Anysphere recently launched a $200-per-month Pro tier for Cursor.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“You noted how customers want Cursor in more places. I think they also want Cursor to solve more of the problems they’re having,” said Milich.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor’s background agents are designed to let users start tasks through Slack or the web app, allowing an agent to take a first pass. If the agent can’t complete the task, users can seamlessly transition into the IDE to pick up where the agent left off. Each agent also has a unique shareable link — making it easy to view progress and code changes on agents that other teammates created.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere says all customers with access to background agents can use the Cursor web app — that includes subscribers to Cursor’s $20-per-month Pro plan, as well as more expensive plans, but not users on Cursor’s free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cursor is not the first to ship AI coding agents, but the company says it has been careful to take its time and not ship “demo-ware” — AI products that look good in theory but fail in practice. That has been the story for a lot of early AI coding agents, which made numerous mistakes in testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team behind Cursor now believes AI reasoning models are advancing enough to make coding agents viable. In a recent interview with Stratechery’s Ben Thompson, Anysphere CEO Michael Truell said he expects AI coding agents to handle at least 20% of a software engineer’s work by 2026.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/opengraph-image.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The company behind Cursor, the viral AI coding editor, launched a web app on Monday that allows users to manage a network of coding agents directly from their browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch marks Cursor’s next big step beyond its integrated development environment (IDE), the core product developers use to access its tools. While Anysphere, the company behind Cursor, initially offered only this AI-powered IDE, the company has made a concerted effort to put its products in more places and develop more agent-powered experiences for users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, Cursor launched background agents — AI systems that solve coding tasks autonomously without user supervision. In June, the company launched a Slack integration that allows users to assign tasks to these background agents by tagging @Cursor, similar to how Cognitions’s AI coding agent, Devin, operates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, with the web app, Cursor users can send natural language requests via browser — on desktop or mobile— to assign background agents tasks such as writing features or fixing bugs in their codebase. The web app also lets users monitor agents working on other tasks, view their progress, and merge completed changes into the codebase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Milich, Cursor’s head of product engineering, tells TechCrunch that the Slack integration and web app are part of an effort to “remove the friction” for users who rely on Cursor — and it seems many do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere announced last month that Cursor has crossed $500 million in annualized recurring revenue, largely driven by monthly subscriptions. The company also said Cursor is now used by more than half of the Fortune 500, including companies such as Nvidia, Uber, and Adobe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To capitalize on this growth, Anysphere recently launched a $200-per-month Pro tier for Cursor.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“You noted how customers want Cursor in more places. I think they also want Cursor to solve more of the problems they’re having,” said Milich.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor’s background agents are designed to let users start tasks through Slack or the web app, allowing an agent to take a first pass. If the agent can’t complete the task, users can seamlessly transition into the IDE to pick up where the agent left off. Each agent also has a unique shareable link — making it easy to view progress and code changes on agents that other teammates created.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere says all customers with access to background agents can use the Cursor web app — that includes subscribers to Cursor’s $20-per-month Pro plan, as well as more expensive plans, but not users on Cursor’s free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cursor is not the first to ship AI coding agents, but the company says it has been careful to take its time and not ship “demo-ware” — AI products that look good in theory but fail in practice. That has been the story for a lot of early AI coding agents, which made numerous mistakes in testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team behind Cursor now believes AI reasoning models are advancing enough to make coding agents viable. In a recent interview with Stratechery’s Ben Thompson, Anysphere CEO Michael Truell said he expects AI coding agents to handle at least 20% of a software engineer’s work by 2026.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/cursor-launches-a-web-app-to-manage-ai-coding-agents/</guid><pubDate>Mon, 30 Jun 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Tiny AI ERP startup Campfire is winning so many startups from NetSuite, Accel led a $35M Series A (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/tiny-ai-erp-startup-campfire-is-winning-so-many-startups-from-netsuite-accel-led-a-35m-series-a/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Campfire-founder-CEO-John-Glasgow.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered accounting startup Campfire announced Monday that it has raised a $35 million Series A led by Accel, with participation from Foundation Capital, Y Combinator, Capital 49, and angel investors including Mercury’s CFO Dan Kang.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Within nine months of formation, we had customers [with] north of 100 employees ripping out NetSuite and putting in Campfire,” founder CEO John Glasgow said. Some of Campfire’s customers that have migrated from NetSuite include wealth management platform Advisor360, construction software startup Rhumbix, and customer experience company Fooji, Campfire says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This was, in part, because Glasgow attended YC in the summer of 2023, despite being decidedly more experienced than the typical 20-something YC founder. He described the age difference with a funny story: During a YC bingo event, “One of the bingos was ‘find someone that’s a parent,’ and I was the hot commodity at YC bingo.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow already had a decade and a half career in finance working for Fidelity, Union Square Advisors, and others. When his manager from Adobe left to run an Accel-backed startup called Invoice2go, he took Glasgow with him. Less than a year later, in the fall of 2021, Bill.com bought Invoice2go for about $625 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow wound up with both the cash and an idea to build his own startup, one that would automate the drudgery in finance like reconciling payments on bills, revenue forecasts, and — the part he discovered during the Invoice2go deal — due diligence for M&amp;amp;A.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He launched Campfire in 2023 to upend 1990s-era enterprise resource planning accounting software (ERP) like NetSuite with an LLM-powered alternative.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Campfire does things like automatically itemize and reconcile AWS cloud computing bills. It generates detailed cash flow analysis, charts, and answers to questions from natural-language prompts.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“One of our customers went from a 15-day to a three-day close when they ripped out NetSuite and put in Campfire,” he says about the time to finalize the books each month.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YC’s famed access to other cohort alums helped him land tech startups as customers like Replit and Replo. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Campfire is just a gnat in terms of its impact on Oracle’s billion-dollar (and growing) NetSuite business, the startup gained enough customers to prove its competitive plausibility.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At its seed stage, Campfire grew to around 100 customers, including, Glasgow said, one global customer on track to do a $250 million ARR. Campfire is now up to 12 employees&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was surprised that there were businesses of this size that were trusting their whole ERP to a 10-person, seed-stage project,” Accel’s John Locke, who had backed Invoice2Go, told TechCrunch of what had enticed him with Campfire. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Locke typically invests at the growth stage. But given that kind of “traction out of the gates” and a total ERP software market of $56 billion in 2024, according to some market research reports, Locke was in to lead the Series A. And he was in big.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The] AI ERP business is massive, and we think John is really the right person to do it. So why don’t we do a $30 [million] to $35 million Series A, and really go for it?” he told Glasgow and his partners. So they did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: This story originally identified Mercury as a customer when it is not.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Campfire-founder-CEO-John-Glasgow.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered accounting startup Campfire announced Monday that it has raised a $35 million Series A led by Accel, with participation from Foundation Capital, Y Combinator, Capital 49, and angel investors including Mercury’s CFO Dan Kang.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Within nine months of formation, we had customers [with] north of 100 employees ripping out NetSuite and putting in Campfire,” founder CEO John Glasgow said. Some of Campfire’s customers that have migrated from NetSuite include wealth management platform Advisor360, construction software startup Rhumbix, and customer experience company Fooji, Campfire says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This was, in part, because Glasgow attended YC in the summer of 2023, despite being decidedly more experienced than the typical 20-something YC founder. He described the age difference with a funny story: During a YC bingo event, “One of the bingos was ‘find someone that’s a parent,’ and I was the hot commodity at YC bingo.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow already had a decade and a half career in finance working for Fidelity, Union Square Advisors, and others. When his manager from Adobe left to run an Accel-backed startup called Invoice2go, he took Glasgow with him. Less than a year later, in the fall of 2021, Bill.com bought Invoice2go for about $625 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow wound up with both the cash and an idea to build his own startup, one that would automate the drudgery in finance like reconciling payments on bills, revenue forecasts, and — the part he discovered during the Invoice2go deal — due diligence for M&amp;amp;A.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He launched Campfire in 2023 to upend 1990s-era enterprise resource planning accounting software (ERP) like NetSuite with an LLM-powered alternative.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Campfire does things like automatically itemize and reconcile AWS cloud computing bills. It generates detailed cash flow analysis, charts, and answers to questions from natural-language prompts.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“One of our customers went from a 15-day to a three-day close when they ripped out NetSuite and put in Campfire,” he says about the time to finalize the books each month.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YC’s famed access to other cohort alums helped him land tech startups as customers like Replit and Replo. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Campfire is just a gnat in terms of its impact on Oracle’s billion-dollar (and growing) NetSuite business, the startup gained enough customers to prove its competitive plausibility.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At its seed stage, Campfire grew to around 100 customers, including, Glasgow said, one global customer on track to do a $250 million ARR. Campfire is now up to 12 employees&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was surprised that there were businesses of this size that were trusting their whole ERP to a 10-person, seed-stage project,” Accel’s John Locke, who had backed Invoice2Go, told TechCrunch of what had enticed him with Campfire. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Locke typically invests at the growth stage. But given that kind of “traction out of the gates” and a total ERP software market of $56 billion in 2024, according to some market research reports, Locke was in to lead the Series A. And he was in big.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The] AI ERP business is massive, and we think John is really the right person to do it. So why don’t we do a $30 [million] to $35 million Series A, and really go for it?” he told Glasgow and his partners. So they did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: This story originally identified Mercury as a customer when it is not.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/tiny-ai-erp-startup-campfire-is-winning-so-many-startups-from-netsuite-accel-led-a-35m-series-a/</guid><pubDate>Mon, 30 Jun 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Power play: Can the grid cope with AI’s growing appetite? (AI News)</title><link>https://www.artificialintelligence-news.com/news/power-play-can-the-grid-cope-with-ais-growing-appetite/</link><description>&lt;p&gt;As the AI Energy Council gathers, the question hanging in the air is: how do we power the future without blowing the grid?&lt;/p&gt;&lt;p&gt;The massive data centres needed to train and run the latest AI are thirsty for electricity. Data centre power use in the UK is on track to multiply six times over by 2034, at which point it could be sucking up nearly a third of all our nation’s electricity. That’s a colossal strain to put on a system that was built for a completely different world, one with predictable, one-way power flows.&lt;/p&gt;&lt;p&gt;The AI Energy Council – a team-up of tech giants, energy firms, the Ofgem regulator, and the National Energy System Operator – has the critical job of trying to predict just how thirsty this AI beast will become. Their work is happening just as the government is pouring £2 billion into its AI Opportunities Action Plan, a grand vision for weaving AI into our hospitals, classrooms, and businesses.&lt;/p&gt;&lt;p&gt;UK Science and Technology Secretary Peter Kyle said: “Giving our researchers and innovators access to the processing power they need will not only maintain our standing as the world’s third-biggest AI power, but put British expertise at the heart of the AI breakthroughs which will improve our lives, modernise our public services, and spark the economic growth which is the cornerstone of our Plan for Change.&lt;/p&gt;&lt;p&gt;“We are clear-eyed though on the need to make sure we can power this golden era for British AI through responsible, sustainable energy sources. Today’s talks will help us drive forward that mission, delivering AI infrastructure which will benefit communities up and down the country for generations to come without ever compromising on our clean energy superpower ambitions.”&lt;/p&gt;&lt;p&gt;The sheer scale of the energy problem is hard to overstate. Globally, the electricity needed for data centres is expected to double in just five years, eventually demanding three times more power than the entire UK currently uses. And AI is the main culprit.&lt;/p&gt;&lt;p&gt;A single rack of AI servers can demand 120 kW of power, a massive leap from the 5-10 kW a normal rack needs. These aren’t steady sips of power, either. AI workloads can spike unpredictably, creating sudden, massive power surges that threaten the stability of the entire grid.&lt;/p&gt;&lt;p&gt;In response, the UK is planning a monumental overhaul. The centrepiece is the “Great Grid Upgrade,” a £58 billion investment designed to be a “once in a generation expansion” of the electricity network. This includes building a new high-capacity electrical superhighway running from north to south and expanding the offshore grid to bring in vast amounts of new wind power.&lt;/p&gt;&lt;p&gt;Ed Miliband, Secretary for Energy Security and Net Zero, commented: “We are making the UK a clean energy superpower, building the homegrown energy this country needs to get bills down for good and create new jobs as part of our Plan for Change.&lt;/p&gt;&lt;p&gt;“Bringing together the biggest players in AI and energy will help us discuss the role AI can play in building a new era of clean electricity for our country, and meeting the power demands of new technology as we build a clean power system for families and businesses.”&lt;/p&gt;&lt;p&gt;But there’s a huge roadblock. Even if we build the wind farms and solar panels, connecting them to the power grid to address surging AI demand right now is another story. The current process is slow, leaving more than 600 renewable energy projects – worth billions – stuck in a queue. Some have been told they could be waiting for 15 years.&lt;/p&gt;&lt;p&gt;Urgent reforms are being pushed through to try and clear this backlog, a vital step if our AI future is to be powered by green energy. The government is also trying to speed things up by declaring data centres “critical national infrastructure” and setting up “AI Growth Zones” where planning and power connections can be fast-tracked.&lt;/p&gt;&lt;p&gt;The data centre industry is shifting from being just part of the problem to becoming part of the solution. Instead of just being passive power hogs, they are becoming active partners in the energy grid. Many are chasing Net Zero targets, investing in their own on-site renewable power, and taking part in “demand-side response” programs. This means they can intelligently pause non-urgent AI tasks when the grid is under stress and fire them up again when green energy is plentiful, helping to balance the whole system.&lt;/p&gt;&lt;p&gt;AI itself could also help. The same complex algorithms that demand so much power can also be used to make our grid smarter, predicting energy spikes and optimising power flow in real-time.&lt;/p&gt;&lt;p&gt;The way forward is clear, but it won’t be easy. The UK has the right ideas and is putting serious money on the table to address the power grid demands of AI, but everything depends on speed and execution. The grid connection jam must be broken, and the Great Grid Upgrade needs to happen at pace.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andreas Jabusch)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Anthropic tests AI running a real business with bizarre results&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;As the AI Energy Council gathers, the question hanging in the air is: how do we power the future without blowing the grid?&lt;/p&gt;&lt;p&gt;The massive data centres needed to train and run the latest AI are thirsty for electricity. Data centre power use in the UK is on track to multiply six times over by 2034, at which point it could be sucking up nearly a third of all our nation’s electricity. That’s a colossal strain to put on a system that was built for a completely different world, one with predictable, one-way power flows.&lt;/p&gt;&lt;p&gt;The AI Energy Council – a team-up of tech giants, energy firms, the Ofgem regulator, and the National Energy System Operator – has the critical job of trying to predict just how thirsty this AI beast will become. Their work is happening just as the government is pouring £2 billion into its AI Opportunities Action Plan, a grand vision for weaving AI into our hospitals, classrooms, and businesses.&lt;/p&gt;&lt;p&gt;UK Science and Technology Secretary Peter Kyle said: “Giving our researchers and innovators access to the processing power they need will not only maintain our standing as the world’s third-biggest AI power, but put British expertise at the heart of the AI breakthroughs which will improve our lives, modernise our public services, and spark the economic growth which is the cornerstone of our Plan for Change.&lt;/p&gt;&lt;p&gt;“We are clear-eyed though on the need to make sure we can power this golden era for British AI through responsible, sustainable energy sources. Today’s talks will help us drive forward that mission, delivering AI infrastructure which will benefit communities up and down the country for generations to come without ever compromising on our clean energy superpower ambitions.”&lt;/p&gt;&lt;p&gt;The sheer scale of the energy problem is hard to overstate. Globally, the electricity needed for data centres is expected to double in just five years, eventually demanding three times more power than the entire UK currently uses. And AI is the main culprit.&lt;/p&gt;&lt;p&gt;A single rack of AI servers can demand 120 kW of power, a massive leap from the 5-10 kW a normal rack needs. These aren’t steady sips of power, either. AI workloads can spike unpredictably, creating sudden, massive power surges that threaten the stability of the entire grid.&lt;/p&gt;&lt;p&gt;In response, the UK is planning a monumental overhaul. The centrepiece is the “Great Grid Upgrade,” a £58 billion investment designed to be a “once in a generation expansion” of the electricity network. This includes building a new high-capacity electrical superhighway running from north to south and expanding the offshore grid to bring in vast amounts of new wind power.&lt;/p&gt;&lt;p&gt;Ed Miliband, Secretary for Energy Security and Net Zero, commented: “We are making the UK a clean energy superpower, building the homegrown energy this country needs to get bills down for good and create new jobs as part of our Plan for Change.&lt;/p&gt;&lt;p&gt;“Bringing together the biggest players in AI and energy will help us discuss the role AI can play in building a new era of clean electricity for our country, and meeting the power demands of new technology as we build a clean power system for families and businesses.”&lt;/p&gt;&lt;p&gt;But there’s a huge roadblock. Even if we build the wind farms and solar panels, connecting them to the power grid to address surging AI demand right now is another story. The current process is slow, leaving more than 600 renewable energy projects – worth billions – stuck in a queue. Some have been told they could be waiting for 15 years.&lt;/p&gt;&lt;p&gt;Urgent reforms are being pushed through to try and clear this backlog, a vital step if our AI future is to be powered by green energy. The government is also trying to speed things up by declaring data centres “critical national infrastructure” and setting up “AI Growth Zones” where planning and power connections can be fast-tracked.&lt;/p&gt;&lt;p&gt;The data centre industry is shifting from being just part of the problem to becoming part of the solution. Instead of just being passive power hogs, they are becoming active partners in the energy grid. Many are chasing Net Zero targets, investing in their own on-site renewable power, and taking part in “demand-side response” programs. This means they can intelligently pause non-urgent AI tasks when the grid is under stress and fire them up again when green energy is plentiful, helping to balance the whole system.&lt;/p&gt;&lt;p&gt;AI itself could also help. The same complex algorithms that demand so much power can also be used to make our grid smarter, predicting energy spikes and optimising power flow in real-time.&lt;/p&gt;&lt;p&gt;The way forward is clear, but it won’t be easy. The UK has the right ideas and is putting serious money on the table to address the power grid demands of AI, but everything depends on speed and execution. The grid connection jam must be broken, and the Great Grid Upgrade needs to happen at pace.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andreas Jabusch)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Anthropic tests AI running a real business with bizarre results&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/power-play-can-the-grid-cope-with-ais-growing-appetite/</guid><pubDate>Mon, 30 Jun 2025 15:53:38 +0000</pubDate></item><item><title>[NEW] AI Testing and Evaluation: Learnings from genome editing (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry, &lt;/em&gt;hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Alta Charo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field’s approach to regulating &lt;em&gt;applications &lt;/em&gt;of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, Daniel Kluttz&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a partner general manager in Microsoft’s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.&lt;/p&gt;











&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript-1"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN:&lt;/strong&gt; Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today I’m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.&lt;/p&gt;



&lt;p&gt;Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama’s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women’s health, stem cell research, genome editing, biosecurity, and more.&lt;/p&gt;



&lt;p&gt;After our conversation with Professor Charo, we’ll hear from Daniel Kluttz, a partner general manager in Microsoft’s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team’s work governing sensitive AI uses and emerging technologies.&lt;/p&gt;



&lt;p&gt;Alta, thank you so much for being here today. I’m a follower of your work and have really been looking forward to our conversation.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;ALTA CHARO:&lt;/strong&gt; It’s my pleasure. Thanks for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Alta, I’d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You’ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, I think it’s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.&lt;/p&gt;



&lt;p&gt;My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or &lt;em&gt;Star Trek&lt;/em&gt;. [LAUGHTER]&lt;/p&gt;



&lt;p&gt;And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; For listeners who are brand new to your field in genomic editing, can you give us what I’ll call a “90-second survey” of the space in perhaps plain language and why it’s important to have a framework for ensuring its responsible use.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, you know, genome editing is both very old and very new. At base, what we’re talking about is a way to either delete sections of the &lt;em&gt;genome&lt;/em&gt;, our collection of genes, or to add things or to alter what’s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it’s a plant, an animal, or a human.&lt;/p&gt;



&lt;p&gt;Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter &lt;em&gt;g&lt;/em&gt; to the letter &lt;em&gt;h&lt;/em&gt; in every word, and in our genomes, you can do similar kinds of things.&lt;/p&gt;



&lt;p&gt;But because of this, we have a responsibility to make sure that whatever we change doesn’t become dangerous and that it doesn’t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn’t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.&lt;/p&gt;



&lt;p&gt;It’s become more efficient. It doesn’t require as much sophisticated laboratory equipment. It’s moved from being something that only a few people can do to something that we’re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who’s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it’s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, to answer that, I’m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I’m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.&lt;/p&gt;



&lt;p&gt;You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called &lt;em&gt;off-target effect&lt;/em&gt;. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there’s going to be an interaction between what you changed and what was there, a &lt;em&gt;gene-gene interaction&lt;/em&gt;, that might have an unanticipated kind of result, a side effect essentially.&lt;/p&gt;



&lt;p&gt;So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it’s going to actually create something harmful. And that really depends upon the application.&lt;/p&gt;



&lt;p&gt;If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.&lt;/p&gt;



&lt;p&gt;It may also be that in other settings, what you’re doing is going to have a much lower risk because you’re working with a more familiar substance, your predictive power is much greater, and it’s not going into a human or an animal or into the environment. So I think that you have to say that the risk &lt;em&gt;and&lt;/em&gt; the benefits, by the way, all are going to depend upon the particular application.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I think on this point of application, there’s many players involved in that, right. Like, we often hear about this puzzle of who’s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it’s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called &lt;em&gt;coordinated framework&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.&lt;/p&gt;



&lt;p&gt;There’s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, &lt;em&gt;IBCs&lt;/em&gt;. You want to do research that involves recombinant DNA and modern biotechnology, &lt;em&gt;including&lt;/em&gt; genome editing but not limited to it, you have to go first to your IBC, and they look and see what you’re doing to decide if there’s a danger there that you have not anticipated that requires special attention.&lt;/p&gt;



&lt;p&gt;If what you’re doing is going to get released into the environment or it’s going to be used to change an animal that’s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.&lt;/p&gt;



&lt;p&gt;If you’re working with humans and you’re doing medical therapies, like you’re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that’s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they’re getting into, that they’re the right people to be recruited, etc.&lt;/p&gt;



&lt;p&gt;So we do have this kind of Jenga game …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yeah, sounds like it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; … of regulatory agencies. And on top of all that, most of this involves professionals who’ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.&lt;/p&gt;



&lt;p&gt;And, of course, the insurance industry plays a big part because they decide whether or not what you’re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you’re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don’t regulate genome editing; we regulate the things that use genome editing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.&lt;/p&gt;



&lt;p&gt;So an example. If you’re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn’t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You’re trying to affect the animal’s physical constitution in some fashion.&lt;/p&gt;



&lt;p&gt;And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that’s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here’s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here’s the surveillance you have to do after it goes on the market.&lt;/p&gt;



&lt;p&gt;Even there, sometimes, it was confusing. What happens when it’s not the kind of animal you’re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?&lt;/p&gt;



&lt;p&gt;Because there, you’re really thinking more about pests, and if you’re editing the mosquito so that it can’t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.&lt;/p&gt;



&lt;p&gt;We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can’t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so … they can’t fly very far. That’s good. That actually makes it easier to control.&lt;/p&gt;



&lt;p&gt;But if you’re doing work that’s right near a border, then you have to be sure that the country next to you has the same rules for whether it’s permitted to do this and how to surveil what you’ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I mean, you’ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you’re walking a tightrope where, you know, if we clamp down too hard, we’ll stifle innovation, and if we’re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It’s still being worked out, frankly, but it’s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.&lt;/p&gt;



&lt;p&gt;Some things can’t be marketed until they’ve gotten an approval from the government. So you come up with a new drug, you can’t sell that until it’s gone through FDA approval.&lt;/p&gt;



&lt;p&gt;On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it’s only after they’re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either &lt;em&gt;pre&lt;/em&gt;-market controls: you can’t go on without permission. Or &lt;em&gt;post&lt;/em&gt;-market controls: we can take you off the market &lt;em&gt;if&lt;/em&gt; a problem occurs.&lt;/p&gt;



&lt;p&gt;How do we decide which one is appropriate for a particular application? It’s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.&lt;/p&gt;



&lt;p&gt;If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.&lt;/p&gt;



&lt;p&gt;And so that is the way that we make this balance. We look at the application area. And we’re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I know we’re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what’s the single piece of advice you give them if they’re interested in policy, regulation, the ethical side of things in genomics or other fields?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; I’d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we’re now going to be growing our buildings instead of building them out of concrete?&lt;/p&gt;



&lt;p&gt;Is it going to be a world in which our plants will glow in the evening so we don’t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?&lt;/p&gt;



&lt;p&gt;You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that’s responsible and helpful to everyone.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It was my pleasure. Thank you for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Now, I’m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft’s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.&lt;/p&gt;



&lt;p&gt;Daniel, it’s great to have you here. Thanks for coming in.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL KLUTTZ:&lt;/strong&gt; It’s great to be here, Kathleen.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. So maybe before we unpack Alta Charo’s insights, I’d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There’s the sensitive uses and emerging technologies. What does that mean?&lt;/p&gt;



&lt;p&gt;Sensitive uses, think of that as Microsoft’s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.&lt;/p&gt;



&lt;p&gt;Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we’re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it’s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I’d love to just understand how similar or not is that to managing the risks of AI in our world?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you’re going to apply that more general-purpose technology. Who’s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.&lt;/p&gt;



&lt;p&gt;Professor Charo talked a little bit about this, but if it’s something that’s been done before and it’s just a new spin on an old thing, maybe we’re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it’s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that’s labeled, what happens? Like, what kind of steps kick in from there?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So we have this Sensitive Uses program that’s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; At Berkeley, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; At Berkeley. That’s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.&lt;/p&gt;



&lt;p&gt;But Sensitive Uses, we force all of our teams when they’re envisioning their system design to think about, could the reasonably foreseeable use or &lt;em&gt;misuse&lt;/em&gt; of the system that they’re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone’s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we’ve had to human rights at Microsoft. And so could that system in it’s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? &lt;/p&gt;



&lt;p&gt;Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we’re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah, I mean, I think we’ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It’s a balancing test. It’s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is &lt;em&gt;not&lt;/em&gt;, and for good reason. It is still developing.&lt;/p&gt;



&lt;p&gt;And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. It’s a great point. So what isn’t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; … what maybe we should be taking into account from what Professor Charo shared with us?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; So one of the things I’ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don’t regulate genome editing; we regulate the things that &lt;em&gt;use&lt;/em&gt; genome editing. And while it’s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it’s fair to say, you know, we don’t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that’s how we think of our internal policy and oversight process at Microsoft, as well.&lt;/p&gt;



&lt;p&gt;And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.&lt;/p&gt;



&lt;p&gt;And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who’s using your tools and how they’re being used. And it’s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, you’re hitting on a great point. And I love this kind of layered approach that we’re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we’re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we’re operating in?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It’s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don’t want to just understand telemetry and data. But it’s really getting out there and understanding from our customers and not &lt;em&gt;just&lt;/em&gt; our customers. I would say our &lt;em&gt;stakeholders&lt;/em&gt; is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we’re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn’t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you’re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it’s very easy to say that you’re collecting data and you’re measuring, I don’t know, trust in AI, right? That’s a very fuzzy concept.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Right. Definitely.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call &lt;em&gt;measurable constructs&lt;/em&gt;. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there’s challenges with that everywhere. And I’m extremely fortunate to work at Microsoft with some of the world’s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure &lt;em&gt;and&lt;/em&gt; allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, makes a lot of sense. Before we close out, if you’re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you’ve ever reviewed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Oh gosh. Wow, this is where I get to be the social scientist.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ: &lt;/strong&gt;It’s like, define &lt;em&gt;favorite&lt;/em&gt;, Kathleen. [LAUGHS] Most &lt;em&gt;memorable&lt;/em&gt;, most &lt;em&gt;painful&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Let’s do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; We’ll do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.&lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. What’s one of the most overused phrases that you have in your AI governance meetings?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; But, you know, it’s said for a reason. And I think it sort of speaks to that clever nature. That’s one that comes to mind.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s great. And then maybe, maybe last one. What are you most excited about in the next, I don’t know, let’s say three months? This world is moving so fast!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we’re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It’s thinking strategically and having that foresight about what’s to come. And it’s exciting.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Thank you, Kathleen. I appreciate it. It’s been fun.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry, &lt;/em&gt;hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Alta Charo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field’s approach to regulating &lt;em&gt;applications &lt;/em&gt;of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, Daniel Kluttz&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a partner general manager in Microsoft’s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.&lt;/p&gt;











&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript-1"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN:&lt;/strong&gt; Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today I’m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.&lt;/p&gt;



&lt;p&gt;Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama’s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women’s health, stem cell research, genome editing, biosecurity, and more.&lt;/p&gt;



&lt;p&gt;After our conversation with Professor Charo, we’ll hear from Daniel Kluttz, a partner general manager in Microsoft’s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team’s work governing sensitive AI uses and emerging technologies.&lt;/p&gt;



&lt;p&gt;Alta, thank you so much for being here today. I’m a follower of your work and have really been looking forward to our conversation.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;ALTA CHARO:&lt;/strong&gt; It’s my pleasure. Thanks for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Alta, I’d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You’ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, I think it’s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.&lt;/p&gt;



&lt;p&gt;My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or &lt;em&gt;Star Trek&lt;/em&gt;. [LAUGHTER]&lt;/p&gt;



&lt;p&gt;And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; For listeners who are brand new to your field in genomic editing, can you give us what I’ll call a “90-second survey” of the space in perhaps plain language and why it’s important to have a framework for ensuring its responsible use.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, you know, genome editing is both very old and very new. At base, what we’re talking about is a way to either delete sections of the &lt;em&gt;genome&lt;/em&gt;, our collection of genes, or to add things or to alter what’s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it’s a plant, an animal, or a human.&lt;/p&gt;



&lt;p&gt;Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter &lt;em&gt;g&lt;/em&gt; to the letter &lt;em&gt;h&lt;/em&gt; in every word, and in our genomes, you can do similar kinds of things.&lt;/p&gt;



&lt;p&gt;But because of this, we have a responsibility to make sure that whatever we change doesn’t become dangerous and that it doesn’t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn’t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.&lt;/p&gt;



&lt;p&gt;It’s become more efficient. It doesn’t require as much sophisticated laboratory equipment. It’s moved from being something that only a few people can do to something that we’re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who’s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it’s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, to answer that, I’m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I’m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.&lt;/p&gt;



&lt;p&gt;You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called &lt;em&gt;off-target effect&lt;/em&gt;. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there’s going to be an interaction between what you changed and what was there, a &lt;em&gt;gene-gene interaction&lt;/em&gt;, that might have an unanticipated kind of result, a side effect essentially.&lt;/p&gt;



&lt;p&gt;So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it’s going to actually create something harmful. And that really depends upon the application.&lt;/p&gt;



&lt;p&gt;If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.&lt;/p&gt;



&lt;p&gt;It may also be that in other settings, what you’re doing is going to have a much lower risk because you’re working with a more familiar substance, your predictive power is much greater, and it’s not going into a human or an animal or into the environment. So I think that you have to say that the risk &lt;em&gt;and&lt;/em&gt; the benefits, by the way, all are going to depend upon the particular application.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I think on this point of application, there’s many players involved in that, right. Like, we often hear about this puzzle of who’s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it’s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called &lt;em&gt;coordinated framework&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.&lt;/p&gt;



&lt;p&gt;There’s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, &lt;em&gt;IBCs&lt;/em&gt;. You want to do research that involves recombinant DNA and modern biotechnology, &lt;em&gt;including&lt;/em&gt; genome editing but not limited to it, you have to go first to your IBC, and they look and see what you’re doing to decide if there’s a danger there that you have not anticipated that requires special attention.&lt;/p&gt;



&lt;p&gt;If what you’re doing is going to get released into the environment or it’s going to be used to change an animal that’s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.&lt;/p&gt;



&lt;p&gt;If you’re working with humans and you’re doing medical therapies, like you’re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that’s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they’re getting into, that they’re the right people to be recruited, etc.&lt;/p&gt;



&lt;p&gt;So we do have this kind of Jenga game …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yeah, sounds like it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; … of regulatory agencies. And on top of all that, most of this involves professionals who’ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.&lt;/p&gt;



&lt;p&gt;And, of course, the insurance industry plays a big part because they decide whether or not what you’re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you’re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don’t regulate genome editing; we regulate the things that use genome editing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.&lt;/p&gt;



&lt;p&gt;So an example. If you’re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn’t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You’re trying to affect the animal’s physical constitution in some fashion.&lt;/p&gt;



&lt;p&gt;And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that’s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here’s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here’s the surveillance you have to do after it goes on the market.&lt;/p&gt;



&lt;p&gt;Even there, sometimes, it was confusing. What happens when it’s not the kind of animal you’re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?&lt;/p&gt;



&lt;p&gt;Because there, you’re really thinking more about pests, and if you’re editing the mosquito so that it can’t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.&lt;/p&gt;



&lt;p&gt;We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can’t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so … they can’t fly very far. That’s good. That actually makes it easier to control.&lt;/p&gt;



&lt;p&gt;But if you’re doing work that’s right near a border, then you have to be sure that the country next to you has the same rules for whether it’s permitted to do this and how to surveil what you’ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I mean, you’ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you’re walking a tightrope where, you know, if we clamp down too hard, we’ll stifle innovation, and if we’re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It’s still being worked out, frankly, but it’s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.&lt;/p&gt;



&lt;p&gt;Some things can’t be marketed until they’ve gotten an approval from the government. So you come up with a new drug, you can’t sell that until it’s gone through FDA approval.&lt;/p&gt;



&lt;p&gt;On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it’s only after they’re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either &lt;em&gt;pre&lt;/em&gt;-market controls: you can’t go on without permission. Or &lt;em&gt;post&lt;/em&gt;-market controls: we can take you off the market &lt;em&gt;if&lt;/em&gt; a problem occurs.&lt;/p&gt;



&lt;p&gt;How do we decide which one is appropriate for a particular application? It’s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.&lt;/p&gt;



&lt;p&gt;If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.&lt;/p&gt;



&lt;p&gt;And so that is the way that we make this balance. We look at the application area. And we’re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I know we’re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what’s the single piece of advice you give them if they’re interested in policy, regulation, the ethical side of things in genomics or other fields?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; I’d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we’re now going to be growing our buildings instead of building them out of concrete?&lt;/p&gt;



&lt;p&gt;Is it going to be a world in which our plants will glow in the evening so we don’t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?&lt;/p&gt;



&lt;p&gt;You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that’s responsible and helpful to everyone.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It was my pleasure. Thank you for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Now, I’m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft’s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.&lt;/p&gt;



&lt;p&gt;Daniel, it’s great to have you here. Thanks for coming in.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL KLUTTZ:&lt;/strong&gt; It’s great to be here, Kathleen.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. So maybe before we unpack Alta Charo’s insights, I’d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There’s the sensitive uses and emerging technologies. What does that mean?&lt;/p&gt;



&lt;p&gt;Sensitive uses, think of that as Microsoft’s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.&lt;/p&gt;



&lt;p&gt;Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we’re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it’s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I’d love to just understand how similar or not is that to managing the risks of AI in our world?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you’re going to apply that more general-purpose technology. Who’s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.&lt;/p&gt;



&lt;p&gt;Professor Charo talked a little bit about this, but if it’s something that’s been done before and it’s just a new spin on an old thing, maybe we’re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it’s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that’s labeled, what happens? Like, what kind of steps kick in from there?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So we have this Sensitive Uses program that’s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; At Berkeley, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; At Berkeley. That’s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.&lt;/p&gt;



&lt;p&gt;But Sensitive Uses, we force all of our teams when they’re envisioning their system design to think about, could the reasonably foreseeable use or &lt;em&gt;misuse&lt;/em&gt; of the system that they’re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone’s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we’ve had to human rights at Microsoft. And so could that system in it’s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? &lt;/p&gt;



&lt;p&gt;Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we’re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah, I mean, I think we’ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It’s a balancing test. It’s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is &lt;em&gt;not&lt;/em&gt;, and for good reason. It is still developing.&lt;/p&gt;



&lt;p&gt;And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. It’s a great point. So what isn’t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; … what maybe we should be taking into account from what Professor Charo shared with us?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; So one of the things I’ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don’t regulate genome editing; we regulate the things that &lt;em&gt;use&lt;/em&gt; genome editing. And while it’s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it’s fair to say, you know, we don’t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that’s how we think of our internal policy and oversight process at Microsoft, as well.&lt;/p&gt;



&lt;p&gt;And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.&lt;/p&gt;



&lt;p&gt;And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who’s using your tools and how they’re being used. And it’s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, you’re hitting on a great point. And I love this kind of layered approach that we’re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we’re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we’re operating in?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It’s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don’t want to just understand telemetry and data. But it’s really getting out there and understanding from our customers and not &lt;em&gt;just&lt;/em&gt; our customers. I would say our &lt;em&gt;stakeholders&lt;/em&gt; is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we’re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn’t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you’re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it’s very easy to say that you’re collecting data and you’re measuring, I don’t know, trust in AI, right? That’s a very fuzzy concept.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Right. Definitely.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call &lt;em&gt;measurable constructs&lt;/em&gt;. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there’s challenges with that everywhere. And I’m extremely fortunate to work at Microsoft with some of the world’s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure &lt;em&gt;and&lt;/em&gt; allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, makes a lot of sense. Before we close out, if you’re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you’ve ever reviewed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Oh gosh. Wow, this is where I get to be the social scientist.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ: &lt;/strong&gt;It’s like, define &lt;em&gt;favorite&lt;/em&gt;, Kathleen. [LAUGHS] Most &lt;em&gt;memorable&lt;/em&gt;, most &lt;em&gt;painful&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Let’s do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; We’ll do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.&lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. What’s one of the most overused phrases that you have in your AI governance meetings?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; But, you know, it’s said for a reason. And I think it sort of speaks to that clever nature. That’s one that comes to mind.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s great. And then maybe, maybe last one. What are you most excited about in the next, I don’t know, let’s say three months? This world is moving so fast!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we’re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It’s thinking strategically and having that foresight about what’s to come. And it’s exciting.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Thank you, Kathleen. I appreciate it. It’s been fun.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</guid><pubDate>Mon, 30 Jun 2025 16:00:17 +0000</pubDate></item><item><title>[NEW] Google embraces AI in the classroom with new Gemini tools for educators, chatbots for students, and more (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/google-embraces-ai-in-the-classroom-with-new-gemini-tools-for-educators-chatbots-for-students-and-more/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Monday announced a series of updates intended to bring its Gemini AI and other AI-powered tools deeper into the classroom. At the ISTE edtech conference, the tech giant introduced more than 30 AI tools for educators, a version of the Gemini app built for education, expanded access to its collaborative video creation app Google Vids, and other tools for managed Chromebooks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates represent a major AI push in the edtech space, where educators are already struggling to adapt to how AI tools, like AI chatbots and startups that promise to help you “cheat on everything,” are making their way into the learning environment. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;School-aged kids and teens today are more likely to ask ChatGPT for help with their homework (or to even do it for them) than they are to ask a teacher to explain the concepts again. In higher ed, meanwhile, colleges are wrestling with whether or not plagiarism detectors can even identify AI-written content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this disruption, Google is charging ahead with AI tools, saying it thinks that “responsible AI” can help drive “more engaging and personalized learning experiences,” when used in conjunction with human-led teaching.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023324" height="390" src="https://techcrunch.com/wp-content/uploads/2025/06/ai-tools-for-educators.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Since announcing its plans to bring Gemini to the classroom last year, Google on Monday said that its Gemini AI suite for educators is now available for free to all Google Workspace for Education accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This includes over 30 new features, like the ability for teachers to brainstorm ideas, generate lesson plans, and personalize content for students using AI technology.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023320" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/lesson-plan.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Over the next several months, Google will give teachers the ability to create interactive study guides using the AI research tool Notebook LM, along with their classroom materials.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Teachers can also create custom versions of the Gemini AI called “Gems,” which will work as AI experts that help students who need extra support or want to better understand the subject.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is essentially just taking an activity that students are already doing — asking an AI chatbot to explain a topic or answer questions — and redirecting that activity back to Google’s own AI technology, where it’s specifically been trained on the teacher’s own classroom materials.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023323" height="378" src="https://techcrunch.com/wp-content/uploads/2025/06/gemini-chatbot-classroom.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, teachers will also be able to offer students real-time support for the AI-powered reading buddy when using the Read Along in Classroom tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google is expanding basic access to its AI-powered video creator, Google Vids, as well, to make it available to all Google Workspace for Education users. Teachers can use the tool to make instructional videos, while students can use Vids for things like book reports or other assignments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google Vids" class="wp-image-3023322" height="405" src="https://techcrunch.com/wp-content/uploads/2025/06/vids.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also rolling out a series of new features designed to track student progress against learning standards and skills, view analytics on student performance and engagement, better secure Gemini user data and data in Gmail, manage who has access to AI tools like Gemini and Notebook LM, have better control over Google Meet waiting rooms, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, along with a handful of updates for managed Chromebooks, Google introduced a new teaching mode called Class tools. This allows teachers to connect directly with their students via Google Classroom and share content to the kids’ screens, like videos, articles, slides, and quizzes. These tools can be adapted to the student’s own language, if need be, and are designed to keep kids focused on learning by restricting browsing to specific tabs.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Monday announced a series of updates intended to bring its Gemini AI and other AI-powered tools deeper into the classroom. At the ISTE edtech conference, the tech giant introduced more than 30 AI tools for educators, a version of the Gemini app built for education, expanded access to its collaborative video creation app Google Vids, and other tools for managed Chromebooks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates represent a major AI push in the edtech space, where educators are already struggling to adapt to how AI tools, like AI chatbots and startups that promise to help you “cheat on everything,” are making their way into the learning environment. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;School-aged kids and teens today are more likely to ask ChatGPT for help with their homework (or to even do it for them) than they are to ask a teacher to explain the concepts again. In higher ed, meanwhile, colleges are wrestling with whether or not plagiarism detectors can even identify AI-written content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this disruption, Google is charging ahead with AI tools, saying it thinks that “responsible AI” can help drive “more engaging and personalized learning experiences,” when used in conjunction with human-led teaching.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023324" height="390" src="https://techcrunch.com/wp-content/uploads/2025/06/ai-tools-for-educators.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Since announcing its plans to bring Gemini to the classroom last year, Google on Monday said that its Gemini AI suite for educators is now available for free to all Google Workspace for Education accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This includes over 30 new features, like the ability for teachers to brainstorm ideas, generate lesson plans, and personalize content for students using AI technology.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023320" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/lesson-plan.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Over the next several months, Google will give teachers the ability to create interactive study guides using the AI research tool Notebook LM, along with their classroom materials.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Teachers can also create custom versions of the Gemini AI called “Gems,” which will work as AI experts that help students who need extra support or want to better understand the subject.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is essentially just taking an activity that students are already doing — asking an AI chatbot to explain a topic or answer questions — and redirecting that activity back to Google’s own AI technology, where it’s specifically been trained on the teacher’s own classroom materials.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023323" height="378" src="https://techcrunch.com/wp-content/uploads/2025/06/gemini-chatbot-classroom.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, teachers will also be able to offer students real-time support for the AI-powered reading buddy when using the Read Along in Classroom tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google is expanding basic access to its AI-powered video creator, Google Vids, as well, to make it available to all Google Workspace for Education users. Teachers can use the tool to make instructional videos, while students can use Vids for things like book reports or other assignments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google Vids" class="wp-image-3023322" height="405" src="https://techcrunch.com/wp-content/uploads/2025/06/vids.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also rolling out a series of new features designed to track student progress against learning standards and skills, view analytics on student performance and engagement, better secure Gemini user data and data in Gmail, manage who has access to AI tools like Gemini and Notebook LM, have better control over Google Meet waiting rooms, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, along with a handful of updates for managed Chromebooks, Google introduced a new teaching mode called Class tools. This allows teachers to connect directly with their students via Google Classroom and share content to the kids’ screens, like videos, articles, slides, and quizzes. These tools can be adapted to the student’s own language, if need be, and are designed to keep kids focused on learning by restricting browsing to specific tabs.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/google-embraces-ai-in-the-classroom-with-new-gemini-tools-for-educators-chatbots-for-students-and-more/</guid><pubDate>Mon, 30 Jun 2025 16:44:28 +0000</pubDate></item><item><title>[NEW] Congress might block state AI laws for five years. Here’s what it means. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/congress-might-block-state-ai-laws-for-five-years-heres-what-it-means/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for five years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill — which the Senate is voting on Monday — ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor — including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen — argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It was initially designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, over the weekend, Cruz and Sen. Marsha Blackburn (R-TN), who has also criticized the bill, agreed to shorten the pause on state-based AI regulation to five years. The new language also attempts to exempt laws addressing child sexual abuse materials, children’s online safety, and an individual’s rights to their name, likeness, voice, and image. However, the amendment says the laws must not place an “undue or disproportionate burden” on AI systems — legal experts are unsure how this would impact state AI laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But the moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana, and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cruz released another revision last week, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill — a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already obligated broadband funding from states that don’t comply.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) previously criticized Cruz’s reconciliation language, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 7, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday, the Senate is engaged in a vote-a-rama — a series of rapid votes on the budget bill’s full slate of amendments. The new language that Cruz and Blackburn agreed on will be included in a broader amendment, one that Republicans are expected to pass on a party line vote. Senators will also likely vote on a Democrat-backed amendment to strip the entire section, sources familiar with the matter told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments last week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I worry that if … we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Dario Amodei&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation — it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode — which has sponsored several state AI safety bills — in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Sen. Josh Hawley (R-MO), who is concerned about states’ rights and is working with Democrats to strip it from the bill. Blackburn also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated June 30 to reflect amendments to the bill, new reporting on the Senate’s timeline to vote on the bill, and fresh Republican opposition to the AI moratorium.  &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for five years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill — which the Senate is voting on Monday — ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor — including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen — argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It was initially designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, over the weekend, Cruz and Sen. Marsha Blackburn (R-TN), who has also criticized the bill, agreed to shorten the pause on state-based AI regulation to five years. The new language also attempts to exempt laws addressing child sexual abuse materials, children’s online safety, and an individual’s rights to their name, likeness, voice, and image. However, the amendment says the laws must not place an “undue or disproportionate burden” on AI systems — legal experts are unsure how this would impact state AI laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But the moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana, and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cruz released another revision last week, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill — a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already obligated broadband funding from states that don’t comply.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) previously criticized Cruz’s reconciliation language, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 7, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday, the Senate is engaged in a vote-a-rama — a series of rapid votes on the budget bill’s full slate of amendments. The new language that Cruz and Blackburn agreed on will be included in a broader amendment, one that Republicans are expected to pass on a party line vote. Senators will also likely vote on a Democrat-backed amendment to strip the entire section, sources familiar with the matter told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments last week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I worry that if … we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Dario Amodei&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation — it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode — which has sponsored several state AI safety bills — in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Sen. Josh Hawley (R-MO), who is concerned about states’ rights and is working with Democrats to strip it from the bill. Blackburn also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated June 30 to reflect amendments to the bill, new reporting on the Senate’s timeline to vote on the bill, and fresh Republican opposition to the AI moratorium.  &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/congress-might-block-state-ai-laws-for-five-years-heres-what-it-means/</guid><pubDate>Mon, 30 Jun 2025 17:02:12 +0000</pubDate></item><item><title>[NEW] Meta restructures its AI unit under ‘Superintelligence Labs’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/meta-restructures-its-ai-unit-under-superintelligence-labs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg is restructuring the company’s AI efforts to center around building&amp;nbsp; AI “superintelligence.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, all teams working on AI at Meta will fall under a new group called Meta Superintelligence Labs, according to Bloomberg, which viewed an internal memo sent Monday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alexandr Wang, the former CEO of data labeling startup Scale AI, will lead the group as chief AI officer. He’ll partner with former GitHub CEO Nat Friedman, who will oversee Meta’s AI products and applied research, per Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has been working hard to get ahead of the AGI race, mainly by acquiring AI companies and employees from top AI firms. Earlier this month, Meta invested $14.3 billion in Scale AI, bringing on Wang in the process. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has also been able to lure 11 new AI researchers from competitors, according to the report, including some previously unreported hires such as Google DeepMind principal researcher Pei Sun and Anthropic engineer Joel Pobar.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg is restructuring the company’s AI efforts to center around building&amp;nbsp; AI “superintelligence.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, all teams working on AI at Meta will fall under a new group called Meta Superintelligence Labs, according to Bloomberg, which viewed an internal memo sent Monday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alexandr Wang, the former CEO of data labeling startup Scale AI, will lead the group as chief AI officer. He’ll partner with former GitHub CEO Nat Friedman, who will oversee Meta’s AI products and applied research, per Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has been working hard to get ahead of the AGI race, mainly by acquiring AI companies and employees from top AI firms. Earlier this month, Meta invested $14.3 billion in Scale AI, bringing on Wang in the process. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has also been able to lure 11 new AI researchers from competitors, according to the report, including some previously unreported hires such as Google DeepMind principal researcher Pei Sun and Anthropic engineer Joel Pobar.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/meta-restructures-its-ai-unit-under-superintelligence-labs/</guid><pubDate>Mon, 30 Jun 2025 17:56:25 +0000</pubDate></item></channel></rss>