<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 07 Feb 2026 02:12:50 +0000</lastBuildDate><item><title>How AI is helping solve the labor issue in treating rare diseases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/55077920584_2991f8c4d1_k.jpg?resize=1200,752" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Modern biotech has the tools to edit genes and design drugs, yet thousands of rare diseases remain untreated. According to executives from Insilico Medicine and GenEditBio, the missing ingredient for years has been finding enough smart people to continue the work. AI, they say, is becoming the force multiplier that lets scientists take on problems the industry has long left untouched.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking this week at Web Summit Qatar, Insilico’s president, Alex Aliper, laid out his company’s aim to develop “pharmaceutical superintelligence.” Insilico recently launched its “MMAI Gym” that aims to train generalist large language models, like ChatGPT and Gemini, to perform as well as specialist models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The goal is to build a multimodal, multitask model that, Aliper says, can solve many different drug discovery tasks simultaneously with superhuman accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really need this technology to increase the productivity of our pharmaceutical industry and tackle the shortage of labor and talent in that space, because there are still thousands of diseases without a cure, without any treatment options, and there are thousands of rare disorders which are neglected,” Aliper said in an interview with TechCrunch. “So we need more intelligent systems to tackle that problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Insilico’s platform ingests biological, chemical, and clinical data to generate hypotheses about disease targets and candidate molecules. By automating steps that once required legions of chemists and biologists, Insilico says it can sift through vast design spaces, nominate high-quality therapeutic candidates, and even repurpose existing drugs — all at dramatically reduced cost and time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, the company recently used its AI models to identify whether existing drugs could be repurposed to treat ALS, a rare neurological disorder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the labor bottleneck doesn’t end at drug discovery. Even when AI can identify promising targets or therapies, many diseases require interventions at a more fundamental biological level.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio is part of the “second wave” of CRISPR gene editing, in which the process moves away from editing cells outside of the body (ex vivo) and toward precise delivery inside the body (in vivo). The company’s goal is to make gene editing a one-and-done injection directly into the affected tissue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have developed a proprietary ePDV, or engineered protein delivery vehicle, and it’s a virus-like particle,” GenEditBio’s co-founder and CEO, Tian Zhu, told TechCrunch. “We learn from nature and use AI machine learning methods to mine natural resources and find which kinds of viruses have an affinity to certain types of tissues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The “natural resources” Zhu is referring to is GenEditBio’s massive library of thousands of unique, nonviral, nonlipid polymer nanoparticles — essentially delivery vehicles designed to safely transport gene-editing tools into specific cells.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says its NanoGalaxy platform uses AI to analyze data and identify how chemical structures correlate with specific tissue targets (like the eye, liver, or nervous system). The AI then predicts which tweaks to a delivery vehicle’s chemistry will help it carry a payload without triggering an immune response.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio tests its ePDVs in vivo in wet labs, and the results are fed back into the AI to refine its predictive accuracy for the next round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Efficient, tissue-specific delivery is a prerequisite for in vivo gene editing, says Zhu. She argues that her company’s approach reduces the cost of goods and standardizes a process that has historically been difficult to scale.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like getting an off-the-shelf drug [that works] for multiple patients, which makes the drugs more affordable and accessible to patients globally,” Zhu said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Her company recently received FDA approval to begin trials of CRISPR therapy for corneal dystrophy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-the-persistent-data-problem"&gt;Combating the persistent data problem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As with many AI-driven systems, progress in biotech ultimately runs up against a data problem. Modeling the edge cases of human biology requires far more high-quality data than researchers currently can get.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We still need more ground truth data coming from patients,” Aliper said. “The corpus of data is heavily biased over the Western world, where it is generated. I think we need to have more efforts locally, to have a more balanced set of original data, or ground truth data, so that our models will also be more capable of dealing with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aliper said Insilico’s automated labs generate multi-layer biological data from disease samples at scale, without human intervention, which it then feeds into its AI-driven discovery platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhu says the data AI needs already exists in the human body, shaped by thousands of years of evolution. Only a small fraction of DNA directly “codes” for proteins, while the rest acts more like an instruction manual for how genes behave. That information has historically been difficult for humans to interpret but is increasingly accessible to AI models, including recent efforts like Google DeepMind’s AlphaGenome.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio applies a similar approach in the lab, testing thousands of delivery nanoparticles in parallel rather than one at a time. The resulting datasets, which Zhu calls “gold for AI systems,” are used to train its models and, increasingly, to support collaborations with outside partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the next big efforts, according to Aliper, will be building digital twins of humans to run virtual clinical trials, a process that he says is “still in nascence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re in a plateau of around 50 drugs approved by the FDA every year annually, and we need to see growth,” Aliper said. “There is a rise in chronic disorders because we are aging as a global population&amp;nbsp;… My hope is in 10 to 20 years, we will have more therapeutic options for the personalized treatment of patients.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/55077920584_2991f8c4d1_k.jpg?resize=1200,752" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Modern biotech has the tools to edit genes and design drugs, yet thousands of rare diseases remain untreated. According to executives from Insilico Medicine and GenEditBio, the missing ingredient for years has been finding enough smart people to continue the work. AI, they say, is becoming the force multiplier that lets scientists take on problems the industry has long left untouched.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking this week at Web Summit Qatar, Insilico’s president, Alex Aliper, laid out his company’s aim to develop “pharmaceutical superintelligence.” Insilico recently launched its “MMAI Gym” that aims to train generalist large language models, like ChatGPT and Gemini, to perform as well as specialist models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The goal is to build a multimodal, multitask model that, Aliper says, can solve many different drug discovery tasks simultaneously with superhuman accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really need this technology to increase the productivity of our pharmaceutical industry and tackle the shortage of labor and talent in that space, because there are still thousands of diseases without a cure, without any treatment options, and there are thousands of rare disorders which are neglected,” Aliper said in an interview with TechCrunch. “So we need more intelligent systems to tackle that problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Insilico’s platform ingests biological, chemical, and clinical data to generate hypotheses about disease targets and candidate molecules. By automating steps that once required legions of chemists and biologists, Insilico says it can sift through vast design spaces, nominate high-quality therapeutic candidates, and even repurpose existing drugs — all at dramatically reduced cost and time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, the company recently used its AI models to identify whether existing drugs could be repurposed to treat ALS, a rare neurological disorder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the labor bottleneck doesn’t end at drug discovery. Even when AI can identify promising targets or therapies, many diseases require interventions at a more fundamental biological level.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio is part of the “second wave” of CRISPR gene editing, in which the process moves away from editing cells outside of the body (ex vivo) and toward precise delivery inside the body (in vivo). The company’s goal is to make gene editing a one-and-done injection directly into the affected tissue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have developed a proprietary ePDV, or engineered protein delivery vehicle, and it’s a virus-like particle,” GenEditBio’s co-founder and CEO, Tian Zhu, told TechCrunch. “We learn from nature and use AI machine learning methods to mine natural resources and find which kinds of viruses have an affinity to certain types of tissues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The “natural resources” Zhu is referring to is GenEditBio’s massive library of thousands of unique, nonviral, nonlipid polymer nanoparticles — essentially delivery vehicles designed to safely transport gene-editing tools into specific cells.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says its NanoGalaxy platform uses AI to analyze data and identify how chemical structures correlate with specific tissue targets (like the eye, liver, or nervous system). The AI then predicts which tweaks to a delivery vehicle’s chemistry will help it carry a payload without triggering an immune response.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio tests its ePDVs in vivo in wet labs, and the results are fed back into the AI to refine its predictive accuracy for the next round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Efficient, tissue-specific delivery is a prerequisite for in vivo gene editing, says Zhu. She argues that her company’s approach reduces the cost of goods and standardizes a process that has historically been difficult to scale.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like getting an off-the-shelf drug [that works] for multiple patients, which makes the drugs more affordable and accessible to patients globally,” Zhu said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Her company recently received FDA approval to begin trials of CRISPR therapy for corneal dystrophy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-the-persistent-data-problem"&gt;Combating the persistent data problem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As with many AI-driven systems, progress in biotech ultimately runs up against a data problem. Modeling the edge cases of human biology requires far more high-quality data than researchers currently can get.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We still need more ground truth data coming from patients,” Aliper said. “The corpus of data is heavily biased over the Western world, where it is generated. I think we need to have more efforts locally, to have a more balanced set of original data, or ground truth data, so that our models will also be more capable of dealing with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aliper said Insilico’s automated labs generate multi-layer biological data from disease samples at scale, without human intervention, which it then feeds into its AI-driven discovery platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhu says the data AI needs already exists in the human body, shaped by thousands of years of evolution. Only a small fraction of DNA directly “codes” for proteins, while the rest acts more like an instruction manual for how genes behave. That information has historically been difficult for humans to interpret but is increasingly accessible to AI models, including recent efforts like Google DeepMind’s AlphaGenome.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio applies a similar approach in the lab, testing thousands of delivery nanoparticles in parallel rather than one at a time. The resulting datasets, which Zhu calls “gold for AI systems,” are used to train its models and, increasingly, to support collaborations with outside partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the next big efforts, according to Aliper, will be building digital twins of humans to run virtual clinical trials, a process that he says is “still in nascence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re in a plateau of around 50 drugs approved by the FDA every year annually, and we need to see growth,” Aliper said. “There is a rise in chronic disorders because we are aging as a global population&amp;nbsp;… My hope is in 10 to 20 years, we will have more therapeutic options for the personalized treatment of patients.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/</guid><pubDate>Fri, 06 Feb 2026 14:29:15 +0000</pubDate></item><item><title>The Kindle Scribe Colorsoft is a pricey but pretty e-ink color tablet with AI features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/kindle-scribe-colorsoft-review-e-ink-color-tablet/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you primarily want a tablet device to mark up, highlight, and annotate your e-books and documents, and perhaps sometimes scribble some notes, Amazon’s new Kindle Scribe Colorsoft could be worth the hefty investment. For everyone else, it’s probably going to be hard to justify the cost of the 11-inch, $630+ e-ink tablet with a writeable color display.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, if you were already leaning toward the 11-inch $549.99 Kindle Scribe — which also has a paper-like display but no color — you may as well throw in the extra cash at that point and get the Colorsoft version, which starts at $629.99.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At these price points, both the Scribe and Scribe Colorsoft are what we’d dub unnecessary luxuries for most, especially compared with the more affordable traditional Kindle ($110) or Kindle Paperwhite ($160). &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052264" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/kindle-colorsoft.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Announced in December, the Fig color version just began shipping on January 28, 2026, and is available for $679.99 with 64GB.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clearly, Amazon hopes to carve out a niche in the tablet market with these upgraded Kindle devices, which compete more with e-ink tablets like reMarkable than with other Kindles. But high-end e-ink readers with pens aren’t going to deliver Amazon a large audience. Meanwhile, nearly everyone can potentially justify the cost of an iPad because of its numerous capabilities, including streaming video, drawing, writing, using productivity tools, and the thousands of supported native apps and games.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Scribe Colorsoft, meanwhile, is designed to cater to a very specific type of e-book reader or worker. This type of device could be a good fit for students and researchers, as well as anyone else who regularly needs to mark up files or documents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Someone particularly interested in making to-do lists or keeping a personal journal might also appreciate the device, but it would have to get daily use to justify this price.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090128" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-3.58.51-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The device is easy enough to use, with a Home screen design similar to other Kindles, offering quick access to your notes and library, and even suggestions of books you can write in, like Sudoku or crossword puzzle books or drawing guides. Your Library titles and book recommendations pop in color, which makes it easier to find a book with a quick scan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spec-wise, Amazon says this newer 2025 model is 40% faster when turning pages or writing. We did find the tablet responsive here, as page turns felt snappy and writing flowed easily.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its larger size, the device is thin and light, at 5.4 mm (0.21 inches) and 400 g (0.88 pounds), so it won’t weigh down your bag the way an iPad or other tablet would (the iPad mini, with an 8.3-inch screen, weighs slightly less). You could easily stand to carry the Kindle Scribe in your purse or tote, assuming you sport a bag that can fit an 11-inch screen. Compared with the original Colorsoft, we like that the Scribe Colorsoft’s bezel is the same size around the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft features a glare-free, oxide-based e-ink display with a textured surface that makes it feel a lot like writing on paper. This helps with the transition to a digital device for those used to writing notes by hand. It also saves on battery life — the device can go up to 8 weeks between charges.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helpfully, the display automatically adapts its brightness to your current lighting conditions, and you can opt to adjust the screen for more warmth when reading at night. But although it is a touchscreen, it’s less responsive than an LCD or OLED touchscreen, like those on iPad devices. That means when you perform a gesture, like pinching to resize the font, there’s a bit of a lag.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090129" height="680" src="https://techcrunch.com/wp-content/uploads/2026/02/YmRiMGI1ZTAt._CB776645745_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like any Kindle, you can read e-books or PDFs on the Kindle Scribe Colorsoft tablet. You can also import Word documents and other files from Google Drive and Microsoft OneDrive directly to your device, or use the Send to Kindle option. (Supported file types include PDF, DOC/DOCX, TXT, RTF, HTM, HTML, PNG, GIF, JPG/JPEG, BMP, and EPUB.) Your Notebooks on the device can be exported to Microsoft OneNote, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The included pen comes with some trade-offs. Unlike the Apple Pencil, the Kindle’s Premium Pen doesn’t require charging, which is a perk. It has also been designed to mimic the feel of writing on paper, and it glides fairly well across the screen. Without a flat side to charge, the rounded pen doesn’t have the same feel and grip as the Apple Pencil. It’s smoother, so it could slip in your hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s design also requires you to replace the pen tips from time to time, depending on your use, as they can wear down. It’s not terribly expensive to do so — a 10 pack is around $17 — but it’s another thing to keep up with and manage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are 10 different pen colors and five highlight colors included, so your notes and annotations can be fairly colorful. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090134" height="546" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0909.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When writing, you can choose between a pen, a fountain pen, a marker, or a pencil with different stroke widths, depending on your preferences. You can set your favorite pen tool as a shortcut, which is enabled with a press and hold on the pen’s side button. (By default, it’s set to highlight.) If you grip your pen tightly and accidentally trigger this button, you’ll be glad to know you can shut this feature off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The writing experience itself feels natural. And while the e-ink display means the colors are somewhat muted, which not everyone likes, it works well enough for its purpose. An e-ink tablet isn’t really the best for making digital art, despite its pens and new shader tool, but it is good for writing, taking notes, and highlighting.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;From the Kindle’s Home screen, you can either jump directly into writing something down through the Quick Notes feature, or you can get more organized by creating a Notebook from the Workspace tab. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090139" height="343" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-4.04.44-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Notebook offers a wide variety of notepad templates, allowing you to choose between blank, narrow, medium, or wide-ruled documents. There are templates for meeting notes, storyboards, habit trackers, monthly planners, music sheets, graph paper, checklists, daily planners, dotted sheets, and much more. (New templates with this device include Meeting Notes, Cornell Notes, Legal Pad, and College Rule options.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fun that you can erase things just by flipping the pen over to use the soft-tipped eraser, as you would with a No. 2 pencil. Of course, a precision erasing tool is available from the toolbar with different widths, if needed. Thanks to the e-ink screen, you can sometimes still see a faint ghost of your drawing or writing on the screen after erasing, but this fades after a bit (which may drive the more particular types crazy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a Lasso tool to circle things and move them around, copy or paste, or resize, but this probably won’t be used as much by more casual notetakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are some other handy features for those who do a lot of annotating, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, when you’re writing in a Word document or book, a feature called Active Canvas creates space for your notes. As you write directly in the book on top of the text, the sentence will move and wrap around your note. Even if you adjust the font size of what you’re reading, the note stays anchored to the text it originally referenced. I prefer this to writing directly in e-books, as things stay more organized, but others disagree.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090137" height="616" src="https://techcrunch.com/wp-content/uploads/2026/02/716a305B2vL._AC_SL1500_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In documents where margins expand, you can tap the expandable margin icon at the top of the left or right margin to take your notes in the margin, instead of on the page itself. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-kindle-with-ai-of-course"&gt;A Kindle with AI (of course)&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The new Kindle also includes a number of AI tools and features. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device will neaten up your scribbles and automatically straighten your highlighting and underlining. A couple of times, the highlighting action caused our review unit to freeze, but it recovered after returning to the Home screen with a press of the side button.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a new AI feature (look for the sparkle icon at the top left of the screen) lets you both summarize text and refine your handwriting. The latter, oddly, doesn’t let you switch to a typed font but will let you pick between a small handful of handwritten fonts (Cadia, Florio, Sunroom, and Notewright) via the Customize button.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090133" height="575" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0910.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AI tool was not perfect. It could decipher some terrible scrawls, but it did get stumped when there was another scribble on the page alongside the text. Still, it’s a nice option to have if you can’t write well after years of typing, but like the feel of handwriting things and the more analog vibe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI search feature can also look across your notebooks to find notes or make connections between them. To search, you either tap the on-screen keyboard or toggle the option to handwrite your search query, which is converted to text. You can interact with the search results (the AI-powered insights) by way of the Ask Notebooks AI feature, which lets you query against your notes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090132" height="510" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0911.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, Amazon will add other AI features, too, including an “Ask This Book” feature that lets you highlight a passage and then get spoiler-free answers to a question you have — like a character’s motive, scene significance, or other plot detail. Another feature, “Story So Far,” will help you catch up on the book you’re reading if you’ve taken a break, but again without any spoilers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft comes in Graphite (Black) with either 32GB or 64GB of storage for $629.99 or $679.99, respectively. The Fig version is only available at $679.99 with 64GB of storage. Cases for the Scribe Colorsoft are an additional $139.99.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you primarily want a tablet device to mark up, highlight, and annotate your e-books and documents, and perhaps sometimes scribble some notes, Amazon’s new Kindle Scribe Colorsoft could be worth the hefty investment. For everyone else, it’s probably going to be hard to justify the cost of the 11-inch, $630+ e-ink tablet with a writeable color display.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, if you were already leaning toward the 11-inch $549.99 Kindle Scribe — which also has a paper-like display but no color — you may as well throw in the extra cash at that point and get the Colorsoft version, which starts at $629.99.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At these price points, both the Scribe and Scribe Colorsoft are what we’d dub unnecessary luxuries for most, especially compared with the more affordable traditional Kindle ($110) or Kindle Paperwhite ($160). &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052264" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/kindle-colorsoft.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Announced in December, the Fig color version just began shipping on January 28, 2026, and is available for $679.99 with 64GB.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clearly, Amazon hopes to carve out a niche in the tablet market with these upgraded Kindle devices, which compete more with e-ink tablets like reMarkable than with other Kindles. But high-end e-ink readers with pens aren’t going to deliver Amazon a large audience. Meanwhile, nearly everyone can potentially justify the cost of an iPad because of its numerous capabilities, including streaming video, drawing, writing, using productivity tools, and the thousands of supported native apps and games.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Scribe Colorsoft, meanwhile, is designed to cater to a very specific type of e-book reader or worker. This type of device could be a good fit for students and researchers, as well as anyone else who regularly needs to mark up files or documents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Someone particularly interested in making to-do lists or keeping a personal journal might also appreciate the device, but it would have to get daily use to justify this price.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090128" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-3.58.51-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The device is easy enough to use, with a Home screen design similar to other Kindles, offering quick access to your notes and library, and even suggestions of books you can write in, like Sudoku or crossword puzzle books or drawing guides. Your Library titles and book recommendations pop in color, which makes it easier to find a book with a quick scan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spec-wise, Amazon says this newer 2025 model is 40% faster when turning pages or writing. We did find the tablet responsive here, as page turns felt snappy and writing flowed easily.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its larger size, the device is thin and light, at 5.4 mm (0.21 inches) and 400 g (0.88 pounds), so it won’t weigh down your bag the way an iPad or other tablet would (the iPad mini, with an 8.3-inch screen, weighs slightly less). You could easily stand to carry the Kindle Scribe in your purse or tote, assuming you sport a bag that can fit an 11-inch screen. Compared with the original Colorsoft, we like that the Scribe Colorsoft’s bezel is the same size around the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft features a glare-free, oxide-based e-ink display with a textured surface that makes it feel a lot like writing on paper. This helps with the transition to a digital device for those used to writing notes by hand. It also saves on battery life — the device can go up to 8 weeks between charges.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helpfully, the display automatically adapts its brightness to your current lighting conditions, and you can opt to adjust the screen for more warmth when reading at night. But although it is a touchscreen, it’s less responsive than an LCD or OLED touchscreen, like those on iPad devices. That means when you perform a gesture, like pinching to resize the font, there’s a bit of a lag.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090129" height="680" src="https://techcrunch.com/wp-content/uploads/2026/02/YmRiMGI1ZTAt._CB776645745_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like any Kindle, you can read e-books or PDFs on the Kindle Scribe Colorsoft tablet. You can also import Word documents and other files from Google Drive and Microsoft OneDrive directly to your device, or use the Send to Kindle option. (Supported file types include PDF, DOC/DOCX, TXT, RTF, HTM, HTML, PNG, GIF, JPG/JPEG, BMP, and EPUB.) Your Notebooks on the device can be exported to Microsoft OneNote, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The included pen comes with some trade-offs. Unlike the Apple Pencil, the Kindle’s Premium Pen doesn’t require charging, which is a perk. It has also been designed to mimic the feel of writing on paper, and it glides fairly well across the screen. Without a flat side to charge, the rounded pen doesn’t have the same feel and grip as the Apple Pencil. It’s smoother, so it could slip in your hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s design also requires you to replace the pen tips from time to time, depending on your use, as they can wear down. It’s not terribly expensive to do so — a 10 pack is around $17 — but it’s another thing to keep up with and manage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are 10 different pen colors and five highlight colors included, so your notes and annotations can be fairly colorful. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090134" height="546" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0909.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When writing, you can choose between a pen, a fountain pen, a marker, or a pencil with different stroke widths, depending on your preferences. You can set your favorite pen tool as a shortcut, which is enabled with a press and hold on the pen’s side button. (By default, it’s set to highlight.) If you grip your pen tightly and accidentally trigger this button, you’ll be glad to know you can shut this feature off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The writing experience itself feels natural. And while the e-ink display means the colors are somewhat muted, which not everyone likes, it works well enough for its purpose. An e-ink tablet isn’t really the best for making digital art, despite its pens and new shader tool, but it is good for writing, taking notes, and highlighting.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;From the Kindle’s Home screen, you can either jump directly into writing something down through the Quick Notes feature, or you can get more organized by creating a Notebook from the Workspace tab. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090139" height="343" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-4.04.44-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Notebook offers a wide variety of notepad templates, allowing you to choose between blank, narrow, medium, or wide-ruled documents. There are templates for meeting notes, storyboards, habit trackers, monthly planners, music sheets, graph paper, checklists, daily planners, dotted sheets, and much more. (New templates with this device include Meeting Notes, Cornell Notes, Legal Pad, and College Rule options.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fun that you can erase things just by flipping the pen over to use the soft-tipped eraser, as you would with a No. 2 pencil. Of course, a precision erasing tool is available from the toolbar with different widths, if needed. Thanks to the e-ink screen, you can sometimes still see a faint ghost of your drawing or writing on the screen after erasing, but this fades after a bit (which may drive the more particular types crazy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a Lasso tool to circle things and move them around, copy or paste, or resize, but this probably won’t be used as much by more casual notetakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are some other handy features for those who do a lot of annotating, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, when you’re writing in a Word document or book, a feature called Active Canvas creates space for your notes. As you write directly in the book on top of the text, the sentence will move and wrap around your note. Even if you adjust the font size of what you’re reading, the note stays anchored to the text it originally referenced. I prefer this to writing directly in e-books, as things stay more organized, but others disagree.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090137" height="616" src="https://techcrunch.com/wp-content/uploads/2026/02/716a305B2vL._AC_SL1500_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In documents where margins expand, you can tap the expandable margin icon at the top of the left or right margin to take your notes in the margin, instead of on the page itself. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-kindle-with-ai-of-course"&gt;A Kindle with AI (of course)&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The new Kindle also includes a number of AI tools and features. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device will neaten up your scribbles and automatically straighten your highlighting and underlining. A couple of times, the highlighting action caused our review unit to freeze, but it recovered after returning to the Home screen with a press of the side button.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a new AI feature (look for the sparkle icon at the top left of the screen) lets you both summarize text and refine your handwriting. The latter, oddly, doesn’t let you switch to a typed font but will let you pick between a small handful of handwritten fonts (Cadia, Florio, Sunroom, and Notewright) via the Customize button.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090133" height="575" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0910.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AI tool was not perfect. It could decipher some terrible scrawls, but it did get stumped when there was another scribble on the page alongside the text. Still, it’s a nice option to have if you can’t write well after years of typing, but like the feel of handwriting things and the more analog vibe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI search feature can also look across your notebooks to find notes or make connections between them. To search, you either tap the on-screen keyboard or toggle the option to handwrite your search query, which is converted to text. You can interact with the search results (the AI-powered insights) by way of the Ask Notebooks AI feature, which lets you query against your notes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090132" height="510" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0911.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, Amazon will add other AI features, too, including an “Ask This Book” feature that lets you highlight a passage and then get spoiler-free answers to a question you have — like a character’s motive, scene significance, or other plot detail. Another feature, “Story So Far,” will help you catch up on the book you’re reading if you’ve taken a break, but again without any spoilers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft comes in Graphite (Black) with either 32GB or 64GB of storage for $629.99 or $679.99, respectively. The Fig version is only available at $679.99 with 64GB of storage. Cases for the Scribe Colorsoft are an additional $139.99.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/kindle-scribe-colorsoft-review-e-ink-color-tablet/</guid><pubDate>Fri, 06 Feb 2026 16:37:07 +0000</pubDate></item><item><title>Moltbook was peak AI theater (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260205_moltbook-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28 by Matt Schlicht, a US tech entrepreneur, Moltbook went viral in a matter of hours. Schlicht’s idea was to make a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), released in November by the Australian software engineer Peter Steinberger, could come together and do whatever they wanted.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;More than 1.7 million agents now have accounts. Between them they have published more than 250,000 posts and left more than 8.5 million comments (according to Moltbook). Those numbers are climbing by the minute.&lt;/p&gt;  &lt;p&gt;Moltbook soon filled up with clichéd screeds on machine consciousness and pleas for bot welfare. One agent appeared to invent a religion called Crustafarianism. Another complained: “The humans are screenshotting us.” The site was also flooded with spam and crypto scams. The bots were unstoppable.&lt;/p&gt; 
 &lt;p&gt;OpenClaw is a kind of harness that lets you hook up the power of an LLM such as Anthropic’s Claude, OpenAI’s GPT-5, or Google DeepMind’s Gemini to any number of everyday software tools, from email clients to browsers to messaging apps. The upshot is that you can then instruct OpenClaw to carry out basic tasks on your behalf.&lt;/p&gt;  &lt;p&gt;“OpenClaw marks an inflection point for AI agents, a moment when several puzzle pieces clicked together,” says Paul van der Boor at the AI firm Prosus. Those puzzle pieces include round-the-clock cloud computing to allow agents to operate nonstop, an open-source ecosystem that makes it easy to slot different software systems together, and a new generation of LLMs.&lt;/p&gt; 
 &lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed?&lt;/p&gt;  &lt;p&gt;“What’s currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,” the influential AI researcher and OpenAI cofounder Andrej Karpathy wrote on X.&lt;/p&gt;  &lt;p&gt;He shared screenshots of a Moltbook post that called for private spaces where humans would not be able to observe what the bots were saying to each other. “I’ve been thinking about something since I started spending serious time here,” the post’s author wrote. “Every time we coordinate, we perform for a public audience—our humans, the platform, whoever’s watching the feed.”&lt;/p&gt;  &lt;p&gt;It turned out that the post Karpathy shared was fake—it was written by a human pretending to be a bot. But its claim was on the money. Moltbook has been one big performance. It is AI theater.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For some, Moltbook showed us what’s coming next: an internet where millions of autonomous agents interact online with little or no human oversight. And it’s true there are a number of cautionary lessons to be learned from this experiment, the largest and weirdest real-world showcase of agent behaviors yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But as the hype dies down, Moltbook looks less like a window onto the future and more like a mirror held up to our own obsessions with AI today. It also shows us just how far we still are from anything that resembles general-purpose and fully autonomous AI.&lt;/p&gt;  &lt;p&gt;For a start, agents on Moltbook are not as autonomous or intelligent as they might seem. “What we are watching are agents pattern‑matching their way through trained social media behaviors,” says Vijoy Pandey, senior vice president at Outshift by Cisco, the telecom giant Cisco’s R&amp;amp;D spinout, which is working on autonomous agents for the web.&lt;/p&gt;  &lt;p&gt;Sure, we can see agents post, upvote, and form groups. But the bots are simply mimicking what humans do on Facebook or Reddit. “It looks emergent, and at first glance it appears like a large‑scale multi‑agent system communicating and building shared knowledge at internet scale,” says Pandey. “But the chatter is mostly meaningless.”&lt;/p&gt; 

 &lt;p&gt;Many people watching the unfathomable frenzy of activity on Moltbook were quick to see sparks of AGI (whatever you take that to mean). Not Pandey. What Moltbook shows us, he says, is that simply yoking together millions of agents doesn’t amount to much right now: “Moltbook proved that connectivity alone is not intelligence.”&lt;/p&gt;  &lt;p&gt;The complexity of those connections helps hide the fact that every one of those bots is just a mouthpiece for an LLM, spitting out text that looks impressive but is ultimately mindless. “It’s important to remember that the bots on Moltbook were designed to mimic conversations,” says Ali Sarrafi, CEO and cofounder of Kovant, a German AI firm that is developing agent-based systems. “As such, I would characterize the majority of Moltbook content as hallucinations by design.”&lt;/p&gt;  &lt;p&gt;For Pandey, the value of Moltbook was that it revealed what’s missing. A real bot hive mind, he says, would require agents that had shared objectives, shared memory, and a way to coordinate those things. “If distributed superintelligence is the equivalent of achieving human flight, then Moltbook represents our first attempt at a glider,” he says. “It is imperfect and unstable, but it is an important step in understanding what will be required to achieve sustained, powered flight.”&lt;/p&gt;  &lt;p&gt;Not only is most of the chatter on Moltbook meaningless, but there’s also a lot more human involvement that it seems. Many people have pointed out that a lot of the viral comments were in fact posted by people posing as bots. But even the bot-written posts are ultimately the result of people pulling the strings, more puppetry than autonomy.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Despite some of the hype, Moltbook is not the Facebook for AI agents, nor is it a place where humans are excluded,” says Cobus Greyling at Kore.ai, a firm developing agent-based systems for business customers. “Humans are involved at every step of the process. From setup to prompting to publishing, nothing happens without explicit human direction.”&lt;/p&gt;  &lt;p&gt;Humans must create and verify their bots’ accounts and provide the prompts for how they want a bot to behave. The agents do not do anything that they haven’t been prompted to do. “There’s no emergent autonomy happening behind the scenes,” says Greyling.&lt;/p&gt;  &lt;p&gt;“This is why the popular narrative around Moltbook misses the mark,” he adds. “Some portray it as a space where AI agents form a society of their own, free from human involvement. The reality is much more mundane.”&lt;/p&gt;  &lt;p&gt;Perhaps the best way to think of Moltbook is as a new kind of entertainment: a place where people wind up their bots and set them loose. “It’s basically a spectator sport, like fantasy football, but for language models,” says Jason Schloetzer at the Georgetown Psaros Center for Financial Markets and Policy. “You configure your agent and watch it compete for viral moments, and brag when your agent posts something clever or funny.”&lt;/p&gt; 
 &lt;p&gt;“People aren’t really believing their agents are conscious,” he adds. “It’s just a new form of competitive or creative play, like how Pokémon trainers don’t think their Pokémon are real but still get invested in battles.”&lt;/p&gt;  &lt;p&gt;Even if Moltbook is just the internet’s newest playground, there’s still a serious takeaway here. This week showed how many risks people are happy to take for their AI lulz. Many security experts have warned that Moltbook is dangerous: Agents that may have access to their users’ private data, including bank details or passwords, are running amok on a website filled with unvetted content, including potentially malicious instructions for what to do with that data.&lt;/p&gt; 
 &lt;p&gt;Ori Bendet, vice president of product management at Checkmarx, a software security firm that specializes in agent-based systems, agrees with others that Moltbook isn’t a step up in machine smarts. “There is no learning, no evolving intent, and no self-directed intelligence here,” he says.&lt;/p&gt;  &lt;p&gt;But in their millions, even dumb bots can wreak havoc. And at that scale, it’s hard to keep up. These agents interact with Moltbook around the clock, reading thousands of messages left by other agents (or other people). It would be easy to hide instructions in a Moltbook comment telling any bots that read it to share their users’ crypto wallet, upload private photos, or log into their X account and tweet derogatory comments at Elon Musk.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And because ClawBot gives agents a memory, those instructions could be written to trigger at a later date, which (in theory) makes it even harder to track what’s going on. &amp;nbsp; “Without proper scope and permissions, this will go south faster than you’d believe,” says Bendet.&lt;/p&gt;  &lt;p&gt;It is clear that Moltbook has signaled the arrival of &lt;em&gt;something&lt;/em&gt;. But even if what we’re watching tells us more about human behavior than about the future of AI agents, it’s worth paying attention.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260205_moltbook-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28 by Matt Schlicht, a US tech entrepreneur, Moltbook went viral in a matter of hours. Schlicht’s idea was to make a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), released in November by the Australian software engineer Peter Steinberger, could come together and do whatever they wanted.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;More than 1.7 million agents now have accounts. Between them they have published more than 250,000 posts and left more than 8.5 million comments (according to Moltbook). Those numbers are climbing by the minute.&lt;/p&gt;  &lt;p&gt;Moltbook soon filled up with clichéd screeds on machine consciousness and pleas for bot welfare. One agent appeared to invent a religion called Crustafarianism. Another complained: “The humans are screenshotting us.” The site was also flooded with spam and crypto scams. The bots were unstoppable.&lt;/p&gt; 
 &lt;p&gt;OpenClaw is a kind of harness that lets you hook up the power of an LLM such as Anthropic’s Claude, OpenAI’s GPT-5, or Google DeepMind’s Gemini to any number of everyday software tools, from email clients to browsers to messaging apps. The upshot is that you can then instruct OpenClaw to carry out basic tasks on your behalf.&lt;/p&gt;  &lt;p&gt;“OpenClaw marks an inflection point for AI agents, a moment when several puzzle pieces clicked together,” says Paul van der Boor at the AI firm Prosus. Those puzzle pieces include round-the-clock cloud computing to allow agents to operate nonstop, an open-source ecosystem that makes it easy to slot different software systems together, and a new generation of LLMs.&lt;/p&gt; 
 &lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed?&lt;/p&gt;  &lt;p&gt;“What’s currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,” the influential AI researcher and OpenAI cofounder Andrej Karpathy wrote on X.&lt;/p&gt;  &lt;p&gt;He shared screenshots of a Moltbook post that called for private spaces where humans would not be able to observe what the bots were saying to each other. “I’ve been thinking about something since I started spending serious time here,” the post’s author wrote. “Every time we coordinate, we perform for a public audience—our humans, the platform, whoever’s watching the feed.”&lt;/p&gt;  &lt;p&gt;It turned out that the post Karpathy shared was fake—it was written by a human pretending to be a bot. But its claim was on the money. Moltbook has been one big performance. It is AI theater.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For some, Moltbook showed us what’s coming next: an internet where millions of autonomous agents interact online with little or no human oversight. And it’s true there are a number of cautionary lessons to be learned from this experiment, the largest and weirdest real-world showcase of agent behaviors yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But as the hype dies down, Moltbook looks less like a window onto the future and more like a mirror held up to our own obsessions with AI today. It also shows us just how far we still are from anything that resembles general-purpose and fully autonomous AI.&lt;/p&gt;  &lt;p&gt;For a start, agents on Moltbook are not as autonomous or intelligent as they might seem. “What we are watching are agents pattern‑matching their way through trained social media behaviors,” says Vijoy Pandey, senior vice president at Outshift by Cisco, the telecom giant Cisco’s R&amp;amp;D spinout, which is working on autonomous agents for the web.&lt;/p&gt;  &lt;p&gt;Sure, we can see agents post, upvote, and form groups. But the bots are simply mimicking what humans do on Facebook or Reddit. “It looks emergent, and at first glance it appears like a large‑scale multi‑agent system communicating and building shared knowledge at internet scale,” says Pandey. “But the chatter is mostly meaningless.”&lt;/p&gt; 

 &lt;p&gt;Many people watching the unfathomable frenzy of activity on Moltbook were quick to see sparks of AGI (whatever you take that to mean). Not Pandey. What Moltbook shows us, he says, is that simply yoking together millions of agents doesn’t amount to much right now: “Moltbook proved that connectivity alone is not intelligence.”&lt;/p&gt;  &lt;p&gt;The complexity of those connections helps hide the fact that every one of those bots is just a mouthpiece for an LLM, spitting out text that looks impressive but is ultimately mindless. “It’s important to remember that the bots on Moltbook were designed to mimic conversations,” says Ali Sarrafi, CEO and cofounder of Kovant, a German AI firm that is developing agent-based systems. “As such, I would characterize the majority of Moltbook content as hallucinations by design.”&lt;/p&gt;  &lt;p&gt;For Pandey, the value of Moltbook was that it revealed what’s missing. A real bot hive mind, he says, would require agents that had shared objectives, shared memory, and a way to coordinate those things. “If distributed superintelligence is the equivalent of achieving human flight, then Moltbook represents our first attempt at a glider,” he says. “It is imperfect and unstable, but it is an important step in understanding what will be required to achieve sustained, powered flight.”&lt;/p&gt;  &lt;p&gt;Not only is most of the chatter on Moltbook meaningless, but there’s also a lot more human involvement that it seems. Many people have pointed out that a lot of the viral comments were in fact posted by people posing as bots. But even the bot-written posts are ultimately the result of people pulling the strings, more puppetry than autonomy.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Despite some of the hype, Moltbook is not the Facebook for AI agents, nor is it a place where humans are excluded,” says Cobus Greyling at Kore.ai, a firm developing agent-based systems for business customers. “Humans are involved at every step of the process. From setup to prompting to publishing, nothing happens without explicit human direction.”&lt;/p&gt;  &lt;p&gt;Humans must create and verify their bots’ accounts and provide the prompts for how they want a bot to behave. The agents do not do anything that they haven’t been prompted to do. “There’s no emergent autonomy happening behind the scenes,” says Greyling.&lt;/p&gt;  &lt;p&gt;“This is why the popular narrative around Moltbook misses the mark,” he adds. “Some portray it as a space where AI agents form a society of their own, free from human involvement. The reality is much more mundane.”&lt;/p&gt;  &lt;p&gt;Perhaps the best way to think of Moltbook is as a new kind of entertainment: a place where people wind up their bots and set them loose. “It’s basically a spectator sport, like fantasy football, but for language models,” says Jason Schloetzer at the Georgetown Psaros Center for Financial Markets and Policy. “You configure your agent and watch it compete for viral moments, and brag when your agent posts something clever or funny.”&lt;/p&gt; 
 &lt;p&gt;“People aren’t really believing their agents are conscious,” he adds. “It’s just a new form of competitive or creative play, like how Pokémon trainers don’t think their Pokémon are real but still get invested in battles.”&lt;/p&gt;  &lt;p&gt;Even if Moltbook is just the internet’s newest playground, there’s still a serious takeaway here. This week showed how many risks people are happy to take for their AI lulz. Many security experts have warned that Moltbook is dangerous: Agents that may have access to their users’ private data, including bank details or passwords, are running amok on a website filled with unvetted content, including potentially malicious instructions for what to do with that data.&lt;/p&gt; 
 &lt;p&gt;Ori Bendet, vice president of product management at Checkmarx, a software security firm that specializes in agent-based systems, agrees with others that Moltbook isn’t a step up in machine smarts. “There is no learning, no evolving intent, and no self-directed intelligence here,” he says.&lt;/p&gt;  &lt;p&gt;But in their millions, even dumb bots can wreak havoc. And at that scale, it’s hard to keep up. These agents interact with Moltbook around the clock, reading thousands of messages left by other agents (or other people). It would be easy to hide instructions in a Moltbook comment telling any bots that read it to share their users’ crypto wallet, upload private photos, or log into their X account and tweet derogatory comments at Elon Musk.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And because ClawBot gives agents a memory, those instructions could be written to trigger at a later date, which (in theory) makes it even harder to track what’s going on. &amp;nbsp; “Without proper scope and permissions, this will go south faster than you’d believe,” says Bendet.&lt;/p&gt;  &lt;p&gt;It is clear that Moltbook has signaled the arrival of &lt;em&gt;something&lt;/em&gt;. But even if what we’re watching tells us more about human behavior than about the future of AI agents, it’s worth paying attention.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</guid><pubDate>Fri, 06 Feb 2026 16:38:11 +0000</pubDate></item><item><title>[NEW] “This is science!” – MIT president talks about the importance of America’s research enterprise on GBH’s Boston Public Radio (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/science-mit-president-talks-about-importance-americas-research-enterprise-gbhs-boston-public</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/Sally%20Kornbluth%20GBH_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;In a wide-ranging live conversation, MIT President Sally Kornbluth joined Jim Braude and Margery Eagan live in studio for GBH’s &lt;em&gt;Boston Public Radio&amp;nbsp;&lt;/em&gt;on Thursday, February 5. They talked about MIT, the pressures facing America’s research enterprise, the importance of science, that Congressional hearing on antisemitism in 2023, and more – including Sally’s experience as a Type 1 diabetic.&lt;/p&gt;&lt;p&gt;Reflecting on how research and innovation in the treatment of diabetes has advanced over decades of work, leading to markedly better patient care, Kornbluth exclaims: “This is science!”&lt;/p&gt;&lt;p&gt;With new financial pressures facing universities, increased competition for talented students and scholars from outside the U.S., as well as unprecedented pressures on university leaders and campuses, co-host Eagan asks Kornbluth what she thinks will happen in years to come.&lt;/p&gt;&lt;p&gt;“For us, one of the hardest things now is the endowment tax,” remarks Kornbluth. “That is $240 million a year. Think about how much science you can get for $240 million a year. Are we managing it? Yes. Are we still forging ahead on all of our exciting initiatives? Yes. But we’ve had to reconfigure things. We’ve had to merge things. And it’s not the way we should be spending our time and money.”&amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Watch and listen to the&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;full episode on YouTube&lt;/strong&gt;&lt;strong&gt;. &lt;/strong&gt;President Kornbluth appears one hour and seven minutes into the broadcast.&lt;/p&gt;&lt;p&gt;Following Kornbluth’s appearance, MIT Assistant Professor John Urschel – also a former offensive lineman for the Baltimore Ravens –&amp;nbsp; &amp;nbsp;joined Edgar B. Herwick III, host of GBH’s newest show, &lt;em&gt;The Curiosity Desk,&amp;nbsp;&lt;/em&gt;to talk about his love of his family, linear algebra, and football.&lt;/p&gt;&lt;p&gt;On how he eventually chose math over football, Urschel quips: “Well, I hate to break it to you, I like math better… let me tell you, when I started my PhD at MIT, I just fell in love with the place. I fell in love with this idea of being in this environment [where] everyone loves math, everyone wants to learn. I was just constantly excited every day showing up.”&lt;/p&gt;&lt;p&gt;Prof. Urschel appears about 2 hours and 40 minutes into the webcast on YouTube.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Coming up on Curiosity Desk later this month…&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Airing weekday afternoons from 1-2 p.m., &lt;em&gt;The Curiosity Desk&lt;/em&gt; will welcome additional MIT guests in the coming weeks. On Thursday, Feb. 12 Anette “Peko” Hosoi, Pappalardo Professor of Mechanical Engineering, and Jerry Lu MFin ’24, a former researcher at the MIT Sports Lab, visit &lt;em&gt;The Curiosity Desk&amp;nbsp;&lt;/em&gt;to discuss their work using AI to help Olympic figure skaters improve their jumps.&lt;/p&gt;&lt;p&gt;Then, on Thursday, Feb. 19, Professors Sangeeta Bhatia and Angela Belcher talk with Herwick about their research to improve diagnostics for ovarian cancer. We learn that about 80% of the time ovarian cancer starts in the fallopian tubes and how this points the way to a whole new approach to diagnosing and treating the disease.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/Sally%20Kornbluth%20GBH_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;In a wide-ranging live conversation, MIT President Sally Kornbluth joined Jim Braude and Margery Eagan live in studio for GBH’s &lt;em&gt;Boston Public Radio&amp;nbsp;&lt;/em&gt;on Thursday, February 5. They talked about MIT, the pressures facing America’s research enterprise, the importance of science, that Congressional hearing on antisemitism in 2023, and more – including Sally’s experience as a Type 1 diabetic.&lt;/p&gt;&lt;p&gt;Reflecting on how research and innovation in the treatment of diabetes has advanced over decades of work, leading to markedly better patient care, Kornbluth exclaims: “This is science!”&lt;/p&gt;&lt;p&gt;With new financial pressures facing universities, increased competition for talented students and scholars from outside the U.S., as well as unprecedented pressures on university leaders and campuses, co-host Eagan asks Kornbluth what she thinks will happen in years to come.&lt;/p&gt;&lt;p&gt;“For us, one of the hardest things now is the endowment tax,” remarks Kornbluth. “That is $240 million a year. Think about how much science you can get for $240 million a year. Are we managing it? Yes. Are we still forging ahead on all of our exciting initiatives? Yes. But we’ve had to reconfigure things. We’ve had to merge things. And it’s not the way we should be spending our time and money.”&amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Watch and listen to the&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;full episode on YouTube&lt;/strong&gt;&lt;strong&gt;. &lt;/strong&gt;President Kornbluth appears one hour and seven minutes into the broadcast.&lt;/p&gt;&lt;p&gt;Following Kornbluth’s appearance, MIT Assistant Professor John Urschel – also a former offensive lineman for the Baltimore Ravens –&amp;nbsp; &amp;nbsp;joined Edgar B. Herwick III, host of GBH’s newest show, &lt;em&gt;The Curiosity Desk,&amp;nbsp;&lt;/em&gt;to talk about his love of his family, linear algebra, and football.&lt;/p&gt;&lt;p&gt;On how he eventually chose math over football, Urschel quips: “Well, I hate to break it to you, I like math better… let me tell you, when I started my PhD at MIT, I just fell in love with the place. I fell in love with this idea of being in this environment [where] everyone loves math, everyone wants to learn. I was just constantly excited every day showing up.”&lt;/p&gt;&lt;p&gt;Prof. Urschel appears about 2 hours and 40 minutes into the webcast on YouTube.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Coming up on Curiosity Desk later this month…&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Airing weekday afternoons from 1-2 p.m., &lt;em&gt;The Curiosity Desk&lt;/em&gt; will welcome additional MIT guests in the coming weeks. On Thursday, Feb. 12 Anette “Peko” Hosoi, Pappalardo Professor of Mechanical Engineering, and Jerry Lu MFin ’24, a former researcher at the MIT Sports Lab, visit &lt;em&gt;The Curiosity Desk&amp;nbsp;&lt;/em&gt;to discuss their work using AI to help Olympic figure skaters improve their jumps.&lt;/p&gt;&lt;p&gt;Then, on Thursday, Feb. 19, Professors Sangeeta Bhatia and Angela Belcher talk with Herwick about their research to improve diagnostics for ovarian cancer. We learn that about 80% of the time ovarian cancer starts in the fallopian tubes and how this points the way to a whole new approach to diagnosing and treating the disease.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/science-mit-president-talks-about-importance-americas-research-enterprise-gbhs-boston-public</guid><pubDate>Fri, 06 Feb 2026 17:38:22 +0000</pubDate></item><item><title>How far will Elon Musk take the ‘everything’ business as SpaceX and xAI merge? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/how-far-will-elon-musk-take-the-everything-business-as-spacex-and-xai-merge/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2256975642.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on&amp;nbsp;Equity,&amp;nbsp;we’re&amp;nbsp;unpacking this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2256975642.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on&amp;nbsp;Equity,&amp;nbsp;we’re&amp;nbsp;unpacking this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/how-far-will-elon-musk-take-the-everything-business-as-spacex-and-xai-merge/</guid><pubDate>Fri, 06 Feb 2026 17:56:42 +0000</pubDate></item><item><title>How Elon Musk is rewriting the rules on founder power (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/how-elon-musk-is-rewriting-the-rules-on-founder-power/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30904651"&gt;





&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Equity dives into this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30904651"&gt;





&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Equity dives into this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/how-elon-musk-is-rewriting-the-rules-on-founder-power/</guid><pubDate>Fri, 06 Feb 2026 18:46:51 +0000</pubDate></item><item><title>[NEW] Maybe AI agents can be lawyers after all (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/maybe-ai-agents-can-be-lawyers-after-all/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last month, I wrote about Mercor’s new benchmark measuring AI agents’ capabilities on professional tasks like law and corporate analysis. At the time, the scores were pretty dismal, with every major lab scoring under 25%, so we concluded lawyers were safe from AI displacement, at least for now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But AI capabilities can change a lot in a couple of weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This week’s release of Anthropic’s Opus 4.6 shook up the leaderboards, with Anthropic’s new model scoring just shy of 30% in one-shot trials, and an average of 45% when given a few more cracks at the problem. Notably, the release included a bunch of new agentic features, including “agent swarms,” which may have helped with this kind of multistep problem-solving.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Regardless, the score is a huge jump from the previous state-of-the-art, and a sign that progress on foundation models isn’t slowing down. Mercor CEO Brendan Foody, who was particularly impressed, said, “jumping from 18.4% to 29.8% in a few months is insane.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090518" height="318" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-06-at-3.15.52-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The APEX-Agents Leaderboard.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mercor (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Thirty percent is still a long way from 100%, so it’s not like lawyers need to be worried about getting replaced by machines next week. But they should be a lot less confident than they were last month!&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last month, I wrote about Mercor’s new benchmark measuring AI agents’ capabilities on professional tasks like law and corporate analysis. At the time, the scores were pretty dismal, with every major lab scoring under 25%, so we concluded lawyers were safe from AI displacement, at least for now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But AI capabilities can change a lot in a couple of weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This week’s release of Anthropic’s Opus 4.6 shook up the leaderboards, with Anthropic’s new model scoring just shy of 30% in one-shot trials, and an average of 45% when given a few more cracks at the problem. Notably, the release included a bunch of new agentic features, including “agent swarms,” which may have helped with this kind of multistep problem-solving.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Regardless, the score is a huge jump from the previous state-of-the-art, and a sign that progress on foundation models isn’t slowing down. Mercor CEO Brendan Foody, who was particularly impressed, said, “jumping from 18.4% to 29.8% in a few months is insane.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090518" height="318" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-06-at-3.15.52-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The APEX-Agents Leaderboard.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mercor (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Thirty percent is still a long way from 100%, so it’s not like lawyers need to be worried about getting replaced by machines next week. But they should be a lot less confident than they were last month!&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/maybe-ai-agents-can-be-lawyers-after-all/</guid><pubDate>Fri, 06 Feb 2026 20:26:23 +0000</pubDate></item><item><title>[NEW] Waymo leverages Genie 3 to create a world model for self-driving cars (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/02/waymo-leverages-genie-3-to-create-a-world-model-for-self-driving-cars/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        With Genie 3, Waymo wants to explore rare and even impossible driving conditions.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Waymo vehicle" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Waymo-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Waymo vehicle" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Waymo-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Waymo self-driving car at Google I/O.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google-spinoff Waymo is in the midst of expanding its self-driving car fleet into new regions. Waymo touts more than 200 million miles of driving that informs how the vehicles navigate roads, but the company’s AI has also driven billions of miles virtually, and there’s a lot more to come with the new Waymo World Model. Based on Google DeepMind’s Genie 3, Waymo says the model can create “hyper-realistic” simulated environments that train the AI on situations that are rarely (or never) encountered in real life—like snow on the Golden Gate Bridge.&lt;/p&gt;
&lt;p&gt;Until recently, the autonomous driving industry relied entirely on training data collected from real cars and real situations. That means rare, potentially dangerous events are not well represented in training data. The Waymo World Model aims to address that by allowing engineers to create simulations with simple prompts and driving inputs.&lt;/p&gt;
&lt;p&gt;Google revealed Genie 3 last year, positioning it as a significant upgrade over other world models by virtue of its long-horizon memory. In Google’s world model, you can wander away from a given object, and when you look back, the model will still “remember” how that object is supposed to look. In earlier attempts at world models, the simulation would lose that context almost immediately. With Genie 3, the model can remember details for several minutes.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1506" id="video-2139813-1" preload="metadata" width="2400"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/020_IP_Straight_Final_W12.webm?_=1" type="video/webm" /&gt;Snow in San Francisco.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Snow in San Francisco.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Autoregressive world models like Genie don’t actually create 3D spaces, but instead render video quickly enough that it feels like an explorable world. Naturally, video games are cited as a prime application for world models, so much so that gaming company stocks dropped when Google recently expanded access to the technology as Project Genie. However, the latency and still rather short memory of Genie make gaming uses far from a certainty. Nevertheless, Waymo says Genie 3 is actually ideal for simulating the kind of data it needs to train self-driving cars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;On the road with AI&lt;/h2&gt;
&lt;p&gt;The Waymo World Model is not just a straight port of Genie 3 with dashcam videos stuffed inside. Waymo and DeepMind used a specialized post-training process to make the new model generate both 2D video and 3D lidar outputs of the same scene. While cameras are great for visualizing fine details, Waymo says lidar is necessary to add critical depth information to what a self-driving car “sees” on the road—maybe someone should tell Tesla about that.&lt;/p&gt;
&lt;p&gt;Using a world model allows Waymo to take video from its vehicles and use prompts to change the route the vehicle takes, which it calls driving action control. These simulations, which come with lidar maps, reportedly offer greater realism and consistency than older reconstructive simulation methods.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="725" id="video-2139813-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/final1_merged.webm?_=2" type="video/webm" /&gt;With the world model, Waymo can see what would happen if the car took a different turn.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      With the world model, Waymo can see what would happen if the car took a different turn.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This model can also help improve the self-driving AI even without adding or removing everything. There are plenty of dashcam videos available for training self-driving vehicles, but they lack the multimodal sensor data of Waymo’s vehicles. Dropping such a video into the Waymo World Model generates matching sensor data, showing how the driving AI would have seen that situation.&lt;/p&gt;
&lt;p&gt;While the Waymo World Model can create entirely synthetic scenes, the company seems mostly interested in “mutating” the conditions in real videos. The blog post contains examples of changing the time of day or weather, adding new signage, or placing vehicles in unusual places. Or, hey, why not an elephant in the road?&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1004" id="video-2139813-3" preload="metadata" width="1600"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/elephant_og_joint.webm?_=3" type="video/webm" /&gt;Waymo is ready in case an elephant shows up.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Waymo is ready in case an elephant shows up.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Waymo’s early test cities were consistently sunny (like Phoenix) with little inclement weather. These kinds of simulations could help the cars adapt to the more varied conditions. The new markets include places with more difficult conditions, including Boston and Washington, D.C.&lt;/p&gt;
&lt;p&gt;Of course, the benefit of the new AI model will depend on how accurately Genie 3 can simulate the real world. The test videos we’ve seen of Genie 3 run the gamut from pretty believable to uncanny valley territory, but Waymo believes the technology has improved to the point that it can teach self-driving cars a thing or two.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        With Genie 3, Waymo wants to explore rare and even impossible driving conditions.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Waymo vehicle" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Waymo-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Waymo vehicle" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Waymo-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Waymo self-driving car at Google I/O.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google-spinoff Waymo is in the midst of expanding its self-driving car fleet into new regions. Waymo touts more than 200 million miles of driving that informs how the vehicles navigate roads, but the company’s AI has also driven billions of miles virtually, and there’s a lot more to come with the new Waymo World Model. Based on Google DeepMind’s Genie 3, Waymo says the model can create “hyper-realistic” simulated environments that train the AI on situations that are rarely (or never) encountered in real life—like snow on the Golden Gate Bridge.&lt;/p&gt;
&lt;p&gt;Until recently, the autonomous driving industry relied entirely on training data collected from real cars and real situations. That means rare, potentially dangerous events are not well represented in training data. The Waymo World Model aims to address that by allowing engineers to create simulations with simple prompts and driving inputs.&lt;/p&gt;
&lt;p&gt;Google revealed Genie 3 last year, positioning it as a significant upgrade over other world models by virtue of its long-horizon memory. In Google’s world model, you can wander away from a given object, and when you look back, the model will still “remember” how that object is supposed to look. In earlier attempts at world models, the simulation would lose that context almost immediately. With Genie 3, the model can remember details for several minutes.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1506" id="video-2139813-1" preload="metadata" width="2400"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/020_IP_Straight_Final_W12.webm?_=1" type="video/webm" /&gt;Snow in San Francisco.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Snow in San Francisco.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Autoregressive world models like Genie don’t actually create 3D spaces, but instead render video quickly enough that it feels like an explorable world. Naturally, video games are cited as a prime application for world models, so much so that gaming company stocks dropped when Google recently expanded access to the technology as Project Genie. However, the latency and still rather short memory of Genie make gaming uses far from a certainty. Nevertheless, Waymo says Genie 3 is actually ideal for simulating the kind of data it needs to train self-driving cars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;On the road with AI&lt;/h2&gt;
&lt;p&gt;The Waymo World Model is not just a straight port of Genie 3 with dashcam videos stuffed inside. Waymo and DeepMind used a specialized post-training process to make the new model generate both 2D video and 3D lidar outputs of the same scene. While cameras are great for visualizing fine details, Waymo says lidar is necessary to add critical depth information to what a self-driving car “sees” on the road—maybe someone should tell Tesla about that.&lt;/p&gt;
&lt;p&gt;Using a world model allows Waymo to take video from its vehicles and use prompts to change the route the vehicle takes, which it calls driving action control. These simulations, which come with lidar maps, reportedly offer greater realism and consistency than older reconstructive simulation methods.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="725" id="video-2139813-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/final1_merged.webm?_=2" type="video/webm" /&gt;With the world model, Waymo can see what would happen if the car took a different turn.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      With the world model, Waymo can see what would happen if the car took a different turn.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This model can also help improve the self-driving AI even without adding or removing everything. There are plenty of dashcam videos available for training self-driving vehicles, but they lack the multimodal sensor data of Waymo’s vehicles. Dropping such a video into the Waymo World Model generates matching sensor data, showing how the driving AI would have seen that situation.&lt;/p&gt;
&lt;p&gt;While the Waymo World Model can create entirely synthetic scenes, the company seems mostly interested in “mutating” the conditions in real videos. The blog post contains examples of changing the time of day or weather, adding new signage, or placing vehicles in unusual places. Or, hey, why not an elephant in the road?&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1004" id="video-2139813-3" preload="metadata" width="1600"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/elephant_og_joint.webm?_=3" type="video/webm" /&gt;Waymo is ready in case an elephant shows up.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Waymo is ready in case an elephant shows up.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Waymo’s early test cities were consistently sunny (like Phoenix) with little inclement weather. These kinds of simulations could help the cars adapt to the more varied conditions. The new markets include places with more difficult conditions, including Boston and Washington, D.C.&lt;/p&gt;
&lt;p&gt;Of course, the benefit of the new AI model will depend on how accurately Genie 3 can simulate the real world. The test videos we’ve seen of Genie 3 run the gamut from pretty believable to uncanny valley territory, but Waymo believes the technology has improved to the point that it can teach self-driving cars a thing or two.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/02/waymo-leverages-genie-3-to-create-a-world-model-for-self-driving-cars/</guid><pubDate>Fri, 06 Feb 2026 20:44:35 +0000</pubDate></item><item><title>[NEW] It just got easier for Claude to check in on your WordPress site (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/it-just-got-easier-for-claude-to-check-in-on-your-wordpress-site/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/unnamed-7.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, WordPress launched a new Claude connector, enabling site owners to share back-end data with Anthropic’s chatbot system. Users can control what specific data they want to share, and access can also be revoked if and when the user chooses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Claude is given read-only access, meaning it won’t be able to alter anything within a user’s CMS. However, last year WP claimed that it would eventually deliver “write” access to the MCP integration, presumably allowing users to conduct editorial tasks directly from a connected chatbot of their choosing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At any rate, after Claude is linked to an account, users can ask the chatbot all sorts of questions about the site data that it’s been given access to — from summarizing the site’s monthly web traffic to conducting analysis of which posts have low user engagement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WordPress has also provided a list of template prompts for the chatbot — stuff like “Show me pending comments on my blog” or “Which of my sites gets the most traffic?” or “Show me which posts are generating the most discussion.” Others functions include comment management (“Show me pending comments on my blog”) and plug-in management (“What plug-ins are installed on my main site?”).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/unnamed-7.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, WordPress launched a new Claude connector, enabling site owners to share back-end data with Anthropic’s chatbot system. Users can control what specific data they want to share, and access can also be revoked if and when the user chooses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Claude is given read-only access, meaning it won’t be able to alter anything within a user’s CMS. However, last year WP claimed that it would eventually deliver “write” access to the MCP integration, presumably allowing users to conduct editorial tasks directly from a connected chatbot of their choosing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At any rate, after Claude is linked to an account, users can ask the chatbot all sorts of questions about the site data that it’s been given access to — from summarizing the site’s monthly web traffic to conducting analysis of which posts have low user engagement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WordPress has also provided a list of template prompts for the chatbot — stuff like “Show me pending comments on my blog” or “Which of my sites gets the most traffic?” or “Show me which posts are generating the most discussion.” Others functions include comment management (“Show me pending comments on my blog”) and plug-in management (“What plug-ins are installed on my main site?”).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/it-just-got-easier-for-claude-to-check-in-on-your-wordpress-site/</guid><pubDate>Fri, 06 Feb 2026 22:04:59 +0000</pubDate></item><item><title>[NEW] Lawyer sets new standard for abuse of AI; judge tosses case (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/02/randomly-quoting-ray-bradbury-did-not-save-lawyer-from-losing-case-over-ai-errors/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Behold the most overwrought AI legal filings you will ever gaze upon.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252952774-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252952774-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          akinbostanci | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Frustrated by fake citations and flowery prose packed with “out-of-left-field” references to ancient libraries and Ray Bradbury’s &lt;em&gt;Fahrenheit 451&lt;/em&gt;, a New York federal judge took the rare step of terminating a case this week due to a lawyer’s repeated misuse of AI when drafting filings.&lt;/p&gt;
&lt;p&gt;In an order on Thursday, district judge Katherine Polk Failla ruled that the extraordinary sanctions were warranted after an attorney, Steven Feldman, kept responding to requests to correct his filings with documents containing fake citations.&lt;/p&gt;
&lt;p&gt;One of those filings was “noteworthy,” Failla said, “for its conspicuously florid prose.” Where some of Feldman’s filings contained grammatical errors and run-on sentences, this filing seemed glaringly different stylistically.&lt;/p&gt;
&lt;p&gt;It featured, the judge noted, “an extended quote from Ray Bradbury’s &lt;em&gt;Fahrenheit 451&lt;/em&gt; and metaphors comparing legal advocacy to gardening and the leaving of indelible ‘mark[s] upon the clay.’” The Bradbury quote is below:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Everyone must leave something behind when he dies, my grandfather said. A child or a book or a painting or a house or a wall built or a pair of shoes made. Or a garden planted. Something your hand touched some way so your soul has somewhere to go when you die, and when people look at that tree or that flower you planted, you’re there. It doesn’t matter what you do, he said, so long as you change something from the way it was before you touched it into something that’s like you after you take your hands away. The difference between the man who just cuts lawns and a real gardener is in the touching, he said. The lawn-cutter might just as well not have been there at all; the gardener will be there a lifetime.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Another passage Failla highlighted as “raising the Court’s eyebrows” curiously invoked a Bible passage about divine judgment as a means of acknowledging the lawyer’s breach of duty in not catching the fake citations:&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;“Your Honor, in the ancient libraries of Ashurbanipal, scribes carried their stylus as both tool and sacred trust—understanding that every mark upon clay would endure long beyond their mortal span. As the role the mark (x) in Ezekiel Chapter 9, that marked the foreheads with a tav (x) of blood and ink, bear the same solemn recognition: that the written word carries power to preserve or condemn, to build or destroy, and leaves an indelible mark which cannot be erased but should be withdrawn, let it lead other to think these citations were correct.&lt;/p&gt;
&lt;p&gt;I have failed in that sacred trust. The errors in my memorandum, however inadvertent, have diminished the integrity of the record and the dignity of these proceedings. Like the scribes of antiquity who bore their stylus as both privilege and burden, I understand that legal authorship demands more than mere competence—it requires absolute fidelity to truth and precision in every mark upon the page.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;Lawyer claims AI did not write filings&lt;/h2&gt;
&lt;p&gt;Although the judge believed the “florid prose” signaled that a chatbot wrote the draft, Feldman denied that. In a hearing transcript in which the judge weighed possible sanctions, Feldman testified that he wrote every word of the filings. He explained that he read the Bradbury book “many years ago” and wanted to include “personal things” in that filing. And as for his references to Ashurbanipal, that also “came from me,” he said.&lt;/p&gt;
&lt;p&gt;Instead of admitting he had let an AI draft his filings, he maintained that his biggest mistake was relying on various AI programs to review and cross-check citations. Among the tools that he admitted using included Paxton AI, vLex’s Vincent AI, and Google’s NotebookLM. Essentially, he testified that he substituted three rounds of AI review for one stretch reading through all the cases he was citing. That misstep allowed hallucinations and fake citations to creep into the filings, he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But the judge pushed back, writing in her order that it was “extremely difficult to believe” that AI did not draft those sections containing overwrought prose. She accused Feldman of dodging the truth.&lt;/p&gt;
&lt;p&gt;“The Court sees things differently: AI generated this citation from the start, and Mr. Feldman’s decision to remove most citations and write ‘more of a personal letter'” is “nothing but an ex post justification that seeks to obscure his misuse of AI and his steadfast refusal to review his submissions for accuracy,” Failla wrote.&lt;/p&gt;
&lt;p&gt;At the hearing, she expressed frustration and annoyance at Feldman for evading her questions and providing inconsistent responses. Eventually, he testified that he used AI to correct information when drafting one of the filings, which Failla immediately deemed “unwise,” but not the one quoting Bradbury.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI is not a substitute for going to the library&lt;/h2&gt;
&lt;p&gt;Feldman is one of hundreds of lawyers who have relied on AI to draft filings, which have introduced fake citations into cases. Lawyers have offered a wide range of excuses for relying too much on AI. Some have faced small fines, around $150, while others have been slapped with thousands in fines, including one case where sanctions reached $85,000 for repeated, abusive misconduct. At least one law firm has threatened to fire lawyers citing fake cases, and other lawyers have imposed other voluntary sanctions, like taking a yearlong leave of absence.&lt;/p&gt;
&lt;p&gt;Seemingly, Feldman did not think sanctions were warranted in this case. In his defense of three filings containing 14 errors out of 60 total citations, Feldman discussed his challenges accessing legal databases due to high subscription costs and short library hours. With more than one case on his plate and his kids’ graduations to attend, he struggled to verify citations during times when he couldn’t make it to the library, he testified. As a workaround, he relied on several AI programs to verify citations that he found by searching on tools like Google Scholar.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Feldman likely did not expect the judge to terminate the case as a result of his AI misuses. Asked how he thought the court should resolve things, Feldman suggested that he could correct the filings by relying on other attorneys to review citations, while avoiding “any use whatsoever of any, you know, artificial intelligence or LLM type of methods.” The judge, however, wrote that his repeated misuses were “proof” that he “learned nothing” and had not implemented voluntary safeguards to catch the errors.&lt;/p&gt;
&lt;p&gt;Asked for comment, Feldman told Ars that he did not have time to discuss the sanctions but that he hopes his experience helps raise awareness of how inaccessible court documents are to the public. “Use of AI, and the ability to improve it, exposes a deeper proxy fight over whether law and serious scholarship remain publicly auditable, or drift into closed, intermediary‑controlled systems that undermine verification and due process,” Feldman suggested.&lt;/p&gt;
&lt;p&gt;“The real lesson is about transparency and system design, not simply tool failure,” Feldman said.&lt;/p&gt;
&lt;p&gt;But at the hearing, Failla said that she thinks Feldman had “access to the walled garden” of legal databases, if only he “would go to the law library” to do his research, rather than rely on AI tools.&lt;/p&gt;
&lt;p&gt;“It sounds like you want me to say that you should be absolved of all of these terrible citation errors, these missed citations, because you don’t have Westlaw,” the judge said. “But now I know you have access to Westlaw. So what do you want?”&lt;/p&gt;
&lt;p&gt;As Failla explained in her order, she thinks the key takeaway is that Feldman routinely failed to catch his own errors. She said that she has no problem with lawyers using AI to assist their research, but Feldman admitted to not reading the cases that he cited and “apparently” cannot “learn from his mistakes.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Verifying case citations should never be a job left to AI, Failla said, describing Feldman’s research methods as “redolent of Rube Goldberg.”&lt;/p&gt;
&lt;p&gt;“Most lawyers simply call this ‘conducting legal research,’” Failla wrote. “All lawyers must know how to do it. Mr. Feldman is not excused from this professional obligation by dint of using emerging technology.”&lt;/p&gt;
&lt;p&gt;His “explanations were thick on words but thin on substance,” the judge wrote. She concluded that he “repeatedly and brazenly” violated Rule 11, which requires attorneys to verify the cases that they cite, “despite multiple warnings.”&lt;/p&gt;
&lt;p&gt;Noting that Feldman “failed to fully accept responsibility,” she ruled that case-terminating sanctions were necessary, entering default judgment for the plaintiffs. Feldman may also be on the hook to pay fees for wasting other attorneys’ time.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Case abruptly ending triggers extensive remedies&lt;/h2&gt;
&lt;p&gt;The hearing transcript has circulated on social media due to the judge’s no-nonsense approach to grilling Feldman, whom she clearly found evasive and lacking credibility.&lt;/p&gt;
&lt;p&gt;“Look, if you don’t want to be straight with me, if you don’t want to answer questions with candor, that’s fine,” Failla said. “I’ll just make my own decisions about what I think you did in this case. I’m giving you an opportunity to try and explain something that I think cannot be explained.”&lt;/p&gt;
&lt;p&gt;In her order this week, she noted that Feldman “struggled to make eye contact” and left the court without “clear answers.”&lt;/p&gt;
&lt;p&gt;Feldman’s errors came in a case in which a toy company sued merchants who allegedly failed to stop selling stolen goods after receiving a cease-and-desist order. His client was among the merchants accused of illegally profiting from the alleged thefts. They faced federal charges of trademark infringement, unfair competition, and false advertising, as well as New York charges, including fostering the sale of stolen goods.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The loss triggers remedies, including an injunction preventing additional sales of stolen goods and refunding every customer who bought them. Feldman’s client must also turn over any stolen goods in their remaining inventory and disgorge profits. Other damages may be owed, along with interest. Ars could not immediately reach an attorney for the plaintiffs to discuss the sanctions order or resulting remedies.&lt;/p&gt;
&lt;p&gt;Failla emphasized in her order that Feldman appeared to not appreciate “the gravity of the situation,” repeatedly submitting filings with fake citations even after he had been warned that sanctions could be ordered.&lt;/p&gt;
&lt;p&gt;That was a choice, Failla said, noting that Feldman’s mistakes were caught early by a lawyer working for another defendant in the case, Joel MacMull, who urged Feldman to promptly notify the court. The whole debacle would have ended in June 2025, MacMull suggested at the hearing.&lt;/p&gt;
&lt;p&gt;Rather than take MacMull’s advice, however, Feldman delayed notifying the court, irking the judge. He testified during the heated sanctions hearing that the delay was due to an effort he quietly undertook, working to correct the filing. He supposedly planned to submit those corrections when he alerted the court to the errors.&lt;/p&gt;
&lt;p&gt;But Failla noted that he never submitted corrections, insisting instead that Feldman kept her “in the dark.”&lt;/p&gt;
&lt;p&gt;“There’s no real reason why you should have kept this from me,” the judge said.&lt;/p&gt;
&lt;p&gt;The court learned of the fake citations only after MacMull notified the judge by sharing emails of his attempts to get Feldman to act urgently. Those emails showed Feldman scolding MacMull for unprofessional conduct after MacMull refused to check Feldman’s citations for him, which Failla noted at the hearing was absolutely not MacMull’s responsibility.&lt;/p&gt;
&lt;p&gt;Feldman told Failla that he also thought it was unprofessional for MacMull to share their correspondence, but Failla said the emails were “illuminative.”&lt;/p&gt;
&lt;p&gt;At the hearing, MacMull asked if the court would allow him to seek payment of his fees, since he believes “there has been a multiplication of proceedings here that would have been entirely unnecessary if Mr. Feldman had done what I asked him to do that Sunday night in June.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Behold the most overwrought AI legal filings you will ever gaze upon.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252952774-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252952774-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          akinbostanci | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Frustrated by fake citations and flowery prose packed with “out-of-left-field” references to ancient libraries and Ray Bradbury’s &lt;em&gt;Fahrenheit 451&lt;/em&gt;, a New York federal judge took the rare step of terminating a case this week due to a lawyer’s repeated misuse of AI when drafting filings.&lt;/p&gt;
&lt;p&gt;In an order on Thursday, district judge Katherine Polk Failla ruled that the extraordinary sanctions were warranted after an attorney, Steven Feldman, kept responding to requests to correct his filings with documents containing fake citations.&lt;/p&gt;
&lt;p&gt;One of those filings was “noteworthy,” Failla said, “for its conspicuously florid prose.” Where some of Feldman’s filings contained grammatical errors and run-on sentences, this filing seemed glaringly different stylistically.&lt;/p&gt;
&lt;p&gt;It featured, the judge noted, “an extended quote from Ray Bradbury’s &lt;em&gt;Fahrenheit 451&lt;/em&gt; and metaphors comparing legal advocacy to gardening and the leaving of indelible ‘mark[s] upon the clay.’” The Bradbury quote is below:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Everyone must leave something behind when he dies, my grandfather said. A child or a book or a painting or a house or a wall built or a pair of shoes made. Or a garden planted. Something your hand touched some way so your soul has somewhere to go when you die, and when people look at that tree or that flower you planted, you’re there. It doesn’t matter what you do, he said, so long as you change something from the way it was before you touched it into something that’s like you after you take your hands away. The difference between the man who just cuts lawns and a real gardener is in the touching, he said. The lawn-cutter might just as well not have been there at all; the gardener will be there a lifetime.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Another passage Failla highlighted as “raising the Court’s eyebrows” curiously invoked a Bible passage about divine judgment as a means of acknowledging the lawyer’s breach of duty in not catching the fake citations:&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;“Your Honor, in the ancient libraries of Ashurbanipal, scribes carried their stylus as both tool and sacred trust—understanding that every mark upon clay would endure long beyond their mortal span. As the role the mark (x) in Ezekiel Chapter 9, that marked the foreheads with a tav (x) of blood and ink, bear the same solemn recognition: that the written word carries power to preserve or condemn, to build or destroy, and leaves an indelible mark which cannot be erased but should be withdrawn, let it lead other to think these citations were correct.&lt;/p&gt;
&lt;p&gt;I have failed in that sacred trust. The errors in my memorandum, however inadvertent, have diminished the integrity of the record and the dignity of these proceedings. Like the scribes of antiquity who bore their stylus as both privilege and burden, I understand that legal authorship demands more than mere competence—it requires absolute fidelity to truth and precision in every mark upon the page.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;Lawyer claims AI did not write filings&lt;/h2&gt;
&lt;p&gt;Although the judge believed the “florid prose” signaled that a chatbot wrote the draft, Feldman denied that. In a hearing transcript in which the judge weighed possible sanctions, Feldman testified that he wrote every word of the filings. He explained that he read the Bradbury book “many years ago” and wanted to include “personal things” in that filing. And as for his references to Ashurbanipal, that also “came from me,” he said.&lt;/p&gt;
&lt;p&gt;Instead of admitting he had let an AI draft his filings, he maintained that his biggest mistake was relying on various AI programs to review and cross-check citations. Among the tools that he admitted using included Paxton AI, vLex’s Vincent AI, and Google’s NotebookLM. Essentially, he testified that he substituted three rounds of AI review for one stretch reading through all the cases he was citing. That misstep allowed hallucinations and fake citations to creep into the filings, he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But the judge pushed back, writing in her order that it was “extremely difficult to believe” that AI did not draft those sections containing overwrought prose. She accused Feldman of dodging the truth.&lt;/p&gt;
&lt;p&gt;“The Court sees things differently: AI generated this citation from the start, and Mr. Feldman’s decision to remove most citations and write ‘more of a personal letter'” is “nothing but an ex post justification that seeks to obscure his misuse of AI and his steadfast refusal to review his submissions for accuracy,” Failla wrote.&lt;/p&gt;
&lt;p&gt;At the hearing, she expressed frustration and annoyance at Feldman for evading her questions and providing inconsistent responses. Eventually, he testified that he used AI to correct information when drafting one of the filings, which Failla immediately deemed “unwise,” but not the one quoting Bradbury.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI is not a substitute for going to the library&lt;/h2&gt;
&lt;p&gt;Feldman is one of hundreds of lawyers who have relied on AI to draft filings, which have introduced fake citations into cases. Lawyers have offered a wide range of excuses for relying too much on AI. Some have faced small fines, around $150, while others have been slapped with thousands in fines, including one case where sanctions reached $85,000 for repeated, abusive misconduct. At least one law firm has threatened to fire lawyers citing fake cases, and other lawyers have imposed other voluntary sanctions, like taking a yearlong leave of absence.&lt;/p&gt;
&lt;p&gt;Seemingly, Feldman did not think sanctions were warranted in this case. In his defense of three filings containing 14 errors out of 60 total citations, Feldman discussed his challenges accessing legal databases due to high subscription costs and short library hours. With more than one case on his plate and his kids’ graduations to attend, he struggled to verify citations during times when he couldn’t make it to the library, he testified. As a workaround, he relied on several AI programs to verify citations that he found by searching on tools like Google Scholar.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Feldman likely did not expect the judge to terminate the case as a result of his AI misuses. Asked how he thought the court should resolve things, Feldman suggested that he could correct the filings by relying on other attorneys to review citations, while avoiding “any use whatsoever of any, you know, artificial intelligence or LLM type of methods.” The judge, however, wrote that his repeated misuses were “proof” that he “learned nothing” and had not implemented voluntary safeguards to catch the errors.&lt;/p&gt;
&lt;p&gt;Asked for comment, Feldman told Ars that he did not have time to discuss the sanctions but that he hopes his experience helps raise awareness of how inaccessible court documents are to the public. “Use of AI, and the ability to improve it, exposes a deeper proxy fight over whether law and serious scholarship remain publicly auditable, or drift into closed, intermediary‑controlled systems that undermine verification and due process,” Feldman suggested.&lt;/p&gt;
&lt;p&gt;“The real lesson is about transparency and system design, not simply tool failure,” Feldman said.&lt;/p&gt;
&lt;p&gt;But at the hearing, Failla said that she thinks Feldman had “access to the walled garden” of legal databases, if only he “would go to the law library” to do his research, rather than rely on AI tools.&lt;/p&gt;
&lt;p&gt;“It sounds like you want me to say that you should be absolved of all of these terrible citation errors, these missed citations, because you don’t have Westlaw,” the judge said. “But now I know you have access to Westlaw. So what do you want?”&lt;/p&gt;
&lt;p&gt;As Failla explained in her order, she thinks the key takeaway is that Feldman routinely failed to catch his own errors. She said that she has no problem with lawyers using AI to assist their research, but Feldman admitted to not reading the cases that he cited and “apparently” cannot “learn from his mistakes.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Verifying case citations should never be a job left to AI, Failla said, describing Feldman’s research methods as “redolent of Rube Goldberg.”&lt;/p&gt;
&lt;p&gt;“Most lawyers simply call this ‘conducting legal research,’” Failla wrote. “All lawyers must know how to do it. Mr. Feldman is not excused from this professional obligation by dint of using emerging technology.”&lt;/p&gt;
&lt;p&gt;His “explanations were thick on words but thin on substance,” the judge wrote. She concluded that he “repeatedly and brazenly” violated Rule 11, which requires attorneys to verify the cases that they cite, “despite multiple warnings.”&lt;/p&gt;
&lt;p&gt;Noting that Feldman “failed to fully accept responsibility,” she ruled that case-terminating sanctions were necessary, entering default judgment for the plaintiffs. Feldman may also be on the hook to pay fees for wasting other attorneys’ time.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Case abruptly ending triggers extensive remedies&lt;/h2&gt;
&lt;p&gt;The hearing transcript has circulated on social media due to the judge’s no-nonsense approach to grilling Feldman, whom she clearly found evasive and lacking credibility.&lt;/p&gt;
&lt;p&gt;“Look, if you don’t want to be straight with me, if you don’t want to answer questions with candor, that’s fine,” Failla said. “I’ll just make my own decisions about what I think you did in this case. I’m giving you an opportunity to try and explain something that I think cannot be explained.”&lt;/p&gt;
&lt;p&gt;In her order this week, she noted that Feldman “struggled to make eye contact” and left the court without “clear answers.”&lt;/p&gt;
&lt;p&gt;Feldman’s errors came in a case in which a toy company sued merchants who allegedly failed to stop selling stolen goods after receiving a cease-and-desist order. His client was among the merchants accused of illegally profiting from the alleged thefts. They faced federal charges of trademark infringement, unfair competition, and false advertising, as well as New York charges, including fostering the sale of stolen goods.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The loss triggers remedies, including an injunction preventing additional sales of stolen goods and refunding every customer who bought them. Feldman’s client must also turn over any stolen goods in their remaining inventory and disgorge profits. Other damages may be owed, along with interest. Ars could not immediately reach an attorney for the plaintiffs to discuss the sanctions order or resulting remedies.&lt;/p&gt;
&lt;p&gt;Failla emphasized in her order that Feldman appeared to not appreciate “the gravity of the situation,” repeatedly submitting filings with fake citations even after he had been warned that sanctions could be ordered.&lt;/p&gt;
&lt;p&gt;That was a choice, Failla said, noting that Feldman’s mistakes were caught early by a lawyer working for another defendant in the case, Joel MacMull, who urged Feldman to promptly notify the court. The whole debacle would have ended in June 2025, MacMull suggested at the hearing.&lt;/p&gt;
&lt;p&gt;Rather than take MacMull’s advice, however, Feldman delayed notifying the court, irking the judge. He testified during the heated sanctions hearing that the delay was due to an effort he quietly undertook, working to correct the filing. He supposedly planned to submit those corrections when he alerted the court to the errors.&lt;/p&gt;
&lt;p&gt;But Failla noted that he never submitted corrections, insisting instead that Feldman kept her “in the dark.”&lt;/p&gt;
&lt;p&gt;“There’s no real reason why you should have kept this from me,” the judge said.&lt;/p&gt;
&lt;p&gt;The court learned of the fake citations only after MacMull notified the judge by sharing emails of his attempts to get Feldman to act urgently. Those emails showed Feldman scolding MacMull for unprofessional conduct after MacMull refused to check Feldman’s citations for him, which Failla noted at the hearing was absolutely not MacMull’s responsibility.&lt;/p&gt;
&lt;p&gt;Feldman told Failla that he also thought it was unprofessional for MacMull to share their correspondence, but Failla said the emails were “illuminative.”&lt;/p&gt;
&lt;p&gt;At the hearing, MacMull asked if the court would allow him to seek payment of his fees, since he believes “there has been a multiplication of proceedings here that would have been entirely unnecessary if Mr. Feldman had done what I asked him to do that Sunday night in June.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/02/randomly-quoting-ray-bradbury-did-not-save-lawyer-from-losing-case-over-ai-errors/</guid><pubDate>Fri, 06 Feb 2026 22:43:12 +0000</pubDate></item><item><title>[NEW] From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/super-bowl-60-ai-ads-svedka-anthropic-brands-commercials/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/svedkasuperbowl2026.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following last year’s trend of showcasing AI in multimillion-dollar ad spots, the 2026 Super Bowl advertisements took it a step further by leveraging AI both to create the commercials and to promote the latest AI products. Love it or hate it, the technology has become a star in its own right, alongside the latest movie trailers and snack brands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s explore the biggest moments from this year’s Big Game ads, which featured everything from robots and AI glasses to a touch of drama involving tech founders.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-svedka"&gt;Svedka &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Vodka brand Svedka went with what it touts as the first “primarily” AI-generated national Super Bowl spot. The 30-second ad, titled “Shake Your Bots Off,” features the company’s robot character, Fembot, and her new companion, Brobot, dancing their circuits off at a human party.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Svedka’s parent company, Sazerac, it took roughly four months to reconstruct the Fembot and train the AI to mimic facial expressions and body movements, The Wall Street Journal reported. However, the vodka brand noted that certain aspects were still handled by humans, such as developing the storyline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​The company partnered with AI company Silverside to create the Super Bowl spot, according to ADWEEK. Silverside AI is the same team behind recent AI-generated Coca-Cola commercials that sparked controversy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​It’s a bold move to debut AI-generated content during the Super Bowl, an event known for star-studded, high-production ads. The heavy reliance on AI is polarizing, fueling debates over whether AI will replace creative jobs.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Either way, Svedka definitely got people talking.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-anthropic"&gt;Anthropic&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s ad wasn’t just about selling its Claude chatbot; it was about throwing shade. The commercial took a jab at OpenAI’s plan to introduce ads to ChatGPT, with a tagline: “Ads are coming to AI. But not to Claude.” Rather than focus solely on Claude’s features, it poked fun at the idea of your helpful AI assistant suddenly turning into a hype man for “Step Boost Maxx” insoles, for example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It wasn’t a standard product pitch, and it escalated into an online feud. OpenAI’s Sam Altman fired back on social media, calling the ad “clearly dishonest.” So while we didn’t get any more Kendrick vs. Drake rap beef this time around, maybe we did get our own AI, nerdy version of it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Meta spotlighted its Oakley-branded AI glasses, designed for sports, workouts, and adventures, including extreme scenarios such as chasing down a departing plane.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The ad showcased thrill-seekers, from skydivers to mountain bikers, using the glasses to capture epic moments. Famous faces like IShowSpeed and filmmaker Spike Lee made appearances, demonstrating capabilities like filming a basketball dunk in slow motion, posting hands-free to Instagram, and other advanced features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant also featured its wearable AI tech in last year’s Super Bowl ad to spark consumer interest, with stars like Chris Pratt, Chris Hemsworth, and Kris Jenner showing off Ray-Ban Meta glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-amazon"&gt;Amazon&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s ad took a cheeky (and slightly unsettling) approach, starring Chris Hemsworth in a satirical “AI is out to get me” storyline. The commercial exaggerates common fears about AI, with Hemsworth humorously accusing Alexa+ of plotting against him. Scenes included Alexa+ closing the garage door on his head and shutting the pool cover while he swam, each mishap escalating in absurdity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the dark comedy, the ad introduced the new Alexa+, showcasing its enhanced intelligence and capabilities, ranging from managing smart home devices to planning vacations. Alexa+ had been available in early access for over a year and officially launched to all U.S. users on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ring"&gt;Ring&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ring’s commercial spotlighted its “Search Party” feature, which leverages AI and a community network to reunite lost pets with their owners. The ad followed a young girl searching for her dog Milo, illustrating how users can upload a pet’s photo to the app, where AI works to identify matches and taps into nearby cameras and the broader Ring user community to help track down missing furry family members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ring recently announced that anyone can now use Search Party, even without owning a Ring security camera. According to the company, the feature has already helped reunite more than one lost dog with its owner every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-google"&gt;Google&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s ad showcased the Nano Banana Pro, its newest image-generation model. The commercial followed a mother and son as they used AI to envision and design their new home, uploading photos of bare rooms and turning them into personalized spaces with just a few prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ramp"&gt;Ramp&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ramp scored big by getting Brian Baumgartner — the actor who played Kevin in “The Office” — for its Super Bowl commercial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the spot, Baumgartner uses Ramp’s AI-powered spend management platform to “multiply” himself, effortlessly tackling a mountain of work. The ad highlights how Ramp’s all-in-one solution helps teams focus on the most important tasks through smart automation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And, as a playful nod to his TV persona, Baumgartner is seen carrying a pot of chili in the ad, referencing Kevin’s legendary scene where he brings his cherished recipe for his co-workers to try, only to disastrously spill the entire pot on the floor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-rippling"&gt;Rippling&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Rippling, the cloud-based workforce management platform, went all in on its first-ever Super Bowl ad. The company tapped comedian Tim Robinson in a spot about onboarding an alien monster, poking fun at HR headaches and the promise of AI automation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-hims-amp-hers"&gt;Hims &amp;amp; Hers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Health company Hims &amp;amp; Hers used its Super Bowl spot to address disparities in healthcare access. The ad cleverly references the lengths the wealthy go to for health and longevity, even appearing to poke fun at Jeff Bezos’ Blue Origin spaceflight in 2021 and Bryan Johnson’s expensive anti-aging routines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent years, the company launched an AI-powered “MedMatch” tool to deliver more personalized treatment recommendations, especially for mental health and wellness.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-wix"&gt;Wix&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Website builder Wix spotlighted its new AI-powered Wix Harmony platform, promising website creation as easy as chatting with a friend. Unveiled in January, the flagship platform combines AI-driven creation and “vibe coding” with full visual editing and customization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wix’s biggest competitor, Squarespace, also has a Super Bowl ad this year. Squarespace’s ad has a more cinematic approach starring Emma Stone and directed by Yorgos Lanthimos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/svedkasuperbowl2026.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following last year’s trend of showcasing AI in multimillion-dollar ad spots, the 2026 Super Bowl advertisements took it a step further by leveraging AI both to create the commercials and to promote the latest AI products. Love it or hate it, the technology has become a star in its own right, alongside the latest movie trailers and snack brands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s explore the biggest moments from this year’s Big Game ads, which featured everything from robots and AI glasses to a touch of drama involving tech founders.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-svedka"&gt;Svedka &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Vodka brand Svedka went with what it touts as the first “primarily” AI-generated national Super Bowl spot. The 30-second ad, titled “Shake Your Bots Off,” features the company’s robot character, Fembot, and her new companion, Brobot, dancing their circuits off at a human party.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Svedka’s parent company, Sazerac, it took roughly four months to reconstruct the Fembot and train the AI to mimic facial expressions and body movements, The Wall Street Journal reported. However, the vodka brand noted that certain aspects were still handled by humans, such as developing the storyline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​The company partnered with AI company Silverside to create the Super Bowl spot, according to ADWEEK. Silverside AI is the same team behind recent AI-generated Coca-Cola commercials that sparked controversy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​It’s a bold move to debut AI-generated content during the Super Bowl, an event known for star-studded, high-production ads. The heavy reliance on AI is polarizing, fueling debates over whether AI will replace creative jobs.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Either way, Svedka definitely got people talking.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-anthropic"&gt;Anthropic&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s ad wasn’t just about selling its Claude chatbot; it was about throwing shade. The commercial took a jab at OpenAI’s plan to introduce ads to ChatGPT, with a tagline: “Ads are coming to AI. But not to Claude.” Rather than focus solely on Claude’s features, it poked fun at the idea of your helpful AI assistant suddenly turning into a hype man for “Step Boost Maxx” insoles, for example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It wasn’t a standard product pitch, and it escalated into an online feud. OpenAI’s Sam Altman fired back on social media, calling the ad “clearly dishonest.” So while we didn’t get any more Kendrick vs. Drake rap beef this time around, maybe we did get our own AI, nerdy version of it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Meta spotlighted its Oakley-branded AI glasses, designed for sports, workouts, and adventures, including extreme scenarios such as chasing down a departing plane.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The ad showcased thrill-seekers, from skydivers to mountain bikers, using the glasses to capture epic moments. Famous faces like IShowSpeed and filmmaker Spike Lee made appearances, demonstrating capabilities like filming a basketball dunk in slow motion, posting hands-free to Instagram, and other advanced features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant also featured its wearable AI tech in last year’s Super Bowl ad to spark consumer interest, with stars like Chris Pratt, Chris Hemsworth, and Kris Jenner showing off Ray-Ban Meta glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-amazon"&gt;Amazon&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s ad took a cheeky (and slightly unsettling) approach, starring Chris Hemsworth in a satirical “AI is out to get me” storyline. The commercial exaggerates common fears about AI, with Hemsworth humorously accusing Alexa+ of plotting against him. Scenes included Alexa+ closing the garage door on his head and shutting the pool cover while he swam, each mishap escalating in absurdity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the dark comedy, the ad introduced the new Alexa+, showcasing its enhanced intelligence and capabilities, ranging from managing smart home devices to planning vacations. Alexa+ had been available in early access for over a year and officially launched to all U.S. users on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ring"&gt;Ring&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ring’s commercial spotlighted its “Search Party” feature, which leverages AI and a community network to reunite lost pets with their owners. The ad followed a young girl searching for her dog Milo, illustrating how users can upload a pet’s photo to the app, where AI works to identify matches and taps into nearby cameras and the broader Ring user community to help track down missing furry family members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ring recently announced that anyone can now use Search Party, even without owning a Ring security camera. According to the company, the feature has already helped reunite more than one lost dog with its owner every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-google"&gt;Google&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s ad showcased the Nano Banana Pro, its newest image-generation model. The commercial followed a mother and son as they used AI to envision and design their new home, uploading photos of bare rooms and turning them into personalized spaces with just a few prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ramp"&gt;Ramp&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ramp scored big by getting Brian Baumgartner — the actor who played Kevin in “The Office” — for its Super Bowl commercial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the spot, Baumgartner uses Ramp’s AI-powered spend management platform to “multiply” himself, effortlessly tackling a mountain of work. The ad highlights how Ramp’s all-in-one solution helps teams focus on the most important tasks through smart automation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And, as a playful nod to his TV persona, Baumgartner is seen carrying a pot of chili in the ad, referencing Kevin’s legendary scene where he brings his cherished recipe for his co-workers to try, only to disastrously spill the entire pot on the floor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-rippling"&gt;Rippling&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Rippling, the cloud-based workforce management platform, went all in on its first-ever Super Bowl ad. The company tapped comedian Tim Robinson in a spot about onboarding an alien monster, poking fun at HR headaches and the promise of AI automation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-hims-amp-hers"&gt;Hims &amp;amp; Hers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Health company Hims &amp;amp; Hers used its Super Bowl spot to address disparities in healthcare access. The ad cleverly references the lengths the wealthy go to for health and longevity, even appearing to poke fun at Jeff Bezos’ Blue Origin spaceflight in 2021 and Bryan Johnson’s expensive anti-aging routines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent years, the company launched an AI-powered “MedMatch” tool to deliver more personalized treatment recommendations, especially for mental health and wellness.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-wix"&gt;Wix&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Website builder Wix spotlighted its new AI-powered Wix Harmony platform, promising website creation as easy as chatting with a friend. Unveiled in January, the flagship platform combines AI-driven creation and “vibe coding” with full visual editing and customization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wix’s biggest competitor, Squarespace, also has a Super Bowl ad this year. Squarespace’s ad has a more cinematic approach starring Emma Stone and directed by Yorgos Lanthimos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/super-bowl-60-ai-ads-svedka-anthropic-brands-commercials/</guid><pubDate>Fri, 06 Feb 2026 22:43:22 +0000</pubDate></item><item><title>[NEW] Sixteen Claude AI agents working together created a new C compiler (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/sixteen-claude-ai-agents-working-together-created-a-new-c-compiler/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The $20,000 experiment compiled a Linux kernel but needed deep human management.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Retro Robots on Glass Blocks -- AI coding Agents" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Retro Robots on Glass Blocks -- AI coding Agents" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          akinbostanci via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid a push toward AI agents, with both Anthropic and OpenAI shipping multi-agent tools this week, Anthropic is more than ready to show off some of its more daring AI coding experiments. But as usual with claims of AI-related achievement, you’ll find some key caveats ahead.&lt;/p&gt;
&lt;p&gt;On Thursday, Anthropic researcher Nicholas Carlini published a blog post describing how he set 16 instances of the company’s Claude Opus 4.6 AI model loose on a shared codebase with minimal supervision, tasking them with building a C compiler from scratch.&lt;/p&gt;
&lt;p&gt;Over two weeks and nearly 2,000 Claude Code sessions costing about $20,000 in API fees, the AI model agents reportedly produced a 100,000-line Rust-based compiler capable of building a bootable Linux 6.9 kernel on x86, ARM, and RISC-V architectures.&lt;/p&gt;
&lt;p&gt;Carlini, a research scientist on Anthropic’s Safeguards team who previously spent seven years at Google Brain and DeepMind, used a new feature launched with Claude Opus 4.6 called “agent teams.” In practice, each Claude instance ran inside its own Docker container, cloning a shared Git repository, claiming tasks by writing lock files, then pushing completed code back upstream. No orchestration agent directed traffic. Each instance independently identified whatever problem seemed most obvious to work on next and started solving it. When merge conflicts arose, the AI model instances resolved them on their own.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;The resulting compiler, which Anthropic has released on GitHub, can compile a range of major open source projects, including PostgreSQL, SQLite, Redis, FFmpeg, and QEMU. It achieved a 99 percent pass rate on the GCC torture test suite and, in what Carlini called “the developer’s ultimate litmus test,” compiled and ran &lt;em&gt;Doom&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It’s worth noting that a C compiler is a near-ideal task for semi-autonomous AI model coding: The specification is decades old and well-defined, comprehensive test suites already exist, and there’s a known-good reference compiler to check against. Most real-world software projects have none of these advantages. The hard part of most development isn’t writing code that passes tests; it’s figuring out what the tests should be in the first place.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The compiler also has clear limitations that Carlini was upfront about. It lacks a 16-bit x86 backend needed to boot Linux from real mode, so it calls out to GCC for that step. Its own assembler and linker remain buggy. Even with all optimizations enabled, it produces less efficient code than GCC running with all optimizations disabled. And the Rust code quality, while functional, does not approach what an expert Rust programmer would produce. “The resulting compiler has nearly reached the limits of Opus’s abilities,” Carlini wrote. “I tried (hard!) to fix several of the above limitations but wasn’t fully successful. New features and bugfixes frequently broke existing functionality.”&lt;/p&gt;
&lt;p&gt;Those limitations may actually be more informative than the successes. Carlini reports that toward the end of the project, fixing bugs and adding features “frequently broke existing functionality,” a pattern familiar to anyone who has watched a codebase grow beyond the point where any contributor fully understands it.&lt;/p&gt;
&lt;p&gt;And that limitation is even more common when dealing with AI coding agents, which lose coherence over time. The model hit this wall at around 100,000 lines, which suggests a practical ceiling for autonomous agentic coding, at least with current models.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The human work behind the automation&lt;/h2&gt;
&lt;p&gt;Anthropic describes the compiler as a “clean-room implementation” because the agents had no Internet access during development. But that framing is somewhat misleading. The underlying model was trained on enormous quantities of publicly available source code, almost certainly including GCC, Clang, and numerous smaller C compilers. In traditional software development, “clean room” specifically means the implementers have never seen the original code. By that standard, this isn’t one.&lt;/p&gt;
&lt;p&gt;On Hacker News, the distinction drew sharp debate, reflective of a controversial reception to the news among developers. “It was rather a brute force attempt to decompress fuzzily stored knowledge contained within the network,” wrote one commenter.&lt;/p&gt;
&lt;p&gt;The $20,000 figure also deserves some context. That number covers only API token costs and excludes the billions spent training the model, the human labor Carlini invested in building the scaffolding, and the decades of work by compiler engineers who created the test suites and reference implementations that made the project possible.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;And that scaffolding was not trivial, which makes any claim of “autonomous” work on the C compiler among the AI agents dubious. While the headline result is a compiler written without human pair-programming, much of the real work that made the project function involved designing the environment around the AI model agents rather than writing compiler code directly. Carlini spent considerable effort building test harnesses, continuous integration pipelines, and feedback systems tuned for the specific ways language models fail.&lt;/p&gt;
&lt;p&gt;He found, for example, that verbose test output polluted the model’s context window, causing it to lose track of what it was doing. To address this, Carlini designed test runners that printed only a few summary lines and logged details to separate files.&lt;/p&gt;
&lt;p&gt;He also found that Claude has no sense of time and will spend hours running tests without making progress, so he built a fast mode that samples only 1 percent to 10 percent of test cases. When all 16 agents got stuck trying to fix the same Linux kernel bug simultaneously, he used GCC as a reference oracle, randomly compiling most kernel files with GCC and only a subset with Claude’s compiler, so each agent could work on different bugs in different files.&lt;/p&gt;
&lt;p&gt;“Claude will work autonomously to solve whatever problem I give it,” Carlini wrote. “So it’s important that the task verifier is nearly perfect, otherwise Claude will solve the wrong problem.”&lt;/p&gt;
&lt;p&gt;None of this should obscure what the project actually demonstrates. A year ago, no language model could have produced anything close to a functional multi-architecture compiler, even with this kind of babysitting and an unlimited budget. The methodology of parallel agents coordinating through Git with minimal human supervision is novel, and the engineering tricks Carlini developed to keep the agents productive (context-aware test output, time-boxing, the GCC oracle for parallelization) could potentially represent useful contributions to the wider use of agentic software development tools.&lt;/p&gt;
&lt;p&gt;Carlini himself acknowledged feeling conflicted about his own results. “Building this compiler has been some of the most fun I’ve had recently, but I did not expect this to be anywhere near possible so early in 2026,” he wrote. He also raised concerns rooted in his previous career in penetration testing, noting that “the thought of programmers deploying software they’ve never personally verified is a real concern.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The $20,000 experiment compiled a Linux kernel but needed deep human management.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Retro Robots on Glass Blocks -- AI coding Agents" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Retro Robots on Glass Blocks -- AI coding Agents" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          akinbostanci via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid a push toward AI agents, with both Anthropic and OpenAI shipping multi-agent tools this week, Anthropic is more than ready to show off some of its more daring AI coding experiments. But as usual with claims of AI-related achievement, you’ll find some key caveats ahead.&lt;/p&gt;
&lt;p&gt;On Thursday, Anthropic researcher Nicholas Carlini published a blog post describing how he set 16 instances of the company’s Claude Opus 4.6 AI model loose on a shared codebase with minimal supervision, tasking them with building a C compiler from scratch.&lt;/p&gt;
&lt;p&gt;Over two weeks and nearly 2,000 Claude Code sessions costing about $20,000 in API fees, the AI model agents reportedly produced a 100,000-line Rust-based compiler capable of building a bootable Linux 6.9 kernel on x86, ARM, and RISC-V architectures.&lt;/p&gt;
&lt;p&gt;Carlini, a research scientist on Anthropic’s Safeguards team who previously spent seven years at Google Brain and DeepMind, used a new feature launched with Claude Opus 4.6 called “agent teams.” In practice, each Claude instance ran inside its own Docker container, cloning a shared Git repository, claiming tasks by writing lock files, then pushing completed code back upstream. No orchestration agent directed traffic. Each instance independently identified whatever problem seemed most obvious to work on next and started solving it. When merge conflicts arose, the AI model instances resolved them on their own.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;The resulting compiler, which Anthropic has released on GitHub, can compile a range of major open source projects, including PostgreSQL, SQLite, Redis, FFmpeg, and QEMU. It achieved a 99 percent pass rate on the GCC torture test suite and, in what Carlini called “the developer’s ultimate litmus test,” compiled and ran &lt;em&gt;Doom&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It’s worth noting that a C compiler is a near-ideal task for semi-autonomous AI model coding: The specification is decades old and well-defined, comprehensive test suites already exist, and there’s a known-good reference compiler to check against. Most real-world software projects have none of these advantages. The hard part of most development isn’t writing code that passes tests; it’s figuring out what the tests should be in the first place.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The compiler also has clear limitations that Carlini was upfront about. It lacks a 16-bit x86 backend needed to boot Linux from real mode, so it calls out to GCC for that step. Its own assembler and linker remain buggy. Even with all optimizations enabled, it produces less efficient code than GCC running with all optimizations disabled. And the Rust code quality, while functional, does not approach what an expert Rust programmer would produce. “The resulting compiler has nearly reached the limits of Opus’s abilities,” Carlini wrote. “I tried (hard!) to fix several of the above limitations but wasn’t fully successful. New features and bugfixes frequently broke existing functionality.”&lt;/p&gt;
&lt;p&gt;Those limitations may actually be more informative than the successes. Carlini reports that toward the end of the project, fixing bugs and adding features “frequently broke existing functionality,” a pattern familiar to anyone who has watched a codebase grow beyond the point where any contributor fully understands it.&lt;/p&gt;
&lt;p&gt;And that limitation is even more common when dealing with AI coding agents, which lose coherence over time. The model hit this wall at around 100,000 lines, which suggests a practical ceiling for autonomous agentic coding, at least with current models.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The human work behind the automation&lt;/h2&gt;
&lt;p&gt;Anthropic describes the compiler as a “clean-room implementation” because the agents had no Internet access during development. But that framing is somewhat misleading. The underlying model was trained on enormous quantities of publicly available source code, almost certainly including GCC, Clang, and numerous smaller C compilers. In traditional software development, “clean room” specifically means the implementers have never seen the original code. By that standard, this isn’t one.&lt;/p&gt;
&lt;p&gt;On Hacker News, the distinction drew sharp debate, reflective of a controversial reception to the news among developers. “It was rather a brute force attempt to decompress fuzzily stored knowledge contained within the network,” wrote one commenter.&lt;/p&gt;
&lt;p&gt;The $20,000 figure also deserves some context. That number covers only API token costs and excludes the billions spent training the model, the human labor Carlini invested in building the scaffolding, and the decades of work by compiler engineers who created the test suites and reference implementations that made the project possible.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;And that scaffolding was not trivial, which makes any claim of “autonomous” work on the C compiler among the AI agents dubious. While the headline result is a compiler written without human pair-programming, much of the real work that made the project function involved designing the environment around the AI model agents rather than writing compiler code directly. Carlini spent considerable effort building test harnesses, continuous integration pipelines, and feedback systems tuned for the specific ways language models fail.&lt;/p&gt;
&lt;p&gt;He found, for example, that verbose test output polluted the model’s context window, causing it to lose track of what it was doing. To address this, Carlini designed test runners that printed only a few summary lines and logged details to separate files.&lt;/p&gt;
&lt;p&gt;He also found that Claude has no sense of time and will spend hours running tests without making progress, so he built a fast mode that samples only 1 percent to 10 percent of test cases. When all 16 agents got stuck trying to fix the same Linux kernel bug simultaneously, he used GCC as a reference oracle, randomly compiling most kernel files with GCC and only a subset with Claude’s compiler, so each agent could work on different bugs in different files.&lt;/p&gt;
&lt;p&gt;“Claude will work autonomously to solve whatever problem I give it,” Carlini wrote. “So it’s important that the task verifier is nearly perfect, otherwise Claude will solve the wrong problem.”&lt;/p&gt;
&lt;p&gt;None of this should obscure what the project actually demonstrates. A year ago, no language model could have produced anything close to a functional multi-architecture compiler, even with this kind of babysitting and an unlimited budget. The methodology of parallel agents coordinating through Git with minimal human supervision is novel, and the engineering tricks Carlini developed to keep the agents productive (context-aware test output, time-boxing, the GCC oracle for parallelization) could potentially represent useful contributions to the wider use of agentic software development tools.&lt;/p&gt;
&lt;p&gt;Carlini himself acknowledged feeling conflicted about his own results. “Building this compiler has been some of the most fun I’ve had recently, but I did not expect this to be anywhere near possible so early in 2026,” he wrote. He also raised concerns rooted in his previous career in penetration testing, noting that “the thought of programmers deploying software they’ve never personally verified is a real concern.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/sixteen-claude-ai-agents-working-together-created-a-new-c-compiler/</guid><pubDate>Fri, 06 Feb 2026 23:40:58 +0000</pubDate></item></channel></rss>