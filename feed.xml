<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 11 Oct 2025 12:37:53 +0000</lastBuildDate><item><title>The fixer’s dilemma: Chris Lehane and OpenAI’s impossible mission (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/10/the-fixers-dilemma-chris-lehane-and-openais-impossible-mission/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-10-at-10.35.15PM.png?resize=1200,789" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chris Lehane is one of the best in the business at making bad news disappear. Al Gore’s press secretary during the Clinton years, Airbnb’s chief crisis manager through every regulatory nightmare from here to Brussels – Lehane knows how to spin. Now he’s two years into what might be his most impossible gig yet: as OpenAI’s VP of global policy, his job is to convince the world that OpenAI genuinely gives a damn about democratizing artificial intelligence while the company increasingly behaves like, well, every other tech giant that’s ever claimed to be different.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I had 20 minutes with him on stage at the Elevate conference in Toronto earlier this week – 20 minutes to get past the talking points and into the real contradictions eating away at OpenAI’s carefully constructed image. It wasn’t easy or entirely successful. Lehane is genuinely good at his job. He’s likable. He sounds reasonable. He admits uncertainty. He even talks about waking up at 3 a.m. worried about whether any of this will actually benefit humanity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But good intentions don’t mean much when your company is subpoenaing critics, draining economically depressed towns of water and electricity, and bringing dead celebrities back to life to assert your market dominance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s Sora problem is really at the root of everything else. The video generation tool launched last week with copyrighted material seemingly baked right into it. It was a bold move for a company already getting sued by the New York Times, the Toronto Star, and half the publishing industry. From a business and marketing standpoint, it was also brilliant. The invite-only app soared to the top of the App Store as people created digital versions of themselves, OpenAI CEO Sam Altman; characters like Pikachu and Cartman of “South Park”; and dead celebrities like Tupac Shakur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked what drove OpenAI’s decision to launch this newest version of Sora with these characters, Lehane offered that Sora is a “general purpose technology” like the printing press, democratizing creativity for people without talent or resources. Even he – a self-described creative zero – can make videos now, he said on stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What he danced around is that OpenAI initially “let” rights holders opt out of having their work used to train Sora, which is not how copyright use typically works. Then, after OpenAI noticed that people really liked using copyrighted images, it “evolved” toward an opt-in model. That’s not iterating. That’s testing how much you can get away with. (By the way, though the Motion Picture Association made some noise last week about legal threats, OpenAI appears to have gotten away with quite a lot.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Naturally, the situation brings to mind the aggravation of publishers who accuse OpenAI of training on their work without sharing the financial spoils. When I pressed Lehane about publishers getting cut out of the economics, he invoked fair use, that American legal doctrine that’s supposed to balance creator rights against public access to knowledge. He called it the secret weapon of U.S. tech dominance.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Maybe. But I’d recently interviewed Al Gore – Lehane’s old boss – and realized anyone could simply ask ChatGPT about it instead of reading my piece on TechCrunch. “It’s ‘iterative’,” I said, “but it’s also a replacement.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lehane listened and dropped his spiel. “We’re all going to need to figure this out,” he said. “It’s really glib and easy to sit here on stage and say we need to figure out new economic revenue models. But I think we will.” (We’re making it up as we go, is what I heard.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the infrastructure question nobody wants to answer honestly. OpenAI is already operating a data center campus in Abilene, Texas, and recently broke ground on a massive data center in Lordstown, Ohio, in partnership with Oracle and SoftBank. Lehane has likened the adoption of AI to the advent of electricity – saying those who accessed it last are still playing catch-up – yet OpenAI’s Stargate project is seemingly targeting some of those same economically challenged places to set up facilities with their attendant and massive appetites for water and electricity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Asked during our sit-down whether these communities will benefit or merely foot the bill, Lehane went to gigawatts and geopolitics. OpenAI needs about a gigawatt of energy per week, he noted. China brought on 450 gigawatts last year plus 33 nuclear facilities. If democracies want democratic AI, he said, they have to compete. “The optimist in me says this will modernize our energy systems,” he’d said, painting a picture of re-industrialized America with transformed power grids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was inspiring, but it was not an answer about whether people in Lordstown and Abilene are going to watch their utility bills spike while OpenAI generates videos of The Notorious B.I.G. It’s very worth noting that video generation is the most energy-intensive AI out there.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s also a human cost, one made clearer the day before our interview, when Zelda Williams logged onto Instagram to beg strangers to stop sending her AI-generated videos of her late father, Robin Williams. “You’re not making art,” she wrote. “You’re making disgusting, over-processed hotdogs out of the lives of human beings.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When I asked about how the company reconciles this kind of intimate harm with its mission, Lehane answered by talking about processes, including responsible design, testing frameworks, and government partnerships. “There is no playbook for this stuff, right?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lehane showed vulnerability in some moments, saying he recognizes the “enormous responsibilities that come with” all that OpenAI does.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether or not those moments were designed for the audience, I believe him. Indeed, I left Toronto thinking I’d watched a master class in political messaging – Lehane threading an impossible needle while dodging questions about company decisions that, for all I know, he doesn’t even agree with. Then news broke that complicated that already complicated picture.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Calvin, a lawyer who works on AI policy at a nonprofit advocacy organization, Encode AI, revealed that at the same time I was talking with Lehane in Toronto, OpenAI had sent a sheriff’s deputy to Calvin’s house in Washington, D.C., during dinner to serve him a subpoena. They wanted his private messages with California legislators, college students, and former OpenAI employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calvin says the move was part of OpenAI’s intimidation tactics around a new piece of AI regulation, California’s SB 53. He says the company weaponized its ongoing legal battle with Elon Musk as a pretext to target critics, implying Encode was secretly funded by Musk. Calvin added that he fought OpenAI’s opposition to California’s SB 53, an AI safety bill, and that when he saw OpenAI claim that it “worked to improve the bill,” he “literally laughed out loud.” In a social media skein, he went on to call Lehane, specifically, the “master of the political dark arts.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Washington, that might be a compliment. At a company like OpenAI whose mission is “to build AI that benefits all of humanity,” it sounds like an indictment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what matters much more is that even OpenAI’s own people are conflicted about what they are becoming.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As my colleague Max reported last week, a number of current and former employees took to social media after Sora 2 was released, expressing their misgivings. Among them was Boaz Barak, an OpenAI researcher and Harvard professor, who wrote about Sora 2 that it is “technically amazing but it’s premature to congratulate ourselves on avoiding the pitfalls of other social media apps and deepfakes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Josh Achiam – OpenAI’s head of mission alignment – tweeted something even more remarkable about Calvin’s accusation. Prefacing his comments by saying they were “possibly a risk to my whole career,”  Achiam went on to write of OpenAI: “We can’t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth pausing to think about that. An OpenAI executive publicly questioning whether his company is becoming “a frightening power instead of a virtuous one,” isn’t on a par with a competitor taking shots or a reporter asking questions. This is someone who chose to work at OpenAI, who believes in its mission, and who is now acknowledging a crisis of conscience despite the professional risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a crystallizing moment, one whose contradictions may only intensify as OpenAI races toward artificial general intelligence. It also has me thinking that the real question isn’t whether Chris Lehane can sell OpenAI’s mission. It’s whether others – including, critically, the other people who work there – still believe it.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-10-at-10.35.15PM.png?resize=1200,789" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chris Lehane is one of the best in the business at making bad news disappear. Al Gore’s press secretary during the Clinton years, Airbnb’s chief crisis manager through every regulatory nightmare from here to Brussels – Lehane knows how to spin. Now he’s two years into what might be his most impossible gig yet: as OpenAI’s VP of global policy, his job is to convince the world that OpenAI genuinely gives a damn about democratizing artificial intelligence while the company increasingly behaves like, well, every other tech giant that’s ever claimed to be different.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I had 20 minutes with him on stage at the Elevate conference in Toronto earlier this week – 20 minutes to get past the talking points and into the real contradictions eating away at OpenAI’s carefully constructed image. It wasn’t easy or entirely successful. Lehane is genuinely good at his job. He’s likable. He sounds reasonable. He admits uncertainty. He even talks about waking up at 3 a.m. worried about whether any of this will actually benefit humanity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But good intentions don’t mean much when your company is subpoenaing critics, draining economically depressed towns of water and electricity, and bringing dead celebrities back to life to assert your market dominance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s Sora problem is really at the root of everything else. The video generation tool launched last week with copyrighted material seemingly baked right into it. It was a bold move for a company already getting sued by the New York Times, the Toronto Star, and half the publishing industry. From a business and marketing standpoint, it was also brilliant. The invite-only app soared to the top of the App Store as people created digital versions of themselves, OpenAI CEO Sam Altman; characters like Pikachu and Cartman of “South Park”; and dead celebrities like Tupac Shakur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked what drove OpenAI’s decision to launch this newest version of Sora with these characters, Lehane offered that Sora is a “general purpose technology” like the printing press, democratizing creativity for people without talent or resources. Even he – a self-described creative zero – can make videos now, he said on stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What he danced around is that OpenAI initially “let” rights holders opt out of having their work used to train Sora, which is not how copyright use typically works. Then, after OpenAI noticed that people really liked using copyrighted images, it “evolved” toward an opt-in model. That’s not iterating. That’s testing how much you can get away with. (By the way, though the Motion Picture Association made some noise last week about legal threats, OpenAI appears to have gotten away with quite a lot.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Naturally, the situation brings to mind the aggravation of publishers who accuse OpenAI of training on their work without sharing the financial spoils. When I pressed Lehane about publishers getting cut out of the economics, he invoked fair use, that American legal doctrine that’s supposed to balance creator rights against public access to knowledge. He called it the secret weapon of U.S. tech dominance.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Maybe. But I’d recently interviewed Al Gore – Lehane’s old boss – and realized anyone could simply ask ChatGPT about it instead of reading my piece on TechCrunch. “It’s ‘iterative’,” I said, “but it’s also a replacement.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lehane listened and dropped his spiel. “We’re all going to need to figure this out,” he said. “It’s really glib and easy to sit here on stage and say we need to figure out new economic revenue models. But I think we will.” (We’re making it up as we go, is what I heard.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the infrastructure question nobody wants to answer honestly. OpenAI is already operating a data center campus in Abilene, Texas, and recently broke ground on a massive data center in Lordstown, Ohio, in partnership with Oracle and SoftBank. Lehane has likened the adoption of AI to the advent of electricity – saying those who accessed it last are still playing catch-up – yet OpenAI’s Stargate project is seemingly targeting some of those same economically challenged places to set up facilities with their attendant and massive appetites for water and electricity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Asked during our sit-down whether these communities will benefit or merely foot the bill, Lehane went to gigawatts and geopolitics. OpenAI needs about a gigawatt of energy per week, he noted. China brought on 450 gigawatts last year plus 33 nuclear facilities. If democracies want democratic AI, he said, they have to compete. “The optimist in me says this will modernize our energy systems,” he’d said, painting a picture of re-industrialized America with transformed power grids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was inspiring, but it was not an answer about whether people in Lordstown and Abilene are going to watch their utility bills spike while OpenAI generates videos of The Notorious B.I.G. It’s very worth noting that video generation is the most energy-intensive AI out there.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s also a human cost, one made clearer the day before our interview, when Zelda Williams logged onto Instagram to beg strangers to stop sending her AI-generated videos of her late father, Robin Williams. “You’re not making art,” she wrote. “You’re making disgusting, over-processed hotdogs out of the lives of human beings.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When I asked about how the company reconciles this kind of intimate harm with its mission, Lehane answered by talking about processes, including responsible design, testing frameworks, and government partnerships. “There is no playbook for this stuff, right?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lehane showed vulnerability in some moments, saying he recognizes the “enormous responsibilities that come with” all that OpenAI does.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether or not those moments were designed for the audience, I believe him. Indeed, I left Toronto thinking I’d watched a master class in political messaging – Lehane threading an impossible needle while dodging questions about company decisions that, for all I know, he doesn’t even agree with. Then news broke that complicated that already complicated picture.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Calvin, a lawyer who works on AI policy at a nonprofit advocacy organization, Encode AI, revealed that at the same time I was talking with Lehane in Toronto, OpenAI had sent a sheriff’s deputy to Calvin’s house in Washington, D.C., during dinner to serve him a subpoena. They wanted his private messages with California legislators, college students, and former OpenAI employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calvin says the move was part of OpenAI’s intimidation tactics around a new piece of AI regulation, California’s SB 53. He says the company weaponized its ongoing legal battle with Elon Musk as a pretext to target critics, implying Encode was secretly funded by Musk. Calvin added that he fought OpenAI’s opposition to California’s SB 53, an AI safety bill, and that when he saw OpenAI claim that it “worked to improve the bill,” he “literally laughed out loud.” In a social media skein, he went on to call Lehane, specifically, the “master of the political dark arts.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Washington, that might be a compliment. At a company like OpenAI whose mission is “to build AI that benefits all of humanity,” it sounds like an indictment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what matters much more is that even OpenAI’s own people are conflicted about what they are becoming.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As my colleague Max reported last week, a number of current and former employees took to social media after Sora 2 was released, expressing their misgivings. Among them was Boaz Barak, an OpenAI researcher and Harvard professor, who wrote about Sora 2 that it is “technically amazing but it’s premature to congratulate ourselves on avoiding the pitfalls of other social media apps and deepfakes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Josh Achiam – OpenAI’s head of mission alignment – tweeted something even more remarkable about Calvin’s accusation. Prefacing his comments by saying they were “possibly a risk to my whole career,”  Achiam went on to write of OpenAI: “We can’t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth pausing to think about that. An OpenAI executive publicly questioning whether his company is becoming “a frightening power instead of a virtuous one,” isn’t on a par with a competitor taking shots or a reporter asking questions. This is someone who chose to work at OpenAI, who believes in its mission, and who is now acknowledging a crisis of conscience despite the professional risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a crystallizing moment, one whose contradictions may only intensify as OpenAI races toward artificial general intelligence. It also has me thinking that the real question isn’t whether Chris Lehane can sell OpenAI’s mission. It’s whether others – including, critically, the other people who work there – still believe it.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/10/the-fixers-dilemma-chris-lehane-and-openais-impossible-mission/</guid><pubDate>Sat, 11 Oct 2025 06:04:26 +0000</pubDate></item></channel></rss>