<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 02 Aug 2025 06:32:17 +0000</lastBuildDate><item><title>[NEW] Why open-source AI became an American national priority (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/why-open-source-ai-became-an-american-national-priority/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;When President Trump released the U.S. AI Action Plan last week, many were surprised to see “encourage open-source and open-weight AI,” as one of the administration’s top priorities. The White House has elevated what was once a highly technical topic into an urgent national concern — and a key strategy to winning the AI race against China.&lt;/p&gt;



&lt;p&gt;China’s emphasis on open source, also highlighted in its own Action Plan released shortly after the U.S., makes the open-source race imperative. And the global soft power that comes with more open models from China makes their recent leadership even more notable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When DeepSeek-R1, a powerful open-source large language model (LLM) out of China, was released earlier this year, it didn’t come with a press tour. No flashy demos. No keynote speeches. But it was open weights and open science. Open weight means anyone with the right skills and computing resources can run, replicate, or make a model their own; open science shares some of the tricks behind the model development. &lt;/p&gt;



&lt;p&gt;Within hours, researchers and developers seized on it. Within days, it became the most-liked model &lt;em&gt;of all time&lt;/em&gt; on Hugging Face — with thousands of variants created and used across major tech companies, research labs and startups. Most strikingly, this explosion of adoption happened not just abroad, but &lt;em&gt;in the U.S.&lt;/em&gt; For the first time, American AI was being built on Chinese foundations.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-deepseek-wasn-t-the-only-one"&gt;DeepSeek wasn’t the only one&lt;/h2&gt;



&lt;p&gt;Within a week, the U.S. stock market — sensing the tremor — took a tumble.&lt;/p&gt;



&lt;p&gt;It turns out Deepseek was just the opening act. Dozens of Chinese research groups are now pushing the frontiers of open-source AI, sharing not only powerful models, but the data, code and scientific methods behind them. They’re moving quickly — and they’re doing it in the open.&lt;/p&gt;



&lt;p&gt;Meanwhile, U.S.-based companies — many of which pioneered the modern AI revolution — are increasingly closing up. Flagship models like GPT-4, Claude and Gemini are no longer released in ways that allow builders more control. They’re accessible only through chatbots or APIs: Gated interfaces that let you interact with a model but not see how it works, retrain it or use it freely. The model’s weights, training data and behavior remain proprietary, tightly controlled by a few tech giants.&lt;/p&gt;



&lt;p&gt;This is a dramatic reversal. Between 2016 and 2020, the U.S. was &lt;em&gt;the&lt;/em&gt; global leader in open-source AI. Research labs from Google, OpenAI, Stanford and elsewhere released breakthrough models and methods that laid the foundation for everything we now call “AI.” The transformer — the “T” in ChatGPT — was born out of this open culture. Hugging Face was created during this era to democratize access to these technologies.&lt;/p&gt;



&lt;p&gt;Now, the U.S. is slipping, and the implications are profound.&lt;/p&gt;



&lt;p&gt;American scientists, startups and institutions are increasingly driven to build on Chinese open models because the best U.S. models are locked behind APIs. As each new open model emerges from abroad, Chinese companies like DeepSeek and Alibaba strengthen their positions as foundational layers in the global AI ecosystem. The tools that power America’s next generation of AI products, research and infrastructure are increasingly coming from overseas.&lt;/p&gt;



&lt;p&gt;And at a deeper level, there’s a more fundamental risk: Every advancement in AI — including the most closed systems — is built on open foundations. Proprietary models depend on open research, from transformer architecture to training libraries and evaluation frameworks. But more importantly, open-source increases a country’s velocity in building AI. It fuels rapid experimentation, lowers barriers to entry and creates compounding innovation. &lt;/p&gt;



&lt;p&gt;When openness slows down, the entire ecosystem follows. If the U.S. falls behind in open-source today, it may find itself falling behind in AI altogether.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-moving-away-from-black-box-ai"&gt;Moving away from black box AI&lt;/h2&gt;



&lt;p&gt;This matters not just for innovation, but for security, science and democratic governance. Open models are transparent and auditable. They allow governments, educators, healthcare institutions and small businesses to adapt AI to their needs, without vendor lock-in or black-box dependencies.&lt;/p&gt;



&lt;p&gt;We need more and better U.S.-developed open source models and artifacts. U.S. institutions already pushing for openness must build on their success. Meta’s open-weight Llama family has led to tens of thousands of variations on Hugging Face. The Allen Institute for AI continues to publish excellent fully open models. Promising startups like Black Forest are building open multimodal systems. Even OpenAI has suggested it may release open weights soon.&lt;/p&gt;



&lt;p&gt;With more public and policy support for open-source AI, as demonstrated by the U.S. AI Action Plan, we can restart a decentralized movement that will ensure America’s leadership. It’s time for the American AI community to wake up, drop the “open is not safe” narrative, and return to its roots: Open science and open-source AI, powered by an unmatched community of frontier labs, big tech, startups, universities and non‑profits.&lt;/p&gt;



&lt;p&gt;We can restart a decentralized movement that will ensure U.S. leadership, built on openness, competition and scientific inquiry, and empower the next generation of builders. If we want AI to reflect democratic principles, we have to build it in the open. And if the U.S. wants to lead the AI race, it must lead the open-source AI race.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Clément Delangue is the co-founder and CEO of Hugging Face.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;When President Trump released the U.S. AI Action Plan last week, many were surprised to see “encourage open-source and open-weight AI,” as one of the administration’s top priorities. The White House has elevated what was once a highly technical topic into an urgent national concern — and a key strategy to winning the AI race against China.&lt;/p&gt;



&lt;p&gt;China’s emphasis on open source, also highlighted in its own Action Plan released shortly after the U.S., makes the open-source race imperative. And the global soft power that comes with more open models from China makes their recent leadership even more notable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When DeepSeek-R1, a powerful open-source large language model (LLM) out of China, was released earlier this year, it didn’t come with a press tour. No flashy demos. No keynote speeches. But it was open weights and open science. Open weight means anyone with the right skills and computing resources can run, replicate, or make a model their own; open science shares some of the tricks behind the model development. &lt;/p&gt;



&lt;p&gt;Within hours, researchers and developers seized on it. Within days, it became the most-liked model &lt;em&gt;of all time&lt;/em&gt; on Hugging Face — with thousands of variants created and used across major tech companies, research labs and startups. Most strikingly, this explosion of adoption happened not just abroad, but &lt;em&gt;in the U.S.&lt;/em&gt; For the first time, American AI was being built on Chinese foundations.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-deepseek-wasn-t-the-only-one"&gt;DeepSeek wasn’t the only one&lt;/h2&gt;



&lt;p&gt;Within a week, the U.S. stock market — sensing the tremor — took a tumble.&lt;/p&gt;



&lt;p&gt;It turns out Deepseek was just the opening act. Dozens of Chinese research groups are now pushing the frontiers of open-source AI, sharing not only powerful models, but the data, code and scientific methods behind them. They’re moving quickly — and they’re doing it in the open.&lt;/p&gt;



&lt;p&gt;Meanwhile, U.S.-based companies — many of which pioneered the modern AI revolution — are increasingly closing up. Flagship models like GPT-4, Claude and Gemini are no longer released in ways that allow builders more control. They’re accessible only through chatbots or APIs: Gated interfaces that let you interact with a model but not see how it works, retrain it or use it freely. The model’s weights, training data and behavior remain proprietary, tightly controlled by a few tech giants.&lt;/p&gt;



&lt;p&gt;This is a dramatic reversal. Between 2016 and 2020, the U.S. was &lt;em&gt;the&lt;/em&gt; global leader in open-source AI. Research labs from Google, OpenAI, Stanford and elsewhere released breakthrough models and methods that laid the foundation for everything we now call “AI.” The transformer — the “T” in ChatGPT — was born out of this open culture. Hugging Face was created during this era to democratize access to these technologies.&lt;/p&gt;



&lt;p&gt;Now, the U.S. is slipping, and the implications are profound.&lt;/p&gt;



&lt;p&gt;American scientists, startups and institutions are increasingly driven to build on Chinese open models because the best U.S. models are locked behind APIs. As each new open model emerges from abroad, Chinese companies like DeepSeek and Alibaba strengthen their positions as foundational layers in the global AI ecosystem. The tools that power America’s next generation of AI products, research and infrastructure are increasingly coming from overseas.&lt;/p&gt;



&lt;p&gt;And at a deeper level, there’s a more fundamental risk: Every advancement in AI — including the most closed systems — is built on open foundations. Proprietary models depend on open research, from transformer architecture to training libraries and evaluation frameworks. But more importantly, open-source increases a country’s velocity in building AI. It fuels rapid experimentation, lowers barriers to entry and creates compounding innovation. &lt;/p&gt;



&lt;p&gt;When openness slows down, the entire ecosystem follows. If the U.S. falls behind in open-source today, it may find itself falling behind in AI altogether.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-moving-away-from-black-box-ai"&gt;Moving away from black box AI&lt;/h2&gt;



&lt;p&gt;This matters not just for innovation, but for security, science and democratic governance. Open models are transparent and auditable. They allow governments, educators, healthcare institutions and small businesses to adapt AI to their needs, without vendor lock-in or black-box dependencies.&lt;/p&gt;



&lt;p&gt;We need more and better U.S.-developed open source models and artifacts. U.S. institutions already pushing for openness must build on their success. Meta’s open-weight Llama family has led to tens of thousands of variations on Hugging Face. The Allen Institute for AI continues to publish excellent fully open models. Promising startups like Black Forest are building open multimodal systems. Even OpenAI has suggested it may release open weights soon.&lt;/p&gt;



&lt;p&gt;With more public and policy support for open-source AI, as demonstrated by the U.S. AI Action Plan, we can restart a decentralized movement that will ensure America’s leadership. It’s time for the American AI community to wake up, drop the “open is not safe” narrative, and return to its roots: Open science and open-source AI, powered by an unmatched community of frontier labs, big tech, startups, universities and non‑profits.&lt;/p&gt;



&lt;p&gt;We can restart a decentralized movement that will ensure U.S. leadership, built on openness, competition and scientific inquiry, and empower the next generation of builders. If we want AI to reflect democratic principles, we have to build it in the open. And if the U.S. wants to lead the AI race, it must lead the open-source AI race.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Clément Delangue is the co-founder and CEO of Hugging Face.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/why-open-source-ai-became-an-american-national-priority/</guid><pubDate>Fri, 01 Aug 2025 19:07:25 +0000</pubDate></item><item><title>Delta denies using AI to come up with inflated, personalized prices (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/delta-denies-using-ai-to-come-up-with-inflated-personalized-prices/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Delta finally explains how its AI pricing works amid ongoing backlash.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Delta spent July dealing with backlash over what the airline company claims is widespread public confusion over its AI pricing system.&lt;/p&gt;
&lt;p&gt;Now, Delta has finally come forward to break down precisely how the AI pricing works to dispute what it claims are "incorrect" characterizations by consumer watchdogs, lawmakers, and media outlets.&lt;/p&gt;
&lt;p&gt;In a letter to lawmakers who accused Delta of using AI to spy on customers' personal data in order to "jack up" prices, Delta insisted that "there is no fare product Delta has ever used, is testing, or plans to use that targets customers with individualized prices based on personal data."&lt;/p&gt;
&lt;p&gt;Confusion arose after Delta Air Lines President Glen William Hauenstein discussed the AI pricing on a summer earnings call. Hauenstein hyped the AI pricing as working to propel revenue, confirming that about 3 percent of domestic flights were sold using the AI pricing system over the past six months and that Delta planned to expand that to 20 percent of tickets by the end of the year.&lt;/p&gt;
&lt;p&gt;Critics demanded transparency, raising concerns that Delta's AI pricing could lead to discriminatory pricing based on a customer's search history or prior purchases. But Delta did not rush to clarify how its AI pricing actually works until lawmakers sent a letter probing Delta's AI practices. Those lawmakers had just announced the Stop AI Price Gouging and Wage Fixing Act, with a press release that called out Delta among companies whose AI pricing models needed to be banned to prevent surveillance pricing that lawmakers fear will disproportionately disrupt fair pricing for the least wealthy.&lt;/p&gt;
&lt;p&gt;Responding, Delta's chief external affairs officer, Peter Carter, thanked lawmakers for their "thoughtful questions regarding Delta’s use of AI," then cautioned them against making assumptions about Delta's AI pricing.&lt;/p&gt;
&lt;p&gt;"Your letter presupposes that we are using, and intend to use, AI for 'individualized' pricing or 'surveillance' pricing, leveraging consumer-specific personal data, such as sensitive personal circumstances or prior purchasing activity to set individualized prices," Carter said. "To clarify, this is incorrect and this assumption, unfortunately, has created confusion and misinformation in the public discourse."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Delta scandal highlights value of transparency&lt;/h2&gt;
&lt;p&gt;According to Delta, the company has "zero tolerance for discriminatory or predatory pricing" and only feeds its AI system aggregated data "to enhance our existing fare pricing processes."&lt;/p&gt;
&lt;p&gt;Rather than basing fare prices on customers' personal information, Carter clarified that "all customers have access to the same fares and offers based on objective criteria provided by the customer such as origin and destination, advance purchase, length of stay, refundability, and travel experience selected."&lt;/p&gt;
&lt;p&gt;The AI use can result in higher or lower prices, but not personalized fares for different customers, Carter said. Instead, Delta plans to use AI pricing to "enhance market competitiveness and drive sales, benefiting both our customers and our business."&lt;/p&gt;
&lt;p&gt;Factors weighed by the AI system, Carter explained, include "customer demand for seats and purchasing data at an aggregated level, competitive offers and schedules, route performance, and cost of providing the service inclusive of jet fuel." That could potentially mean a rival's promotion or schedule change could trigger the AI system to lower prices to stay competitive, or it might increase prices based on rising fuel costs to help increase revenue or meet business goals.&lt;/p&gt;
&lt;p&gt;"Given the tens of millions of fares and hundreds of thousands of routes for sale at any given time, the use of new technology like AI promises to streamline the process by which we analyze existing data and the speed and scale at which we can respond to changing market dynamics," Carter wrote.&lt;/p&gt;
&lt;p&gt;He explained the AI system helps Delta aggregate purchasing data for specific routes and flights, adapt to new market conditions, and factor in "thousands of variables simultaneously." AI could also eventually be used to assist with crew scheduling, improve flight availability, or help reservation specialists answer complex questions or resolve disputes.&lt;/p&gt;
&lt;p&gt;But "to reiterate, prices are not targeted to individual consumers," Carter emphasized.&lt;/p&gt;
&lt;p&gt;Delta further pointed out that the company does not require customers to log in to search for tickets, which means customers can search for flights without sharing any personal information.&lt;/p&gt;
&lt;p&gt;For AI companies paying attention to the Delta backlash, there may be a lesson about the value of transparency in Delta's scandal. Critics noted Delta was among the first to admit it was using AI to influence pricing, but the vague explanation on the earnings call stoked confusion over how, as Delta seemed to drag its feet amid calls by groups like Consumer Watchdog for more transparency.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Delta finally explains how its AI pricing works amid ongoing backlash.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Delta spent July dealing with backlash over what the airline company claims is widespread public confusion over its AI pricing system.&lt;/p&gt;
&lt;p&gt;Now, Delta has finally come forward to break down precisely how the AI pricing works to dispute what it claims are "incorrect" characterizations by consumer watchdogs, lawmakers, and media outlets.&lt;/p&gt;
&lt;p&gt;In a letter to lawmakers who accused Delta of using AI to spy on customers' personal data in order to "jack up" prices, Delta insisted that "there is no fare product Delta has ever used, is testing, or plans to use that targets customers with individualized prices based on personal data."&lt;/p&gt;
&lt;p&gt;Confusion arose after Delta Air Lines President Glen William Hauenstein discussed the AI pricing on a summer earnings call. Hauenstein hyped the AI pricing as working to propel revenue, confirming that about 3 percent of domestic flights were sold using the AI pricing system over the past six months and that Delta planned to expand that to 20 percent of tickets by the end of the year.&lt;/p&gt;
&lt;p&gt;Critics demanded transparency, raising concerns that Delta's AI pricing could lead to discriminatory pricing based on a customer's search history or prior purchases. But Delta did not rush to clarify how its AI pricing actually works until lawmakers sent a letter probing Delta's AI practices. Those lawmakers had just announced the Stop AI Price Gouging and Wage Fixing Act, with a press release that called out Delta among companies whose AI pricing models needed to be banned to prevent surveillance pricing that lawmakers fear will disproportionately disrupt fair pricing for the least wealthy.&lt;/p&gt;
&lt;p&gt;Responding, Delta's chief external affairs officer, Peter Carter, thanked lawmakers for their "thoughtful questions regarding Delta’s use of AI," then cautioned them against making assumptions about Delta's AI pricing.&lt;/p&gt;
&lt;p&gt;"Your letter presupposes that we are using, and intend to use, AI for 'individualized' pricing or 'surveillance' pricing, leveraging consumer-specific personal data, such as sensitive personal circumstances or prior purchasing activity to set individualized prices," Carter said. "To clarify, this is incorrect and this assumption, unfortunately, has created confusion and misinformation in the public discourse."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Delta scandal highlights value of transparency&lt;/h2&gt;
&lt;p&gt;According to Delta, the company has "zero tolerance for discriminatory or predatory pricing" and only feeds its AI system aggregated data "to enhance our existing fare pricing processes."&lt;/p&gt;
&lt;p&gt;Rather than basing fare prices on customers' personal information, Carter clarified that "all customers have access to the same fares and offers based on objective criteria provided by the customer such as origin and destination, advance purchase, length of stay, refundability, and travel experience selected."&lt;/p&gt;
&lt;p&gt;The AI use can result in higher or lower prices, but not personalized fares for different customers, Carter said. Instead, Delta plans to use AI pricing to "enhance market competitiveness and drive sales, benefiting both our customers and our business."&lt;/p&gt;
&lt;p&gt;Factors weighed by the AI system, Carter explained, include "customer demand for seats and purchasing data at an aggregated level, competitive offers and schedules, route performance, and cost of providing the service inclusive of jet fuel." That could potentially mean a rival's promotion or schedule change could trigger the AI system to lower prices to stay competitive, or it might increase prices based on rising fuel costs to help increase revenue or meet business goals.&lt;/p&gt;
&lt;p&gt;"Given the tens of millions of fares and hundreds of thousands of routes for sale at any given time, the use of new technology like AI promises to streamline the process by which we analyze existing data and the speed and scale at which we can respond to changing market dynamics," Carter wrote.&lt;/p&gt;
&lt;p&gt;He explained the AI system helps Delta aggregate purchasing data for specific routes and flights, adapt to new market conditions, and factor in "thousands of variables simultaneously." AI could also eventually be used to assist with crew scheduling, improve flight availability, or help reservation specialists answer complex questions or resolve disputes.&lt;/p&gt;
&lt;p&gt;But "to reiterate, prices are not targeted to individual consumers," Carter emphasized.&lt;/p&gt;
&lt;p&gt;Delta further pointed out that the company does not require customers to log in to search for tickets, which means customers can search for flights without sharing any personal information.&lt;/p&gt;
&lt;p&gt;For AI companies paying attention to the Delta backlash, there may be a lesson about the value of transparency in Delta's scandal. Critics noted Delta was among the first to admit it was using AI to influence pricing, but the vague explanation on the earnings call stoked confusion over how, as Delta seemed to drag its feet amid calls by groups like Consumer Watchdog for more transparency.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/delta-denies-using-ai-to-come-up-with-inflated-personalized-prices/</guid><pubDate>Fri, 01 Aug 2025 19:07:48 +0000</pubDate></item><item><title>A backlog at the Commerce Department is reportedly stalling Nvidia’s H20 chip licenses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/a-backlog-at-the-commerce-department-is-reportedly-stalling-nvidias-h20-chip-licenses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier in July, U.S. Secretary of Commerce Howard Lutnick gave chipmakers like Nvidia the green light to start selling certain AI chips in China again, but his department is said to be holding things up. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from Reuters, Nvidia has yet to receive a license to sell its H20 AI chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is currently sitting on a backlog of licensing applications due to turmoil within the department, in large part because of a loss of staff and a breakdown in communications with the industry, per Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This holdup comes as national security experts are urging the Trump administration to restrict Nvidia from selling its H20 AI chips to China on national security grounds.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier in July, U.S. Secretary of Commerce Howard Lutnick gave chipmakers like Nvidia the green light to start selling certain AI chips in China again, but his department is said to be holding things up. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from Reuters, Nvidia has yet to receive a license to sell its H20 AI chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is currently sitting on a backlog of licensing applications due to turmoil within the department, in large part because of a loss of staff and a breakdown in communications with the industry, per Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This holdup comes as national security experts are urging the Trump administration to restrict Nvidia from selling its H20 AI chips to China on national security grounds.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/a-backlog-at-the-commerce-department-is-reportedly-stalling-nvidias-h20-chip-licenses/</guid><pubDate>Fri, 01 Aug 2025 20:30:14 +0000</pubDate></item><item><title>At $250 million, top AI salaries dwarf those of the Manhattan Project and the Space Race (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand holding lots of dollar notes" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand holding lots of dollar notes" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Paper Boat Creative via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Silicon Valley's AI talent war just reached a compensation milestone that makes even the most legendary scientific achievements of the past look financially modest. When Meta recently offered AI researcher Matt Deitke $250 million over four years (an average of $62.5 million per year)—with potentially $100 million in the first year alone—it shattered every historical precedent for scientific and technical compensation we can find on record. That includes salaries during the development of major scientific milestones of the 20th century.&lt;/p&gt;
&lt;p&gt;The New York Times reported that Deitke had cofounded a startup called Vercept and previously led the development of Molmo, a multimodal AI system, at the Allen Institute for Artificial Intelligence. His expertise in systems that juggle images, sounds, and text—exactly the kind of technology Meta wants to build—made him a prime target for recruitment. But he's not alone: Meta CEO Mark Zuckerberg reportedly also offered an unnamed AI engineer $1 billion in compensation to be paid out over several years. What's going on?&lt;/p&gt;
&lt;p&gt;These astronomical sums reflect what tech companies believe is at stake: a race to create artificial general intelligence (AGI) or superintelligence—machines capable of performing intellectual tasks at or beyond the human level. Meta, Google, OpenAI, and others are betting that whoever achieves this breakthrough first could dominate markets worth trillions. Whether this vision is realistic or merely Silicon Valley hype, it's driving compensation to unprecedented levels.&lt;/p&gt;
&lt;p&gt;To put these salaries in a historical perspective: J. Robert Oppenheimer, who led the Manhattan Project that ended World War II, earned approximately $10,000 per year in 1943. Adjusted for inflation using the US Government's CPI Inflation Calculator, that's about $190,865 in today's dollars—roughly what a senior software engineer makes today. The 24-year-old Deitke, who recently dropped out of a PhD program, will earn approximately 327 times what Oppenheimer made while developing the atomic bomb.&lt;/p&gt;
&lt;p&gt;Many top athletes can't compete with these numbers. The New York Times noted that Steph Curry's most recent four-year contract with the Golden State Warriors was $35 million less than Deitke's Meta deal (although soccer superstar Cristiano Ronaldo will make $275 million this year as the highest-paid professional athlete in the world).&amp;nbsp; The comparison prompted observers to call this an "NBA-style" talent market—except the AI researchers are making more than NBA stars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Racing toward “superintelligence”&lt;/h2&gt;
&lt;p&gt;Mark Zuckerberg recently told investors that Meta plans to continue throwing money at AI talent "because we have conviction that superintelligence is going to improve every aspect of what we do." In a recent open letter, he described superintelligent AI as technology that would "begin an exciting new era of individual empowerment," despite declining to define what superintelligence actually is.&lt;/p&gt;
&lt;p&gt;This vision explains why companies treat AI researchers like irreplaceable assets rather than well-compensated professionals. If these companies are correct, the first to achieve artificial general intelligence or superintelligence won't just have a better product—they'll have technology that could invent endless new products or automate away millions of knowledge-worker jobs and transform the global economy. The company that controls that kind of technology could become the richest company in history by far.&lt;/p&gt;
&lt;p&gt;So perhaps it's not surprising that even the highest salaries of employees from the early tech era pale in comparison to today's AI researcher salaries. Thomas Watson Sr., IBM's legendary CEO, received $517,221 in 1941—the third-highest salary in America at the time (about $11.8 million in 2025 dollars). The modern AI researcher's package represents more than five times Watson's peak compensation, despite Watson building one of the 20th century's most dominant technology companies.&lt;/p&gt;
&lt;p&gt;The contrast becomes even more stark when considering the collaborative nature of past scientific achievements. During Bell Labs' golden age of innovation—when researchers developed the transistor, information theory, and other foundational technologies—the lab's director made about 12 times what the lowest-paid worker earned.&amp;nbsp; Meanwhile, Claude Shannon, who created information theory at Bell Labs in 1948, worked on a standard professional salary while creating the mathematical foundation for all modern communication.&lt;/p&gt;
&lt;p&gt;The "Traitorous Eight" who left William Shockley to found Fairchild Semiconductor—the company that essentially birthed Silicon Valley—split ownership of just 800 shares out of 1,325 total when they started. Their seed funding of $1.38 million (about $16.1 million today) for the entire company is a fraction of what a single AI researcher now commands.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Even Space Race salaries were far cheaper&lt;/h2&gt;
&lt;p&gt;The Apollo program offers another striking comparison. Neil Armstrong, the first human to walk on the moon, earned about $27,000 annually—roughly $244,639 in today's money. His crewmates Buzz Aldrin and Michael Collins made even less, earning the equivalent of $168,737 and $155,373, respectively, in today's dollars. Current NASA astronauts earn between $104,898 and $161,141 per year. Meta's AI researcher will make more in three days than Armstrong made in a year for taking "one giant leap for mankind."&lt;/p&gt;
&lt;p&gt;The engineers who designed the rockets and mission control systems for the Apollo program also earned modest salaries by modern standards. A 1970 NASA technical report provides a window into these earnings by analyzing salary data for the entire engineering profession. The report, which used data from the Engineering Manpower Commission, noted that these industry-wide salary curves corresponded directly to the government's General Schedule (GS) pay scale on which NASA's own employees were paid.&lt;/p&gt;
&lt;p&gt;According to a chart in the 1970 report, a newly graduated engineer in 1966 started with an annual salary of between $8,500 and $10,000 (about $84,622 to $99,555 today). A typical engineer with a decade of experience earned around $17,000 annually ($169,244 today). Even the most elite, top-performing engineers with 20 years of experience peaked at a salary of around $278,000 per year in today's dollars—a sum that a top AI researcher like Deitke can now earn in just a few days.&lt;/p&gt;
&lt;h2&gt;Why the AI talent market is different&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2103443 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An image of a faceless human silhouette (chest up) with exposed microchip contacts and circuitry erupting from its open head. This visual metaphor explores transhumanism, AI integration, or the erosion of organic thought in the digital age. The stark contrast between the biological silhouette and mechanical components highlights themes of technological dependence or posthuman evolution. Ideal for articles on neural implants, futurism, or the ethics of human augmentation." class="center large" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2214539478-1024x640.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Boris Zhitkov via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn't the first time technical talent has commanded premium prices. In 2012, after three University of Toronto academics published AI research, they auctioned themselves to Google for $44 million (about $62.6 million in today's dollars). By 2014, a Microsoft executive was comparing AI researcher salaries to NFL quarterback contracts. But today's numbers dwarf even those precedents.&lt;/p&gt;
&lt;p&gt;Several factors explain this unprecedented compensation explosion. We're in a new realm of industrial wealth concentration unseen since the Gilded Age of the late 19th century. Unlike previous scientific endeavors, today's AI race features multiple companies with trillion-dollar valuations competing for an extremely limited talent pool. Only a small number of researchers have the specific expertise needed to work on the most capable AI systems, particularly in areas like multimodal AI, which Deitke specializes in. And AI hype is currently off the charts as "the next big thing" in technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The economics also differ fundamentally from past projects. The Manhattan Project cost $1.9 billion total (about $34.4 billion adjusted for inflation), while Meta alone plans to spend tens of billions annually on AI infrastructure. For a company approaching a $2 trillion market cap, the potential payoff from achieving AGI first dwarfs Deitke's compensation package.&lt;/p&gt;
&lt;p&gt;One executive put it bluntly to The New York Times: "If I'm Zuck and I'm spending $80 billion in one year on capital expenditures alone, is it worth kicking in another $5 billion or more to acquire a truly world-class team to bring the company to the next level? The answer is obviously yes."&lt;/p&gt;
&lt;p&gt;Young researchers maintain private chat groups on Slack and Discord to share offer details and negotiation strategies. Some hire unofficial agents. Companies not only offer massive cash and stock packages but also computing resources—the NYT reported that some potential hires were told they would be allotted 30,000 GPUs, the specialized chips that power AI development.&lt;/p&gt;
&lt;p&gt;Also, tech companies believe they're engaged in an arms race where the winner could reshape civilization. Unlike the Manhattan Project or Apollo program, which had specific, limited goals, the race for artificial general intelligence ostensibly has no ceiling. A machine that can match human intelligence could theoretically improve itself, creating what researchers call an "intelligence explosion" that could potentially offer cascading discoveries—if it actually comes to pass.&lt;/p&gt;
&lt;p&gt;Whether these companies are building humanity's ultimate labor replacement technology or merely chasing hype remains an open question, but we've certainly traveled a long way from the $8 per diem that Neil Armstrong received for his moon mission—about $70.51 in today's dollars—before deductions for the "accommodations" NASA provided on the spacecraft. After Deitke accepted Meta's offer, Vercept co-founder Kiana Ehsani joked on social media, "We look forward to joining Matt on his private island next year."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand holding lots of dollar notes" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand holding lots of dollar notes" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Paper Boat Creative via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Silicon Valley's AI talent war just reached a compensation milestone that makes even the most legendary scientific achievements of the past look financially modest. When Meta recently offered AI researcher Matt Deitke $250 million over four years (an average of $62.5 million per year)—with potentially $100 million in the first year alone—it shattered every historical precedent for scientific and technical compensation we can find on record. That includes salaries during the development of major scientific milestones of the 20th century.&lt;/p&gt;
&lt;p&gt;The New York Times reported that Deitke had cofounded a startup called Vercept and previously led the development of Molmo, a multimodal AI system, at the Allen Institute for Artificial Intelligence. His expertise in systems that juggle images, sounds, and text—exactly the kind of technology Meta wants to build—made him a prime target for recruitment. But he's not alone: Meta CEO Mark Zuckerberg reportedly also offered an unnamed AI engineer $1 billion in compensation to be paid out over several years. What's going on?&lt;/p&gt;
&lt;p&gt;These astronomical sums reflect what tech companies believe is at stake: a race to create artificial general intelligence (AGI) or superintelligence—machines capable of performing intellectual tasks at or beyond the human level. Meta, Google, OpenAI, and others are betting that whoever achieves this breakthrough first could dominate markets worth trillions. Whether this vision is realistic or merely Silicon Valley hype, it's driving compensation to unprecedented levels.&lt;/p&gt;
&lt;p&gt;To put these salaries in a historical perspective: J. Robert Oppenheimer, who led the Manhattan Project that ended World War II, earned approximately $10,000 per year in 1943. Adjusted for inflation using the US Government's CPI Inflation Calculator, that's about $190,865 in today's dollars—roughly what a senior software engineer makes today. The 24-year-old Deitke, who recently dropped out of a PhD program, will earn approximately 327 times what Oppenheimer made while developing the atomic bomb.&lt;/p&gt;
&lt;p&gt;Many top athletes can't compete with these numbers. The New York Times noted that Steph Curry's most recent four-year contract with the Golden State Warriors was $35 million less than Deitke's Meta deal (although soccer superstar Cristiano Ronaldo will make $275 million this year as the highest-paid professional athlete in the world).&amp;nbsp; The comparison prompted observers to call this an "NBA-style" talent market—except the AI researchers are making more than NBA stars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Racing toward “superintelligence”&lt;/h2&gt;
&lt;p&gt;Mark Zuckerberg recently told investors that Meta plans to continue throwing money at AI talent "because we have conviction that superintelligence is going to improve every aspect of what we do." In a recent open letter, he described superintelligent AI as technology that would "begin an exciting new era of individual empowerment," despite declining to define what superintelligence actually is.&lt;/p&gt;
&lt;p&gt;This vision explains why companies treat AI researchers like irreplaceable assets rather than well-compensated professionals. If these companies are correct, the first to achieve artificial general intelligence or superintelligence won't just have a better product—they'll have technology that could invent endless new products or automate away millions of knowledge-worker jobs and transform the global economy. The company that controls that kind of technology could become the richest company in history by far.&lt;/p&gt;
&lt;p&gt;So perhaps it's not surprising that even the highest salaries of employees from the early tech era pale in comparison to today's AI researcher salaries. Thomas Watson Sr., IBM's legendary CEO, received $517,221 in 1941—the third-highest salary in America at the time (about $11.8 million in 2025 dollars). The modern AI researcher's package represents more than five times Watson's peak compensation, despite Watson building one of the 20th century's most dominant technology companies.&lt;/p&gt;
&lt;p&gt;The contrast becomes even more stark when considering the collaborative nature of past scientific achievements. During Bell Labs' golden age of innovation—when researchers developed the transistor, information theory, and other foundational technologies—the lab's director made about 12 times what the lowest-paid worker earned.&amp;nbsp; Meanwhile, Claude Shannon, who created information theory at Bell Labs in 1948, worked on a standard professional salary while creating the mathematical foundation for all modern communication.&lt;/p&gt;
&lt;p&gt;The "Traitorous Eight" who left William Shockley to found Fairchild Semiconductor—the company that essentially birthed Silicon Valley—split ownership of just 800 shares out of 1,325 total when they started. Their seed funding of $1.38 million (about $16.1 million today) for the entire company is a fraction of what a single AI researcher now commands.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Even Space Race salaries were far cheaper&lt;/h2&gt;
&lt;p&gt;The Apollo program offers another striking comparison. Neil Armstrong, the first human to walk on the moon, earned about $27,000 annually—roughly $244,639 in today's money. His crewmates Buzz Aldrin and Michael Collins made even less, earning the equivalent of $168,737 and $155,373, respectively, in today's dollars. Current NASA astronauts earn between $104,898 and $161,141 per year. Meta's AI researcher will make more in three days than Armstrong made in a year for taking "one giant leap for mankind."&lt;/p&gt;
&lt;p&gt;The engineers who designed the rockets and mission control systems for the Apollo program also earned modest salaries by modern standards. A 1970 NASA technical report provides a window into these earnings by analyzing salary data for the entire engineering profession. The report, which used data from the Engineering Manpower Commission, noted that these industry-wide salary curves corresponded directly to the government's General Schedule (GS) pay scale on which NASA's own employees were paid.&lt;/p&gt;
&lt;p&gt;According to a chart in the 1970 report, a newly graduated engineer in 1966 started with an annual salary of between $8,500 and $10,000 (about $84,622 to $99,555 today). A typical engineer with a decade of experience earned around $17,000 annually ($169,244 today). Even the most elite, top-performing engineers with 20 years of experience peaked at a salary of around $278,000 per year in today's dollars—a sum that a top AI researcher like Deitke can now earn in just a few days.&lt;/p&gt;
&lt;h2&gt;Why the AI talent market is different&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2103443 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An image of a faceless human silhouette (chest up) with exposed microchip contacts and circuitry erupting from its open head. This visual metaphor explores transhumanism, AI integration, or the erosion of organic thought in the digital age. The stark contrast between the biological silhouette and mechanical components highlights themes of technological dependence or posthuman evolution. Ideal for articles on neural implants, futurism, or the ethics of human augmentation." class="center large" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2214539478-1024x640.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Boris Zhitkov via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn't the first time technical talent has commanded premium prices. In 2012, after three University of Toronto academics published AI research, they auctioned themselves to Google for $44 million (about $62.6 million in today's dollars). By 2014, a Microsoft executive was comparing AI researcher salaries to NFL quarterback contracts. But today's numbers dwarf even those precedents.&lt;/p&gt;
&lt;p&gt;Several factors explain this unprecedented compensation explosion. We're in a new realm of industrial wealth concentration unseen since the Gilded Age of the late 19th century. Unlike previous scientific endeavors, today's AI race features multiple companies with trillion-dollar valuations competing for an extremely limited talent pool. Only a small number of researchers have the specific expertise needed to work on the most capable AI systems, particularly in areas like multimodal AI, which Deitke specializes in. And AI hype is currently off the charts as "the next big thing" in technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The economics also differ fundamentally from past projects. The Manhattan Project cost $1.9 billion total (about $34.4 billion adjusted for inflation), while Meta alone plans to spend tens of billions annually on AI infrastructure. For a company approaching a $2 trillion market cap, the potential payoff from achieving AGI first dwarfs Deitke's compensation package.&lt;/p&gt;
&lt;p&gt;One executive put it bluntly to The New York Times: "If I'm Zuck and I'm spending $80 billion in one year on capital expenditures alone, is it worth kicking in another $5 billion or more to acquire a truly world-class team to bring the company to the next level? The answer is obviously yes."&lt;/p&gt;
&lt;p&gt;Young researchers maintain private chat groups on Slack and Discord to share offer details and negotiation strategies. Some hire unofficial agents. Companies not only offer massive cash and stock packages but also computing resources—the NYT reported that some potential hires were told they would be allotted 30,000 GPUs, the specialized chips that power AI development.&lt;/p&gt;
&lt;p&gt;Also, tech companies believe they're engaged in an arms race where the winner could reshape civilization. Unlike the Manhattan Project or Apollo program, which had specific, limited goals, the race for artificial general intelligence ostensibly has no ceiling. A machine that can match human intelligence could theoretically improve itself, creating what researchers call an "intelligence explosion" that could potentially offer cascading discoveries—if it actually comes to pass.&lt;/p&gt;
&lt;p&gt;Whether these companies are building humanity's ultimate labor replacement technology or merely chasing hype remains an open question, but we've certainly traveled a long way from the $8 per diem that Neil Armstrong received for his moon mission—about $70.51 in today's dollars—before deductions for the "accommodations" NASA provided on the spacecraft. After Deitke accepted Meta's offer, Vercept co-founder Kiana Ehsani joked on social media, "We look forward to joining Matt on his private island next year."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/</guid><pubDate>Fri, 01 Aug 2025 21:23:42 +0000</pubDate></item><item><title>[NEW] New vision model from Cohere runs on two GPUs, beats top-tier VLMs on visual tasks (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/new-vision-model-from-cohere-runs-on-two-gpus-beats-top-tier-vlms-on-visual-tasks/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rise in Deep Research features and other AI-powered analysis has given rise to more models and services looking to simplify that process and read more of the documents businesses actually use.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Canadian AI company Cohere is banking on its models, including a newly released visual model, to make the case that Deep Research features should also be optimized for enterprise use cases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company has released Command A Vision, a visual model specifically targeting enterprise use cases, built on the back of its Command A model. The 112 billion parameter model can “unlock valuable insights from visual data, and make highly accurate, data-driven decisions through document optical character recognition (OCR) and image analysis,” the company says. &lt;/p&gt;



&lt;p&gt;“Whether it’s interpreting product manuals with complex diagrams or analyzing photographs of real-world scenes for risk detection, Command A Vision excels at tackling the most demanding enterprise vision challenges,” the company said in a blog post.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This means Command A Vision can read and analyze the most common types of images enterprises need: graphs, charts, diagrams, scanned documents and PDFs.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;? @cohere just dropped Command A Vision on @huggingface  ?&lt;/p&gt;&lt;p&gt;Designed for enterprise multimodal use cases: interpreting product manuals, analyzing photos, asking about charts… ❓??&lt;/p&gt;&lt;p&gt;A 112B dense vision-language model with SOTA performance – check out the benchmark metrics in… pic.twitter.com/ORMfM5f8cF&lt;/p&gt;— Jeff Boudier ? (@jeffboudier) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Since it’s built on Command A’s architecture, Command A Vision requires two or fewer GPUs, just like the text model. The vision model also retains the text capabilities of Command A to read words on images and understands at least 23 languages. Cohere said that, unlike other models, Command A Vision reduces the total cost of ownership for enterprises and is fully optimized for retrieval use cases for businesses.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-cohere-is-architecting-command-a"&gt;How Cohere is architecting Command A&lt;/h2&gt;



&lt;p&gt;Cohere said it followed a Llava architecture to build its Command A models, including the visual model. This architecture turns visual features into soft vision tokens, which can be divided into different tiles.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These tiles are passed into the Command A text tower, “a dense, 111B parameters textual LLM,” the company said. “In this manner, a single image consumes up to 3,328 tokens.”&lt;/p&gt;



&lt;p&gt;Cohere said it trained the visual model in three stages: vision-language alignment, supervised fine-tuning (SFT) and post-training reinforcement learning with human feedback (RLHF).&lt;/p&gt;



&lt;p&gt;“This approach enables the mapping of image encoder features to the language model embedding space,” the company said. “In contrast, during the SFT stage, we simultaneously trained the vision encoder, the vision adapter and the language model on a diverse set of instruction-following multimodal tasks.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-visualizing-enterprise-ai-nbsp"&gt;Visualizing enterprise AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Benchmark tests showed Command A Vision outperforming other models with similar visual capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Cohere pitted Command A Vision against OpenAI’s GPT 4.1, Meta’s Llama 4 Maverick, Mistral’s Pixtral Large and Mistral Medium 3 in nine benchmark tests. The company did not mention if it tested the model against Mistral’s OCR-focused API, Mistral OCR.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It enables agents to securely see inside your organization’s visual data, unlocking the automation of tedious tasks involving slides, diagrams, PDFs, and photos. pic.twitter.com/iHZnUWekrk&lt;/p&gt;— cohere (@cohere) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Command A Vision outscored the other models in tests such as ChartQA, OCRBench, AI2D and TextVQA. Overall, Command A Vision had an average score of 83.1% compared to GPT 4.1’s 78.6%, Llama 4 Maverick’s 80.5% and the 78.3% from Mistral Medium 3.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcSCnFTJrO6NF-S-eFsFHUhCdJaM1xHBNqkNcTjYv8igsOjBmtZYa8IAo0WiTapRQkSAP92LzXGE77B5EOWjlwPksCdsatx10o6SlehYtg9JDwBQNOa2E8cRdKQ2BRz-l5xbWBosg?key=Vfq9RrNgfcLbbqBNE4F1QQ" /&gt;&lt;/figure&gt;



&lt;p&gt;Most large language models (LLMs) these days are multimodal, meaning they can generate or understand visual media like photos or videos. However, enterprises generally use more graphical documents such as charts and PDFs, so extracting information from these unstructured data sources often proves difficult.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With Deep Research on the rise, the importance of bringing in models capable of reading, analyzing and even downloading unstructured data has grown.&lt;/p&gt;



&lt;p&gt;Cohere also said it’s offering Command A Vision in an open weights system, in hopes that enterprises looking to move away from closed or proprietary models will start using its products.&amp;nbsp;So far, there is some interest from developers.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Very impressed at its accuracy extracting hand handwritten notes from an image!&lt;/p&gt;— Adam Sardo (@sardo_adam) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Finally, an AI that won’t judge my terrible doodles.&lt;/p&gt;— Martha Wisener ? (@martwisener) August 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rise in Deep Research features and other AI-powered analysis has given rise to more models and services looking to simplify that process and read more of the documents businesses actually use.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Canadian AI company Cohere is banking on its models, including a newly released visual model, to make the case that Deep Research features should also be optimized for enterprise use cases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company has released Command A Vision, a visual model specifically targeting enterprise use cases, built on the back of its Command A model. The 112 billion parameter model can “unlock valuable insights from visual data, and make highly accurate, data-driven decisions through document optical character recognition (OCR) and image analysis,” the company says. &lt;/p&gt;



&lt;p&gt;“Whether it’s interpreting product manuals with complex diagrams or analyzing photographs of real-world scenes for risk detection, Command A Vision excels at tackling the most demanding enterprise vision challenges,” the company said in a blog post.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This means Command A Vision can read and analyze the most common types of images enterprises need: graphs, charts, diagrams, scanned documents and PDFs.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;? @cohere just dropped Command A Vision on @huggingface  ?&lt;/p&gt;&lt;p&gt;Designed for enterprise multimodal use cases: interpreting product manuals, analyzing photos, asking about charts… ❓??&lt;/p&gt;&lt;p&gt;A 112B dense vision-language model with SOTA performance – check out the benchmark metrics in… pic.twitter.com/ORMfM5f8cF&lt;/p&gt;— Jeff Boudier ? (@jeffboudier) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Since it’s built on Command A’s architecture, Command A Vision requires two or fewer GPUs, just like the text model. The vision model also retains the text capabilities of Command A to read words on images and understands at least 23 languages. Cohere said that, unlike other models, Command A Vision reduces the total cost of ownership for enterprises and is fully optimized for retrieval use cases for businesses.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-cohere-is-architecting-command-a"&gt;How Cohere is architecting Command A&lt;/h2&gt;



&lt;p&gt;Cohere said it followed a Llava architecture to build its Command A models, including the visual model. This architecture turns visual features into soft vision tokens, which can be divided into different tiles.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These tiles are passed into the Command A text tower, “a dense, 111B parameters textual LLM,” the company said. “In this manner, a single image consumes up to 3,328 tokens.”&lt;/p&gt;



&lt;p&gt;Cohere said it trained the visual model in three stages: vision-language alignment, supervised fine-tuning (SFT) and post-training reinforcement learning with human feedback (RLHF).&lt;/p&gt;



&lt;p&gt;“This approach enables the mapping of image encoder features to the language model embedding space,” the company said. “In contrast, during the SFT stage, we simultaneously trained the vision encoder, the vision adapter and the language model on a diverse set of instruction-following multimodal tasks.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-visualizing-enterprise-ai-nbsp"&gt;Visualizing enterprise AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Benchmark tests showed Command A Vision outperforming other models with similar visual capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Cohere pitted Command A Vision against OpenAI’s GPT 4.1, Meta’s Llama 4 Maverick, Mistral’s Pixtral Large and Mistral Medium 3 in nine benchmark tests. The company did not mention if it tested the model against Mistral’s OCR-focused API, Mistral OCR.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It enables agents to securely see inside your organization’s visual data, unlocking the automation of tedious tasks involving slides, diagrams, PDFs, and photos. pic.twitter.com/iHZnUWekrk&lt;/p&gt;— cohere (@cohere) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Command A Vision outscored the other models in tests such as ChartQA, OCRBench, AI2D and TextVQA. Overall, Command A Vision had an average score of 83.1% compared to GPT 4.1’s 78.6%, Llama 4 Maverick’s 80.5% and the 78.3% from Mistral Medium 3.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcSCnFTJrO6NF-S-eFsFHUhCdJaM1xHBNqkNcTjYv8igsOjBmtZYa8IAo0WiTapRQkSAP92LzXGE77B5EOWjlwPksCdsatx10o6SlehYtg9JDwBQNOa2E8cRdKQ2BRz-l5xbWBosg?key=Vfq9RrNgfcLbbqBNE4F1QQ" /&gt;&lt;/figure&gt;



&lt;p&gt;Most large language models (LLMs) these days are multimodal, meaning they can generate or understand visual media like photos or videos. However, enterprises generally use more graphical documents such as charts and PDFs, so extracting information from these unstructured data sources often proves difficult.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With Deep Research on the rise, the importance of bringing in models capable of reading, analyzing and even downloading unstructured data has grown.&lt;/p&gt;



&lt;p&gt;Cohere also said it’s offering Command A Vision in an open weights system, in hopes that enterprises looking to move away from closed or proprietary models will start using its products.&amp;nbsp;So far, there is some interest from developers.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Very impressed at its accuracy extracting hand handwritten notes from an image!&lt;/p&gt;— Adam Sardo (@sardo_adam) July 31, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Finally, an AI that won’t judge my terrible doodles.&lt;/p&gt;— Martha Wisener ? (@martwisener) August 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/new-vision-model-from-cohere-runs-on-two-gpus-beats-top-tier-vlms-on-visual-tasks/</guid><pubDate>Fri, 01 Aug 2025 22:05:20 +0000</pubDate></item></channel></rss>