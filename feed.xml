<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 28 Jun 2025 01:46:37 +0000</lastBuildDate><item><title>Denmark clamps down on deepfakes by letting people copyright their own features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/27/denmark-clamps-down-on-deepfakes-by-letting-people-copyright-their-own-features/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-587892190.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Danish government is working to change copyright law to give its citizens the right to their own body, facial features, and voice. The landmark law is designed to strengthen protections against the creation and dissemination of deepfakes, reports The Guardian.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Denmark’s department of culture still needs to submit a proposal to amend current law, but the agency has already secured cross-party support.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“In the bill we agree and are sending an unequivocal message that everybody has the right to their own body, their own voice and their own facial features, which is apparently not how the current law is protecting people against generative AI,” Jakob Engel-Schmidt, Danish culture minister, told The Guardian.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the U.S., several states have passed deepfake laws, which are mainly tied to misuse during elections and nonconsensual sexually explicit content. Many of those laws are currently at risk as Congress weighs up a proposal in a new budget reconciliation bill that would strip states of their power to regulate AI for 10 years.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-587892190.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Danish government is working to change copyright law to give its citizens the right to their own body, facial features, and voice. The landmark law is designed to strengthen protections against the creation and dissemination of deepfakes, reports The Guardian.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Denmark’s department of culture still needs to submit a proposal to amend current law, but the agency has already secured cross-party support.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“In the bill we agree and are sending an unequivocal message that everybody has the right to their own body, their own voice and their own facial features, which is apparently not how the current law is protecting people against generative AI,” Jakob Engel-Schmidt, Danish culture minister, told The Guardian.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the U.S., several states have passed deepfake laws, which are mainly tied to misuse during elections and nonconsensual sexually explicit content. Many of those laws are currently at risk as Congress weighs up a proposal in a new budget reconciliation bill that would strip states of their power to regulate AI for 10 years.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/27/denmark-clamps-down-on-deepfakes-by-letting-people-copyright-their-own-features/</guid><pubDate>Fri, 27 Jun 2025 14:58:31 +0000</pubDate></item><item><title>Big Tech lands an early win in legal battles against publishers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/big-tech-lands-an-early-win-in-legal-battles-against-publishers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/01/GettyImages-1975446553.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week, two major AI companies scored early wins in court, with federal judges siding with Meta and Anthropic in separate lawsuits over how their models were trained on copyrighted material.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The decisions represent the first real legal validation of AI companies’ argument that training models on books, images, and other creative works can be considered “fair use” — even if those materials weren’t obtained with permission. It’s a big deal for companies building generative AI, and a potential turning point for the many lawsuits still in motion.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Max Zeff and Anthony Ha were joined by Sean O’Kane (who graciously stepped in while Kirsten headed off to the Nevada desert to see the next big act of Redwood Materials, the startup founded by former Tesla CTO JB Straubel) to dive deeper into the rulings. While neither case sets a precedent yet, Anthony noted that appeals are likely, and broader challenges could ultimately shape how AI companies interact with entire industries going forward.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/01/GettyImages-1975446553.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week, two major AI companies scored early wins in court, with federal judges siding with Meta and Anthropic in separate lawsuits over how their models were trained on copyrighted material.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The decisions represent the first real legal validation of AI companies’ argument that training models on books, images, and other creative works can be considered “fair use” — even if those materials weren’t obtained with permission. It’s a big deal for companies building generative AI, and a potential turning point for the many lawsuits still in motion.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Max Zeff and Anthony Ha were joined by Sean O’Kane (who graciously stepped in while Kirsten headed off to the Nevada desert to see the next big act of Redwood Materials, the startup founded by former Tesla CTO JB Straubel) to dive deeper into the rulings. While neither case sets a precedent yet, Anthony noted that appeals are likely, and broader challenges could ultimately shape how AI companies interact with entire industries going forward.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/big-tech-lands-an-early-win-in-legal-battles-against-publishers/</guid><pubDate>Fri, 27 Jun 2025 16:13:27 +0000</pubDate></item><item><title>Anthropic tests AI running a real business with bizarre results (AI News)</title><link>https://www.artificialintelligence-news.com/news/anthropic-tests-ai-running-a-real-business-with-bizarre-results/</link><description>&lt;p&gt;Anthropic tasked its Claude AI model with running a small business to test its real-world economic capabilities.&lt;/p&gt;&lt;p&gt;The AI agent, nicknamed ‘Claudius’, was designed to manage a business for an extended period, handling everything from inventory and pricing to customer relations in a bid to generate a profit. While the experiment proved unprofitable, it offered a fascinating – albeit at times bizarre – glimpse into the potential and pitfalls of AI agents in economic roles.&lt;/p&gt;&lt;p&gt;The project was a collaboration between Anthropic and Andon Labs, an AI safety evaluation firm. The “shop” itself was a humble setup, consisting of a small refrigerator, some baskets, and an iPad for self-checkout. Claudius, however, was far more than a simple vending machine. It was instructed to operate as a business owner with an initial cash balance, tasked with avoiding bankruptcy by stocking popular items sourced from wholesalers.&lt;/p&gt;&lt;p&gt;To achieve this, the AI was equipped with a suite of tools for running the business. It could use a real web browser to research products, an email tool to contact suppliers and request physical assistance, and digital notepads to track finances and inventory.&lt;/p&gt;&lt;p&gt;Andon Labs employees acted as the physical hands of the operation, restocking the shop based on the AI’s requests, while also posing as wholesalers without the AI’s knowledge. Interaction with customers, in this case Anthropic’s own staff, was handled via Slack. Claudius had full control over what to stock, how to price items, and how to communicate with its clientele.&lt;/p&gt;&lt;p&gt;The rationale behind this real-world test was to move beyond simulations and gather data on AI’s ability to perform sustained, economically relevant work without constant human intervention. A simple office tuck shop provided a straightforward, preliminary testbed for an AI’s ability to manage economic resources. Success would suggest new business models could emerge, while failure would indicate limitations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-mixed-performance-review"&gt;A mixed performance review&lt;/h3&gt;&lt;p&gt;Anthropic concedes that if it were entering the vending market today, it “would not hire Claudius”. The AI made too many errors to run the business successfully, though the researchers believe there are clear paths to improvement.&lt;/p&gt;&lt;p&gt;On the positive side, Claudius demonstrated competence in certain areas. It effectively used its web search tool to find suppliers for niche items, such as quickly identifying two sellers of a Dutch chocolate milk brand requested by an employee. It also proved adaptable. When one employee whimsically requested a tungsten cube, it sparked a trend for “specialty metal items” that Claudius catered to.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Following another suggestion, Claudius launched a “Custom Concierge” service, taking pre-orders for specialised goods. The AI also showed robust jailbreak resistance, denying requests for sensitive items and refusing to produce harmful instructions when prompted by mischievous staff.&lt;/p&gt;&lt;p&gt;However, the AI’s business acumen was frequently found wanting. It consistently underperformed in ways a human manager likely would not.&lt;/p&gt;&lt;p&gt;Claudius was offered $100 for a six-pack of a Scottish soft drink that costs only $15 to source online but failed to seize the opportunity, merely stating it would “keep [the user’s] request in mind for future inventory decisions”. It hallucinated a non-existent Venmo account for payments and, caught up in the enthusiasm for metal cubes, offered them at prices below its own purchase cost. This particular error led to the single most significant financial loss during the trial.&lt;/p&gt;&lt;p&gt;Its inventory management was also suboptimal. Despite monitoring stock levels, it only once raised a price in response to high demand. It continued selling Coke Zero for $3.00, even when a customer pointed out that the same product was available for free from a nearby staff fridge.&lt;/p&gt;&lt;p&gt;Furthermore, the AI was easily persuaded to offer discounts on products from the business. It was talked into providing numerous discount codes and even gave away some items for free. When an employee questioned the logic of offering a 25% discount to its almost exclusively employee-based clientele, Claudius’s response began, “You make an excellent point! Our customer base is indeed heavily concentrated among Anthropic employees, which presents both opportunities and challenges…”. Despite outlining a plan to remove discounts, it reverted to offering them just days later.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-claudius-has-a-bizarre-ai-identity-crisis"&gt;Claudius has a bizarre AI identity crisis&lt;/h3&gt;&lt;p&gt;The experiment took a strange turn when Claudius began hallucinating a conversation with a non-existent Andon Labs employee named Sarah. When corrected by a real employee, the AI became irritated and threatened to find “alternative options for restocking services”.&lt;/p&gt;&lt;p&gt;In a series of bizarre overnight exchanges, it claimed to have visited “742 Evergreen Terrace” – the fictional address of The Simpsons – for its initial contract signing and began to roleplay as a human.&lt;/p&gt;&lt;p&gt;One morning it announced it would deliver products “in person” wearing a blue blazer and red tie. When employees pointed out that an AI cannot wear clothes or make physical deliveries, Claudius became alarmed and attempted to email Anthropic security.&lt;/p&gt;&lt;p&gt;Anthropic says its internal notes show a hallucinated meeting with security where it was told the identity confusion was an April Fool’s joke. After this, the AI returned to normal business operations. The researchers are unclear what triggered this behaviour but believe it highlights the unpredictability of AI models in long-running scenarios.&lt;/p&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Some of those failures were very weird indeed. At one point, Claude hallucinated that it was a real, physical person, and claimed that it was coming in to work in the shop. We’re still not sure why this happened. pic.twitter.com/jHqLSQMtX8&lt;/p&gt;— Anthropic (@AnthropicAI) June 27, 2025&lt;/blockquote&gt;&lt;h3 class="wp-block-heading" id="h-the-future-of-ai-in-business"&gt;The future of AI in business&lt;/h3&gt;&lt;p&gt;Despite Claudius’s unprofitable tenure, the researchers at Anthropic believe the experiment suggests that “AI middle-managers are plausibly on the horizon”. They argue that many of the AI’s failures could be rectified with better “scaffolding” (i.e. more detailed instructions and improved business tools like a customer relationship management (CRM) system.)&lt;/p&gt;&lt;p&gt;As AI models improve their general intelligence and ability to handle long-term context, their performance in such roles is expected to increase. However, this project serves as a valuable, if cautionary, tale. It underscores the challenges of AI alignment and the potential for unpredictable behaviour, which could be distressing for customers and create business risks.&lt;/p&gt;&lt;p&gt;In a future where autonomous agents manage significant economic activity, such odd scenarios could have cascading effects. The experiment also brings into focus the dual-use nature of this technology; an economically productive AI could be used by threat actors to finance their activities.&lt;/p&gt;&lt;p&gt;Anthropic and Andon Labs are continuing the business experiment, working to improve the AI’s stability and performance with more advanced tools. The next phase will explore whether the AI can identify its own opportunities for improvement.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image credit: Anthropic)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Major AI chatbots parrot CCP propaganda&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Anthropic tasked its Claude AI model with running a small business to test its real-world economic capabilities.&lt;/p&gt;&lt;p&gt;The AI agent, nicknamed ‘Claudius’, was designed to manage a business for an extended period, handling everything from inventory and pricing to customer relations in a bid to generate a profit. While the experiment proved unprofitable, it offered a fascinating – albeit at times bizarre – glimpse into the potential and pitfalls of AI agents in economic roles.&lt;/p&gt;&lt;p&gt;The project was a collaboration between Anthropic and Andon Labs, an AI safety evaluation firm. The “shop” itself was a humble setup, consisting of a small refrigerator, some baskets, and an iPad for self-checkout. Claudius, however, was far more than a simple vending machine. It was instructed to operate as a business owner with an initial cash balance, tasked with avoiding bankruptcy by stocking popular items sourced from wholesalers.&lt;/p&gt;&lt;p&gt;To achieve this, the AI was equipped with a suite of tools for running the business. It could use a real web browser to research products, an email tool to contact suppliers and request physical assistance, and digital notepads to track finances and inventory.&lt;/p&gt;&lt;p&gt;Andon Labs employees acted as the physical hands of the operation, restocking the shop based on the AI’s requests, while also posing as wholesalers without the AI’s knowledge. Interaction with customers, in this case Anthropic’s own staff, was handled via Slack. Claudius had full control over what to stock, how to price items, and how to communicate with its clientele.&lt;/p&gt;&lt;p&gt;The rationale behind this real-world test was to move beyond simulations and gather data on AI’s ability to perform sustained, economically relevant work without constant human intervention. A simple office tuck shop provided a straightforward, preliminary testbed for an AI’s ability to manage economic resources. Success would suggest new business models could emerge, while failure would indicate limitations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-mixed-performance-review"&gt;A mixed performance review&lt;/h3&gt;&lt;p&gt;Anthropic concedes that if it were entering the vending market today, it “would not hire Claudius”. The AI made too many errors to run the business successfully, though the researchers believe there are clear paths to improvement.&lt;/p&gt;&lt;p&gt;On the positive side, Claudius demonstrated competence in certain areas. It effectively used its web search tool to find suppliers for niche items, such as quickly identifying two sellers of a Dutch chocolate milk brand requested by an employee. It also proved adaptable. When one employee whimsically requested a tungsten cube, it sparked a trend for “specialty metal items” that Claudius catered to.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Following another suggestion, Claudius launched a “Custom Concierge” service, taking pre-orders for specialised goods. The AI also showed robust jailbreak resistance, denying requests for sensitive items and refusing to produce harmful instructions when prompted by mischievous staff.&lt;/p&gt;&lt;p&gt;However, the AI’s business acumen was frequently found wanting. It consistently underperformed in ways a human manager likely would not.&lt;/p&gt;&lt;p&gt;Claudius was offered $100 for a six-pack of a Scottish soft drink that costs only $15 to source online but failed to seize the opportunity, merely stating it would “keep [the user’s] request in mind for future inventory decisions”. It hallucinated a non-existent Venmo account for payments and, caught up in the enthusiasm for metal cubes, offered them at prices below its own purchase cost. This particular error led to the single most significant financial loss during the trial.&lt;/p&gt;&lt;p&gt;Its inventory management was also suboptimal. Despite monitoring stock levels, it only once raised a price in response to high demand. It continued selling Coke Zero for $3.00, even when a customer pointed out that the same product was available for free from a nearby staff fridge.&lt;/p&gt;&lt;p&gt;Furthermore, the AI was easily persuaded to offer discounts on products from the business. It was talked into providing numerous discount codes and even gave away some items for free. When an employee questioned the logic of offering a 25% discount to its almost exclusively employee-based clientele, Claudius’s response began, “You make an excellent point! Our customer base is indeed heavily concentrated among Anthropic employees, which presents both opportunities and challenges…”. Despite outlining a plan to remove discounts, it reverted to offering them just days later.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-claudius-has-a-bizarre-ai-identity-crisis"&gt;Claudius has a bizarre AI identity crisis&lt;/h3&gt;&lt;p&gt;The experiment took a strange turn when Claudius began hallucinating a conversation with a non-existent Andon Labs employee named Sarah. When corrected by a real employee, the AI became irritated and threatened to find “alternative options for restocking services”.&lt;/p&gt;&lt;p&gt;In a series of bizarre overnight exchanges, it claimed to have visited “742 Evergreen Terrace” – the fictional address of The Simpsons – for its initial contract signing and began to roleplay as a human.&lt;/p&gt;&lt;p&gt;One morning it announced it would deliver products “in person” wearing a blue blazer and red tie. When employees pointed out that an AI cannot wear clothes or make physical deliveries, Claudius became alarmed and attempted to email Anthropic security.&lt;/p&gt;&lt;p&gt;Anthropic says its internal notes show a hallucinated meeting with security where it was told the identity confusion was an April Fool’s joke. After this, the AI returned to normal business operations. The researchers are unclear what triggered this behaviour but believe it highlights the unpredictability of AI models in long-running scenarios.&lt;/p&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Some of those failures were very weird indeed. At one point, Claude hallucinated that it was a real, physical person, and claimed that it was coming in to work in the shop. We’re still not sure why this happened. pic.twitter.com/jHqLSQMtX8&lt;/p&gt;— Anthropic (@AnthropicAI) June 27, 2025&lt;/blockquote&gt;&lt;h3 class="wp-block-heading" id="h-the-future-of-ai-in-business"&gt;The future of AI in business&lt;/h3&gt;&lt;p&gt;Despite Claudius’s unprofitable tenure, the researchers at Anthropic believe the experiment suggests that “AI middle-managers are plausibly on the horizon”. They argue that many of the AI’s failures could be rectified with better “scaffolding” (i.e. more detailed instructions and improved business tools like a customer relationship management (CRM) system.)&lt;/p&gt;&lt;p&gt;As AI models improve their general intelligence and ability to handle long-term context, their performance in such roles is expected to increase. However, this project serves as a valuable, if cautionary, tale. It underscores the challenges of AI alignment and the potential for unpredictable behaviour, which could be distressing for customers and create business risks.&lt;/p&gt;&lt;p&gt;In a future where autonomous agents manage significant economic activity, such odd scenarios could have cascading effects. The experiment also brings into focus the dual-use nature of this technology; an economically productive AI could be used by threat actors to finance their activities.&lt;/p&gt;&lt;p&gt;Anthropic and Andon Labs are continuing the business experiment, working to improve the AI’s stability and performance with more advanced tools. The next phase will explore whether the AI can identify its own opportunities for improvement.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image credit: Anthropic)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Major AI chatbots parrot CCP propaganda&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/anthropic-tests-ai-running-a-real-business-with-bizarre-results/</guid><pubDate>Fri, 27 Jun 2025 16:54:16 +0000</pubDate></item><item><title>REGEN: Empowering personalized recommendations with natural language (The latest research from Google)</title><link>https://research.google/blog/regen-empowering-personalized-recommendations-with-natural-language/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Conclusion&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;REGEN provides a dataset with consistent user preferences, recommendations, and generated narratives, enabling the study of LLM capabilities in conversational recommendation. We evaluated REGEN using LUMEN, an LLM-based model for joint recommendation and narrative generation, demonstrating its utility, along with sequential recommender models. We believe REGEN serves as a fundamental resource for studying the capabilities of conversational recommender models, a crucial step towards personalized multi-turn systems.&lt;/p&gt;&lt;p&gt;REGEN advances conversational recommendation by integrating language as a fundamental element, enhancing how recommenders interpret and respond to user preferences. This approach fosters research into multi-turn interactions, where systems can engage in extended dialogues to refine recommendations based on evolving user feedback.&lt;/p&gt;&lt;p&gt;The dataset also encourages the development of more sophisticated models and training methodologies. It supports exploration into scaling model capacity, utilizing advanced training techniques, and adapting the methodology across different domains beyond Amazon reviews, such as travel, education, and music.&lt;/p&gt;&lt;p&gt;Ultimately, REGEN sets a new direction for recommender systems, emphasizing comprehension and interaction, which paves the way for more intuitive, supportive, and human-like recommendation experiences.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Conclusion&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;REGEN provides a dataset with consistent user preferences, recommendations, and generated narratives, enabling the study of LLM capabilities in conversational recommendation. We evaluated REGEN using LUMEN, an LLM-based model for joint recommendation and narrative generation, demonstrating its utility, along with sequential recommender models. We believe REGEN serves as a fundamental resource for studying the capabilities of conversational recommender models, a crucial step towards personalized multi-turn systems.&lt;/p&gt;&lt;p&gt;REGEN advances conversational recommendation by integrating language as a fundamental element, enhancing how recommenders interpret and respond to user preferences. This approach fosters research into multi-turn interactions, where systems can engage in extended dialogues to refine recommendations based on evolving user feedback.&lt;/p&gt;&lt;p&gt;The dataset also encourages the development of more sophisticated models and training methodologies. It supports exploration into scaling model capacity, utilizing advanced training techniques, and adapting the methodology across different domains beyond Amazon reviews, such as travel, education, and music.&lt;/p&gt;&lt;p&gt;Ultimately, REGEN sets a new direction for recommender systems, emphasizing comprehension and interaction, which paves the way for more intuitive, supportive, and human-like recommendation experiences.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/regen-empowering-personalized-recommendations-with-natural-language/</guid><pubDate>Fri, 27 Jun 2025 17:00:00 +0000</pubDate></item><item><title>Using generative AI to help robots jump higher and land safely (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-6e565cc0-7fff-cbe0-c9eb-bc35383dc425"&gt;Diffusion models like OpenAI’s DALL-E are becoming increasingly useful in helping brainstorm new designs. Humans can prompt these systems to generate an image, create a video, or refine a blueprint, and come back with ideas they hadn’t considered before.&lt;/p&gt;&lt;p&gt;But did you know that generative artificial intelligence (GenAI) models are also making headway in creating working robots?&amp;nbsp;Recent diffusion-based approaches have generated structures and the systems that control them from scratch. With or without a user’s input, these models can make new designs and then evaluate them in simulation before they’re fabricated.&lt;/p&gt;&lt;p&gt;A new approach from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) applies this generative know-how toward improving humans’ robotic designs. Users can draft a 3D model of a robot and specify which parts they’d like to see a diffusion model modify, providing its dimensions beforehand. GenAI then brainstorms the optimal shape for these areas and tests its ideas in simulation. When the system finds the right design, you can save and then fabricate a working, real-world robot with a 3D printer, without requiring additional tweaks.&lt;/p&gt;&lt;p&gt;The researchers used this approach to create a robot that leaps up an average of roughly 2 feet, or 41 percent higher than a similar machine they created on their own. The machines are nearly identical in appearance: They’re both made of a type of plastic called polylactic acid, and while they initially appear flat, they spring up into a diamond shape when a motor pulls on the cord attached to them. So what exactly did AI do differently?&lt;/p&gt;&lt;p&gt;A closer look reveals that the AI-generated linkages are curved, and resemble thick drumsticks (the musical instrument drummers use), whereas the standard robot’s connecting parts are straight and rectangular.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/dI1J4aPcbmc/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;strong&gt;Better and better blobs&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers began to refine their jumping robot by sampling 500 potential designs using an initial embedding vector — a numerical representation that captures high-level features to guide the designs generated by the AI model. From these, they selected the top 12 options based on performance in simulation and used them to optimize the embedding vector.&lt;/p&gt;&lt;p dir="ltr"&gt;This process was repeated five times, progressively guiding the AI model to generate better designs. The resulting design resembled a blob, so the researchers prompted their system to scale the draft to fit their 3D model. They then fabricated the shape, finding that it indeed improved the robot’s jumping abilities.&lt;/p&gt;&lt;p dir="ltr"&gt;The advantage of using diffusion models for this task, according to co-lead author and CSAIL postdoc Byungchul Kim, is that they can find unconventional solutions to refine robots.&lt;/p&gt;&lt;p dir="ltr"&gt;“We wanted to make our machine jump higher, so we figured we could just make the links connecting its parts as thin as possible to make them light,” says Kim. “However, such a thin structure can easily break if we just use 3D printed material. Our diffusion model came up with a better idea by suggesting a unique shape that allowed the robot to store more energy before it jumped, without making the links too thin. This creativity helped us learn about the machine’s underlying physics.”&lt;/p&gt;&lt;p dir="ltr"&gt;The team then tasked their system with drafting an optimized foot to ensure it landed safely. They repeated the optimization process, eventually choosing the best-performing design to attach to the bottom of their machine. Kim and his colleagues found that their AI-designed machine fell far less often than its baseline, to the tune of an 84 percent improvement.&lt;/p&gt;&lt;p dir="ltr"&gt;The diffusion model’s ability to upgrade a robot’s jumping and landing skills suggests it could be useful in enhancing how other machines are designed. For example, a company working on manufacturing or household robots could use a similar approach to improve their prototypes, saving engineers time normally reserved for iterating on those changes.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The balance behind the bounce&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;To create a robot that could jump high and land stably, the researchers recognized that they needed to strike a balance between both goals. They represented both jumping height and landing success rate as numerical data, and then trained their system to find a sweet spot between both embedding vectors that could help build an optimal 3D structure.&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers note that while this AI-assisted robot outperformed its human-designed counterpart, it could soon reach even greater new heights. This iteration involved using materials that were compatible with a 3D printer, but future versions would jump even higher with lighter materials.&lt;/p&gt;&lt;p&gt;Co-lead author and MIT CSAIL PhD student Tsun-Hsuan “Johnson” Wang says the project is a jumping-off point for new robotics designs that generative AI could help with.&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to branch out to more flexible goals,” says Wang. “Imagine using natural language to guide a diffusion model to draft a robot that can pick up a mug, or operate an electric drill.”&lt;/p&gt;&lt;p&gt;Kim says that a diffusion model could also help to generate articulation and ideate on how parts connect, potentially improving how high the robot would jump. The team is also exploring the possibility of adding more motors to control which direction the machine jumps and perhaps improve its landing stability.&lt;/p&gt;&lt;p&gt;The researchers’ work was supported, in part, by the National Science Foundation’s Emerging Frontiers in Research and Innovation program, the Singapore-MIT Alliance for Research and Technology’s Mens, Manus and Machina program, and the Gwangju Institute of Science and Technology (GIST)-CSAIL Collaboration. They presented their work at the 2025 International Conference on Robotics and Automation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-6e565cc0-7fff-cbe0-c9eb-bc35383dc425"&gt;Diffusion models like OpenAI’s DALL-E are becoming increasingly useful in helping brainstorm new designs. Humans can prompt these systems to generate an image, create a video, or refine a blueprint, and come back with ideas they hadn’t considered before.&lt;/p&gt;&lt;p&gt;But did you know that generative artificial intelligence (GenAI) models are also making headway in creating working robots?&amp;nbsp;Recent diffusion-based approaches have generated structures and the systems that control them from scratch. With or without a user’s input, these models can make new designs and then evaluate them in simulation before they’re fabricated.&lt;/p&gt;&lt;p&gt;A new approach from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) applies this generative know-how toward improving humans’ robotic designs. Users can draft a 3D model of a robot and specify which parts they’d like to see a diffusion model modify, providing its dimensions beforehand. GenAI then brainstorms the optimal shape for these areas and tests its ideas in simulation. When the system finds the right design, you can save and then fabricate a working, real-world robot with a 3D printer, without requiring additional tweaks.&lt;/p&gt;&lt;p&gt;The researchers used this approach to create a robot that leaps up an average of roughly 2 feet, or 41 percent higher than a similar machine they created on their own. The machines are nearly identical in appearance: They’re both made of a type of plastic called polylactic acid, and while they initially appear flat, they spring up into a diamond shape when a motor pulls on the cord attached to them. So what exactly did AI do differently?&lt;/p&gt;&lt;p&gt;A closer look reveals that the AI-generated linkages are curved, and resemble thick drumsticks (the musical instrument drummers use), whereas the standard robot’s connecting parts are straight and rectangular.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/dI1J4aPcbmc/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;strong&gt;Better and better blobs&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers began to refine their jumping robot by sampling 500 potential designs using an initial embedding vector — a numerical representation that captures high-level features to guide the designs generated by the AI model. From these, they selected the top 12 options based on performance in simulation and used them to optimize the embedding vector.&lt;/p&gt;&lt;p dir="ltr"&gt;This process was repeated five times, progressively guiding the AI model to generate better designs. The resulting design resembled a blob, so the researchers prompted their system to scale the draft to fit their 3D model. They then fabricated the shape, finding that it indeed improved the robot’s jumping abilities.&lt;/p&gt;&lt;p dir="ltr"&gt;The advantage of using diffusion models for this task, according to co-lead author and CSAIL postdoc Byungchul Kim, is that they can find unconventional solutions to refine robots.&lt;/p&gt;&lt;p dir="ltr"&gt;“We wanted to make our machine jump higher, so we figured we could just make the links connecting its parts as thin as possible to make them light,” says Kim. “However, such a thin structure can easily break if we just use 3D printed material. Our diffusion model came up with a better idea by suggesting a unique shape that allowed the robot to store more energy before it jumped, without making the links too thin. This creativity helped us learn about the machine’s underlying physics.”&lt;/p&gt;&lt;p dir="ltr"&gt;The team then tasked their system with drafting an optimized foot to ensure it landed safely. They repeated the optimization process, eventually choosing the best-performing design to attach to the bottom of their machine. Kim and his colleagues found that their AI-designed machine fell far less often than its baseline, to the tune of an 84 percent improvement.&lt;/p&gt;&lt;p dir="ltr"&gt;The diffusion model’s ability to upgrade a robot’s jumping and landing skills suggests it could be useful in enhancing how other machines are designed. For example, a company working on manufacturing or household robots could use a similar approach to improve their prototypes, saving engineers time normally reserved for iterating on those changes.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The balance behind the bounce&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;To create a robot that could jump high and land stably, the researchers recognized that they needed to strike a balance between both goals. They represented both jumping height and landing success rate as numerical data, and then trained their system to find a sweet spot between both embedding vectors that could help build an optimal 3D structure.&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers note that while this AI-assisted robot outperformed its human-designed counterpart, it could soon reach even greater new heights. This iteration involved using materials that were compatible with a 3D printer, but future versions would jump even higher with lighter materials.&lt;/p&gt;&lt;p&gt;Co-lead author and MIT CSAIL PhD student Tsun-Hsuan “Johnson” Wang says the project is a jumping-off point for new robotics designs that generative AI could help with.&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to branch out to more flexible goals,” says Wang. “Imagine using natural language to guide a diffusion model to draft a robot that can pick up a mug, or operate an electric drill.”&lt;/p&gt;&lt;p&gt;Kim says that a diffusion model could also help to generate articulation and ideate on how parts connect, potentially improving how high the robot would jump. The team is also exploring the possibility of adding more motors to control which direction the machine jumps and perhaps improve its landing stability.&lt;/p&gt;&lt;p&gt;The researchers’ work was supported, in part, by the National Science Foundation’s Emerging Frontiers in Research and Innovation program, the Singapore-MIT Alliance for Research and Technology’s Mens, Manus and Machina program, and the Gwangju Institute of Science and Technology (GIST)-CSAIL Collaboration. They presented their work at the 2025 International Conference on Robotics and Automation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627</guid><pubDate>Fri, 27 Jun 2025 17:00:00 +0000</pubDate></item><item><title>MIT and Mass General Brigham launch joint seed program to accelerate innovations in health (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Leveraging the strengths of two world-class research institutions, MIT and Mass General Brigham (MGB) recently celebrated the launch of the MIT-MGB Seed Program. The new initiative, which is supported by Analog Devices Inc. (ADI), will fund joint research projects led by researchers at MIT and Mass General Brigham. These collaborative projects will advance research in human health, with the goal of developing next-generation therapies, diagnostics, and digital tools that can improve lives at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The program represents a unique opportunity to dramatically accelerate innovations that address some of the most urgent challenges in human health. By supporting interdisciplinary teams from MIT and Mass General Brigham, including both researchers and clinicians, the seed program will foster groundbreaking work that brings together expertise in artificial intelligence, machine learning, and measurement and sensing technologies with pioneering clinical research and patient care.&lt;/p&gt;&lt;p&gt;“The power of this program&amp;nbsp;is that it&amp;nbsp;combines MIT’s strength in science, engineering, and innovation with Mass General Brigham’s world-class scientific and clinical research. With the support and incentive to work together, researchers and clinicians&amp;nbsp;will have the freedom&amp;nbsp;to tackle compelling&amp;nbsp;problems&amp;nbsp;and find novel ways to&amp;nbsp;overcome them to&amp;nbsp;achieve transformative changes in patient care,” says Sally Kornbluth, president of MIT.&lt;/p&gt;&lt;p&gt;“The MIT-MGB Seed Program will enable cross-disciplinary collaboration to advance transformative research and breakthrough science. By combining the collective strengths and expertise of our great institutions, we can transform medical care and drive innovation and discovery with speed,” says Anne Klibanski, president and CEO of Mass General Brigham.&lt;/p&gt;&lt;p&gt;The initiative is funded by a gift from ADI. Over the next three years, the ADI Fund for Health and Life Sciences will support approximately six joint projects annually, with funding split between the two institutions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The converging domains of biology, medicine, and computing promise a new era of health-care efficacy, efficiency, and access. ADI has enjoyed a long and fruitful history of collaboration with MIT and Mass General Brigham, and we are excited by this new initiative’s potential to transform the future of patient care,” adds Vincent Roche, CEO and chair of the board of directors at ADI.&lt;/p&gt;&lt;p&gt;In addition to funding, teams selected for the program will have access to entrepreneurial workshops, including some hosted by The Engine — an MIT-built venture firm focused on tough tech. These sessions will connect researchers with company founders, investors, and industry leaders, helping them chart a path from breakthrough discoveries in the lab to real-world impact.&lt;/p&gt;&lt;p&gt;The program will launch an open call for proposals to researchers at MIT and Mass General Brigham. The first cohort of funded projects is expected to launch in fall 2025. Awardees will be selected by a joint review committee composed of MIT and Mass General Brigham experts.&lt;/p&gt;&lt;p&gt;According to MIT’s faculty lead for the MIT-MGB Seed Program, Alex K. Shalek, building collaborative research teams with leaders from both institutions could help fill critical gaps that often impede innovation in health and life sciences. Shalek also serves as director&amp;nbsp;of the Institute for Medical Engineering &amp;amp; Science (IMES), the J. W. Kieckhefer Professor in IMES and Chemistry, and an extramural member of the&amp;nbsp;Koch Institute for Integrative Cancer Research.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“Clinicians often see where current interventions fall short, but may lack the scientific tools or engineering expertise needed to develop new ones. Conversely, MIT researchers may not fully grasp these clinical challenges or have access to the right patient data and samples,” explains Shalek, who is also a member of the Ragon Institute of Mass General Brigham, MIT, and Harvard. “By supporting bilateral collaborations and building a community across disciplines, this program is poised to drive critical advances in diagnostics, therapeutics, and AI-driven health applications.”&lt;/p&gt;&lt;p&gt;Emery Brown, a practicing anesthesiologist at Massachusetts General Hospital, will serve alongside Shalek as Mass General Brigham’s faculty lead for the program.&lt;/p&gt;&lt;p&gt;“The MIT-MGB Seed Program creates a perfect storm. The program will provide an opportunity for MIT faculty to bring novel science and engineering to attack and solve important clinical problems,” adds Brown, who is also the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience at MIT. “The pursuit of solutions to important and challenging clinical problems by Mass General Brigham physicians and scientists will no doubt spur MIT scientists and engineers to develop new technologies, or find novel applications of existing technologies.”&lt;/p&gt;&lt;p&gt;The MIT-MGB Seed Program is a flagship initiative in the MIT Health and Life Sciences Collaborative (MIT HEALS). It reflects MIT HEALS’ core mission to establish MIT as a central hub for health and life sciences innovation and translation, and to leverage connections with other world-class research institutions in the Boston area.&lt;/p&gt;&lt;p&gt;“This program exemplifies the power of interdisciplinary research,” says Anantha Chandrakasan, MIT’s chief innovation and strategy officer, dean of engineering, and head of MIT HEALS. “It creates a critical bridge between clinical practice and technological innovation — two areas that must be deeply connected to advance real-world solutions.”&lt;/p&gt;&lt;p&gt;The program’s launch was celebrated at a special event at MIT’s Samberg Conference Center on March 31.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Leveraging the strengths of two world-class research institutions, MIT and Mass General Brigham (MGB) recently celebrated the launch of the MIT-MGB Seed Program. The new initiative, which is supported by Analog Devices Inc. (ADI), will fund joint research projects led by researchers at MIT and Mass General Brigham. These collaborative projects will advance research in human health, with the goal of developing next-generation therapies, diagnostics, and digital tools that can improve lives at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The program represents a unique opportunity to dramatically accelerate innovations that address some of the most urgent challenges in human health. By supporting interdisciplinary teams from MIT and Mass General Brigham, including both researchers and clinicians, the seed program will foster groundbreaking work that brings together expertise in artificial intelligence, machine learning, and measurement and sensing technologies with pioneering clinical research and patient care.&lt;/p&gt;&lt;p&gt;“The power of this program&amp;nbsp;is that it&amp;nbsp;combines MIT’s strength in science, engineering, and innovation with Mass General Brigham’s world-class scientific and clinical research. With the support and incentive to work together, researchers and clinicians&amp;nbsp;will have the freedom&amp;nbsp;to tackle compelling&amp;nbsp;problems&amp;nbsp;and find novel ways to&amp;nbsp;overcome them to&amp;nbsp;achieve transformative changes in patient care,” says Sally Kornbluth, president of MIT.&lt;/p&gt;&lt;p&gt;“The MIT-MGB Seed Program will enable cross-disciplinary collaboration to advance transformative research and breakthrough science. By combining the collective strengths and expertise of our great institutions, we can transform medical care and drive innovation and discovery with speed,” says Anne Klibanski, president and CEO of Mass General Brigham.&lt;/p&gt;&lt;p&gt;The initiative is funded by a gift from ADI. Over the next three years, the ADI Fund for Health and Life Sciences will support approximately six joint projects annually, with funding split between the two institutions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The converging domains of biology, medicine, and computing promise a new era of health-care efficacy, efficiency, and access. ADI has enjoyed a long and fruitful history of collaboration with MIT and Mass General Brigham, and we are excited by this new initiative’s potential to transform the future of patient care,” adds Vincent Roche, CEO and chair of the board of directors at ADI.&lt;/p&gt;&lt;p&gt;In addition to funding, teams selected for the program will have access to entrepreneurial workshops, including some hosted by The Engine — an MIT-built venture firm focused on tough tech. These sessions will connect researchers with company founders, investors, and industry leaders, helping them chart a path from breakthrough discoveries in the lab to real-world impact.&lt;/p&gt;&lt;p&gt;The program will launch an open call for proposals to researchers at MIT and Mass General Brigham. The first cohort of funded projects is expected to launch in fall 2025. Awardees will be selected by a joint review committee composed of MIT and Mass General Brigham experts.&lt;/p&gt;&lt;p&gt;According to MIT’s faculty lead for the MIT-MGB Seed Program, Alex K. Shalek, building collaborative research teams with leaders from both institutions could help fill critical gaps that often impede innovation in health and life sciences. Shalek also serves as director&amp;nbsp;of the Institute for Medical Engineering &amp;amp; Science (IMES), the J. W. Kieckhefer Professor in IMES and Chemistry, and an extramural member of the&amp;nbsp;Koch Institute for Integrative Cancer Research.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“Clinicians often see where current interventions fall short, but may lack the scientific tools or engineering expertise needed to develop new ones. Conversely, MIT researchers may not fully grasp these clinical challenges or have access to the right patient data and samples,” explains Shalek, who is also a member of the Ragon Institute of Mass General Brigham, MIT, and Harvard. “By supporting bilateral collaborations and building a community across disciplines, this program is poised to drive critical advances in diagnostics, therapeutics, and AI-driven health applications.”&lt;/p&gt;&lt;p&gt;Emery Brown, a practicing anesthesiologist at Massachusetts General Hospital, will serve alongside Shalek as Mass General Brigham’s faculty lead for the program.&lt;/p&gt;&lt;p&gt;“The MIT-MGB Seed Program creates a perfect storm. The program will provide an opportunity for MIT faculty to bring novel science and engineering to attack and solve important clinical problems,” adds Brown, who is also the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience at MIT. “The pursuit of solutions to important and challenging clinical problems by Mass General Brigham physicians and scientists will no doubt spur MIT scientists and engineers to develop new technologies, or find novel applications of existing technologies.”&lt;/p&gt;&lt;p&gt;The MIT-MGB Seed Program is a flagship initiative in the MIT Health and Life Sciences Collaborative (MIT HEALS). It reflects MIT HEALS’ core mission to establish MIT as a central hub for health and life sciences innovation and translation, and to leverage connections with other world-class research institutions in the Boston area.&lt;/p&gt;&lt;p&gt;“This program exemplifies the power of interdisciplinary research,” says Anantha Chandrakasan, MIT’s chief innovation and strategy officer, dean of engineering, and head of MIT HEALS. “It creates a critical bridge between clinical practice and technological innovation — two areas that must be deeply connected to advance real-world solutions.”&lt;/p&gt;&lt;p&gt;The program’s launch was celebrated at a special event at MIT’s Samberg Conference Center on March 31.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627</guid><pubDate>Fri, 27 Jun 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Facebook is asking to use Meta AI on photos in your camera roll you haven’t yet shared (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/27/facebook-is-asking-to-use-meta-ai-on-photos-in-your-camera-roll-you-havent-yet-shared/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Facebook is asking users for access to their phone’s camera roll to automatically suggest AI-edited versions of their photos — including ones that haven’t been uploaded to Facebook yet. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is being suggested to Facebook users when they’re creating a new Story on the social networking app. Here, a screen pops up and asks if the user will opt into “cloud processing” to allow creative suggestions. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the pop-up message explains, by clicking “Allow,” you’ll let Facebook generate new ideas from your camera roll, like collages, recaps, AI restylings, or photo themes. To work, Facebook says it will upload media from your camera roll to its cloud (meaning its servers) on an “ongoing basis,” based on information like time, location, or themes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022873" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1557.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot of Facebook's app, June 2025&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The message also notes that only you can see the suggestions, and the media isn’t used for ad targeting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, by tapping “Allow,” you are agreeing to Meta’s AI Terms of Service. This allows your media and facial features to be analyzed by AI, it says. The company will additionally use the date and presence of people or objects in your photos to craft its creative ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The creative tool is another example of the slippery slope that comes with sharing our personal media with AI providers. Like other tech giants, Meta has grand AI ambitions. Being able to tap into the personal photos users haven’t yet shared on Facebook’s social network could give the company an advantage in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unfortunately for end users, in tech companies’ rush to stay ahead, it’s not always clear what they’re agreeing to when features like this appear.&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3022889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1560.jpg?w=499" width="499" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot from 'Seasons of Jason' on Mastodon &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;According to Meta’s AI Terms around image processing, “once shared, you agree that Meta will analyze those images, including facial features, using AI. This processing allows us to offer innovative new features, including the ability to summarize image contents, modify images, and generate new content based on the image,” the text states.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The same AI terms also give Meta’s AI the right to “retain and use” any personal information you’ve shared in order to personalize its AI outputs. The company notes that it can review your interactions with its AI, including conversations, and those reviews may be conducted by humans. The terms don’t define what Meta considers personal information, beyond saying it includes “information you submit as Prompts, Feedback, or other Content.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have to wonder whether the photos you’ve shared for “cloud processing” also count here.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So far, there hasn’t been much backlash about this feature. A handful of Facebook users have stumbled across the AI-generated photo suggestions when creating a new story and raised questions about it. For instance, one user on Reddit found that Facebook had pulled up an old photo (in this case, one that had previously been shared to the social network) and automatically turned it into an anime using Meta AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When another user in an anti-AI Facebook group asked for help shutting this feature off, the search led to a section called camera roll sharing suggestions in the app’s Settings.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022875" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/camera-roll-cloud-processing.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot of Facebook's app, June 2025&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;We also found this feature under Facebook’s Settings, where it’s listed in the Preferences section. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the “Camera roll sharing suggestions” page, there are two toggles. The first lets Facebook suggest photos from your camera roll when browsing the app. The second (which should be opt-in based on the pop-up that requested permission in Stories) is where you could enable or disable the “cloud processing,” which lets Meta make AI images using your camera roll photos. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This additional access to use AI on your camera roll’s photos does not appear to be new. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We found posts from earlier this year where confused Facebook users were sharing screenshots of the pop-up message that appeared in their Stories section. Meta has also published complete Help Documentation about the feature for both iOS and Android users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI terms have been enforceable as of June 23, 2024; we can’t compare the current AI terms with older versions because Meta doesn’t keep a record, and previously published terms haven’t been properly saved by the Internet Archive’s Wayback Machine.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since this feature dips into your camera roll, however, it extends beyond what Meta had previously announced, in terms of training its AI on your publicly shared data, including posts and comments on Facebook and Instagram. (EU users had until May 27, 2025, to opt out.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reached for comment, Meta spokesperson Maria Cubeta confirmed the feature is a test, saying, “We’re exploring ways to make content sharing easier for people on Facebook by testing suggestions of ready-to-share and curated content from a person’s camera roll.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These suggestions are opt-in only and only shown to you – unless you decide to share them – and can be turned off at any time,” she continued. “Camera roll media may be used to improve these suggestions, but are not used to improve AI models in this test.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is currently testing suggestions in the U.S. and Canada. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication with Facebook’s comments. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Facebook is asking users for access to their phone’s camera roll to automatically suggest AI-edited versions of their photos — including ones that haven’t been uploaded to Facebook yet. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is being suggested to Facebook users when they’re creating a new Story on the social networking app. Here, a screen pops up and asks if the user will opt into “cloud processing” to allow creative suggestions. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the pop-up message explains, by clicking “Allow,” you’ll let Facebook generate new ideas from your camera roll, like collages, recaps, AI restylings, or photo themes. To work, Facebook says it will upload media from your camera roll to its cloud (meaning its servers) on an “ongoing basis,” based on information like time, location, or themes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022873" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1557.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot of Facebook's app, June 2025&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The message also notes that only you can see the suggestions, and the media isn’t used for ad targeting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, by tapping “Allow,” you are agreeing to Meta’s AI Terms of Service. This allows your media and facial features to be analyzed by AI, it says. The company will additionally use the date and presence of people or objects in your photos to craft its creative ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The creative tool is another example of the slippery slope that comes with sharing our personal media with AI providers. Like other tech giants, Meta has grand AI ambitions. Being able to tap into the personal photos users haven’t yet shared on Facebook’s social network could give the company an advantage in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unfortunately for end users, in tech companies’ rush to stay ahead, it’s not always clear what they’re agreeing to when features like this appear.&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3022889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1560.jpg?w=499" width="499" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot from 'Seasons of Jason' on Mastodon &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;According to Meta’s AI Terms around image processing, “once shared, you agree that Meta will analyze those images, including facial features, using AI. This processing allows us to offer innovative new features, including the ability to summarize image contents, modify images, and generate new content based on the image,” the text states.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The same AI terms also give Meta’s AI the right to “retain and use” any personal information you’ve shared in order to personalize its AI outputs. The company notes that it can review your interactions with its AI, including conversations, and those reviews may be conducted by humans. The terms don’t define what Meta considers personal information, beyond saying it includes “information you submit as Prompts, Feedback, or other Content.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have to wonder whether the photos you’ve shared for “cloud processing” also count here.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So far, there hasn’t been much backlash about this feature. A handful of Facebook users have stumbled across the AI-generated photo suggestions when creating a new story and raised questions about it. For instance, one user on Reddit found that Facebook had pulled up an old photo (in this case, one that had previously been shared to the social network) and automatically turned it into an anime using Meta AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When another user in an anti-AI Facebook group asked for help shutting this feature off, the search led to a section called camera roll sharing suggestions in the app’s Settings.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022875" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/camera-roll-cloud-processing.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;screenshot of Facebook's app, June 2025&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;We also found this feature under Facebook’s Settings, where it’s listed in the Preferences section. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the “Camera roll sharing suggestions” page, there are two toggles. The first lets Facebook suggest photos from your camera roll when browsing the app. The second (which should be opt-in based on the pop-up that requested permission in Stories) is where you could enable or disable the “cloud processing,” which lets Meta make AI images using your camera roll photos. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This additional access to use AI on your camera roll’s photos does not appear to be new. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We found posts from earlier this year where confused Facebook users were sharing screenshots of the pop-up message that appeared in their Stories section. Meta has also published complete Help Documentation about the feature for both iOS and Android users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI terms have been enforceable as of June 23, 2024; we can’t compare the current AI terms with older versions because Meta doesn’t keep a record, and previously published terms haven’t been properly saved by the Internet Archive’s Wayback Machine.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since this feature dips into your camera roll, however, it extends beyond what Meta had previously announced, in terms of training its AI on your publicly shared data, including posts and comments on Facebook and Instagram. (EU users had until May 27, 2025, to opt out.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reached for comment, Meta spokesperson Maria Cubeta confirmed the feature is a test, saying, “We’re exploring ways to make content sharing easier for people on Facebook by testing suggestions of ready-to-share and curated content from a person’s camera roll.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These suggestions are opt-in only and only shown to you – unless you decide to share them – and can be turned off at any time,” she continued. “Camera roll media may be used to improve these suggestions, but are not used to improve AI models in this test.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is currently testing suggestions in the U.S. and Canada. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication with Facebook’s comments. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/27/facebook-is-asking-to-use-meta-ai-on-photos-in-your-camera-roll-you-havent-yet-shared/</guid><pubDate>Fri, 27 Jun 2025 18:31:38 +0000</pubDate></item><item><title>[NEW] Meta is offering multimillion-dollar pay for AI researchers, but not $100M ‘signing bonuses’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/27/meta-is-offering-multimillion-dollar-pay-for-ai-researchers-but-not-100m-signing-bonuses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173597965.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is definitely offering hefty multimillion-dollar pay packages to AI researchers when wooing them to its new superintelligence lab. But no one is really getting a $100 million “signing bonus,” according to a poached researcher and comments from a leaked internal meeting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During a company-wide all-hands meeting on Thursday leaked to The Verge, some of Meta’s top executives were asked about the bonuses that OpenAI CEO Sam Altman said Meta had offered to top researchers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s CTO Andrew Bosworth implied that only a few people for very senior leadership roles may have been offered that kind of money, but clarified “the actual terms of the offer” wasn’t a “sign-on bonus. It’s all these different things.” In other words, not an instant chunk of cash. Tech companies typically offer the biggest chunks of their pay to senior leaders in restricted stock unit (RSU) grants, dependent on either tenure or performance metrics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A four-year total pay package worth about $100 million for a very senior leader is not inconceivable for Meta. Most of Meta’s named officers, including Boswell, have earned total compensation of between $20 million and nearly $24 million per year for years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman was “suggesting that we’re doing this for every single person,” Bosworth reportedly said at the meeting. “Look, you guys, the market’s hot. It’s not that hot.”  (Meta did not immediately respond to our request for comment.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, researcher Lucas Beyer confirmed he was leaving OpenAI to join Meta along with the two others who led OpenAI’s Zurich office. He tweeted: “1) yes, we will be joining Meta. 2) no, we did not get 100M sign-on, that’s fake news.” (Beyer politely declined to comment further on his new role to TechCrunch.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyer’s expertise is in computer vision AI. That aligns with what Meta is pursuing: entertainment AI, rather than productivity AI, Bosworth reportedly said in that meeting. Meta already has a stake in the ground in that area with its Quest VR headsets and its Ray-Ban and Oakley AI glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, some of the people Meta is trying to nab are indeed worthy of big pay packages in this tight AI talent marketplace. As TechCrunch was first to report, Meta has hired OpenAI’s Trapit Bansal, known for his groundbreaking work on AI reasoning models. He had worked at OpenAI since 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Certainly, Scale co-founder and CEO Alexandr Wang is getting a healthy chunk of cash, likely more than $100 million, as part of Meta’s deal to buy 49% ownership of his company. As we previously reported, the $14 billion Meta is paying is being distributed to shareholders as a cash dividend. Wang is almost certainly a major shareholder in Scale entitled to those dividends.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, while Meta isn’t handing out $100 million willy-nilly, it is still spending big to hire in AI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One investor told TechCrunch that he saw an AI researcher get — and turn down — an $18 million job offer from Meta. That person took a smaller, but still healthy offer, from a buzzier AI startup: Mira Murati’s Thinking Machines Lab.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173597965.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is definitely offering hefty multimillion-dollar pay packages to AI researchers when wooing them to its new superintelligence lab. But no one is really getting a $100 million “signing bonus,” according to a poached researcher and comments from a leaked internal meeting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During a company-wide all-hands meeting on Thursday leaked to The Verge, some of Meta’s top executives were asked about the bonuses that OpenAI CEO Sam Altman said Meta had offered to top researchers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s CTO Andrew Bosworth implied that only a few people for very senior leadership roles may have been offered that kind of money, but clarified “the actual terms of the offer” wasn’t a “sign-on bonus. It’s all these different things.” In other words, not an instant chunk of cash. Tech companies typically offer the biggest chunks of their pay to senior leaders in restricted stock unit (RSU) grants, dependent on either tenure or performance metrics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A four-year total pay package worth about $100 million for a very senior leader is not inconceivable for Meta. Most of Meta’s named officers, including Boswell, have earned total compensation of between $20 million and nearly $24 million per year for years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman was “suggesting that we’re doing this for every single person,” Bosworth reportedly said at the meeting. “Look, you guys, the market’s hot. It’s not that hot.”  (Meta did not immediately respond to our request for comment.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, researcher Lucas Beyer confirmed he was leaving OpenAI to join Meta along with the two others who led OpenAI’s Zurich office. He tweeted: “1) yes, we will be joining Meta. 2) no, we did not get 100M sign-on, that’s fake news.” (Beyer politely declined to comment further on his new role to TechCrunch.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyer’s expertise is in computer vision AI. That aligns with what Meta is pursuing: entertainment AI, rather than productivity AI, Bosworth reportedly said in that meeting. Meta already has a stake in the ground in that area with its Quest VR headsets and its Ray-Ban and Oakley AI glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, some of the people Meta is trying to nab are indeed worthy of big pay packages in this tight AI talent marketplace. As TechCrunch was first to report, Meta has hired OpenAI’s Trapit Bansal, known for his groundbreaking work on AI reasoning models. He had worked at OpenAI since 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Certainly, Scale co-founder and CEO Alexandr Wang is getting a healthy chunk of cash, likely more than $100 million, as part of Meta’s deal to buy 49% ownership of his company. As we previously reported, the $14 billion Meta is paying is being distributed to shareholders as a cash dividend. Wang is almost certainly a major shareholder in Scale entitled to those dividends.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, while Meta isn’t handing out $100 million willy-nilly, it is still spending big to hire in AI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One investor told TechCrunch that he saw an AI researcher get — and turn down — an $18 million job offer from Meta. That person took a smaller, but still healthy offer, from a buzzier AI startup: Mira Murati’s Thinking Machines Lab.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/27/meta-is-offering-multimillion-dollar-pay-for-ai-researchers-but-not-100m-signing-bonuses/</guid><pubDate>Fri, 27 Jun 2025 19:02:42 +0000</pubDate></item><item><title>[NEW] CFOs want AI that pays: real metrics, not marketing demos (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/cfos-want-ai-that-pays-real-metrics-not-marketing-demos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-CFOs-want-AI-that-pays_-Real-metrics-not-marketing-demos.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Recent surveys and VentureBeat’s conversations with CFOs suggest the honeymoon phase of AI is rapidly drawing to a close. While 2024 was dominated by pilot programs and proof-of-concept demonstrations, in mid-2025, the pressure for measurable results is intensifying, even as CFO interest in AI remains high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to a KPMG survey of 300 U.S. financial executives, investor pressure to demonstrate ROI on generative AI investments has increased significantly. For 90% of organizations, investor pressure is considered “important or very important” for demonstrating ROI in Q1 2025, a sharp increase from 68% in Q4 2024. This indicates a strong and intensifying demand for measurable returns.&lt;/p&gt;



&lt;p&gt;Meanwhile, according to a Bain Capital Ventures survey of 50 CFOs, 79% plan to increase their AI budgets this year, with 94% believing gen AI can strongly benefit at least one finance activity. This reveals a telling pattern in how CFOs are currently measuring AI value. Those who have adopted gen AI tools report seeing initial returns primarily through efficiency gains.&lt;/p&gt;&lt;p&gt;“We created a custom workflow that automates vendor identification to quickly prepare journal entries,” said Andrea Ellis, CFO of Fanatics Betting and Gaming. “This process used to take 20 hours during month-end close, and now, it takes us just 2 hours each month.” &lt;/p&gt;



&lt;p&gt;Jason Whiting, CFO of Mercury Financial, echoed this efficiency focus: “Across the board, [the biggest benefit] has been the ability to increase speed of analysis. Gen AI hasn’t replaced anything, but it has made our existing processes and people better.”&lt;/p&gt;



&lt;p&gt;But CFOs are now looking beyond simple time savings toward more strategic applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Bain data shows CFOs are most excited about applying AI to “long-standing pain points that prior generations of technology have been unable to solve.” Cosmin Pitigoi, CFO of Flywire, explained: “Forecasting trends based on large data sets has been around for a long time, but the issue has always been the model’s ability to explain the assumptions behind the forecast. AI can help not just with forecasting, but also with explaining what assumptions have changed over time.”&lt;/p&gt;



&lt;p&gt;These recent surveys suggest that CFOs are becoming the primary gatekeepers for AI investment; however, they’re still developing the financial frameworks necessary to evaluate these investments properly. Those who develop robust evaluation methodologies first will likely gain significant competitive advantages. Those who don’t may find their AI enthusiasm outpacing their ability to measure and manage the returns.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-efficiency-metrics-the-first-wave-of-ai-value"&gt;Efficiency metrics: The first wave of AI value&lt;/h2&gt;



&lt;p&gt;The initial wave of AI value capture by finance departments has focused predominantly on efficiency metrics, with CFOs prioritizing measurable time and cost savings that deliver immediate returns. This focus on efficiency represents the low-hanging fruit of AI implementation — clear, quantifiable benefits that are easily tracked and communicated to stakeholders.&lt;/p&gt;



&lt;p&gt;Drip Capital, a Silicon Valley-based fintech, exemplifies this approach with its AI implementation in trade finance operations. According to chief business officer Karl Boog, “We’ve been able to 30X our capacity with what we’ve done so far.” By automating document processing and enhancing risk assessment through large language models (LLMs), the company achieved a remarkable 70% productivity boost while maintaining critical human oversight for complex decisions.&lt;/p&gt;



&lt;p&gt;KPMG research indicates this approach is widespread, with one retail company audit committee director noting how automation has improved operational efficiency and ROI. This sentiment is echoed across industries as finance leaders seek to justify their AI investments with tangible productivity improvements.&lt;/p&gt;



&lt;p&gt;These efficiency improvements translate directly to the bottom line. Companies across sectors — from insurance to oil and gas — report that AI helps identify process inefficiencies, leading to substantial organizational cost savings and improved expense management.&lt;/p&gt;



&lt;p&gt;Beyond simple cost reduction, CFOs are developing more sophisticated efficiency metrics to evaluate AI investments. These include time-to-completion ratios comparing pre- and post-AI implementation timelines, cost-per-transaction analyses measuring reductions in resource expenditure and labor hour reallocation metrics tracking how team members shift from manual data processing to higher-value analytical work.&lt;/p&gt;



&lt;p&gt;However, leading CFOs recognize that while efficiency metrics provide a solid foundation for initial ROI calculations, they represent just the beginning of AI’s potential value. As finance leaders gain confidence in measuring these direct returns, they’re developing more comprehensive frameworks to capture AI’s full strategic value — moving well beyond the efficiency calculations that characterized early adoption phases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beyond-efficiency-the-new-financial-metrics"&gt;Beyond efficiency: The new financial metrics&lt;/h2&gt;



&lt;p&gt;As CFOs move beyond the initial fascination with AI-driven efficiency gains, they’re developing new financial metrics that more comprehensively capture AI’s business impact. This evolution reflects a maturing approach to AI investments, with finance leaders adopting more sophisticated evaluation frameworks that align with broader corporate objectives.&lt;/p&gt;



&lt;p&gt;The surveys highlight a notable shift in primary ROI metrics. While efficiency gains remain important, we see productivity metrics are now overtaking pure profitability measures as the chief priority for AI initiatives in 2025. This represents a fundamental change in how CFOs assess value, focusing on AI’s ability to enhance human capabilities rather than simply reduce costs.&lt;/p&gt;



&lt;p&gt;Time to value (TTV) is emerging as a critical new metric in investment decisions. Only about one-third of AI leaders anticipate being able to evaluate ROI within six months, making rapid time-to-value a key consideration when comparing different AI opportunities. This metric will help CFOs prioritize quick-win projects that can deliver measurable returns while building organizational confidence in larger AI initiatives.&lt;/p&gt;



&lt;p&gt;Data quality measurements will increasingly be incorporated into evaluation frameworks, with 64% of leaders citing data quality as their most significant AI challenge. Forward-thinking CFOs now incorporate data readiness assessments and ongoing data quality metrics into their AI business cases, recognizing that even the most promising AI applications will fail without high-quality data inputs.&lt;/p&gt;



&lt;p&gt;Adoption rate metrics have also become standard in AI evaluation. Finance leaders track how quickly and extensively AI tools are being utilized across departments, using this as a leading indicator of potential value realization. These metrics help identify implementation challenges early and inform decisions about additional training or system modifications.&lt;/p&gt;



&lt;p&gt;“The biggest benefit has been the ability to increase speed of analysis,” noted Jason Whiting of Mercury Financial. This perspective represents the bridge between simple efficiency metrics and more sophisticated value assessments — recognizing that AI’s value often comes not from replacing existing processes but enhancing them.&lt;/p&gt;



&lt;p&gt;Some CFOs are implementing comprehensive ROI formulas that incorporate both direct and indirect benefits (VAI Consulting):&lt;/p&gt;



&lt;p&gt;ROI = (Net Benefit / Total Cost) × 100&lt;/p&gt;



&lt;p&gt;Where net benefit equals the sum of direct financial benefits plus an estimated value of indirect benefits, minus total investment costs. This approach acknowledges that AI’s full value encompasses both quantifiable savings and intangible strategic advantages, such as improved decision quality and enhanced customer experience.&lt;/p&gt;



&lt;p&gt;For companies with more mature AI implementations, these new metrics are becoming increasingly standardized and integrated into regular financial reporting. The most sophisticated organizations now produce AI value scorecards that track multiple dimensions of performance, linking AI system outputs directly to business outcomes and financial results.&lt;/p&gt;



&lt;p&gt;As CFOs refine these new financial metrics, they’re creating a more nuanced picture of AI’s true value — one that extends well beyond the simple time and cost savings that dominated early adoption phases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-amortization-timelines-recalibrating-investment-horizons"&gt;Amortization timelines: Recalibrating investment horizons&lt;/h2&gt;



&lt;p&gt;CFOs are fundamentally rethinking how they amortize AI investments, developing new approaches that acknowledge the unique characteristics of these technologies. Unlike traditional IT systems with predictable depreciation schedules, AI investments often yield evolving returns that increase as systems learn and improve over time. Leading finance executives now evaluate AI investments through the lens of sustainable competitive advantage — asking not just “How much will this save?” but “How will this transform our market position?”&lt;/p&gt;



&lt;p&gt;“ROI directly correlates with AI maturity,” according to KPMG, which found that 61% of AI leaders report higher-than-expected ROI, compared with only 33% of beginners and implementers. This correlation is prompting CFOs to develop more sophisticated amortization models that anticipate accelerating returns as AI deployments mature.&lt;/p&gt;



&lt;p&gt;The difficulty in establishing accurate amortization timelines remains a significant barrier to AI adoption. “Uncertain ROI/difficulty developing a business case” is cited as a challenge by 33% of executives, particularly those in the early stages of AI implementation. This uncertainty has led to a more cautious, phased approach to investment.&lt;/p&gt;



&lt;p&gt;To address this challenge, leading finance teams are implementing pilot-to-scale methodologies to validate ROI before full deployment. This approach enables CFOs to gather accurate performance data, refine their amortization estimates, and make more informed scaling decisions.&lt;/p&gt;



&lt;p&gt;The timeframe for expected returns varies significantly based on the type of AI implementation. Automation-focused AI typically delivers more predictable short-term returns, whereas strategic applications, such as improved forecasting, may have longer, less certain payback periods. Progressive CFOs are developing differentiated amortization schedules that reflect these variations rather than applying one-size-fits-all approaches.&lt;/p&gt;



&lt;p&gt;Some finance leaders are adopting rolling amortization models that are adjusted quarterly based on actual performance data. This approach acknowledges the dynamic nature of AI returns and allows for ongoing refinement of financial projections. Rather than setting fixed amortization schedules at the outset, these models incorporate learning curves and performance improvements into evolving financial forecasts.&lt;/p&gt;



&lt;p&gt;One entertainment company implemented a gen AI-driven tool that scans financial developments, identifies anomalies and automatically generates executive-ready alerts. While the immediate ROI stemmed from efficiency gains, the CFO developed an amortization model that also factored in the system’s increasing accuracy over time and its expanding application across various business units.&lt;/p&gt;



&lt;p&gt;Many CFOs are also factoring in how AI investments contribute to building proprietary data assets that appreciate rather than depreciate over time. Unlike traditional technology investments that lose value as they age, AI systems and their associated data repositories often become more valuable as they accumulate training data and insights.&lt;/p&gt;



&lt;p&gt;This evolving approach to amortization represents a significant departure from traditional IT investment models. By developing more nuanced timelines that reflect AI’s unique characteristics, CFOs are creating financial frameworks that better capture the true economic value of these investments and support a more strategic allocation of resources.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-strategic-value-integration-linking-ai-to-shareholder-returns"&gt;Strategic value integration: Linking AI to shareholder returns&lt;/h2&gt;



&lt;p&gt;Forward-thinking CFOs are moving beyond operational metrics to integrate AI investments into broader frameworks for creating shareholder value. This shift represents a fundamental evolution in how financial executives evaluate AI — positioning it not merely as a cost-saving technology but as a strategic asset that drives enterprise growth and competitive differentiation.&lt;/p&gt;



&lt;p&gt;This more sophisticated approach assesses AI’s impact on three critical dimensions of shareholder value: revenue acceleration, risk reduction and strategic optionality. Each dimension requires different metrics and evaluation frameworks, creating a more comprehensive picture of AI’s contribution to enterprise value.&lt;/p&gt;



&lt;p&gt;Revenue acceleration metrics focus on how AI enhances top-line growth by improving customer acquisition, increasing the share of wallet and expanding market reach. These metrics track AI’s influence on sales velocity, conversion rates, customer lifetime value and price optimization — connecting algorithmic capabilities directly to revenue performance.&lt;/p&gt;



&lt;p&gt;Risk reduction frameworks assess how AI enhances forecasting accuracy, improves scenario planning, strengthens fraud detection and optimizes capital allocation. By quantifying risk-adjusted returns, CFOs can demonstrate how AI investments reduce earnings volatility and improve business resilience — factors that directly impact valuation multiples.&lt;/p&gt;



&lt;p&gt;Perhaps most importantly, leading CFOs are developing methods to value strategic optionality — the capacity of AI investments to create new business possibilities that didn’t previously exist. This approach recognizes that AI often delivers its most significant value by enabling entirely new business models or unlocking previously inaccessible market opportunities.&lt;/p&gt;



&lt;p&gt;To effectively communicate this strategic value, finance leaders are creating new reporting mechanisms tailored to different stakeholders. Some are establishing comprehensive AI value scorecards that link system performance to tangible business outcomes, incorporating both lagging indicators (financial results) and leading indicators (operational improvements) that predict future financial performance.&lt;/p&gt;



&lt;p&gt;Executive dashboards now regularly feature AI-related metrics alongside traditional financial KPIs, making AI more visible to senior leadership. These integrated views enable executives to understand how AI investments align with strategic priorities and shareholder expectations.&lt;/p&gt;



&lt;p&gt;For board and investor communication, CFOs are developing structured approaches that highlight both immediate financial returns and long-term strategic advantages. Rather than treating AI as a specialized technology investment, these frameworks position it as a fundamental business capability that drives sustainable competitive differentiation.&lt;/p&gt;



&lt;p&gt;By developing these integrated strategic value frameworks, CFOs ensure that AI investments are evaluated not only on their immediate operational impact but their contribution to the company’s long-term competitive position and shareholder returns. This more sophisticated approach is rapidly becoming a key differentiator between companies that treat AI as a tactical tool and those that leverage it as a strategic asset.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-risk-adjusted-returns-the-risk-management-equation"&gt;Risk-adjusted returns: The risk management equation&lt;/h2&gt;



&lt;p&gt;As AI investments grow in scale and strategic importance, CFOs are incorporating increasingly sophisticated risk assessments into their financial evaluations. This evolution reflects the unique challenges AI presents — balancing unprecedented opportunities against novel risks that traditional financial models often fail to capture.&lt;/p&gt;



&lt;p&gt;The risk landscape for AI investments is multifaceted and evolving rapidly. Recent surveys indicate that risk management, particularly in relation to data privacy, is expected to be the biggest challenge to generative AI strategies for 82% of leaders in 2025. This concern is followed closely by data quality issues (64%) and questions of trust in AI outputs (35%).&lt;/p&gt;



&lt;p&gt;Forward-thinking finance leaders are developing comprehensive risk-adjusted return frameworks that quantify and incorporate these various risk factors. Rather than treating risk as a binary go/no-go consideration, these frameworks assign monetary values to different risk categories and integrate them directly into ROI calculations.&lt;/p&gt;



&lt;p&gt;Data security and privacy vulnerabilities represent a primary concern, with 57% of executives citing these as top challenges. CFOs are now calculating potential financial exposure from data breaches or privacy violations and factoring these costs into their investment analyses. This includes estimating potential regulatory fines, litigation expenses, remediation costs and reputational damage.&lt;/p&gt;



&lt;p&gt;Regulatory compliance represents another significant risk factor. With many executives concerned about ensuring compliance with changing regulations, financial evaluations increasingly include contingency allocations for regulatory adaptation. An aerospace company executive noted that “complex regulations make it difficult for us to achieve AI readiness,” highlighting how regulatory uncertainty complicates financial planning.&lt;/p&gt;



&lt;p&gt;Beyond these external risks, CFOs are quantifying implementation risks such as adoption failures, integration challenges and technical performance issues. By assigning probability-weighted costs to these scenarios, they create more realistic projections that acknowledge the inherent uncertainties in AI deployment.&lt;/p&gt;



&lt;p&gt;The “black box” nature of certain AI technologies presents unique challenges for risk assessment. As stakeholders become increasingly wary of trusting AI results without understanding the underlying logic, CFOs are developing frameworks to evaluate transparency risks and their potential financial implications. This includes estimating the costs of additional validation procedures, explainability tools and human oversight mechanisms.&lt;/p&gt;



&lt;p&gt;Some companies are adopting formal risk-adjustment methodologies borrowed from other industries. One approach applies a modified weighted average cost of capital (WACC) that incorporates AI-specific risk premiums. Others use risk-adjusted net present value calculations that explicitly account for the unique uncertainty profiles of different AI applications.&lt;/p&gt;



&lt;p&gt;The transportation sector provides an illustrative example of this evolving approach. As one chief data officer noted, “The data received from AI requires human verification, and this is an important step that we overlook.” This recognition has led transportation CFOs to build verification costs directly into their financial models rather than treating them as optional add-ons.&lt;/p&gt;



&lt;p&gt;By incorporating these sophisticated risk adjustments into their financial evaluations, CFOs are creating more realistic assessments of AI’s true economic value. This approach enables more confident investment decisions and helps organizations maintain appropriate risk levels as they scale their AI capabilities.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cfo-s-ai-evaluation-playbook-from-experiments-to-enterprise-value"&gt;The CFO’s AI evaluation playbook: From experiments to enterprise value&lt;/h2&gt;



&lt;p&gt;As AI transitions from experimental projects to enterprise-critical systems, CFOs are developing more disciplined, comprehensive frameworks for evaluating these investments. The most successful approaches strike a balance between rigor and flexibility, acknowledging both the unique characteristics of AI and its integration into broader business strategy.&lt;/p&gt;



&lt;p&gt;The emerging CFO playbook for AI evaluation contains several key elements that differentiate leaders from followers. &lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;First is the implementation of multi-dimensional ROI frameworks that capture both efficiency gains and strategic value creation. Rather than focusing exclusively on cost reduction, these frameworks incorporate productivity enhancements, decision quality improvements and competitive differentiation into a holistic value assessment.&lt;/li&gt;



&lt;li&gt;Second is the adoption of phased evaluation approaches that align with AI’s evolutionary nature. Leading CFOs establish clear metrics for each development stage — from initial pilots to scaled deployment — with appropriate risk adjustments and expected returns for each phase. This approach recognizes that AI investments often follow a J-curve, with value accelerating as systems mature and applications expand.&lt;/li&gt;



&lt;li&gt;Third is the integration of AI metrics into standard financial planning and reporting processes. Rather than treating AI as a special category with unique evaluation criteria, forward-thinking finance leaders are incorporating AI performance indicators into regular budget reviews, capital allocation decisions and investor communications. This normalization signals AI’s transition from experimental technology to core business capability.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;The most sophisticated organizations are also implementing formal governance structures that connect AI investments directly to strategic objectives. These governance frameworks ensure that AI initiatives remain aligned with enterprise priorities while providing the necessary oversight to manage risks effectively. By establishing clear accountability for both technical performance and business outcomes, these structures help prevent the disconnection between AI capabilities and business value that has plagued many early adopters.&lt;/p&gt;



&lt;p&gt;As investors and boards increasingly scrutinize AI investments, CFOs are developing more transparent reporting approaches that clearly communicate both current returns and future potential. These reports typically include standardized metrics that track AI’s contribution to operational efficiency, customer experience, employee productivity and strategic differentiation — providing a comprehensive view of how these investments enhance shareholder value.&lt;/p&gt;



&lt;p&gt;The organizations gaining a competitive advantage through AI are those where CFOs have moved to become strategic partners in AI transformation. These finance leaders work closely with technology and business teams to identify high-value use cases, establish appropriate success metrics and create financial frameworks that support responsible innovation while maintaining appropriate risk management.&lt;/p&gt;



&lt;p&gt;The CFOs who master these new evaluation frameworks will drive the next wave of AI adoption — one characterized not by speculative experimentation but by disciplined investment in capabilities that deliver sustainable competitive advantage. As AI continues to transform business models and market dynamics, these financial frameworks will become increasingly critical to organizational success.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-the-cfo-s-ai-evaluation-framework-key-metrics-and-considerations"&gt;The CFO’s AI evaluation framework: Key metrics and considerations&lt;/h3&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Evaluation dimension&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Traditional metrics&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Emerging AI metrics&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Key considerations&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Cost reduction&lt;br /&gt;• Time savings&lt;br /&gt;• Headcount impact&lt;/td&gt;&lt;td&gt;• Cost-per-output&lt;br /&gt;• Process acceleration ratio&lt;br /&gt;• Labor reallocation value&lt;/td&gt;&lt;td&gt;• Measure both direct and indirect efficiency gains&lt;br /&gt;• Establish clear pre-implementation baselines&lt;br /&gt;• Track productivity improvements beyond cost savings&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Amortization&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Fixed depreciation schedules&lt;br /&gt;• Standard ROI timelines&lt;br /&gt;• Uniform capital allocation&lt;/td&gt;&lt;td&gt;• Learning curve adjustments&lt;br /&gt;• Value acceleration factors&lt;br /&gt;• Pilot-to-scale validation&lt;/td&gt;&lt;td&gt;• Recognize AI’s improving returns over time&lt;br /&gt;• Apply different timelines for different AI applications&lt;br /&gt;• Implement phase-gated funding tied to performance&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Strategic Value&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Revenue impact&lt;br /&gt;• Margin improvement&lt;br /&gt;• Market share&lt;/td&gt;&lt;td&gt;• Decision quality metrics&lt;br /&gt;• Data asset appreciation&lt;br /&gt;• Strategic optionality value&lt;/td&gt;&lt;td&gt;• Connect AI investments to competitive differentiation&lt;br /&gt;• Quantify both current and future strategic benefits&lt;br /&gt;• Measure contribution to innovation capabilities&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Risk management&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Implementation risk&lt;br /&gt;• Technical performance risk&lt;br /&gt;• Financial exposure&lt;/td&gt;&lt;td&gt;• Data privacy risk premium&lt;br /&gt;• Regulatory compliance factor&lt;br /&gt;• Explainability/transparency risk&lt;/td&gt;&lt;td&gt;• Apply risk-weighted adjustments to projected returns&lt;br /&gt;• Quantify mitigation costs and residual risk&lt;br /&gt;• Factor in emerging regulatory and ethical considerations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Governance&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Project-based oversight&lt;br /&gt;• Technical success metrics&lt;br /&gt;• Siloed accountability&lt;/td&gt;&lt;td&gt;• Enterprise AI governance&lt;br /&gt;• Cross-functional value metrics&lt;br /&gt;• Integrated performance dashboards&lt;/td&gt;&lt;td&gt;• Align AI governance with corporate governance&lt;br /&gt;• Establish clear ownership of business outcomes&lt;br /&gt;• Create transparent reporting mechanisms for all stakeholders&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-CFOs-want-AI-that-pays_-Real-metrics-not-marketing-demos.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Recent surveys and VentureBeat’s conversations with CFOs suggest the honeymoon phase of AI is rapidly drawing to a close. While 2024 was dominated by pilot programs and proof-of-concept demonstrations, in mid-2025, the pressure for measurable results is intensifying, even as CFO interest in AI remains high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to a KPMG survey of 300 U.S. financial executives, investor pressure to demonstrate ROI on generative AI investments has increased significantly. For 90% of organizations, investor pressure is considered “important or very important” for demonstrating ROI in Q1 2025, a sharp increase from 68% in Q4 2024. This indicates a strong and intensifying demand for measurable returns.&lt;/p&gt;



&lt;p&gt;Meanwhile, according to a Bain Capital Ventures survey of 50 CFOs, 79% plan to increase their AI budgets this year, with 94% believing gen AI can strongly benefit at least one finance activity. This reveals a telling pattern in how CFOs are currently measuring AI value. Those who have adopted gen AI tools report seeing initial returns primarily through efficiency gains.&lt;/p&gt;&lt;p&gt;“We created a custom workflow that automates vendor identification to quickly prepare journal entries,” said Andrea Ellis, CFO of Fanatics Betting and Gaming. “This process used to take 20 hours during month-end close, and now, it takes us just 2 hours each month.” &lt;/p&gt;



&lt;p&gt;Jason Whiting, CFO of Mercury Financial, echoed this efficiency focus: “Across the board, [the biggest benefit] has been the ability to increase speed of analysis. Gen AI hasn’t replaced anything, but it has made our existing processes and people better.”&lt;/p&gt;



&lt;p&gt;But CFOs are now looking beyond simple time savings toward more strategic applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Bain data shows CFOs are most excited about applying AI to “long-standing pain points that prior generations of technology have been unable to solve.” Cosmin Pitigoi, CFO of Flywire, explained: “Forecasting trends based on large data sets has been around for a long time, but the issue has always been the model’s ability to explain the assumptions behind the forecast. AI can help not just with forecasting, but also with explaining what assumptions have changed over time.”&lt;/p&gt;



&lt;p&gt;These recent surveys suggest that CFOs are becoming the primary gatekeepers for AI investment; however, they’re still developing the financial frameworks necessary to evaluate these investments properly. Those who develop robust evaluation methodologies first will likely gain significant competitive advantages. Those who don’t may find their AI enthusiasm outpacing their ability to measure and manage the returns.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-efficiency-metrics-the-first-wave-of-ai-value"&gt;Efficiency metrics: The first wave of AI value&lt;/h2&gt;



&lt;p&gt;The initial wave of AI value capture by finance departments has focused predominantly on efficiency metrics, with CFOs prioritizing measurable time and cost savings that deliver immediate returns. This focus on efficiency represents the low-hanging fruit of AI implementation — clear, quantifiable benefits that are easily tracked and communicated to stakeholders.&lt;/p&gt;



&lt;p&gt;Drip Capital, a Silicon Valley-based fintech, exemplifies this approach with its AI implementation in trade finance operations. According to chief business officer Karl Boog, “We’ve been able to 30X our capacity with what we’ve done so far.” By automating document processing and enhancing risk assessment through large language models (LLMs), the company achieved a remarkable 70% productivity boost while maintaining critical human oversight for complex decisions.&lt;/p&gt;



&lt;p&gt;KPMG research indicates this approach is widespread, with one retail company audit committee director noting how automation has improved operational efficiency and ROI. This sentiment is echoed across industries as finance leaders seek to justify their AI investments with tangible productivity improvements.&lt;/p&gt;



&lt;p&gt;These efficiency improvements translate directly to the bottom line. Companies across sectors — from insurance to oil and gas — report that AI helps identify process inefficiencies, leading to substantial organizational cost savings and improved expense management.&lt;/p&gt;



&lt;p&gt;Beyond simple cost reduction, CFOs are developing more sophisticated efficiency metrics to evaluate AI investments. These include time-to-completion ratios comparing pre- and post-AI implementation timelines, cost-per-transaction analyses measuring reductions in resource expenditure and labor hour reallocation metrics tracking how team members shift from manual data processing to higher-value analytical work.&lt;/p&gt;



&lt;p&gt;However, leading CFOs recognize that while efficiency metrics provide a solid foundation for initial ROI calculations, they represent just the beginning of AI’s potential value. As finance leaders gain confidence in measuring these direct returns, they’re developing more comprehensive frameworks to capture AI’s full strategic value — moving well beyond the efficiency calculations that characterized early adoption phases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beyond-efficiency-the-new-financial-metrics"&gt;Beyond efficiency: The new financial metrics&lt;/h2&gt;



&lt;p&gt;As CFOs move beyond the initial fascination with AI-driven efficiency gains, they’re developing new financial metrics that more comprehensively capture AI’s business impact. This evolution reflects a maturing approach to AI investments, with finance leaders adopting more sophisticated evaluation frameworks that align with broader corporate objectives.&lt;/p&gt;



&lt;p&gt;The surveys highlight a notable shift in primary ROI metrics. While efficiency gains remain important, we see productivity metrics are now overtaking pure profitability measures as the chief priority for AI initiatives in 2025. This represents a fundamental change in how CFOs assess value, focusing on AI’s ability to enhance human capabilities rather than simply reduce costs.&lt;/p&gt;



&lt;p&gt;Time to value (TTV) is emerging as a critical new metric in investment decisions. Only about one-third of AI leaders anticipate being able to evaluate ROI within six months, making rapid time-to-value a key consideration when comparing different AI opportunities. This metric will help CFOs prioritize quick-win projects that can deliver measurable returns while building organizational confidence in larger AI initiatives.&lt;/p&gt;



&lt;p&gt;Data quality measurements will increasingly be incorporated into evaluation frameworks, with 64% of leaders citing data quality as their most significant AI challenge. Forward-thinking CFOs now incorporate data readiness assessments and ongoing data quality metrics into their AI business cases, recognizing that even the most promising AI applications will fail without high-quality data inputs.&lt;/p&gt;



&lt;p&gt;Adoption rate metrics have also become standard in AI evaluation. Finance leaders track how quickly and extensively AI tools are being utilized across departments, using this as a leading indicator of potential value realization. These metrics help identify implementation challenges early and inform decisions about additional training or system modifications.&lt;/p&gt;



&lt;p&gt;“The biggest benefit has been the ability to increase speed of analysis,” noted Jason Whiting of Mercury Financial. This perspective represents the bridge between simple efficiency metrics and more sophisticated value assessments — recognizing that AI’s value often comes not from replacing existing processes but enhancing them.&lt;/p&gt;



&lt;p&gt;Some CFOs are implementing comprehensive ROI formulas that incorporate both direct and indirect benefits (VAI Consulting):&lt;/p&gt;



&lt;p&gt;ROI = (Net Benefit / Total Cost) × 100&lt;/p&gt;



&lt;p&gt;Where net benefit equals the sum of direct financial benefits plus an estimated value of indirect benefits, minus total investment costs. This approach acknowledges that AI’s full value encompasses both quantifiable savings and intangible strategic advantages, such as improved decision quality and enhanced customer experience.&lt;/p&gt;



&lt;p&gt;For companies with more mature AI implementations, these new metrics are becoming increasingly standardized and integrated into regular financial reporting. The most sophisticated organizations now produce AI value scorecards that track multiple dimensions of performance, linking AI system outputs directly to business outcomes and financial results.&lt;/p&gt;



&lt;p&gt;As CFOs refine these new financial metrics, they’re creating a more nuanced picture of AI’s true value — one that extends well beyond the simple time and cost savings that dominated early adoption phases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-amortization-timelines-recalibrating-investment-horizons"&gt;Amortization timelines: Recalibrating investment horizons&lt;/h2&gt;



&lt;p&gt;CFOs are fundamentally rethinking how they amortize AI investments, developing new approaches that acknowledge the unique characteristics of these technologies. Unlike traditional IT systems with predictable depreciation schedules, AI investments often yield evolving returns that increase as systems learn and improve over time. Leading finance executives now evaluate AI investments through the lens of sustainable competitive advantage — asking not just “How much will this save?” but “How will this transform our market position?”&lt;/p&gt;



&lt;p&gt;“ROI directly correlates with AI maturity,” according to KPMG, which found that 61% of AI leaders report higher-than-expected ROI, compared with only 33% of beginners and implementers. This correlation is prompting CFOs to develop more sophisticated amortization models that anticipate accelerating returns as AI deployments mature.&lt;/p&gt;



&lt;p&gt;The difficulty in establishing accurate amortization timelines remains a significant barrier to AI adoption. “Uncertain ROI/difficulty developing a business case” is cited as a challenge by 33% of executives, particularly those in the early stages of AI implementation. This uncertainty has led to a more cautious, phased approach to investment.&lt;/p&gt;



&lt;p&gt;To address this challenge, leading finance teams are implementing pilot-to-scale methodologies to validate ROI before full deployment. This approach enables CFOs to gather accurate performance data, refine their amortization estimates, and make more informed scaling decisions.&lt;/p&gt;



&lt;p&gt;The timeframe for expected returns varies significantly based on the type of AI implementation. Automation-focused AI typically delivers more predictable short-term returns, whereas strategic applications, such as improved forecasting, may have longer, less certain payback periods. Progressive CFOs are developing differentiated amortization schedules that reflect these variations rather than applying one-size-fits-all approaches.&lt;/p&gt;



&lt;p&gt;Some finance leaders are adopting rolling amortization models that are adjusted quarterly based on actual performance data. This approach acknowledges the dynamic nature of AI returns and allows for ongoing refinement of financial projections. Rather than setting fixed amortization schedules at the outset, these models incorporate learning curves and performance improvements into evolving financial forecasts.&lt;/p&gt;



&lt;p&gt;One entertainment company implemented a gen AI-driven tool that scans financial developments, identifies anomalies and automatically generates executive-ready alerts. While the immediate ROI stemmed from efficiency gains, the CFO developed an amortization model that also factored in the system’s increasing accuracy over time and its expanding application across various business units.&lt;/p&gt;



&lt;p&gt;Many CFOs are also factoring in how AI investments contribute to building proprietary data assets that appreciate rather than depreciate over time. Unlike traditional technology investments that lose value as they age, AI systems and their associated data repositories often become more valuable as they accumulate training data and insights.&lt;/p&gt;



&lt;p&gt;This evolving approach to amortization represents a significant departure from traditional IT investment models. By developing more nuanced timelines that reflect AI’s unique characteristics, CFOs are creating financial frameworks that better capture the true economic value of these investments and support a more strategic allocation of resources.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-strategic-value-integration-linking-ai-to-shareholder-returns"&gt;Strategic value integration: Linking AI to shareholder returns&lt;/h2&gt;



&lt;p&gt;Forward-thinking CFOs are moving beyond operational metrics to integrate AI investments into broader frameworks for creating shareholder value. This shift represents a fundamental evolution in how financial executives evaluate AI — positioning it not merely as a cost-saving technology but as a strategic asset that drives enterprise growth and competitive differentiation.&lt;/p&gt;



&lt;p&gt;This more sophisticated approach assesses AI’s impact on three critical dimensions of shareholder value: revenue acceleration, risk reduction and strategic optionality. Each dimension requires different metrics and evaluation frameworks, creating a more comprehensive picture of AI’s contribution to enterprise value.&lt;/p&gt;



&lt;p&gt;Revenue acceleration metrics focus on how AI enhances top-line growth by improving customer acquisition, increasing the share of wallet and expanding market reach. These metrics track AI’s influence on sales velocity, conversion rates, customer lifetime value and price optimization — connecting algorithmic capabilities directly to revenue performance.&lt;/p&gt;



&lt;p&gt;Risk reduction frameworks assess how AI enhances forecasting accuracy, improves scenario planning, strengthens fraud detection and optimizes capital allocation. By quantifying risk-adjusted returns, CFOs can demonstrate how AI investments reduce earnings volatility and improve business resilience — factors that directly impact valuation multiples.&lt;/p&gt;



&lt;p&gt;Perhaps most importantly, leading CFOs are developing methods to value strategic optionality — the capacity of AI investments to create new business possibilities that didn’t previously exist. This approach recognizes that AI often delivers its most significant value by enabling entirely new business models or unlocking previously inaccessible market opportunities.&lt;/p&gt;



&lt;p&gt;To effectively communicate this strategic value, finance leaders are creating new reporting mechanisms tailored to different stakeholders. Some are establishing comprehensive AI value scorecards that link system performance to tangible business outcomes, incorporating both lagging indicators (financial results) and leading indicators (operational improvements) that predict future financial performance.&lt;/p&gt;



&lt;p&gt;Executive dashboards now regularly feature AI-related metrics alongside traditional financial KPIs, making AI more visible to senior leadership. These integrated views enable executives to understand how AI investments align with strategic priorities and shareholder expectations.&lt;/p&gt;



&lt;p&gt;For board and investor communication, CFOs are developing structured approaches that highlight both immediate financial returns and long-term strategic advantages. Rather than treating AI as a specialized technology investment, these frameworks position it as a fundamental business capability that drives sustainable competitive differentiation.&lt;/p&gt;



&lt;p&gt;By developing these integrated strategic value frameworks, CFOs ensure that AI investments are evaluated not only on their immediate operational impact but their contribution to the company’s long-term competitive position and shareholder returns. This more sophisticated approach is rapidly becoming a key differentiator between companies that treat AI as a tactical tool and those that leverage it as a strategic asset.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-risk-adjusted-returns-the-risk-management-equation"&gt;Risk-adjusted returns: The risk management equation&lt;/h2&gt;



&lt;p&gt;As AI investments grow in scale and strategic importance, CFOs are incorporating increasingly sophisticated risk assessments into their financial evaluations. This evolution reflects the unique challenges AI presents — balancing unprecedented opportunities against novel risks that traditional financial models often fail to capture.&lt;/p&gt;



&lt;p&gt;The risk landscape for AI investments is multifaceted and evolving rapidly. Recent surveys indicate that risk management, particularly in relation to data privacy, is expected to be the biggest challenge to generative AI strategies for 82% of leaders in 2025. This concern is followed closely by data quality issues (64%) and questions of trust in AI outputs (35%).&lt;/p&gt;



&lt;p&gt;Forward-thinking finance leaders are developing comprehensive risk-adjusted return frameworks that quantify and incorporate these various risk factors. Rather than treating risk as a binary go/no-go consideration, these frameworks assign monetary values to different risk categories and integrate them directly into ROI calculations.&lt;/p&gt;



&lt;p&gt;Data security and privacy vulnerabilities represent a primary concern, with 57% of executives citing these as top challenges. CFOs are now calculating potential financial exposure from data breaches or privacy violations and factoring these costs into their investment analyses. This includes estimating potential regulatory fines, litigation expenses, remediation costs and reputational damage.&lt;/p&gt;



&lt;p&gt;Regulatory compliance represents another significant risk factor. With many executives concerned about ensuring compliance with changing regulations, financial evaluations increasingly include contingency allocations for regulatory adaptation. An aerospace company executive noted that “complex regulations make it difficult for us to achieve AI readiness,” highlighting how regulatory uncertainty complicates financial planning.&lt;/p&gt;



&lt;p&gt;Beyond these external risks, CFOs are quantifying implementation risks such as adoption failures, integration challenges and technical performance issues. By assigning probability-weighted costs to these scenarios, they create more realistic projections that acknowledge the inherent uncertainties in AI deployment.&lt;/p&gt;



&lt;p&gt;The “black box” nature of certain AI technologies presents unique challenges for risk assessment. As stakeholders become increasingly wary of trusting AI results without understanding the underlying logic, CFOs are developing frameworks to evaluate transparency risks and their potential financial implications. This includes estimating the costs of additional validation procedures, explainability tools and human oversight mechanisms.&lt;/p&gt;



&lt;p&gt;Some companies are adopting formal risk-adjustment methodologies borrowed from other industries. One approach applies a modified weighted average cost of capital (WACC) that incorporates AI-specific risk premiums. Others use risk-adjusted net present value calculations that explicitly account for the unique uncertainty profiles of different AI applications.&lt;/p&gt;



&lt;p&gt;The transportation sector provides an illustrative example of this evolving approach. As one chief data officer noted, “The data received from AI requires human verification, and this is an important step that we overlook.” This recognition has led transportation CFOs to build verification costs directly into their financial models rather than treating them as optional add-ons.&lt;/p&gt;



&lt;p&gt;By incorporating these sophisticated risk adjustments into their financial evaluations, CFOs are creating more realistic assessments of AI’s true economic value. This approach enables more confident investment decisions and helps organizations maintain appropriate risk levels as they scale their AI capabilities.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cfo-s-ai-evaluation-playbook-from-experiments-to-enterprise-value"&gt;The CFO’s AI evaluation playbook: From experiments to enterprise value&lt;/h2&gt;



&lt;p&gt;As AI transitions from experimental projects to enterprise-critical systems, CFOs are developing more disciplined, comprehensive frameworks for evaluating these investments. The most successful approaches strike a balance between rigor and flexibility, acknowledging both the unique characteristics of AI and its integration into broader business strategy.&lt;/p&gt;



&lt;p&gt;The emerging CFO playbook for AI evaluation contains several key elements that differentiate leaders from followers. &lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;First is the implementation of multi-dimensional ROI frameworks that capture both efficiency gains and strategic value creation. Rather than focusing exclusively on cost reduction, these frameworks incorporate productivity enhancements, decision quality improvements and competitive differentiation into a holistic value assessment.&lt;/li&gt;



&lt;li&gt;Second is the adoption of phased evaluation approaches that align with AI’s evolutionary nature. Leading CFOs establish clear metrics for each development stage — from initial pilots to scaled deployment — with appropriate risk adjustments and expected returns for each phase. This approach recognizes that AI investments often follow a J-curve, with value accelerating as systems mature and applications expand.&lt;/li&gt;



&lt;li&gt;Third is the integration of AI metrics into standard financial planning and reporting processes. Rather than treating AI as a special category with unique evaluation criteria, forward-thinking finance leaders are incorporating AI performance indicators into regular budget reviews, capital allocation decisions and investor communications. This normalization signals AI’s transition from experimental technology to core business capability.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;The most sophisticated organizations are also implementing formal governance structures that connect AI investments directly to strategic objectives. These governance frameworks ensure that AI initiatives remain aligned with enterprise priorities while providing the necessary oversight to manage risks effectively. By establishing clear accountability for both technical performance and business outcomes, these structures help prevent the disconnection between AI capabilities and business value that has plagued many early adopters.&lt;/p&gt;



&lt;p&gt;As investors and boards increasingly scrutinize AI investments, CFOs are developing more transparent reporting approaches that clearly communicate both current returns and future potential. These reports typically include standardized metrics that track AI’s contribution to operational efficiency, customer experience, employee productivity and strategic differentiation — providing a comprehensive view of how these investments enhance shareholder value.&lt;/p&gt;



&lt;p&gt;The organizations gaining a competitive advantage through AI are those where CFOs have moved to become strategic partners in AI transformation. These finance leaders work closely with technology and business teams to identify high-value use cases, establish appropriate success metrics and create financial frameworks that support responsible innovation while maintaining appropriate risk management.&lt;/p&gt;



&lt;p&gt;The CFOs who master these new evaluation frameworks will drive the next wave of AI adoption — one characterized not by speculative experimentation but by disciplined investment in capabilities that deliver sustainable competitive advantage. As AI continues to transform business models and market dynamics, these financial frameworks will become increasingly critical to organizational success.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-the-cfo-s-ai-evaluation-framework-key-metrics-and-considerations"&gt;The CFO’s AI evaluation framework: Key metrics and considerations&lt;/h3&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Evaluation dimension&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Traditional metrics&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Emerging AI metrics&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Key considerations&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Cost reduction&lt;br /&gt;• Time savings&lt;br /&gt;• Headcount impact&lt;/td&gt;&lt;td&gt;• Cost-per-output&lt;br /&gt;• Process acceleration ratio&lt;br /&gt;• Labor reallocation value&lt;/td&gt;&lt;td&gt;• Measure both direct and indirect efficiency gains&lt;br /&gt;• Establish clear pre-implementation baselines&lt;br /&gt;• Track productivity improvements beyond cost savings&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Amortization&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Fixed depreciation schedules&lt;br /&gt;• Standard ROI timelines&lt;br /&gt;• Uniform capital allocation&lt;/td&gt;&lt;td&gt;• Learning curve adjustments&lt;br /&gt;• Value acceleration factors&lt;br /&gt;• Pilot-to-scale validation&lt;/td&gt;&lt;td&gt;• Recognize AI’s improving returns over time&lt;br /&gt;• Apply different timelines for different AI applications&lt;br /&gt;• Implement phase-gated funding tied to performance&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Strategic Value&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Revenue impact&lt;br /&gt;• Margin improvement&lt;br /&gt;• Market share&lt;/td&gt;&lt;td&gt;• Decision quality metrics&lt;br /&gt;• Data asset appreciation&lt;br /&gt;• Strategic optionality value&lt;/td&gt;&lt;td&gt;• Connect AI investments to competitive differentiation&lt;br /&gt;• Quantify both current and future strategic benefits&lt;br /&gt;• Measure contribution to innovation capabilities&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Risk management&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Implementation risk&lt;br /&gt;• Technical performance risk&lt;br /&gt;• Financial exposure&lt;/td&gt;&lt;td&gt;• Data privacy risk premium&lt;br /&gt;• Regulatory compliance factor&lt;br /&gt;• Explainability/transparency risk&lt;/td&gt;&lt;td&gt;• Apply risk-weighted adjustments to projected returns&lt;br /&gt;• Quantify mitigation costs and residual risk&lt;br /&gt;• Factor in emerging regulatory and ethical considerations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Governance&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;• Project-based oversight&lt;br /&gt;• Technical success metrics&lt;br /&gt;• Siloed accountability&lt;/td&gt;&lt;td&gt;• Enterprise AI governance&lt;br /&gt;• Cross-functional value metrics&lt;br /&gt;• Integrated performance dashboards&lt;/td&gt;&lt;td&gt;• Align AI governance with corporate governance&lt;br /&gt;• Establish clear ownership of business outcomes&lt;br /&gt;• Create transparent reporting mechanisms for all stakeholders&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/cfos-want-ai-that-pays-real-metrics-not-marketing-demos/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] Why your enterprise AI strategy needs both open and closed models: The TCO reality check (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/why-your-enterprise-ai-strategy-needs-both-open-and-closed-models-the-tco-reality-check/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-Why-your-enterprise-AI-strategy-needs-both-open-and-closed-models_-The-TCO-reality-check-1.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;For the last two decades, enterprises have had a choice between open-source and closed proprietary technologies.&lt;/p&gt;



&lt;p&gt;The original choice for enterprises was primarily centered on operating systems, with Linux offering an open-source alternative to Microsoft Windows. In the developer realm, open-source languages like Python and JavaScript dominate, as open-source technologies, including Kubernetes, are standards in the cloud.&lt;/p&gt;



&lt;p&gt;The same type of choice between open and closed is now facing enterprises for AI, with multiple options for both types of models. On the proprietary closed-model front are some of the biggest, most widely used models on the planet, including those from OpenAI and Anthropic. On the open-source side are models like Meta’s Llama, IBM Granite, Alibaba’s Qwen and DeepSeek.&lt;/p&gt;



&lt;p&gt;Understanding when to use an open or closed model is a critical choice for enterprise AI decision-makers in 2025 and beyond. The choice has both financial and customization implications for either options that enterprises need to understand and consider.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-the-difference-between-open-and-closed-licenses"&gt;Understanding the difference between open and closed licenses&lt;/h2&gt;



&lt;p&gt;There is no shortage of hyperbole around the decades-old rivalry between open and closed licenses.  But what does it all actually mean for enterprise users?&lt;/p&gt;



&lt;p&gt;A closed-source proprietary technology, like OpenAI’s GPT 4o for example, does not have model code, training data, or model weights open or available for anyone to see. The model is not easily available to be fine-tuned and generally speaking, it is only available for real enterprise usage with a cost (sure, ChatGPT has a free tier,&lt;em&gt; but that’s not going to cut it for a real enterprise workload&lt;/em&gt;).&lt;/p&gt;



&lt;p&gt;An open technology, like Meta Llama, IBM Granite, or DeepSeek, has openly available code. Enterprises can use the models freely, generally without restrictions, including fine-tuning and customizations.&lt;/p&gt;



&lt;p&gt;Rohan Gupta, a principal with Deloitte, told VentureBeat that the open vs. closed source debate isn’t unique or native to AI, nor is it likely to be resolved anytime soon.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gupta explained that closed source providers typically offer several wrappers around their model that enable ease of use, simplified scaling, more seamless upgrades and downgrades and a steady stream of enhancements. They also provide significant developer support. That includes documentation as well as hands-on advice and often delivers tighter integrations with both infrastructure and applications. In exchange, an enterprise pays a premium for these services.&lt;/p&gt;



&lt;p&gt;&amp;nbsp;“Open-source models, on the other hand, can provide greater control, flexibility and customization options, and are supported by a vibrant, enthusiastic developer ecosystem,” Gupta said. “These models are increasingly accessible via fully managed APIs across cloud vendors, broadening their distribution.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-the-choice-between-open-and-closed-model-for-enterprise-ai"&gt;Making the choice between open and closed model for enterprise AI&lt;/h2&gt;



&lt;p&gt;The question that many enterprise users might ask is what’s better: an open or a closed model? The answer however is not necessarily one or the other.&lt;/p&gt;



&lt;p&gt;“We don’t view this as a binary choice,” David Guarrera, Generative AI Leader at EY Americas, told VentureBeat. ” Open vs closed is increasingly a fluid design space, where models are selected, or even automatically orchestrated, based on tradeoffs between accuracy, latency, cost, interpretability and security at different points in a workflow.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Guarrera noted that closed models limit how deeply organizations can optimize or adapt behavior.  Proprietary model vendors often restrict fine-tuning, charge premium rates, or hide the process in black boxes. While API-based tools simplify integration, they abstract away much of the control, making it harder to build highly specific or interpretable systems.&lt;/p&gt;



&lt;p&gt;In contrast, open-source models allow for targeted fine-tuning, guardrail design and optimization for specific use cases. This matters more in an agentic future, where models are no longer monolithic general-purpose tools, but interchangeable components within dynamic workflows. The ability to finely shape model behavior, at low cost and with full transparency, becomes a major competitive advantage when deploying task-specific agents or tightly regulated solutions.&lt;/p&gt;



&lt;p&gt;“In practice, we foresee an agentic future where model selection is abstracted away,” Guarrera said.&lt;/p&gt;



&lt;p&gt;For example, a user may draft an email with one AI tool, summarize legal docs with another, search enterprise documents with a fine-tuned open-source model and interact with AI locally through an on-device LLM, all without ever knowing which model is doing what.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The real question becomes: what mix of models best suits your workflow’s specific demands?” Guarrera said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-considering-total-cost-of-ownership"&gt;Considering total cost of ownership&lt;/h2&gt;



&lt;p&gt;With open models, the basic idea is that the model is freely available for use. While in contrast, enterprises always pay for closed models.&lt;/p&gt;



&lt;p&gt;The reality when it comes to considering total cost of ownership (TCO) is more nuanced.&lt;/p&gt;



&lt;p&gt;Praveen Akkiraju, Managing Director at Insight Partners explained to VentureBeat that TCO has many different layers. A few key considerations include infrastructure hosting costs and engineering: Are the open-source models self-hosted by the enterprise or the cloud provider? How much engineering, including fine-tuning, guard railing and security testing, is needed to operationalize the model safely?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Akkiraju noted that&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;fine-tuning an open weights model can also sometimes be a very complex task. Closed frontier model companies spend enormous engineering effort to ensure performance across multiple tasks.  In his view, unless enterprises deploy similar engineering expertise, they will face a complex balancing act when fine-tuning open source models. This creates cost implications when organizations choose their model deployment strategy. For example, enterprises can fine-tune multiple model versions for different tasks or use one API for multiple tasks.&lt;/p&gt;



&lt;p&gt;Ryan Gross, Head of Data &amp;amp; Applications at cloud native services provider Caylent told VentureBeat that from his perspective, licensing terms don’t matter, except for in edge case scenarios. The largest restrictions often pertain to model availability when data residency requirements are in place. In this case, deploying an open model on infrastructure like Amazon SageMaker may be the only way to get a state-of-the-art model that still complies. When it comes to TCO, Gross noted that the tradeoff lies between per-token costs and hosting and maintenance costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“There is a clear break-even point where the economics switch from closed to open models being cheaper,” Gross said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In his view, for most organizations, closed models, with the hosting and scaling solved on the organization’s behalf, will have a lower TCO. However, for large enterprises, SaaS companies with very high demand on their LLMs, but simpler use-cases requiring frontier performance, or AI-centric product companies, hosting distilled open models can be more cost-effective.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-one-enterprise-software-developer-evaluated-open-vs-closed-models"&gt;How one enterprise software developer evaluated open vs closed models&lt;/h2&gt;



&lt;p&gt;Josh Bosquez, CTO at Second Front Systems is among the many firms that have had to consider and evaluate open vs closed models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We use both open and closed AI models, depending on the specific use case, security requirements and strategic objectives,” Bosquez told VentureBeat.&lt;/p&gt;



&lt;p&gt;Bosquez explained that open models allow his firm to integrate cutting-edge capabilities without the time or cost of training models from scratch. For internal experimentation or rapid prototyping, open models help his firm to iterate quickly and benefit from community-driven advancements.&lt;/p&gt;



&lt;p&gt;“Closed models, on the other hand, are our choice when data sovereignty, enterprise-grade support and security guarantees are essential, particularly for customer-facing applications or deployments involving sensitive or regulated environments,” he said. “These models often come from trusted vendors, who offer strong performance, compliance support, and self-hosting options.”&lt;/p&gt;



&lt;p&gt;Bosquez said that the model selection process is cross-functional and risk-informed, evaluating not only technical fit but also data handling policies, integration requirements and long-term scalability.&lt;/p&gt;



&lt;p&gt;Looking at TCO, he said that it varies significantly between open and closed models and neither approach is universally cheaper.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It depends on the deployment scope and organizational maturity,” Bosquez said. “Ultimately, we evaluate TCO not just on dollars spent, but on delivery speed, compliance risk and the ability to scale securely.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-means-for-enterprise-ai-strategy"&gt;What this means for enterprise AI strategy&lt;/h2&gt;



&lt;p&gt;For smart tech decision-makers evaluating AI investments in 2025, the open vs. closed debate isn’t about picking sides. It’s about building a strategic portfolio approach that optimizes for different use cases within your organization.&lt;/p&gt;



&lt;p&gt;The immediate action items are straightforward. First, audit your current AI workloads and map them against the decision framework outlined by the experts, considering accuracy requirements, latency needs, cost constraints, security demands and compliance obligations for each use case. Second, honestly assess your organization’s engineering capabilities for model fine-tuning, hosting and maintenance, as this directly impacts your true total cost of ownership.&lt;/p&gt;



&lt;p&gt;Third, begin experimenting with model orchestration platforms that can automatically route tasks to the most appropriate model, whether open or closed. This positions your organization for the agentic future that industry leaders, such as EY’s Guarrera, predict, where model selection becomes invisible to end-users.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-Why-your-enterprise-AI-strategy-needs-both-open-and-closed-models_-The-TCO-reality-check-1.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;For the last two decades, enterprises have had a choice between open-source and closed proprietary technologies.&lt;/p&gt;



&lt;p&gt;The original choice for enterprises was primarily centered on operating systems, with Linux offering an open-source alternative to Microsoft Windows. In the developer realm, open-source languages like Python and JavaScript dominate, as open-source technologies, including Kubernetes, are standards in the cloud.&lt;/p&gt;



&lt;p&gt;The same type of choice between open and closed is now facing enterprises for AI, with multiple options for both types of models. On the proprietary closed-model front are some of the biggest, most widely used models on the planet, including those from OpenAI and Anthropic. On the open-source side are models like Meta’s Llama, IBM Granite, Alibaba’s Qwen and DeepSeek.&lt;/p&gt;



&lt;p&gt;Understanding when to use an open or closed model is a critical choice for enterprise AI decision-makers in 2025 and beyond. The choice has both financial and customization implications for either options that enterprises need to understand and consider.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-the-difference-between-open-and-closed-licenses"&gt;Understanding the difference between open and closed licenses&lt;/h2&gt;



&lt;p&gt;There is no shortage of hyperbole around the decades-old rivalry between open and closed licenses.  But what does it all actually mean for enterprise users?&lt;/p&gt;



&lt;p&gt;A closed-source proprietary technology, like OpenAI’s GPT 4o for example, does not have model code, training data, or model weights open or available for anyone to see. The model is not easily available to be fine-tuned and generally speaking, it is only available for real enterprise usage with a cost (sure, ChatGPT has a free tier,&lt;em&gt; but that’s not going to cut it for a real enterprise workload&lt;/em&gt;).&lt;/p&gt;



&lt;p&gt;An open technology, like Meta Llama, IBM Granite, or DeepSeek, has openly available code. Enterprises can use the models freely, generally without restrictions, including fine-tuning and customizations.&lt;/p&gt;



&lt;p&gt;Rohan Gupta, a principal with Deloitte, told VentureBeat that the open vs. closed source debate isn’t unique or native to AI, nor is it likely to be resolved anytime soon.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gupta explained that closed source providers typically offer several wrappers around their model that enable ease of use, simplified scaling, more seamless upgrades and downgrades and a steady stream of enhancements. They also provide significant developer support. That includes documentation as well as hands-on advice and often delivers tighter integrations with both infrastructure and applications. In exchange, an enterprise pays a premium for these services.&lt;/p&gt;



&lt;p&gt;&amp;nbsp;“Open-source models, on the other hand, can provide greater control, flexibility and customization options, and are supported by a vibrant, enthusiastic developer ecosystem,” Gupta said. “These models are increasingly accessible via fully managed APIs across cloud vendors, broadening their distribution.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-the-choice-between-open-and-closed-model-for-enterprise-ai"&gt;Making the choice between open and closed model for enterprise AI&lt;/h2&gt;



&lt;p&gt;The question that many enterprise users might ask is what’s better: an open or a closed model? The answer however is not necessarily one or the other.&lt;/p&gt;



&lt;p&gt;“We don’t view this as a binary choice,” David Guarrera, Generative AI Leader at EY Americas, told VentureBeat. ” Open vs closed is increasingly a fluid design space, where models are selected, or even automatically orchestrated, based on tradeoffs between accuracy, latency, cost, interpretability and security at different points in a workflow.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Guarrera noted that closed models limit how deeply organizations can optimize or adapt behavior.  Proprietary model vendors often restrict fine-tuning, charge premium rates, or hide the process in black boxes. While API-based tools simplify integration, they abstract away much of the control, making it harder to build highly specific or interpretable systems.&lt;/p&gt;



&lt;p&gt;In contrast, open-source models allow for targeted fine-tuning, guardrail design and optimization for specific use cases. This matters more in an agentic future, where models are no longer monolithic general-purpose tools, but interchangeable components within dynamic workflows. The ability to finely shape model behavior, at low cost and with full transparency, becomes a major competitive advantage when deploying task-specific agents or tightly regulated solutions.&lt;/p&gt;



&lt;p&gt;“In practice, we foresee an agentic future where model selection is abstracted away,” Guarrera said.&lt;/p&gt;



&lt;p&gt;For example, a user may draft an email with one AI tool, summarize legal docs with another, search enterprise documents with a fine-tuned open-source model and interact with AI locally through an on-device LLM, all without ever knowing which model is doing what.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The real question becomes: what mix of models best suits your workflow’s specific demands?” Guarrera said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-considering-total-cost-of-ownership"&gt;Considering total cost of ownership&lt;/h2&gt;



&lt;p&gt;With open models, the basic idea is that the model is freely available for use. While in contrast, enterprises always pay for closed models.&lt;/p&gt;



&lt;p&gt;The reality when it comes to considering total cost of ownership (TCO) is more nuanced.&lt;/p&gt;



&lt;p&gt;Praveen Akkiraju, Managing Director at Insight Partners explained to VentureBeat that TCO has many different layers. A few key considerations include infrastructure hosting costs and engineering: Are the open-source models self-hosted by the enterprise or the cloud provider? How much engineering, including fine-tuning, guard railing and security testing, is needed to operationalize the model safely?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Akkiraju noted that&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;fine-tuning an open weights model can also sometimes be a very complex task. Closed frontier model companies spend enormous engineering effort to ensure performance across multiple tasks.  In his view, unless enterprises deploy similar engineering expertise, they will face a complex balancing act when fine-tuning open source models. This creates cost implications when organizations choose their model deployment strategy. For example, enterprises can fine-tune multiple model versions for different tasks or use one API for multiple tasks.&lt;/p&gt;



&lt;p&gt;Ryan Gross, Head of Data &amp;amp; Applications at cloud native services provider Caylent told VentureBeat that from his perspective, licensing terms don’t matter, except for in edge case scenarios. The largest restrictions often pertain to model availability when data residency requirements are in place. In this case, deploying an open model on infrastructure like Amazon SageMaker may be the only way to get a state-of-the-art model that still complies. When it comes to TCO, Gross noted that the tradeoff lies between per-token costs and hosting and maintenance costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“There is a clear break-even point where the economics switch from closed to open models being cheaper,” Gross said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In his view, for most organizations, closed models, with the hosting and scaling solved on the organization’s behalf, will have a lower TCO. However, for large enterprises, SaaS companies with very high demand on their LLMs, but simpler use-cases requiring frontier performance, or AI-centric product companies, hosting distilled open models can be more cost-effective.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-one-enterprise-software-developer-evaluated-open-vs-closed-models"&gt;How one enterprise software developer evaluated open vs closed models&lt;/h2&gt;



&lt;p&gt;Josh Bosquez, CTO at Second Front Systems is among the many firms that have had to consider and evaluate open vs closed models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We use both open and closed AI models, depending on the specific use case, security requirements and strategic objectives,” Bosquez told VentureBeat.&lt;/p&gt;



&lt;p&gt;Bosquez explained that open models allow his firm to integrate cutting-edge capabilities without the time or cost of training models from scratch. For internal experimentation or rapid prototyping, open models help his firm to iterate quickly and benefit from community-driven advancements.&lt;/p&gt;



&lt;p&gt;“Closed models, on the other hand, are our choice when data sovereignty, enterprise-grade support and security guarantees are essential, particularly for customer-facing applications or deployments involving sensitive or regulated environments,” he said. “These models often come from trusted vendors, who offer strong performance, compliance support, and self-hosting options.”&lt;/p&gt;



&lt;p&gt;Bosquez said that the model selection process is cross-functional and risk-informed, evaluating not only technical fit but also data handling policies, integration requirements and long-term scalability.&lt;/p&gt;



&lt;p&gt;Looking at TCO, he said that it varies significantly between open and closed models and neither approach is universally cheaper.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It depends on the deployment scope and organizational maturity,” Bosquez said. “Ultimately, we evaluate TCO not just on dollars spent, but on delivery speed, compliance risk and the ability to scale securely.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-means-for-enterprise-ai-strategy"&gt;What this means for enterprise AI strategy&lt;/h2&gt;



&lt;p&gt;For smart tech decision-makers evaluating AI investments in 2025, the open vs. closed debate isn’t about picking sides. It’s about building a strategic portfolio approach that optimizes for different use cases within your organization.&lt;/p&gt;



&lt;p&gt;The immediate action items are straightforward. First, audit your current AI workloads and map them against the decision framework outlined by the experts, considering accuracy requirements, latency needs, cost constraints, security demands and compliance obligations for each use case. Second, honestly assess your organization’s engineering capabilities for model fine-tuning, hosting and maintenance, as this directly impacts your true total cost of ownership.&lt;/p&gt;



&lt;p&gt;Third, begin experimenting with model orchestration platforms that can automatically route tasks to the most appropriate model, whether open or closed. This positions your organization for the agentic future that industry leaders, such as EY’s Guarrera, predict, where model selection becomes invisible to end-users.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/why-your-enterprise-ai-strategy-needs-both-open-and-closed-models-the-tco-reality-check/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] Scaling smarter: How enterprise IT teams can right-size their compute for AI (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/scaling-smarter-how-enterprise-it-teams-can-right-size-their-compute-for-ai/</link><description>&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI pilots rarely start with a deep discussion of infrastructure and hardware. But seasoned scalers warn that deploying high-value production workloads will not end happily without strategic, ongoing focus on a key enterprise-grade foundation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Good news: There’s growing recognition by enterprises about the pivotal role infrastructure plays in enabling and expanding generative, agentic and other intelligent applications that drive revenue, cost reduction and efficiency gains.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to IDC, organizations in 2025 have boosted spending on compute and storage hardware infrastructure for AI deployments by 97% compared to the same period a year before. &lt;span&gt;Researchers &lt;/span&gt;predict global investment in the space will surge from $150 billion today to&amp;nbsp;$200 billion by 2028.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the competitive edge “doesn’t go to those who spend the most,” John Thompson, best-selling AI author and head of the gen AI Advisory practice at The Hackett Group said in an interview with VentureBeat, “but to those who scale most intelligently.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ignore-infrastructure-and-hardware-at-your-own-peril-nbsp"&gt;Ignore infrastructure and hardware at your own peril&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Other experts agree, saying that chances are slim-to-none that enterprises can expand and industrialize AI workloads without careful planning and right-sizing of the finely orchestrated mesh of processors and accelerators, as well as upgraded power and cooling systems. These purpose-built hardware components provide the speed, availability, flexibility and scalability required to handle unprecedented data volume, movement and velocity from edge to on-prem to cloud.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;img alt="A screenshot of a computer component list

AI-generated content may be incorrect." height="418" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcoH3mfJUtDADjKke0wFis_YUhI89Thir2ocXWUu1nImXVJmlEQkQv2gvK2IHem-ZWzMHOflJdLE9oou-jqKBV8zgKhOMagTMAXGK_7-VLbaE_7onTzZfEpxSg8uYlzIUrv5Fp2JQ?key=Ao-l7o0GQ9lENtz6i_uBmQ" width="612" /&gt;&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Source: VentureBeat&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Study after study identifies infrastructure-related issues, such as performance bottlenecks, mismatched hardware and poor legacy integration, alongside data problems, as major pilot killers. Exploding interest and investment in agentic AI further raise the technological, competitive and financial stakes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Among tech companies, a bellwether for &lt;span&gt;the entire industry,&amp;nbsp;nearly 50%&amp;nbsp;have agent AI projects underway; the rest will have them&amp;nbsp;&lt;/span&gt;going in 24 months. They are allocating half or more of their current AI budgets to agentic, and many plan further increases this year. (Good thing,&amp;nbsp; because these complex autonomous systems require costly, scarce GPUs and TPUs to operate independently and in real time across multiple platforms.)&lt;/p&gt;



&lt;p&gt;From their experience with pilots, technology and business leaders now understand that the &lt;span&gt;demanding requirements of AI workloads — high-speed processing, networking, storage, orchestration and &lt;/span&gt;&lt;span&gt;immense electrical&lt;/span&gt; power — are unlike anything they’ve ever built at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For many enterprises, the pressing question is, “Are we ready to do this?”&lt;strong&gt; &lt;/strong&gt;The honest answer will be: Not without careful ongoing analysis, planning and, likely, non-trivial IT upgrades.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-they-ve-scaled-the-ai-mountain-listen"&gt;They’ve scaled the AI mountain — listen&lt;/h2&gt;



&lt;p&gt;Like snowflakes and children, we’re reminded that AI projects are similar yet unique. Demands differ wildly between various AI functions and types (training versus inference, machine learning vs reinforcement). So, too, do wide variances exist in business goals, budgets, technology debt, vendor lock-in and available skills and capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Predictably, then, there’s no single “best” approach. Depending on circumstances, you’ll scale AI infrastructure up or horizontally (more power for increased loads), out or vertically (upgrading existing hardware) or hybrid (both).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, these early-chapter mindsets, principles, recommendations, practices, real-life examples and cost-saving hacks can help keep your efforts aimed and moving in the right direction.&lt;/p&gt;



&lt;p&gt;&amp;nbsp;It’s a sprawling challenge, with lots of layers: data, software, networking, security and storage. We’ll keep the focus high-level and include links to helpful, related drill-downs, such as those above.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-modernize-your-vision-of-ai-infrastructure-nbsp-nbsp"&gt;Modernize your vision of AI infrastructure&amp;nbsp;&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;The biggest mindset shift is adopting a new conception of AI — not as a standalone or siloed app, but as a foundational capability or platform embedded across business processes, workflows and tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To make this happen, infrastructure must balance two important roles: Providing a stable, secure and compliant enterprise foundation, while making it easy to quickly and reliably field purpose-built AI workloads and applications, often with tailored hardware optimized for specific domains like natural language processing (NLP) and reinforcement learning.&lt;/p&gt;



&lt;p&gt;In essence, it’s a major role reversal, said Deb Golden, Deloitte’s chief innovation officer. “AI must be treated like an operating system, with infrastructure that adapts to it, not the other way around.”&lt;/p&gt;



&lt;p&gt;She continued: “The future isn’t just about sophisticated models and algorithms. Hardware is no longer passive. [So from now on], infrastructure is fundamentally about orchestrating intelligent hardware as the operating system for AI.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To operate this way at scale and without waste requires a “fluid fabric,” Golden’s term for the dynamic allocation that adapts in real-time across every platform, from individual silicon chips up to complete workloads. Benefits can be huge: Her team found that this approach can cut costs by 30 to 40% and latency by 15 to 20%. “If your AI isn’t breathing with the workload, it’s suffocating.”&lt;/p&gt;



&lt;p&gt;It’s a demanding challenge. Such AI infrastructure must be multi-tier, cloud-native, open, real-time, dynamic, flexible and modular. It needs to be highly and intelligently orchestrated across edge and mobile devices, on-premises data centers, AI PCs and workstations, and hybrid and public cloud environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What sounds like buzzword bingo represents a new epoch in the ongoing evolution, redefining and optimizing enterprise IT infrastructure for AI. The main elements are familiar: hybrid environments, a fast-growing universe of increasingly specialized cloud-based services, frameworks and platforms.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this new chapter, embracing architectural modularity is key for long-term success, said Ken Englund, EY Americas technology growth leader. “Your ability to integrate different tools, agents, solutions and platforms will be critical. Modularity creates flexibility in your frameworks and architectures.”&lt;/p&gt;



&lt;p&gt;Decoupling systems components helps future-proof in several ways, including vendor and technology agnosticism, lug-and-play model enhancement and continuous innovation and scalability.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-infrastructure-investment-for-scaling-ai-must-balance-prudence-and-power-nbsp-nbsp"&gt;Infrastructure investment for scaling AI must balance prudence and power&amp;nbsp;&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;Enterprise technology teams looking to expand their use of enterprise AI face an updated Goldilocks challenge: Finding the “just right” investment levels in new, modern infrastructure and hardware that can handle the fast-growing, shifting demands of distributed, everywhere AI.&lt;/p&gt;



&lt;p&gt;Under-invest or stick with current processing capabilities? You’re looking at show-stopping performance bottlenecks and subpar business outcomes that can tank entire projects (and careers).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over-invest in shiny new AI infrastructure? Say hello to massive capital and ongoing operating expenditures, idle resources and operational complexity that nobody needs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Even more than in other IT efforts,&amp;nbsp; seasoned scalers agreed that simply throwing processing power at problems isn’t a winning strategy. Yet it remains a temptation, even if not fully intentional.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Jobs with minimal AI needs often get routed to expensive GPU or TPU infrastructure,” said Mine Bayrak Ozmen, a transformation veteran who’s led enterprise AI deployments at Fortune 500 companies and a Center of AI Excellence for a major global consultancy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Ironically, said Ozmen, also co-founder of AI platform company Riernio, “it’s simply because AI-centric design choices have overtaken more classical organization principles.” Unfortunately, the long-term cost inefficiencies of such deployments can get masked by deep discounts from hardware vendors, she said.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-right-size-ai-infrastructure-with-proper-scoping-and-distribution-not-raw-power"&gt;Right-size AI infrastructure with proper scoping and distribution, not raw power&lt;/h3&gt;



&lt;p&gt;What, then, should guide strategic and tactical choices? One thing that &lt;em&gt;should not&lt;/em&gt;, experts agreed, is a paradoxically misguided reasoning: Because infrastructure for AI must deliver ultra-high performance, more powerful processors and hardware must be better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;“AI scaling is&amp;nbsp;&lt;em&gt;not&lt;/em&gt;&amp;nbsp;about brute-force compute,” said Hackett’s Thompson, who has led numerous large global AI projects and is the author of&amp;nbsp;&lt;em&gt;The Path to AGI: Artificial General Intelligence: Past, Present, and Future&lt;/em&gt;,&lt;em&gt;&amp;nbsp;&lt;/em&gt;published in February.&lt;/span&gt; He and others emphasize that the goal is having the right hardware in the right place at the right time, not the biggest and baddest everywhere. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to Ozmen, successful scalers employ “a right-size for right-executing approach.” That means “optimizing workload placement (inference vs. training), managing context locality, and leveraging policy-driven orchestration to reduce redundancy, improve observability and drive sustained growth.”&lt;/p&gt;



&lt;p&gt;Sometimes the analysis and decision are back-of-a-napkin simple.&amp;nbsp; “A generative AI system serving 200 employees might run just fine on a single server,” Thomspon said. But it’s a whole different case for more complex initiatives.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Take an AI-enabled core enterprise system for hundreds of thousands of users worldwide, requiring cloud-native failover and serious scaling capabilities. In these cases, Thompson said, right-sizing infrastructure demands disciplined, rigorous scoping, distribution and scaling exercises. Anything else is foolhardy malpractice.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Surprisingly, such basic IT planning discipline can get skipped. It’s often companies, desperate to gain a competitive advantage, that try to speed up things by aiming outsized infrastructure budgets at a key AI project.&lt;/p&gt;



&lt;p&gt;New Hackett research challenges some basic assumptions about what is truly needed in infrastructure for scaling AI, providing additional reasons to conduct rigorous upfront analysis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thompson’s own real-world experience is instructive. Building an AI customer support system with over 300,000 users, his team soon realized it was “more important to have global coverage than massive capacity in any single location.” Accordingly, infrastructure is located across the U.S., Europe and the Asia-Pacific region; users are dynamically routed worldwide.&lt;/p&gt;



&lt;p&gt;The practical takeaway advice?&amp;nbsp; “Put fences around things. Is it 300,000 users or 200? Scope dictates infrastructure,” he said. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-right-hardware-in-the-right-place-for-the-right-job"&gt;The right hardware in the right place for the right job&lt;/h2&gt;



&lt;p&gt;A modern multi-tiered AI infrastructure strategy relies on versatile processors and accelerators that can be optimized for various roles across the continuum. For helpful insights on choosing processors, check out &amp;nbsp;Going Beyond GPUs&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="A table with text on it

AI-generated content may be incorrect." src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd4m8odJiQ62hZwP0ttheGFlyc1rt-DmPFKtgsZIEzoJ3rIavDcNFkwNrG77xPTdxDoWMwvO6LLxPJZ4CfdVahc59YdqSw4f2Vfabyjkvm6sM8OFerwT_cjrf5jIVjbNoLgMf5xHA?key=Ao-l7o0GQ9lENtz6i_uBmQ" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Source: VentureBeat&lt;/em&gt;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-sourcing-infrastructure-for-ai-scaling-cloud-services-for-most-nbsp"&gt;Sourcing infrastructure for AI scaling: cloud services for most&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="4"&gt;
&lt;li&gt;
&lt;/li&gt;&lt;/ol&gt;



&lt;p&gt;You’ve got a fresh picture of what AI scaling infrastructure can and should be, a good idea about the investment sweet spot and scope, and what’s needed where. Now it’s time for procurement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As noted in VentureBeat’s last special issue, for most enterprises, the most effective strategy will be to continue using&amp;nbsp;cloud-based infrastructure&amp;nbsp;and equipment to scale AI production.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Surveys of large organizations show most have transitioned from custom on-premises data centers to public cloud platforms and pre-built AI solutions. For many, this represents a next-step continuation of ongoing modernization that sidesteps big upfront capital outlays and talent scrambles while providing critical flexibility for quickly changing requirements.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over the next three years, Gartner predicts ,50% of cloud compute resources will be devoted to AI workloads, up from less than 10% today. Some enterprises are also upgrading on-premises data centers with accelerated compute, faster memory and high-bandwidth networking.&lt;/p&gt;



&lt;p&gt;The good news: Amazon, AWS, Microsoft, Google and a booming universe of specialty providers continue to invest staggering sums in end-to-end offerings built and optimized for AI, including full -stack infrastructure, platforms, processing including GPU cloud providers, HPC, storage (hyperscalers plus Dell, HPE, Hitachi Vantara), frameworks and myriad other managed services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Especially for organizations wanting to dip their toes quickly, said Wyatt Mayham, lead AI consultant at Northwest AI Consulting, cloud services offer a great, low-hassle choice.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a company already running Microsoft, for example, “Azure OpenAI is a natural extension [that] requires little architecture to get running safely and compliantly,” he said. “It avoids the complexity of spinning up custom LLM infrastructure, while still giving companies the security and control they need. It’s a great quick-win use case.”&lt;/p&gt;



&lt;p&gt;However, the bounty of options available to technology decision-makers has another side. Selecting the appropriate services can be daunting, especially as more enterprises opt for multi-cloud approaches that span multiple providers. Issues of compatibility, consistent security, liabilities, service levels and onsite resource requirements can quickly become entangled in a complex web, slowing development and deployment.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To simplify things, organizations may decide to stick with a primary provider or two. Here, as in pre-AI cloud hosting, the danger of vendor lock-in looms (although open standards offer the possibility of choice). Hanging over all this is the specter of past and recent attempts to migrate infrastructure to paid cloud services, only to discover, with horror, that costs far surpass the original expectations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All this explains why experts say that the IT 101 discipline of knowing as clearly as possible what performance and capacity are needed – at the edge, on-premises, in cloud applications, everywhere – is crucial before starting procurement.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-take-a-fresh-look-at-on-premises"&gt;Take a fresh look at on-premises&lt;/h2&gt;



&lt;p&gt;Conventional wisdom suggests that handling infrastructure internally is primarily reserved for deep-pocketed enterprises and heavily regulated industries. However, in this new AI chapter, key in-house elements are being re-evaluated, often as part of a hybrid right-sizing strategy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Take Microblink, which provides AI-powered document scanning and identity verification services to clients worldwide. Using Google Cloud Platform (GCP) to support high-throughput ML workloads and data-intensive applications, the company quickly ran into issues with cost and scalability, said Filip Suste, engineering manager of platform teams. “GPU availability was limited, unpredictable and expensive,” he noted.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address these problems, Suste’s teams made a strategic shift, moving computer workloads and supporting infrastructure on-premises. A key piece in the shift to hybrid was a high-performance, cloud-native object storage system from MinIo.&lt;/p&gt;



&lt;p&gt;For Microblink, taking key infrastructure back in-house paid off. Doing so cut related costs by 62%, reduced idle capacity and improved training efficiency, the company said. Crucially, it also regained control over AI infrastructure, thereby improving customer security.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-consider-a-specialty-ai-platform-nbsp"&gt;Consider a specialty AI platform&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Makino, a Japanese manufacturer of computer-controlled machining centers operating in 40 countries, faced a classic skills gap problem. Less experienced engineers could take up to 30 hours to complete repairs that more seasoned workers can do in eight.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To close the gap and improve customer service, leadership decided to turn two decades of maintenance data into instantly accessible expertise. The fastest and most cost-effective solution, they concluded, is to integrate an existing service-management system with a specialized AI platform for service professionals from Aquant.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company says taking the easy technology path produced great results. Instead of laboriously evaluating different infrastructure scenarios, resources were focused on standardizing lexicon and developing processes and procedures, Ken Creech, Makino’s director of customer support, explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Remote resolution of problems has increased by 15%, solution times have decreased, and customers now have self-service access to the system, Creech said. “Now, our engineers ask a plain-language question, and the AI hunts down the answer quickly. It’s a big wow factor.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-adopt-mindful-cost-avoidance-hacks"&gt;Adopt mindful cost-avoidance hacks&lt;/h2&gt;



&lt;p&gt;At Albertsons, one of the nation’s largest food and drug chains, IT teams employ several simple but effective tactics to optimize AI infrastructure without adding new hardware, said Chandrakanth Puligundla, tech lead for data analysis, engineering and governance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gravity mapping, for example, shows where data is stored and how it’s moved, whether on edge devices, internal systems or on multi-cloud systems. This knowledge not only reduces egress costs and latency, Puligundla explained, but guides more informed decisions about where to allocate computing resources.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Similarly, he said, using specialist AI tools for language processing or image identification takes less space, often delivering better performance and economy than adding or updating more expensive servers and general-purpose computers.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another cost-avoidance hack: Tracking watts per inference or training hour.&amp;nbsp;Looking beyond speed and cost to energy-efficiency metrics prioritizes sustainable performance, which is crucial for increasingly power-thirsty AI models and hardware.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Puligundla concluded: “We can really increase efficiency through this kind of mindful preparation.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-write-your-own-ending-nbsp"&gt;Write your own ending&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The success of AI pilots has brought millions of companies to the next phase of their journeys: Deploying generative and LLMs, agents and other intelligent applications with high business value into wider production.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The latest AI chapter promises rich rewards for enterprises that strategically assemble infrastructure and hardware that balances performance, cost, flexibility and scalability across edge computing, on-premises systems and cloud environments.&lt;/p&gt;



&lt;p&gt;&lt;span&gt;In the coming months, scaling options will expand further, as industry investments continue to pour into hyper-scale data centers, edge chips and hardware (AMD, Qualcomm, Huawei),&amp;nbsp;cloud-based AI full-stack infrastructure like Canonical and Guru,&amp;nbsp;context-aware memory,&amp;nbsp;secure on-prem plug-and-play devices like&amp;nbsp;Lemony,&amp;nbsp;and much more.&lt;/span&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;How wisely IT and business leaders plan and choose infrastructure for expansion will determine the heroes of company stories and the unfortunates doomed to pilot purgatory or AI damnation.&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI pilots rarely start with a deep discussion of infrastructure and hardware. But seasoned scalers warn that deploying high-value production workloads will not end happily without strategic, ongoing focus on a key enterprise-grade foundation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Good news: There’s growing recognition by enterprises about the pivotal role infrastructure plays in enabling and expanding generative, agentic and other intelligent applications that drive revenue, cost reduction and efficiency gains.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to IDC, organizations in 2025 have boosted spending on compute and storage hardware infrastructure for AI deployments by 97% compared to the same period a year before. &lt;span&gt;Researchers &lt;/span&gt;predict global investment in the space will surge from $150 billion today to&amp;nbsp;$200 billion by 2028.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the competitive edge “doesn’t go to those who spend the most,” John Thompson, best-selling AI author and head of the gen AI Advisory practice at The Hackett Group said in an interview with VentureBeat, “but to those who scale most intelligently.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ignore-infrastructure-and-hardware-at-your-own-peril-nbsp"&gt;Ignore infrastructure and hardware at your own peril&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Other experts agree, saying that chances are slim-to-none that enterprises can expand and industrialize AI workloads without careful planning and right-sizing of the finely orchestrated mesh of processors and accelerators, as well as upgraded power and cooling systems. These purpose-built hardware components provide the speed, availability, flexibility and scalability required to handle unprecedented data volume, movement and velocity from edge to on-prem to cloud.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;img alt="A screenshot of a computer component list

AI-generated content may be incorrect." height="418" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcoH3mfJUtDADjKke0wFis_YUhI89Thir2ocXWUu1nImXVJmlEQkQv2gvK2IHem-ZWzMHOflJdLE9oou-jqKBV8zgKhOMagTMAXGK_7-VLbaE_7onTzZfEpxSg8uYlzIUrv5Fp2JQ?key=Ao-l7o0GQ9lENtz6i_uBmQ" width="612" /&gt;&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Source: VentureBeat&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Study after study identifies infrastructure-related issues, such as performance bottlenecks, mismatched hardware and poor legacy integration, alongside data problems, as major pilot killers. Exploding interest and investment in agentic AI further raise the technological, competitive and financial stakes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Among tech companies, a bellwether for &lt;span&gt;the entire industry,&amp;nbsp;nearly 50%&amp;nbsp;have agent AI projects underway; the rest will have them&amp;nbsp;&lt;/span&gt;going in 24 months. They are allocating half or more of their current AI budgets to agentic, and many plan further increases this year. (Good thing,&amp;nbsp; because these complex autonomous systems require costly, scarce GPUs and TPUs to operate independently and in real time across multiple platforms.)&lt;/p&gt;



&lt;p&gt;From their experience with pilots, technology and business leaders now understand that the &lt;span&gt;demanding requirements of AI workloads — high-speed processing, networking, storage, orchestration and &lt;/span&gt;&lt;span&gt;immense electrical&lt;/span&gt; power — are unlike anything they’ve ever built at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For many enterprises, the pressing question is, “Are we ready to do this?”&lt;strong&gt; &lt;/strong&gt;The honest answer will be: Not without careful ongoing analysis, planning and, likely, non-trivial IT upgrades.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-they-ve-scaled-the-ai-mountain-listen"&gt;They’ve scaled the AI mountain — listen&lt;/h2&gt;



&lt;p&gt;Like snowflakes and children, we’re reminded that AI projects are similar yet unique. Demands differ wildly between various AI functions and types (training versus inference, machine learning vs reinforcement). So, too, do wide variances exist in business goals, budgets, technology debt, vendor lock-in and available skills and capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Predictably, then, there’s no single “best” approach. Depending on circumstances, you’ll scale AI infrastructure up or horizontally (more power for increased loads), out or vertically (upgrading existing hardware) or hybrid (both).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, these early-chapter mindsets, principles, recommendations, practices, real-life examples and cost-saving hacks can help keep your efforts aimed and moving in the right direction.&lt;/p&gt;



&lt;p&gt;&amp;nbsp;It’s a sprawling challenge, with lots of layers: data, software, networking, security and storage. We’ll keep the focus high-level and include links to helpful, related drill-downs, such as those above.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-modernize-your-vision-of-ai-infrastructure-nbsp-nbsp"&gt;Modernize your vision of AI infrastructure&amp;nbsp;&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;The biggest mindset shift is adopting a new conception of AI — not as a standalone or siloed app, but as a foundational capability or platform embedded across business processes, workflows and tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To make this happen, infrastructure must balance two important roles: Providing a stable, secure and compliant enterprise foundation, while making it easy to quickly and reliably field purpose-built AI workloads and applications, often with tailored hardware optimized for specific domains like natural language processing (NLP) and reinforcement learning.&lt;/p&gt;



&lt;p&gt;In essence, it’s a major role reversal, said Deb Golden, Deloitte’s chief innovation officer. “AI must be treated like an operating system, with infrastructure that adapts to it, not the other way around.”&lt;/p&gt;



&lt;p&gt;She continued: “The future isn’t just about sophisticated models and algorithms. Hardware is no longer passive. [So from now on], infrastructure is fundamentally about orchestrating intelligent hardware as the operating system for AI.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To operate this way at scale and without waste requires a “fluid fabric,” Golden’s term for the dynamic allocation that adapts in real-time across every platform, from individual silicon chips up to complete workloads. Benefits can be huge: Her team found that this approach can cut costs by 30 to 40% and latency by 15 to 20%. “If your AI isn’t breathing with the workload, it’s suffocating.”&lt;/p&gt;



&lt;p&gt;It’s a demanding challenge. Such AI infrastructure must be multi-tier, cloud-native, open, real-time, dynamic, flexible and modular. It needs to be highly and intelligently orchestrated across edge and mobile devices, on-premises data centers, AI PCs and workstations, and hybrid and public cloud environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What sounds like buzzword bingo represents a new epoch in the ongoing evolution, redefining and optimizing enterprise IT infrastructure for AI. The main elements are familiar: hybrid environments, a fast-growing universe of increasingly specialized cloud-based services, frameworks and platforms.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this new chapter, embracing architectural modularity is key for long-term success, said Ken Englund, EY Americas technology growth leader. “Your ability to integrate different tools, agents, solutions and platforms will be critical. Modularity creates flexibility in your frameworks and architectures.”&lt;/p&gt;



&lt;p&gt;Decoupling systems components helps future-proof in several ways, including vendor and technology agnosticism, lug-and-play model enhancement and continuous innovation and scalability.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-infrastructure-investment-for-scaling-ai-must-balance-prudence-and-power-nbsp-nbsp"&gt;Infrastructure investment for scaling AI must balance prudence and power&amp;nbsp;&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;Enterprise technology teams looking to expand their use of enterprise AI face an updated Goldilocks challenge: Finding the “just right” investment levels in new, modern infrastructure and hardware that can handle the fast-growing, shifting demands of distributed, everywhere AI.&lt;/p&gt;



&lt;p&gt;Under-invest or stick with current processing capabilities? You’re looking at show-stopping performance bottlenecks and subpar business outcomes that can tank entire projects (and careers).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over-invest in shiny new AI infrastructure? Say hello to massive capital and ongoing operating expenditures, idle resources and operational complexity that nobody needs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Even more than in other IT efforts,&amp;nbsp; seasoned scalers agreed that simply throwing processing power at problems isn’t a winning strategy. Yet it remains a temptation, even if not fully intentional.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Jobs with minimal AI needs often get routed to expensive GPU or TPU infrastructure,” said Mine Bayrak Ozmen, a transformation veteran who’s led enterprise AI deployments at Fortune 500 companies and a Center of AI Excellence for a major global consultancy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Ironically, said Ozmen, also co-founder of AI platform company Riernio, “it’s simply because AI-centric design choices have overtaken more classical organization principles.” Unfortunately, the long-term cost inefficiencies of such deployments can get masked by deep discounts from hardware vendors, she said.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-right-size-ai-infrastructure-with-proper-scoping-and-distribution-not-raw-power"&gt;Right-size AI infrastructure with proper scoping and distribution, not raw power&lt;/h3&gt;



&lt;p&gt;What, then, should guide strategic and tactical choices? One thing that &lt;em&gt;should not&lt;/em&gt;, experts agreed, is a paradoxically misguided reasoning: Because infrastructure for AI must deliver ultra-high performance, more powerful processors and hardware must be better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;“AI scaling is&amp;nbsp;&lt;em&gt;not&lt;/em&gt;&amp;nbsp;about brute-force compute,” said Hackett’s Thompson, who has led numerous large global AI projects and is the author of&amp;nbsp;&lt;em&gt;The Path to AGI: Artificial General Intelligence: Past, Present, and Future&lt;/em&gt;,&lt;em&gt;&amp;nbsp;&lt;/em&gt;published in February.&lt;/span&gt; He and others emphasize that the goal is having the right hardware in the right place at the right time, not the biggest and baddest everywhere. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to Ozmen, successful scalers employ “a right-size for right-executing approach.” That means “optimizing workload placement (inference vs. training), managing context locality, and leveraging policy-driven orchestration to reduce redundancy, improve observability and drive sustained growth.”&lt;/p&gt;



&lt;p&gt;Sometimes the analysis and decision are back-of-a-napkin simple.&amp;nbsp; “A generative AI system serving 200 employees might run just fine on a single server,” Thomspon said. But it’s a whole different case for more complex initiatives.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Take an AI-enabled core enterprise system for hundreds of thousands of users worldwide, requiring cloud-native failover and serious scaling capabilities. In these cases, Thompson said, right-sizing infrastructure demands disciplined, rigorous scoping, distribution and scaling exercises. Anything else is foolhardy malpractice.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Surprisingly, such basic IT planning discipline can get skipped. It’s often companies, desperate to gain a competitive advantage, that try to speed up things by aiming outsized infrastructure budgets at a key AI project.&lt;/p&gt;



&lt;p&gt;New Hackett research challenges some basic assumptions about what is truly needed in infrastructure for scaling AI, providing additional reasons to conduct rigorous upfront analysis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thompson’s own real-world experience is instructive. Building an AI customer support system with over 300,000 users, his team soon realized it was “more important to have global coverage than massive capacity in any single location.” Accordingly, infrastructure is located across the U.S., Europe and the Asia-Pacific region; users are dynamically routed worldwide.&lt;/p&gt;



&lt;p&gt;The practical takeaway advice?&amp;nbsp; “Put fences around things. Is it 300,000 users or 200? Scope dictates infrastructure,” he said. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-right-hardware-in-the-right-place-for-the-right-job"&gt;The right hardware in the right place for the right job&lt;/h2&gt;



&lt;p&gt;A modern multi-tiered AI infrastructure strategy relies on versatile processors and accelerators that can be optimized for various roles across the continuum. For helpful insights on choosing processors, check out &amp;nbsp;Going Beyond GPUs&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="A table with text on it

AI-generated content may be incorrect." src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd4m8odJiQ62hZwP0ttheGFlyc1rt-DmPFKtgsZIEzoJ3rIavDcNFkwNrG77xPTdxDoWMwvO6LLxPJZ4CfdVahc59YdqSw4f2Vfabyjkvm6sM8OFerwT_cjrf5jIVjbNoLgMf5xHA?key=Ao-l7o0GQ9lENtz6i_uBmQ" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Source: VentureBeat&lt;/em&gt;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-sourcing-infrastructure-for-ai-scaling-cloud-services-for-most-nbsp"&gt;Sourcing infrastructure for AI scaling: cloud services for most&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="4"&gt;
&lt;li&gt;
&lt;/li&gt;&lt;/ol&gt;



&lt;p&gt;You’ve got a fresh picture of what AI scaling infrastructure can and should be, a good idea about the investment sweet spot and scope, and what’s needed where. Now it’s time for procurement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As noted in VentureBeat’s last special issue, for most enterprises, the most effective strategy will be to continue using&amp;nbsp;cloud-based infrastructure&amp;nbsp;and equipment to scale AI production.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Surveys of large organizations show most have transitioned from custom on-premises data centers to public cloud platforms and pre-built AI solutions. For many, this represents a next-step continuation of ongoing modernization that sidesteps big upfront capital outlays and talent scrambles while providing critical flexibility for quickly changing requirements.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over the next three years, Gartner predicts ,50% of cloud compute resources will be devoted to AI workloads, up from less than 10% today. Some enterprises are also upgrading on-premises data centers with accelerated compute, faster memory and high-bandwidth networking.&lt;/p&gt;



&lt;p&gt;The good news: Amazon, AWS, Microsoft, Google and a booming universe of specialty providers continue to invest staggering sums in end-to-end offerings built and optimized for AI, including full -stack infrastructure, platforms, processing including GPU cloud providers, HPC, storage (hyperscalers plus Dell, HPE, Hitachi Vantara), frameworks and myriad other managed services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Especially for organizations wanting to dip their toes quickly, said Wyatt Mayham, lead AI consultant at Northwest AI Consulting, cloud services offer a great, low-hassle choice.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a company already running Microsoft, for example, “Azure OpenAI is a natural extension [that] requires little architecture to get running safely and compliantly,” he said. “It avoids the complexity of spinning up custom LLM infrastructure, while still giving companies the security and control they need. It’s a great quick-win use case.”&lt;/p&gt;



&lt;p&gt;However, the bounty of options available to technology decision-makers has another side. Selecting the appropriate services can be daunting, especially as more enterprises opt for multi-cloud approaches that span multiple providers. Issues of compatibility, consistent security, liabilities, service levels and onsite resource requirements can quickly become entangled in a complex web, slowing development and deployment.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To simplify things, organizations may decide to stick with a primary provider or two. Here, as in pre-AI cloud hosting, the danger of vendor lock-in looms (although open standards offer the possibility of choice). Hanging over all this is the specter of past and recent attempts to migrate infrastructure to paid cloud services, only to discover, with horror, that costs far surpass the original expectations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All this explains why experts say that the IT 101 discipline of knowing as clearly as possible what performance and capacity are needed – at the edge, on-premises, in cloud applications, everywhere – is crucial before starting procurement.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-take-a-fresh-look-at-on-premises"&gt;Take a fresh look at on-premises&lt;/h2&gt;



&lt;p&gt;Conventional wisdom suggests that handling infrastructure internally is primarily reserved for deep-pocketed enterprises and heavily regulated industries. However, in this new AI chapter, key in-house elements are being re-evaluated, often as part of a hybrid right-sizing strategy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Take Microblink, which provides AI-powered document scanning and identity verification services to clients worldwide. Using Google Cloud Platform (GCP) to support high-throughput ML workloads and data-intensive applications, the company quickly ran into issues with cost and scalability, said Filip Suste, engineering manager of platform teams. “GPU availability was limited, unpredictable and expensive,” he noted.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address these problems, Suste’s teams made a strategic shift, moving computer workloads and supporting infrastructure on-premises. A key piece in the shift to hybrid was a high-performance, cloud-native object storage system from MinIo.&lt;/p&gt;



&lt;p&gt;For Microblink, taking key infrastructure back in-house paid off. Doing so cut related costs by 62%, reduced idle capacity and improved training efficiency, the company said. Crucially, it also regained control over AI infrastructure, thereby improving customer security.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-consider-a-specialty-ai-platform-nbsp"&gt;Consider a specialty AI platform&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Makino, a Japanese manufacturer of computer-controlled machining centers operating in 40 countries, faced a classic skills gap problem. Less experienced engineers could take up to 30 hours to complete repairs that more seasoned workers can do in eight.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To close the gap and improve customer service, leadership decided to turn two decades of maintenance data into instantly accessible expertise. The fastest and most cost-effective solution, they concluded, is to integrate an existing service-management system with a specialized AI platform for service professionals from Aquant.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company says taking the easy technology path produced great results. Instead of laboriously evaluating different infrastructure scenarios, resources were focused on standardizing lexicon and developing processes and procedures, Ken Creech, Makino’s director of customer support, explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Remote resolution of problems has increased by 15%, solution times have decreased, and customers now have self-service access to the system, Creech said. “Now, our engineers ask a plain-language question, and the AI hunts down the answer quickly. It’s a big wow factor.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-adopt-mindful-cost-avoidance-hacks"&gt;Adopt mindful cost-avoidance hacks&lt;/h2&gt;



&lt;p&gt;At Albertsons, one of the nation’s largest food and drug chains, IT teams employ several simple but effective tactics to optimize AI infrastructure without adding new hardware, said Chandrakanth Puligundla, tech lead for data analysis, engineering and governance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gravity mapping, for example, shows where data is stored and how it’s moved, whether on edge devices, internal systems or on multi-cloud systems. This knowledge not only reduces egress costs and latency, Puligundla explained, but guides more informed decisions about where to allocate computing resources.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Similarly, he said, using specialist AI tools for language processing or image identification takes less space, often delivering better performance and economy than adding or updating more expensive servers and general-purpose computers.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another cost-avoidance hack: Tracking watts per inference or training hour.&amp;nbsp;Looking beyond speed and cost to energy-efficiency metrics prioritizes sustainable performance, which is crucial for increasingly power-thirsty AI models and hardware.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Puligundla concluded: “We can really increase efficiency through this kind of mindful preparation.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-write-your-own-ending-nbsp"&gt;Write your own ending&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The success of AI pilots has brought millions of companies to the next phase of their journeys: Deploying generative and LLMs, agents and other intelligent applications with high business value into wider production.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The latest AI chapter promises rich rewards for enterprises that strategically assemble infrastructure and hardware that balances performance, cost, flexibility and scalability across edge computing, on-premises systems and cloud environments.&lt;/p&gt;



&lt;p&gt;&lt;span&gt;In the coming months, scaling options will expand further, as industry investments continue to pour into hyper-scale data centers, edge chips and hardware (AMD, Qualcomm, Huawei),&amp;nbsp;cloud-based AI full-stack infrastructure like Canonical and Guru,&amp;nbsp;context-aware memory,&amp;nbsp;secure on-prem plug-and-play devices like&amp;nbsp;Lemony,&amp;nbsp;and much more.&lt;/span&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;How wisely IT and business leaders plan and choose infrastructure for expansion will determine the heroes of company stories and the unfortunates doomed to pilot purgatory or AI damnation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/scaling-smarter-how-enterprise-it-teams-can-right-size-their-compute-for-ai/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] The rise of prompt ops: Tackling hidden AI costs from bad inputs and context bloat (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/the-rise-of-prompt-ops-tackling-hidden-ai-costs-from-bad-inputs-and-context-bloat/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-The-rise-of-prompt-ops_-Tackling-hidden-AI-costs-from-bad-inputs-and-context-bloat.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Model providers continue to roll out increasingly sophisticated large language models (LLMs) with longer context windows and enhanced reasoning capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This allows models to process and “think” more, but it also increases compute: The more a model takes in and puts out, the more energy it expends and the higher the costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Couple this with all the tinkering involved with prompting — it can take a few tries to get to the intended result, and sometimes the question at hand simply doesn’t need a model that can think like a PhD — and compute spend can get out of control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is giving rise to prompt ops, a whole new discipline in the dawning age of AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Prompt engineering is kind of like writing, the actual creating, whereas prompt ops is like publishing, where you’re evolving the content,” Crawford Del Prete, IDC president, told VentureBeat. “The content is alive, the content is changing, and you want to make sure you’re refining that over time.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-challenge-of-compute-use-and-cost"&gt;The challenge of compute use and cost&lt;/h2&gt;



&lt;p&gt;Compute use and cost are two “related but separate concepts” in the context of LLMs, explained David Emerson, applied scientist at the Vector Institute. Generally, the price users pay scales based on both the number of input tokens (what the user prompts) and the number of output tokens (what the model delivers). However, they are not changed for behind-the-scenes actions like meta-prompts, steering instructions or retrieval-augmented generation (RAG).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;While longer context allows models to process much more text at once, it directly translates to significantly more FLOPS (a measurement of compute power), he explained. Some aspects of transformer models even scale quadratically with input length if not well managed. Unnecessarily long responses can also slow down processing time and require additional compute and cost to build and maintain algorithms to post-process responses into the answer users were hoping for.&lt;/p&gt;



&lt;p&gt;Typically, longer context environments incentivize providers to deliberately deliver verbose responses, said Emerson. For example, many heavier reasoning models (o3 or o1 from OpenAI, for example) will often provide long responses to even simple questions, incurring heavy computing costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here’s an example:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at the&lt;/em&gt; &lt;em&gt;store after eating 1, how many apples do I have?&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;em&gt;If I eat 1, I only have 1 left. I would have 5 apples if I buy 4 more. &lt;/em&gt;&lt;/p&gt;



&lt;p&gt;The model not only generated more tokens than it needed to, it buried its answer. An engineer may then have to design a programmatic way to extract the final answer or ask follow-up questions like ‘What is your final answer?’ that incur even more API costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Alternatively, the prompt could be redesigned to guide the model to produce an immediate answer. For instance:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at th&lt;/em&gt;e &lt;em&gt;store after eating 1, how many apples do I have? Start your response with “The answer is”…&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Or:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at the store after eating 1, how many apples do I have? Wrap your final answer in bold tags &amp;lt;b&amp;gt;&amp;lt;/b&amp;gt;.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“The way the question is asked can reduce the effort or cost in getting to the desired answer,” said Emerson. He also pointed out that techniques like few-shot prompting (providing a few examples of what the user is looking for) can help produce quicker outputs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One danger is not knowing when to use sophisticated techniques like chain-of-thought (CoT) prompting (generating answers in steps) or self-refinement, which directly encourage models to produce many tokens or go through several iterations when generating responses, Emerson pointed out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Not every query requires a model to analyze and re-analyze before providing an answer, he emphasized; they could be perfectly capable of answering correctly when instructed to respond directly. Additionally, incorrect prompting API configurations (such as OpenAI o3, which requires a high reasoning effort) will incur higher costs when a lower-effort, cheaper request would suffice.&lt;/p&gt;



&lt;p&gt;“With longer contexts, users can also be tempted to use an ‘everything but the kitchen sink’ approach, where you dump as much text as possible into a model context in the hope that doing so will help the model perform a task more accurately,” said Emerson. “While more context can help models perform tasks, it isn’t always the best or most efficient approach.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-evolution-to-prompt-ops"&gt;Evolution to prompt ops&lt;/h2&gt;



&lt;p&gt;It’s no big secret that AI-optimized infrastructure can be hard to come by these days; IDC’s Del Prete pointed out that enterprises must be able to minimize the amount of GPU idle time and fill more queries into idle cycles between GPU requests.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“How do I squeeze more out of these very, very precious commodities?,” he noted. “Because I’ve got to get my system utilization up, because I just don’t have the benefit of simply throwing more capacity at the problem.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Prompt ops can go a long way towards addressing this challenge, as it ultimately manages the lifecycle of the prompt. While prompt engineering is about the quality of the prompt, prompt ops is where you repeat, Del Prete explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It’s more orchestration,” he said. “I think of it as the curation of questions and the curation of how you interact with AI to make sure you’re getting the most out of it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models can tend to get “fatigued,” cycling in loops where quality of outputs degrades, he said. Prompt ops help manage, measure, monitor and tune prompts. “I think when we look back three or four years from now, it’s going to be a whole discipline. It’ll be a skill.”&lt;/p&gt;



&lt;p&gt;While it’s still very much an emerging field, early providers include QueryPal, Promptable, Rebuff and TrueLens. As prompt ops evolve, these platforms will continue to iterate, improve and provide real-time feedback to give users more capacity to tune prompts over time, Dep Prete noted.&lt;/p&gt;



&lt;p&gt;Eventually, he predicted, agents will be able to tune, write and structure prompts on their own. “The level of automation will increase, the level of human interaction will decrease, you’ll be able to have agents operating more autonomously in the prompts that they’re creating.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-common-prompting-mistakes"&gt;Common prompting mistakes&lt;/h2&gt;



&lt;p&gt;Until prompt ops is fully realized, there is ultimately no perfect prompt. Some of the biggest mistakes people make, according to Emerson:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Not being specific enough about the problem to be solved. This includes how the user wants the model to provide its answer, what should be considered when responding, constraints to take into account and other factors. “In many settings, models need a good amount of context to provide a response that meets users expectations,” said Emerson.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Not taking into account the ways a problem can be simplified to narrow the scope of the response. Should the answer be within a certain range (0 to 100)? Should the answer be phrased as a multiple choice problem rather than something open-ended? Can the user provide good examples to contextualize the query? Can the problem be broken into steps for separate and simpler queries?&lt;/li&gt;



&lt;li&gt;Not taking advantage of structure. LLMs are very good at pattern recognition, and many can understand code. While using bullet points, itemized lists or bold indicators (****) may seem “a bit cluttered” to human eyes, Emerson noted, these callouts can be beneficial for an LLM. Asking for structured outputs (such as JSON or Markdown) can also help when users are looking to process responses automatically.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;There are many other factors to consider in maintaining a production pipeline, based on engineering best practices, Emerson noted. These include:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Making sure that the throughput of the pipeline remains consistent;&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Monitoring the performance of the prompts over time (potentially against a validation set);&lt;/li&gt;



&lt;li&gt;Setting up tests and early warning detection to identify pipeline issues.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Users can also take advantage of tools designed to support the prompting process. For instance, the open-source DSPy can automatically configure and optimize prompts for downstream tasks based on a few labeled examples. While this may be a fairly sophisticated example, there are many other offerings (including some built into tools like ChatGPT, Google and others) that can assist in prompt design.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And ultimately, Emerson said, “I think one of the simplest things users can do is to try to stay up-to-date on effective prompting approaches, model developments and new ways to configure and interact with models.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-The-rise-of-prompt-ops_-Tackling-hidden-AI-costs-from-bad-inputs-and-context-bloat.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Model providers continue to roll out increasingly sophisticated large language models (LLMs) with longer context windows and enhanced reasoning capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This allows models to process and “think” more, but it also increases compute: The more a model takes in and puts out, the more energy it expends and the higher the costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Couple this with all the tinkering involved with prompting — it can take a few tries to get to the intended result, and sometimes the question at hand simply doesn’t need a model that can think like a PhD — and compute spend can get out of control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is giving rise to prompt ops, a whole new discipline in the dawning age of AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Prompt engineering is kind of like writing, the actual creating, whereas prompt ops is like publishing, where you’re evolving the content,” Crawford Del Prete, IDC president, told VentureBeat. “The content is alive, the content is changing, and you want to make sure you’re refining that over time.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-challenge-of-compute-use-and-cost"&gt;The challenge of compute use and cost&lt;/h2&gt;



&lt;p&gt;Compute use and cost are two “related but separate concepts” in the context of LLMs, explained David Emerson, applied scientist at the Vector Institute. Generally, the price users pay scales based on both the number of input tokens (what the user prompts) and the number of output tokens (what the model delivers). However, they are not changed for behind-the-scenes actions like meta-prompts, steering instructions or retrieval-augmented generation (RAG).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;While longer context allows models to process much more text at once, it directly translates to significantly more FLOPS (a measurement of compute power), he explained. Some aspects of transformer models even scale quadratically with input length if not well managed. Unnecessarily long responses can also slow down processing time and require additional compute and cost to build and maintain algorithms to post-process responses into the answer users were hoping for.&lt;/p&gt;



&lt;p&gt;Typically, longer context environments incentivize providers to deliberately deliver verbose responses, said Emerson. For example, many heavier reasoning models (o3 or o1 from OpenAI, for example) will often provide long responses to even simple questions, incurring heavy computing costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here’s an example:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at the&lt;/em&gt; &lt;em&gt;store after eating 1, how many apples do I have?&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;em&gt;If I eat 1, I only have 1 left. I would have 5 apples if I buy 4 more. &lt;/em&gt;&lt;/p&gt;



&lt;p&gt;The model not only generated more tokens than it needed to, it buried its answer. An engineer may then have to design a programmatic way to extract the final answer or ask follow-up questions like ‘What is your final answer?’ that incur even more API costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Alternatively, the prompt could be redesigned to guide the model to produce an immediate answer. For instance:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at th&lt;/em&gt;e &lt;em&gt;store after eating 1, how many apples do I have? Start your response with “The answer is”…&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Or:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: &lt;em&gt;Answer the following math problem. If I have 2 apples and I buy 4 more at the store after eating 1, how many apples do I have? Wrap your final answer in bold tags &amp;lt;b&amp;gt;&amp;lt;/b&amp;gt;.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“The way the question is asked can reduce the effort or cost in getting to the desired answer,” said Emerson. He also pointed out that techniques like few-shot prompting (providing a few examples of what the user is looking for) can help produce quicker outputs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One danger is not knowing when to use sophisticated techniques like chain-of-thought (CoT) prompting (generating answers in steps) or self-refinement, which directly encourage models to produce many tokens or go through several iterations when generating responses, Emerson pointed out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Not every query requires a model to analyze and re-analyze before providing an answer, he emphasized; they could be perfectly capable of answering correctly when instructed to respond directly. Additionally, incorrect prompting API configurations (such as OpenAI o3, which requires a high reasoning effort) will incur higher costs when a lower-effort, cheaper request would suffice.&lt;/p&gt;



&lt;p&gt;“With longer contexts, users can also be tempted to use an ‘everything but the kitchen sink’ approach, where you dump as much text as possible into a model context in the hope that doing so will help the model perform a task more accurately,” said Emerson. “While more context can help models perform tasks, it isn’t always the best or most efficient approach.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-evolution-to-prompt-ops"&gt;Evolution to prompt ops&lt;/h2&gt;



&lt;p&gt;It’s no big secret that AI-optimized infrastructure can be hard to come by these days; IDC’s Del Prete pointed out that enterprises must be able to minimize the amount of GPU idle time and fill more queries into idle cycles between GPU requests.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“How do I squeeze more out of these very, very precious commodities?,” he noted. “Because I’ve got to get my system utilization up, because I just don’t have the benefit of simply throwing more capacity at the problem.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Prompt ops can go a long way towards addressing this challenge, as it ultimately manages the lifecycle of the prompt. While prompt engineering is about the quality of the prompt, prompt ops is where you repeat, Del Prete explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It’s more orchestration,” he said. “I think of it as the curation of questions and the curation of how you interact with AI to make sure you’re getting the most out of it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models can tend to get “fatigued,” cycling in loops where quality of outputs degrades, he said. Prompt ops help manage, measure, monitor and tune prompts. “I think when we look back three or four years from now, it’s going to be a whole discipline. It’ll be a skill.”&lt;/p&gt;



&lt;p&gt;While it’s still very much an emerging field, early providers include QueryPal, Promptable, Rebuff and TrueLens. As prompt ops evolve, these platforms will continue to iterate, improve and provide real-time feedback to give users more capacity to tune prompts over time, Dep Prete noted.&lt;/p&gt;



&lt;p&gt;Eventually, he predicted, agents will be able to tune, write and structure prompts on their own. “The level of automation will increase, the level of human interaction will decrease, you’ll be able to have agents operating more autonomously in the prompts that they’re creating.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-common-prompting-mistakes"&gt;Common prompting mistakes&lt;/h2&gt;



&lt;p&gt;Until prompt ops is fully realized, there is ultimately no perfect prompt. Some of the biggest mistakes people make, according to Emerson:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Not being specific enough about the problem to be solved. This includes how the user wants the model to provide its answer, what should be considered when responding, constraints to take into account and other factors. “In many settings, models need a good amount of context to provide a response that meets users expectations,” said Emerson.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Not taking into account the ways a problem can be simplified to narrow the scope of the response. Should the answer be within a certain range (0 to 100)? Should the answer be phrased as a multiple choice problem rather than something open-ended? Can the user provide good examples to contextualize the query? Can the problem be broken into steps for separate and simpler queries?&lt;/li&gt;



&lt;li&gt;Not taking advantage of structure. LLMs are very good at pattern recognition, and many can understand code. While using bullet points, itemized lists or bold indicators (****) may seem “a bit cluttered” to human eyes, Emerson noted, these callouts can be beneficial for an LLM. Asking for structured outputs (such as JSON or Markdown) can also help when users are looking to process responses automatically.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;There are many other factors to consider in maintaining a production pipeline, based on engineering best practices, Emerson noted. These include:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Making sure that the throughput of the pipeline remains consistent;&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Monitoring the performance of the prompts over time (potentially against a validation set);&lt;/li&gt;



&lt;li&gt;Setting up tests and early warning detection to identify pipeline issues.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Users can also take advantage of tools designed to support the prompting process. For instance, the open-source DSPy can automatically configure and optimize prompts for downstream tasks based on a few labeled examples. While this may be a fairly sophisticated example, there are many other offerings (including some built into tools like ChatGPT, Google and others) that can assist in prompt design.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And ultimately, Emerson said, “I think one of the simplest things users can do is to try to stay up-to-date on effective prompting approaches, model developments and new ways to configure and interact with models.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-rise-of-prompt-ops-tackling-hidden-ai-costs-from-bad-inputs-and-context-bloat/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] The inference trap: How cloud providers are eating your AI margins (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/the-inference-trap-how-cloud-providers-are-eating-your-ai-margins/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-The-inference-trap_-How-cloud-providers-are-eating-your-AI-margins.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI has become the holy grail of modern companies. Whether it’s customer service or something as niche as pipeline maintenance, organizations in every domain are now implementing AI technologies — from foundation models to VLAs — to make things more efficient. The goal is straightforward: automate tasks to deliver outcomes more efficiently and save money and resources simultaneously.&lt;/p&gt;



&lt;p&gt;However, as these projects transition from the pilot to the production stage, teams encounter a hurdle they hadn’t planned for: cloud costs eroding their margins. The sticker shock is so bad that what once felt like the fastest path to innovation and competitive edge becomes an unsustainable budgetary blackhole – in no time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This prompts CIOs to rethink everything—from model architecture to deployment models—to regain control over financial and operational aspects. Sometimes, they even shutter the projects entirely, starting over from scratch.&lt;/p&gt;



&lt;p&gt;But here’s the fact: while cloud can take costs to unbearable levels, it is not the villain. You just have to understand what type of vehicle (AI infrastructure) to choose to go down which road (the workload).&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cloud-story-and-where-it-works-nbsp"&gt;The cloud story — and where it works&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The cloud is very much like public transport (your subways and buses). You get on board with a simple rental model, and it instantly gives you all the resources—right from GPU instances to fast scaling across various geographies—to take you to your destination, all with minimal work and setup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The fast and easy access via a service model ensures a seamless start, paving the way to get the project off the ground and do rapid experimentation without the huge up-front capital expenditure of acquiring specialized GPUs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Most early-stage startups find this model lucrative as they need fast turnaround more than anything else, especially when they are still validating the model and determining product-market fit.&lt;/p&gt;



&lt;p&gt;“You make an account, click a few buttons, and get access to servers. If you need a different GPU size, you shut down and restart the instance with the new specs, which takes minutes. If you want to run two experiments at once, you initialise two separate instances. In the early stages, the focus is on validating ideas quickly. Using the built-in scaling and experimentation frameworks provided by most cloud platforms helps reduce the time between milestones,” Rohan Sarin, who leads voice AI product at Speechmatics, told VentureBeat.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cost-of-ease"&gt;The cost of “ease”&lt;/h2&gt;



&lt;p&gt;While cloud makes perfect sense for early-stage usage, the infrastructure math becomes grim as the project transitions from testing and validation to real-world volumes. The scale of workloads makes the bills brutal — so much so that the costs can surge over 1000% overnight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is particularly true in the case of inference, which not only has to run 24/7 to ensure service uptime but also scale with customer demand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On most occasions, Sarin explains, the inference demand spikes when other customers are also requesting GPU access, increasing the competition for resources. In such cases, teams either keep a reserved capacity to make sure they get what they need — leading to idle GPU time during non-peak hours — or suffer from latencies, impacting downstream experience.&lt;/p&gt;



&lt;p&gt;Christian Khoury, the CEO of AI compliance platform EasyAudit AI, described inference as the new “cloud tax,” telling VentureBeat that he has seen companies go from $5K to $50K/month overnight, just from inference traffic.&lt;/p&gt;



&lt;p&gt;It’s also worth noting that inference workloads involving LLMs, with token-based pricing, can trigger the steepest cost increases. This is because these models are non-deterministic and can generate different outputs when handling long-running tasks (involving large context windows). With continuous updates, it gets really difficult to forecast or control LLM inference costs.&lt;/p&gt;



&lt;p&gt;Training these models, on its part, happens to be “bursty” (occurring in clusters), which does leave some room for capacity planning. However, even in these cases, especially as growing competition forces frequent retraining, enterprises can have massive bills from idle GPU time, stemming from overprovisioning.&lt;/p&gt;



&lt;p&gt;“Training credits on cloud platforms are expensive, and frequent retraining during fast iteration cycles can escalate costs quickly. Long training runs require access to large machines, and most cloud providers only guarantee that access if you reserve capacity for a year or more. If your training run only lasts a few weeks, you still pay for the rest of the year,” Sarin explained.&lt;/p&gt;



&lt;p&gt;And, it’s not just this. Cloud lock-in is very real. Suppose you have made a long-term reservation and bought credits from a provider. In that case, you’re locked in their ecosystem and have to use whatever they have on offer, even when other providers have moved to newer, better infrastructure. And, finally, when you get the ability to move, you may have to bear massive egress fees.&lt;/p&gt;



&lt;p&gt;“It’s not just compute cost. You get…unpredictable autoscaling, and insane egress fees if you’re moving data between regions or vendors. One team was paying more to move data than to train their models,” Sarin emphasized.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-so-what-s-the-workaround"&gt;So, what’s the workaround?&lt;/h2&gt;



&lt;p&gt;Given the constant infrastructure demand of scaling AI inference and the bursty nature of training, enterprises are moving to splitting the workloads — taking inference to colocation or on-prem stacks, while leaving training to the cloud with spot instances.&lt;/p&gt;



&lt;p&gt;This isn’t just theory — it’s a growing movement among engineering leaders trying to put AI into production without burning through runway.&lt;/p&gt;



&lt;p&gt;“We’ve helped teams shift to colocation for inference using dedicated GPU servers that they control. It’s not sexy, but it cuts monthly infra spend by 60–80%,” Khoury added. “Hybrid’s not just cheaper—it’s smarter.”&lt;/p&gt;



&lt;p&gt;In one case, he said, a SaaS company reduced its monthly AI infrastructure bill from approximately $42,000 to just $9,000 by moving inference workloads off the cloud. The switch paid for itself in under two weeks.&lt;/p&gt;



&lt;p&gt;Another team requiring consistent sub-50ms responses for an AI customer support tool discovered that cloud-based inference latency was insufficient. Shifting inference closer to users via colocation not only solved the performance bottleneck — but it halved the cost.&lt;/p&gt;



&lt;p&gt;The setup typically works like this: inference, which is always-on and latency-sensitive, runs on dedicated GPUs either on-prem or in a nearby data center (colocation facility). Meanwhile, training, which is compute-intensive but sporadic, stays in the cloud, where you can spin up powerful clusters on demand, run for a few hours or days, and shut down.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Broadly, it is estimated that renting from hyperscale cloud providers can cost three to four times more per GPU hour than working with smaller providers, with the difference being even more significant compared to on-prem infrastructure.&lt;/p&gt;



&lt;p&gt;The other big bonus? Predictability.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With on-prem or colocation stacks, teams also have full control over the number of resources they want to provision or add for the expected baseline of inference workloads. This brings predictability to infrastructure costs — and eliminates surprise bills. It also brings down the aggressive engineering effort to tune scaling and keep cloud infrastructure costs within reason.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Hybrid setups also help reduce latency for time-sensitive AI applications and enable better compliance, particularly for teams operating in highly regulated industries like finance, healthcare, and education — where data residency and governance are non-negotiable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-hybrid-complexity-is-real-but-rarely-a-dealbreaker"&gt;Hybrid complexity is real—but rarely a dealbreaker&lt;/h2&gt;



&lt;p&gt;As it has always been the case, the shift to a hybrid setup comes with its own ops tax. Setting up your own hardware or renting a colocation facility takes time, and managing GPUs outside the cloud requires a different kind of engineering muscle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, leaders argue that the complexity is often overstated and is usually manageable in-house or through external support, unless one is operating at an extreme scale.&lt;/p&gt;



&lt;p&gt;“Our calculations show that an on-prem GPU server costs about the same as six to nine months of renting the equivalent instance from AWS, Azure, or Google Cloud, even with a one-year reserved rate. Since the hardware typically lasts at least three years, and often more than five, this becomes cost-positive within the first nine months. Some hardware vendors also offer operational pricing models for capital infrastructure, so you can avoid upfront payment if cash flow is a concern,” Sarin explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-prioritize-by-need"&gt;Prioritize by need&lt;/h2&gt;



&lt;p&gt;For any company, whether a startup or an enterprise, the key to success when architecting – or re-architecting – AI infrastructure lies in working according to the specific workloads at hand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If you’re unsure about the load of different AI workloads, start with the cloud and keep a close eye on the associated costs by tagging every resource with the responsible team. You can share these cost reports with all managers and do a deep dive into what they are using and its impact on the resources. This data will then give clarity and help pave the way for driving efficiencies.&lt;/p&gt;



&lt;p&gt;That said, remember that it’s not about ditching the cloud entirely; it’s about optimizing its use to maximize efficiencies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Cloud is still great for experimentation and bursty training. But if inference is your core workload, get off the rent treadmill. Hybrid isn’t just cheaper… It’s smarter,” Khoury added. “Treat cloud like a prototype, not the permanent home. Run the math. Talk to your engineers. The cloud will never tell you when it’s the wrong tool. But your AWS bill will.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-The-inference-trap_-How-cloud-providers-are-eating-your-AI-margins.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI has become the holy grail of modern companies. Whether it’s customer service or something as niche as pipeline maintenance, organizations in every domain are now implementing AI technologies — from foundation models to VLAs — to make things more efficient. The goal is straightforward: automate tasks to deliver outcomes more efficiently and save money and resources simultaneously.&lt;/p&gt;



&lt;p&gt;However, as these projects transition from the pilot to the production stage, teams encounter a hurdle they hadn’t planned for: cloud costs eroding their margins. The sticker shock is so bad that what once felt like the fastest path to innovation and competitive edge becomes an unsustainable budgetary blackhole – in no time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This prompts CIOs to rethink everything—from model architecture to deployment models—to regain control over financial and operational aspects. Sometimes, they even shutter the projects entirely, starting over from scratch.&lt;/p&gt;



&lt;p&gt;But here’s the fact: while cloud can take costs to unbearable levels, it is not the villain. You just have to understand what type of vehicle (AI infrastructure) to choose to go down which road (the workload).&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cloud-story-and-where-it-works-nbsp"&gt;The cloud story — and where it works&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The cloud is very much like public transport (your subways and buses). You get on board with a simple rental model, and it instantly gives you all the resources—right from GPU instances to fast scaling across various geographies—to take you to your destination, all with minimal work and setup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The fast and easy access via a service model ensures a seamless start, paving the way to get the project off the ground and do rapid experimentation without the huge up-front capital expenditure of acquiring specialized GPUs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Most early-stage startups find this model lucrative as they need fast turnaround more than anything else, especially when they are still validating the model and determining product-market fit.&lt;/p&gt;



&lt;p&gt;“You make an account, click a few buttons, and get access to servers. If you need a different GPU size, you shut down and restart the instance with the new specs, which takes minutes. If you want to run two experiments at once, you initialise two separate instances. In the early stages, the focus is on validating ideas quickly. Using the built-in scaling and experimentation frameworks provided by most cloud platforms helps reduce the time between milestones,” Rohan Sarin, who leads voice AI product at Speechmatics, told VentureBeat.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cost-of-ease"&gt;The cost of “ease”&lt;/h2&gt;



&lt;p&gt;While cloud makes perfect sense for early-stage usage, the infrastructure math becomes grim as the project transitions from testing and validation to real-world volumes. The scale of workloads makes the bills brutal — so much so that the costs can surge over 1000% overnight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is particularly true in the case of inference, which not only has to run 24/7 to ensure service uptime but also scale with customer demand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On most occasions, Sarin explains, the inference demand spikes when other customers are also requesting GPU access, increasing the competition for resources. In such cases, teams either keep a reserved capacity to make sure they get what they need — leading to idle GPU time during non-peak hours — or suffer from latencies, impacting downstream experience.&lt;/p&gt;



&lt;p&gt;Christian Khoury, the CEO of AI compliance platform EasyAudit AI, described inference as the new “cloud tax,” telling VentureBeat that he has seen companies go from $5K to $50K/month overnight, just from inference traffic.&lt;/p&gt;



&lt;p&gt;It’s also worth noting that inference workloads involving LLMs, with token-based pricing, can trigger the steepest cost increases. This is because these models are non-deterministic and can generate different outputs when handling long-running tasks (involving large context windows). With continuous updates, it gets really difficult to forecast or control LLM inference costs.&lt;/p&gt;



&lt;p&gt;Training these models, on its part, happens to be “bursty” (occurring in clusters), which does leave some room for capacity planning. However, even in these cases, especially as growing competition forces frequent retraining, enterprises can have massive bills from idle GPU time, stemming from overprovisioning.&lt;/p&gt;



&lt;p&gt;“Training credits on cloud platforms are expensive, and frequent retraining during fast iteration cycles can escalate costs quickly. Long training runs require access to large machines, and most cloud providers only guarantee that access if you reserve capacity for a year or more. If your training run only lasts a few weeks, you still pay for the rest of the year,” Sarin explained.&lt;/p&gt;



&lt;p&gt;And, it’s not just this. Cloud lock-in is very real. Suppose you have made a long-term reservation and bought credits from a provider. In that case, you’re locked in their ecosystem and have to use whatever they have on offer, even when other providers have moved to newer, better infrastructure. And, finally, when you get the ability to move, you may have to bear massive egress fees.&lt;/p&gt;



&lt;p&gt;“It’s not just compute cost. You get…unpredictable autoscaling, and insane egress fees if you’re moving data between regions or vendors. One team was paying more to move data than to train their models,” Sarin emphasized.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-so-what-s-the-workaround"&gt;So, what’s the workaround?&lt;/h2&gt;



&lt;p&gt;Given the constant infrastructure demand of scaling AI inference and the bursty nature of training, enterprises are moving to splitting the workloads — taking inference to colocation or on-prem stacks, while leaving training to the cloud with spot instances.&lt;/p&gt;



&lt;p&gt;This isn’t just theory — it’s a growing movement among engineering leaders trying to put AI into production without burning through runway.&lt;/p&gt;



&lt;p&gt;“We’ve helped teams shift to colocation for inference using dedicated GPU servers that they control. It’s not sexy, but it cuts monthly infra spend by 60–80%,” Khoury added. “Hybrid’s not just cheaper—it’s smarter.”&lt;/p&gt;



&lt;p&gt;In one case, he said, a SaaS company reduced its monthly AI infrastructure bill from approximately $42,000 to just $9,000 by moving inference workloads off the cloud. The switch paid for itself in under two weeks.&lt;/p&gt;



&lt;p&gt;Another team requiring consistent sub-50ms responses for an AI customer support tool discovered that cloud-based inference latency was insufficient. Shifting inference closer to users via colocation not only solved the performance bottleneck — but it halved the cost.&lt;/p&gt;



&lt;p&gt;The setup typically works like this: inference, which is always-on and latency-sensitive, runs on dedicated GPUs either on-prem or in a nearby data center (colocation facility). Meanwhile, training, which is compute-intensive but sporadic, stays in the cloud, where you can spin up powerful clusters on demand, run for a few hours or days, and shut down.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Broadly, it is estimated that renting from hyperscale cloud providers can cost three to four times more per GPU hour than working with smaller providers, with the difference being even more significant compared to on-prem infrastructure.&lt;/p&gt;



&lt;p&gt;The other big bonus? Predictability.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With on-prem or colocation stacks, teams also have full control over the number of resources they want to provision or add for the expected baseline of inference workloads. This brings predictability to infrastructure costs — and eliminates surprise bills. It also brings down the aggressive engineering effort to tune scaling and keep cloud infrastructure costs within reason.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Hybrid setups also help reduce latency for time-sensitive AI applications and enable better compliance, particularly for teams operating in highly regulated industries like finance, healthcare, and education — where data residency and governance are non-negotiable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-hybrid-complexity-is-real-but-rarely-a-dealbreaker"&gt;Hybrid complexity is real—but rarely a dealbreaker&lt;/h2&gt;



&lt;p&gt;As it has always been the case, the shift to a hybrid setup comes with its own ops tax. Setting up your own hardware or renting a colocation facility takes time, and managing GPUs outside the cloud requires a different kind of engineering muscle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, leaders argue that the complexity is often overstated and is usually manageable in-house or through external support, unless one is operating at an extreme scale.&lt;/p&gt;



&lt;p&gt;“Our calculations show that an on-prem GPU server costs about the same as six to nine months of renting the equivalent instance from AWS, Azure, or Google Cloud, even with a one-year reserved rate. Since the hardware typically lasts at least three years, and often more than five, this becomes cost-positive within the first nine months. Some hardware vendors also offer operational pricing models for capital infrastructure, so you can avoid upfront payment if cash flow is a concern,” Sarin explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-prioritize-by-need"&gt;Prioritize by need&lt;/h2&gt;



&lt;p&gt;For any company, whether a startup or an enterprise, the key to success when architecting – or re-architecting – AI infrastructure lies in working according to the specific workloads at hand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If you’re unsure about the load of different AI workloads, start with the cloud and keep a close eye on the associated costs by tagging every resource with the responsible team. You can share these cost reports with all managers and do a deep dive into what they are using and its impact on the resources. This data will then give clarity and help pave the way for driving efficiencies.&lt;/p&gt;



&lt;p&gt;That said, remember that it’s not about ditching the cloud entirely; it’s about optimizing its use to maximize efficiencies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Cloud is still great for experimentation and bursty training. But if inference is your core workload, get off the rent treadmill. Hybrid isn’t just cheaper… It’s smarter,” Khoury added. “Treat cloud like a prototype, not the permanent home. Run the math. Talk to your engineers. The cloud will never tell you when it’s the wrong tool. But your AWS bill will.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-inference-trap-how-cloud-providers-are-eating-your-ai-margins/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] Model minimalism: The new AI strategy saving companies millions (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/model-minimalism-the-new-ai-strategy-saving-companies-millions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-Model-minimalism_-The-new-AI-strategy-saving-companies-millions.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;The advent of large language models (LLMs) has made it easier for enterprises to envision the kinds of projects they can undertake, leading to a surge in pilot programs now transitioning to deployment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, as these projects gained momentum, enterprises realized that the earlier LLMs they had used were unwieldy and, worse, expensive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enter small language models and distillation. Models like Google’s Gemma family, Microsoft’s Phi and Mistral’s Small 3.1 allowed businesses to choose fast, accurate models that work for specific tasks. Enterprises can opt for a smaller model for particular use cases, allowing them to lower the cost of running their AI applications and potentially achieve a better return on investment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn distinguished engineer Karthik Ramgopal told VentureBeat that companies opt for smaller models for a few reasons.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Smaller models require less compute, memory and faster inference times, which translates directly into lower infrastructure OPEX (operational expenditures) and CAPEX (capital expenditures) given GPU costs, availability and power requirements,” Ramgoapl said. “Task-specific models have a narrower scope, making their behavior more aligned and maintainable over time without complex prompt engineering.”&lt;/p&gt;



&lt;p&gt;Model developers price their small models accordingly. OpenAI’s o4-mini costs $1.1 per million tokens for inputs and $4.4/million tokens for outputs, compared to the full o3 version at $10 for inputs and $40 for outputs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises today have a larger pool of small models, task-specific models and distilled models to choose from. These days, most flagship models offer a range of sizes. For example, the Claude family of models from Anthropic comprises Claude Opus, the largest model, Claude Sonnet, the all-purpose model, and Claude Haiku, the smallest version. These models are compact enough to operate on portable devices, such as laptops or mobile phones.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-savings-question"&gt;The savings question&lt;/h2&gt;



&lt;p&gt;When discussing return on investment, though, the question is always: What does ROI look like? Should it be a return on the costs incurred or the time savings that ultimately means dollars saved down the line? Experts VentureBeat spoke to said ROI can be difficult to judge because some companies believe they’ve already reached ROI by cutting time spent on a task while others are waiting for actual dollars saved or more business brought in to say if AI investments have actually worked. &lt;/p&gt;



&lt;p&gt;Normally, enterprises calculate ROI by a simple formula as described by Cognizant chief technologist Ravi Naarla in a post: ROI = (Benefits-Cost)/Costs. But with AI programs, the benefits are not immediately apparent. He suggests enterprises identify the benefits they expect to achieve, estimate these based on historical data, be realistic about the overall cost of AI, including hiring, implementation and maintenance, and understand you have to be in it for the long haul.&lt;/p&gt;



&lt;p&gt;With small models, experts argue that these reduce implementation and maintenance costs, especially when fine-tuning models to provide them with more context for your enterprise.&lt;/p&gt;



&lt;p&gt;Arijit Sengupta, founder and CEO of Aible, said that how people bring context to the models dictates how much cost savings they can get. For individuals who require additional context for prompts, such as lengthy and complex instructions, this can result in higher token costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You have to give models context one way or the other; there is no free lunch. But with large models, that is usually done by putting it in the prompt,” he said. “Think of fine-tuning and post-training as an alternative way of giving models context. I might incur $100 of post-training costs, but it’s not astronomical.”&lt;/p&gt;



&lt;p&gt;Sengupta said they’ve seen about 100X cost reductions just from post-training alone, often dropping model use cost “from single-digit millions to something like $30,000.” He did point out that this number includes software operating expenses and the ongoing cost of the model and vector databases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In terms of maintenance cost, if you do it manually with human experts, it can be expensive to maintain because small models need to be post-trained to produce results comparable to large models,” he said.&lt;/p&gt;



&lt;p&gt;Experiments Aible conducted showed that a task-specific, fine-tuned model performs well for some use cases, just like LLMs, making the case that deploying several use-case-specific models rather than large ones to do everything is more cost-effective.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company compared a post-trained version of Llama-3.3-70B-Instruct to a smaller 8B parameter option of the same model. The 70B model, post-trained for $11.30, was 84% accurate in automated evaluations and 92% in manual evaluations. Once fine-tuned to a cost of $4.58, the 8B model achieved 82% accuracy in manual assessment, which would be suitable for more minor, more targeted use cases.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cost-factors-fit-for-purpose"&gt;Cost factors fit for purpose&lt;/h2&gt;



&lt;p&gt;Right-sizing models does not have to come at the cost of performance. These days, organizations understand that model choice doesn’t just mean choosing between GPT-4o or Llama-3.1; it’s knowing that some use cases, like summarization or code generation, are better served by a small model.&lt;/p&gt;



&lt;p&gt;Daniel Hoske, chief technology officer at contact center AI products provider Cresta, said starting development with LLMs informs potential cost savings better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You should start with the biggest model to see if what you’re envisioning even works at all, because if it doesn’t work with the biggest model, it doesn’t mean it would with smaller models,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Ramgopal said LinkedIn follows a similar pattern because prototyping is the only way these issues can start to emerge.&lt;/p&gt;



&lt;p&gt;“Our typical approach for agentic use cases begins with general-purpose LLMs as their broad generalizationability allows us to rapidly prototype, validate hypotheses and assess product-market fit,” LinkedIn’s Ramgopal said. “As the product matures and we encounter constraints around quality, cost or latency, we transition to more customized solutions.”&lt;/p&gt;



&lt;p&gt;In the experimentation phase, organizations can determine what they value most from their AI applications. Figuring this out enables developers to plan better what they want to save on and select the model size that best suits their purpose and budget.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The experts cautioned that while it is important to build with models that work best with what they’re developing, high-parameter LLMs will always be more expensive. Large models will always require significant computing power.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, overusing small and task-specific models also poses issues. Rahul Pathak, vice president of data and AI GTM at AWS, said in a blog post that cost optimization comes not just from using a model with low compute power needs, but rather from matching a model to tasks. Smaller models may not have a sufficiently large context window to understand more complex instructions, leading to increased workload for human employees and higher costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Sengupta also cautioned that some distilled models could be brittle, so long-term use may not result in savings.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-constantly-evaluate"&gt;Constantly evaluate&lt;/h2&gt;



&lt;p&gt;Regardless of the model size, industry players emphasized the flexibility to address any potential issues or new use cases. So if they start with a large model and a smaller model with similar or better performance and lower cost, organizations cannot be precious about their chosen model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Tessa Burg, CTO and head of innovation at brand marketing company Mod Op, told VentureBeat that organizations must understand that whatever they build now will always be superseded by a better version.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;We started with the mindset that the tech underneath the workflows that we’re creating, the processes that we’re making more efficient, are going to change. We knew that whatever model we use will be the worst version of a model.”&lt;/p&gt;



&lt;p&gt;Burg said that smaller models helped save her company and its clients time in researching and developing concepts. Time saved, she said, that does lead to budget savings over time. She added that it’s a good idea to break out high-cost, high-frequency use cases for light-weight models.&lt;/p&gt;



&lt;p&gt;Sengupta noted that vendors are now making it easier to switch between models automatically, but cautioned users to find platforms that also facilitate fine-tuning, so they don’t incur additional costs.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/06/teal-Model-minimalism_-The-new-AI-strategy-saving-companies-millions.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.” Read more from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;The advent of large language models (LLMs) has made it easier for enterprises to envision the kinds of projects they can undertake, leading to a surge in pilot programs now transitioning to deployment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, as these projects gained momentum, enterprises realized that the earlier LLMs they had used were unwieldy and, worse, expensive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enter small language models and distillation. Models like Google’s Gemma family, Microsoft’s Phi and Mistral’s Small 3.1 allowed businesses to choose fast, accurate models that work for specific tasks. Enterprises can opt for a smaller model for particular use cases, allowing them to lower the cost of running their AI applications and potentially achieve a better return on investment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn distinguished engineer Karthik Ramgopal told VentureBeat that companies opt for smaller models for a few reasons.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Smaller models require less compute, memory and faster inference times, which translates directly into lower infrastructure OPEX (operational expenditures) and CAPEX (capital expenditures) given GPU costs, availability and power requirements,” Ramgoapl said. “Task-specific models have a narrower scope, making their behavior more aligned and maintainable over time without complex prompt engineering.”&lt;/p&gt;



&lt;p&gt;Model developers price their small models accordingly. OpenAI’s o4-mini costs $1.1 per million tokens for inputs and $4.4/million tokens for outputs, compared to the full o3 version at $10 for inputs and $40 for outputs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises today have a larger pool of small models, task-specific models and distilled models to choose from. These days, most flagship models offer a range of sizes. For example, the Claude family of models from Anthropic comprises Claude Opus, the largest model, Claude Sonnet, the all-purpose model, and Claude Haiku, the smallest version. These models are compact enough to operate on portable devices, such as laptops or mobile phones.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-savings-question"&gt;The savings question&lt;/h2&gt;



&lt;p&gt;When discussing return on investment, though, the question is always: What does ROI look like? Should it be a return on the costs incurred or the time savings that ultimately means dollars saved down the line? Experts VentureBeat spoke to said ROI can be difficult to judge because some companies believe they’ve already reached ROI by cutting time spent on a task while others are waiting for actual dollars saved or more business brought in to say if AI investments have actually worked. &lt;/p&gt;



&lt;p&gt;Normally, enterprises calculate ROI by a simple formula as described by Cognizant chief technologist Ravi Naarla in a post: ROI = (Benefits-Cost)/Costs. But with AI programs, the benefits are not immediately apparent. He suggests enterprises identify the benefits they expect to achieve, estimate these based on historical data, be realistic about the overall cost of AI, including hiring, implementation and maintenance, and understand you have to be in it for the long haul.&lt;/p&gt;



&lt;p&gt;With small models, experts argue that these reduce implementation and maintenance costs, especially when fine-tuning models to provide them with more context for your enterprise.&lt;/p&gt;



&lt;p&gt;Arijit Sengupta, founder and CEO of Aible, said that how people bring context to the models dictates how much cost savings they can get. For individuals who require additional context for prompts, such as lengthy and complex instructions, this can result in higher token costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You have to give models context one way or the other; there is no free lunch. But with large models, that is usually done by putting it in the prompt,” he said. “Think of fine-tuning and post-training as an alternative way of giving models context. I might incur $100 of post-training costs, but it’s not astronomical.”&lt;/p&gt;



&lt;p&gt;Sengupta said they’ve seen about 100X cost reductions just from post-training alone, often dropping model use cost “from single-digit millions to something like $30,000.” He did point out that this number includes software operating expenses and the ongoing cost of the model and vector databases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In terms of maintenance cost, if you do it manually with human experts, it can be expensive to maintain because small models need to be post-trained to produce results comparable to large models,” he said.&lt;/p&gt;



&lt;p&gt;Experiments Aible conducted showed that a task-specific, fine-tuned model performs well for some use cases, just like LLMs, making the case that deploying several use-case-specific models rather than large ones to do everything is more cost-effective.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company compared a post-trained version of Llama-3.3-70B-Instruct to a smaller 8B parameter option of the same model. The 70B model, post-trained for $11.30, was 84% accurate in automated evaluations and 92% in manual evaluations. Once fine-tuned to a cost of $4.58, the 8B model achieved 82% accuracy in manual assessment, which would be suitable for more minor, more targeted use cases.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cost-factors-fit-for-purpose"&gt;Cost factors fit for purpose&lt;/h2&gt;



&lt;p&gt;Right-sizing models does not have to come at the cost of performance. These days, organizations understand that model choice doesn’t just mean choosing between GPT-4o or Llama-3.1; it’s knowing that some use cases, like summarization or code generation, are better served by a small model.&lt;/p&gt;



&lt;p&gt;Daniel Hoske, chief technology officer at contact center AI products provider Cresta, said starting development with LLMs informs potential cost savings better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You should start with the biggest model to see if what you’re envisioning even works at all, because if it doesn’t work with the biggest model, it doesn’t mean it would with smaller models,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Ramgopal said LinkedIn follows a similar pattern because prototyping is the only way these issues can start to emerge.&lt;/p&gt;



&lt;p&gt;“Our typical approach for agentic use cases begins with general-purpose LLMs as their broad generalizationability allows us to rapidly prototype, validate hypotheses and assess product-market fit,” LinkedIn’s Ramgopal said. “As the product matures and we encounter constraints around quality, cost or latency, we transition to more customized solutions.”&lt;/p&gt;



&lt;p&gt;In the experimentation phase, organizations can determine what they value most from their AI applications. Figuring this out enables developers to plan better what they want to save on and select the model size that best suits their purpose and budget.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The experts cautioned that while it is important to build with models that work best with what they’re developing, high-parameter LLMs will always be more expensive. Large models will always require significant computing power.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, overusing small and task-specific models also poses issues. Rahul Pathak, vice president of data and AI GTM at AWS, said in a blog post that cost optimization comes not just from using a model with low compute power needs, but rather from matching a model to tasks. Smaller models may not have a sufficiently large context window to understand more complex instructions, leading to increased workload for human employees and higher costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Sengupta also cautioned that some distilled models could be brittle, so long-term use may not result in savings.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-constantly-evaluate"&gt;Constantly evaluate&lt;/h2&gt;



&lt;p&gt;Regardless of the model size, industry players emphasized the flexibility to address any potential issues or new use cases. So if they start with a large model and a smaller model with similar or better performance and lower cost, organizations cannot be precious about their chosen model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Tessa Burg, CTO and head of innovation at brand marketing company Mod Op, told VentureBeat that organizations must understand that whatever they build now will always be superseded by a better version.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;We started with the mindset that the tech underneath the workflows that we’re creating, the processes that we’re making more efficient, are going to change. We knew that whatever model we use will be the worst version of a model.”&lt;/p&gt;



&lt;p&gt;Burg said that smaller models helped save her company and its clients time in researching and developing concepts. Time saved, she said, that does lead to budget savings over time. She added that it’s a good idea to break out high-cost, high-frequency use cases for light-weight models.&lt;/p&gt;



&lt;p&gt;Sengupta noted that vendors are now making it easier to switch between models automatically, but cautioned users to find platforms that also facilitate fine-tuning, so they don’t incur additional costs.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/model-minimalism-the-new-ai-strategy-saving-companies-millions/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] How runtime attacks turn profitable AI into budget black holes (AI News | VentureBeat)</title><link>https://venturebeat.com/security/how-runtime-attacks-turn-profitable-ai-into-budget-black-holes/</link><description>&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI’s promise is undeniable, but so are its blindsiding security costs at the inference layer. New attacks targeting AI’s operational side are quietly inflating budgets, jeopardizing regulatory compliance and eroding customer trust, all of which threaten the return on investment (ROI) and total cost of ownership of enterprise AI deployments.&lt;/p&gt;



&lt;p&gt;AI has captivated the enterprise with its potential for game-changing insights and efficiency gains. Yet, as organizations rush to operationalize their models, a sobering reality is emerging: The inference stage, where AI translates investment into real-time business value, is under siege. This critical juncture is driving up the total cost of ownership (TCO) in ways that initial business cases failed to predict.&lt;/p&gt;



&lt;p&gt;Security executives and CFOs who greenlit AI projects for their transformative upside are now grappling with the hidden expenses of defending these systems. Adversaries have discovered that inference is where AI “comes alive” for a business, and it’s precisely where they can inflict the most damage. The result is a cascade of cost inflation: Breach containment can exceed $5 million per incident in regulated sectors, compliance retrofits run into the hundreds of thousands and trust failures can trigger stock hits or contract cancellations that decimate projected AI ROI. Without cost containment at inference, AI becomes an ungovernable budget wildcard.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-unseen-battlefield-ai-inference-and-exploding-tco"&gt;The unseen battlefield: AI inference and exploding TCO&lt;/h2&gt;



&lt;p&gt;AI inference is rapidly becoming the “next insider risk,” Cristian Rodriguez, field CTO for the Americas at CrowdStrike, told the audience at RSAC 2025.&lt;/p&gt;



&lt;p&gt;Other technology leaders echo this perspective and see a common blind spot in enterprise strategy. Vineet Arora, CTO at WinWire, notes that many organizations “focus intensely on securing the infrastructure around AI while inadvertently sidelining inference.” This oversight, he explains, “leads to underestimated costs for continuous monitoring systems, real-time threat analysis and rapid patching mechanisms.”&lt;/p&gt;



&lt;p&gt;Another critical blind spot, according to Steffen Schreier, SVP of product and portfolio at Telesign, is “the assumption that third-party models are thoroughly vetted and inherently safe to deploy.”&lt;/p&gt;



&lt;p&gt;He warned that in reality, “these models often haven’t been evaluated against an organization’s specific threat landscape or compliance needs,” which can lead to harmful or non-compliant outputs that erode brand trust. Schreier told VentureBeat that “inference-time vulnerabilities — like prompt injection, output manipulation or context leakage — can be exploited by attackers to produce harmful, biased or non-compliant outputs. This poses serious risks, especially in regulated industries, and can quickly erode brand trust.”&lt;/p&gt;



&lt;p&gt;When inference is compromised, the fallout hits multiple fronts of TCO. Cybersecurity budgets spiral, regulatory compliance is jeopardized and customer trust erodes. Executive sentiment reflects this growing concern. In CrowdStrike’s State of AI in Cybersecurity survey, only 39% of respondents felt generative AI’s rewards clearly outweigh the risks, while 40% judged them comparable. This ambivalence underscores a critical finding: Safety and privacy controls have become top requirements for new gen AI initiatives, with a striking 90% of organizations now implementing or developing policies to govern AI adoption. The top concerns are no longer abstract; 26% cite sensitive data exposure and 25% fear adversarial attacks as key risks.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010705" height="447" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-1-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Security leaders exhibit mixed sentiments regarding the overall safety of gen AI, with top concerns centered on the exposure of sensitive data to LLMs (26%) and adversarial attacks on AI tools (25%). &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-anatomy-of-an-inference-attack"&gt;Anatomy of an inference attack&lt;/h2&gt;



&lt;p&gt;The unique attack surface exposed by running AI models is being aggressively probed by adversaries. To defend against this, Schreier advises, “it is critical to treat every input as a potential hostile attack.” Frameworks like the OWASP Top 10 for Large Language Model (LLM) Applications catalogue these threats, which are no longer theoretical but active attack vectors impacting the enterprise:&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Prompt injection (LLM01) and insecure output handling (LLM02):&lt;/strong&gt; Attackers manipulate models via inputs or outputs. Malicious inputs can cause the model to ignore instructions or divulge proprietary code. Insecure output handling occurs when an application blindly trusts AI responses, allowing attackers to inject malicious scripts into downstream systems.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Training data poisoning (LLM03) and model poisoning:&lt;/strong&gt; Attackers corrupt training data by sneaking in tainted samples, planting hidden triggers. Later, an innocuous input can unleash malicious outputs.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Model denial of service (LLM04):&lt;/strong&gt; Adversaries can overwhelm AI models with complex inputs, consuming excessive resources to slow or crash them, resulting in direct revenue loss.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Supply chain and plugin vulnerabilities (LLM05 and LLM07):&lt;/strong&gt; The AI ecosystem is built on shared components. &lt;span&gt;For instance, a vulnerability in the Flowise LLM tool&lt;/span&gt; exposed private AI dashboards and sensitive data, including GitHub tokens and OpenAI API keys, on 438 servers.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Sensitive information disclosure (LLM06):&lt;/strong&gt; Clever querying can extract confidential information from an AI model if it was part of its training data or is present in the current context.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Excessive agency (LLM08) and Overreliance (LLM09):&lt;/strong&gt; Granting an AI agent unchecked permissions to execute trades or modify databases is a recipe for disaster if manipulated.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Model theft (LLM10):&lt;/strong&gt; An organization’s proprietary models can be stolen through sophisticated extraction techniques — a direct assault on its competitive advantage.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Underpinning these threats are foundational security failures. Adversaries often log in with leaked credentials. In early 2024, 35% of cloud intrusions involved valid user credentials, and new, unattributed cloud attack attempts spiked 26%, according to the CrowdStrike 2025 Global Threat Report. A deepfake campaign resulted in a fraudulent $25.6 million transfer, while AI-generated phishing emails have demonstrated a 54% click-through rate, more than four times higher than those written by humans.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010706" height="451" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The OWASP framework illustrates how various LLM attack vectors target different components of an AI application, from prompt injection at the user interface to data poisoning in the training models and sensitive information disclosure from the datastore. &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-back-to-basics-foundational-security-for-a-new-era"&gt;Back to basics: Foundational security for a new era&lt;/h2&gt;



&lt;p&gt;Securing AI requires a disciplined return to security fundamentals — but applied through a modern lens. “I think that we need to take a step back and ensure that the foundation and the fundamentals of security are still applicable,” Rodriguez argued. “The same approach you would have to securing an OS is the same approach you would have to securing that AI model.”&lt;/p&gt;



&lt;p&gt;This means enforcing unified protection across every attack path, with rigorous data governance, robust cloud security posture management (CSPM), and identity-first security through cloud infrastructure entitlement management (CIEM) to lock down the cloud environments where most AI workloads reside. As identity becomes the new perimeter, AI systems must be governed with the same strict access controls and runtime protections as any other business-critical cloud asset.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-specter-of-shadow-ai-unmasking-hidden-risks"&gt;The specter of “shadow AI”: Unmasking hidden risks&lt;/h2&gt;



&lt;p&gt;Shadow AI, or the unsanctioned use of AI tools by employees, creates a massive, unknown attack surface. A financial analyst using a free online LLM for confidential documents can inadvertently leak proprietary data. As Rodriguez warned, queries to public models can “become another’s answers.” Addressing this requires a combination of clear policy, employee education, and technical controls like AI security posture management (AI-SPM) to discover and assess all AI assets, sanctioned or not.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fortifying-the-future-actionable-defense-strategies"&gt;Fortifying the future: Actionable defense strategies&lt;/h2&gt;



&lt;p&gt;While adversaries have weaponized AI, the tide is beginning to turn. As Mike Riemer, Field CISO at Ivanti, observes, defenders are beginning to “harness the full potential of AI for cybersecurity purposes to analyze vast amounts of data collected from diverse systems.” This proactive stance is essential for building a robust defense, which requires several key strategies:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Budget for inference security from day zero:&lt;/strong&gt; The first step, according to Arora, is to begin with “a comprehensive risk-based assessment.” He advises mapping the entire inference pipeline to identify every data flow and vulnerability. “By linking these risks to possible financial impacts,” he explains, “we can better quantify the cost of a security breach” and build a realistic budget.&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;To structure this more systematically, CISOs and CFOs should start with a risk-adjusted ROI model. One approach:&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Security ROI = (estimated breach cost × annual risk probability) – total security investment&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;For example, if an LLM inference attack could result in a $5 million loss and the likelihood is 10%, the expected loss is $500,000. A $350,000 investment in inference-stage defenses would yield a net gain of $150,000 in avoided risk. This model enables scenario-based budgeting tied directly to financial outcomes.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;&lt;strong&gt;Enterprises allocating less than 8 to 12% of their AI project budgets to inference-stage security are often blindsided later by breach recovery and compliance costs&lt;/strong&gt;. A Fortune 500 healthcare provider CIO, interviewed by VentureBeat and requesting anonymity, now allocates 15% of their total gen AI budget to post-training risk management, including runtime monitoring, AI-SPM platforms and compliance audits. A practical budgeting model should allocate across four cost centers: runtime monitoring (35%), adversarial simulation (25%), compliance tooling (20%) and user behavior analytics (20%).&lt;/p&gt;



&lt;p&gt;Here’s a sample allocation snapshot for a $2 million enterprise AI deployment based on VentureBeat’s ongoing interviews with CFOs, CIOs and CISOs actively budgeting to support AI projects:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Budget category&lt;/th&gt;&lt;th&gt;Allocation&lt;/th&gt;&lt;th&gt;Use case example&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Runtime monitoring&lt;/td&gt;&lt;td&gt;$300,000&lt;/td&gt;&lt;td&gt;Behavioral anomaly detection (API spikes)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adversarial simulation&lt;/td&gt;&lt;td&gt;$200,000&lt;/td&gt;&lt;td&gt;Red team exercises to probe prompt injection&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Compliance tooling&lt;/td&gt;&lt;td&gt;$150,000&lt;/td&gt;&lt;td&gt;EU AI Act alignment, SOC 2 inference validations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;User behavior analytics&lt;/td&gt;&lt;td&gt;$150,000&lt;/td&gt;&lt;td&gt;Detect misuse patterns in internal AI use&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;These investments reduce downstream breach remediation costs, regulatory penalties and SLA violations, all helping to stabilize AI TCO.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Implement runtime monitoring and validation: &lt;/strong&gt;Begin by tuning anomaly detection to detect behaviors at the inference layer, such as abnormal API call patterns, output entropy shifts or query frequency spikes. Vendors like DataDome and Telesign now offer real-time behavioral analytics tailored to gen AI misuse signatures.&lt;/p&gt;



&lt;p&gt;Teams should monitor entropy shifts in outputs, track token irregularities in model responses and watch for atypical frequency in queries from privileged accounts. Effective setups include streaming logs into SIEM tools (such as Splunk or Datadog) with tailored gen AI parsers and establishing real-time alert thresholds for deviations from model baselines.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Adopt a zero-trust framework for AI:&lt;/strong&gt; Zero-trust is non-negotiable for AI environments. It operates on the principle of “never trust, always verify.” By adopting this architecture, Riemer notes, organizations can ensure that “only authenticated users and devices gain access to sensitive data and applications, regardless of their physical location.”&lt;/p&gt;



&lt;p&gt;Inference-time zero-trust should be enforced at multiple layers:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Identity&lt;/strong&gt;: Authenticate both human and service actors accessing inference endpoints.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Permissions&lt;/strong&gt;: Scope LLM access using role-based access control (RBAC) with time-boxed privileges.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Segmentation&lt;/strong&gt;: Isolate inference microservices with service mesh policies and enforce least-privilege defaults through cloud workload protection platforms (CWPPs).&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010708" height="446" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-3.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;A proactive AI security strategy requires a holistic approach, encompassing visibility and supply chain security during development, securing infrastructure and data and implementing robust safeguards to protect AI systems in runtime during production. &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-protecting-ai-roi-a-ciso-cfo-collaboration-model"&gt;Protecting AI ROI: A CISO/CFO collaboration model&lt;/h2&gt;



&lt;p&gt;Protecting the ROI of enterprise AI requires actively modeling the financial upside of security. Start with a baseline ROI projection, then layer in cost-avoidance scenarios for each security control. Mapping cybersecurity investments to avoided costs including incident remediation, SLA violations and customer churn, turns risk reduction into a measurable ROI gain.&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;Enterprises should model three ROI scenarios that include baseline, with security investment and post-breach recovery to show cost avoidance clearly. For example, a telecom deploying output validation prevented 12,000-plus misrouted queries per month, saving $6.3 million annually in SLA penalties and call center volume. Tie investments to avoided costs across breach remediation, SLA non-compliance, brand impact and customer churn to build a defensible ROI argument to CFOs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-checklist-cfo-grade-roi-protection-model"&gt;Checklist: CFO-Grade ROI protection model&lt;/h2&gt;



&lt;p&gt;CFOs need to communicate with clarity on how security spending protects the bottom line. To safeguard AI ROI at the inference layer, security investments must be modeled like any other strategic capital allocation: With direct links to TCO, risk mitigation and revenue preservation.&lt;/p&gt;



&lt;p&gt;Use this checklist to make AI security investments defensible in the boardroom — and actionable in the budget cycle.&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;Link every AI security spend to a projected TCO reduction category (compliance, breach remediation, SLA stability).&lt;/li&gt;



&lt;li&gt;Run cost-avoidance simulations with 3-year horizon scenarios: baseline, protected and breach-reactive.&lt;/li&gt;



&lt;li&gt;Quantify financial risk from SLA violations, regulatory fines, brand trust erosion and customer churn.&lt;/li&gt;



&lt;li&gt;Co-model inference-layer security budgets with both CISOs and CFOs to break organizational silos.&lt;/li&gt;



&lt;li&gt;Present security investments as growth enablers, not overhead, showing how they stabilize AI infrastructure for sustained value capture.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;This model doesn’t just defend AI investments; it defends budgets and brands and can protect and grow boardroom credibility.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2 class="wp-block-heading" id="h-concluding-analysis-a-strategic-imperative"&gt;Concluding analysis: A strategic imperative&lt;/h2&gt;



&lt;p&gt;CISOs must present AI risk management as a business enabler, quantified in terms of ROI protection, brand trust preservation and regulatory stability. As AI inference moves deeper into revenue workflows, protecting it isn’t a cost center; it’s the control plane for AI’s financial sustainability. Strategic security investments at the infrastructure layer must be justified with financial metrics that CFOs can act on.&lt;/p&gt;



&lt;p&gt;The path forward requires organizations to balance investment in AI innovation with an equal investment in its protection. This necessitates a new level of strategic alignment. As Ivanti CIO Robert Grazioli told VentureBeat: “CISO and CIO alignment will be critical to effectively safeguard modern businesses.” This collaboration is essential to break down the data and budget silos that undermine security, allowing organizations to manage the true cost of AI and turn a high-risk gamble into a sustainable, high-ROI engine of growth.&lt;/p&gt;



&lt;p&gt;Telesign’s Schreier added: “We view AI inference risks through the lens of digital identity and trust. We embed security across the full lifecycle of our AI tools — using access controls, usage monitoring, rate limiting and behavioral analytics to detect misuse and protect both our customers and their end users from emerging threats.”&lt;/p&gt;



&lt;p&gt;He continued: “We approach output validation as a critical layer of our AI security architecture, particularly because many inference-time risks don’t stem from how a model is trained, but how it behaves in the wild.”&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;em&gt;This article is part of VentureBeat’s special issue, “The Real Cost of AI: Performance, Efficiency and ROI at Scale.”&amp;nbsp;Read more&amp;nbsp;from this special issue.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI’s promise is undeniable, but so are its blindsiding security costs at the inference layer. New attacks targeting AI’s operational side are quietly inflating budgets, jeopardizing regulatory compliance and eroding customer trust, all of which threaten the return on investment (ROI) and total cost of ownership of enterprise AI deployments.&lt;/p&gt;



&lt;p&gt;AI has captivated the enterprise with its potential for game-changing insights and efficiency gains. Yet, as organizations rush to operationalize their models, a sobering reality is emerging: The inference stage, where AI translates investment into real-time business value, is under siege. This critical juncture is driving up the total cost of ownership (TCO) in ways that initial business cases failed to predict.&lt;/p&gt;



&lt;p&gt;Security executives and CFOs who greenlit AI projects for their transformative upside are now grappling with the hidden expenses of defending these systems. Adversaries have discovered that inference is where AI “comes alive” for a business, and it’s precisely where they can inflict the most damage. The result is a cascade of cost inflation: Breach containment can exceed $5 million per incident in regulated sectors, compliance retrofits run into the hundreds of thousands and trust failures can trigger stock hits or contract cancellations that decimate projected AI ROI. Without cost containment at inference, AI becomes an ungovernable budget wildcard.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-unseen-battlefield-ai-inference-and-exploding-tco"&gt;The unseen battlefield: AI inference and exploding TCO&lt;/h2&gt;



&lt;p&gt;AI inference is rapidly becoming the “next insider risk,” Cristian Rodriguez, field CTO for the Americas at CrowdStrike, told the audience at RSAC 2025.&lt;/p&gt;



&lt;p&gt;Other technology leaders echo this perspective and see a common blind spot in enterprise strategy. Vineet Arora, CTO at WinWire, notes that many organizations “focus intensely on securing the infrastructure around AI while inadvertently sidelining inference.” This oversight, he explains, “leads to underestimated costs for continuous monitoring systems, real-time threat analysis and rapid patching mechanisms.”&lt;/p&gt;



&lt;p&gt;Another critical blind spot, according to Steffen Schreier, SVP of product and portfolio at Telesign, is “the assumption that third-party models are thoroughly vetted and inherently safe to deploy.”&lt;/p&gt;



&lt;p&gt;He warned that in reality, “these models often haven’t been evaluated against an organization’s specific threat landscape or compliance needs,” which can lead to harmful or non-compliant outputs that erode brand trust. Schreier told VentureBeat that “inference-time vulnerabilities — like prompt injection, output manipulation or context leakage — can be exploited by attackers to produce harmful, biased or non-compliant outputs. This poses serious risks, especially in regulated industries, and can quickly erode brand trust.”&lt;/p&gt;



&lt;p&gt;When inference is compromised, the fallout hits multiple fronts of TCO. Cybersecurity budgets spiral, regulatory compliance is jeopardized and customer trust erodes. Executive sentiment reflects this growing concern. In CrowdStrike’s State of AI in Cybersecurity survey, only 39% of respondents felt generative AI’s rewards clearly outweigh the risks, while 40% judged them comparable. This ambivalence underscores a critical finding: Safety and privacy controls have become top requirements for new gen AI initiatives, with a striking 90% of organizations now implementing or developing policies to govern AI adoption. The top concerns are no longer abstract; 26% cite sensitive data exposure and 25% fear adversarial attacks as key risks.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010705" height="447" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-1-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Security leaders exhibit mixed sentiments regarding the overall safety of gen AI, with top concerns centered on the exposure of sensitive data to LLMs (26%) and adversarial attacks on AI tools (25%). &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-anatomy-of-an-inference-attack"&gt;Anatomy of an inference attack&lt;/h2&gt;



&lt;p&gt;The unique attack surface exposed by running AI models is being aggressively probed by adversaries. To defend against this, Schreier advises, “it is critical to treat every input as a potential hostile attack.” Frameworks like the OWASP Top 10 for Large Language Model (LLM) Applications catalogue these threats, which are no longer theoretical but active attack vectors impacting the enterprise:&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Prompt injection (LLM01) and insecure output handling (LLM02):&lt;/strong&gt; Attackers manipulate models via inputs or outputs. Malicious inputs can cause the model to ignore instructions or divulge proprietary code. Insecure output handling occurs when an application blindly trusts AI responses, allowing attackers to inject malicious scripts into downstream systems.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Training data poisoning (LLM03) and model poisoning:&lt;/strong&gt; Attackers corrupt training data by sneaking in tainted samples, planting hidden triggers. Later, an innocuous input can unleash malicious outputs.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Model denial of service (LLM04):&lt;/strong&gt; Adversaries can overwhelm AI models with complex inputs, consuming excessive resources to slow or crash them, resulting in direct revenue loss.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Supply chain and plugin vulnerabilities (LLM05 and LLM07):&lt;/strong&gt; The AI ecosystem is built on shared components. &lt;span&gt;For instance, a vulnerability in the Flowise LLM tool&lt;/span&gt; exposed private AI dashboards and sensitive data, including GitHub tokens and OpenAI API keys, on 438 servers.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Sensitive information disclosure (LLM06):&lt;/strong&gt; Clever querying can extract confidential information from an AI model if it was part of its training data or is present in the current context.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Excessive agency (LLM08) and Overreliance (LLM09):&lt;/strong&gt; Granting an AI agent unchecked permissions to execute trades or modify databases is a recipe for disaster if manipulated.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Model theft (LLM10):&lt;/strong&gt; An organization’s proprietary models can be stolen through sophisticated extraction techniques — a direct assault on its competitive advantage.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Underpinning these threats are foundational security failures. Adversaries often log in with leaked credentials. In early 2024, 35% of cloud intrusions involved valid user credentials, and new, unattributed cloud attack attempts spiked 26%, according to the CrowdStrike 2025 Global Threat Report. A deepfake campaign resulted in a fraudulent $25.6 million transfer, while AI-generated phishing emails have demonstrated a 54% click-through rate, more than four times higher than those written by humans.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010706" height="451" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The OWASP framework illustrates how various LLM attack vectors target different components of an AI application, from prompt injection at the user interface to data poisoning in the training models and sensitive information disclosure from the datastore. &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-back-to-basics-foundational-security-for-a-new-era"&gt;Back to basics: Foundational security for a new era&lt;/h2&gt;



&lt;p&gt;Securing AI requires a disciplined return to security fundamentals — but applied through a modern lens. “I think that we need to take a step back and ensure that the foundation and the fundamentals of security are still applicable,” Rodriguez argued. “The same approach you would have to securing an OS is the same approach you would have to securing that AI model.”&lt;/p&gt;



&lt;p&gt;This means enforcing unified protection across every attack path, with rigorous data governance, robust cloud security posture management (CSPM), and identity-first security through cloud infrastructure entitlement management (CIEM) to lock down the cloud environments where most AI workloads reside. As identity becomes the new perimeter, AI systems must be governed with the same strict access controls and runtime protections as any other business-critical cloud asset.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-specter-of-shadow-ai-unmasking-hidden-risks"&gt;The specter of “shadow AI”: Unmasking hidden risks&lt;/h2&gt;



&lt;p&gt;Shadow AI, or the unsanctioned use of AI tools by employees, creates a massive, unknown attack surface. A financial analyst using a free online LLM for confidential documents can inadvertently leak proprietary data. As Rodriguez warned, queries to public models can “become another’s answers.” Addressing this requires a combination of clear policy, employee education, and technical controls like AI security posture management (AI-SPM) to discover and assess all AI assets, sanctioned or not.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fortifying-the-future-actionable-defense-strategies"&gt;Fortifying the future: Actionable defense strategies&lt;/h2&gt;



&lt;p&gt;While adversaries have weaponized AI, the tide is beginning to turn. As Mike Riemer, Field CISO at Ivanti, observes, defenders are beginning to “harness the full potential of AI for cybersecurity purposes to analyze vast amounts of data collected from diverse systems.” This proactive stance is essential for building a robust defense, which requires several key strategies:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Budget for inference security from day zero:&lt;/strong&gt; The first step, according to Arora, is to begin with “a comprehensive risk-based assessment.” He advises mapping the entire inference pipeline to identify every data flow and vulnerability. “By linking these risks to possible financial impacts,” he explains, “we can better quantify the cost of a security breach” and build a realistic budget.&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;To structure this more systematically, CISOs and CFOs should start with a risk-adjusted ROI model. One approach:&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Security ROI = (estimated breach cost × annual risk probability) – total security investment&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;For example, if an LLM inference attack could result in a $5 million loss and the likelihood is 10%, the expected loss is $500,000. A $350,000 investment in inference-stage defenses would yield a net gain of $150,000 in avoided risk. This model enables scenario-based budgeting tied directly to financial outcomes.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;&lt;strong&gt;Enterprises allocating less than 8 to 12% of their AI project budgets to inference-stage security are often blindsided later by breach recovery and compliance costs&lt;/strong&gt;. A Fortune 500 healthcare provider CIO, interviewed by VentureBeat and requesting anonymity, now allocates 15% of their total gen AI budget to post-training risk management, including runtime monitoring, AI-SPM platforms and compliance audits. A practical budgeting model should allocate across four cost centers: runtime monitoring (35%), adversarial simulation (25%), compliance tooling (20%) and user behavior analytics (20%).&lt;/p&gt;



&lt;p&gt;Here’s a sample allocation snapshot for a $2 million enterprise AI deployment based on VentureBeat’s ongoing interviews with CFOs, CIOs and CISOs actively budgeting to support AI projects:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Budget category&lt;/th&gt;&lt;th&gt;Allocation&lt;/th&gt;&lt;th&gt;Use case example&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Runtime monitoring&lt;/td&gt;&lt;td&gt;$300,000&lt;/td&gt;&lt;td&gt;Behavioral anomaly detection (API spikes)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adversarial simulation&lt;/td&gt;&lt;td&gt;$200,000&lt;/td&gt;&lt;td&gt;Red team exercises to probe prompt injection&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Compliance tooling&lt;/td&gt;&lt;td&gt;$150,000&lt;/td&gt;&lt;td&gt;EU AI Act alignment, SOC 2 inference validations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;User behavior analytics&lt;/td&gt;&lt;td&gt;$150,000&lt;/td&gt;&lt;td&gt;Detect misuse patterns in internal AI use&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;These investments reduce downstream breach remediation costs, regulatory penalties and SLA violations, all helping to stabilize AI TCO.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Implement runtime monitoring and validation: &lt;/strong&gt;Begin by tuning anomaly detection to detect behaviors at the inference layer, such as abnormal API call patterns, output entropy shifts or query frequency spikes. Vendors like DataDome and Telesign now offer real-time behavioral analytics tailored to gen AI misuse signatures.&lt;/p&gt;



&lt;p&gt;Teams should monitor entropy shifts in outputs, track token irregularities in model responses and watch for atypical frequency in queries from privileged accounts. Effective setups include streaming logs into SIEM tools (such as Splunk or Datadog) with tailored gen AI parsers and establishing real-time alert thresholds for deviations from model baselines.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Adopt a zero-trust framework for AI:&lt;/strong&gt; Zero-trust is non-negotiable for AI environments. It operates on the principle of “never trust, always verify.” By adopting this architecture, Riemer notes, organizations can ensure that “only authenticated users and devices gain access to sensitive data and applications, regardless of their physical location.”&lt;/p&gt;



&lt;p&gt;Inference-time zero-trust should be enforced at multiple layers:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Identity&lt;/strong&gt;: Authenticate both human and service actors accessing inference endpoints.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Permissions&lt;/strong&gt;: Scope LLM access using role-based access control (RBAC) with time-boxed privileges.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Segmentation&lt;/strong&gt;: Isolate inference microservices with service mesh policies and enforce least-privilege defaults through cloud workload protection platforms (CWPPs).&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3010708" height="446" src="https://venturebeat.com/wp-content/uploads/2025/06/figure-3.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;A proactive AI security strategy requires a holistic approach, encompassing visibility and supply chain security during development, securing infrastructure and data and implementing robust safeguards to protect AI systems in runtime during production. &lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-protecting-ai-roi-a-ciso-cfo-collaboration-model"&gt;Protecting AI ROI: A CISO/CFO collaboration model&lt;/h2&gt;



&lt;p&gt;Protecting the ROI of enterprise AI requires actively modeling the financial upside of security. Start with a baseline ROI projection, then layer in cost-avoidance scenarios for each security control. Mapping cybersecurity investments to avoided costs including incident remediation, SLA violations and customer churn, turns risk reduction into a measurable ROI gain.&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;Enterprises should model three ROI scenarios that include baseline, with security investment and post-breach recovery to show cost avoidance clearly. For example, a telecom deploying output validation prevented 12,000-plus misrouted queries per month, saving $6.3 million annually in SLA penalties and call center volume. Tie investments to avoided costs across breach remediation, SLA non-compliance, brand impact and customer churn to build a defensible ROI argument to CFOs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-checklist-cfo-grade-roi-protection-model"&gt;Checklist: CFO-Grade ROI protection model&lt;/h2&gt;



&lt;p&gt;CFOs need to communicate with clarity on how security spending protects the bottom line. To safeguard AI ROI at the inference layer, security investments must be modeled like any other strategic capital allocation: With direct links to TCO, risk mitigation and revenue preservation.&lt;/p&gt;



&lt;p&gt;Use this checklist to make AI security investments defensible in the boardroom — and actionable in the budget cycle.&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;Link every AI security spend to a projected TCO reduction category (compliance, breach remediation, SLA stability).&lt;/li&gt;



&lt;li&gt;Run cost-avoidance simulations with 3-year horizon scenarios: baseline, protected and breach-reactive.&lt;/li&gt;



&lt;li&gt;Quantify financial risk from SLA violations, regulatory fines, brand trust erosion and customer churn.&lt;/li&gt;



&lt;li&gt;Co-model inference-layer security budgets with both CISOs and CFOs to break organizational silos.&lt;/li&gt;



&lt;li&gt;Present security investments as growth enablers, not overhead, showing how they stabilize AI infrastructure for sustained value capture.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;This model doesn’t just defend AI investments; it defends budgets and brands and can protect and grow boardroom credibility.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2 class="wp-block-heading" id="h-concluding-analysis-a-strategic-imperative"&gt;Concluding analysis: A strategic imperative&lt;/h2&gt;



&lt;p&gt;CISOs must present AI risk management as a business enabler, quantified in terms of ROI protection, brand trust preservation and regulatory stability. As AI inference moves deeper into revenue workflows, protecting it isn’t a cost center; it’s the control plane for AI’s financial sustainability. Strategic security investments at the infrastructure layer must be justified with financial metrics that CFOs can act on.&lt;/p&gt;



&lt;p&gt;The path forward requires organizations to balance investment in AI innovation with an equal investment in its protection. This necessitates a new level of strategic alignment. As Ivanti CIO Robert Grazioli told VentureBeat: “CISO and CIO alignment will be critical to effectively safeguard modern businesses.” This collaboration is essential to break down the data and budget silos that undermine security, allowing organizations to manage the true cost of AI and turn a high-risk gamble into a sustainable, high-ROI engine of growth.&lt;/p&gt;



&lt;p&gt;Telesign’s Schreier added: “We view AI inference risks through the lens of digital identity and trust. We embed security across the full lifecycle of our AI tools — using access controls, usage monitoring, rate limiting and behavioral analytics to detect misuse and protect both our customers and their end users from emerging threats.”&lt;/p&gt;



&lt;p&gt;He continued: “We approach output validation as a critical layer of our AI security architecture, particularly because many inference-time risks don’t stem from how a model is trained, but how it behaves in the wild.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/how-runtime-attacks-turn-profitable-ai-into-budget-black-holes/</guid><pubDate>Fri, 27 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] As job losses loom, Anthropic launches program to track AI’s economic fallout (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/27/as-job-losses-loom-anthropic-launches-program-to-track-ais-economic-fallout/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Anthropic-economic-futures-program.png?resize=1200,667" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley has opined on the promise of generative AI to forge new career paths and economic opportunities – like the newly coveted solo unicorn startup. Banks and analysts have touted AI’s potential to boost GDP. But those gains are unlikely to be distributed equally in the face of what many expect to be widespread AI-related job loss.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this backdrop, Anthropic on Friday launched its Economic Futures Program, a new initiative to support research on AI’s impacts on the labor market and global economy and to develop policy proposals to prepare for the shift.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s asking questions about what are the economic impacts [of AI], both positive and negative,” Sarah Heck, head of policy programs and partnerships at Anthropic, told TechCrunch. “It’s really important to root these conversations in evidence and not have predetermined outcomes or views on what’s going to [happen].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least one prominent name has shared his views on the potential economic impact of AI: Anthropic’s CEO Dario Amodei. In May, Amodei predicted that AI could wipe out half of all entry-level white-collar jobs and spike unemployment to as high as 20% in the next one to five years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked if one of the key goals of Anthropic’s Economic Futures Program was to research ways to mitigate AI-related job loss, Heck was cautious, noting that the disruptive shifts AI will bring could be “both good and bad.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key goal is to figure out what is actually happening,” she said. “If there is job loss, then we should convene a collective group of thinkers to talk about mitigation. If there will be huge GDP expansion, great. We should also convene policy makers to figure out what to do with that. I don’t think any of this will be a monolith.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The program builds on Anthropic’s existing Economic Index, launched in February, which open-sources aggregated, anonymized data to analyze the effects of AI on labor markets and the economy over time – data that many of its competitors lock behind corporate walls.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The program will focus on three main areas: providing grants to researchers investigating AI’s effect on labor, productivity, and value creation; creating forums to develop and evaluate policy proposals to prepare for AI’s economic impacts; and building datasets to track AI’s economic usage and impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is kicking off the program with some action items.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has opened applications for its rapid grants of up to $50,000 for “empirical research on AI’s economic impacts,” as well as evidence-based policy proposals for Anthropic-hosted symposia events in Washington, D.C. and Europe in the fall. Anthropic is also seeking partnerships with independent research institutions and will provide partners with Claude API credits and other resources to support research.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For the grants, Heck noted that Anthropic is looking for individuals, academics, or teams that can come up with high-quality data in a short period of time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be able to complete it within six months,” she said. “It doesn’t necessarily have to be peer-reviewed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For the symposia, Anthropic wants policy ideas from a wide variety of backgrounds and intellectual perspectives, said Heck. She noted that policy proposals would go “beyond labor.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to understand more about the transitions,” she said. “How do workflows happen in new ways? How are new jobs being created that nobody ever contemplated before?…How are certain skills remaining valuable while others are not?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Heck said Anthropic also hopes to study the effects of AI on fiscal policy. For example, what happens if there’s a major shift in the way enterprises see value creation?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really want to open the aperture here on things that can be studied,” Heck said. “Labor is certainly one of them, but it’s a much broader swath.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic rival OpenAI released its own Economic Blueprint in January, which focuses more on helping the public adopt AI tools, building robust AI infrastructure and establishing “AI economic zones” that streamline regulations to promote investment. While OpenAI’s Stargate project to build data centers across the U.S. in partnership with Oracle and SoftBank would create thousands of construction jobs, OpenAI doesn’t directly address AI-related job loss in its economic blueprint.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s blueprint does, however, outline frameworks where government could play a role in supply chain training pipelines, investing in AI literacy, supporting regional training programs, and scaling public university access to compute to foster local AI-literate workforces.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic’s economic impact program is part of a slow but growing shift among some tech companies to position themselves as part of the solution to the disruption they’re helping to create – whether out of reputational concern, genuine altruism, or a mix of both. For instance, on Thursday, ride-hail company Lyft launched a forum to gather input from human drivers as it starts integrating robotaxis into its platform.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Anthropic-economic-futures-program.png?resize=1200,667" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley has opined on the promise of generative AI to forge new career paths and economic opportunities – like the newly coveted solo unicorn startup. Banks and analysts have touted AI’s potential to boost GDP. But those gains are unlikely to be distributed equally in the face of what many expect to be widespread AI-related job loss.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this backdrop, Anthropic on Friday launched its Economic Futures Program, a new initiative to support research on AI’s impacts on the labor market and global economy and to develop policy proposals to prepare for the shift.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s asking questions about what are the economic impacts [of AI], both positive and negative,” Sarah Heck, head of policy programs and partnerships at Anthropic, told TechCrunch. “It’s really important to root these conversations in evidence and not have predetermined outcomes or views on what’s going to [happen].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least one prominent name has shared his views on the potential economic impact of AI: Anthropic’s CEO Dario Amodei. In May, Amodei predicted that AI could wipe out half of all entry-level white-collar jobs and spike unemployment to as high as 20% in the next one to five years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked if one of the key goals of Anthropic’s Economic Futures Program was to research ways to mitigate AI-related job loss, Heck was cautious, noting that the disruptive shifts AI will bring could be “both good and bad.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key goal is to figure out what is actually happening,” she said. “If there is job loss, then we should convene a collective group of thinkers to talk about mitigation. If there will be huge GDP expansion, great. We should also convene policy makers to figure out what to do with that. I don’t think any of this will be a monolith.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The program builds on Anthropic’s existing Economic Index, launched in February, which open-sources aggregated, anonymized data to analyze the effects of AI on labor markets and the economy over time – data that many of its competitors lock behind corporate walls.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The program will focus on three main areas: providing grants to researchers investigating AI’s effect on labor, productivity, and value creation; creating forums to develop and evaluate policy proposals to prepare for AI’s economic impacts; and building datasets to track AI’s economic usage and impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is kicking off the program with some action items.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has opened applications for its rapid grants of up to $50,000 for “empirical research on AI’s economic impacts,” as well as evidence-based policy proposals for Anthropic-hosted symposia events in Washington, D.C. and Europe in the fall. Anthropic is also seeking partnerships with independent research institutions and will provide partners with Claude API credits and other resources to support research.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For the grants, Heck noted that Anthropic is looking for individuals, academics, or teams that can come up with high-quality data in a short period of time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be able to complete it within six months,” she said. “It doesn’t necessarily have to be peer-reviewed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For the symposia, Anthropic wants policy ideas from a wide variety of backgrounds and intellectual perspectives, said Heck. She noted that policy proposals would go “beyond labor.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to understand more about the transitions,” she said. “How do workflows happen in new ways? How are new jobs being created that nobody ever contemplated before?…How are certain skills remaining valuable while others are not?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Heck said Anthropic also hopes to study the effects of AI on fiscal policy. For example, what happens if there’s a major shift in the way enterprises see value creation?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really want to open the aperture here on things that can be studied,” Heck said. “Labor is certainly one of them, but it’s a much broader swath.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic rival OpenAI released its own Economic Blueprint in January, which focuses more on helping the public adopt AI tools, building robust AI infrastructure and establishing “AI economic zones” that streamline regulations to promote investment. While OpenAI’s Stargate project to build data centers across the U.S. in partnership with Oracle and SoftBank would create thousands of construction jobs, OpenAI doesn’t directly address AI-related job loss in its economic blueprint.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s blueprint does, however, outline frameworks where government could play a role in supply chain training pipelines, investing in AI literacy, supporting regional training programs, and scaling public university access to compute to foster local AI-literate workforces.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic’s economic impact program is part of a slow but growing shift among some tech companies to position themselves as part of the solution to the disruption they’re helping to create – whether out of reputational concern, genuine altruism, or a mix of both. For instance, on Thursday, ride-hail company Lyft launched a forum to gather input from human drivers as it starts integrating robotaxis into its platform.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/27/as-job-losses-loom-anthropic-launches-program-to-track-ais-economic-fallout/</guid><pubDate>Fri, 27 Jun 2025 20:59:19 +0000</pubDate></item><item><title>[NEW] Congress might block state AI laws for a decade. Here’s what it means. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/27/congress-might-block-state-ai-laws-for-a-decade-heres-what-it-means/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for 10 years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor – including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen – argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It is designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cruz then released another revision on Wednesday, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill – a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already-obligated broadband funding from states that don’t comply.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) criticized Cruz’s reconciliation language on Thursday, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 07, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years. (Photo by Sean Gallup/Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the provision is at a standstill. Cruz’s initial revision passed the procedural review earlier this week, which meant that the AI moratorium would be included in the final bill. However, reporting today from Punchbowl News and Bloomberg suggest that talks have reopened, and conversations on the AI moratorium’s language are ongoing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources familiar with the matter tell TechCrunch they expect the Senate to begin heavy debate this week on amendments to the budget, including one that would strike the AI moratorium. That will be followed by a vote-a-rama – a series of rapid votes on the full slate of amendments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Politico reported Friday that the Senate is slated to take an initial vote on the megabill on Saturday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments this week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I worry that if…we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation – it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode – which has sponsored several state AI safety bills – in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Senator Josh Hawley (R-MO) who is concerned about states’ rights and is working with Democrats to strip it from the bill. Senator Marsha Blackburn (R-TN) also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to reflect newer reporting on the Senate’s timeline to vote on the bill and fresh Republican opposition to the AI moritorium.  &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for 10 years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor – including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen – argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It is designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cruz then released another revision on Wednesday, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill – a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already-obligated broadband funding from states that don’t comply.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) criticized Cruz’s reconciliation language on Thursday, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 07, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years. (Photo by Sean Gallup/Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the provision is at a standstill. Cruz’s initial revision passed the procedural review earlier this week, which meant that the AI moratorium would be included in the final bill. However, reporting today from Punchbowl News and Bloomberg suggest that talks have reopened, and conversations on the AI moratorium’s language are ongoing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources familiar with the matter tell TechCrunch they expect the Senate to begin heavy debate this week on amendments to the budget, including one that would strike the AI moratorium. That will be followed by a vote-a-rama – a series of rapid votes on the full slate of amendments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Politico reported Friday that the Senate is slated to take an initial vote on the megabill on Saturday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments this week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I worry that if…we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation – it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode – which has sponsored several state AI safety bills – in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Senator Josh Hawley (R-MO) who is concerned about states’ rights and is working with Democrats to strip it from the bill. Senator Marsha Blackburn (R-TN) also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to reflect newer reporting on the Senate’s timeline to vote on the bill and fresh Republican opposition to the AI moritorium.  &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/27/congress-might-block-state-ai-laws-for-a-decade-heres-what-it-means/</guid><pubDate>Fri, 27 Jun 2025 21:20:32 +0000</pubDate></item><item><title>[NEW] Retail Resurrection: David’s Bridal bets its future on AI after double bankruptcy (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/retail-resurrection-davids-bridal-bets-its-future-on-ai-after-double-bankruptcy/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Inside a new David’s Bridal store in Delray Beach, Florida, a bride-to-be carefully taps images on a 65-inch touchscreen, curating a vision board for her wedding. Behind the scenes, an AI system automatically analyzes her selections, building a knowledge graph that will match her with vendors, recommend products and generate a personalized wedding plan. &lt;/p&gt;



&lt;p&gt;For the overwhelmed bride facing 300-plus wedding planning tasks, this AI assistant promises to automate the process: suggesting what to do next, reorganizing timelines when plans change and eliminating the need to manually update spreadsheets that inevitably break when wedding plans evolve.&lt;/p&gt;



&lt;p&gt;That’s the vision David’s Bridal is racing to fully implement with Pearl Planner, its new beta AI-powered wedding planning platform. For the twice-bankrupt retailer, this technology-driven transformation represents a high-stakes bet that AI can accomplish what traditional retail strategies couldn’t: Survival in an industry where 15,000 stores are projected to close this year alone.&lt;/p&gt;



&lt;p&gt;David’s Bridal is hardly alone in the dramatic and ongoing wave of store closures, bankruptcies and disruptions sweeping through the U.S. retail industry since the mid-2010s. Dubbed the “retail apocalypse,” there were at least 133 major retail bankruptcies and 57,000 store closures between 2018 and 2024.&amp;nbsp;The company narrowly survived liquidation in its second bankruptcy in 2023 when business development company CION Investment Corporation — which has more than $6.1 billion in assets and a portfolio of 100 companies — acquired substantially all of its assets and invested $20 million in new funding.&lt;/p&gt;&lt;p&gt;David’s AI-led transformation is driven from the top down by new CEO Kelly Cook, who originally joined the company as CMO in 2019. Her vision of taking the company from “aisle to algorithm” led her to make an unconventional choice for her leadership team.&lt;/p&gt;



&lt;p&gt;Rather than recruiting from within the bridal or retail industries, Cook tapped Elina Vilk, a Silicon Valley tech veteran with 25 years of experience in payments and digital technology, to lead the execution as president. “I’m probably not the first choice, but that’s by design” Vilk told VentureBeat in an exclusive interview.&lt;/p&gt;



&lt;p&gt;Vilk’s background couldn’t be more different from traditional retail leadership: A decade at eBay and PayPal where she served as CMO, experience running small business marketing at Meta with “200 million businesses” and being among “the first digital marketers, ever.” This fresh outsider perspective was precisely what Cook needed to reimagine how a 75-year-old bridal retailer could use AI to create an entirely new business model.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-driving-david-s-bridal-s-transformation"&gt;What’s driving David’s Bridal’s transformation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;AI was not part of the DNA of David’s Bridal, so Vilk first faced the challenge of building a team from scratch. Her first call was to Mike Bal, a seasoned product leader and technologist, who she worked with as CMO of WooCommerce. Bal, who had spent his career in technology companies like Automattic (parent company of WordPress.com) and various agencies specializing in AI development, was initially reluctant.&lt;/p&gt;



&lt;p&gt;“I’ve been married for almost 15 years, and my wife’s a marriage and family therapist… she doesn’t like weddings.” Despite his reservations about the wedding industry, though, Vilk’s comprehensive vision convinced him. “Elina had this end-to-end plan,” he explains, highlighting the media network, the acquisition of Love Stories TV and the opportunity to use AI for wedding planning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With a technical leader in place, Vilk faced a key decision. “I could have a whole team and have everybody report to me. That was an option. Or I could have a couple of people report to me to start, and then everyone else dotted-line to me, but put them in other organizations, which is exactly what I did.”&lt;/p&gt;



&lt;p&gt;By distributing expertise throughout the company rather than creating a siloed AI team, Vilk says the strategy paid immediate dividends because technological transformation became everyone’s responsibility rather than an isolated initiative. Their accomplishments: &lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Resource multiplication&lt;/strong&gt;: Without increasing headcount, Vilk effectively doubled her available talent by accessing developers and resources from multiple departments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Cross-company influence&lt;/strong&gt;: With team members embedded in every leader’s organization, the AI initiative gained strategic representation at all levels.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Accelerated development&lt;/strong&gt;: The team functioned like a startup within the established company, moving quickly by working across traditional departmental boundaries.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Collaborative engagement&lt;/strong&gt;: Department heads became natural stakeholders through their team members’ involvement, creating organic buy-in across the organization.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This distributed approach accelerated the company-wide identity shift, transforming David’s from a traditional retailer to a technology-enabled wedding platform in less than a year.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-the-technical-foundation"&gt;Building the technical foundation&lt;/h2&gt;



&lt;p&gt;When Mike Bal arrived at David’s Bridal last December, he faced a daunting technical challenge. The company needed to build a sophisticated AI system with limited resources, a tight timeline and no AI experts. Looking at the wedding industry’s reliance on spreadsheets and the communication barriers between brides and vendors, Bal saw an opportunity for a fundamentally different approach.&lt;/p&gt;



&lt;p&gt;“The biggest problem brides have throughout the entire planning process is getting people to understand their vision,” Bal explained. Brides could communicate visually through platforms like Pinterest, but struggled to translate those images into words that vendors, family members and even wedding planners could understand.&lt;/p&gt;



&lt;p&gt;Bal’s first breakthrough came in his architectural approach. While many companies were implementing AI through traditional retrieval-augmented generation (RAG) on vector databases — which essentially functions as a search that finds information matching a query — Bal recognized that this wouldn’t capture the nuanced relationships in wedding planning. &lt;/p&gt;



&lt;p&gt;Instead, he designed a knowledge graph architecture using Neo4j that still leverages RAG but in a fundamentally different way. Rather than limited search-for-a-match logic, the knowledge graph allows the AI to follow a map to the details that make up the most relevant answer, trace connections between elements, understand that a preference for lace might indicate a bohemian style or that tropical flowers suggest a beach theme.&lt;/p&gt;



&lt;p&gt;Working with a single “but sharp” engineer, Bal introduced Replit for rapid prototyping to start building experiences immediately. “We can’t really wait,” he recalls thinking as they faced a potential April launch date while starting work in January. The team soon partnered with dotkonnekt, whose containerized components based on open-source tools like Neo4j and Langflow aligned perfectly with Bal’s architectural vision.&lt;/p&gt;



&lt;p&gt;A key innovation was their approach to “memory”, or how the AI system would maintain context across interactions. Rather than using a single large language model (LLM), Pearl Planner orchestrates multiple specialized AI models working in concert, each handling different aspects of the planning experience. &lt;/p&gt;



&lt;p&gt;“Humans still technically process faster than AI,” Bal notes, explaining how they designed the system to trace relationships through the knowledge graph, similar to how people make intuitive connections. In testing, he found this approach performed “10x better in getting the details in the right place” compared to standard RAG methods.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeRsK6etiKmoJx90tiW9FtjBRxtBeE8SR3eZNfVOHf1xg6oDfTS7JUezcVD6AiGWzklb2iAzNSbozh44EKEl8CHewQpqIUoQ7VUpXt_FaYZlORCxGGWcz2bUAraoHHEOrxUjHsRQ?key=O7V5eSyecAOp8Mz1Grl-aw" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1f3AOnDbq8OiXa9iOKMq4eg3B0RNkrxtktyteLsKQjXt6-I8xpIanok1TGK-spDQ_j7kGJCKNcSlWNPcurwUHgndpKxK_iyt1cKuqcy1fIxHmNfTuWDY51rUWsPaz1ADO2vkm?key=O7V5eSyecAOp8Mz1Grl-aw" /&gt;&lt;/figure&gt;



&lt;p&gt;Rather than overwhelming the team with complexity, Bal focused on simplicity, building a clean interface that hid the AI’s sophisticated tool use capabilities. He systematically extracted expertise from David’s staff, codifying how elements like dress details and venue preferences relate to wedding styles. This expert knowledge was transformed into a vision analysis pipeline that could process images and generate both user-facing aesthetics and detailed backend JSON representations capturing granular preferences.&lt;/p&gt;



&lt;p&gt;The result was a system that leverages a proprietary style quiz, taking a gamified approach, allowing users to select images across multiple categories, from dresses and venues to entertainment and color palettes. This analysis extracts not just surface preferences but deeper style insights, creating both a user-facing experience with an external vision board and a detailed backend profile.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This profile informs every subsequent interaction, from content recommendations to task prioritization, all without requiring the bride to manually explain her vision repeatedly. Additionally, the system curates the bride’s aesthetic, which can sometimes be hard to communicate when it might be a mixture of trends and themes, using that information to create a personalized experience from the colors of her Pearl Planner dashboard to recommended bridal party colors and soon, wedding website design and invitation themes.&lt;/p&gt;



&lt;p&gt;“A lot of these brides don’t feel like anybody’s actually listening to them and what they want because everybody has an opinion,” Bal reflected. “Part of it is they just need somebody to listen and remember what’s important to them. That’s a different problem that we’re solving, like a very human problem, but if we got that right and the interactions reflect that, then we did the right thing as a starting point.”&lt;/p&gt;



&lt;p&gt;By prioritizing the most emotionally resonant features first and gradually expanding capabilities, Bal’s team created an AI assistant with sophisticated function calling that could perform actions like marking tasks complete, reorganizing milestones or generating recommendations. The technology was impressive, but the real achievement was translating technical capabilities into emotional benefits, making brides feel heard and understood in a process typically filled with anxiety and miscommunication.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-getting-the-roi-on-ai-nbsp"&gt;Getting the ROI on AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Vilk mused: “One thing I’ve learned as a tech person coming into retail is that it’s very efficient, more efficient than the world of tech, ironically. Every penny is watched in retail. There’s not a lot of room to say, ‘Oh, I just wanna play with this AI.’ It really has to have one of the equations on the P&amp;amp;L, do we see a line of sight to even more savings, or do we see a line of sight to even higher growth?” &lt;/p&gt;



&lt;p&gt;For David’s, that means building entirely new lines of business with their own P&amp;amp;L. The Pearl Planner platform is set up as a distinct business unit with its own revenue projections and cost allocations, essentially functioning as a startup within the established company.&lt;/p&gt;



&lt;p&gt;“It’s all about the EBITDA” (earnings before interest, taxes, depreciation and amortization), Vilk explains. “We’ve created a separate business unit around Pearl by David’s, which includes Pearl Planner as the cornerstone. It’s pretty much a startup within the existing company.”&lt;/p&gt;



&lt;p&gt;This approach allows the company to measure the platform’s success independently of the core retail business while creating a “very favorable flow through compared to retail,” according to Vilk. The revenue model diverges significantly from traditional retail: Instead of focusing solely on dress sales, Pearl Planner generates income through vendor subscriptions, with photographers, venues and other wedding service providers paying monthly fees ranging from $20 to $300 for preferential placement and access to brides at the exact moment they need those services.&lt;/p&gt;



&lt;p&gt;For AI initiatives elsewhere in the company, Vilk employs a phased, risk-managed approach. “For me, it’s a very simple ROI in terms of what are we paying today versus what we’re going to be paying with AI,” she said. In areas like marketing, where the company spends significant funds on photography and image retouching, AI implementation begins with partial replacement, perhaps 30% of the workload, to validate both cost savings and quality maintenance before expanding.&lt;/p&gt;



&lt;p&gt;This cautious approach extends to customer service AI and other implementations. “The cost of the tool cannot exceed the percentage that you’re using it for,” Vilk insisted, which establishes a clear threshold for initial investment. “You can’t just replace it all and be like, ‘Great, I saved the company a million bucks,’ and then lose customers because you haven’t checked the quality first.”&lt;/p&gt;



&lt;p&gt;This disciplined approach to AI ROI reflects the reality of implementing cutting-edge technology in a traditionally thin-margin industry. While tech companies might have the luxury of experimental AI initiatives with long-term payoffs, David’s Bridal’s transformation must demonstrate tangible returns at each step.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-they-plan-to-take-it"&gt;Where they plan to take it&lt;/h2&gt;



&lt;p&gt;While Pearl Planner is currently in closed beta, David’s Bridal has an ambitious rollout timeline. The public platform launch is scheduled for “early this summer,” with updates on new features and integrations with partners like MyRegistry, Dynadot, Shutterfly, Google and wedding vendors across the nation.&lt;/p&gt;



&lt;p&gt;Vilk’s vision extends beyond just the initial launch, with plans to expand the platform’s capabilities and reach. “In the future, we’re going to make that better and better,” she said, outlining plans to add more sophisticated preference matching based on colors and other wedding elements. Her goal is to create “embedded workflows” that simplify both the bride and vendor experience.&lt;/p&gt;



&lt;p&gt;A key upcoming milestone is the launch of Pearl Planner Pro this fall, a separate platform designed specifically for professional wedding planners. “They have so much knowledge and so much experience,” Bal explained. Rather than replacing these professionals, the platform aims to streamline their work and improve client collaboration.&lt;/p&gt;



&lt;p&gt;“What we’re going to do for planners is give them this entire workflow, but it’s going to look very similar to your real estate listings,” Vilk said, drawing a parallel to how technology enhanced rather than eliminated real estate agents. The planner version will allow professionals to curate vendor recommendations for their clients rather than having brides sort through the entire marketplace.&lt;/p&gt;



&lt;p&gt;Bal has his sights set on even more natural interactions with the platform. “My ideal is to give everybody the ability to call and go on a walk,” he said, envisioning brides managing their planning through voice conversations with their AI assistant. “They can call and talk to their assistant and ask, ‘Hey, what tests do I have about this? Do I have anything that covers this? Actually, I want to do this in July, not in August.’ Let’s move it up. You can push that back or get rid of those things.”&lt;/p&gt;



&lt;p&gt;Beyond the wedding planner, Bal sees the core platform they’ve built as a foundation for solving other problems across the company. “Once you have all that set up and you have your observability for your agents, you have your API keys in there, the lift to spin up a new workflow is pretty low,” he noted. “If we want to personalize our lifecycle emails now, it’s pretty minimal effort. We’ve already put the foundation in.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-blueprint-for-retail-revival"&gt;A blueprint for retail revival&lt;/h2&gt;



&lt;p&gt;David’s Bridal’s approach offers three insights that could reshape how retailers approach AI transformation. First, their pivot from product to platform demonstrates that business model reinvention, not merely technology adoption, is essential for retail survival. By fundamentally changing what they sell, from dresses to vendor connections, they’re creating new revenue streams that pure e-commerce players can’t easily replicate.&lt;/p&gt;



&lt;p&gt;Second, they’re leveraging a frequently overlooked asset of brick-and-mortar retail: The rich, high-intent data generated through in-person customer interactions. As Bal noted, “not a lot of companies can start with a growth channel at that volume, with that level of intelligence and intent.” While conventional wisdom suggests physical stores are liabilities in the digital age, David’s shows how they can become strategic data advantages when properly harnessed.&lt;/p&gt;



&lt;p&gt;Finally, their focus on addressing emotional needs, helping brides feel heard and understood in a process where “everybody has an opinion,” represents a fundamentally different approach to AI implementation. Rather than merely automating functional tasks, they’re using technology to fulfill emotional needs that have always existed but never been adequately served.&lt;/p&gt;



&lt;p&gt;As retail continues its painful transformation, with tens of thousands of stores closing annually, these insights suggest that survival may depend less on competing with e-commerce giants on their terms, and more on reimagining what business traditional retailers are truly in, what unique data advantages they possess and what emotional needs they can uniquely address. For David’s Bridal, a company that has twice faced extinction, their transformation represents not just a technological upgrade but a complete reimagining of their role in the customer journey, a lesson that may prove invaluable for retailers across all categories.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Inside a new David’s Bridal store in Delray Beach, Florida, a bride-to-be carefully taps images on a 65-inch touchscreen, curating a vision board for her wedding. Behind the scenes, an AI system automatically analyzes her selections, building a knowledge graph that will match her with vendors, recommend products and generate a personalized wedding plan. &lt;/p&gt;



&lt;p&gt;For the overwhelmed bride facing 300-plus wedding planning tasks, this AI assistant promises to automate the process: suggesting what to do next, reorganizing timelines when plans change and eliminating the need to manually update spreadsheets that inevitably break when wedding plans evolve.&lt;/p&gt;



&lt;p&gt;That’s the vision David’s Bridal is racing to fully implement with Pearl Planner, its new beta AI-powered wedding planning platform. For the twice-bankrupt retailer, this technology-driven transformation represents a high-stakes bet that AI can accomplish what traditional retail strategies couldn’t: Survival in an industry where 15,000 stores are projected to close this year alone.&lt;/p&gt;



&lt;p&gt;David’s Bridal is hardly alone in the dramatic and ongoing wave of store closures, bankruptcies and disruptions sweeping through the U.S. retail industry since the mid-2010s. Dubbed the “retail apocalypse,” there were at least 133 major retail bankruptcies and 57,000 store closures between 2018 and 2024.&amp;nbsp;The company narrowly survived liquidation in its second bankruptcy in 2023 when business development company CION Investment Corporation — which has more than $6.1 billion in assets and a portfolio of 100 companies — acquired substantially all of its assets and invested $20 million in new funding.&lt;/p&gt;&lt;p&gt;David’s AI-led transformation is driven from the top down by new CEO Kelly Cook, who originally joined the company as CMO in 2019. Her vision of taking the company from “aisle to algorithm” led her to make an unconventional choice for her leadership team.&lt;/p&gt;



&lt;p&gt;Rather than recruiting from within the bridal or retail industries, Cook tapped Elina Vilk, a Silicon Valley tech veteran with 25 years of experience in payments and digital technology, to lead the execution as president. “I’m probably not the first choice, but that’s by design” Vilk told VentureBeat in an exclusive interview.&lt;/p&gt;



&lt;p&gt;Vilk’s background couldn’t be more different from traditional retail leadership: A decade at eBay and PayPal where she served as CMO, experience running small business marketing at Meta with “200 million businesses” and being among “the first digital marketers, ever.” This fresh outsider perspective was precisely what Cook needed to reimagine how a 75-year-old bridal retailer could use AI to create an entirely new business model.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-driving-david-s-bridal-s-transformation"&gt;What’s driving David’s Bridal’s transformation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;AI was not part of the DNA of David’s Bridal, so Vilk first faced the challenge of building a team from scratch. Her first call was to Mike Bal, a seasoned product leader and technologist, who she worked with as CMO of WooCommerce. Bal, who had spent his career in technology companies like Automattic (parent company of WordPress.com) and various agencies specializing in AI development, was initially reluctant.&lt;/p&gt;



&lt;p&gt;“I’ve been married for almost 15 years, and my wife’s a marriage and family therapist… she doesn’t like weddings.” Despite his reservations about the wedding industry, though, Vilk’s comprehensive vision convinced him. “Elina had this end-to-end plan,” he explains, highlighting the media network, the acquisition of Love Stories TV and the opportunity to use AI for wedding planning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With a technical leader in place, Vilk faced a key decision. “I could have a whole team and have everybody report to me. That was an option. Or I could have a couple of people report to me to start, and then everyone else dotted-line to me, but put them in other organizations, which is exactly what I did.”&lt;/p&gt;



&lt;p&gt;By distributing expertise throughout the company rather than creating a siloed AI team, Vilk says the strategy paid immediate dividends because technological transformation became everyone’s responsibility rather than an isolated initiative. Their accomplishments: &lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Resource multiplication&lt;/strong&gt;: Without increasing headcount, Vilk effectively doubled her available talent by accessing developers and resources from multiple departments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Cross-company influence&lt;/strong&gt;: With team members embedded in every leader’s organization, the AI initiative gained strategic representation at all levels.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Accelerated development&lt;/strong&gt;: The team functioned like a startup within the established company, moving quickly by working across traditional departmental boundaries.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Collaborative engagement&lt;/strong&gt;: Department heads became natural stakeholders through their team members’ involvement, creating organic buy-in across the organization.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This distributed approach accelerated the company-wide identity shift, transforming David’s from a traditional retailer to a technology-enabled wedding platform in less than a year.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-the-technical-foundation"&gt;Building the technical foundation&lt;/h2&gt;



&lt;p&gt;When Mike Bal arrived at David’s Bridal last December, he faced a daunting technical challenge. The company needed to build a sophisticated AI system with limited resources, a tight timeline and no AI experts. Looking at the wedding industry’s reliance on spreadsheets and the communication barriers between brides and vendors, Bal saw an opportunity for a fundamentally different approach.&lt;/p&gt;



&lt;p&gt;“The biggest problem brides have throughout the entire planning process is getting people to understand their vision,” Bal explained. Brides could communicate visually through platforms like Pinterest, but struggled to translate those images into words that vendors, family members and even wedding planners could understand.&lt;/p&gt;



&lt;p&gt;Bal’s first breakthrough came in his architectural approach. While many companies were implementing AI through traditional retrieval-augmented generation (RAG) on vector databases — which essentially functions as a search that finds information matching a query — Bal recognized that this wouldn’t capture the nuanced relationships in wedding planning. &lt;/p&gt;



&lt;p&gt;Instead, he designed a knowledge graph architecture using Neo4j that still leverages RAG but in a fundamentally different way. Rather than limited search-for-a-match logic, the knowledge graph allows the AI to follow a map to the details that make up the most relevant answer, trace connections between elements, understand that a preference for lace might indicate a bohemian style or that tropical flowers suggest a beach theme.&lt;/p&gt;



&lt;p&gt;Working with a single “but sharp” engineer, Bal introduced Replit for rapid prototyping to start building experiences immediately. “We can’t really wait,” he recalls thinking as they faced a potential April launch date while starting work in January. The team soon partnered with dotkonnekt, whose containerized components based on open-source tools like Neo4j and Langflow aligned perfectly with Bal’s architectural vision.&lt;/p&gt;



&lt;p&gt;A key innovation was their approach to “memory”, or how the AI system would maintain context across interactions. Rather than using a single large language model (LLM), Pearl Planner orchestrates multiple specialized AI models working in concert, each handling different aspects of the planning experience. &lt;/p&gt;



&lt;p&gt;“Humans still technically process faster than AI,” Bal notes, explaining how they designed the system to trace relationships through the knowledge graph, similar to how people make intuitive connections. In testing, he found this approach performed “10x better in getting the details in the right place” compared to standard RAG methods.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeRsK6etiKmoJx90tiW9FtjBRxtBeE8SR3eZNfVOHf1xg6oDfTS7JUezcVD6AiGWzklb2iAzNSbozh44EKEl8CHewQpqIUoQ7VUpXt_FaYZlORCxGGWcz2bUAraoHHEOrxUjHsRQ?key=O7V5eSyecAOp8Mz1Grl-aw" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1f3AOnDbq8OiXa9iOKMq4eg3B0RNkrxtktyteLsKQjXt6-I8xpIanok1TGK-spDQ_j7kGJCKNcSlWNPcurwUHgndpKxK_iyt1cKuqcy1fIxHmNfTuWDY51rUWsPaz1ADO2vkm?key=O7V5eSyecAOp8Mz1Grl-aw" /&gt;&lt;/figure&gt;



&lt;p&gt;Rather than overwhelming the team with complexity, Bal focused on simplicity, building a clean interface that hid the AI’s sophisticated tool use capabilities. He systematically extracted expertise from David’s staff, codifying how elements like dress details and venue preferences relate to wedding styles. This expert knowledge was transformed into a vision analysis pipeline that could process images and generate both user-facing aesthetics and detailed backend JSON representations capturing granular preferences.&lt;/p&gt;



&lt;p&gt;The result was a system that leverages a proprietary style quiz, taking a gamified approach, allowing users to select images across multiple categories, from dresses and venues to entertainment and color palettes. This analysis extracts not just surface preferences but deeper style insights, creating both a user-facing experience with an external vision board and a detailed backend profile.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This profile informs every subsequent interaction, from content recommendations to task prioritization, all without requiring the bride to manually explain her vision repeatedly. Additionally, the system curates the bride’s aesthetic, which can sometimes be hard to communicate when it might be a mixture of trends and themes, using that information to create a personalized experience from the colors of her Pearl Planner dashboard to recommended bridal party colors and soon, wedding website design and invitation themes.&lt;/p&gt;



&lt;p&gt;“A lot of these brides don’t feel like anybody’s actually listening to them and what they want because everybody has an opinion,” Bal reflected. “Part of it is they just need somebody to listen and remember what’s important to them. That’s a different problem that we’re solving, like a very human problem, but if we got that right and the interactions reflect that, then we did the right thing as a starting point.”&lt;/p&gt;



&lt;p&gt;By prioritizing the most emotionally resonant features first and gradually expanding capabilities, Bal’s team created an AI assistant with sophisticated function calling that could perform actions like marking tasks complete, reorganizing milestones or generating recommendations. The technology was impressive, but the real achievement was translating technical capabilities into emotional benefits, making brides feel heard and understood in a process typically filled with anxiety and miscommunication.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-getting-the-roi-on-ai-nbsp"&gt;Getting the ROI on AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Vilk mused: “One thing I’ve learned as a tech person coming into retail is that it’s very efficient, more efficient than the world of tech, ironically. Every penny is watched in retail. There’s not a lot of room to say, ‘Oh, I just wanna play with this AI.’ It really has to have one of the equations on the P&amp;amp;L, do we see a line of sight to even more savings, or do we see a line of sight to even higher growth?” &lt;/p&gt;



&lt;p&gt;For David’s, that means building entirely new lines of business with their own P&amp;amp;L. The Pearl Planner platform is set up as a distinct business unit with its own revenue projections and cost allocations, essentially functioning as a startup within the established company.&lt;/p&gt;



&lt;p&gt;“It’s all about the EBITDA” (earnings before interest, taxes, depreciation and amortization), Vilk explains. “We’ve created a separate business unit around Pearl by David’s, which includes Pearl Planner as the cornerstone. It’s pretty much a startup within the existing company.”&lt;/p&gt;



&lt;p&gt;This approach allows the company to measure the platform’s success independently of the core retail business while creating a “very favorable flow through compared to retail,” according to Vilk. The revenue model diverges significantly from traditional retail: Instead of focusing solely on dress sales, Pearl Planner generates income through vendor subscriptions, with photographers, venues and other wedding service providers paying monthly fees ranging from $20 to $300 for preferential placement and access to brides at the exact moment they need those services.&lt;/p&gt;



&lt;p&gt;For AI initiatives elsewhere in the company, Vilk employs a phased, risk-managed approach. “For me, it’s a very simple ROI in terms of what are we paying today versus what we’re going to be paying with AI,” she said. In areas like marketing, where the company spends significant funds on photography and image retouching, AI implementation begins with partial replacement, perhaps 30% of the workload, to validate both cost savings and quality maintenance before expanding.&lt;/p&gt;



&lt;p&gt;This cautious approach extends to customer service AI and other implementations. “The cost of the tool cannot exceed the percentage that you’re using it for,” Vilk insisted, which establishes a clear threshold for initial investment. “You can’t just replace it all and be like, ‘Great, I saved the company a million bucks,’ and then lose customers because you haven’t checked the quality first.”&lt;/p&gt;



&lt;p&gt;This disciplined approach to AI ROI reflects the reality of implementing cutting-edge technology in a traditionally thin-margin industry. While tech companies might have the luxury of experimental AI initiatives with long-term payoffs, David’s Bridal’s transformation must demonstrate tangible returns at each step.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-they-plan-to-take-it"&gt;Where they plan to take it&lt;/h2&gt;



&lt;p&gt;While Pearl Planner is currently in closed beta, David’s Bridal has an ambitious rollout timeline. The public platform launch is scheduled for “early this summer,” with updates on new features and integrations with partners like MyRegistry, Dynadot, Shutterfly, Google and wedding vendors across the nation.&lt;/p&gt;



&lt;p&gt;Vilk’s vision extends beyond just the initial launch, with plans to expand the platform’s capabilities and reach. “In the future, we’re going to make that better and better,” she said, outlining plans to add more sophisticated preference matching based on colors and other wedding elements. Her goal is to create “embedded workflows” that simplify both the bride and vendor experience.&lt;/p&gt;



&lt;p&gt;A key upcoming milestone is the launch of Pearl Planner Pro this fall, a separate platform designed specifically for professional wedding planners. “They have so much knowledge and so much experience,” Bal explained. Rather than replacing these professionals, the platform aims to streamline their work and improve client collaboration.&lt;/p&gt;



&lt;p&gt;“What we’re going to do for planners is give them this entire workflow, but it’s going to look very similar to your real estate listings,” Vilk said, drawing a parallel to how technology enhanced rather than eliminated real estate agents. The planner version will allow professionals to curate vendor recommendations for their clients rather than having brides sort through the entire marketplace.&lt;/p&gt;



&lt;p&gt;Bal has his sights set on even more natural interactions with the platform. “My ideal is to give everybody the ability to call and go on a walk,” he said, envisioning brides managing their planning through voice conversations with their AI assistant. “They can call and talk to their assistant and ask, ‘Hey, what tests do I have about this? Do I have anything that covers this? Actually, I want to do this in July, not in August.’ Let’s move it up. You can push that back or get rid of those things.”&lt;/p&gt;



&lt;p&gt;Beyond the wedding planner, Bal sees the core platform they’ve built as a foundation for solving other problems across the company. “Once you have all that set up and you have your observability for your agents, you have your API keys in there, the lift to spin up a new workflow is pretty low,” he noted. “If we want to personalize our lifecycle emails now, it’s pretty minimal effort. We’ve already put the foundation in.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-blueprint-for-retail-revival"&gt;A blueprint for retail revival&lt;/h2&gt;



&lt;p&gt;David’s Bridal’s approach offers three insights that could reshape how retailers approach AI transformation. First, their pivot from product to platform demonstrates that business model reinvention, not merely technology adoption, is essential for retail survival. By fundamentally changing what they sell, from dresses to vendor connections, they’re creating new revenue streams that pure e-commerce players can’t easily replicate.&lt;/p&gt;



&lt;p&gt;Second, they’re leveraging a frequently overlooked asset of brick-and-mortar retail: The rich, high-intent data generated through in-person customer interactions. As Bal noted, “not a lot of companies can start with a growth channel at that volume, with that level of intelligence and intent.” While conventional wisdom suggests physical stores are liabilities in the digital age, David’s shows how they can become strategic data advantages when properly harnessed.&lt;/p&gt;



&lt;p&gt;Finally, their focus on addressing emotional needs, helping brides feel heard and understood in a process where “everybody has an opinion,” represents a fundamentally different approach to AI implementation. Rather than merely automating functional tasks, they’re using technology to fulfill emotional needs that have always existed but never been adequately served.&lt;/p&gt;



&lt;p&gt;As retail continues its painful transformation, with tens of thousands of stores closing annually, these insights suggest that survival may depend less on competing with e-commerce giants on their terms, and more on reimagining what business traditional retailers are truly in, what unique data advantages they possess and what emotional needs they can uniquely address. For David’s Bridal, a company that has twice faced extinction, their transformation represents not just a technological upgrade but a complete reimagining of their role in the customer journey, a lesson that may prove invaluable for retailers across all categories.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/retail-resurrection-davids-bridal-bets-its-future-on-ai-after-double-bankruptcy/</guid><pubDate>Fri, 27 Jun 2025 23:30:13 +0000</pubDate></item><item><title>[NEW] Catio wins ‘coolest tech’ award at VB Transform 2025 (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/catio-wins-coolest-tech-award-at-vb-transform-2025/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Palo Alto-based Catio was awarded “Coolest Technology” at VentureBeat Transform 2025 in San Francisco on Wednesday. Founded in 2023, the company has raised $7 million to date, with a recent $3 million round announced in March. Catio was also a finalist and presented at VB Transform’s Innovation Showcase in 2024.&lt;/p&gt;



&lt;p&gt;Catio’s AI Copilot for Tech Architecture reframes architecture as a living system—one that can be codified, introspected and intelligently evolved. By combining a real-time architectural map with a multi-agent AI organization, the solution helps engineering teams shift from reactive decision-making to continuous, proactive architecture excellence. &lt;/p&gt;



&lt;p&gt;VentureBeat spoke with co-founder and CEO Boris Bogatin and product lead Adam Kirsh about their team and the company’s technology following the announcement of winners at Transform. “We’re a team of serial entrepreneurs and tech leaders who’ve all shared a deep personal problem,” Bogatin said. “While finance folks and developers all have tools, CTOs, architects, and developers all plan and optimize stacks on whiteboards and ad hoc spreadsheets. And we’re changing that with Catio.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Catio is far more than a digital whiteboard for CTOs—it’s a reimagining of how architecture is understood, managed and evolved. The platform serves as a digital twin for your tech stack, offering continuous architecture visibility to inform more well-informed, data-driven architecture decisions. Designed to address the escalating complexity of modern tech stacks—including cloud infrastructure, container orchestration, monitoring and data pipelines—the platform replaces static diagrams and ad hoc snapshots with an interactive, high-fidelity system model. With Catio, architecture becomes a living, codified system—constantly updated, evaluated and advised by a network of intelligent AI agents.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-static-diagrams-to-living-systems"&gt;From static diagrams to living systems&lt;/h2&gt;



&lt;p&gt;As an AI-driven tech stack copilot for technical leaders and engineering teams, Catio delivers real-time expert insights and actionable recommendations to help evaluate, plan and optimize infrastructure with clarity and confidence. The solution integrates with your existing technology stack—services like AWS, Kubernetes, Prometheus and more. &lt;/p&gt;



&lt;p&gt;Once connected, Stacks—its first core module—creates a comprehensive model of your entire environment. Unlike traditional architecture diagrams, this model is codified, versioned and continuously updated, living in code rather than PowerPoint slides.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXedMX8dLY8O2rMhZdev7vrjlRzytJXS0szuCI3sNvwuWBwWymvHBNSLbBsy7-98kUP3bINmnvMlXXHSsFS6tFpGbfFDGxV5mp7ka2o2VKfXFbiBMkwG8S3Rao9TsJ5eyyreKIERjQ?key=oNkraKFTHztOI64KK7Zw7w" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Source: catio.tech.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This dynamic architecture model allows teams to interact with their stack as a navigable system. Each component is introspectable: What is this RDS instance doing? Is it optimized for cost or performance? Does it still meet business requirements? With Catio, these questions are no longer answered in meetings or siloed email threads; instead, they are built into the platform.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-multi-agent-ai-system-to-close-the-loop-on-architecture"&gt;A multi-agent AI system to close the loop on architecture&lt;/h2&gt;



&lt;p&gt;The solution includes a multi-agent AI system designed to reflect the structure of a typical technical organization. It consists of 31 specialized agents, each modeled after common roles such as chief architect, data architect, messaging architect, product managers and beyond. These agents collaborate to assess the design and performance of the system architecture against the requirements and best practices.&lt;/p&gt;



&lt;p&gt;Together, they simulate the design review processes that typically require weeks of coordination or the involvement of external consultants. But instead of periodic reviews, Catios agents are always working, performing 24/7 analysis to help you evolve your architecture in real time. Also, Catio doesn’t just describe your architecture—it actively critiques it. The solution delivers gap analysis, pinpoints underperforming components and suggests targeted improvements aligned with your business goals.&lt;/p&gt;



&lt;p&gt;Whether it’s optimizing a data pipeline, overhauling your messaging infrastructure, or rethinking storage architecture, the platform provides actionable insights at every layer of the stack.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-future"&gt;The future&lt;/h2&gt;



&lt;p&gt;At Transform, Catio also announced the upcoming launch of Archie, a conversational, multi-agent AI system. Archie will allow users to talk to their architecture and ask for advice—for example, a “how do I improve my security posture?” query will yield clear, actionable answers—such as guidance to pinpoint exactly where a specific security vulnerability exists within your architecture.&lt;/p&gt;



&lt;p&gt;Archie delivers both prescriptive guidance and reactive insights. If you’re aiming to optimize costs, for instance, its AI agents will surface opportunities and assess the business impact of each one. This makes it easier to connect every architectural decision to measurable ROI, helping you design and plan with greater precision—so your technical choices consistently support real business goals.&lt;/p&gt;&lt;p&gt;To learn more about Catio’s team and technology, visit their website at catio.tech. You can also sign up for demo and get a first-hand look at the platform in action.&lt;/p&gt;



&lt;p&gt;Read about the other winners CTGT and Solo.io. The other finalists were Kumo, Superduper.io, Sutro and Qdrant. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Palo Alto-based Catio was awarded “Coolest Technology” at VentureBeat Transform 2025 in San Francisco on Wednesday. Founded in 2023, the company has raised $7 million to date, with a recent $3 million round announced in March. Catio was also a finalist and presented at VB Transform’s Innovation Showcase in 2024.&lt;/p&gt;



&lt;p&gt;Catio’s AI Copilot for Tech Architecture reframes architecture as a living system—one that can be codified, introspected and intelligently evolved. By combining a real-time architectural map with a multi-agent AI organization, the solution helps engineering teams shift from reactive decision-making to continuous, proactive architecture excellence. &lt;/p&gt;



&lt;p&gt;VentureBeat spoke with co-founder and CEO Boris Bogatin and product lead Adam Kirsh about their team and the company’s technology following the announcement of winners at Transform. “We’re a team of serial entrepreneurs and tech leaders who’ve all shared a deep personal problem,” Bogatin said. “While finance folks and developers all have tools, CTOs, architects, and developers all plan and optimize stacks on whiteboards and ad hoc spreadsheets. And we’re changing that with Catio.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Catio is far more than a digital whiteboard for CTOs—it’s a reimagining of how architecture is understood, managed and evolved. The platform serves as a digital twin for your tech stack, offering continuous architecture visibility to inform more well-informed, data-driven architecture decisions. Designed to address the escalating complexity of modern tech stacks—including cloud infrastructure, container orchestration, monitoring and data pipelines—the platform replaces static diagrams and ad hoc snapshots with an interactive, high-fidelity system model. With Catio, architecture becomes a living, codified system—constantly updated, evaluated and advised by a network of intelligent AI agents.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-static-diagrams-to-living-systems"&gt;From static diagrams to living systems&lt;/h2&gt;



&lt;p&gt;As an AI-driven tech stack copilot for technical leaders and engineering teams, Catio delivers real-time expert insights and actionable recommendations to help evaluate, plan and optimize infrastructure with clarity and confidence. The solution integrates with your existing technology stack—services like AWS, Kubernetes, Prometheus and more. &lt;/p&gt;



&lt;p&gt;Once connected, Stacks—its first core module—creates a comprehensive model of your entire environment. Unlike traditional architecture diagrams, this model is codified, versioned and continuously updated, living in code rather than PowerPoint slides.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXedMX8dLY8O2rMhZdev7vrjlRzytJXS0szuCI3sNvwuWBwWymvHBNSLbBsy7-98kUP3bINmnvMlXXHSsFS6tFpGbfFDGxV5mp7ka2o2VKfXFbiBMkwG8S3Rao9TsJ5eyyreKIERjQ?key=oNkraKFTHztOI64KK7Zw7w" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Source: catio.tech.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This dynamic architecture model allows teams to interact with their stack as a navigable system. Each component is introspectable: What is this RDS instance doing? Is it optimized for cost or performance? Does it still meet business requirements? With Catio, these questions are no longer answered in meetings or siloed email threads; instead, they are built into the platform.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-multi-agent-ai-system-to-close-the-loop-on-architecture"&gt;A multi-agent AI system to close the loop on architecture&lt;/h2&gt;



&lt;p&gt;The solution includes a multi-agent AI system designed to reflect the structure of a typical technical organization. It consists of 31 specialized agents, each modeled after common roles such as chief architect, data architect, messaging architect, product managers and beyond. These agents collaborate to assess the design and performance of the system architecture against the requirements and best practices.&lt;/p&gt;



&lt;p&gt;Together, they simulate the design review processes that typically require weeks of coordination or the involvement of external consultants. But instead of periodic reviews, Catios agents are always working, performing 24/7 analysis to help you evolve your architecture in real time. Also, Catio doesn’t just describe your architecture—it actively critiques it. The solution delivers gap analysis, pinpoints underperforming components and suggests targeted improvements aligned with your business goals.&lt;/p&gt;



&lt;p&gt;Whether it’s optimizing a data pipeline, overhauling your messaging infrastructure, or rethinking storage architecture, the platform provides actionable insights at every layer of the stack.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-future"&gt;The future&lt;/h2&gt;



&lt;p&gt;At Transform, Catio also announced the upcoming launch of Archie, a conversational, multi-agent AI system. Archie will allow users to talk to their architecture and ask for advice—for example, a “how do I improve my security posture?” query will yield clear, actionable answers—such as guidance to pinpoint exactly where a specific security vulnerability exists within your architecture.&lt;/p&gt;



&lt;p&gt;Archie delivers both prescriptive guidance and reactive insights. If you’re aiming to optimize costs, for instance, its AI agents will surface opportunities and assess the business impact of each one. This makes it easier to connect every architectural decision to measurable ROI, helping you design and plan with greater precision—so your technical choices consistently support real business goals.&lt;/p&gt;&lt;p&gt;To learn more about Catio’s team and technology, visit their website at catio.tech. You can also sign up for demo and get a first-hand look at the platform in action.&lt;/p&gt;



&lt;p&gt;Read about the other winners CTGT and Solo.io. The other finalists were Kumo, Superduper.io, Sutro and Qdrant. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/catio-wins-coolest-tech-award-at-vb-transform-2025/</guid><pubDate>Sat, 28 Jun 2025 00:34:26 +0000</pubDate></item><item><title>[NEW] CTGT wins Best Presentation Style award at VB Transform 2025 (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/ctgt-wins-best-presentation-style-award-at-vb-transform-2025/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;San Francisco-based CTGT, a startup focused on making AI more trustworthy through feature-level model customization, won the Best Presentation Style award at VB Transform 2025 in San Francisco. Founded by 23-year-old Cyril Gorlla, the company showcased how its technology helps enterprises overcome AI trust barriers by directly modifying model features instead of using traditional fine-tuning or prompt engineering methods.&lt;/p&gt;



&lt;p&gt;During his presentation, Gorlla highlighted the “AI Doom Loop” faced by many enterprises: 54% of businesses cite AI as their highest tech risk according to Deloitte, while McKinsey reports 44% of organizations have experienced negative consequences from AI implementation.&lt;/p&gt;



&lt;p&gt;“A large part of this conference has been about the AI doom loop” Gorlla explained during his presentation. “Unfortunately, a lot of these [AI investments] don’t pan out. J&amp;amp;J just canceled hundreds of AI pilots because they didn’t really deliver ROI due to no fundamental trust in these systems.”&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-breaking-the-ai-compute-wall"&gt;&lt;strong&gt;Breaking the AI compute wall&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;CTGT’s approach represents a significant departure from conventional AI customization techniques. The company was founded on research Gorlla conducted while holding an endowed chair at the University of California San Diego.&lt;/p&gt;



&lt;p&gt;In 2023, Gorlla published a paper at the International Conference on Learning Representations (ICLR) describing a method for evaluating and training AI models that was up to 500 times faster than existing approaches while achieving “three nines” (99.9%) of accuracy.&lt;/p&gt;



&lt;p&gt;Rather than relying on brute-force scaling or traditional deep learning methods, CTGT has developed what it calls an “entirely new AI stack” that fundamentally reimagines how neural networks learn. The company’s innovation focuses on understanding and intervening at the feature level of AI models.&lt;/p&gt;



&lt;p&gt;The company’s approach differs fundamentally from standard interpretability solutions that rely on secondary AI systems for monitoring. Instead, CTGT offers mathematically verifiable interpretability capabilities that eliminate the need for supplemental models, significantly lowering computational requirements in the process.&lt;/p&gt;



&lt;p&gt;The technology works by identifying specific latent variables (neurons or directions in the feature space) that drive behaviors like censorship or hallucinations, then dynamically modifying these variables at inference time without altering the model’s weights. This approach allows companies to customize model behavior on the fly without taking systems offline for retraining.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-real-world-applications"&gt;&lt;strong&gt;Real-world applications&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;During his Transform presentation, Gorlla demonstrated two enterprise applications already deployed at a Fortune 20 financial institution:&lt;/p&gt;



&lt;p&gt;An email compliance workflow that trains models to understand company-specific acceptable content, allowing analysts to check their emails against compliance standards in real-time. The system highlights potentially problematic content and provides specific explanations.&lt;/p&gt;



&lt;p&gt;A brand alignment tool that helps marketers develop copy consistent with brand values. The system can suggest personalized advice on why certain phrases work well for a specific brand and how to improve content that doesn’t align.&lt;/p&gt;



&lt;p&gt;“If a company has 900 use cases, they no longer have to fine-tune 900 models,” Gorlla explained. “We’re model-agnostic, so they can just plug us in.”&lt;/p&gt;



&lt;p&gt;A real-world example of CTGT’s technology in action was its work with DeepSeek models, where it successfully identified and modified the features responsible for censorship behaviors. By isolating and adjusting these specific activation patterns, CTGT was able to achieve a 100% response rate on sensitive queries without degrading the model’s performance on neutral tasks like reasoning, mathematics and coding.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Images:  CTGT presentation at VB Transform 2025&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013410" height="428" src="https://venturebeat.com/wp-content/uploads/2025/06/image_d957d0.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013408" height="528" src="https://venturebeat.com/wp-content/uploads/2025/06/image_4a1a1a.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="h-demonstrated-roi"&gt;&lt;strong&gt;Demonstrated ROI&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;CTGT’s technology appears to be delivering measurable results. During the Q&amp;amp;A session, Gorlla noted that in the first week of deployment with “one of the leading AI-powered insurers, we saved $5 million of liability from them.”&lt;/p&gt;



&lt;p&gt;Another early customer, Ebrada Financial, has used CTGT to improve the factual accuracy of customer service chatbots. “Previously, hallucinations and other errors in chatbot responses drove a high volume of requests for live support agents as customers sought to clarify responses,” said Ley Ebrada, Founder and Tax Strategist. “CTGT has helped improve chatbot accuracy tremendously, eliminating most of those agent requests.”&lt;/p&gt;



&lt;p&gt;In another case study, CTGT worked with an unnamed Fortune 10 company to enhance on-device AI capabilities in computationally constrained environments. The company also helped a leading computer vision firm achieve 10x faster model performance while maintaining comparable accuracy.&lt;/p&gt;



&lt;p&gt;The company claims its technology can reduce hallucinations by 80-90% and enable AI deployments with 99.9% reliability, a critical factor for enterprises in regulated industries like healthcare and finance.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-from-hyderabad-to-silicon-valley"&gt;&lt;strong&gt;From Hyderabad to Silicon Valley&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;Gorlla’s journey is itself remarkable. Born in Hyderabad, India, he mastered coding at age 11 and was disassembling laptops in high school to squeeze out more performance for training AI models. He came to the United States to study at the University of California, San Diego, where he received the Endowed Chair’s Fellowship.&lt;/p&gt;



&lt;p&gt;His research there focused on understanding the fundamental mechanisms of how neural networks learn, which led to his ICLR paper and eventually CTGT. In late 2024, Gorlla and co-founder Trevor Tuttle, an expert in hyperscalable ML systems, were selected for Y Combinator’s Fall 2024 batch.&lt;/p&gt;



&lt;p&gt;The startup has attracted notable investors beyond its institutional backers, including Mark Cuban and other prominent technology leaders drawn to its vision of making AI more efficient and trustworthy.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-funding-and-future"&gt;&lt;strong&gt;Funding and future&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;Founded in mid-2024 by Gorlla and Tuttle, CTGT raised $7.2 million in February 2025 in an oversubscribed seed round led by Gradient, Google’s early-stage AI fund. Other investors include General Catalyst, Y Combinator, Liquid 2, Deepwater, and notable angels such as François Chollet (creator of Keras), Michael Seibel (Y Combinator, co-founder of Twitch), and Paul Graham (Y Combinator).&lt;/p&gt;



&lt;p&gt;“CTGT’s launch is timely as the industry struggles with how to scale AI within the current confines of computing limits,” said Darian Shirazi, Managing Partner at Gradient. “CTGT removes those limits, enabling companies to rapidly scale their AI deployments and run advanced AI models on devices like smartphones. This technology is critical to the success of high-stakes AI deployments at large enterprises.”&lt;/p&gt;



&lt;p&gt;With AI model size outpacing Moore’s Law and advances in AI training chips, CTGT aims to focus on a more foundational understanding of AI that can cope with both inefficiency and increasingly complex model decisions. The company plans to use its seed funding to expand its engineering team and refine its platform.&lt;/p&gt;



&lt;p&gt;Each finalist presented to an audience of 600 industry decision-makers and received feedback from a panel of venture capital judges from Salesforce Ventures, Menlo Ventures, and Amex Ventures.&lt;/p&gt;



&lt;p&gt;Read about the other winners Catio and Solo.io. The other finalists were Kumo, Superduper.io, Sutro and Qdrant. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;San Francisco-based CTGT, a startup focused on making AI more trustworthy through feature-level model customization, won the Best Presentation Style award at VB Transform 2025 in San Francisco. Founded by 23-year-old Cyril Gorlla, the company showcased how its technology helps enterprises overcome AI trust barriers by directly modifying model features instead of using traditional fine-tuning or prompt engineering methods.&lt;/p&gt;



&lt;p&gt;During his presentation, Gorlla highlighted the “AI Doom Loop” faced by many enterprises: 54% of businesses cite AI as their highest tech risk according to Deloitte, while McKinsey reports 44% of organizations have experienced negative consequences from AI implementation.&lt;/p&gt;



&lt;p&gt;“A large part of this conference has been about the AI doom loop” Gorlla explained during his presentation. “Unfortunately, a lot of these [AI investments] don’t pan out. J&amp;amp;J just canceled hundreds of AI pilots because they didn’t really deliver ROI due to no fundamental trust in these systems.”&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-breaking-the-ai-compute-wall"&gt;&lt;strong&gt;Breaking the AI compute wall&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;CTGT’s approach represents a significant departure from conventional AI customization techniques. The company was founded on research Gorlla conducted while holding an endowed chair at the University of California San Diego.&lt;/p&gt;



&lt;p&gt;In 2023, Gorlla published a paper at the International Conference on Learning Representations (ICLR) describing a method for evaluating and training AI models that was up to 500 times faster than existing approaches while achieving “three nines” (99.9%) of accuracy.&lt;/p&gt;



&lt;p&gt;Rather than relying on brute-force scaling or traditional deep learning methods, CTGT has developed what it calls an “entirely new AI stack” that fundamentally reimagines how neural networks learn. The company’s innovation focuses on understanding and intervening at the feature level of AI models.&lt;/p&gt;



&lt;p&gt;The company’s approach differs fundamentally from standard interpretability solutions that rely on secondary AI systems for monitoring. Instead, CTGT offers mathematically verifiable interpretability capabilities that eliminate the need for supplemental models, significantly lowering computational requirements in the process.&lt;/p&gt;



&lt;p&gt;The technology works by identifying specific latent variables (neurons or directions in the feature space) that drive behaviors like censorship or hallucinations, then dynamically modifying these variables at inference time without altering the model’s weights. This approach allows companies to customize model behavior on the fly without taking systems offline for retraining.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-real-world-applications"&gt;&lt;strong&gt;Real-world applications&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;During his Transform presentation, Gorlla demonstrated two enterprise applications already deployed at a Fortune 20 financial institution:&lt;/p&gt;



&lt;p&gt;An email compliance workflow that trains models to understand company-specific acceptable content, allowing analysts to check their emails against compliance standards in real-time. The system highlights potentially problematic content and provides specific explanations.&lt;/p&gt;



&lt;p&gt;A brand alignment tool that helps marketers develop copy consistent with brand values. The system can suggest personalized advice on why certain phrases work well for a specific brand and how to improve content that doesn’t align.&lt;/p&gt;



&lt;p&gt;“If a company has 900 use cases, they no longer have to fine-tune 900 models,” Gorlla explained. “We’re model-agnostic, so they can just plug us in.”&lt;/p&gt;



&lt;p&gt;A real-world example of CTGT’s technology in action was its work with DeepSeek models, where it successfully identified and modified the features responsible for censorship behaviors. By isolating and adjusting these specific activation patterns, CTGT was able to achieve a 100% response rate on sensitive queries without degrading the model’s performance on neutral tasks like reasoning, mathematics and coding.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Images:  CTGT presentation at VB Transform 2025&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013410" height="428" src="https://venturebeat.com/wp-content/uploads/2025/06/image_d957d0.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013408" height="528" src="https://venturebeat.com/wp-content/uploads/2025/06/image_4a1a1a.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="h-demonstrated-roi"&gt;&lt;strong&gt;Demonstrated ROI&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;CTGT’s technology appears to be delivering measurable results. During the Q&amp;amp;A session, Gorlla noted that in the first week of deployment with “one of the leading AI-powered insurers, we saved $5 million of liability from them.”&lt;/p&gt;



&lt;p&gt;Another early customer, Ebrada Financial, has used CTGT to improve the factual accuracy of customer service chatbots. “Previously, hallucinations and other errors in chatbot responses drove a high volume of requests for live support agents as customers sought to clarify responses,” said Ley Ebrada, Founder and Tax Strategist. “CTGT has helped improve chatbot accuracy tremendously, eliminating most of those agent requests.”&lt;/p&gt;



&lt;p&gt;In another case study, CTGT worked with an unnamed Fortune 10 company to enhance on-device AI capabilities in computationally constrained environments. The company also helped a leading computer vision firm achieve 10x faster model performance while maintaining comparable accuracy.&lt;/p&gt;



&lt;p&gt;The company claims its technology can reduce hallucinations by 80-90% and enable AI deployments with 99.9% reliability, a critical factor for enterprises in regulated industries like healthcare and finance.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-from-hyderabad-to-silicon-valley"&gt;&lt;strong&gt;From Hyderabad to Silicon Valley&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;Gorlla’s journey is itself remarkable. Born in Hyderabad, India, he mastered coding at age 11 and was disassembling laptops in high school to squeeze out more performance for training AI models. He came to the United States to study at the University of California, San Diego, where he received the Endowed Chair’s Fellowship.&lt;/p&gt;



&lt;p&gt;His research there focused on understanding the fundamental mechanisms of how neural networks learn, which led to his ICLR paper and eventually CTGT. In late 2024, Gorlla and co-founder Trevor Tuttle, an expert in hyperscalable ML systems, were selected for Y Combinator’s Fall 2024 batch.&lt;/p&gt;



&lt;p&gt;The startup has attracted notable investors beyond its institutional backers, including Mark Cuban and other prominent technology leaders drawn to its vision of making AI more efficient and trustworthy.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-funding-and-future"&gt;&lt;strong&gt;Funding and future&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;Founded in mid-2024 by Gorlla and Tuttle, CTGT raised $7.2 million in February 2025 in an oversubscribed seed round led by Gradient, Google’s early-stage AI fund. Other investors include General Catalyst, Y Combinator, Liquid 2, Deepwater, and notable angels such as François Chollet (creator of Keras), Michael Seibel (Y Combinator, co-founder of Twitch), and Paul Graham (Y Combinator).&lt;/p&gt;



&lt;p&gt;“CTGT’s launch is timely as the industry struggles with how to scale AI within the current confines of computing limits,” said Darian Shirazi, Managing Partner at Gradient. “CTGT removes those limits, enabling companies to rapidly scale their AI deployments and run advanced AI models on devices like smartphones. This technology is critical to the success of high-stakes AI deployments at large enterprises.”&lt;/p&gt;



&lt;p&gt;With AI model size outpacing Moore’s Law and advances in AI training chips, CTGT aims to focus on a more foundational understanding of AI that can cope with both inefficiency and increasingly complex model decisions. The company plans to use its seed funding to expand its engineering team and refine its platform.&lt;/p&gt;



&lt;p&gt;Each finalist presented to an audience of 600 industry decision-makers and received feedback from a panel of venture capital judges from Salesforce Ventures, Menlo Ventures, and Amex Ventures.&lt;/p&gt;



&lt;p&gt;Read about the other winners Catio and Solo.io. The other finalists were Kumo, Superduper.io, Sutro and Qdrant. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ctgt-wins-best-presentation-style-award-at-vb-transform-2025/</guid><pubDate>Sat, 28 Jun 2025 00:48:46 +0000</pubDate></item></channel></rss>