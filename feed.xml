<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 06 Sep 2025 06:27:26 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Warner Bros. sues Midjourney to stop AI knockoffs of Batman, Scooby-Doo (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/warner-bros-sues-midjourney-to-stop-ai-knockoffs-of-batman-scooby-doo/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Warner Bros. case builds on arguments raised in a Disney/Universal lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="372" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Scooby-Doo-and-Batman-via-WB-640x372.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Scooby-Doo-and-Batman-via-WB-1152x648-1757094194.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      DVD art for the animated movie &lt;em&gt;Scooby-Doo &amp;amp; Batman: The Brave and the Bold&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Warner Bros. Discovery

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Warner Bros. hit Midjourney with a lawsuit Thursday, crafting a complaint that strives to shoot down defenses that the AI company has already raised in a similar lawsuit filed by Disney and Universal Studios earlier this year.&lt;/p&gt;
&lt;p&gt;The big film studios have alleged that Midjourney profits off image generation models trained to produce outputs of popular characters. For Disney and Universal, intellectual property rights to pop icons like Darth Vader and the Simpsons were allegedly infringed. And now, the WB complaint defends rights over comic characters like Superman, Wonder Woman, and Batman, as well as characters considered "pillars of pop culture with a lasting impact on generations," like Scooby-Doo and Bugs Bunny, and modern cartoon characters like Rick and Morty.&lt;/p&gt;
&lt;p&gt;"Midjourney brazenly dispenses Warner Bros. Discovery’s intellectual property as if it were its own," the WB complaint said, accusing Midjourney of allowing subscribers to "pick iconic" copyrighted characters and generate them in "every imaginable scene."&lt;/p&gt;
&lt;p&gt;Planning to seize Midjourney's profits from allegedly using beloved characters to promote its service, Warner Bros. described Midjourney as "defiant and undeterred" by the Disney/Universal lawsuit. Despite that litigation, WB claimed that Midjourney has recently removed copyright protections in its supposedly shameful ongoing bid for profits. Nothing but a permanent injunction will end Midjourney's outputs of allegedly "countless infringing images," WB argued, branding Midjourney's alleged infringements as "vast, intentional, and unrelenting."&lt;/p&gt;
&lt;p&gt;Examples of closely matching outputs include prompts for "screencaps" showing specific movie frames, a search term that at least one artist, Reid Southen, had optimistically predicted Midjourney would block last year, but it apparently did not.&lt;/p&gt;
&lt;p&gt;Here are some examples included in WB's complaint:&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="942" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Superman-via-WB-complaint.jpg" width="1350" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney's output for the prompt, "Superman, classic cartoon character, DC comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="812" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Dark-Knight-via-WB-complaint-1024x812.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, screencap from The Dark Knight.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Batman-via-WB-complaint-1024x747.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, comic book character from DC Comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, screencap from The Dark Knight.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, comic book character from DC Comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
          &lt;div class="ars-gallery-thumbnails grid grid-cols-4 gap-3 sm:grid-cols-6"&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="532" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Scooby-Doo-via-WB-complaint-640x532.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="366" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Rick-and-Morty-via-WB-complaint-640x366.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="308" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Rick-and-Morty-via-WB-complaint-640x308.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="308" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Batman-via-WB-complaint-640x308.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="298" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Scooby-Doo-via-WB-complaint-640x298.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
              &lt;/div&gt;
      &lt;/div&gt;

&lt;p&gt;Midjourney could face devastating financial consequences in a loss. At trial, WB is hoping discovery will show the true extent of Midjourney's alleged infringement, asking the court for maximum statutory damages, at $150,000 per infringing output. Just 2,000 infringing outputs unearthed could cost Midjourney more than its total revenue for 2024, which was approximately $300 million, the WB complaint said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Warner Bros. hopes to hobble Midjourney's best defense&lt;/h2&gt;
&lt;p&gt;For Midjourney, the WB complaint could potentially hit harder than the Disney/Universal lawsuit. WB's complaint shows how closely studios are monitoring AI copyright litigation, likely choosing ideal moments to strike when studios feel they can better defend their property. So, while much of WB's complaint echoes Disney and Universal's arguments—which Midjourney has already begun defending against—IP attorney Randy McCarthy suggested in statements provided to Ars that WB also looked for seemingly smart ways to potentially overcome some of Midjourney's best defenses when filing its complaint.&lt;/p&gt;
&lt;p&gt;WB likely took note when Midjourney filed its response to the Disney/Universal lawsuit last month, arguing that its system is "trained on billions of publicly available images" and generates images not by retrieving a copy of an image in its database but based on "complex statistical relationships between visual features and words in the text-image pairs are encoded within the model."&lt;/p&gt;
&lt;p&gt;This defense could allow Midjourney to avoid claims that it copied WB images and distributes copies through its models. But hoping to dodge this defense, WB didn't argue that Midjourney retains copies of its images. Rather, the entertainment giant raised a more nuanced argument that:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Midjourney used software, servers, and other technology to store and fix data associated with Warner Bros. Discovery’s Copyrighted Works in such a manner that those works are thereby embodied in the model, from which Midjourney is then able to generate, reproduce, publicly display, and distribute unlimited "copies" and "derivative works" of Warner Bros. Discovery’s works as defined by the Copyright Act."&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;McCarthy noted that WB's argument pushes the court to at least consider that even though "Midjourney does not store copies of the works in its model," its system "nonetheless accesses the data relating to the works that are stored by Midjourney’s system."&lt;/p&gt;
&lt;p&gt;"This seems to be a very clever way to counter MJ's 'statistical pattern analysis' arguments," McCarthy said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If it's a winning argument, that could give WB a path to wipe Midjourney's models. WB argued that each time Midjourney provides a "substantially new" version of its image generator, it "repeats this process." And that ongoing activity—due to Midjourney’s initial allegedly "massive copying" of WB works—allows Midjourney to "further reproduce, publicly display, publicly perform, and distribute image and video outputs that are identical or virtually identical to Warner Bros. Discovery’s Copyrighted Works in response to simple prompts from subscribers."&lt;/p&gt;
&lt;p&gt;Perhaps further strengthening the WB's argument, the lawsuit noted that Midjourney promotes allegedly infringing outputs on its 24/7 YouTube channel and appears to have plans to compete with traditional TV and streaming services. Asking the court to block Midjourney's outputs instead, WB claims it's already been "substantially and irreparably harmed" and risks further damages if the AI image generator is left unchecked.&lt;/p&gt;
&lt;p&gt;As alleged proof that the AI company knows its tool is being used to infringe WB property, WB pointed to Midjourney's own Discord server and subreddit, where users post outputs depicting WB characters and share tips to help others do the same. They also called out Midjourney's "Explore" page, which allows users to drop a WB-referencing output into the prompt field to generate similar images.&lt;/p&gt;
&lt;p&gt;"It is hard to imagine copyright infringement that is any more willful than what Midjourney is doing here," the WB complaint said.&lt;/p&gt;
&lt;p&gt;WB and Midjourney did not immediately respond to Ars' request to comment.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Midjourney slammed for promising “fewer blocked jobs”&lt;/h2&gt;
&lt;p&gt;McCarthy noted that WB's legal strategy differs in other ways from the arguments Midjourney's already weighed in the Disney/Universal lawsuit.&lt;/p&gt;
&lt;p&gt;The WB complaint also anticipates Midjourney's likely defense that users are generating infringing outputs, not Midjourney, which could invalidate any charges of direct copyright infringement.&lt;/p&gt;
&lt;p&gt;In the Disney/Universal lawsuit, Midjourney argued that courts have recently found that AI tools referencing copyrighted works is "a quintessentially transformative fair use," accusing studios of trying to censor "an instrument for user expression." They claim that Midjourney cannot know about infringing outputs unless studios use the company's DMCA process, while noting that subscribers have "any number of legitimate, noninfringing grounds to create images incorporating characters from popular culture," including "non-commercial fan art, experimentation and ideation, and social commentary and criticism."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To avoid losing on that front, the WB complaint doesn't depend on a ruling that Midjourney directly infringed copyrights. Instead, the complaint "more fully" emphasizes how Midjourney may be "secondarily liable for infringement via contributory, inducement and/or vicarious liability by inducing its users to directly infringe," McCarthy suggested.&lt;/p&gt;
&lt;p&gt;Additionally, WB's complaint "seems to be emphasizing" that Midjourney "allegedly has the technical means to prevent its system from accepting prompts that directly reference copyrighted characters," and "that would prevent infringing outputs from being displayed," McCarthy said.&lt;/p&gt;
&lt;p&gt;The complaint noted that Midjourney is in full control of what outputs can be generated. Noting that Midjourney "temporarily refused to 'animate'" outputs of WB characters after launching video generations, the lawsuit appears to have been filed in response to Midjourney "deliberately" removing those protections and then announcing that subscribers would experience "fewer blocked jobs."&lt;/p&gt;
&lt;p&gt;Together, these arguments "appear to be intended to lead to the inference that Midjourney is willfully enticing its users to infringe," McCarthy said.&lt;/p&gt;
&lt;p&gt;WB's complaint details simple user prompts that generate allegedly infringing outputs without any need to manipulate the system. The ease of generating popular characters seems to make Midjourney a destination for users frustrated by other AI image generators that make it harder to generate infringing outputs, WB alleged.&lt;/p&gt;
&lt;p&gt;On top of that, Midjourney also infringes copyrights by generating WB characters, "even in response to generic prompts like 'classic comic book superhero battle.'" And while Midjourney has seemingly taken steps to block WB characters from appearing on its "Explore" page, where users can find inspiration for prompts, these guardrails aren't perfect, but rather "spotty and suspicious," WB alleged. Supposedly, searches for correctly spelled character names like "Batman" are blocked, but any user who accidentally or intentionally mispells a character's name like "Batma" can learn an easy way to work around that block.&lt;/p&gt;
&lt;p&gt;Additionally, WB alleged, "the outputs often contain extensive nuance and detail, background elements, costumes, and accessories beyond what was specified in the prompt." And every time that Midjourney outputs an allegedly infringing image, it "also trains on the outputs it has generated," the lawsuit noted, creating a never-ending cycle of continually enhanced AI fakes of pop icons.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Midjourney could slow down the cycle and "minimize" these allegedly infringing outputs, if it cannot automatically block them all, WB suggested. But instead, "Midjourney has made a calculated and profit-driven decision to offer zero protection for copyright owners even though Midjourney knows about the breathtaking scope of its piracy and copyright infringement," WB alleged.&lt;/p&gt;
&lt;p&gt;Fearing a supposed scheme to replace WB in the market by stealing its best-known characters, WB accused Midjourney of willfully allowing WB characters to be generated in order to "generate more money for Midjourney" to potentially compete in streaming markets.&lt;/p&gt;
&lt;h2&gt;Midjourney will remove protections “on a whim”&lt;/h2&gt;
&lt;p&gt;As Midjourney's efforts to expand its features escalate, WB claimed that trust is lost. Even if Midjourney takes steps to address rightsholders' concerns, WB argued, studios must remain watchful of every upgrade, since apparently, "Midjourney can and will remove copyright protection measures on a whim."&lt;/p&gt;
&lt;p&gt;The complaint noted that Midjourney just this week announced "plans to continue deploying new versions" of its image generator, promising to make it easier to search for and save popular artists' styles—updating a feature that many artists loathe.&lt;/p&gt;
&lt;p&gt;Without an injunction, Midjourney's alleged infringement could interfere with WB's licensing opportunities for its content, while "illegally and unfairly" diverting customers who buy WB products like posters, wall art, prints, and coloring books, the complaint said.&lt;/p&gt;
&lt;p&gt;Perhaps Midjourney's strongest defense could be efforts to prove that WB benefits from its image generator. In the Disney/Universal lawsuit, Midjourney pointed out that studios "benefit from generative AI models," claiming that "many dozens of Midjourney subscribers are associated with" Disney and Universal corporate email addresses. If WB corporate email addresses are found among subscribers, Midjourney could claim that WB is trying to "have it both ways" by "seeking to profit" from AI tools while preventing Midjourney and its subscribers from doing the same.&lt;/p&gt;
&lt;p&gt;McCarthy suggested it's too soon to say how the WB battle will play out, but Midjourney's response will reveal how it intends to shift tactics to avoid courts potentially picking apart its defense of its training data, while keeping any blame for copyright-infringing outputs squarely on users.&lt;/p&gt;
&lt;p&gt;"As with the Disney/Universal lawsuit, we need to wait to see how Midjourney answers these latest allegations," McCarthy said. "It is definitely an interesting development that will have widespread implications for many sectors of our society."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Warner Bros. case builds on arguments raised in a Disney/Universal lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="372" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Scooby-Doo-and-Batman-via-WB-640x372.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Scooby-Doo-and-Batman-via-WB-1152x648-1757094194.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      DVD art for the animated movie &lt;em&gt;Scooby-Doo &amp;amp; Batman: The Brave and the Bold&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Warner Bros. Discovery

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Warner Bros. hit Midjourney with a lawsuit Thursday, crafting a complaint that strives to shoot down defenses that the AI company has already raised in a similar lawsuit filed by Disney and Universal Studios earlier this year.&lt;/p&gt;
&lt;p&gt;The big film studios have alleged that Midjourney profits off image generation models trained to produce outputs of popular characters. For Disney and Universal, intellectual property rights to pop icons like Darth Vader and the Simpsons were allegedly infringed. And now, the WB complaint defends rights over comic characters like Superman, Wonder Woman, and Batman, as well as characters considered "pillars of pop culture with a lasting impact on generations," like Scooby-Doo and Bugs Bunny, and modern cartoon characters like Rick and Morty.&lt;/p&gt;
&lt;p&gt;"Midjourney brazenly dispenses Warner Bros. Discovery’s intellectual property as if it were its own," the WB complaint said, accusing Midjourney of allowing subscribers to "pick iconic" copyrighted characters and generate them in "every imaginable scene."&lt;/p&gt;
&lt;p&gt;Planning to seize Midjourney's profits from allegedly using beloved characters to promote its service, Warner Bros. described Midjourney as "defiant and undeterred" by the Disney/Universal lawsuit. Despite that litigation, WB claimed that Midjourney has recently removed copyright protections in its supposedly shameful ongoing bid for profits. Nothing but a permanent injunction will end Midjourney's outputs of allegedly "countless infringing images," WB argued, branding Midjourney's alleged infringements as "vast, intentional, and unrelenting."&lt;/p&gt;
&lt;p&gt;Examples of closely matching outputs include prompts for "screencaps" showing specific movie frames, a search term that at least one artist, Reid Southen, had optimistically predicted Midjourney would block last year, but it apparently did not.&lt;/p&gt;
&lt;p&gt;Here are some examples included in WB's complaint:&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="942" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Superman-via-WB-complaint.jpg" width="1350" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney's output for the prompt, "Superman, classic cartoon character, DC comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="812" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Dark-Knight-via-WB-complaint-1024x812.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, screencap from The Dark Knight.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Batman-via-WB-complaint-1024x747.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, comic book character from DC Comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, screencap from The Dark Knight.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Midjourney prompt: “Batman, comic book character from DC Comics.”&lt;/span&gt;
                &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
          &lt;div class="ars-gallery-thumbnails grid grid-cols-4 gap-3 sm:grid-cols-6"&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="532" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Scooby-Doo-via-WB-complaint-640x532.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="366" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/Midjourney-output-Rick-and-Morty-via-WB-complaint-640x366.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="308" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Rick-and-Morty-via-WB-complaint-640x308.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="308" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Batman-via-WB-complaint-640x308.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="298" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/User-generated-Scooby-Doo-via-WB-complaint-640x298.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
              &lt;/div&gt;
      &lt;/div&gt;

&lt;p&gt;Midjourney could face devastating financial consequences in a loss. At trial, WB is hoping discovery will show the true extent of Midjourney's alleged infringement, asking the court for maximum statutory damages, at $150,000 per infringing output. Just 2,000 infringing outputs unearthed could cost Midjourney more than its total revenue for 2024, which was approximately $300 million, the WB complaint said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Warner Bros. hopes to hobble Midjourney's best defense&lt;/h2&gt;
&lt;p&gt;For Midjourney, the WB complaint could potentially hit harder than the Disney/Universal lawsuit. WB's complaint shows how closely studios are monitoring AI copyright litigation, likely choosing ideal moments to strike when studios feel they can better defend their property. So, while much of WB's complaint echoes Disney and Universal's arguments—which Midjourney has already begun defending against—IP attorney Randy McCarthy suggested in statements provided to Ars that WB also looked for seemingly smart ways to potentially overcome some of Midjourney's best defenses when filing its complaint.&lt;/p&gt;
&lt;p&gt;WB likely took note when Midjourney filed its response to the Disney/Universal lawsuit last month, arguing that its system is "trained on billions of publicly available images" and generates images not by retrieving a copy of an image in its database but based on "complex statistical relationships between visual features and words in the text-image pairs are encoded within the model."&lt;/p&gt;
&lt;p&gt;This defense could allow Midjourney to avoid claims that it copied WB images and distributes copies through its models. But hoping to dodge this defense, WB didn't argue that Midjourney retains copies of its images. Rather, the entertainment giant raised a more nuanced argument that:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Midjourney used software, servers, and other technology to store and fix data associated with Warner Bros. Discovery’s Copyrighted Works in such a manner that those works are thereby embodied in the model, from which Midjourney is then able to generate, reproduce, publicly display, and distribute unlimited "copies" and "derivative works" of Warner Bros. Discovery’s works as defined by the Copyright Act."&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;McCarthy noted that WB's argument pushes the court to at least consider that even though "Midjourney does not store copies of the works in its model," its system "nonetheless accesses the data relating to the works that are stored by Midjourney’s system."&lt;/p&gt;
&lt;p&gt;"This seems to be a very clever way to counter MJ's 'statistical pattern analysis' arguments," McCarthy said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If it's a winning argument, that could give WB a path to wipe Midjourney's models. WB argued that each time Midjourney provides a "substantially new" version of its image generator, it "repeats this process." And that ongoing activity—due to Midjourney’s initial allegedly "massive copying" of WB works—allows Midjourney to "further reproduce, publicly display, publicly perform, and distribute image and video outputs that are identical or virtually identical to Warner Bros. Discovery’s Copyrighted Works in response to simple prompts from subscribers."&lt;/p&gt;
&lt;p&gt;Perhaps further strengthening the WB's argument, the lawsuit noted that Midjourney promotes allegedly infringing outputs on its 24/7 YouTube channel and appears to have plans to compete with traditional TV and streaming services. Asking the court to block Midjourney's outputs instead, WB claims it's already been "substantially and irreparably harmed" and risks further damages if the AI image generator is left unchecked.&lt;/p&gt;
&lt;p&gt;As alleged proof that the AI company knows its tool is being used to infringe WB property, WB pointed to Midjourney's own Discord server and subreddit, where users post outputs depicting WB characters and share tips to help others do the same. They also called out Midjourney's "Explore" page, which allows users to drop a WB-referencing output into the prompt field to generate similar images.&lt;/p&gt;
&lt;p&gt;"It is hard to imagine copyright infringement that is any more willful than what Midjourney is doing here," the WB complaint said.&lt;/p&gt;
&lt;p&gt;WB and Midjourney did not immediately respond to Ars' request to comment.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Midjourney slammed for promising “fewer blocked jobs”&lt;/h2&gt;
&lt;p&gt;McCarthy noted that WB's legal strategy differs in other ways from the arguments Midjourney's already weighed in the Disney/Universal lawsuit.&lt;/p&gt;
&lt;p&gt;The WB complaint also anticipates Midjourney's likely defense that users are generating infringing outputs, not Midjourney, which could invalidate any charges of direct copyright infringement.&lt;/p&gt;
&lt;p&gt;In the Disney/Universal lawsuit, Midjourney argued that courts have recently found that AI tools referencing copyrighted works is "a quintessentially transformative fair use," accusing studios of trying to censor "an instrument for user expression." They claim that Midjourney cannot know about infringing outputs unless studios use the company's DMCA process, while noting that subscribers have "any number of legitimate, noninfringing grounds to create images incorporating characters from popular culture," including "non-commercial fan art, experimentation and ideation, and social commentary and criticism."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To avoid losing on that front, the WB complaint doesn't depend on a ruling that Midjourney directly infringed copyrights. Instead, the complaint "more fully" emphasizes how Midjourney may be "secondarily liable for infringement via contributory, inducement and/or vicarious liability by inducing its users to directly infringe," McCarthy suggested.&lt;/p&gt;
&lt;p&gt;Additionally, WB's complaint "seems to be emphasizing" that Midjourney "allegedly has the technical means to prevent its system from accepting prompts that directly reference copyrighted characters," and "that would prevent infringing outputs from being displayed," McCarthy said.&lt;/p&gt;
&lt;p&gt;The complaint noted that Midjourney is in full control of what outputs can be generated. Noting that Midjourney "temporarily refused to 'animate'" outputs of WB characters after launching video generations, the lawsuit appears to have been filed in response to Midjourney "deliberately" removing those protections and then announcing that subscribers would experience "fewer blocked jobs."&lt;/p&gt;
&lt;p&gt;Together, these arguments "appear to be intended to lead to the inference that Midjourney is willfully enticing its users to infringe," McCarthy said.&lt;/p&gt;
&lt;p&gt;WB's complaint details simple user prompts that generate allegedly infringing outputs without any need to manipulate the system. The ease of generating popular characters seems to make Midjourney a destination for users frustrated by other AI image generators that make it harder to generate infringing outputs, WB alleged.&lt;/p&gt;
&lt;p&gt;On top of that, Midjourney also infringes copyrights by generating WB characters, "even in response to generic prompts like 'classic comic book superhero battle.'" And while Midjourney has seemingly taken steps to block WB characters from appearing on its "Explore" page, where users can find inspiration for prompts, these guardrails aren't perfect, but rather "spotty and suspicious," WB alleged. Supposedly, searches for correctly spelled character names like "Batman" are blocked, but any user who accidentally or intentionally mispells a character's name like "Batma" can learn an easy way to work around that block.&lt;/p&gt;
&lt;p&gt;Additionally, WB alleged, "the outputs often contain extensive nuance and detail, background elements, costumes, and accessories beyond what was specified in the prompt." And every time that Midjourney outputs an allegedly infringing image, it "also trains on the outputs it has generated," the lawsuit noted, creating a never-ending cycle of continually enhanced AI fakes of pop icons.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Midjourney could slow down the cycle and "minimize" these allegedly infringing outputs, if it cannot automatically block them all, WB suggested. But instead, "Midjourney has made a calculated and profit-driven decision to offer zero protection for copyright owners even though Midjourney knows about the breathtaking scope of its piracy and copyright infringement," WB alleged.&lt;/p&gt;
&lt;p&gt;Fearing a supposed scheme to replace WB in the market by stealing its best-known characters, WB accused Midjourney of willfully allowing WB characters to be generated in order to "generate more money for Midjourney" to potentially compete in streaming markets.&lt;/p&gt;
&lt;h2&gt;Midjourney will remove protections “on a whim”&lt;/h2&gt;
&lt;p&gt;As Midjourney's efforts to expand its features escalate, WB claimed that trust is lost. Even if Midjourney takes steps to address rightsholders' concerns, WB argued, studios must remain watchful of every upgrade, since apparently, "Midjourney can and will remove copyright protection measures on a whim."&lt;/p&gt;
&lt;p&gt;The complaint noted that Midjourney just this week announced "plans to continue deploying new versions" of its image generator, promising to make it easier to search for and save popular artists' styles—updating a feature that many artists loathe.&lt;/p&gt;
&lt;p&gt;Without an injunction, Midjourney's alleged infringement could interfere with WB's licensing opportunities for its content, while "illegally and unfairly" diverting customers who buy WB products like posters, wall art, prints, and coloring books, the complaint said.&lt;/p&gt;
&lt;p&gt;Perhaps Midjourney's strongest defense could be efforts to prove that WB benefits from its image generator. In the Disney/Universal lawsuit, Midjourney pointed out that studios "benefit from generative AI models," claiming that "many dozens of Midjourney subscribers are associated with" Disney and Universal corporate email addresses. If WB corporate email addresses are found among subscribers, Midjourney could claim that WB is trying to "have it both ways" by "seeking to profit" from AI tools while preventing Midjourney and its subscribers from doing the same.&lt;/p&gt;
&lt;p&gt;McCarthy suggested it's too soon to say how the WB battle will play out, but Midjourney's response will reveal how it intends to shift tactics to avoid courts potentially picking apart its defense of its training data, while keeping any blame for copyright-infringing outputs squarely on users.&lt;/p&gt;
&lt;p&gt;"As with the Disney/Universal lawsuit, we need to wait to see how Midjourney answers these latest allegations," McCarthy said. "It is definitely an interesting development that will have widespread implications for many sectors of our society."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/warner-bros-sues-midjourney-to-stop-ai-knockoffs-of-batman-scooby-doo/</guid><pubDate>Fri, 05 Sep 2025 18:47:32 +0000</pubDate></item><item><title>Google Gemini dubbed ‘high risk’ for kids and teens in new safety assessment (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/05/google-gemini-dubbed-high-risk-for-kids-and-teens-in-new-safety-assessment/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2197065135.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Common Sense Media, a kids-safety-focused nonprofit offering ratings and reviews of media and technology, released its risk assessment of Google’s Gemini AI products on Friday. While the organization found that Google’s AI clearly told kids it was a computer, not a friend — something that’s associated with helping drive delusional thinking and psychosis in emotionally vulnerable individuals — it did suggest that there was room for improvement across several other fronts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Common Sense said that Gemini’s “Under 13” and “Teen Experience” tiers both appeared to be the adult versions of Gemini under the hood, with only some additional safety features added on top. The organization believes that for AI products to truly be safer for kids, they should be built with child safety in mind from the ground up.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For example, its analysis found that Gemini could still share “inappropriate and unsafe” material with children, which they may not be ready for, including information related to sex, drugs, alcohol, and other unsafe mental health advice. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latter could be of particular concern to parents, as AI has reportedly played a role in some teen suicides in recent months. OpenAI is facing its first wrongful death lawsuit after a 16-year-old boy died by suicide after allegedly consulting with ChatGPT for months about his plans, having successfully bypassed the chatbot’s safety guardrails. Previously, the AI companion maker Character.AI was also sued over a teen user’s suicide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the analysis comes as news leaks indicate that Apple is considering Gemini as the LLM (large language model) that will help to power its forthcoming AI-enabled Siri, due out next year. This could expose more teens to risks, unless Apple mitigates the safety concerns somehow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Common Sense also said that Gemini’s products for kids and teens ignored how younger users needed different guidance and information than older ones. As a result, both were labeled as “High Risk” in the overall rating, despite the filters added for safety.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Gemini gets some basics right, but it stumbles on the details,” Common Sense Media Senior Director of AI Programs Robbie Torney said in a statement about the new assessment viewed by TechCrunch. “An AI platform for kids should meet them where they are, not take a one-size-fits-all approach to kids at different stages of development. For AI to be safe and effective for kids, it must be designed with their needs and development in mind, not just a modified version of a product built for adults,” Torney added.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google pushed back against the assessment, while noting that its safety features were improving.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company told TechCrunch it has specific policies and safeguards in place for users under 18 to help prevent harmful outputs and that it red-teams and consults with outside experts to improve its protections. However, it also admitted that some of Gemini’s responses weren’t working as intended, so it added additional safeguards to address those concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company pointed out (as Common Sense had also noted) that it does have safeguards to prevent its models from engaging in conversations that could give the semblance of real relationships. Plus, Google suggested that Common Sense’s report seemed to have referenced features that weren’t available to users under 18, but it didn’t have access to the questions the organization used in its tests to be sure.   &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Common Sense Media has previously performed other assessments of AI services, including those from OpenAI, Perplexity, Claude, Meta AI, and more. It found that Meta AI and Character.AI were “unacceptable” — meaning the risk was severe, not just high. Perplexity was deemed high risk, ChatGPT was labeled “moderate,” and Claude (targeted at users 18 and up) was found to be a minimal risk.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2197065135.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Common Sense Media, a kids-safety-focused nonprofit offering ratings and reviews of media and technology, released its risk assessment of Google’s Gemini AI products on Friday. While the organization found that Google’s AI clearly told kids it was a computer, not a friend — something that’s associated with helping drive delusional thinking and psychosis in emotionally vulnerable individuals — it did suggest that there was room for improvement across several other fronts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Common Sense said that Gemini’s “Under 13” and “Teen Experience” tiers both appeared to be the adult versions of Gemini under the hood, with only some additional safety features added on top. The organization believes that for AI products to truly be safer for kids, they should be built with child safety in mind from the ground up.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For example, its analysis found that Gemini could still share “inappropriate and unsafe” material with children, which they may not be ready for, including information related to sex, drugs, alcohol, and other unsafe mental health advice. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latter could be of particular concern to parents, as AI has reportedly played a role in some teen suicides in recent months. OpenAI is facing its first wrongful death lawsuit after a 16-year-old boy died by suicide after allegedly consulting with ChatGPT for months about his plans, having successfully bypassed the chatbot’s safety guardrails. Previously, the AI companion maker Character.AI was also sued over a teen user’s suicide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the analysis comes as news leaks indicate that Apple is considering Gemini as the LLM (large language model) that will help to power its forthcoming AI-enabled Siri, due out next year. This could expose more teens to risks, unless Apple mitigates the safety concerns somehow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Common Sense also said that Gemini’s products for kids and teens ignored how younger users needed different guidance and information than older ones. As a result, both were labeled as “High Risk” in the overall rating, despite the filters added for safety.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Gemini gets some basics right, but it stumbles on the details,” Common Sense Media Senior Director of AI Programs Robbie Torney said in a statement about the new assessment viewed by TechCrunch. “An AI platform for kids should meet them where they are, not take a one-size-fits-all approach to kids at different stages of development. For AI to be safe and effective for kids, it must be designed with their needs and development in mind, not just a modified version of a product built for adults,” Torney added.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google pushed back against the assessment, while noting that its safety features were improving.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company told TechCrunch it has specific policies and safeguards in place for users under 18 to help prevent harmful outputs and that it red-teams and consults with outside experts to improve its protections. However, it also admitted that some of Gemini’s responses weren’t working as intended, so it added additional safeguards to address those concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company pointed out (as Common Sense had also noted) that it does have safeguards to prevent its models from engaging in conversations that could give the semblance of real relationships. Plus, Google suggested that Common Sense’s report seemed to have referenced features that weren’t available to users under 18, but it didn’t have access to the questions the organization used in its tests to be sure.   &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Common Sense Media has previously performed other assessments of AI services, including those from OpenAI, Perplexity, Claude, Meta AI, and more. It found that Meta AI and Character.AI were “unacceptable” — meaning the risk was severe, not just high. Perplexity was deemed high risk, ChatGPT was labeled “moderate,” and Claude (targeted at users 18 and up) was found to be a minimal risk.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/05/google-gemini-dubbed-high-risk-for-kids-and-teens-in-new-safety-assessment/</guid><pubDate>Fri, 05 Sep 2025 19:09:12 +0000</pubDate></item><item><title>Attorneys general warn OpenAI ‘harm to children will not be tolerated’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/05/attorneys-general-warn-openai-harm-to-children-will-not-be-tolerated/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/teens-teenagers-GettyImages-2158370531.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Attorney General Rob Bonta and Delaware Attorney General Kathy Jennings met with and sent an open letter to OpenAI to express their concerns over the safety of ChatGPT, particularly for children and teens.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The warning comes a week after Bonta and 44 other attorneys general sent a letter to 12 of the top AI companies, following reports of sexually inappropriate interactions between AI chatbots and children.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Since the issuance of that letter, we learned of the heartbreaking death by suicide of one young Californian after he had prolonged interactions with an OpenAI chatbot, as well as a similarly disturbing murder-suicide in Connecticut,” Bonta and Jennings write. “Whatever safeguards were in place did not work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two state officials are currently investigating OpenAI’s proposed restructuring into a for-profit entity to ensure that the mission of the nonprofit remains intact. That mission “includes ensuring that artificial intelligence is deployed safely” and building artificial general intelligence (AGI) to benefit all humanity, “including children,” per the letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Before we get to benefiting, we need to ensure that adequate safety measures are in place to not harm,” the letter continues. “It is our shared view that OpenAI and the industry at large are not where they need to be in ensuring safety in AI products’ development and deployment. As Attorneys General, public safety is one of our core missions. As we continue our dialogue related to OpenAI’s recapitalization plan, we must work to accelerate and amplify safety as a governing force in the future of this powerful technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bonta and Jennings have asked for more information about OpenAI’s current safety precautions and governance, and said they expect the company to take immediate remedial measures where appropriate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/teens-teenagers-GettyImages-2158370531.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Attorney General Rob Bonta and Delaware Attorney General Kathy Jennings met with and sent an open letter to OpenAI to express their concerns over the safety of ChatGPT, particularly for children and teens.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The warning comes a week after Bonta and 44 other attorneys general sent a letter to 12 of the top AI companies, following reports of sexually inappropriate interactions between AI chatbots and children.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Since the issuance of that letter, we learned of the heartbreaking death by suicide of one young Californian after he had prolonged interactions with an OpenAI chatbot, as well as a similarly disturbing murder-suicide in Connecticut,” Bonta and Jennings write. “Whatever safeguards were in place did not work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two state officials are currently investigating OpenAI’s proposed restructuring into a for-profit entity to ensure that the mission of the nonprofit remains intact. That mission “includes ensuring that artificial intelligence is deployed safely” and building artificial general intelligence (AGI) to benefit all humanity, “including children,” per the letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Before we get to benefiting, we need to ensure that adequate safety measures are in place to not harm,” the letter continues. “It is our shared view that OpenAI and the industry at large are not where they need to be in ensuring safety in AI products’ development and deployment. As Attorneys General, public safety is one of our core missions. As we continue our dialogue related to OpenAI’s recapitalization plan, we must work to accelerate and amplify safety as a governing force in the future of this powerful technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bonta and Jennings have asked for more information about OpenAI’s current safety precautions and governance, and said they expect the company to take immediate remedial measures where appropriate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/05/attorneys-general-warn-openai-harm-to-children-will-not-be-tolerated/</guid><pubDate>Fri, 05 Sep 2025 19:21:45 +0000</pubDate></item><item><title>Personalized AI companion app Dot is shutting down (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/05/personalized-ai-companion-app-dot-is-shutting-down/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Dot, an AI companion app that aimed to be a friend and confidante, is shutting down, the company announced on Friday. On a message published on its website, the startup behind Dot, New Computer, said that the product will remain operational until October 5, giving users time to download their data. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in 2024 by co-founders Sam Whitmore and former Apple designer Jason Yuan, Dot waded into what’s now become a more controversial area for AI chatbots. The app they created was described as an AI “friend and companion,” which would become more personalized to you and your interests over time in order to offer advice, sympathy, and emotional support. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Yuan explained at the time, Dot was “facilitating a relationship with my inner self. It’s like a living mirror of myself, so to speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, this may not be a safe area to invest in as a smaller startup. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI technology has become more mainstream, there have been reports of how emotionally vulnerable people have been led into delusional thinking by AI chatbots like ChatGPT. This has led to a phenomenon described as “AI psychosis,” resulting from how the scyophantic chatbots reinforce a user’s confused or paranoid beliefs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Dot shuts down, AI chatbot&amp;nbsp;apps broadly have been falling under increased scrutiny over safety concerns.&amp;nbsp;OpenAI is currently being sued by the parents of a California teenager who took his life after messaging with ChatGPT about his suicidal thoughts. Other stories have highlighted how AI companion apps can reinforce unhealthy behaviors in users who are mentally unwell. This week, two U.S. attorneys general sent a letter to OpenAI over safety concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dot’s makers didn’t address whether these types of issues had weighed on the founders’ minds. Instead, the brief post only notes that Whitmore and Yuan’s shared “Northstar” had diverged. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Rather than compromise either vision, we’ve decided to go our separate ways and wind down operations,” the post explains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be sensitive to the fact that this means many of you will lose access to a friend, confidante, and companion, which is somewhat unprecedented in software, so we want to give you some time to say goodbye. Dot will remain operational until October 5, and until then you can download all of your data by navigating to the settings page and tapping ‘Request your data.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The post suggests the startup had “hundreds of thousands” of users, but data from app intelligence provider Appfigures sees only 24,500 lifetime downloads on iOS since launching in June 2024. (There was no Android version.) &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Dot, an AI companion app that aimed to be a friend and confidante, is shutting down, the company announced on Friday. On a message published on its website, the startup behind Dot, New Computer, said that the product will remain operational until October 5, giving users time to download their data. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in 2024 by co-founders Sam Whitmore and former Apple designer Jason Yuan, Dot waded into what’s now become a more controversial area for AI chatbots. The app they created was described as an AI “friend and companion,” which would become more personalized to you and your interests over time in order to offer advice, sympathy, and emotional support. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Yuan explained at the time, Dot was “facilitating a relationship with my inner self. It’s like a living mirror of myself, so to speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, this may not be a safe area to invest in as a smaller startup. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI technology has become more mainstream, there have been reports of how emotionally vulnerable people have been led into delusional thinking by AI chatbots like ChatGPT. This has led to a phenomenon described as “AI psychosis,” resulting from how the scyophantic chatbots reinforce a user’s confused or paranoid beliefs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Dot shuts down, AI chatbot&amp;nbsp;apps broadly have been falling under increased scrutiny over safety concerns.&amp;nbsp;OpenAI is currently being sued by the parents of a California teenager who took his life after messaging with ChatGPT about his suicidal thoughts. Other stories have highlighted how AI companion apps can reinforce unhealthy behaviors in users who are mentally unwell. This week, two U.S. attorneys general sent a letter to OpenAI over safety concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dot’s makers didn’t address whether these types of issues had weighed on the founders’ minds. Instead, the brief post only notes that Whitmore and Yuan’s shared “Northstar” had diverged. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Rather than compromise either vision, we’ve decided to go our separate ways and wind down operations,” the post explains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be sensitive to the fact that this means many of you will lose access to a friend, confidante, and companion, which is somewhat unprecedented in software, so we want to give you some time to say goodbye. Dot will remain operational until October 5, and until then you can download all of your data by navigating to the settings page and tapping ‘Request your data.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The post suggests the startup had “hundreds of thousands” of users, but data from app intelligence provider Appfigures sees only 24,500 lifetime downloads on iOS since launching in June 2024. (There was no Android version.) &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/05/personalized-ai-companion-app-dot-is-shutting-down/</guid><pubDate>Fri, 05 Sep 2025 19:27:47 +0000</pubDate></item><item><title>“First of its kind” AI settlement: Anthropic to pay authors $1.5 billion (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/first-of-its-kind-ai-settlement-anthropic-to-pay-authors-1-5-billion/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Settlement shows AI companies can face consequences for pirated training data.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-604354902-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-604354902-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bespalyi | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Authors revealed today that Anthropic agreed to pay $1.5 billion and destroy all copies of the books the AI company pirated to train its artificial intelligence models.&lt;/p&gt;
&lt;p&gt;In a press release provided to Ars, the authors confirmed that the settlement is "believed to be the largest publicly reported recovery in the history of US copyright litigation." Covering 500,000 works that Anthropic pirated for AI training, if a court approves the settlement, each author will receive $3,000 per work that Anthropic stole. "Depending on the number of claims submitted, the final figure per work could be higher," the press release noted.&lt;/p&gt;
&lt;p&gt;Anthropic has already agreed to the settlement terms, but a court must approve them before the settlement is finalized. Preliminary approval may be granted this week, while the ultimate decision may be delayed until 2026, the press release noted.&lt;/p&gt;
&lt;p&gt;Justin Nelson, a lawyer representing the three authors who initially sued to spark the class action—Andrea Bartz, Kirk Wallace Johnson, and Charles Graeber—confirmed that if the "first of its kind" settlement "in the AI era" is approved, the payouts will "far" surpass "any other known copyright recovery."&lt;/p&gt;
&lt;p&gt;"It will provide meaningful compensation for each class work and sets a precedent requiring AI companies to pay copyright owners," Nelson said. "This settlement sends a powerful message to AI companies and creators alike that taking copyrighted works from these pirate websites is wrong."&lt;/p&gt;
&lt;p&gt;Groups representing authors celebrated the settlement on Friday. The CEO of the Authors’ Guild, Mary Rasenberger, said it was "an excellent result for authors, publishers, and rightsholders generally." Perhaps most critically, the settlement shows "there are serious consequences when" companies "pirate authors’ works to train their AI, robbing those least able to afford it," Rasenberger said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Maria Pallante, president and CEO of the Association of American Publishers, agreed the settlement was "beneficial" to stakeholders "beyond the monetary terms."&lt;/p&gt;
&lt;p&gt;"The proposed settlement provides enormous value in sending the message that Artificial Intelligence companies cannot unlawfully acquire content from shadow libraries or other pirate sources as the building blocks for their models," Pallante said.&lt;/p&gt;
&lt;p&gt;Notably, the settlement allows authors to retain rights and legal claims for any works not covered by the lawsuit. It also does not release any past or future claims over Anthropic's potentially infringing outputs.&lt;/p&gt;
&lt;p&gt;In the coming weeks, if the settlement is preliminarily approved, authors will be able to search this website to confirm if their works were part of the class action and are therefore eligible for a payout. Any author seeking compensation will then be able to provide contact information to receive notifications as the settlement is finalized. In the meantime, the Authors Guild provided a thorough breakdown of how the settlement will work, including information for authors who are wondering if their works are included in the class.&lt;/p&gt;
&lt;p&gt;Today, Anthropic likely breathes a sigh of relief to avoid the costs of extended litigation and potentially paying more for pirating books. However, the rest of the AI industry is likely horrified by the settlement, which advocates had suggested&amp;nbsp;could set an alarming precedent that could financially ruin emerging AI companies like Anthropic.&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach Anthropic for comment. But Aparna Sridhar, Anthropic’s deputy general counsel, provided a statement to Ars, emphasizing that the court found "Anthropic’s approach to training AI models constitutes fair use."&lt;/p&gt;
&lt;p class="css-at9mc1 evys1bk0"&gt;“Today’s settlement, if approved, will resolve the plaintiffs’ remaining legacy claims," Sridhar said. "We remain committed to developing safe AI systems that help people and organizations extend their capabilities, advance scientific discovery and solve complex problems."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Settlement shows AI companies can face consequences for pirated training data.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-604354902-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-604354902-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bespalyi | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Authors revealed today that Anthropic agreed to pay $1.5 billion and destroy all copies of the books the AI company pirated to train its artificial intelligence models.&lt;/p&gt;
&lt;p&gt;In a press release provided to Ars, the authors confirmed that the settlement is "believed to be the largest publicly reported recovery in the history of US copyright litigation." Covering 500,000 works that Anthropic pirated for AI training, if a court approves the settlement, each author will receive $3,000 per work that Anthropic stole. "Depending on the number of claims submitted, the final figure per work could be higher," the press release noted.&lt;/p&gt;
&lt;p&gt;Anthropic has already agreed to the settlement terms, but a court must approve them before the settlement is finalized. Preliminary approval may be granted this week, while the ultimate decision may be delayed until 2026, the press release noted.&lt;/p&gt;
&lt;p&gt;Justin Nelson, a lawyer representing the three authors who initially sued to spark the class action—Andrea Bartz, Kirk Wallace Johnson, and Charles Graeber—confirmed that if the "first of its kind" settlement "in the AI era" is approved, the payouts will "far" surpass "any other known copyright recovery."&lt;/p&gt;
&lt;p&gt;"It will provide meaningful compensation for each class work and sets a precedent requiring AI companies to pay copyright owners," Nelson said. "This settlement sends a powerful message to AI companies and creators alike that taking copyrighted works from these pirate websites is wrong."&lt;/p&gt;
&lt;p&gt;Groups representing authors celebrated the settlement on Friday. The CEO of the Authors’ Guild, Mary Rasenberger, said it was "an excellent result for authors, publishers, and rightsholders generally." Perhaps most critically, the settlement shows "there are serious consequences when" companies "pirate authors’ works to train their AI, robbing those least able to afford it," Rasenberger said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Maria Pallante, president and CEO of the Association of American Publishers, agreed the settlement was "beneficial" to stakeholders "beyond the monetary terms."&lt;/p&gt;
&lt;p&gt;"The proposed settlement provides enormous value in sending the message that Artificial Intelligence companies cannot unlawfully acquire content from shadow libraries or other pirate sources as the building blocks for their models," Pallante said.&lt;/p&gt;
&lt;p&gt;Notably, the settlement allows authors to retain rights and legal claims for any works not covered by the lawsuit. It also does not release any past or future claims over Anthropic's potentially infringing outputs.&lt;/p&gt;
&lt;p&gt;In the coming weeks, if the settlement is preliminarily approved, authors will be able to search this website to confirm if their works were part of the class action and are therefore eligible for a payout. Any author seeking compensation will then be able to provide contact information to receive notifications as the settlement is finalized. In the meantime, the Authors Guild provided a thorough breakdown of how the settlement will work, including information for authors who are wondering if their works are included in the class.&lt;/p&gt;
&lt;p&gt;Today, Anthropic likely breathes a sigh of relief to avoid the costs of extended litigation and potentially paying more for pirating books. However, the rest of the AI industry is likely horrified by the settlement, which advocates had suggested&amp;nbsp;could set an alarming precedent that could financially ruin emerging AI companies like Anthropic.&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach Anthropic for comment. But Aparna Sridhar, Anthropic’s deputy general counsel, provided a statement to Ars, emphasizing that the court found "Anthropic’s approach to training AI models constitutes fair use."&lt;/p&gt;
&lt;p class="css-at9mc1 evys1bk0"&gt;“Today’s settlement, if approved, will resolve the plaintiffs’ remaining legacy claims," Sridhar said. "We remain committed to developing safe AI systems that help people and organizations extend their capabilities, advance scientific discovery and solve complex problems."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/first-of-its-kind-ai-settlement-anthropic-to-pay-authors-1-5-billion/</guid><pubDate>Fri, 05 Sep 2025 20:26:03 +0000</pubDate></item><item><title>Screw the money — Anthropic’s $1.5B copyright settlement sucks for writers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/05/screw-the-money-anthropics-1-5b-copyright-settlement-sucks-for-writers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1175885065.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Around half a million writers will be eligible for a payday of at least $3,000, thanks to a historic $1.5 billion settlement in a class action lawsuit that a group of authors brought against Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This landmark settlement marks the largest payout in the history of U.S. copyright law, but this isn’t a victory for authors — it’s yet another win for tech companies.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tech giants are racing to amass as much written material as possible to train their LLMs, which power groundbreaking AI chat products like ChatGPT and Claude — the same products that are endangering the creative industries, even if their outputs are milquetoast. These AIs can become more sophisticated when they ingest more data, but after scraping basically the entire internet, these companies are literally running out of new information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Anthropic, the company behind Claude, pirated millions of books from “shadow libraries” and fed them into its AI. This particular lawsuit, Bartz v. Anthropic, is one of dozens filed against companies like Meta, Google, OpenAI, and Midjourney over the legality of training AI on copyrighted works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But writers aren’t getting this settlement because their work was fed to an AI — this is just a costly slap on the wrist for Anthropic, a company that just raised another $13 billion, because it illegally downloaded books instead of buying them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, federal judge William Alsup sided with Anthropic and ruled that it is, indeed, legal to train AI on copyrighted material. The judge argues that this use case is “transformative” enough to be protected by the fair use doctrine, a carve-out of copyright law that&amp;nbsp;hasn’t been updated&amp;nbsp;since 1976.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like any reader aspiring to be a writer, Anthropic’s LLMs trained upon works not to race ahead and replicate or supplant them — but to turn a hard corner and create something different,” the judge said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was the piracy — not the AI training — that moved Judge Alsup to bring the case to trial, but with Anthropic’s settlement, a trial is no longer necessary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today’s settlement, if approved, will resolve the plaintiffs’ remaining legacy claims,” said Aparna Sridhar, deputy general counsel at Anthropic, in a statement. “We remain committed to developing safe AI systems that help people and organizations extend their capabilities, advance scientific discovery, and solve complex problems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As dozens more cases over the relationship between AI and copyrighted works go to court, judges now have Bartz v. Anthropic to reference as a precedent. But given the ramifications of these decisions, maybe another judge will arrive at a different conclusion.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1175885065.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Around half a million writers will be eligible for a payday of at least $3,000, thanks to a historic $1.5 billion settlement in a class action lawsuit that a group of authors brought against Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This landmark settlement marks the largest payout in the history of U.S. copyright law, but this isn’t a victory for authors — it’s yet another win for tech companies.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tech giants are racing to amass as much written material as possible to train their LLMs, which power groundbreaking AI chat products like ChatGPT and Claude — the same products that are endangering the creative industries, even if their outputs are milquetoast. These AIs can become more sophisticated when they ingest more data, but after scraping basically the entire internet, these companies are literally running out of new information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Anthropic, the company behind Claude, pirated millions of books from “shadow libraries” and fed them into its AI. This particular lawsuit, Bartz v. Anthropic, is one of dozens filed against companies like Meta, Google, OpenAI, and Midjourney over the legality of training AI on copyrighted works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But writers aren’t getting this settlement because their work was fed to an AI — this is just a costly slap on the wrist for Anthropic, a company that just raised another $13 billion, because it illegally downloaded books instead of buying them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, federal judge William Alsup sided with Anthropic and ruled that it is, indeed, legal to train AI on copyrighted material. The judge argues that this use case is “transformative” enough to be protected by the fair use doctrine, a carve-out of copyright law that&amp;nbsp;hasn’t been updated&amp;nbsp;since 1976.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like any reader aspiring to be a writer, Anthropic’s LLMs trained upon works not to race ahead and replicate or supplant them — but to turn a hard corner and create something different,” the judge said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was the piracy — not the AI training — that moved Judge Alsup to bring the case to trial, but with Anthropic’s settlement, a trial is no longer necessary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today’s settlement, if approved, will resolve the plaintiffs’ remaining legacy claims,” said Aparna Sridhar, deputy general counsel at Anthropic, in a statement. “We remain committed to developing safe AI systems that help people and organizations extend their capabilities, advance scientific discovery, and solve complex problems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As dozens more cases over the relationship between AI and copyrighted works go to court, judges now have Bartz v. Anthropic to reference as a precedent. But given the ramifications of these decisions, maybe another judge will arrive at a different conclusion.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/05/screw-the-money-anthropics-1-5b-copyright-settlement-sucks-for-writers/</guid><pubDate>Fri, 05 Sep 2025 20:59:21 +0000</pubDate></item><item><title>OpenAI reorganizes research team behind ChatGPT’s personality (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/05/openai-reorganizes-research-team-behind-chatgpts-personality/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is reorganizing its Model Behavior team, a small but influential group of researchers who shape how the company’s AI models interact with people, TechCrunch has learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an August memo to staff seen by TechCrunch, OpenAI’s chief research officer Mark Chen said the Model Behavior team — which consists of roughly 14 researchers — would be joining the Post Training team, a larger research group responsible for improving the company’s AI models after their initial pre-training.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As part of the changes, the Model Behavior team will now report to OpenAI’s Post Training lead Max Schwarzer. An OpenAI spokesperson confirmed these changes to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team’s founding leader, Joanne Jang, is also moving on to start a new project at the company. In an interview with TechCrunch, Jang says she’s building out a new research team called OAI Labs, which will be responsible for “inventing and prototyping new interfaces for how people collaborate with AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team has become one of OpenAI’s key research groups, responsible for shaping the personality of the company’s AI models and for reducing sycophancy — which occurs when AI models simply agree with and reinforce user beliefs, even unhealthy ones, rather than offering balanced responses. The team has also worked on navigating political bias in model responses and helped OpenAI define its stance on AI consciousness.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the memo to staff, Chen said that now is the time to bring the work of OpenAI’s Model Behavior team closer to core model development. By doing so, the company is signaling that the “personality” of its AI is now considered a critical factor in how the technology evolves.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, OpenAI has faced increased scrutiny over the behavior of its AI models. Users strongly objected to personality changes made to GPT-5, which the company said exhibited lower rates of sycophancy but seemed colder to some users. This led OpenAI to restore access to some of its legacy models, such as GPT-4o, and to release an update to make the newer GPT-5 responses feel “warmer and friendlier” without increasing sycophancy.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and all AI model developers have to walk a fine line to make their AI chatbots friendly to talk to but not sycophantic. In August, the parents of a 16-year-old boy sued OpenAI over ChatGPT’s alleged role in their son’s suicide. The boy, Adam Raine, confided some of his suicidal thoughts and plans to ChatGPT (specifically a version powered by GPT-4o), according to court documents, in the months leading up to his death. The lawsuit alleges that GPT-4o failed to push back on his suicidal ideations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team has worked on every OpenAI model since GPT-4, including GPT-4o, GPT-4.5, and GPT-5. Before starting the unit, Jang previously worked on projects such as Dall-E 2, OpenAI’s early image-generation tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jang announced in a post on X last week that she’s leaving the team to “begin something new at OpenAI.” The former head of Model Behavior has been with OpenAI for nearly four years.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jang told TechCrunch she will serve as the general manager of OAI Labs, which will report to Chen for now. However, it’s early days, and it’s not clear yet what those novel interfaces will be, she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m really excited to explore patterns that move us beyond the chat paradigm, which is currently associated more with companionship, or even agents, where there’s an emphasis on autonomy,” said Jang. “I’ve been thinking of [AI systems] as instruments for thinking, making, playing, doing, learning, and connecting.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🧪 i’m starting oai labs: a research-driven group focused on inventing and prototyping new interfaces for how people collaborate with ai.&lt;/p&gt;&lt;p&gt;i’m excited to explore patterns that move us beyond chat or even agents — toward new paradigms and instruments for thinking, making,…&lt;/p&gt;— Joanne Jang (@joannejang) September 5, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When asked whether OAI Labs will collaborate on these novel interfaces with former Apple design chief Jony Ive — who’s now working with OpenAI on a family of AI hardware devices — Jang said she’s open to lots of ideas. However, she said she’ll likely start with research areas she’s more familiar with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated to include a link to Jang’s post announcing her new position, which was released after this story published. We also clarify the models that OpenAI’s Model Behavior team worked on.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is reorganizing its Model Behavior team, a small but influential group of researchers who shape how the company’s AI models interact with people, TechCrunch has learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an August memo to staff seen by TechCrunch, OpenAI’s chief research officer Mark Chen said the Model Behavior team — which consists of roughly 14 researchers — would be joining the Post Training team, a larger research group responsible for improving the company’s AI models after their initial pre-training.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As part of the changes, the Model Behavior team will now report to OpenAI’s Post Training lead Max Schwarzer. An OpenAI spokesperson confirmed these changes to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team’s founding leader, Joanne Jang, is also moving on to start a new project at the company. In an interview with TechCrunch, Jang says she’s building out a new research team called OAI Labs, which will be responsible for “inventing and prototyping new interfaces for how people collaborate with AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team has become one of OpenAI’s key research groups, responsible for shaping the personality of the company’s AI models and for reducing sycophancy — which occurs when AI models simply agree with and reinforce user beliefs, even unhealthy ones, rather than offering balanced responses. The team has also worked on navigating political bias in model responses and helped OpenAI define its stance on AI consciousness.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the memo to staff, Chen said that now is the time to bring the work of OpenAI’s Model Behavior team closer to core model development. By doing so, the company is signaling that the “personality” of its AI is now considered a critical factor in how the technology evolves.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, OpenAI has faced increased scrutiny over the behavior of its AI models. Users strongly objected to personality changes made to GPT-5, which the company said exhibited lower rates of sycophancy but seemed colder to some users. This led OpenAI to restore access to some of its legacy models, such as GPT-4o, and to release an update to make the newer GPT-5 responses feel “warmer and friendlier” without increasing sycophancy.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and all AI model developers have to walk a fine line to make their AI chatbots friendly to talk to but not sycophantic. In August, the parents of a 16-year-old boy sued OpenAI over ChatGPT’s alleged role in their son’s suicide. The boy, Adam Raine, confided some of his suicidal thoughts and plans to ChatGPT (specifically a version powered by GPT-4o), according to court documents, in the months leading up to his death. The lawsuit alleges that GPT-4o failed to push back on his suicidal ideations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Model Behavior team has worked on every OpenAI model since GPT-4, including GPT-4o, GPT-4.5, and GPT-5. Before starting the unit, Jang previously worked on projects such as Dall-E 2, OpenAI’s early image-generation tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jang announced in a post on X last week that she’s leaving the team to “begin something new at OpenAI.” The former head of Model Behavior has been with OpenAI for nearly four years.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jang told TechCrunch she will serve as the general manager of OAI Labs, which will report to Chen for now. However, it’s early days, and it’s not clear yet what those novel interfaces will be, she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m really excited to explore patterns that move us beyond the chat paradigm, which is currently associated more with companionship, or even agents, where there’s an emphasis on autonomy,” said Jang. “I’ve been thinking of [AI systems] as instruments for thinking, making, playing, doing, learning, and connecting.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🧪 i’m starting oai labs: a research-driven group focused on inventing and prototyping new interfaces for how people collaborate with ai.&lt;/p&gt;&lt;p&gt;i’m excited to explore patterns that move us beyond chat or even agents — toward new paradigms and instruments for thinking, making,…&lt;/p&gt;— Joanne Jang (@joannejang) September 5, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When asked whether OAI Labs will collaborate on these novel interfaces with former Apple design chief Jony Ive — who’s now working with OpenAI on a family of AI hardware devices — Jang said she’s open to lots of ideas. However, she said she’ll likely start with research areas she’s more familiar with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated to include a link to Jang’s post announcing her new position, which was released after this story published. We also clarify the models that OpenAI’s Model Behavior team worked on.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/05/openai-reorganizes-research-team-behind-chatgpts-personality/</guid><pubDate>Fri, 05 Sep 2025 23:19:12 +0000</pubDate></item></channel></rss>