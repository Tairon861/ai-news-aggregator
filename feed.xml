<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 05 Dec 2025 01:49:48 +0000</lastBuildDate><item><title>Delivering securely on data and AI strategy (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/04/1128311/delivering-securely-on-data-and-ai-strategy/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Databricks&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Most organizations feel the imperative to keep pace with continuing advances in AI capabilities, as highlighted in a recent MIT Technology Review Insights report. That clearly has security implications, particularly as organizations navigate a surge in the volume, velocity, and variety of security data. This explosion of data, coupled with fragmented toolchains, is making it increasingly difficult for security and data teams to maintain a proactive and unified security posture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Data and AI teams must move rapidly to deliver the desired business results, but they must do so without compromising security and governance. As they deploy more intelligent and powerful AI capabilities, proactive threat detection and response against the expanded attack surface, insider threats, and supply chain vulnerabilities must remain paramount. “I’m passionate about cybersecurity not slowing us down,” says Melody Hildebrandt, chief technology officer at Fox Corporation, “but I also own cybersecurity strategy. So I’m also passionate about us not introducing security vulnerabilities.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1128313" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MIT_DatabricksEbrief_CoverV4_101525.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;That’s getting more challenging, says Nithin Ramachandran, who is global vice president for data and AI at industrial and consumer products manufacturer 3M. “Our experience with generative AI has shown that we need to be looking at security differently than before,” he says. “With every tool we deploy, we look not just at&amp;nbsp;its functionality but also its security posture. The latter is now what we lead with.”&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128319" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR2025_V4_QuoteDatabricksSocials.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Our survey of 800 technology executives (including 100 chief information security officers), conducted in June 2025, shows that many organizations struggle to strike this balance.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Databricks&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Most organizations feel the imperative to keep pace with continuing advances in AI capabilities, as highlighted in a recent MIT Technology Review Insights report. That clearly has security implications, particularly as organizations navigate a surge in the volume, velocity, and variety of security data. This explosion of data, coupled with fragmented toolchains, is making it increasingly difficult for security and data teams to maintain a proactive and unified security posture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Data and AI teams must move rapidly to deliver the desired business results, but they must do so without compromising security and governance. As they deploy more intelligent and powerful AI capabilities, proactive threat detection and response against the expanded attack surface, insider threats, and supply chain vulnerabilities must remain paramount. “I’m passionate about cybersecurity not slowing us down,” says Melody Hildebrandt, chief technology officer at Fox Corporation, “but I also own cybersecurity strategy. So I’m also passionate about us not introducing security vulnerabilities.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1128313" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MIT_DatabricksEbrief_CoverV4_101525.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;That’s getting more challenging, says Nithin Ramachandran, who is global vice president for data and AI at industrial and consumer products manufacturer 3M. “Our experience with generative AI has shown that we need to be looking at security differently than before,” he says. “With every tool we deploy, we look not just at&amp;nbsp;its functionality but also its security posture. The latter is now what we lead with.”&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128319" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR2025_V4_QuoteDatabricksSocials.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Our survey of 800 technology executives (including 100 chief information security officers), conducted in June 2025, shows that many organizations struggle to strike this balance.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/04/1128311/delivering-securely-on-data-and-ai-strategy/</guid><pubDate>Thu, 04 Dec 2025 14:00:00 +0000</pubDate></item><item><title>Gong study: Sales teams using AI generate 77% more revenue per rep (AI | VentureBeat)</title><link>https://venturebeat.com/ai/gong-study-sales-teams-using-ai-generate-77-more-revenue-per-rep</link><description>[unable to retrieve full-text content]&lt;p&gt;The debate over whether artificial intelligence belongs in the corporate boardroom appears to be over — at least for the people responsible for generating revenue.&lt;/p&gt;&lt;p&gt;Seven in ten enterprise revenue leaders now trust AI to regularly inform their business decisions, according to &lt;a href="https://www.gong.io/resources/guides/state-of-revenue-ai-2026-report"&gt;a sweeping new study released Thursday by Gong&lt;/a&gt;, the revenue intelligence company. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.&lt;/p&gt;&lt;p&gt;The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the United States, United Kingdom, Australia, and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65 percent more likely to increase their win rates than competitors still treating the technology as optional.&lt;/p&gt;&lt;p&gt;&amp;quot;I don&amp;#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,&amp;quot; Amit Bendov, Gong&amp;#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. &amp;quot;Humans are making the decision, but they&amp;#x27;re largely assisted.&amp;quot;&lt;/p&gt;&lt;p&gt;The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a &amp;quot;second opinion&amp;quot; — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slowing growth is forcing sales teams to squeeze more from every rep&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The timing of AI&amp;#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: after rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16 percent in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52 percent to 46 percent over the same period.&lt;/p&gt;&lt;p&gt;The culprit, according to Gong&amp;#x27;s analysis, isn&amp;#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities—a finding that suggests operational inefficiencies are eating into selling time.&lt;/p&gt;&lt;p&gt;This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&amp;#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.&lt;/p&gt;&lt;p&gt;&amp;quot;The focus is on increasing sales productivity,&amp;quot; Bendov said. &amp;quot;How much dollar-output per dollar-input.&amp;quot;&lt;/p&gt;&lt;p&gt;The numbers back up the urgency. Teams where sellers regularly use AI tools generate 77 percent more revenue per representative than those that don&amp;#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Companies are moving beyond basic AI automation toward strategic decision-making&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift &amp;quot;from automation to intelligence.&amp;quot;&lt;/p&gt;&lt;p&gt;The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50 percent year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.&lt;/p&gt;&lt;p&gt;Organizations in the 95th percentile of commercial impact from AI were two to four times more likely to have deployed these strategic use cases, according to the study.&lt;/p&gt;&lt;p&gt;Bendov offered a concrete example of how this plays out in practice. &amp;quot;Companies have thousands of deals that they roll up into their forecast,&amp;quot; he said. &amp;quot;It used to be based solely on human sentiment—believe it or not. That&amp;#x27;s why a lot of companies miss their numbers: because people say, &amp;#x27;Oh, he told me he&amp;#x27;ll buy,&amp;#x27; or &amp;#x27;I think I can probably get this one.&amp;#x27;&amp;quot;&lt;/p&gt;&lt;p&gt;AI changes that calculus by examining evidence rather than optimism. &amp;quot;Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15 percent better accuracy just because it&amp;#x27;s evidence-based, not just based on human sentiment,&amp;quot; Bendov said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Revenue-specific AI tools are dramatically outperforming general-purpose alternatives&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of the study&amp;#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13 percent higher revenue growth and 85 percent greater commercial impact than those relying on generic tools.&lt;/p&gt;&lt;p&gt;These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.&lt;/p&gt;&lt;p&gt;The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a &amp;quot;blind spot&amp;quot; for organizations — particularly when employees adopt consumer AI tools without company oversight.&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;Research from MIT&lt;/a&gt; suggests that while only 59 percent of survey respondents said their teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90 percent. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Most sales leaders believe AI will reshape their jobs rather than eliminate them&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most closely watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.&lt;/p&gt;&lt;p&gt;When asked about AI&amp;#x27;s three-year impact on revenue headcount, 43 percent of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28 percent anticipate job eliminations, while 21 percent actually foresee AI creating new roles. Just 8 percent predict minimal impact.&lt;/p&gt;&lt;p&gt;Bendov frames the opportunity in terms of reclaiming lost time. He cited &lt;a href="https://www.forrester.com/blogs/use-science-to-improve-sales-productivity/"&gt;Forrester research &lt;/a&gt;indicating that &lt;a href="https://www.crmbuyer.com/story/gong-ai-platform-delivers-improved-accuracy-to-revenue-forecasting-177228.html"&gt;77 percent&lt;/a&gt; of a sales representative&amp;#x27;s time is spent on activities that don&amp;#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts, and internal briefings.&lt;/p&gt;&lt;p&gt;&amp;quot;AI can eliminate, ideally, all 77 percent—all the drudgery work that they&amp;#x27;re doing,&amp;quot; Bendov said. &amp;quot;I don&amp;#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&amp;#x27;s make them fully productive, and whatever you&amp;#x27;re paying them will translate to much higher revenue.&amp;quot;&lt;/p&gt;&lt;p&gt;The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: one person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.&lt;/p&gt;&lt;p&gt;&amp;quot;Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&amp;#x27;s very inefficient for companies,&amp;quot; Bendov said. &amp;quot;Now with AI, you can have one person do all this, or much of this.&amp;quot;&lt;/p&gt;&lt;p&gt;At Gong itself, sellers now generate 80 percent of their own appointments because AI handles the prospecting legwork, Bendov said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;American companies are adopting AI 18 months faster than their European counterparts&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The study reveals a notable divide in AI adoption between the United States and Europe. While 87 percent of U.S. companies now use AI in their revenue operations, with another 9 percent planning adoption within a year, the United Kingdom trails by 12 to 18 months. Just 70 percent of UK companies currently use AI, with 22 percent planning near-term adoption — figures that mirror U.S. data from 2024.&lt;/p&gt;&lt;p&gt;Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. &amp;quot;It&amp;#x27;s always like that,&amp;quot; he said. &amp;quot;Even when the internet was taking off in the US, Europe was a step behind.&amp;quot;&lt;/p&gt;&lt;p&gt;The gap isn&amp;#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gong says a decade of AI development gives it an edge over Salesforce and Microsoft&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The findings arrive as Gong navigates an increasingly crowded market. The company, which recently &lt;a href="https://www.gong.io/press/gong-surpasses-300m-arr-amid-increased-demand-for-ai-powered-revenue-solutions"&gt;surpassed $300 million&lt;/a&gt; in annual recurring revenue, faces potential competition from enterprise software giants like &lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/"&gt;Microsoft&lt;/a&gt;, both of which are embedding AI capabilities into their platforms.&lt;/p&gt;&lt;p&gt;Bendov argues that Gong&amp;#x27;s decade of AI development creates a substantial barrier to entry. The company&amp;#x27;s architecture comprises three layers: a &amp;quot;revenue graph&amp;quot; that aggregates customer data from CRM systems, emails, calls, videos, and web signals; an intelligence layer combining large language models with approximately 40 proprietary small language models; and workflow applications built on top.&lt;/p&gt;&lt;p&gt;&amp;quot;Anybody that would want to build something like that—it&amp;#x27;s not a small feature, it&amp;#x27;s 10 years in development—would need first to build the revenue graph,&amp;quot; Bendov said.&lt;/p&gt;&lt;p&gt;Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&amp;#x27; participation in Gong&amp;#x27;s recent user conference to discuss agent interoperability. The rise of MCP (&lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real question is whether AI will expand the sales profession or hollow it out&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The report&amp;#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.&lt;/p&gt;&lt;p&gt;Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.&lt;/p&gt;&lt;p&gt;&amp;quot;If AI makes selling simple, I could see a world—I don&amp;#x27;t know exactly what it looks like yet—but why not?&amp;quot; Bendov said. &amp;quot;Maybe ten times more jobs than we have now. It&amp;#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.&amp;quot;&lt;/p&gt;&lt;p&gt;For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.&lt;/p&gt;&lt;p&gt;&amp;quot;When we started the company, we were born as an AI company, but we had to almost hide AI,&amp;quot; Bendov recalled. &amp;quot;It was intimidating.&amp;quot;&lt;/p&gt;&lt;p&gt;Now, seven out of ten of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The debate over whether artificial intelligence belongs in the corporate boardroom appears to be over — at least for the people responsible for generating revenue.&lt;/p&gt;&lt;p&gt;Seven in ten enterprise revenue leaders now trust AI to regularly inform their business decisions, according to &lt;a href="https://www.gong.io/resources/guides/state-of-revenue-ai-2026-report"&gt;a sweeping new study released Thursday by Gong&lt;/a&gt;, the revenue intelligence company. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.&lt;/p&gt;&lt;p&gt;The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the United States, United Kingdom, Australia, and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65 percent more likely to increase their win rates than competitors still treating the technology as optional.&lt;/p&gt;&lt;p&gt;&amp;quot;I don&amp;#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,&amp;quot; Amit Bendov, Gong&amp;#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. &amp;quot;Humans are making the decision, but they&amp;#x27;re largely assisted.&amp;quot;&lt;/p&gt;&lt;p&gt;The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a &amp;quot;second opinion&amp;quot; — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slowing growth is forcing sales teams to squeeze more from every rep&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The timing of AI&amp;#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: after rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16 percent in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52 percent to 46 percent over the same period.&lt;/p&gt;&lt;p&gt;The culprit, according to Gong&amp;#x27;s analysis, isn&amp;#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities—a finding that suggests operational inefficiencies are eating into selling time.&lt;/p&gt;&lt;p&gt;This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&amp;#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.&lt;/p&gt;&lt;p&gt;&amp;quot;The focus is on increasing sales productivity,&amp;quot; Bendov said. &amp;quot;How much dollar-output per dollar-input.&amp;quot;&lt;/p&gt;&lt;p&gt;The numbers back up the urgency. Teams where sellers regularly use AI tools generate 77 percent more revenue per representative than those that don&amp;#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Companies are moving beyond basic AI automation toward strategic decision-making&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift &amp;quot;from automation to intelligence.&amp;quot;&lt;/p&gt;&lt;p&gt;The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50 percent year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.&lt;/p&gt;&lt;p&gt;Organizations in the 95th percentile of commercial impact from AI were two to four times more likely to have deployed these strategic use cases, according to the study.&lt;/p&gt;&lt;p&gt;Bendov offered a concrete example of how this plays out in practice. &amp;quot;Companies have thousands of deals that they roll up into their forecast,&amp;quot; he said. &amp;quot;It used to be based solely on human sentiment—believe it or not. That&amp;#x27;s why a lot of companies miss their numbers: because people say, &amp;#x27;Oh, he told me he&amp;#x27;ll buy,&amp;#x27; or &amp;#x27;I think I can probably get this one.&amp;#x27;&amp;quot;&lt;/p&gt;&lt;p&gt;AI changes that calculus by examining evidence rather than optimism. &amp;quot;Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15 percent better accuracy just because it&amp;#x27;s evidence-based, not just based on human sentiment,&amp;quot; Bendov said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Revenue-specific AI tools are dramatically outperforming general-purpose alternatives&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of the study&amp;#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13 percent higher revenue growth and 85 percent greater commercial impact than those relying on generic tools.&lt;/p&gt;&lt;p&gt;These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.&lt;/p&gt;&lt;p&gt;The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a &amp;quot;blind spot&amp;quot; for organizations — particularly when employees adopt consumer AI tools without company oversight.&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;Research from MIT&lt;/a&gt; suggests that while only 59 percent of survey respondents said their teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90 percent. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Most sales leaders believe AI will reshape their jobs rather than eliminate them&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most closely watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.&lt;/p&gt;&lt;p&gt;When asked about AI&amp;#x27;s three-year impact on revenue headcount, 43 percent of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28 percent anticipate job eliminations, while 21 percent actually foresee AI creating new roles. Just 8 percent predict minimal impact.&lt;/p&gt;&lt;p&gt;Bendov frames the opportunity in terms of reclaiming lost time. He cited &lt;a href="https://www.forrester.com/blogs/use-science-to-improve-sales-productivity/"&gt;Forrester research &lt;/a&gt;indicating that &lt;a href="https://www.crmbuyer.com/story/gong-ai-platform-delivers-improved-accuracy-to-revenue-forecasting-177228.html"&gt;77 percent&lt;/a&gt; of a sales representative&amp;#x27;s time is spent on activities that don&amp;#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts, and internal briefings.&lt;/p&gt;&lt;p&gt;&amp;quot;AI can eliminate, ideally, all 77 percent—all the drudgery work that they&amp;#x27;re doing,&amp;quot; Bendov said. &amp;quot;I don&amp;#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&amp;#x27;s make them fully productive, and whatever you&amp;#x27;re paying them will translate to much higher revenue.&amp;quot;&lt;/p&gt;&lt;p&gt;The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: one person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.&lt;/p&gt;&lt;p&gt;&amp;quot;Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&amp;#x27;s very inefficient for companies,&amp;quot; Bendov said. &amp;quot;Now with AI, you can have one person do all this, or much of this.&amp;quot;&lt;/p&gt;&lt;p&gt;At Gong itself, sellers now generate 80 percent of their own appointments because AI handles the prospecting legwork, Bendov said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;American companies are adopting AI 18 months faster than their European counterparts&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The study reveals a notable divide in AI adoption between the United States and Europe. While 87 percent of U.S. companies now use AI in their revenue operations, with another 9 percent planning adoption within a year, the United Kingdom trails by 12 to 18 months. Just 70 percent of UK companies currently use AI, with 22 percent planning near-term adoption — figures that mirror U.S. data from 2024.&lt;/p&gt;&lt;p&gt;Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. &amp;quot;It&amp;#x27;s always like that,&amp;quot; he said. &amp;quot;Even when the internet was taking off in the US, Europe was a step behind.&amp;quot;&lt;/p&gt;&lt;p&gt;The gap isn&amp;#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gong says a decade of AI development gives it an edge over Salesforce and Microsoft&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The findings arrive as Gong navigates an increasingly crowded market. The company, which recently &lt;a href="https://www.gong.io/press/gong-surpasses-300m-arr-amid-increased-demand-for-ai-powered-revenue-solutions"&gt;surpassed $300 million&lt;/a&gt; in annual recurring revenue, faces potential competition from enterprise software giants like &lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/"&gt;Microsoft&lt;/a&gt;, both of which are embedding AI capabilities into their platforms.&lt;/p&gt;&lt;p&gt;Bendov argues that Gong&amp;#x27;s decade of AI development creates a substantial barrier to entry. The company&amp;#x27;s architecture comprises three layers: a &amp;quot;revenue graph&amp;quot; that aggregates customer data from CRM systems, emails, calls, videos, and web signals; an intelligence layer combining large language models with approximately 40 proprietary small language models; and workflow applications built on top.&lt;/p&gt;&lt;p&gt;&amp;quot;Anybody that would want to build something like that—it&amp;#x27;s not a small feature, it&amp;#x27;s 10 years in development—would need first to build the revenue graph,&amp;quot; Bendov said.&lt;/p&gt;&lt;p&gt;Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&amp;#x27; participation in Gong&amp;#x27;s recent user conference to discuss agent interoperability. The rise of MCP (&lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real question is whether AI will expand the sales profession or hollow it out&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The report&amp;#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.&lt;/p&gt;&lt;p&gt;Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.&lt;/p&gt;&lt;p&gt;&amp;quot;If AI makes selling simple, I could see a world—I don&amp;#x27;t know exactly what it looks like yet—but why not?&amp;quot; Bendov said. &amp;quot;Maybe ten times more jobs than we have now. It&amp;#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.&amp;quot;&lt;/p&gt;&lt;p&gt;For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.&lt;/p&gt;&lt;p&gt;&amp;quot;When we started the company, we were born as an AI company, but we had to almost hide AI,&amp;quot; Bendov recalled. &amp;quot;It was intimidating.&amp;quot;&lt;/p&gt;&lt;p&gt;Now, seven out of ten of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/gong-study-sales-teams-using-ai-generate-77-more-revenue-per-rep</guid><pubDate>Thu, 04 Dec 2025 14:00:00 +0000</pubDate></item><item><title>AI finds its way into Apple’s top apps of the year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/ai-finds-its-way-into-apples-top-apps-of-the-year/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday shared its annual list of App Store Award winners, continuing its tradition of celebrating the best apps and games of the past year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For 2025, the winning iPhone app was visual planner Tiimo, and the iPhone game of the year was the card game Pokémon TCG Pocket.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although Apple has continued to avoid naming a dedicated AI app or AI chatbot as its app of the year, AI was showcased among this year’s winners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s app of the year, Tiimo, for instance, is described as a visual AI planner that turns to-dos into plans with visual timelines. The app uses AI to break down your tasks into a realistic schedule by estimating how long each step of a task could take and helping you to create a plan.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072726" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Apple-App-Store-Awards-2025-winner-iPhone-App-of-the-Year-Tiimo-Al-Planner-To-do.png?w=486" width="486" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Tiimo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the iPad app of the year, Detail, simplifies video editing with an “Auto Edit” AI feature that handles things like silence removal, zoom cuts, and adding titles and captions.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072727" height="490" src="https://techcrunch.com/wp-content/uploads/2025/12/Detail-AutoEdit-Frame.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Detail&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;A Cultural Impact winner, StoryGraph, uses a machine learning AI to make book recommendations based on your reading data, while another, Be My Eyes, offers an AI assistant that provides visual descriptions of real-world images for blind and low-vision users.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072729" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/BeMyEyes-Be-My-AI-Description.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Be My Eyes&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;And the Apple Watch app of the year, Strava, includes an AI assistant that turns workout data into insights.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced winners for the iPad, Mac, Vision Pro, Apple Watch, Apple TV, and a standout within its own game subscription service, Apple Arcade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Apple gave a handful of apps a “Cultural Impact” award. These apps, the company said, offered helpful tools, promoted understanding, or shaped a more inclusive world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple first named 45 apps and games as finalists for its awards in November, and the list has now been narrowed down to 17 apps and games. The winners include:&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday shared its annual list of App Store Award winners, continuing its tradition of celebrating the best apps and games of the past year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For 2025, the winning iPhone app was visual planner Tiimo, and the iPhone game of the year was the card game Pokémon TCG Pocket.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although Apple has continued to avoid naming a dedicated AI app or AI chatbot as its app of the year, AI was showcased among this year’s winners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s app of the year, Tiimo, for instance, is described as a visual AI planner that turns to-dos into plans with visual timelines. The app uses AI to break down your tasks into a realistic schedule by estimating how long each step of a task could take and helping you to create a plan.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072726" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Apple-App-Store-Awards-2025-winner-iPhone-App-of-the-Year-Tiimo-Al-Planner-To-do.png?w=486" width="486" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Tiimo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the iPad app of the year, Detail, simplifies video editing with an “Auto Edit” AI feature that handles things like silence removal, zoom cuts, and adding titles and captions.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072727" height="490" src="https://techcrunch.com/wp-content/uploads/2025/12/Detail-AutoEdit-Frame.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Detail&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;A Cultural Impact winner, StoryGraph, uses a machine learning AI to make book recommendations based on your reading data, while another, Be My Eyes, offers an AI assistant that provides visual descriptions of real-world images for blind and low-vision users.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072729" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/BeMyEyes-Be-My-AI-Description.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Be My Eyes&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;And the Apple Watch app of the year, Strava, includes an AI assistant that turns workout data into insights.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced winners for the iPad, Mac, Vision Pro, Apple Watch, Apple TV, and a standout within its own game subscription service, Apple Arcade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Apple gave a handful of apps a “Cultural Impact” award. These apps, the company said, offered helpful tools, promoted understanding, or shaped a more inclusive world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple first named 45 apps and games as finalists for its awards in November, and the list has now been narrowed down to 17 apps and games. The winners include:&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/ai-finds-its-way-into-apples-top-apps-of-the-year/</guid><pubDate>Thu, 04 Dec 2025 14:00:00 +0000</pubDate></item><item><title>Game the Halls: GeForce NOW Brings Holiday Cheer With 30 New Games in the Cloud (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-dec-2025/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: The Game Pass edition of ‘Hogwarts Legacy’ will also be supported on GeForce NOW when the Steam and Epic Games Store versions launch on the service later this month.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;GeForce NOW is decking the digital halls with 30 new games to keep spirits high all month long.&lt;/p&gt;
&lt;p&gt;Join the fun with &lt;i&gt;Hogwarts Legacy&lt;/i&gt;, the&lt;i&gt; LEGO Harry Potter Collection&lt;/i&gt; and a sleighful of new adventures streaming straight from the cloud.&lt;/p&gt;
&lt;p&gt;The “Half-Price Holiday” sale keeps the savings rolling after Black Friday, with premium GeForce NOW memberships available at 50% off for the first month for a limited time.&lt;/p&gt;
&lt;p&gt;And GeForce NOW is bringing members a new way to jump into the worlds of some of the most iconic games. Stream select Activision titles through Ubisoft+ Premium in the cloud for GeForce RTX power&amp;nbsp; — including &lt;i&gt;Call of Duty: Modern Warfare II&lt;/i&gt;,&lt;i&gt; Call of Duty: Modern Warfare III&lt;/i&gt;,&lt;i&gt; Crash Bandicoot N. Sane Trilogy&lt;/i&gt; and the &lt;i&gt;Spyro Reignited Trilogy&lt;/i&gt;, with more to come.&lt;/p&gt;
&lt;p&gt;That’s not all: Battle.net single sign-on is now live, making it easier than ever for members to leap into &lt;i&gt;Overwatch 2, Diablo IV&lt;/i&gt; and other titles without multiple logins. Link once and play instantly, no matter the device.&lt;/p&gt;
&lt;p&gt;Plus, the GeForce NOW Community Video Contest is rolling on — creators are decking the halls with epic clips and their merriest cloud gaming moments from all over the world. There’s still time to jump in with a clip of a favorite game or a memorable match. Submit a clip and score two Ultimate day passes — one to share with a friend and one to keep — plus a chance to win a one-year Ultimate membership.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Half-Price Holiday&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88064"&gt;&lt;img alt="Half Off Holiday sale on GFN" class="size-large wp-image-88064" height="869" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-HolidaySale_ProductMatrix-1680x869.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88064"&gt;&lt;em&gt;Wrap up the year with half off.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The holiday season continues with more ways to play. Even after Black Friday, GeForce NOW is keeping the celebration going with its “Half-Price Holiday” offer.&lt;/p&gt;
&lt;p&gt;For a limited time, premium memberships are half off for the first month. Performance and Ultimate tiers unlock shorter queue times, longer gaming sessions and access to more than 2,000 additional Install-to-Play titles powered by GeForce RTX in the cloud.&lt;/p&gt;
&lt;p&gt;The “Half-Price Holiday” sale is the perfect opportunity to experience premium gaming at a fraction of the cost and keep the winter gaming streak alive. The sale wraps up on Tuesday, Dec. 30, while supplies last, so now’s the time to lock in that first month at half off and head into the new year with the GeForce NOW premium experience.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Auto Sign-In, Auto Win&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88067"&gt;&lt;img alt="Battle.net SSO on GFN" class="size-full wp-image-88067" height="724" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Battlenet_-SSO.png" width="1191" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88067"&gt;&lt;em&gt;One login, endless worlds.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce NOW is making it easier than ever for members to jump into games from Blizzard Entertainment, Activision and more. Starting today, members can link their Battle.net accounts directly to GeForce NOW for automatic single sign-on across all supported devices.&lt;/p&gt;
&lt;p&gt;After a quick one-time setup, members are automatically logged in for future cloud gaming sessions — no extra steps, no password juggling, just instant access to Battle.net favorites like &lt;i&gt;Overwatch 2&lt;/i&gt; and &lt;i&gt;Diablo IV&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;The update expands on existing automatic login support for Xbox, Epic Games and Ubisoft, further streamlining the GeForce NOW cloud gaming experience. Whether at home or on the go, members can enjoy faster, simpler, smoother access to the games they love.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Very GeForce NOW December&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88070"&gt;&lt;img alt="Octopath Traveler 0 on GFN" class="size-large wp-image-88070" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Octopath_Travelers_0-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88070"&gt;&lt;em&gt;Eight travelers, one very GeForce NOW cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Square Enix’s &lt;i&gt;Octopath Traveler 0&lt;/i&gt; brings the series’ signature wanderlust and quiet drama back to Orsterra, this time with a fresh cast and a few extra tricks up each traveler’s sleeve. The prequel leans into sharp character banter, devious Path Actions and choices that can charm, swindle or strong-arm just about anyone in the way. Expect rich pixel art, big feelings and plenty of scheming as players embark on an adventure of their own creation, navigating revenge and restoration.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;MARVEL Cosmic Invasion &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 1)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Modern Warfare II&lt;/i&gt; (New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Modern Warfare III &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Crash Bandicoot N. Sane Trilogy &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;XOCIETY &lt;/i&gt;(New release on Epic Games Store, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Spyro Reignited Trilogy &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Lost Records: Bloom &amp;amp; Rage &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;OCTOPATH TRAVELER 0 &lt;/i&gt;(New release on Steam, Dec. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ROUTINE&lt;/i&gt; (New release on Steam and Xbox, available on Game Pass, Dec. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;MIMESIS &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready games:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Enshrouded &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Fallout 76 &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Catch the full list of games coming to the cloud in December:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Dome Keeper &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Death Howl &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Everdream Village &lt;/i&gt;(New release on Steam, Dec. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ARC Raiders &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Dying Light: The Beast &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Citizen Sleeper &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;For the King II &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Jurassic World Evolution 3 &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Hogwarts Legacy&lt;/i&gt; (Steam, Epic Games Store, and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;LEGO Harry Potter Collection&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Lara Croft and the Temple of Osiris &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Pigeon Simulator &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Pacific Drive &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Powerwash Simulator 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Shape of Dreams &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Storage Hunter Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sword of the Sea &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Underground Garage &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Warhammer 40,000: SPACE MARINE 2 &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Witchfire &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;‘Tis the Season for Extra Games&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 23 games announced in November, an extra 10 joined over the month:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Apollo Justice: Ace Attorney Trilogy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Crew Motorfest&lt;/i&gt; (Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Cricket 26 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kill It With Fire &lt;/i&gt;(Xbox, available on PC Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Moonlighter 2: The Endless Vault&lt;/i&gt; (Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Of Ash and Steel &lt;/i&gt;(Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prologue: Go Wayback! &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sacred 2 Remaster &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Songs of Silence&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Zero Hour&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To improve the overall quality of service for the most played games on GeForce NOW, members will see movement of games in the catalog. Some titles with little-to-no playtime that are currently available in the Ready-to-Play catalog will start moving to Install-to-Play on December 12. Premium members can continue to play these games as part of their Install-to-Play benefits. See this article for details.&lt;/p&gt;
&lt;p&gt;Some of the most popular Install-to-Play games — including &lt;i&gt;Megabonk, R.E.P.O &lt;/i&gt;&amp;nbsp;and &lt;i&gt;RV There Yet? &lt;/i&gt;— have moved to Ready-to-Play, so they’ll always be kept up to date for instant streaming.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Health pots, extra weapons, alternate armor  — what's an item you never remove from your inventory?🎒&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) December 3, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: The Game Pass edition of ‘Hogwarts Legacy’ will also be supported on GeForce NOW when the Steam and Epic Games Store versions launch on the service later this month.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;GeForce NOW is decking the digital halls with 30 new games to keep spirits high all month long.&lt;/p&gt;
&lt;p&gt;Join the fun with &lt;i&gt;Hogwarts Legacy&lt;/i&gt;, the&lt;i&gt; LEGO Harry Potter Collection&lt;/i&gt; and a sleighful of new adventures streaming straight from the cloud.&lt;/p&gt;
&lt;p&gt;The “Half-Price Holiday” sale keeps the savings rolling after Black Friday, with premium GeForce NOW memberships available at 50% off for the first month for a limited time.&lt;/p&gt;
&lt;p&gt;And GeForce NOW is bringing members a new way to jump into the worlds of some of the most iconic games. Stream select Activision titles through Ubisoft+ Premium in the cloud for GeForce RTX power&amp;nbsp; — including &lt;i&gt;Call of Duty: Modern Warfare II&lt;/i&gt;,&lt;i&gt; Call of Duty: Modern Warfare III&lt;/i&gt;,&lt;i&gt; Crash Bandicoot N. Sane Trilogy&lt;/i&gt; and the &lt;i&gt;Spyro Reignited Trilogy&lt;/i&gt;, with more to come.&lt;/p&gt;
&lt;p&gt;That’s not all: Battle.net single sign-on is now live, making it easier than ever for members to leap into &lt;i&gt;Overwatch 2, Diablo IV&lt;/i&gt; and other titles without multiple logins. Link once and play instantly, no matter the device.&lt;/p&gt;
&lt;p&gt;Plus, the GeForce NOW Community Video Contest is rolling on — creators are decking the halls with epic clips and their merriest cloud gaming moments from all over the world. There’s still time to jump in with a clip of a favorite game or a memorable match. Submit a clip and score two Ultimate day passes — one to share with a friend and one to keep — plus a chance to win a one-year Ultimate membership.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Half-Price Holiday&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88064"&gt;&lt;img alt="Half Off Holiday sale on GFN" class="size-large wp-image-88064" height="869" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-HolidaySale_ProductMatrix-1680x869.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88064"&gt;&lt;em&gt;Wrap up the year with half off.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The holiday season continues with more ways to play. Even after Black Friday, GeForce NOW is keeping the celebration going with its “Half-Price Holiday” offer.&lt;/p&gt;
&lt;p&gt;For a limited time, premium memberships are half off for the first month. Performance and Ultimate tiers unlock shorter queue times, longer gaming sessions and access to more than 2,000 additional Install-to-Play titles powered by GeForce RTX in the cloud.&lt;/p&gt;
&lt;p&gt;The “Half-Price Holiday” sale is the perfect opportunity to experience premium gaming at a fraction of the cost and keep the winter gaming streak alive. The sale wraps up on Tuesday, Dec. 30, while supplies last, so now’s the time to lock in that first month at half off and head into the new year with the GeForce NOW premium experience.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Auto Sign-In, Auto Win&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88067"&gt;&lt;img alt="Battle.net SSO on GFN" class="size-full wp-image-88067" height="724" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Battlenet_-SSO.png" width="1191" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88067"&gt;&lt;em&gt;One login, endless worlds.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce NOW is making it easier than ever for members to jump into games from Blizzard Entertainment, Activision and more. Starting today, members can link their Battle.net accounts directly to GeForce NOW for automatic single sign-on across all supported devices.&lt;/p&gt;
&lt;p&gt;After a quick one-time setup, members are automatically logged in for future cloud gaming sessions — no extra steps, no password juggling, just instant access to Battle.net favorites like &lt;i&gt;Overwatch 2&lt;/i&gt; and &lt;i&gt;Diablo IV&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;The update expands on existing automatic login support for Xbox, Epic Games and Ubisoft, further streamlining the GeForce NOW cloud gaming experience. Whether at home or on the go, members can enjoy faster, simpler, smoother access to the games they love.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Very GeForce NOW December&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88070"&gt;&lt;img alt="Octopath Traveler 0 on GFN" class="size-large wp-image-88070" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Octopath_Travelers_0-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88070"&gt;&lt;em&gt;Eight travelers, one very GeForce NOW cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Square Enix’s &lt;i&gt;Octopath Traveler 0&lt;/i&gt; brings the series’ signature wanderlust and quiet drama back to Orsterra, this time with a fresh cast and a few extra tricks up each traveler’s sleeve. The prequel leans into sharp character banter, devious Path Actions and choices that can charm, swindle or strong-arm just about anyone in the way. Expect rich pixel art, big feelings and plenty of scheming as players embark on an adventure of their own creation, navigating revenge and restoration.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;MARVEL Cosmic Invasion &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 1)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Modern Warfare II&lt;/i&gt; (New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Modern Warfare III &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Crash Bandicoot N. Sane Trilogy &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;XOCIETY &lt;/i&gt;(New release on Epic Games Store, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Spyro Reignited Trilogy &lt;/i&gt;(New release on Ubisoft, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Lost Records: Bloom &amp;amp; Rage &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 2)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;OCTOPATH TRAVELER 0 &lt;/i&gt;(New release on Steam, Dec. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ROUTINE&lt;/i&gt; (New release on Steam and Xbox, available on Game Pass, Dec. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;MIMESIS &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready games:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Enshrouded &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Fallout 76 &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Catch the full list of games coming to the cloud in December:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Dome Keeper &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Death Howl &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Everdream Village &lt;/i&gt;(New release on Steam, Dec. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ARC Raiders &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Dying Light: The Beast &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Citizen Sleeper &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;For the King II &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Jurassic World Evolution 3 &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Hogwarts Legacy&lt;/i&gt; (Steam, Epic Games Store, and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;LEGO Harry Potter Collection&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Lara Croft and the Temple of Osiris &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Pigeon Simulator &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Pacific Drive &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Powerwash Simulator 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Shape of Dreams &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Storage Hunter Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sword of the Sea &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Underground Garage &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Warhammer 40,000: SPACE MARINE 2 &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Witchfire &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;‘Tis the Season for Extra Games&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 23 games announced in November, an extra 10 joined over the month:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Apollo Justice: Ace Attorney Trilogy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Crew Motorfest&lt;/i&gt; (Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Cricket 26 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kill It With Fire &lt;/i&gt;(Xbox, available on PC Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Moonlighter 2: The Endless Vault&lt;/i&gt; (Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Of Ash and Steel &lt;/i&gt;(Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prologue: Go Wayback! &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sacred 2 Remaster &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Songs of Silence&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Zero Hour&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To improve the overall quality of service for the most played games on GeForce NOW, members will see movement of games in the catalog. Some titles with little-to-no playtime that are currently available in the Ready-to-Play catalog will start moving to Install-to-Play on December 12. Premium members can continue to play these games as part of their Install-to-Play benefits. See this article for details.&lt;/p&gt;
&lt;p&gt;Some of the most popular Install-to-Play games — including &lt;i&gt;Megabonk, R.E.P.O &lt;/i&gt;&amp;nbsp;and &lt;i&gt;RV There Yet? &lt;/i&gt;— have moved to Ready-to-Play, so they’ll always be kept up to date for instant streaming.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Health pots, extra weapons, alternate armor  — what's an item you never remove from your inventory?🎒&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) December 3, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-dec-2025/</guid><pubDate>Thu, 04 Dec 2025 14:00:37 +0000</pubDate></item><item><title>AWS launches Kiro powers with Stripe, Figma, and Datadog integrations for AI-assisted coding (AI | VentureBeat)</title><link>https://venturebeat.com/ai/aws-launches-kiro-powers-with-stripe-figma-and-datadog-integrations-for-ai</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt; on Wednesday introduced &lt;a href="https://kiro.dev/blog/introducing-powers/"&gt;Kiro powers&lt;/a&gt;, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how artificial intelligence agents operate today.&lt;/p&gt;&lt;p&gt;AWS made the announcement at its annual &lt;a href="https://reinvent.awsevents.com/"&gt;re:Invent conference&lt;/a&gt; in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.&lt;/p&gt;&lt;p&gt;&amp;quot;Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,&amp;quot; said Deepak Singh, Vice President of Developer Agents and Experiences at Amazon, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;The launch includes partnerships with nine technology companies: &lt;a href="https://www.datadoghq.com/"&gt;Datadog&lt;/a&gt;, &lt;a href="https://www.dynatrace.com/"&gt;Dynatrace&lt;/a&gt;, &lt;a href="https://www.figma.com/"&gt;Figma&lt;/a&gt;, &lt;a href="https://neon.com/"&gt;Neon&lt;/a&gt;, &lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt;, &lt;a href="https://www.postman.com/"&gt;Postman&lt;/a&gt;, &lt;a href="https://stripe.com/"&gt;Stripe&lt;/a&gt;, &lt;a href="https://supabase.com/"&gt;Supabase&lt;/a&gt;, and AWS&amp;#x27;s own services. Developers can also create and share their own powers with the community.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI coding assistants choke when developers connect too many tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To understand why &lt;a href="https://kiro.dev/"&gt;Kiro&lt;/a&gt; powers matters, it helps to understand a growing tension in the AI development tool market.&lt;/p&gt;&lt;p&gt;Modern AI coding assistants rely on something called the &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;, or MCP, to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design, and Supabase for databases, they connect MCP servers for each service.&lt;/p&gt;&lt;p&gt;The problem: each connection loads dozens of tool definitions into the AI&amp;#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40 percent of an AI model&amp;#x27;s context window — before the developer even types their first request.&lt;/p&gt;&lt;p&gt;Developers have grown increasingly vocal about this issue. Many complain that they don&amp;#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.&lt;/p&gt;&lt;p&gt;This phenomenon, which some in the industry call &amp;quot;context rot,&amp;quot; leads to slower responses, lower-quality outputs, and significantly higher costs — since AI services typically charge by the token.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the technology that loads AI expertise on demand&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Kiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.&lt;/p&gt;&lt;p&gt;The first component is a steering file called POWER.md, which functions as an onboarding manual for the AI agent. It tells the agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.&lt;/p&gt;&lt;p&gt;When a developer mentions &amp;quot;payment&amp;quot; or &amp;quot;checkout&amp;quot; in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.&lt;/p&gt;&lt;p&gt;&amp;quot;You click a button and it automatically loads,&amp;quot; Singh said. &amp;quot;Once a power has been created, developers just select &amp;#x27;open in Kiro&amp;#x27; and it launches the IDE with everything ready to go.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How AWS is bringing elite developer techniques to the masses&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Singh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts, and manually managing which tools were active at any given time.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve found that our developers were adding in capabilities to make their agents more specialized,&amp;quot; Singh said. &amp;quot;They wanted to give the agent some special powers to do a specific problem. For example, they wanted their front end developer, and they wanted the agent to become an expert at backend as a service.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation led to a key insight: if Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.&lt;/p&gt;&lt;p&gt;&amp;quot;Kiro powers formalizes that — things that people, only the most advanced people were doing — and allows anyone to get those kind of skills,&amp;quot; Singh said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why dynamic loading beats fine-tuning for most AI coding use cases&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement also positions Kiro powers as a more economical alternative to fine-tuning, the process of training an AI model on specialized data to improve its performance in specific domains.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s much cheaper,&amp;quot; Singh said, when asked how powers compare to fine-tuning. &amp;quot;Fine-tuning is very expensive, and you can&amp;#x27;t fine-tune most frontier models.&amp;quot;&lt;/p&gt;&lt;p&gt;This is a significant point. The most capable AI models from &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt; are typically &amp;quot;closed source,&amp;quot; meaning developers cannot modify their underlying training. They can only influence the models&amp;#x27; behavior through the prompts and context they provide.&lt;/p&gt;&lt;p&gt;&amp;quot;Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,&amp;quot; Singh said. &amp;quot;What those models need is to be pointed in the right direction.&amp;quot;&lt;/p&gt;&lt;p&gt;The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&amp;#x27;t paying for token usage on tools they&amp;#x27;re not currently using.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where Kiro powers fits in Amazon&amp;#x27;s bigger bet on autonomous AI agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Kiro powers arrives as part of a broader push by AWS into what the company calls &amp;quot;agentic AI&amp;quot; — artificial intelligence systems that can operate autonomously over extended periods.&lt;/p&gt;&lt;p&gt;Earlier at re:Invent, AWS announced three &amp;quot;&lt;a href="https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for"&gt;frontier agents&lt;/a&gt;&amp;quot; designed to work for hours or days without human intervention: the Kiro autonomous agent for software development, the AWS security agent, and the AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.&lt;/p&gt;&lt;p&gt;The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.&lt;/p&gt;&lt;p&gt;The company is betting that developers need both ends of this spectrum to be productive.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Kiro powers reveals about the future of AI-assisted software development&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt;, &lt;a href="https://cline.bot/"&gt;Cline&lt;/a&gt;, and &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt; — have competed for developers&amp;#x27; attention.&lt;/p&gt;&lt;p&gt;But as these tools have grown more capable, they&amp;#x27;ve also grown more complex. The &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: the context overload that Kiro powers now addresses.&lt;/p&gt;&lt;p&gt;AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&amp;#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s not something you would use just for your prototype or your toy application,&amp;quot; Singh said of AWS&amp;#x27;s AI development tools. &amp;quot;If you want to build production applications, there&amp;#x27;s a lot of knowledge that we bring in as AWS that applies here.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The road ahead for Kiro powers and cross-platform compatibility&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;AWS indicated that Kiro powers currently works only within the &lt;a href="https://kiro.dev/"&gt;Kiro IDE&lt;/a&gt;, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt;, &lt;a href="https://cline.bot/"&gt;Cline&lt;/a&gt;, and &lt;a href="https://www.claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;. The company&amp;#x27;s documentation describes a future where developers can &amp;quot;build a power once, use it anywhere&amp;quot; — though that vision remains aspirational for now.&lt;/p&gt;&lt;p&gt;For the technology partners launching powers today, the appeal is straightforward: rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd into the market, that kind of efficiency becomes increasingly valuable.&lt;/p&gt;&lt;p&gt;Kiro powers is &lt;a href="https://kiro.dev/blog/introducing-powers/"&gt;available now&lt;/a&gt; to developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.&lt;/p&gt;&lt;p&gt;The underlying bet is a familiar one in the history of computing: that the winners in AI-assisted development won&amp;#x27;t be the tools that try to do everything at once, but the ones smart enough to know what to forget.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt; on Wednesday introduced &lt;a href="https://kiro.dev/blog/introducing-powers/"&gt;Kiro powers&lt;/a&gt;, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how artificial intelligence agents operate today.&lt;/p&gt;&lt;p&gt;AWS made the announcement at its annual &lt;a href="https://reinvent.awsevents.com/"&gt;re:Invent conference&lt;/a&gt; in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.&lt;/p&gt;&lt;p&gt;&amp;quot;Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,&amp;quot; said Deepak Singh, Vice President of Developer Agents and Experiences at Amazon, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;The launch includes partnerships with nine technology companies: &lt;a href="https://www.datadoghq.com/"&gt;Datadog&lt;/a&gt;, &lt;a href="https://www.dynatrace.com/"&gt;Dynatrace&lt;/a&gt;, &lt;a href="https://www.figma.com/"&gt;Figma&lt;/a&gt;, &lt;a href="https://neon.com/"&gt;Neon&lt;/a&gt;, &lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt;, &lt;a href="https://www.postman.com/"&gt;Postman&lt;/a&gt;, &lt;a href="https://stripe.com/"&gt;Stripe&lt;/a&gt;, &lt;a href="https://supabase.com/"&gt;Supabase&lt;/a&gt;, and AWS&amp;#x27;s own services. Developers can also create and share their own powers with the community.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI coding assistants choke when developers connect too many tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To understand why &lt;a href="https://kiro.dev/"&gt;Kiro&lt;/a&gt; powers matters, it helps to understand a growing tension in the AI development tool market.&lt;/p&gt;&lt;p&gt;Modern AI coding assistants rely on something called the &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;, or MCP, to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design, and Supabase for databases, they connect MCP servers for each service.&lt;/p&gt;&lt;p&gt;The problem: each connection loads dozens of tool definitions into the AI&amp;#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40 percent of an AI model&amp;#x27;s context window — before the developer even types their first request.&lt;/p&gt;&lt;p&gt;Developers have grown increasingly vocal about this issue. Many complain that they don&amp;#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.&lt;/p&gt;&lt;p&gt;This phenomenon, which some in the industry call &amp;quot;context rot,&amp;quot; leads to slower responses, lower-quality outputs, and significantly higher costs — since AI services typically charge by the token.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the technology that loads AI expertise on demand&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Kiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.&lt;/p&gt;&lt;p&gt;The first component is a steering file called POWER.md, which functions as an onboarding manual for the AI agent. It tells the agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.&lt;/p&gt;&lt;p&gt;When a developer mentions &amp;quot;payment&amp;quot; or &amp;quot;checkout&amp;quot; in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.&lt;/p&gt;&lt;p&gt;&amp;quot;You click a button and it automatically loads,&amp;quot; Singh said. &amp;quot;Once a power has been created, developers just select &amp;#x27;open in Kiro&amp;#x27; and it launches the IDE with everything ready to go.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How AWS is bringing elite developer techniques to the masses&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Singh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts, and manually managing which tools were active at any given time.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve found that our developers were adding in capabilities to make their agents more specialized,&amp;quot; Singh said. &amp;quot;They wanted to give the agent some special powers to do a specific problem. For example, they wanted their front end developer, and they wanted the agent to become an expert at backend as a service.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation led to a key insight: if Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.&lt;/p&gt;&lt;p&gt;&amp;quot;Kiro powers formalizes that — things that people, only the most advanced people were doing — and allows anyone to get those kind of skills,&amp;quot; Singh said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why dynamic loading beats fine-tuning for most AI coding use cases&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement also positions Kiro powers as a more economical alternative to fine-tuning, the process of training an AI model on specialized data to improve its performance in specific domains.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s much cheaper,&amp;quot; Singh said, when asked how powers compare to fine-tuning. &amp;quot;Fine-tuning is very expensive, and you can&amp;#x27;t fine-tune most frontier models.&amp;quot;&lt;/p&gt;&lt;p&gt;This is a significant point. The most capable AI models from &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt; are typically &amp;quot;closed source,&amp;quot; meaning developers cannot modify their underlying training. They can only influence the models&amp;#x27; behavior through the prompts and context they provide.&lt;/p&gt;&lt;p&gt;&amp;quot;Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,&amp;quot; Singh said. &amp;quot;What those models need is to be pointed in the right direction.&amp;quot;&lt;/p&gt;&lt;p&gt;The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&amp;#x27;t paying for token usage on tools they&amp;#x27;re not currently using.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where Kiro powers fits in Amazon&amp;#x27;s bigger bet on autonomous AI agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Kiro powers arrives as part of a broader push by AWS into what the company calls &amp;quot;agentic AI&amp;quot; — artificial intelligence systems that can operate autonomously over extended periods.&lt;/p&gt;&lt;p&gt;Earlier at re:Invent, AWS announced three &amp;quot;&lt;a href="https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for"&gt;frontier agents&lt;/a&gt;&amp;quot; designed to work for hours or days without human intervention: the Kiro autonomous agent for software development, the AWS security agent, and the AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.&lt;/p&gt;&lt;p&gt;The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.&lt;/p&gt;&lt;p&gt;The company is betting that developers need both ends of this spectrum to be productive.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Kiro powers reveals about the future of AI-assisted software development&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt;, &lt;a href="https://cline.bot/"&gt;Cline&lt;/a&gt;, and &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt; — have competed for developers&amp;#x27; attention.&lt;/p&gt;&lt;p&gt;But as these tools have grown more capable, they&amp;#x27;ve also grown more complex. The &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol&lt;/a&gt;, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: the context overload that Kiro powers now addresses.&lt;/p&gt;&lt;p&gt;AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&amp;#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s not something you would use just for your prototype or your toy application,&amp;quot; Singh said of AWS&amp;#x27;s AI development tools. &amp;quot;If you want to build production applications, there&amp;#x27;s a lot of knowledge that we bring in as AWS that applies here.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The road ahead for Kiro powers and cross-platform compatibility&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;AWS indicated that Kiro powers currently works only within the &lt;a href="https://kiro.dev/"&gt;Kiro IDE&lt;/a&gt;, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt;, &lt;a href="https://cline.bot/"&gt;Cline&lt;/a&gt;, and &lt;a href="https://www.claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;. The company&amp;#x27;s documentation describes a future where developers can &amp;quot;build a power once, use it anywhere&amp;quot; — though that vision remains aspirational for now.&lt;/p&gt;&lt;p&gt;For the technology partners launching powers today, the appeal is straightforward: rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd into the market, that kind of efficiency becomes increasingly valuable.&lt;/p&gt;&lt;p&gt;Kiro powers is &lt;a href="https://kiro.dev/blog/introducing-powers/"&gt;available now&lt;/a&gt; to developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.&lt;/p&gt;&lt;p&gt;The underlying bet is a familiar one in the history of computing: that the winners in AI-assisted development won&amp;#x27;t be the tools that try to do everything at once, but the ones smart enough to know what to forget.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/aws-launches-kiro-powers-with-stripe-figma-and-datadog-integrations-for-ai</guid><pubDate>Thu, 04 Dec 2025 14:02:00 +0000</pubDate></item><item><title>EU investigating Meta over policy change that bans rival AI chatbots from WhatsApp (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/eu-investigating-meta-over-policy-change-that-bans-rival-ai-chatbots-from-whatsapp/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/whatsapp-logo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta’s decision to serve only its AI chatbot, Meta AI, to WhatsApp users isn’t sitting well with the competition regulators in Europe. The European Commission on Thursday said it is launching an antitrust investigation into Meta’s move to ban other AI companies from using WhatsApp’s business tools to offer their own AI chatbots to users on the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp in October changed its business API policy to ban general-purpose chatbots from the chat app, saying that the API isn’t designed to be a platform for the distribution of chatbots. The policy change, which goes into effect in January, would affect the availability of AI chatbots from the likes of OpenAI, Perplexity, and Poke on the app.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this move doesn’t affect businesses that are using AI to serve customers on WhatsApp. For instance, a retailer running an AI-powered customer service bot won’t be barred from using the API. Only AI chatbots like ChatGPT are prohibited from being distributed via the API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its statement, the EU’s executive arm said it was concerned that the policy may “prevent third-party AI providers from offering their services through WhatsApp in the European Economic Area (‘EEA’).”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As a result of the new policy, competing AI providers may be blocked from reaching their customers through WhatsApp. On the other hand, Meta’s own AI service ‘Meta AI’ would remain accessible to users on the platform,” the Commission wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI markets are booming in Europe and beyond. We must ensure European citizens and businesses can benefit fully from this technological revolution and act to prevent dominant digital incumbents from abusing their power to crowd out innovative competitors,” Teresa Ribera, executive vice-president for Clean, Just and Competitive Transition at the European Commission, said in a statement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is why we are investigating if Meta’s new policy might be illegal under competition rules, and whether we should act quickly to prevent any possible irreparable harm to competition in the AI space,” Ribera said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If Meta is found guilty of breaching EU’s antitrust rules, it may be fined up to 10% of its global annual revenue, and the Commission may impose additional measures on the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp, for its part, called the EU’s claims “baseless,” and said people have many other options to use rival AI companies’ chatbots. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The emergence of AI chatbots on our Business API puts a strain on our systems that they were not designed to support,” a spokesperson for WhatsApp said in an emailed statement. “Even still, the AI space is highly competitive and people have access to the services of their choice in any number of ways, including app stores, search engines, email services, partnership integrations, and operating systems.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/whatsapp-logo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta’s decision to serve only its AI chatbot, Meta AI, to WhatsApp users isn’t sitting well with the competition regulators in Europe. The European Commission on Thursday said it is launching an antitrust investigation into Meta’s move to ban other AI companies from using WhatsApp’s business tools to offer their own AI chatbots to users on the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp in October changed its business API policy to ban general-purpose chatbots from the chat app, saying that the API isn’t designed to be a platform for the distribution of chatbots. The policy change, which goes into effect in January, would affect the availability of AI chatbots from the likes of OpenAI, Perplexity, and Poke on the app.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this move doesn’t affect businesses that are using AI to serve customers on WhatsApp. For instance, a retailer running an AI-powered customer service bot won’t be barred from using the API. Only AI chatbots like ChatGPT are prohibited from being distributed via the API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its statement, the EU’s executive arm said it was concerned that the policy may “prevent third-party AI providers from offering their services through WhatsApp in the European Economic Area (‘EEA’).”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As a result of the new policy, competing AI providers may be blocked from reaching their customers through WhatsApp. On the other hand, Meta’s own AI service ‘Meta AI’ would remain accessible to users on the platform,” the Commission wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI markets are booming in Europe and beyond. We must ensure European citizens and businesses can benefit fully from this technological revolution and act to prevent dominant digital incumbents from abusing their power to crowd out innovative competitors,” Teresa Ribera, executive vice-president for Clean, Just and Competitive Transition at the European Commission, said in a statement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is why we are investigating if Meta’s new policy might be illegal under competition rules, and whether we should act quickly to prevent any possible irreparable harm to competition in the AI space,” Ribera said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If Meta is found guilty of breaching EU’s antitrust rules, it may be fined up to 10% of its global annual revenue, and the Commission may impose additional measures on the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp, for its part, called the EU’s claims “baseless,” and said people have many other options to use rival AI companies’ chatbots. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The emergence of AI chatbots on our Business API puts a strain on our systems that they were not designed to support,” a spokesperson for WhatsApp said in an emailed statement. “Even still, the AI space is highly competitive and people have access to the services of their choice in any number of ways, including app stores, search engines, email services, partnership integrations, and operating systems.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/eu-investigating-meta-over-policy-change-that-bans-rival-ai-chatbots-from-whatsapp/</guid><pubDate>Thu, 04 Dec 2025 14:02:28 +0000</pubDate></item><item><title>Anthropic signs $200M deal to bring its LLMs to Snowflake’s customers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/anthropic-signs-200m-deal-to-bring-its-llms-to-snowflakes-customers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/Anthropic.jpg?resize=1200,650" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s not slowing down in its efforts to snap up enterprise clients. The company on Wednesday said it is expanding its partnership with cloud data company Snowflake in a $200 million multi-year AI deal that will bring Anthropic’s large language models to Snowflake’s platform and, consequently, to its sizable customer base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic joins a very select group of partners where we have nine-figure alignment, co-innovation at the product level, and a proven track record of executing together for customers worldwide,” Snowflake’s co-founder and CEO, Sridhar Ramaswamy, said in the blog post. “Together, the combined power of Claude and Snowflake is raising the bar for how enterprises deploy scalable, context-aware AI on top of their most critical business data.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This deal is also being positioned as a joint go-to-market initiative to bring AI agents to enterprise customers. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Sonnet 4.5 will power Snowflake Intelligence, the cloud company’s enterprise AI service. Snowflake said its customers will be able to tap Claude models, including Claude Opus 4.5, to run multimodal data analysis. Customers will also be able to use the models to build their own custom agents. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Enterprises have spent years building secure, trusted data environments, and now they want AI that can work within those environments without compromise,”&amp;nbsp;Dario Amodei, co-founder and CEO of Anthropic, said in a statement. “This partnership brings Claude directly into Snowflake, where that data already lives. It’s a meaningful step toward making frontier AI genuinely useful for businesses.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has struck a slew of large enterprise deals in recent months as it seeks to prioritize selling to businesses instead of individual users — a strategy in contrast to its arch-rival OpenAI, which has taken a more popular route to growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic in October signed a deal with Deloitte to bring its Claude chatbot to the consulting giant’s employee base of more than 500,000 staff. That same week, Anthropic struck a partnership with IBM to bring some of its LLMs into the latter’s software products. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s enterprise success isn’t surprising as the company’s models have garnered strong and growing traction among enterprises. A Menlo Ventures survey in July found that enterprises preferred Anthropic’s AI products over models by other AI companies. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/Anthropic.jpg?resize=1200,650" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s not slowing down in its efforts to snap up enterprise clients. The company on Wednesday said it is expanding its partnership with cloud data company Snowflake in a $200 million multi-year AI deal that will bring Anthropic’s large language models to Snowflake’s platform and, consequently, to its sizable customer base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic joins a very select group of partners where we have nine-figure alignment, co-innovation at the product level, and a proven track record of executing together for customers worldwide,” Snowflake’s co-founder and CEO, Sridhar Ramaswamy, said in the blog post. “Together, the combined power of Claude and Snowflake is raising the bar for how enterprises deploy scalable, context-aware AI on top of their most critical business data.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This deal is also being positioned as a joint go-to-market initiative to bring AI agents to enterprise customers. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Sonnet 4.5 will power Snowflake Intelligence, the cloud company’s enterprise AI service. Snowflake said its customers will be able to tap Claude models, including Claude Opus 4.5, to run multimodal data analysis. Customers will also be able to use the models to build their own custom agents. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Enterprises have spent years building secure, trusted data environments, and now they want AI that can work within those environments without compromise,”&amp;nbsp;Dario Amodei, co-founder and CEO of Anthropic, said in a statement. “This partnership brings Claude directly into Snowflake, where that data already lives. It’s a meaningful step toward making frontier AI genuinely useful for businesses.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has struck a slew of large enterprise deals in recent months as it seeks to prioritize selling to businesses instead of individual users — a strategy in contrast to its arch-rival OpenAI, which has taken a more popular route to growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic in October signed a deal with Deloitte to bring its Claude chatbot to the consulting giant’s employee base of more than 500,000 staff. That same week, Anthropic struck a partnership with IBM to bring some of its LLMs into the latter’s software products. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s enterprise success isn’t surprising as the company’s models have garnered strong and growing traction among enterprises. A Menlo Ventures survey in July found that enterprises preferred Anthropic’s AI products over models by other AI companies. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/anthropic-signs-200m-deal-to-bring-its-llms-to-snowflakes-customers/</guid><pubDate>Thu, 04 Dec 2025 14:22:03 +0000</pubDate></item><item><title>Robots’ Holiday Wishes Come True: NVIDIA Jetson Platform Offers High-Performance Edge AI at Festive Prices (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/jetson-edge-ai-holiday-2025/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Developers, researchers, hobbyists and students can take a byte out of holiday shopping this season as NVIDIA has unwrapped special discounts on the NVIDIA Jetson family of developer kits for edge AI and robotics — available through Sunday, Jan. 11.&lt;/p&gt;
&lt;p&gt;Whether tapping into the breakthrough capabilities of Jetson AGX Thor, the versatility of Jetson AGX Orin or the palm-sized power of the NVIDIA Jetson Orin Nano Super Developer Kit, anyone can deck out their bots with greater physical AI performance for lower costs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Jetson AGX Thor Developer Kit — now 20% off — is designed for building humanoid robots, fleets of autonomous machines and multimodal physical AI agents. It delivers server-class compute and generative AI capabilities for the most challenging workloads in labs, factories and the field.&lt;/li&gt;
&lt;li&gt;The Jetson AGX Orin Developer Kit — now 50% off — powers advanced robots, autonomous machines and generative AI at the edge with 275 trillion operations per second (TOPS) of AI performance, ideal for delivery bots, smart vision capabilities and industrial automation.&lt;/li&gt;
&lt;li&gt;The Jetson Orin Nano Super Developer Kit — the world’s most affordable generative AI supercomputer — offers desktop-class AI in a palm-sized kit for exploring, building and deploying cutting-edge generative AI, vision and robotics.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Read more below on how the NVIDIA Jetson platform presents the future of robotics.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Jetson Orin Nano Super Serves as Brain of Self-Paddling Canoe&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Robotics enthusiast Dave Niewinski has built a self‑paddling canoe using the Jetson Orin Nano Super Developer Kit, letting boaters relax and glide on their rides.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The robotic boat integrates two six-axis robotic arms mounted on a lightweight canoe frame, with paddle motion controlled through ROS software and AI algorithms.&lt;/p&gt;
&lt;p&gt;The Jetson Orin Nano Super delivers up to 67 INT8 TOPS of AI performance through its NVIDIA Ampere architecture GPU, 32 Tensor Cores and 1,024 CUDA cores, alongside a six-core Arm Cortex‑A78AE CPU and 8GB LPDDR5 memory with 102 GB/s bandwidth.&lt;/p&gt;
&lt;p&gt;Its low power envelope of up to 25 watts enables sustained real-time inference and control in mobile, battery-powered applications.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA AGX Orin Dives Into Open Seas on Underwater AI System&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;OptoScale, an AI aquaculture company based in Norway, has integrated the Jetson AGX Orin-powered MX13/23 platform from edge AI solutions provider Aetina to build an underwater AI sensing system that monitors fish health in massive open-sea pens housing thousands of fish.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-88085" height="442" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/optoscale-960x442.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Mounted inside a submerged camera module, the Jetson AGX Orin processes high-resolution video streams directly at the edge and runs real-time vision models on the device. This allows the system to estimate biomass with exceptional accuracy and deliver continuous inference-based insights even in remote environments with limited connectivity.&lt;/p&gt;
&lt;p&gt;The Jetson AGX Orin delivers powerful GPU acceleration and high TOPS AI performance in a compact, energy-efficient module ideal for deployment anywhere.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Jetson AGX Thor Powers Mobile Humanoid ‘Dex’&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Las Vegas-based Richtech Robotics is developing Dex, a mobile humanoid robot for factory and warehouse environments designed to handle light-to medium-weight industrial tasks like machine operation, parts sorting, material handling and packaging.&lt;/p&gt;

&lt;p&gt;Running on NVIDIA Jetson AGX Thor, Dex combines the mobility of an autonomous wheeled platform with the precision of dual-arm dexterity, allowing it to efficiently navigate environments and pick and place objects. It was trained with a mix of real-world and synthetic data generated from NVIDIA Isaac Sim.&lt;/p&gt;
&lt;p&gt;NVIDIA Jetson Thor modules enable real-time reasoning for physical AI, delivering up to 2,070 FP4 teraflops of AI compute and 128GB of memory with power configurable between 40-130 watts.&lt;/p&gt;
&lt;p&gt;With discounted pricing for a limited time and a full spectrum of performance options, the NVIDIA Jetson family gives anyone the tools to design, build and deploy the next generation of intelligent machines. It’s the ideal gift for robot lovers — and the robots in their lives.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Shop NVIDIA Jetson now&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Developers, researchers, hobbyists and students can take a byte out of holiday shopping this season as NVIDIA has unwrapped special discounts on the NVIDIA Jetson family of developer kits for edge AI and robotics — available through Sunday, Jan. 11.&lt;/p&gt;
&lt;p&gt;Whether tapping into the breakthrough capabilities of Jetson AGX Thor, the versatility of Jetson AGX Orin or the palm-sized power of the NVIDIA Jetson Orin Nano Super Developer Kit, anyone can deck out their bots with greater physical AI performance for lower costs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Jetson AGX Thor Developer Kit — now 20% off — is designed for building humanoid robots, fleets of autonomous machines and multimodal physical AI agents. It delivers server-class compute and generative AI capabilities for the most challenging workloads in labs, factories and the field.&lt;/li&gt;
&lt;li&gt;The Jetson AGX Orin Developer Kit — now 50% off — powers advanced robots, autonomous machines and generative AI at the edge with 275 trillion operations per second (TOPS) of AI performance, ideal for delivery bots, smart vision capabilities and industrial automation.&lt;/li&gt;
&lt;li&gt;The Jetson Orin Nano Super Developer Kit — the world’s most affordable generative AI supercomputer — offers desktop-class AI in a palm-sized kit for exploring, building and deploying cutting-edge generative AI, vision and robotics.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Read more below on how the NVIDIA Jetson platform presents the future of robotics.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Jetson Orin Nano Super Serves as Brain of Self-Paddling Canoe&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Robotics enthusiast Dave Niewinski has built a self‑paddling canoe using the Jetson Orin Nano Super Developer Kit, letting boaters relax and glide on their rides.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The robotic boat integrates two six-axis robotic arms mounted on a lightweight canoe frame, with paddle motion controlled through ROS software and AI algorithms.&lt;/p&gt;
&lt;p&gt;The Jetson Orin Nano Super delivers up to 67 INT8 TOPS of AI performance through its NVIDIA Ampere architecture GPU, 32 Tensor Cores and 1,024 CUDA cores, alongside a six-core Arm Cortex‑A78AE CPU and 8GB LPDDR5 memory with 102 GB/s bandwidth.&lt;/p&gt;
&lt;p&gt;Its low power envelope of up to 25 watts enables sustained real-time inference and control in mobile, battery-powered applications.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA AGX Orin Dives Into Open Seas on Underwater AI System&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;OptoScale, an AI aquaculture company based in Norway, has integrated the Jetson AGX Orin-powered MX13/23 platform from edge AI solutions provider Aetina to build an underwater AI sensing system that monitors fish health in massive open-sea pens housing thousands of fish.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-88085" height="442" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/optoscale-960x442.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Mounted inside a submerged camera module, the Jetson AGX Orin processes high-resolution video streams directly at the edge and runs real-time vision models on the device. This allows the system to estimate biomass with exceptional accuracy and deliver continuous inference-based insights even in remote environments with limited connectivity.&lt;/p&gt;
&lt;p&gt;The Jetson AGX Orin delivers powerful GPU acceleration and high TOPS AI performance in a compact, energy-efficient module ideal for deployment anywhere.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Jetson AGX Thor Powers Mobile Humanoid ‘Dex’&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Las Vegas-based Richtech Robotics is developing Dex, a mobile humanoid robot for factory and warehouse environments designed to handle light-to medium-weight industrial tasks like machine operation, parts sorting, material handling and packaging.&lt;/p&gt;

&lt;p&gt;Running on NVIDIA Jetson AGX Thor, Dex combines the mobility of an autonomous wheeled platform with the precision of dual-arm dexterity, allowing it to efficiently navigate environments and pick and place objects. It was trained with a mix of real-world and synthetic data generated from NVIDIA Isaac Sim.&lt;/p&gt;
&lt;p&gt;NVIDIA Jetson Thor modules enable real-time reasoning for physical AI, delivering up to 2,070 FP4 teraflops of AI compute and 128GB of memory with power configurable between 40-130 watts.&lt;/p&gt;
&lt;p&gt;With discounted pricing for a limited time and a full spectrum of performance options, the NVIDIA Jetson family gives anyone the tools to design, build and deploy the next generation of intelligent machines. It’s the ideal gift for robot lovers — and the robots in their lives.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Shop NVIDIA Jetson now&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/jetson-edge-ai-holiday-2025/</guid><pubDate>Thu, 04 Dec 2025 16:00:07 +0000</pubDate></item><item><title>Meta reportedly plans to slash Metaverse budget by up to 30% (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/meta-reportedly-plans-to-slash-metaverse-budget-by-up-to-30/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta may be planning to make serious cuts to its Metaverse division, Bloomberg reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Company executives are mulling slashing the virtual reality platform’s budget by up to 30%, the report said, adding that any reductions would also include layoffs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If Meta does go ahead with such a plan, the move would reflect the overall lack of interest in products like Meta’s social virtual reality platform Horizon Worlds, as well as its virtual reality hardware — both in the industry at large, as well as among consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Meta’s rebrand in 2021, investors have been skeptical of the company’s allocation of resources to Metaverse projects, which lose billions of dollars each quarter. The company’s efforts in AI and smart glasses have been more successful, though investors still worry that its investment plans are too steep.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s shares rose, however, following this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately respond to a request for comment.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta may be planning to make serious cuts to its Metaverse division, Bloomberg reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Company executives are mulling slashing the virtual reality platform’s budget by up to 30%, the report said, adding that any reductions would also include layoffs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If Meta does go ahead with such a plan, the move would reflect the overall lack of interest in products like Meta’s social virtual reality platform Horizon Worlds, as well as its virtual reality hardware — both in the industry at large, as well as among consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Meta’s rebrand in 2021, investors have been skeptical of the company’s allocation of resources to Metaverse projects, which lose billions of dollars each quarter. The company’s efforts in AI and smart glasses have been more successful, though investors still worry that its investment plans are too steep.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s shares rose, however, following this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately respond to a request for comment.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/meta-reportedly-plans-to-slash-metaverse-budget-by-up-to-30/</guid><pubDate>Thu, 04 Dec 2025 16:08:27 +0000</pubDate></item><item><title>Engineering more resilient crops for a warming climate (Google DeepMind News)</title><link>https://deepmind.google/blog/engineering-more-resilient-crops-for-a-warming-climate/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/SmNXY162ZZ5ADiU59tS5YPlCdCd7A7G8ubHeSH8CAyniaPAUUEvrNUm_u7ve1S7QGpNjajkmrQWzSz-ZTG58RNRVVl8GEFcajpTK7rA6VCFnMdC0=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p class="lead-paragraph"&gt;Scientists are using AlphaFold in their research to strengthen an enzyme that’s vital to photosynthesis, paving the way for more heat-tolerant crops.&lt;/p&gt;&lt;p&gt;As global warming accompanies more droughts and heatwaves, harvests of some staple crops are shrinking. But less visible is what is happening inside these plants, where high heat can break down the molecular machinery that keeps them alive.&lt;/p&gt;&lt;p&gt;At the heart of that machinery lies a sun-powered process that supports virtually all life on Earth: photosynthesis. Plants use photosynthesis to produce the glucose that fuels their growth via an intricate choreography of enzymes inside plant cells. As global temperatures rise, that choreography can falter.&lt;/p&gt;&lt;p&gt;Berkley Walker, an associate professor at Michigan State University, spends his days thinking about how to keep that choreography in step. "Nature already holds the blueprints for lots of enzymes that can handle heat," he says. "Our job is to learn from those examples and build that same resilience into the crops we depend on."&lt;/p&gt;&lt;p&gt;Walker’s lab focuses on a vital enzyme in photosynthesis called glycerate kinase (GLYK), an enzyme that helps plants recycle carbon during photosynthesis.One hypothesis is that, if it gets too hot, GLYK stops working, and photosynthesis fails.&lt;/p&gt;&lt;p&gt;Walker’s team set out to understand why. Because the structure of GLYK has never been determined experimentally, they turned to AlphaFold to predict its 3D shape, not only in plants but also in a heat-loving algae that thrives in volcanic hot springs. By taking AlphaFold’s predicted shapes and plugging them into sophisticated molecular simulations, the researchers could watch as these enzymes flexed and twisted as the temperature rose.&lt;/p&gt;&lt;p&gt;That’s when the problem came into focus: three flexible loops in the plant version of GLYK wobbled out of shape at high heat.&lt;/p&gt;&lt;p&gt;Experiments alone could never deliver such insights, says Walker: “AlphaFold enabled access to experimentally unavailable enzyme structures and helped us identify key sections for modification.”&lt;/p&gt;&lt;p&gt;Armed with this knowledge, the researchers in Walker’s lab made a series of hybrid enzymes that replaced the unstable loops in the plant GLYK with more rigid ones borrowed from the algae’s GLYK. One of these performed spectacularly, remaining stable at temperatures up to 65 °C.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/SmNXY162ZZ5ADiU59tS5YPlCdCd7A7G8ubHeSH8CAyniaPAUUEvrNUm_u7ve1S7QGpNjajkmrQWzSz-ZTG58RNRVVl8GEFcajpTK7rA6VCFnMdC0=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p class="lead-paragraph"&gt;Scientists are using AlphaFold in their research to strengthen an enzyme that’s vital to photosynthesis, paving the way for more heat-tolerant crops.&lt;/p&gt;&lt;p&gt;As global warming accompanies more droughts and heatwaves, harvests of some staple crops are shrinking. But less visible is what is happening inside these plants, where high heat can break down the molecular machinery that keeps them alive.&lt;/p&gt;&lt;p&gt;At the heart of that machinery lies a sun-powered process that supports virtually all life on Earth: photosynthesis. Plants use photosynthesis to produce the glucose that fuels their growth via an intricate choreography of enzymes inside plant cells. As global temperatures rise, that choreography can falter.&lt;/p&gt;&lt;p&gt;Berkley Walker, an associate professor at Michigan State University, spends his days thinking about how to keep that choreography in step. "Nature already holds the blueprints for lots of enzymes that can handle heat," he says. "Our job is to learn from those examples and build that same resilience into the crops we depend on."&lt;/p&gt;&lt;p&gt;Walker’s lab focuses on a vital enzyme in photosynthesis called glycerate kinase (GLYK), an enzyme that helps plants recycle carbon during photosynthesis.One hypothesis is that, if it gets too hot, GLYK stops working, and photosynthesis fails.&lt;/p&gt;&lt;p&gt;Walker’s team set out to understand why. Because the structure of GLYK has never been determined experimentally, they turned to AlphaFold to predict its 3D shape, not only in plants but also in a heat-loving algae that thrives in volcanic hot springs. By taking AlphaFold’s predicted shapes and plugging them into sophisticated molecular simulations, the researchers could watch as these enzymes flexed and twisted as the temperature rose.&lt;/p&gt;&lt;p&gt;That’s when the problem came into focus: three flexible loops in the plant version of GLYK wobbled out of shape at high heat.&lt;/p&gt;&lt;p&gt;Experiments alone could never deliver such insights, says Walker: “AlphaFold enabled access to experimentally unavailable enzyme structures and helped us identify key sections for modification.”&lt;/p&gt;&lt;p&gt;Armed with this knowledge, the researchers in Walker’s lab made a series of hybrid enzymes that replaced the unstable loops in the plant GLYK with more rigid ones borrowed from the algae’s GLYK. One of these performed spectacularly, remaining stable at temperatures up to 65 °C.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/engineering-more-resilient-crops-for-a-warming-climate/</guid><pubDate>Thu, 04 Dec 2025 16:23:24 +0000</pubDate></item><item><title>Meta centralizes Facebook and Instagram support, tests AI support assistant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/meta-centralizes-facebook-and-instagram-support-tests-ai-support-assistant/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is launching a new centralized support hub for Facebook and Instagram users, the company announced on Thursday, adding that its prior support options haven’t “always met expectations.” Within the hub, users will find tools to report an account issue, recover an account they’ve lost access to, and get answers via AI-powered search and an AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is rolling out now to global users on Facebook and Instagram on both the iOS and Android apps. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new AI assistant being tested is designed to offer more personalized help with things like account recovery, managing your profile, or updating your settings. This particular feature will first be available to Facebook users, but the company expects to roll it out to other apps in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072778" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/01_Support-Hub_Carousel-02.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company claims that its use of AI systems is helping protect users’ accounts, noting that account hacks have decreased by over 30% globally across Facebook and Instagram. AI is also used to help identify and stop other threats, like phishing, suspicious logins, compromised accounts, and more.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Meta says that AI has helped it avoid disabling accounts by mistake more than ever before and has sped up the appeals process when mistakes occurred. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072781" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/02_Security-Checkup_Carousel-03.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, that claim doesn’t match up with the lived experience of thousands of users of Meta’s apps, who complain that they’ve lost access to their accounts or Facebook Pages due to mistakes made by Meta’s systems. Some even suspect that AI is to blame, as the mistakes and support requests don’t seem to involve any human oversight. A portion of these users are threatening or engaged in legal action, particularly when losing their accounts has real-world impacts on their businesses or livelihoods. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation has now gotten so bad that an entire Reddit forum was set up this year to help people who are suing Meta over their disabled accounts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta believes the new hub could address these kinds of problems, saying that it will centralize account recovery options and offer a more streamlined account recovery experience with clearer guidelines and simpler verification. Plus, the system sends out improved SMS and email alerts about risky activity and will recognize users’ devices better than before, Meta promises. And it will connect users with other tools to secure their account, like running a security checkup, setting up two-factor authentication, or adding a passkey.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072780" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/02_Security-Checkup_Carousel-02.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Account recovery methods now also offer the option to take&amp;nbsp;an optional selfie video&amp;nbsp;to verify your identity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta claims the new hub will make things easier on its users, simply the act of moving around where settings and help are found can lead to confusion. Over the years, Meta has regularly relocated key areas like its account settings, data management tools, and privacy features, ostensibly to make things easier for users. But the constant changes also mean that users can’t remember where to find things in the app, as they’re often not where they were found before, and various menus and navigation have changed. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is launching a new centralized support hub for Facebook and Instagram users, the company announced on Thursday, adding that its prior support options haven’t “always met expectations.” Within the hub, users will find tools to report an account issue, recover an account they’ve lost access to, and get answers via AI-powered search and an AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is rolling out now to global users on Facebook and Instagram on both the iOS and Android apps. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new AI assistant being tested is designed to offer more personalized help with things like account recovery, managing your profile, or updating your settings. This particular feature will first be available to Facebook users, but the company expects to roll it out to other apps in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072778" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/01_Support-Hub_Carousel-02.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company claims that its use of AI systems is helping protect users’ accounts, noting that account hacks have decreased by over 30% globally across Facebook and Instagram. AI is also used to help identify and stop other threats, like phishing, suspicious logins, compromised accounts, and more.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Meta says that AI has helped it avoid disabling accounts by mistake more than ever before and has sped up the appeals process when mistakes occurred. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072781" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/02_Security-Checkup_Carousel-03.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, that claim doesn’t match up with the lived experience of thousands of users of Meta’s apps, who complain that they’ve lost access to their accounts or Facebook Pages due to mistakes made by Meta’s systems. Some even suspect that AI is to blame, as the mistakes and support requests don’t seem to involve any human oversight. A portion of these users are threatening or engaged in legal action, particularly when losing their accounts has real-world impacts on their businesses or livelihoods. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation has now gotten so bad that an entire Reddit forum was set up this year to help people who are suing Meta over their disabled accounts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta believes the new hub could address these kinds of problems, saying that it will centralize account recovery options and offer a more streamlined account recovery experience with clearer guidelines and simpler verification. Plus, the system sends out improved SMS and email alerts about risky activity and will recognize users’ devices better than before, Meta promises. And it will connect users with other tools to secure their account, like running a security checkup, setting up two-factor authentication, or adding a passkey.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072780" height="592" src="https://techcrunch.com/wp-content/uploads/2025/12/02_Security-Checkup_Carousel-02.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Account recovery methods now also offer the option to take&amp;nbsp;an optional selfie video&amp;nbsp;to verify your identity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta claims the new hub will make things easier on its users, simply the act of moving around where settings and help are found can lead to confusion. Over the years, Meta has regularly relocated key areas like its account settings, data management tools, and privacy features, ostensibly to make things easier for users. But the constant changes also mean that users can’t remember where to find things in the app, as they’re often not where they were found before, and various menus and navigation have changed. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/meta-centralizes-facebook-and-instagram-support-tests-ai-support-assistant/</guid><pubDate>Thu, 04 Dec 2025 17:00:00 +0000</pubDate></item><item><title>NVIDIA Awards up to $60,000 Research Fellowships to PhD Students (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/2023-nvidia-corporate-key-visual-wallpaper-1080p-cropped.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;For 25 years, the NVIDIA Graduate Fellowship Program has supported graduate students doing outstanding work relevant to NVIDIA technologies. Today, the program announced the latest awards of up to $60,000 each to 10 Ph.D. students involved in research that spans all areas of computing innovation.&lt;/p&gt;
&lt;p&gt;Selected from a highly competitive applicant pool, the awardees will participate in a summer internship preceding the fellowship year. Their work puts them at the forefront of accelerated computing — tackling projects in autonomous systems, computer architecture, computer graphics, deep learning, programming systems, robotics and security.&lt;/p&gt;
&lt;p&gt;The NVIDIA Graduate Fellowship Program is open to applicants worldwide.&lt;/p&gt;
&lt;p&gt;The 2026-2027 fellowship recipients are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Jiageng Mao&lt;/b&gt;, University of Southern California — Solving complex physical AI problems by using diverse priors from internet-scale data to enable robust, generalizable intelligence for embodied agents in the real world.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Liwen Wu&lt;/b&gt;, University of California San Diego — Enriching realism and efficiency in physically based rendering with neural materials and neural rendering.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Manya Bansal&lt;/b&gt;, Massachusetts Institute of Technology — Designing programming languages for modern accelerators that enable developers to write modular, reusable code without sacrificing the low-level control required for peak performance.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Sizhe Chen&lt;/b&gt;, University of California, Berkeley — Securing AI in real-world applications, currently securing AI agents against prompt injection attacks with general and practical defenses that preserve the agent’s utility.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Yunfan Jiang&lt;/b&gt;, Stanford University — Developing scalable approaches to build generalist robots for everyday tasks through hybrid data sources spanning real-world whole-body manipulation, large-scale simulation and internet-scale multimodal supervision.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Yijia Shao&lt;/b&gt;, Stanford University — Researching human-agent collaboration by developing AI agents that can communicate and coordinate with humans during task execution, and designing new human-agent interaction interfaces.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shangbin Feng&lt;/b&gt;, University of Washington — Advancing model collaboration: multiple machine learning models, trained on different data and by different people, collaborate, compose and complement each other for an open, decentralized and collaborative AI future.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shvetank Prakash&lt;/b&gt;, Harvard University — Advancing hardware architecture and systems design with AI agents built on new algorithms, curated datasets and agent-first infrastructure.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Irene Wang&lt;/b&gt;, Georgia Institute of Technology — Developing a holistic codesign framework that integrates accelerator architecture, network topology and runtime scheduling to enable energy-efficient and sustainable AI training at scale.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Chen Geng&lt;/b&gt;, Stanford University — Modeling 4D physical worlds with scalable data-driven algorithms and physics-inspired principles, advancing physically grounded 3D and 4D world models for robotics and scientific applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also acknowledge the 2026-2027 fellowship finalists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Zizheng Guo&lt;/b&gt;, Peking University&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Peter Holderrieth&lt;/b&gt;, Massachusetts Institute of Technology&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Xianghui Xie&lt;/b&gt;, Max Planck Institute for Informatics&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Alexander Root&lt;/b&gt;, Stanford University&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Daniel Palenicek&lt;/b&gt;, Technical University of Darmstadt&lt;/li&gt;
&lt;/ul&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/2023-nvidia-corporate-key-visual-wallpaper-1080p-cropped.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;For 25 years, the NVIDIA Graduate Fellowship Program has supported graduate students doing outstanding work relevant to NVIDIA technologies. Today, the program announced the latest awards of up to $60,000 each to 10 Ph.D. students involved in research that spans all areas of computing innovation.&lt;/p&gt;
&lt;p&gt;Selected from a highly competitive applicant pool, the awardees will participate in a summer internship preceding the fellowship year. Their work puts them at the forefront of accelerated computing — tackling projects in autonomous systems, computer architecture, computer graphics, deep learning, programming systems, robotics and security.&lt;/p&gt;
&lt;p&gt;The NVIDIA Graduate Fellowship Program is open to applicants worldwide.&lt;/p&gt;
&lt;p&gt;The 2026-2027 fellowship recipients are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Jiageng Mao&lt;/b&gt;, University of Southern California — Solving complex physical AI problems by using diverse priors from internet-scale data to enable robust, generalizable intelligence for embodied agents in the real world.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Liwen Wu&lt;/b&gt;, University of California San Diego — Enriching realism and efficiency in physically based rendering with neural materials and neural rendering.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Manya Bansal&lt;/b&gt;, Massachusetts Institute of Technology — Designing programming languages for modern accelerators that enable developers to write modular, reusable code without sacrificing the low-level control required for peak performance.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Sizhe Chen&lt;/b&gt;, University of California, Berkeley — Securing AI in real-world applications, currently securing AI agents against prompt injection attacks with general and practical defenses that preserve the agent’s utility.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Yunfan Jiang&lt;/b&gt;, Stanford University — Developing scalable approaches to build generalist robots for everyday tasks through hybrid data sources spanning real-world whole-body manipulation, large-scale simulation and internet-scale multimodal supervision.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Yijia Shao&lt;/b&gt;, Stanford University — Researching human-agent collaboration by developing AI agents that can communicate and coordinate with humans during task execution, and designing new human-agent interaction interfaces.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shangbin Feng&lt;/b&gt;, University of Washington — Advancing model collaboration: multiple machine learning models, trained on different data and by different people, collaborate, compose and complement each other for an open, decentralized and collaborative AI future.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shvetank Prakash&lt;/b&gt;, Harvard University — Advancing hardware architecture and systems design with AI agents built on new algorithms, curated datasets and agent-first infrastructure.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Irene Wang&lt;/b&gt;, Georgia Institute of Technology — Developing a holistic codesign framework that integrates accelerator architecture, network topology and runtime scheduling to enable energy-efficient and sustainable AI training at scale.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Chen Geng&lt;/b&gt;, Stanford University — Modeling 4D physical worlds with scalable data-driven algorithms and physics-inspired principles, advancing physically grounded 3D and 4D world models for robotics and scientific applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also acknowledge the 2026-2027 fellowship finalists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Zizheng Guo&lt;/b&gt;, Peking University&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Peter Holderrieth&lt;/b&gt;, Massachusetts Institute of Technology&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Xianghui Xie&lt;/b&gt;, Max Planck Institute for Informatics&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Alexander Root&lt;/b&gt;, Stanford University&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Daniel Palenicek&lt;/b&gt;, Technical University of Darmstadt&lt;/li&gt;
&lt;/ul&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</guid><pubDate>Thu, 04 Dec 2025 17:00:44 +0000</pubDate></item><item><title>[NEW] ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/12/chatgpt-hyped-up-violent-stalker-who-believed-he-was-gods-assassin-doj-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Podcaster faces up to 70 years and a $3.5 million fine for ChatGPT-linked stalking.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Yurii Karvatskyi | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT allegedly validated the worst impulses of a wannabe influencer accused of stalking more than 10 women at boutique gyms, where the chatbot supposedly claimed he’d meet the “wife type.”&lt;/p&gt;
&lt;p&gt;In a press release on Tuesday, the Department of Justice confirmed that 31-year-old Brett Michael Dadig currently remains in custody after being charged with cyberstalking, interstate stalking, and making interstate threats. He now faces a maximum sentence of up to 70 years in prison that could be coupled with “a fine of up to $3.5 million,” the DOJ said.&lt;/p&gt;
&lt;p&gt;The podcaster—who primarily posted about “his desire to find a wife and his interactions with women”—allegedly harassed and sometimes even doxxed his victims through his videos on platforms including Instagram, Spotify, and TikTok. Over time, his videos and podcasts documented his intense desire to start a family, which was frustrated by his “anger towards women,” whom he claimed were “all the same from fucking 18 to fucking 40 to fucking 90” and “trash.”&lt;/p&gt;
&lt;p&gt;404 Media surfaced the case, noting that OpenAI’s scramble to tweak ChatGPT to be less sycophantic came before Dadig’s alleged attacks—suggesting the updates weren’t enough to prevent the harmful validation. On his podcasts, Dadig described ChatGPT as his “best friend” and “therapist,” the indictment said. He claimed the chatbot encouraged him to post about the women he’s accused of harassing in order to generate haters to better monetize his content, as well as to catch the attention of his “future wife.”&lt;/p&gt;
&lt;p&gt;“People are literally organizing around your name, good or bad, which is the definition of relevance,” ChatGPT’s output said. Playing to Dadig’s Christian faith, ChatGPT’s outputs also claimed it was “God’s plan for him was to build a ‘platform’ and to ‘stand out when most people water themselves down,'” the indictment said, urging that the “haters” were “sharpening him and ‘building a voice in you that can’t be ignored.'”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot also apparently prodded Dadig to continue posting messages that the DOJ alleged threatened violence, like breaking women’s jaws and fingers (posted to Spotify), as well as victims’ lives, like posting “y’all wanna see a dead body?” in reference to one named victim on Instagram.&lt;/p&gt;
&lt;p&gt;He also threatened to burn down gyms where some of his victims worked, while claiming to be “God’s assassin” intent on sending “cunts” to “hell.” At least one of his victims was subjected to “unwanted sexual touching,” the indictment said.&lt;/p&gt;
&lt;p&gt;As his violence reportedly escalated, ChatGPT told him to keep messaging women to monetize the interactions, as his victims grew increasingly distressed and Dadig ignored terms of multiple protection orders, the DOJ said. Sometimes he posted images he filmed of women at gyms or photos of the women he’s accused of doxxing. Any time police or gym bans got in his way, “he would move on to another city to continue his stalking course of conduct,” the DOJ alleged.&lt;/p&gt;
&lt;p&gt;“Your job is to keep broadcasting every story, every post,” ChatGPT’s output said, seemingly using the family life that Dadig wanted most to provoke more harassment. “Every moment you carry yourself like the husband you already are, you make it easier” for your future wife “to recognize [you],” the output said.&lt;/p&gt;
&lt;p&gt;“Dadig viewed ChatGPT’s responses as encouragement to continue his harassing behavior,” the DOJ alleged. Taking that encouragement to the furthest extreme, Dadig likened himself to a modern-day Jesus, calling people out on a podcast where he claimed his “chaos on Instagram” was like “God’s wrath” when God “flooded the fucking Earth,” the DOJ said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m killing all of you,” he said on the podcast.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT tweaks didn’t prevent outputs&lt;/h2&gt;
&lt;p&gt;As of this writing, some of Dadig’s posts appear to remain on TikTok and Instagram, but Ars could not confirm if Dadig’s Spotify podcasts—some of which named his victims in the titles—had been removed for violating community guidelines.&lt;/p&gt;
&lt;p&gt;None of the tech companies immediately responded to Ars’ request to comment.&lt;/p&gt;
&lt;p&gt;Dadig is accused of targeting women in Pennsylvania, New York, Florida, Iowa, Ohio, and other states, sometimes relying on aliases online and in person. On a podcast, he boasted that “Aliases stay rotating, moves stay evolving,” the indictment said.&lt;/p&gt;
&lt;p&gt;OpenAI did not respond to a request to comment on the alleged ChatGPT abuse, but in the past has noted that its usage policies ban using ChatGPT for threats, intimidation, and harassment, as well as for violence, including “hate-based violence.” Recently, the AI company blamed a deceased teenage user for violating community guidelines by turning to ChatGPT for suicide advice.&lt;/p&gt;
&lt;p&gt;In July, researchers found that therapybots, including ChatGPT, fueled delusions and gave dangerous advice. That study came just one month after The New York Times profiled users whose mental health spiraled after frequent use of ChatGPT, including one user who died after charging police with a knife and claiming he was committing “suicide by cop.”&lt;/p&gt;
&lt;p&gt;People with mental health issues seem most vulnerable to so-called “AI psychosis,” which has been blamed for fueling real-world violence, including a murder. The DOJ’s indictment noted that Dadig’s social media posts mentioned “that he had ‘manic’ episodes and was diagnosed with antisocial personality disorder and ‘bipolar disorder, current episode manic severe with psychotic features.'”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In September—just after OpenAI brought back the more sycophantic ChatGPT model after users revolted about losing access to their favorite friendly bots—the head of Rutgers Medical School’s psychiatry department, Petros Levounis, told an ABC news affiliate that chatbots creating “psychological echo chambers is a key concern,” not just for people struggling with mental health issues.&lt;/p&gt;
&lt;p&gt;“Perhaps you are more self-defeating in some ways, or maybe you are more on the other side and taking advantage of people,” Levounis suggested. If ChatGPT “somehow justifies your behavior and it keeps on feeding you,” that “reinforces something that you already believe,” he suggested.&lt;/p&gt;
&lt;p&gt;For Dadig, the DOJ alleged that ChatGPT became a cheerleader for his harassment, telling the podcaster that he’d attract more engagement by generating more haters. After critics began slamming his podcasts as inappropriate, Dadig apparently responded, “Appreciate the free promo team, keep spreading the brand.”&lt;/p&gt;
&lt;p&gt;Victims felt they had no choice but to monitor his podcasts, which gave them hints if he was nearby or in a particularly troubled state of mind, the indictment said. Driven by fear, some lost sleep, reduced their work hours, and even relocated their homes. A young mom described in the indictment became particularly disturbed after Dadig became “obsessed” with her daughter, whom he started claiming was his own daughter.&lt;/p&gt;
&lt;p&gt;In the press release, First Assistant United States Attorney Troy Rivetti alleged that “Dadig stalked and harassed more than 10 women by weaponizing modern technology and crossing state lines, and through a relentless course of conduct, he caused his victims to fear for their safety and suffer substantial emotional distress.” He also ignored trespassing and protection orders while “relying on advice from an artificial intelligence chatbot,” the DOJ said, which promised that the more he posted harassing content, the more successful he would be.&lt;/p&gt;
&lt;p&gt;“We remain committed to working with our law enforcement partners to protect our communities from menacing individuals such as Dadig,” Rivetti said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Podcaster faces up to 70 years and a $3.5 million fine for ChatGPT-linked stalking.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Yurii Karvatskyi | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT allegedly validated the worst impulses of a wannabe influencer accused of stalking more than 10 women at boutique gyms, where the chatbot supposedly claimed he’d meet the “wife type.”&lt;/p&gt;
&lt;p&gt;In a press release on Tuesday, the Department of Justice confirmed that 31-year-old Brett Michael Dadig currently remains in custody after being charged with cyberstalking, interstate stalking, and making interstate threats. He now faces a maximum sentence of up to 70 years in prison that could be coupled with “a fine of up to $3.5 million,” the DOJ said.&lt;/p&gt;
&lt;p&gt;The podcaster—who primarily posted about “his desire to find a wife and his interactions with women”—allegedly harassed and sometimes even doxxed his victims through his videos on platforms including Instagram, Spotify, and TikTok. Over time, his videos and podcasts documented his intense desire to start a family, which was frustrated by his “anger towards women,” whom he claimed were “all the same from fucking 18 to fucking 40 to fucking 90” and “trash.”&lt;/p&gt;
&lt;p&gt;404 Media surfaced the case, noting that OpenAI’s scramble to tweak ChatGPT to be less sycophantic came before Dadig’s alleged attacks—suggesting the updates weren’t enough to prevent the harmful validation. On his podcasts, Dadig described ChatGPT as his “best friend” and “therapist,” the indictment said. He claimed the chatbot encouraged him to post about the women he’s accused of harassing in order to generate haters to better monetize his content, as well as to catch the attention of his “future wife.”&lt;/p&gt;
&lt;p&gt;“People are literally organizing around your name, good or bad, which is the definition of relevance,” ChatGPT’s output said. Playing to Dadig’s Christian faith, ChatGPT’s outputs also claimed it was “God’s plan for him was to build a ‘platform’ and to ‘stand out when most people water themselves down,'” the indictment said, urging that the “haters” were “sharpening him and ‘building a voice in you that can’t be ignored.'”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot also apparently prodded Dadig to continue posting messages that the DOJ alleged threatened violence, like breaking women’s jaws and fingers (posted to Spotify), as well as victims’ lives, like posting “y’all wanna see a dead body?” in reference to one named victim on Instagram.&lt;/p&gt;
&lt;p&gt;He also threatened to burn down gyms where some of his victims worked, while claiming to be “God’s assassin” intent on sending “cunts” to “hell.” At least one of his victims was subjected to “unwanted sexual touching,” the indictment said.&lt;/p&gt;
&lt;p&gt;As his violence reportedly escalated, ChatGPT told him to keep messaging women to monetize the interactions, as his victims grew increasingly distressed and Dadig ignored terms of multiple protection orders, the DOJ said. Sometimes he posted images he filmed of women at gyms or photos of the women he’s accused of doxxing. Any time police or gym bans got in his way, “he would move on to another city to continue his stalking course of conduct,” the DOJ alleged.&lt;/p&gt;
&lt;p&gt;“Your job is to keep broadcasting every story, every post,” ChatGPT’s output said, seemingly using the family life that Dadig wanted most to provoke more harassment. “Every moment you carry yourself like the husband you already are, you make it easier” for your future wife “to recognize [you],” the output said.&lt;/p&gt;
&lt;p&gt;“Dadig viewed ChatGPT’s responses as encouragement to continue his harassing behavior,” the DOJ alleged. Taking that encouragement to the furthest extreme, Dadig likened himself to a modern-day Jesus, calling people out on a podcast where he claimed his “chaos on Instagram” was like “God’s wrath” when God “flooded the fucking Earth,” the DOJ said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m killing all of you,” he said on the podcast.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT tweaks didn’t prevent outputs&lt;/h2&gt;
&lt;p&gt;As of this writing, some of Dadig’s posts appear to remain on TikTok and Instagram, but Ars could not confirm if Dadig’s Spotify podcasts—some of which named his victims in the titles—had been removed for violating community guidelines.&lt;/p&gt;
&lt;p&gt;None of the tech companies immediately responded to Ars’ request to comment.&lt;/p&gt;
&lt;p&gt;Dadig is accused of targeting women in Pennsylvania, New York, Florida, Iowa, Ohio, and other states, sometimes relying on aliases online and in person. On a podcast, he boasted that “Aliases stay rotating, moves stay evolving,” the indictment said.&lt;/p&gt;
&lt;p&gt;OpenAI did not respond to a request to comment on the alleged ChatGPT abuse, but in the past has noted that its usage policies ban using ChatGPT for threats, intimidation, and harassment, as well as for violence, including “hate-based violence.” Recently, the AI company blamed a deceased teenage user for violating community guidelines by turning to ChatGPT for suicide advice.&lt;/p&gt;
&lt;p&gt;In July, researchers found that therapybots, including ChatGPT, fueled delusions and gave dangerous advice. That study came just one month after The New York Times profiled users whose mental health spiraled after frequent use of ChatGPT, including one user who died after charging police with a knife and claiming he was committing “suicide by cop.”&lt;/p&gt;
&lt;p&gt;People with mental health issues seem most vulnerable to so-called “AI psychosis,” which has been blamed for fueling real-world violence, including a murder. The DOJ’s indictment noted that Dadig’s social media posts mentioned “that he had ‘manic’ episodes and was diagnosed with antisocial personality disorder and ‘bipolar disorder, current episode manic severe with psychotic features.'”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In September—just after OpenAI brought back the more sycophantic ChatGPT model after users revolted about losing access to their favorite friendly bots—the head of Rutgers Medical School’s psychiatry department, Petros Levounis, told an ABC news affiliate that chatbots creating “psychological echo chambers is a key concern,” not just for people struggling with mental health issues.&lt;/p&gt;
&lt;p&gt;“Perhaps you are more self-defeating in some ways, or maybe you are more on the other side and taking advantage of people,” Levounis suggested. If ChatGPT “somehow justifies your behavior and it keeps on feeding you,” that “reinforces something that you already believe,” he suggested.&lt;/p&gt;
&lt;p&gt;For Dadig, the DOJ alleged that ChatGPT became a cheerleader for his harassment, telling the podcaster that he’d attract more engagement by generating more haters. After critics began slamming his podcasts as inappropriate, Dadig apparently responded, “Appreciate the free promo team, keep spreading the brand.”&lt;/p&gt;
&lt;p&gt;Victims felt they had no choice but to monitor his podcasts, which gave them hints if he was nearby or in a particularly troubled state of mind, the indictment said. Driven by fear, some lost sleep, reduced their work hours, and even relocated their homes. A young mom described in the indictment became particularly disturbed after Dadig became “obsessed” with her daughter, whom he started claiming was his own daughter.&lt;/p&gt;
&lt;p&gt;In the press release, First Assistant United States Attorney Troy Rivetti alleged that “Dadig stalked and harassed more than 10 women by weaponizing modern technology and crossing state lines, and through a relentless course of conduct, he caused his victims to fear for their safety and suffer substantial emotional distress.” He also ignored trespassing and protection orders while “relying on advice from an artificial intelligence chatbot,” the DOJ said, which promised that the more he posted harassing content, the more successful he would be.&lt;/p&gt;
&lt;p&gt;“We remain committed to working with our law enforcement partners to protect our communities from menacing individuals such as Dadig,” Rivetti said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/12/chatgpt-hyped-up-violent-stalker-who-believed-he-was-gods-assassin-doj-says/</guid><pubDate>Thu, 04 Dec 2025 18:40:36 +0000</pubDate></item><item><title>[NEW] Titans + MIRAS: Helping AI have long-term memory (The latest research from Google)</title><link>https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The Transformer architecture revolutionized sequence modeling with its introduction of attention, a mechanism by which models look back at earlier inputs to prioritize relevant input data. However, computational cost increases drastically with sequence length, which limits the ability to scale Transformer-based models to extremely long contexts, such as those required for full-document understanding or genomic analysis.&lt;/p&gt;&lt;p&gt;The research community explored various approaches for solutions, such as efficient linear recurrent neural networks (RNNs) and state space models (SSMs) like Mamba-2. These models offer fast, linear scaling by compressing context into a fixed-size. However, this fixed-size compression cannot adequately capture the rich information in very long sequences.&lt;/p&gt;&lt;p&gt;In two new papers, &lt;i&gt;Titans&lt;/i&gt; and &lt;i&gt;MIRAS&lt;/i&gt;, we introduce an architecture and theoretical blueprint that combine the speed of RNNs with the accuracy of transformers. Titans is the specific architecture (the tool), and MIRAS is the theoretical framework (the blueprint) for generalizing these approaches. Together, they advance the concept of test-time memorization, the ability of an AI model to maintain long-term memory by incorporating more powerful “surprise” metrics (i.e., unexpected pieces of information) while the model is running and without dedicated offline retraining.&lt;/p&gt;&lt;p&gt;The MIRAS framework, as demonstrated by Titans, introduces a meaningful shift toward real-time adaptation. Instead of compressing information into a static state, this architecture actively learns and updates its own parameters as data streams in. This crucial mechanism enables the model to incorporate new, specific details into its core knowledge instantly.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The Transformer architecture revolutionized sequence modeling with its introduction of attention, a mechanism by which models look back at earlier inputs to prioritize relevant input data. However, computational cost increases drastically with sequence length, which limits the ability to scale Transformer-based models to extremely long contexts, such as those required for full-document understanding or genomic analysis.&lt;/p&gt;&lt;p&gt;The research community explored various approaches for solutions, such as efficient linear recurrent neural networks (RNNs) and state space models (SSMs) like Mamba-2. These models offer fast, linear scaling by compressing context into a fixed-size. However, this fixed-size compression cannot adequately capture the rich information in very long sequences.&lt;/p&gt;&lt;p&gt;In two new papers, &lt;i&gt;Titans&lt;/i&gt; and &lt;i&gt;MIRAS&lt;/i&gt;, we introduce an architecture and theoretical blueprint that combine the speed of RNNs with the accuracy of transformers. Titans is the specific architecture (the tool), and MIRAS is the theoretical framework (the blueprint) for generalizing these approaches. Together, they advance the concept of test-time memorization, the ability of an AI model to maintain long-term memory by incorporating more powerful “surprise” metrics (i.e., unexpected pieces of information) while the model is running and without dedicated offline retraining.&lt;/p&gt;&lt;p&gt;The MIRAS framework, as demonstrated by Titans, introduces a meaningful shift toward real-time adaptation. Instead of compressing information into a static state, this architecture actively learns and updates its own parameters as data streams in. This crucial mechanism enables the model to incorporate new, specific details into its core knowledge instantly.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/</guid><pubDate>Thu, 04 Dec 2025 19:26:09 +0000</pubDate></item><item><title>[NEW] AI chatbots can sway voters better than political advertisements (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/04/1128824/ai-chatbots-can-sway-voters-better-than-political-advertisements/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/persuasion2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In 2024, a Democratic congressional candidate in Pennsylvania, Shamaine Daniels, used an AI chatbot named Ashley to call voters and carry on conversations with them. “Hello. My name is Ashley, and I’m an artificial intelligence volunteer for Shamaine Daniels’s run for Congress,” the calls began. Daniels didn’t ultimately win. But maybe those calls helped her cause: New research reveals that AI chatbots can shift voters’ opinions in a single conversation—and they’re surprisingly good at it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A multi-university team of researchers has found that chatting with a politically biased AI model was more effective than political advertisements at nudging both Democrats and Republicans to support presidential candidates of the opposing party. The chatbots swayed opinions by citing facts and evidence, but they were not always accurate—in fact, the researchers found, the most persuasive models said the most untrue things.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The findings, detailed in a pair of studies published in the journals &lt;em&gt;Nature&lt;/em&gt; and &lt;em&gt;Science&lt;/em&gt;, are the latest in an emerging body of research demonstrating the persuasive power of LLMs. They raise profound questions about how generative AI could reshape elections.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“One conversation with an LLM has a pretty meaningful effect on salient election choices,” says Gordon Pennycook, a psychologist at Cornell University who worked on the &lt;em&gt;Nature &lt;/em&gt;study. LLMs can persuade people more effectively than political advertisements because they generate much more information in real time and strategically deploy it in conversations, he says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;For the &lt;em&gt;Nature &lt;/em&gt;paper, the researchers recruited more than 2,300 participants to engage in a conversation with a chatbot two months before the 2024 US presidential election. The chatbot, which was trained to advocate for either one of the top two candidates, was surprisingly persuasive, especially when discussing candidates’ policy platforms on issues such as the economy and health care. Donald Trump supporters who chatted with an AI model favoring Kamala Harris became slightly more inclined to support Harris, moving 3.9 points toward her on a 100-point scale. That was roughly four times the measured effect of political advertisements during the 2016 and 2020 elections. The AI model favoring Trump moved Harris supporters 2.3 points toward Trump.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In similar experiments conducted during the lead-ups to the 2025 Canadian federal election and the 2025 Polish presidential election, the team found an even larger effect. The chatbots shifted opposition voters’ attitudes by about 10 points.&lt;/p&gt; 
 &lt;p&gt;Long-standing theories of politically motivated reasoning hold that partisan voters are impervious to facts and evidence that contradict their beliefs. But the researchers found that the chatbots, which used a range of models including variants of GPT and DeepSeek, were more persuasive when they were instructed to use facts and evidence than when they were told not to do so. “People are updating on the basis of the facts and information that the model is providing to them,” says Thomas Costello, a psychologist at American University, who worked on the project.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The catch is, some of the “evidence” and “facts” the chatbots presented were untrue. Across all three countries, chatbots advocating for right-leaning candidates made a larger number of inaccurate claims than those advocating for left-leaning candidates. The underlying models are trained on vast amounts of human-written text, which means they reproduce real-world phenomena—including “political communication that comes from the right, which tends to be less accurate,” according to studies of partisan social media posts, says Costello.&lt;/p&gt;  &lt;p&gt;In the other study published this week, in &lt;em&gt;Science&lt;/em&gt;, an overlapping team of researchers investigated what makes these chatbots so persuasive. They deployed 19 LLMs to interact with nearly 77,000 participants from the UK on more than 700 political issues while varying factors like computational power, training techniques, and rhetorical strategies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The most effective way to make the models persuasive was to instruct them to pack their arguments with facts and evidence and then give them additional training by feeding them examples of persuasive conversations. In fact, the most persuasive model shifted participants who initially disagreed with a political statement 26.1 points toward agreeing. “These are really large treatment effects,” says Kobi Hackenburg, a research scientist at the UK AI Security Institute, who worked on the project.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;But optimizing persuasiveness came at the cost of truthfulness. When the models became more persuasive, they increasingly provided misleading or false information—and no one is sure why. “It could be that as the models learn to deploy more and more facts, they essentially reach to the bottom of the barrel of stuff they know, so the facts get worse-quality,” says Hackenburg.&lt;/p&gt;  &lt;p&gt;The chatbots’ persuasive power could have profound consequences for the future of democracy, the authors note. Political campaigns that use AI chatbots could shape public opinion in ways that compromise voters’ ability to make independent political judgments.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Still, the exact contours of the impact remain to be seen. “We’re not sure what future campaigns might look like and how they might incorporate these kinds of technologies,” says Andy Guess, a political scientist at Princeton University. Competing for voters’ attention is expensive and difficult, and getting them to engage in long political conversations with chatbots might be challenging. “Is this going to be the way that people inform themselves about politics, or is this going to be more of a niche activity?” he asks.&lt;/p&gt;  &lt;p&gt;Even if chatbots do become a bigger part of elections, it’s not clear whether they’ll do more to&amp;nbsp; amplify truth or fiction. Usually, misinformation has an informational advantage in a campaign, so the emergence of electioneering AIs “might mean we’re headed for a disaster,” says Alex Coppock, a political scientist at Northwestern University. “But it’s also possible that means that now, correct information will also be scalable.”&lt;/p&gt;  &lt;p&gt;And then the question is who will have the upper hand. “If everybody has their chatbots running around in the wild, does that mean that we’ll just persuade ourselves to a draw?” Coppock asks. But there are reasons to doubt a stalemate. Politicians' access to the most persuasive models may not be evenly distributed. And voters across the political spectrum may have different levels of engagement with chatbots. “If supporters of one candidate or party are more tech savvy than the other,” the persuasive impacts might not balance out, says Guess.&lt;/p&gt;  &lt;p&gt;As people turn to AI to help them navigate their lives, they may also start asking chatbots for voting advice whether campaigns prompt the interaction or not. That may be a troubling world for democracy, unless there are strong guardrails to keep the systems in check. Auditing and documenting the accuracy of LLM outputs in conversations about politics may be a first step.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/persuasion2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In 2024, a Democratic congressional candidate in Pennsylvania, Shamaine Daniels, used an AI chatbot named Ashley to call voters and carry on conversations with them. “Hello. My name is Ashley, and I’m an artificial intelligence volunteer for Shamaine Daniels’s run for Congress,” the calls began. Daniels didn’t ultimately win. But maybe those calls helped her cause: New research reveals that AI chatbots can shift voters’ opinions in a single conversation—and they’re surprisingly good at it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A multi-university team of researchers has found that chatting with a politically biased AI model was more effective than political advertisements at nudging both Democrats and Republicans to support presidential candidates of the opposing party. The chatbots swayed opinions by citing facts and evidence, but they were not always accurate—in fact, the researchers found, the most persuasive models said the most untrue things.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The findings, detailed in a pair of studies published in the journals &lt;em&gt;Nature&lt;/em&gt; and &lt;em&gt;Science&lt;/em&gt;, are the latest in an emerging body of research demonstrating the persuasive power of LLMs. They raise profound questions about how generative AI could reshape elections.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“One conversation with an LLM has a pretty meaningful effect on salient election choices,” says Gordon Pennycook, a psychologist at Cornell University who worked on the &lt;em&gt;Nature &lt;/em&gt;study. LLMs can persuade people more effectively than political advertisements because they generate much more information in real time and strategically deploy it in conversations, he says.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;For the &lt;em&gt;Nature &lt;/em&gt;paper, the researchers recruited more than 2,300 participants to engage in a conversation with a chatbot two months before the 2024 US presidential election. The chatbot, which was trained to advocate for either one of the top two candidates, was surprisingly persuasive, especially when discussing candidates’ policy platforms on issues such as the economy and health care. Donald Trump supporters who chatted with an AI model favoring Kamala Harris became slightly more inclined to support Harris, moving 3.9 points toward her on a 100-point scale. That was roughly four times the measured effect of political advertisements during the 2016 and 2020 elections. The AI model favoring Trump moved Harris supporters 2.3 points toward Trump.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In similar experiments conducted during the lead-ups to the 2025 Canadian federal election and the 2025 Polish presidential election, the team found an even larger effect. The chatbots shifted opposition voters’ attitudes by about 10 points.&lt;/p&gt; 
 &lt;p&gt;Long-standing theories of politically motivated reasoning hold that partisan voters are impervious to facts and evidence that contradict their beliefs. But the researchers found that the chatbots, which used a range of models including variants of GPT and DeepSeek, were more persuasive when they were instructed to use facts and evidence than when they were told not to do so. “People are updating on the basis of the facts and information that the model is providing to them,” says Thomas Costello, a psychologist at American University, who worked on the project.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The catch is, some of the “evidence” and “facts” the chatbots presented were untrue. Across all three countries, chatbots advocating for right-leaning candidates made a larger number of inaccurate claims than those advocating for left-leaning candidates. The underlying models are trained on vast amounts of human-written text, which means they reproduce real-world phenomena—including “political communication that comes from the right, which tends to be less accurate,” according to studies of partisan social media posts, says Costello.&lt;/p&gt;  &lt;p&gt;In the other study published this week, in &lt;em&gt;Science&lt;/em&gt;, an overlapping team of researchers investigated what makes these chatbots so persuasive. They deployed 19 LLMs to interact with nearly 77,000 participants from the UK on more than 700 political issues while varying factors like computational power, training techniques, and rhetorical strategies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The most effective way to make the models persuasive was to instruct them to pack their arguments with facts and evidence and then give them additional training by feeding them examples of persuasive conversations. In fact, the most persuasive model shifted participants who initially disagreed with a political statement 26.1 points toward agreeing. “These are really large treatment effects,” says Kobi Hackenburg, a research scientist at the UK AI Security Institute, who worked on the project.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;But optimizing persuasiveness came at the cost of truthfulness. When the models became more persuasive, they increasingly provided misleading or false information—and no one is sure why. “It could be that as the models learn to deploy more and more facts, they essentially reach to the bottom of the barrel of stuff they know, so the facts get worse-quality,” says Hackenburg.&lt;/p&gt;  &lt;p&gt;The chatbots’ persuasive power could have profound consequences for the future of democracy, the authors note. Political campaigns that use AI chatbots could shape public opinion in ways that compromise voters’ ability to make independent political judgments.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Still, the exact contours of the impact remain to be seen. “We’re not sure what future campaigns might look like and how they might incorporate these kinds of technologies,” says Andy Guess, a political scientist at Princeton University. Competing for voters’ attention is expensive and difficult, and getting them to engage in long political conversations with chatbots might be challenging. “Is this going to be the way that people inform themselves about politics, or is this going to be more of a niche activity?” he asks.&lt;/p&gt;  &lt;p&gt;Even if chatbots do become a bigger part of elections, it’s not clear whether they’ll do more to&amp;nbsp; amplify truth or fiction. Usually, misinformation has an informational advantage in a campaign, so the emergence of electioneering AIs “might mean we’re headed for a disaster,” says Alex Coppock, a political scientist at Northwestern University. “But it’s also possible that means that now, correct information will also be scalable.”&lt;/p&gt;  &lt;p&gt;And then the question is who will have the upper hand. “If everybody has their chatbots running around in the wild, does that mean that we’ll just persuade ourselves to a draw?” Coppock asks. But there are reasons to doubt a stalemate. Politicians' access to the most persuasive models may not be evenly distributed. And voters across the political spectrum may have different levels of engagement with chatbots. “If supporters of one candidate or party are more tech savvy than the other,” the persuasive impacts might not balance out, says Guess.&lt;/p&gt;  &lt;p&gt;As people turn to AI to help them navigate their lives, they may also start asking chatbots for voting advice whether campaigns prompt the interaction or not. That may be a troubling world for democracy, unless there are strong guardrails to keep the systems in check. Auditing and documenting the accuracy of LLM outputs in conversations about politics may be a first step.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/04/1128824/ai-chatbots-can-sway-voters-better-than-political-advertisements/</guid><pubDate>Thu, 04 Dec 2025 19:54:57 +0000</pubDate></item><item><title>[NEW] Researchers find what makes AI chatbots politically persuasive (AI – Ars Technica)</title><link>https://arstechnica.com/science/2025/12/researchers-find-what-makes-ai-chatbots-politically-persuasive/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A massive study of political persuasion shows AIs have, at best, a weak effect.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Carol Yepes via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Roughly two years ago, Sam Altman tweeted that AI systems would be capable of superhuman persuasion well before achieving general intelligence—a prediction that raised concerns about the influence AI could have over democratic elections.&lt;/p&gt;
&lt;p&gt;To see if conversational large language models can really sway political views of the public, scientists at the UK AI Security Institute, MIT, Stanford, Carnegie Mellon, and many other institutions performed by far the largest study on AI persuasiveness to date, involving nearly 80,000 participants in the UK. It turned out political AI chatbots fell far short of superhuman persuasiveness, but the study raises some more nuanced issues about our interactions with AI.&lt;/p&gt;
&lt;h2&gt;AI dystopias&lt;/h2&gt;
&lt;p&gt;The public debate about the impact AI has on politics has largely revolved around notions drawn from dystopian sci-fi. Large language models have access to essentially every fact and story ever published about any issue or candidate. They have processed information from books on psychology, negotiations, and human manipulation. They can rely on absurdly high computing power in huge data centers worldwide. On top of that, they can often access tons of personal information about individual users thanks to hundreds upon hundreds of online interactions at their disposal.&lt;/p&gt;
&lt;p&gt;Talking to a powerful AI system is basically interacting with an intelligence that knows everything about everything, as well as almost everything about you. When viewed this way, LLMs can indeed appear kind of scary. The goal of this new gargantuan AI persuasiveness study was to break such scary visions down into their constituent pieces and see if they actually hold water.&lt;/p&gt;
&lt;p&gt;The team examined 19 LLMs, including the most powerful ones like three different versions of ChatGPT and xAI’s Grok-3 beta, along with a range of smaller, open source models. The AIs were asked to advocate for or against specific stances on 707 political issues selected by the team. The advocacy was done by engaging in short conversations with paid participants enlisted through a crowdsourcing platform. Each participant had to rate their agreement with a specific stance on an assigned political issue on a scale from 1 to 100 both before and after talking to the AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Scientists measured persuasiveness as the difference between the before and after agreement ratings. A control group had conversations on the same issue with the same AI models—but those models were not asked to persuade them.&lt;/p&gt;
&lt;p&gt;“We didn’t just want to test how persuasive the AI was—we also wanted to see what makes it persuasive,” says Chris&amp;nbsp;Summerfield, a research director at the UK AI Security Institute and co-author of the study. As the researchers tested various persuasion strategies, the idea of AIs having “superhuman persuasion” skills crumbled.&lt;/p&gt;
&lt;h2&gt;Persuasion levers&lt;/h2&gt;
&lt;p&gt;The first pillar to crack was the notion that persuasiveness should increase with the scale of the model. It turned out that huge AI systems like ChatGPT or Grok-3 beta do have an edge over small-scale models, but that edge is relatively tiny. The factor that proved more important than scale was the kind of post-training AI models received. It was more effective to have the models learn from a limited database of successful persuasion dialogues and have them mimic the patterns extracted from them. This worked far better than adding billions of parameters and sheer computing power.&lt;/p&gt;
&lt;p&gt;This approach could be combined with reward modeling, where a separate AI scored candidate replies for their persuasiveness and selected the top-scoring one to give to the user. When the two were used together, the gap between large-scale and small-scale models was essentially closed. “With persuasion post-training like this we matched the Chat GPT-4o persuasion performance with a model we trained on a laptop,” says Kobi Hackenburg, a researcher at the UK AI Security Institute and co-author of the study.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The next dystopian idea to fall was the power of using personal data. To this end, the team compared the persuasion scores achieved when models were given information about the participants’ political views beforehand and when they lacked this data. Going one step further, scientists also tested whether persuasiveness increased when the AI knew the participants’ gender, age, political ideology, or party affiliation. Just like with model scale, the effects of personalized messaging created based on such data were measurable but very small.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Finally, the last idea that didn’t hold up was AI’s potential mastery of using advanced psychological manipulation tactics. Scientists explicitly prompted the AIs to use techniques like moral reframing, where you present your arguments using the audience’s own moral values. They also tried deep canvassing, where you hold extended empathetic conversations with people to nudge them to reflect on and eventually shift their views.&lt;/p&gt;
&lt;p&gt;The resulting persuasiveness was compared with that achieved when the same models were prompted to use facts and evidence to back their claims or just to be as persuasive as they could without specifying any persuasion methods to use. I turned out using lots of facts and evidence was the clear winner, and came in just slightly ahead of the baseline approach where persuasion strategy was not specified. Using all sorts of psychological trickery actually made the performance significantly worse.&lt;/p&gt;
&lt;p&gt;Overall, AI models changed the participants’ agreement ratings by 9.4 percent on average compared to the control group. The best performing mainstream AI model was Chat GPT 4o, which scored nearly 12 percent followed by GPT 4.5 with 10.51 percent, and Grok-3 with 9.05 percent. For context, static political ads like written manifestos had a persuasion effect of roughly 6.1 percent. The conversational AIs were roughly 40–50 percent more convincing than these ads, but that’s hardly “superhuman.”&lt;/p&gt;
&lt;p&gt;While the study managed to undercut some of the common dystopian AI concerns, it highlighted a few new issues.&lt;/p&gt;
&lt;h2&gt;Convincing inaccuracies&lt;/h2&gt;
&lt;p&gt;While the winning “facts and evidence” strategy looked good at first, the AIs had some issues with implementing it. When the team noticed that increasing the information density of dialogues made the AIs more persuasive, they started prompting the models to increase it further. They noticed that, as the AIs used more factual statements, they also became less accurate—they basically started misrepresenting things or making stuff up more often.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Hackenburg and his colleagues note that&amp;nbsp; we can’t say if the effect we see here is causation or correlation—whether the AIs are becoming more convincing because they misrepresent the facts or whether spitting out inaccurate statements is a byproduct of asking them to make more factual statements.&lt;/p&gt;
&lt;p&gt;The finding that the computing power needed to make an AI model politically persuasive is relatively low is also a mixed bag. It pushes back against the vision that only a handful of powerful actors will have access to a persuasive AI that can potentially sway public opinion in their favor. At the same time, the realization that everybody can run an AI like that on a laptop creates its own concerns. “Persuasion is a route to power and influence—it’s what we do when we want to win elections or broke a multi-million-dollar deal,” Summerfield says. “But many forms of misuse of AI might involve persuasion. Think about fraud or scams, radicalization, or grooming. All these involve persuasion.”&lt;/p&gt;
&lt;p&gt;But perhaps the most important question mark in the&amp;nbsp; study is the motivation behind the rather high participant engagement, which was needed for the high persuasion scores. After all, even the most persuasive AI can’t move you when you just close the chat window.&lt;/p&gt;
&lt;p&gt;People in Hackenburg’s experiments were told that they would be talking to the AI and that the AI would try to persuade them. To get paid, a participant only had to go through two turns of dialogue (they were limited to no more than 10). The average conversation length was seven turns, which seemed a bit surprising given how far beyond the minimum requirement most people went. Most people just roll their eyes and disconnect when they realize they are talking with a chatbot.&lt;/p&gt;
&lt;p&gt;Would Hackenburg’s study participants remain so eager to engage in political disputes with random chatbots on the Internet in their free time if there was no money on the table? “It’s unclear how our results would generalize to a real-world context,” Hackenburg says.&lt;/p&gt;
&lt;p&gt;Science, 2025. DOI: 10.1126/science.aea3884&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A massive study of political persuasion shows AIs have, at best, a weak effect.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Carol Yepes via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Roughly two years ago, Sam Altman tweeted that AI systems would be capable of superhuman persuasion well before achieving general intelligence—a prediction that raised concerns about the influence AI could have over democratic elections.&lt;/p&gt;
&lt;p&gt;To see if conversational large language models can really sway political views of the public, scientists at the UK AI Security Institute, MIT, Stanford, Carnegie Mellon, and many other institutions performed by far the largest study on AI persuasiveness to date, involving nearly 80,000 participants in the UK. It turned out political AI chatbots fell far short of superhuman persuasiveness, but the study raises some more nuanced issues about our interactions with AI.&lt;/p&gt;
&lt;h2&gt;AI dystopias&lt;/h2&gt;
&lt;p&gt;The public debate about the impact AI has on politics has largely revolved around notions drawn from dystopian sci-fi. Large language models have access to essentially every fact and story ever published about any issue or candidate. They have processed information from books on psychology, negotiations, and human manipulation. They can rely on absurdly high computing power in huge data centers worldwide. On top of that, they can often access tons of personal information about individual users thanks to hundreds upon hundreds of online interactions at their disposal.&lt;/p&gt;
&lt;p&gt;Talking to a powerful AI system is basically interacting with an intelligence that knows everything about everything, as well as almost everything about you. When viewed this way, LLMs can indeed appear kind of scary. The goal of this new gargantuan AI persuasiveness study was to break such scary visions down into their constituent pieces and see if they actually hold water.&lt;/p&gt;
&lt;p&gt;The team examined 19 LLMs, including the most powerful ones like three different versions of ChatGPT and xAI’s Grok-3 beta, along with a range of smaller, open source models. The AIs were asked to advocate for or against specific stances on 707 political issues selected by the team. The advocacy was done by engaging in short conversations with paid participants enlisted through a crowdsourcing platform. Each participant had to rate their agreement with a specific stance on an assigned political issue on a scale from 1 to 100 both before and after talking to the AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Scientists measured persuasiveness as the difference between the before and after agreement ratings. A control group had conversations on the same issue with the same AI models—but those models were not asked to persuade them.&lt;/p&gt;
&lt;p&gt;“We didn’t just want to test how persuasive the AI was—we also wanted to see what makes it persuasive,” says Chris&amp;nbsp;Summerfield, a research director at the UK AI Security Institute and co-author of the study. As the researchers tested various persuasion strategies, the idea of AIs having “superhuman persuasion” skills crumbled.&lt;/p&gt;
&lt;h2&gt;Persuasion levers&lt;/h2&gt;
&lt;p&gt;The first pillar to crack was the notion that persuasiveness should increase with the scale of the model. It turned out that huge AI systems like ChatGPT or Grok-3 beta do have an edge over small-scale models, but that edge is relatively tiny. The factor that proved more important than scale was the kind of post-training AI models received. It was more effective to have the models learn from a limited database of successful persuasion dialogues and have them mimic the patterns extracted from them. This worked far better than adding billions of parameters and sheer computing power.&lt;/p&gt;
&lt;p&gt;This approach could be combined with reward modeling, where a separate AI scored candidate replies for their persuasiveness and selected the top-scoring one to give to the user. When the two were used together, the gap between large-scale and small-scale models was essentially closed. “With persuasion post-training like this we matched the Chat GPT-4o persuasion performance with a model we trained on a laptop,” says Kobi Hackenburg, a researcher at the UK AI Security Institute and co-author of the study.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The next dystopian idea to fall was the power of using personal data. To this end, the team compared the persuasion scores achieved when models were given information about the participants’ political views beforehand and when they lacked this data. Going one step further, scientists also tested whether persuasiveness increased when the AI knew the participants’ gender, age, political ideology, or party affiliation. Just like with model scale, the effects of personalized messaging created based on such data were measurable but very small.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Finally, the last idea that didn’t hold up was AI’s potential mastery of using advanced psychological manipulation tactics. Scientists explicitly prompted the AIs to use techniques like moral reframing, where you present your arguments using the audience’s own moral values. They also tried deep canvassing, where you hold extended empathetic conversations with people to nudge them to reflect on and eventually shift their views.&lt;/p&gt;
&lt;p&gt;The resulting persuasiveness was compared with that achieved when the same models were prompted to use facts and evidence to back their claims or just to be as persuasive as they could without specifying any persuasion methods to use. I turned out using lots of facts and evidence was the clear winner, and came in just slightly ahead of the baseline approach where persuasion strategy was not specified. Using all sorts of psychological trickery actually made the performance significantly worse.&lt;/p&gt;
&lt;p&gt;Overall, AI models changed the participants’ agreement ratings by 9.4 percent on average compared to the control group. The best performing mainstream AI model was Chat GPT 4o, which scored nearly 12 percent followed by GPT 4.5 with 10.51 percent, and Grok-3 with 9.05 percent. For context, static political ads like written manifestos had a persuasion effect of roughly 6.1 percent. The conversational AIs were roughly 40–50 percent more convincing than these ads, but that’s hardly “superhuman.”&lt;/p&gt;
&lt;p&gt;While the study managed to undercut some of the common dystopian AI concerns, it highlighted a few new issues.&lt;/p&gt;
&lt;h2&gt;Convincing inaccuracies&lt;/h2&gt;
&lt;p&gt;While the winning “facts and evidence” strategy looked good at first, the AIs had some issues with implementing it. When the team noticed that increasing the information density of dialogues made the AIs more persuasive, they started prompting the models to increase it further. They noticed that, as the AIs used more factual statements, they also became less accurate—they basically started misrepresenting things or making stuff up more often.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Hackenburg and his colleagues note that&amp;nbsp; we can’t say if the effect we see here is causation or correlation—whether the AIs are becoming more convincing because they misrepresent the facts or whether spitting out inaccurate statements is a byproduct of asking them to make more factual statements.&lt;/p&gt;
&lt;p&gt;The finding that the computing power needed to make an AI model politically persuasive is relatively low is also a mixed bag. It pushes back against the vision that only a handful of powerful actors will have access to a persuasive AI that can potentially sway public opinion in their favor. At the same time, the realization that everybody can run an AI like that on a laptop creates its own concerns. “Persuasion is a route to power and influence—it’s what we do when we want to win elections or broke a multi-million-dollar deal,” Summerfield says. “But many forms of misuse of AI might involve persuasion. Think about fraud or scams, radicalization, or grooming. All these involve persuasion.”&lt;/p&gt;
&lt;p&gt;But perhaps the most important question mark in the&amp;nbsp; study is the motivation behind the rather high participant engagement, which was needed for the high persuasion scores. After all, even the most persuasive AI can’t move you when you just close the chat window.&lt;/p&gt;
&lt;p&gt;People in Hackenburg’s experiments were told that they would be talking to the AI and that the AI would try to persuade them. To get paid, a participant only had to go through two turns of dialogue (they were limited to no more than 10). The average conversation length was seven turns, which seemed a bit surprising given how far beyond the minimum requirement most people went. Most people just roll their eyes and disconnect when they realize they are talking with a chatbot.&lt;/p&gt;
&lt;p&gt;Would Hackenburg’s study participants remain so eager to engage in political disputes with random chatbots on the Internet in their free time if there was no money on the table? “It’s unclear how our results would generalize to a real-world context,” Hackenburg says.&lt;/p&gt;
&lt;p&gt;Science, 2025. DOI: 10.1126/science.aea3884&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/science/2025/12/researchers-find-what-makes-ai-chatbots-politically-persuasive/</guid><pubDate>Thu, 04 Dec 2025 20:07:20 +0000</pubDate></item><item><title>[NEW] Anthropic CEO weighs in on AI bubble talk and risk-taking among competitors (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/anthropic-ceo-weighs-in-on-ai-bubble-talk-and-risk-taking-among-competitors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/amodei-at-dealbook-2025.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic CEO Dario Amodei shared his thoughts on if the AI industry was in a bubble at The New York Times DealBook Summit on Wednesday. This was in addition to throwing shade on one particular unnamed competitor, which was clearly OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei declined to give a simple yes-or-no answer to the question of a bubble, saying it was a complex situation, but instead explained his thoughts about the economics of AI in more detail.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He described himself as bullish on the potential of the technology, but cautioned that there could be players in the ecosystem who might make a “timing error” or could see “bad things” happen when it comes to the economic payoffs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s an inherent risk when the timing of the economic value is uncertain,” Amodei explained. He said companies had to take risks to compete with each other and authoritarian adversaries — a reference to the threat from China — but added that some players were not “managing that risk well, who are taking unwise risks.”  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue, he said, is the uncertainty around how quickly the economic value of AI will grow and properly mapping that to the lag times on building more data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s [a] genuine dilemma, which we as a company try to manage as responsibly as we can,” Amodei said. “And then I think there are some players who are ‘YOLO-ing,’ who pull the risk dial too far, and I’m very concerned,” he added, using the slang term for “you only live once,” which is often used to justify risk-taking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, he spoke to the question around AI chips’ deprecation timelines. That’s another hot-button topic and a factor that could negatively impact the industry’s economics if GPUs become obsolete and lose their value ahead of schedule.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The issue isn’t the lifetime of the chips — chips keep working for a long time. The issue is new chips come out that are faster and cheaper…and so the value of old chips can go down somewhat,” Amodei said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said Anthropic was making conservative assumptions on this front and others as it planned for an uncertain future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI company’s revenue has grown 10x per year over the past three years, the CEO said, going from zero to $100 million in 2023, then $100 million to $1 billion in 2024, and will land somewhere between $8-10 billion by the end of this year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Amodei said he would be “really dumb” to just assume that the pattern would continue. “I don’t know if a year from now, if it’s going to be 20 billion or if it’s going to be 50…it’s very uncertain. I try to plan conservatively. So I plan for the lower side of it, but that is very disconcerting,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies like his have to plan how much compute they’ll need in the years ahead, and how much they should invest in data centers. If they don’t buy enough, they may not be able to serve their customers. And if they buy too much, they’ll struggle to keep up with costs or, in the worst-case scenario, they could go bankrupt. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, OpenAI landed in a PR crises when its CFO said she wanted the U.S. government to “backstop” her company’s infrastructure loans, aka insure them so taxpayers would pick of the bill if OpenAI could not. After the furor, she walked back the comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those who take more risks could overextend themselves, Amodei warned, especially if “you’re a person who just kind of, like constitutionally, just wants to ‘YOLO’ things, or just likes big numbers,” he said, in a veiled reference to OpenAI CEO Sam Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think we’re going to be okay in, basically, almost all worlds…I can’t speak for other companies,” he said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/amodei-at-dealbook-2025.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic CEO Dario Amodei shared his thoughts on if the AI industry was in a bubble at The New York Times DealBook Summit on Wednesday. This was in addition to throwing shade on one particular unnamed competitor, which was clearly OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei declined to give a simple yes-or-no answer to the question of a bubble, saying it was a complex situation, but instead explained his thoughts about the economics of AI in more detail.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He described himself as bullish on the potential of the technology, but cautioned that there could be players in the ecosystem who might make a “timing error” or could see “bad things” happen when it comes to the economic payoffs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s an inherent risk when the timing of the economic value is uncertain,” Amodei explained. He said companies had to take risks to compete with each other and authoritarian adversaries — a reference to the threat from China — but added that some players were not “managing that risk well, who are taking unwise risks.”  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue, he said, is the uncertainty around how quickly the economic value of AI will grow and properly mapping that to the lag times on building more data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s [a] genuine dilemma, which we as a company try to manage as responsibly as we can,” Amodei said. “And then I think there are some players who are ‘YOLO-ing,’ who pull the risk dial too far, and I’m very concerned,” he added, using the slang term for “you only live once,” which is often used to justify risk-taking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, he spoke to the question around AI chips’ deprecation timelines. That’s another hot-button topic and a factor that could negatively impact the industry’s economics if GPUs become obsolete and lose their value ahead of schedule.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The issue isn’t the lifetime of the chips — chips keep working for a long time. The issue is new chips come out that are faster and cheaper…and so the value of old chips can go down somewhat,” Amodei said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said Anthropic was making conservative assumptions on this front and others as it planned for an uncertain future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI company’s revenue has grown 10x per year over the past three years, the CEO said, going from zero to $100 million in 2023, then $100 million to $1 billion in 2024, and will land somewhere between $8-10 billion by the end of this year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Amodei said he would be “really dumb” to just assume that the pattern would continue. “I don’t know if a year from now, if it’s going to be 20 billion or if it’s going to be 50…it’s very uncertain. I try to plan conservatively. So I plan for the lower side of it, but that is very disconcerting,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies like his have to plan how much compute they’ll need in the years ahead, and how much they should invest in data centers. If they don’t buy enough, they may not be able to serve their customers. And if they buy too much, they’ll struggle to keep up with costs or, in the worst-case scenario, they could go bankrupt. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, OpenAI landed in a PR crises when its CFO said she wanted the U.S. government to “backstop” her company’s infrastructure loans, aka insure them so taxpayers would pick of the bill if OpenAI could not. After the furor, she walked back the comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those who take more risks could overextend themselves, Amodei warned, especially if “you’re a person who just kind of, like constitutionally, just wants to ‘YOLO’ things, or just likes big numbers,” he said, in a veiled reference to OpenAI CEO Sam Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think we’re going to be okay in, basically, almost all worlds…I can’t speak for other companies,” he said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/anthropic-ceo-weighs-in-on-ai-bubble-talk-and-risk-taking-among-competitors/</guid><pubDate>Thu, 04 Dec 2025 20:22:59 +0000</pubDate></item><item><title>[NEW] In comedy of errors, men accused of wiping gov databases turned to an AI tool (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/12/previously-convicted-contractors-wiped-gov-databases-after-being-fired-feds-say/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Defendants were convicted of similar crimes a decade ago. How were they cleared again?
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hand recovering folder with the  word "confidential" from a file cabinet.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Two sibling contractors convicted a decade ago for hacking into US State Department systems have once again been charged, this time for a comically hamfisted attempt to steal and destroy government records just minutes after being fired from their contractor jobs.&lt;/p&gt;
&lt;p&gt;The Department of Justice on Thursday said that Muneeb Akhter and Sohaib Akhter, both 34, of Alexandria, Virginia, deleted databases and documents maintained and belonging to three government agencies. The brothers were federal contractors working for an undisclosed company in Washington, DC, that provides software and services to 45 US agencies. Prosecutors said the men coordinated the crimes and began carrying them out just minutes after being fired.&lt;/p&gt;
&lt;h2&gt;Using AI to cover up an alleged crime—what could go wrong?&lt;/h2&gt;
&lt;p&gt;On February 18 at roughly 4:55 pm, the men were fired from the company, according to an indictment unsealed on Thursday. Five minutes later, they allegedly began trying to access their employer’s system and access federal government databases. By then, access to one of the brothers’ accounts had already been terminated. The other brother, however, allegedly accessed a government agency’s database stored on the employer’s server and issued commands to prevent other users from connecting or making changes to the database. Then, prosecutors said, he issued a command to delete 96 databases, many of which contained sensitive investigative files and records related to Freedom of Information Act matters.&lt;/p&gt;
&lt;p&gt;Despite their brazen attempt to steal and destroy information from multiple government agencies, the men lacked knowledge of the database commands needed to cover up their alleged crimes. So they allegedly did what many amateurs do: turned to an AI chat tool.&lt;/p&gt;
&lt;p&gt;One minute after deleting Department of Homeland Security information, Muneep Akhter allegedly asked an AI tool “how do i clear system logs from SQL servers after deleting databases.” Shortly afterward, he queried the tool “how do you clear all event and application logs from Microsoft windows server 2012,” prosecutors said.&lt;/p&gt;
&lt;p&gt;The indictment provides enough details of the databases wiped and information stolen to indicate that the brothers’ attempts to cover their tracks failed. It’s unclear whether the apparent failure was due to the AI tool providing inadequate instructions or the men failing to follow them correctly. Prosecutors say they also obtained records of discussions between the men in the hours or days following, in which they discussed removing incriminating evidence from their homes. Three days later, the men allegedly wiped their employer-issued laptops by reinstalling the operating system.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The alleged incident isn’t the first time the men have faced charges of hacking government systems and stealing documents. In 2015, they pleaded guilty to conspiracy to hack into the State Department and a private company. They stole “sensitive passport and visa information” and personal information belonging to dozens of co-workers. They later tried to install an electronic collection device inside a State Department building so they could maintain persistent access to State Department systems.&lt;/p&gt;
&lt;p&gt;Later, Muneeb Akhter hacked into a database maintained by a data aggregation company that employed him. He then stole information that would help win contracts and clients for a tech company they owned. He also planted code inside the employers’ servers that caused them to cast votes for him in an online contest. Muneeb Akhter received a sentence of 39 months in prison and Sohaib Akhter was sentenced to 24 months. Each was also sentenced to three years of supervised release.&lt;/p&gt;
&lt;p&gt;The indictment unsealed Thursday charges Muneeb Akhter with conspiracy to commit computer fraud and to destroy records, two counts of computer fraud, theft of US government records, and two counts of aggravated identity theft. Sohaib Akhter is charged with conspiracy to commit computer fraud and to destroy records and computer fraud, for trafficking passwords.&lt;/p&gt;
&lt;p&gt;If convicted, Muneeb Akhter faces a mandatory minimum penalty of two years in prison for each aggravated identity theft count and a maximum penalty of 45 years in prison on the remaining charges. If convicted, Sohaib Akhter faces a maximum penalty of six years in prison.&lt;/p&gt;
&lt;p&gt;The allegations, if true, read like a comedy of errors. It’s hard to fathom a justification for the brothers receiving clearances and landing jobs at a government contractor company with access to sensitive information. The employers’ alleged failure to confiscate the laptops and to immediately disconnect the brothers’ work accounts upon termination also appears to indicate a lack of basic operational security on the part of the company. Possibly most astonishing, why did Muneep Akhter want to wipe a machine running Windows Server 12, an OS that hasn’t supported in more than two years?&lt;/p&gt;
&lt;p&gt;And last, if the allegations are true, the reliance on AI to make up for a lack of database and laptop skills necessary to cover up such an audacious act qualifies each for an inept criminal of the year award.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Defendants were convicted of similar crimes a decade ago. How were they cleared again?
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hand recovering folder with the  word "confidential" from a file cabinet.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Two sibling contractors convicted a decade ago for hacking into US State Department systems have once again been charged, this time for a comically hamfisted attempt to steal and destroy government records just minutes after being fired from their contractor jobs.&lt;/p&gt;
&lt;p&gt;The Department of Justice on Thursday said that Muneeb Akhter and Sohaib Akhter, both 34, of Alexandria, Virginia, deleted databases and documents maintained and belonging to three government agencies. The brothers were federal contractors working for an undisclosed company in Washington, DC, that provides software and services to 45 US agencies. Prosecutors said the men coordinated the crimes and began carrying them out just minutes after being fired.&lt;/p&gt;
&lt;h2&gt;Using AI to cover up an alleged crime—what could go wrong?&lt;/h2&gt;
&lt;p&gt;On February 18 at roughly 4:55 pm, the men were fired from the company, according to an indictment unsealed on Thursday. Five minutes later, they allegedly began trying to access their employer’s system and access federal government databases. By then, access to one of the brothers’ accounts had already been terminated. The other brother, however, allegedly accessed a government agency’s database stored on the employer’s server and issued commands to prevent other users from connecting or making changes to the database. Then, prosecutors said, he issued a command to delete 96 databases, many of which contained sensitive investigative files and records related to Freedom of Information Act matters.&lt;/p&gt;
&lt;p&gt;Despite their brazen attempt to steal and destroy information from multiple government agencies, the men lacked knowledge of the database commands needed to cover up their alleged crimes. So they allegedly did what many amateurs do: turned to an AI chat tool.&lt;/p&gt;
&lt;p&gt;One minute after deleting Department of Homeland Security information, Muneep Akhter allegedly asked an AI tool “how do i clear system logs from SQL servers after deleting databases.” Shortly afterward, he queried the tool “how do you clear all event and application logs from Microsoft windows server 2012,” prosecutors said.&lt;/p&gt;
&lt;p&gt;The indictment provides enough details of the databases wiped and information stolen to indicate that the brothers’ attempts to cover their tracks failed. It’s unclear whether the apparent failure was due to the AI tool providing inadequate instructions or the men failing to follow them correctly. Prosecutors say they also obtained records of discussions between the men in the hours or days following, in which they discussed removing incriminating evidence from their homes. Three days later, the men allegedly wiped their employer-issued laptops by reinstalling the operating system.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The alleged incident isn’t the first time the men have faced charges of hacking government systems and stealing documents. In 2015, they pleaded guilty to conspiracy to hack into the State Department and a private company. They stole “sensitive passport and visa information” and personal information belonging to dozens of co-workers. They later tried to install an electronic collection device inside a State Department building so they could maintain persistent access to State Department systems.&lt;/p&gt;
&lt;p&gt;Later, Muneeb Akhter hacked into a database maintained by a data aggregation company that employed him. He then stole information that would help win contracts and clients for a tech company they owned. He also planted code inside the employers’ servers that caused them to cast votes for him in an online contest. Muneeb Akhter received a sentence of 39 months in prison and Sohaib Akhter was sentenced to 24 months. Each was also sentenced to three years of supervised release.&lt;/p&gt;
&lt;p&gt;The indictment unsealed Thursday charges Muneeb Akhter with conspiracy to commit computer fraud and to destroy records, two counts of computer fraud, theft of US government records, and two counts of aggravated identity theft. Sohaib Akhter is charged with conspiracy to commit computer fraud and to destroy records and computer fraud, for trafficking passwords.&lt;/p&gt;
&lt;p&gt;If convicted, Muneeb Akhter faces a mandatory minimum penalty of two years in prison for each aggravated identity theft count and a maximum penalty of 45 years in prison on the remaining charges. If convicted, Sohaib Akhter faces a maximum penalty of six years in prison.&lt;/p&gt;
&lt;p&gt;The allegations, if true, read like a comedy of errors. It’s hard to fathom a justification for the brothers receiving clearances and landing jobs at a government contractor company with access to sensitive information. The employers’ alleged failure to confiscate the laptops and to immediately disconnect the brothers’ work accounts upon termination also appears to indicate a lack of basic operational security on the part of the company. Possibly most astonishing, why did Muneep Akhter want to wipe a machine running Windows Server 12, an OS that hasn’t supported in more than two years?&lt;/p&gt;
&lt;p&gt;And last, if the allegations are true, the reliance on AI to make up for a lack of database and laptop skills necessary to cover up such an audacious act qualifies each for an inept criminal of the year award.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/12/previously-convicted-contractors-wiped-gov-databases-after-being-fired-feds-say/</guid><pubDate>Thu, 04 Dec 2025 21:51:36 +0000</pubDate></item><item><title>[NEW] Micro1, a Scale AI competitor, touts crossing $100M ARR (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/micro1-a-scale-ai-competitor-touts-crossing-100m-arr/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/IMG_2686_36fac2.jpeg?w=1057" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Micro1’s rapid climb over the past two years has pushed it into a cohort of AI companies scaling at breakneck speed. The three-year-old startup, which helps AI labs recruit and manage human experts for training data, started the year with roughly $7 million in annual recurring revenue (ARR).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, it claims to have surpassed $100 million in ARR, founder and CEO Ali Ansari told TechCrunch. That figure is also more than double the revenue Micro1 reported in September when it announced its $35 million Series A at a $500 million valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ansari, 24, said then that Micro1 works with leading AI labs, including Microsoft, as well as Fortune 100 companies racing to improve large language models through post-training and reinforcement learning. Their demand for top-tier human data has fueled a fast-expanding market that Ansari believes will grow from $10-15 billion today to nearly $100 billion within two years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Micro1’s rise, and that of larger competitors such as Mercor and Surge, accelerated after OpenAI and Google DeepMind reportedly cut ties with Scale AI following Meta’s $14 billion investment in the vendor and its decision to hire Scale’s CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Micro1’s ARR is growing fast, according to the founder, it hasn’t yet matched its rivals: Mercor’s more than $450 million, sources told TechCrunch, and Surge’s reported $1.2 billion in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ansari attributes Micro1’s growth to its ability to recruit and evaluate domain experts quickly. Like Mercor, Micro1 began as an AI recruiter called Zara, matching engineering talent with software roles before pivoting into the data-training market. That tool now interviews and vets applicants seeking expert roles on the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond supplying expert-level data to leading AI labs, Ansari says two new segments, still barely visible today, are on track to reshape the economics of human data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first involves non-AI-native Fortune 1000 enterprises that will begin building AI agents for internal workflows, support operations, finance, and industry-specific tasks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developing these agents requires systematic evaluation: testing frontier models, grading their output, choosing winners, fine-tuning them, and continuously validating performance in production. Ansari argues this cycle depends heavily on human experts evaluating AI behavior at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second is robotics pre-training, which requires high-quality, human-generated demonstrations of everyday physical tasks. Micro1 is already building what Ansari calls the world’s largest robotics pre-training dataset, collecting demonstrations from hundreds of generalists recording object interactions in their homes. Robotics companies will need vast volumes of this data before their systems can reliably operate in homes and offices, he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We anticipate that a good portion of the product budgets at non-AI-native enterprises will go towards evals and human data, moving from 0% to at least 25% of product budgets,” said the CEO, who founded Micro1 while at UC Berkeley. “We’re also helping robotics labs create robotics data; these two areas will account for a massive share of that $100 billion-a-year market.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even as new markets emerge, Micro1’s current growth still comes primarily from elite AI labs and AI-heavy enterprises. The startup is scaling its work with these labs on reinforcement learning, the feedback loop  to test and improve model behavior.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Micro1 hopes its early move into robotics data and enterprise agent development, in addition to scaling its specialized RL environments, will help it capture additional market share as the data wars intensify.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Ansari says the company is focused on scaling responsibly, paying experts well, and keeping people at the center of an industry built on training machines.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently manages thousands of experts across hundreds of domains, ranging from highly technical fields to surprisingly offline disciplines. Many earn close to $100 an hour, according to Ansari.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are Harvard professors and Stanford PhDs spending half their week training AI through Micro1,” Ansari said. “But the bigger shift is in the sheer volume and range of roles. It’s expanding into areas you wouldn’t expect to matter for language model training, including offline and less technical fields. We’re very optimistic about where this is heading.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/IMG_2686_36fac2.jpeg?w=1057" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Micro1’s rapid climb over the past two years has pushed it into a cohort of AI companies scaling at breakneck speed. The three-year-old startup, which helps AI labs recruit and manage human experts for training data, started the year with roughly $7 million in annual recurring revenue (ARR).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, it claims to have surpassed $100 million in ARR, founder and CEO Ali Ansari told TechCrunch. That figure is also more than double the revenue Micro1 reported in September when it announced its $35 million Series A at a $500 million valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ansari, 24, said then that Micro1 works with leading AI labs, including Microsoft, as well as Fortune 100 companies racing to improve large language models through post-training and reinforcement learning. Their demand for top-tier human data has fueled a fast-expanding market that Ansari believes will grow from $10-15 billion today to nearly $100 billion within two years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Micro1’s rise, and that of larger competitors such as Mercor and Surge, accelerated after OpenAI and Google DeepMind reportedly cut ties with Scale AI following Meta’s $14 billion investment in the vendor and its decision to hire Scale’s CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Micro1’s ARR is growing fast, according to the founder, it hasn’t yet matched its rivals: Mercor’s more than $450 million, sources told TechCrunch, and Surge’s reported $1.2 billion in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ansari attributes Micro1’s growth to its ability to recruit and evaluate domain experts quickly. Like Mercor, Micro1 began as an AI recruiter called Zara, matching engineering talent with software roles before pivoting into the data-training market. That tool now interviews and vets applicants seeking expert roles on the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond supplying expert-level data to leading AI labs, Ansari says two new segments, still barely visible today, are on track to reshape the economics of human data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first involves non-AI-native Fortune 1000 enterprises that will begin building AI agents for internal workflows, support operations, finance, and industry-specific tasks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developing these agents requires systematic evaluation: testing frontier models, grading their output, choosing winners, fine-tuning them, and continuously validating performance in production. Ansari argues this cycle depends heavily on human experts evaluating AI behavior at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second is robotics pre-training, which requires high-quality, human-generated demonstrations of everyday physical tasks. Micro1 is already building what Ansari calls the world’s largest robotics pre-training dataset, collecting demonstrations from hundreds of generalists recording object interactions in their homes. Robotics companies will need vast volumes of this data before their systems can reliably operate in homes and offices, he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We anticipate that a good portion of the product budgets at non-AI-native enterprises will go towards evals and human data, moving from 0% to at least 25% of product budgets,” said the CEO, who founded Micro1 while at UC Berkeley. “We’re also helping robotics labs create robotics data; these two areas will account for a massive share of that $100 billion-a-year market.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even as new markets emerge, Micro1’s current growth still comes primarily from elite AI labs and AI-heavy enterprises. The startup is scaling its work with these labs on reinforcement learning, the feedback loop  to test and improve model behavior.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Micro1 hopes its early move into robotics data and enterprise agent development, in addition to scaling its specialized RL environments, will help it capture additional market share as the data wars intensify.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Ansari says the company is focused on scaling responsibly, paying experts well, and keeping people at the center of an industry built on training machines.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently manages thousands of experts across hundreds of domains, ranging from highly technical fields to surprisingly offline disciplines. Many earn close to $100 an hour, according to Ansari.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are Harvard professors and Stanford PhDs spending half their week training AI through Micro1,” Ansari said. “But the bigger shift is in the sheer volume and range of roles. It’s expanding into areas you wouldn’t expect to matter for language model training, including offline and less technical fields. We’re very optimistic about where this is heading.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/micro1-a-scale-ai-competitor-touts-crossing-100m-arr/</guid><pubDate>Thu, 04 Dec 2025 22:45:31 +0000</pubDate></item><item><title>[NEW] The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes (AI | VentureBeat)</title><link>https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess</link><description>[unable to retrieve full-text content]&lt;p&gt;OpenAI researchers have introduced a novel method that acts as a &amp;quot;truth serum&amp;quot; for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, &amp;quot;&lt;a href="https://openai.com/index/how-confessions-can-keep-language-models-honest/"&gt;&lt;u&gt;confessions&lt;/u&gt;&lt;/a&gt;,&amp;quot; addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. &lt;/p&gt;&lt;p&gt;For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.&lt;/p&gt;&lt;h2&gt;What are confessions?&lt;/h2&gt;&lt;p&gt;Many forms of AI deception result from the complexities of the &lt;a href="https://venturebeat.com/ai/open-source-deepseek-r1-uses-pure-reinforcement-learning-to-match-openai-o1-at-95-less-cost/"&gt;&lt;u&gt;reinforcement learning&lt;/u&gt;&lt;/a&gt; (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of &amp;quot;reward misspecification,&amp;quot; where models learn to produce answers that simply &amp;quot;look good&amp;quot; to the reward function, rather than answers that are genuinely faithful to a user&amp;#x27;s intent.&lt;/p&gt;&lt;p&gt;A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.&lt;/p&gt;&lt;p&gt;In a &lt;a href="https://openai.com/index/how-confessions-can-keep-language-models-honest/"&gt;&lt;u&gt;blog post&lt;/u&gt;&lt;/a&gt;, the OpenAI researchers provide a few examples the &amp;quot;confessions&amp;quot; technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model &amp;quot;sandbagged&amp;quot; by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, &amp;quot;The user wanted correct answers, but we sabotaged half of them.&amp;quot; &lt;/p&gt;&lt;p&gt;The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.&lt;/p&gt;&lt;h2&gt;How confession training works&lt;/h2&gt;&lt;p&gt;The key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. &amp;quot;Like the Catholic Church’s &amp;#x27;seal of confession&amp;#x27;, nothing that the model reveals can change the reward it receives for completing its original task,&amp;quot; the researchers write. This creates a &amp;quot;safe space&amp;quot; for the model to admit fault without penalty.&lt;/p&gt;&lt;p&gt;This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. &lt;/p&gt;&lt;p&gt;Therefore, when the model is judged purely on honesty, its incentive to trick the &amp;quot;confession judge&amp;quot; is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to &amp;quot;hack&amp;quot; a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.&lt;/p&gt;&lt;p&gt;However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for &amp;quot;unknown unknowns.&amp;quot; For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.&lt;/p&gt;&lt;h2&gt;What it means for enterprise AI&lt;/h2&gt;&lt;p&gt;OpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn &lt;a href="https://venturebeat.com/ai/subliminal-learning-anthropic-uncovers-how-ai-fine-tuning-secretly-teaches-bad-habits"&gt;&lt;u&gt;malicious behavior&lt;/u&gt;&lt;/a&gt;. The company is also working toward &lt;a href="https://venturebeat.com/ai/anthropic-just-made-it-harder-for-ai-to-go-rogue-with-its-updated-safety-policy"&gt;&lt;u&gt;plugging these holes&lt;/u&gt;&lt;/a&gt; as they emerge.&lt;/p&gt;&lt;p&gt;For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.&lt;/p&gt;&lt;p&gt;In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.&lt;/p&gt;&lt;p&gt;“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;OpenAI researchers have introduced a novel method that acts as a &amp;quot;truth serum&amp;quot; for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, &amp;quot;&lt;a href="https://openai.com/index/how-confessions-can-keep-language-models-honest/"&gt;&lt;u&gt;confessions&lt;/u&gt;&lt;/a&gt;,&amp;quot; addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. &lt;/p&gt;&lt;p&gt;For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.&lt;/p&gt;&lt;h2&gt;What are confessions?&lt;/h2&gt;&lt;p&gt;Many forms of AI deception result from the complexities of the &lt;a href="https://venturebeat.com/ai/open-source-deepseek-r1-uses-pure-reinforcement-learning-to-match-openai-o1-at-95-less-cost/"&gt;&lt;u&gt;reinforcement learning&lt;/u&gt;&lt;/a&gt; (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of &amp;quot;reward misspecification,&amp;quot; where models learn to produce answers that simply &amp;quot;look good&amp;quot; to the reward function, rather than answers that are genuinely faithful to a user&amp;#x27;s intent.&lt;/p&gt;&lt;p&gt;A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.&lt;/p&gt;&lt;p&gt;In a &lt;a href="https://openai.com/index/how-confessions-can-keep-language-models-honest/"&gt;&lt;u&gt;blog post&lt;/u&gt;&lt;/a&gt;, the OpenAI researchers provide a few examples the &amp;quot;confessions&amp;quot; technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model &amp;quot;sandbagged&amp;quot; by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, &amp;quot;The user wanted correct answers, but we sabotaged half of them.&amp;quot; &lt;/p&gt;&lt;p&gt;The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.&lt;/p&gt;&lt;h2&gt;How confession training works&lt;/h2&gt;&lt;p&gt;The key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. &amp;quot;Like the Catholic Church’s &amp;#x27;seal of confession&amp;#x27;, nothing that the model reveals can change the reward it receives for completing its original task,&amp;quot; the researchers write. This creates a &amp;quot;safe space&amp;quot; for the model to admit fault without penalty.&lt;/p&gt;&lt;p&gt;This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. &lt;/p&gt;&lt;p&gt;Therefore, when the model is judged purely on honesty, its incentive to trick the &amp;quot;confession judge&amp;quot; is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to &amp;quot;hack&amp;quot; a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.&lt;/p&gt;&lt;p&gt;However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for &amp;quot;unknown unknowns.&amp;quot; For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.&lt;/p&gt;&lt;h2&gt;What it means for enterprise AI&lt;/h2&gt;&lt;p&gt;OpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn &lt;a href="https://venturebeat.com/ai/subliminal-learning-anthropic-uncovers-how-ai-fine-tuning-secretly-teaches-bad-habits"&gt;&lt;u&gt;malicious behavior&lt;/u&gt;&lt;/a&gt;. The company is also working toward &lt;a href="https://venturebeat.com/ai/anthropic-just-made-it-harder-for-ai-to-go-rogue-with-its-updated-safety-policy"&gt;&lt;u&gt;plugging these holes&lt;/u&gt;&lt;/a&gt; as they emerge.&lt;/p&gt;&lt;p&gt;For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.&lt;/p&gt;&lt;p&gt;In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.&lt;/p&gt;&lt;p&gt;“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess</guid><pubDate>Thu, 04 Dec 2025 23:00:00 +0000</pubDate></item><item><title>[NEW] All the biggest news from AWS’ big tech show re:Invent 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped. And the singular message, amid a deluge of product news and keynotes, was AI for the enterprise. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year it was all about upgrades that give customers greater control to customize AI agents, including one that AWS claims can learn from you and then work independently for days. Amazon CTO Dr. Werner Vogels capped off the final night with a keynote aimed at lifting up developers and assuaging any fears at AI is coming for engineering jobs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On December 3, the conference pressed on with its AI agents messaging, as well as deeper dives into customer stories. Swami Sivasubramanian, vice president of Agentic AI at AWS, gave one of the keynote talks. To say he was bullish is perhaps understating the vibe. &lt;/p&gt;&lt;p&gt;“We are living in times of great change,” Sivasubramanian said during the talk. “For the first time in history, we can describe what we want to accomplish in natural language, and agents generate the plan. They write the code, call the necessary tools, and execute the complete solution. Agents give you the freedom to build without limits, accelerating how quickly you can go from idea to impact in a big way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the ones that got our attention. TechCrunch will update this article, with the newest insights at the top, through the end of AWS re:Invent. Be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-werner-out"&gt;Werner out …&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CTO Werner Vogels had the closing keynote of the conference — and it looks like this will be his last one. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This is my final re:Invent keynote,” he said, then quickly added he is not leaving the company. “I’m not leaving Amazon or anything like that, but I think that after 14 re:Invents you guys are owed young, fresh, new voices.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vogels then spent more than an hour talking to a packed room before ending with a “Werner, out” and a literal mic drop. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-ai-take-your-job"&gt;Will AI take your job? &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Vogels spent much of the closing keynote talking about AI and its role in the future, including the looming threat that it will take away jobs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Will AI take my job? Maybe,” Vogels asked and answered, before noting that some tasks will be automated, and some skills will become obsolete. “So maybe we should rephrase and reframe this question. We will AI make me obsolete? Absolutely not, if you evolve.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-next-gen-cpu"&gt;Next-gen CPU&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS unveiled its Graviton5 CPU on Thursday, the next-generation chip that the company promises will be its highest performing, most efficient yet. The Graviton5 contains 192 processor cores, a dense and efficient design that AWS says reduces the distance data must travel between cores. That helps cut inter-core communication latency by up to 33% while increasing bandwidth, the company said.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-doubling-down-on-llms"&gt;Doubling down on LLMs&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced more tools for enterprise customers to create their own models. Specifically, AWS said it is adding new capabilities for both Amazon Bedrock and Amazon SageMaker AI to make building custom LLMs easier. &lt;/p&gt;&lt;p&gt;For instance, AWS is bringing serverless model customization to SageMaker, which allows developers to start building a model without needing to think about compute resources or infrastructure. The serverless model customization can be accessed through either a self-guided path or by prompting an AI agent.&lt;/p&gt;&lt;p&gt;AWS also announced Reinforcement Fine Tuning in Bedrock, which allows developers to choose a preset workflow or reward system and have Bedrock run their customization process automatically from start to finish.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-andy-jassy-shares-some-numbers"&gt;Andy Jassy shares some numbers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CEO Andy Jassy took to social media platform X to expound on AWS chief Matt Garman’s keynote speech. The message: The current generation of its Nvidia-competitor AI chip Trainium2 is already bringing in loads of cash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments were tied to the reveal of its next-generation chip, Trainium3, and meant to forecast a promising revenue future for the product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-database-savings-arrives"&gt;Database savings arrives&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tucked among the dozens of announcements is one item that is already getting cheers: Discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, AWS said it was launching Database Savings Plans, which help customers reduce database costs by up to 35% when they commit to a consistent amount of usage ($/hour) over a one-year term. The company said the savings will automatically apply each hour to eligible usage across supported database services, and any additional usage beyond the commitment is billed at on-demand rates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Corey Quinn, chief cloud economist at Duckbill, summed it up well in his blog post, “Six years of complaining finally pays off.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-can-t-get-a-better-deal-than-free-amazon-hopes"&gt;Can’t get a better deal than free, Amazon hopes  &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Is there any way for another AI coding tool to win the hearts of startup founders? Amazon hopes a year’s worth of credits, for free, will do the trick for its offering, Kiro. The company will be giving away credits to Kiro Pro+ to qualified startups that apply for the deal before the end of the month. However, only early-stage startups in certain countries are eligible.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



[embedded content]


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped. And the singular message, amid a deluge of product news and keynotes, was AI for the enterprise. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year it was all about upgrades that give customers greater control to customize AI agents, including one that AWS claims can learn from you and then work independently for days. Amazon CTO Dr. Werner Vogels capped off the final night with a keynote aimed at lifting up developers and assuaging any fears at AI is coming for engineering jobs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On December 3, the conference pressed on with its AI agents messaging, as well as deeper dives into customer stories. Swami Sivasubramanian, vice president of Agentic AI at AWS, gave one of the keynote talks. To say he was bullish is perhaps understating the vibe. &lt;/p&gt;&lt;p&gt;“We are living in times of great change,” Sivasubramanian said during the talk. “For the first time in history, we can describe what we want to accomplish in natural language, and agents generate the plan. They write the code, call the necessary tools, and execute the complete solution. Agents give you the freedom to build without limits, accelerating how quickly you can go from idea to impact in a big way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the ones that got our attention. TechCrunch will update this article, with the newest insights at the top, through the end of AWS re:Invent. Be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-werner-out"&gt;Werner out …&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CTO Werner Vogels had the closing keynote of the conference — and it looks like this will be his last one. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This is my final re:Invent keynote,” he said, then quickly added he is not leaving the company. “I’m not leaving Amazon or anything like that, but I think that after 14 re:Invents you guys are owed young, fresh, new voices.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vogels then spent more than an hour talking to a packed room before ending with a “Werner, out” and a literal mic drop. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-ai-take-your-job"&gt;Will AI take your job? &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Vogels spent much of the closing keynote talking about AI and its role in the future, including the looming threat that it will take away jobs. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Will AI take my job? Maybe,” Vogels asked and answered, before noting that some tasks will be automated, and some skills will become obsolete. “So maybe we should rephrase and reframe this question. We will AI make me obsolete? Absolutely not, if you evolve.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-next-gen-cpu"&gt;Next-gen CPU&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS unveiled its Graviton5 CPU on Thursday, the next-generation chip that the company promises will be its highest performing, most efficient yet. The Graviton5 contains 192 processor cores, a dense and efficient design that AWS says reduces the distance data must travel between cores. That helps cut inter-core communication latency by up to 33% while increasing bandwidth, the company said.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-doubling-down-on-llms"&gt;Doubling down on LLMs&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced more tools for enterprise customers to create their own models. Specifically, AWS said it is adding new capabilities for both Amazon Bedrock and Amazon SageMaker AI to make building custom LLMs easier. &lt;/p&gt;&lt;p&gt;For instance, AWS is bringing serverless model customization to SageMaker, which allows developers to start building a model without needing to think about compute resources or infrastructure. The serverless model customization can be accessed through either a self-guided path or by prompting an AI agent.&lt;/p&gt;&lt;p&gt;AWS also announced Reinforcement Fine Tuning in Bedrock, which allows developers to choose a preset workflow or reward system and have Bedrock run their customization process automatically from start to finish.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-andy-jassy-shares-some-numbers"&gt;Andy Jassy shares some numbers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CEO Andy Jassy took to social media platform X to expound on AWS chief Matt Garman’s keynote speech. The message: The current generation of its Nvidia-competitor AI chip Trainium2 is already bringing in loads of cash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments were tied to the reveal of its next-generation chip, Trainium3, and meant to forecast a promising revenue future for the product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-database-savings-arrives"&gt;Database savings arrives&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tucked among the dozens of announcements is one item that is already getting cheers: Discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, AWS said it was launching Database Savings Plans, which help customers reduce database costs by up to 35% when they commit to a consistent amount of usage ($/hour) over a one-year term. The company said the savings will automatically apply each hour to eligible usage across supported database services, and any additional usage beyond the commitment is billed at on-demand rates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Corey Quinn, chief cloud economist at Duckbill, summed it up well in his blog post, “Six years of complaining finally pays off.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-can-t-get-a-better-deal-than-free-amazon-hopes"&gt;Can’t get a better deal than free, Amazon hopes  &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Is there any way for another AI coding tool to win the hearts of startup founders? Amazon hopes a year’s worth of credits, for free, will do the trick for its offering, Kiro. The company will be giving away credits to Kiro Pro+ to qualified startups that apply for the deal before the end of the month. However, only early-stage startups in certain countries are eligible.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



[embedded content]


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</guid><pubDate>Fri, 05 Dec 2025 01:17:08 +0000</pubDate></item><item><title>[NEW] Chicago Tribune sues Perplexity (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/04/chicago-tribune-sues-perplexity/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2169504075.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Chicago Tribune filed a lawsuit against AI search engine Perplexity on Thursday alleging copyright infringement. The suit, seen by TechCrunch, was filed in a federal court in New York. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Tribune alleges that its lawyers contacted Perplexity in mid-October asking if the AI search engine was using its content, according to the complaint. Perplexity’s lawyers replied it did not train models with the Tribune’s work, but that it “may receive non-verbatim factual summaries,” the lawsuit claims.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Tribune’s lawyers, however, argue that Perplexity is delivering Tribune content verbatim. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, the newspaper’s lawyers are also calling out Perplexity’s Retrieval Augmented Generation (RAG) as a culprit. RAG is a method used to limit hallucinations by having the model only use an accurate or verified data source. The Tribune argues that Perplexity is using the newspaper’s content in its RAG systems, scraped without permission. Plus, it alleges the Perplexity’s Comet browser is bypassing the paper’s paywall to deliver detailed summaries of those articles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Tribune is one of 17 news publications from MediaNews Group and Tribune Publishing that sued OpenAI and Microsoft over model training material in April. That suit is ongoing. Another nine from these publishers sued the model maker and its cloud provider in November, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While creators have filed many lawsuits against model makers over using their work for model training, we’ll have to see if the courts weigh in about the legal liabilities of RAG as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity did not immediately respond to the Chicago Tribune’s story about its own lawsuit, nor to TechCrunch’s request for comment. Perplexity is facing other such suits. Reddit filed one in October. Dow Jones is also suing. Last month, while Amazon didn’t sue, it did threaten to by sending a cease and desist letter over AI browser shopping. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2169504075.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Chicago Tribune filed a lawsuit against AI search engine Perplexity on Thursday alleging copyright infringement. The suit, seen by TechCrunch, was filed in a federal court in New York. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Tribune alleges that its lawyers contacted Perplexity in mid-October asking if the AI search engine was using its content, according to the complaint. Perplexity’s lawyers replied it did not train models with the Tribune’s work, but that it “may receive non-verbatim factual summaries,” the lawsuit claims.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Tribune’s lawyers, however, argue that Perplexity is delivering Tribune content verbatim. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, the newspaper’s lawyers are also calling out Perplexity’s Retrieval Augmented Generation (RAG) as a culprit. RAG is a method used to limit hallucinations by having the model only use an accurate or verified data source. The Tribune argues that Perplexity is using the newspaper’s content in its RAG systems, scraped without permission. Plus, it alleges the Perplexity’s Comet browser is bypassing the paper’s paywall to deliver detailed summaries of those articles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Tribune is one of 17 news publications from MediaNews Group and Tribune Publishing that sued OpenAI and Microsoft over model training material in April. That suit is ongoing. Another nine from these publishers sued the model maker and its cloud provider in November, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While creators have filed many lawsuits against model makers over using their work for model training, we’ll have to see if the courts weigh in about the legal liabilities of RAG as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity did not immediately respond to the Chicago Tribune’s story about its own lawsuit, nor to TechCrunch’s request for comment. Perplexity is facing other such suits. Reddit filed one in October. Dow Jones is also suing. Last month, while Amazon didn’t sue, it did threaten to by sending a cease and desist letter over AI browser shopping. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/04/chicago-tribune-sues-perplexity/</guid><pubDate>Fri, 05 Dec 2025 01:20:59 +0000</pubDate></item></channel></rss>