<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 17 Oct 2025 01:39:39 +0000</lastBuildDate><item><title>Amazon and Chobani adopt Strella's AI interviews for customer research as fast-growing startup raises $14M (AI | VentureBeat)</title><link>https://venturebeat.com/ai/amazon-and-chobani-adopt-strellas-ai-interviews-for-customer-research-as</link><description>[unable to retrieve full-text content]&lt;p&gt;One year after emerging from stealth, &lt;a href="https://www.strella.io/"&gt;&lt;u&gt;Strella&lt;/u&gt;&lt;/a&gt; has raised $14 million in Series A funding to expand its AI-powered customer research platform, the company announced Thursday. The round, led by &lt;a href="https://www.bvp.com/"&gt;&lt;u&gt;Bessemer Venture Partners&lt;/u&gt;&lt;/a&gt; with participation from &lt;a href="https://www.decibel.vc/"&gt;&lt;u&gt;Decibel Partners&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.bain.com/consulting-services/strategy/future-back-ventures/"&gt;&lt;u&gt;Bain Future Back Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.mvp-vc.com/"&gt;&lt;u&gt;MVP Ventures&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://645ventures.com/"&gt;&lt;u&gt;645 Ventures&lt;/u&gt;&lt;/a&gt;, comes as enterprises increasingly turn to artificial intelligence to understand customers faster and more deeply than traditional methods allow.&lt;/p&gt;&lt;p&gt;The investment marks a sharp acceleration for the startup founded by Lydia Hylton and Priya Krishnan, two former consultants and product managers who watched companies struggle with a customer research process that could take eight weeks from start to finish. Since October, Strella has grown revenue tenfold, quadrupled its customer base to more than 40 paying enterprises, and tripled its average contract values by moving upmarket to serve Fortune 500 companies.&lt;/p&gt;&lt;p&gt;&amp;quot;Research tends to be bookended by two very strategic steps: first, we have a problem—what research should we do? And second, we&amp;#x27;ve done the research—now what are we going to do with it?&amp;quot; said Hylton, Strella&amp;#x27;s CEO, in an exclusive interview with VentureBeat. &amp;quot;All the stuff in the middle tends to be execution and lower-skill work. We view Strella as doing that middle 90% of the work.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform now serves &lt;a href="https://www.amazon.com/"&gt;&lt;u&gt;Amazon&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.duolingo.com/"&gt;&lt;u&gt;Duolingo&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.apollographql.com/"&gt;&lt;u&gt;Apollo GraphQL&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.chobani.com/"&gt;&lt;u&gt;Chobani&lt;/u&gt;&lt;/a&gt;, collectively conducting thousands of AI-moderated interviews that deliver what the company claims is a 90% average time savings on manual research work. The company is approaching $1 million in revenue after beginning monetization only in January, with month-over-month growth of 50% and zero customer churn to date.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How AI-powered interviews compress eight-week research projects into days&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Strella&amp;#x27;s technology addresses a workflow that has frustrated product teams, marketers, and designers for decades. Traditional customer research requires writing interview guides, recruiting participants, scheduling calls, conducting interviews, taking notes, synthesizing findings, and creating presentations — a process that consumes weeks of highly-skilled labor and often delays critical product decisions.&lt;/p&gt;&lt;p&gt;The platform compresses that timeline to days by using AI to moderate voice-based interviews that run like Zoom calls, but with an artificial intelligence agent asking questions, following up on interesting responses, and detecting when participants are being evasive or fraudulent. The system then synthesizes findings automatically, creating highlight reels and charts from unstructured qualitative data.&lt;/p&gt;&lt;p&gt;&amp;quot;It used to take eight weeks. Now you can do it in the span of a couple days,&amp;quot; Hylton told VentureBeat. &amp;quot;The primary technology is through an AI-moderated interview. It&amp;#x27;s like being in a Zoom call with an AI instead of a human — it&amp;#x27;s completely free form and voice based.&amp;quot;&lt;/p&gt;&lt;p&gt;Critically, the platform also supports human moderators joining the same calls, reflecting the founders&amp;#x27; belief that humans won&amp;#x27;t disappear from the research process. &amp;quot;Human moderation won&amp;#x27;t go away, which is why we&amp;#x27;ve supported human moderation from our Genesis,&amp;quot; Hylton said. &amp;quot;Research tends to be bookended by two very strategic steps: we have a problem, what&amp;#x27;s the research that we should do? And we&amp;#x27;ve done the research, now what are we going to do with it? All the stuff in the middle tends to be execution and lower skill work. We view Strella as doing that middle 90% of the work.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why customers tell AI moderators the truth they won&amp;#x27;t share with humans&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of Strella&amp;#x27;s most surprising findings challenges assumptions about AI in qualitative research: participants appear more honest with AI moderators than with humans. The founders discovered this pattern repeatedly as customers ran head-to-head comparisons between traditional human-moderated studies and Strella&amp;#x27;s AI approach.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re a designer and you get on a Zoom call with a customer and you say, &amp;#x27;Do you like my design?&amp;#x27; they&amp;#x27;re always gonna say yes. They don&amp;#x27;t want to hurt your feelings,&amp;quot; Hylton explained. &amp;quot;But it&amp;#x27;s not a problem at all for Strella. They would tell you exactly what they think about it, which is really valuable. It&amp;#x27;s very hard to get honest feedback.&amp;quot;&lt;/p&gt;&lt;p&gt;Krishnan, Strella&amp;#x27;s COO, said companies initially worried about using AI and &amp;quot;eroding quality,&amp;quot; but the platform has &amp;quot;actually found the opposite to be true. People are much more open and honest with an AI moderator, and so the level of insight that you get is much richer because people are giving their unfiltered feedback.&amp;quot;&lt;/p&gt;&lt;p&gt;This dynamic has practical business implications. Brian Santiago, Senior Product Design Manager at Apollo GraphQL, said in a statement: &amp;quot;Before Strella, studies took weeks. Now we get insights in a day — sometimes in just a few hours. And because participants open up more with the AI moderator, the feedback is deeper and more honest.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform also addresses endemic fraud in online surveys, particularly when participants are compensated. Because Strella interviews happen on camera in real time, the AI moderator can detect when someone pauses suspiciously long — perhaps to consult ChatGPT — and flags them as potentially fraudulent. &amp;quot;We are fraud resistant,&amp;quot; Hylton said, contrasting this with traditional surveys where fraud rates can be substantial.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Solving mobile app research with persistent screen sharing technology&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A major focus of the Series A funding will be expanding &lt;a href="https://apps.apple.com/us/app/strella-mobile-interview/id6746277771"&gt;&lt;u&gt;Strella&amp;#x27;s recently-launched mobile application&lt;/u&gt;&lt;/a&gt;, which Krishnan identified as critical competitive differentiation. The mobile app enables persistent screen sharing during interviews — allowing researchers to watch users navigate mobile applications in real time while the AI moderator asks about their experience.&lt;/p&gt;&lt;p&gt;&amp;quot;We are the only player in the market that supports screen sharing on mobile,&amp;quot; Hylton said. &amp;quot;You know, I want to understand what are the pain points with my app? Why do people not seem to be able to find the checkout flow? Well, in order to do that effectively, you&amp;#x27;d like to see the user screen while they&amp;#x27;re doing an interview.&amp;quot;&lt;/p&gt;&lt;p&gt;For consumer-facing companies where mobile represents the primary customer interface, this capability opens entirely new use cases. The founders noted that &amp;quot;several of our customers didn&amp;#x27;t do research before&amp;quot; but have now built research practices around Strella because the platform finally made mobile research accessible at scale.&lt;/p&gt;&lt;p&gt;The platform also supports embedding traditional survey question types directly into the conversational interview, approaching what Hylton called &amp;quot;feature parity with a survey&amp;quot; while maintaining the engagement advantages of a natural conversation. Strella interviews regularly run 60 to 90 minutes with nearly 100% completion rates—a duration that would see 60-70% drop-off in a traditional survey format.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Strella differentiated in a market crowded with AI research startups&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Strella enters a market that appears crowded at first glance, with established players like &lt;a href="https://www.qualtrics.com/"&gt;&lt;u&gt;Qualtrics&lt;/u&gt;&lt;/a&gt; and a wave of AI-powered startups promising to transform customer research. The founders themselves initially pursued a different approach — synthetic respondents, or &amp;quot;digital twins&amp;quot; that simulate customer perspectives using large language models.&lt;/p&gt;&lt;p&gt;&amp;quot;We actually pivoted from that. That was our initial idea,&amp;quot; Hylton revealed, referring to synthetic respondents. &amp;quot;People are very intrigued by that concept, but found in practice, no willingness to pay right now.&amp;quot;&lt;/p&gt;&lt;p&gt;Recent research suggesting companies &lt;a href="https://venturebeat.com/ai/this-new-ai-technique-creates-digital-twin-consumers-and-it-could-kill-the"&gt;&lt;u&gt;could use language models as digital twins&lt;/u&gt;&lt;/a&gt; for customer feedback has reignited interest in that approach. But Hylton remains skeptical: &amp;quot;The capabilities of the LLMs as they are today are not good enough, in my opinion, to justify a standalone company. Right now you could just ask ChatGPT, &amp;#x27;What would new users of Duolingo think about this ad copy?&amp;#x27; You can do that. Adding the standalone idea of a synthetic panel is sort of just putting a wrapper on that.&amp;quot;&lt;/p&gt;&lt;p&gt;Instead, Strella&amp;#x27;s bet is that the real value lies in collecting proprietary qualitative data at scale — building what could become &amp;quot;the system of truth for all qualitative insights&amp;quot; within enterprises, as Lindsey Li, Vice President at Bessemer Venture Partners, described it.&lt;/p&gt;&lt;p&gt;Li, who led the investment just one year after Strella emerged from stealth, said the firm was convinced by both the technology and the team. &amp;quot;Strella has built highly differentiated technology that enables a continuous interview rather than a survey,&amp;quot; Li said. &amp;quot;We heard time and time again that customers loved this product experience relative to other offerings.&amp;quot;&lt;/p&gt;&lt;p&gt;On the defensibility question that concerns many AI investors, Li emphasized product execution over patents: &amp;quot;We think the long game here will be won with a million small product decisions, all of which must be driven by deep empathy for customer pain and an understanding of how best to address their needs. Lydia and Priya exhibit that in spades.&amp;quot;&lt;/p&gt;&lt;p&gt;The founders point to technical depth that&amp;#x27;s difficult to replicate. Most competitors started with adaptive surveys — text-based interfaces where users type responses and wait for the next question. Some have added voice, but typically as uploaded audio clips rather than free-flowing conversation.&lt;/p&gt;&lt;p&gt;&amp;quot;Our approach is fundamentally better, which is the fact that it is a free form conversation,&amp;quot; Hylton said. &amp;quot;You never have to control anything. You&amp;#x27;re never typing, there&amp;#x27;s no buttons, there&amp;#x27;s no upload and wait for the next question. It&amp;#x27;s completely free form, and that has been an extraordinarily hard product to build. There&amp;#x27;s a tremendous amount of IP in the way that we prompt our moderator, the way that we run analysis.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform also improves with use, learning from each customer&amp;#x27;s research patterns to fine-tune future interview guides and questions. &amp;quot;Our product gets better for our customers as they continue to use us,&amp;quot; Hylton said. All research accumulates in a central repository where teams can generate new insights by chatting with the data or creating visualizations from previously unstructured qualitative feedback.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Creating new research budgets instead of just automating existing ones&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps more important than displacing existing research is expanding the total market. Krishnan said growth has been &amp;quot;fundamentally related to our product&amp;quot; creating new research that wouldn&amp;#x27;t have happened otherwise.&lt;/p&gt;&lt;p&gt;&amp;quot;We have expanded the use cases in which people would conduct research,&amp;quot; Krishnan explained. &amp;quot;Several of our customers didn&amp;#x27;t do research before, have always wanted to do research, but didn&amp;#x27;t have a dedicated researcher or team at their company that was devoted to it, and have purchased Strella to kick off and enable their research practice. That&amp;#x27;s been really cool where we&amp;#x27;ve seen this market just opening up.&amp;quot;&lt;/p&gt;&lt;p&gt;This expansion comes as enterprises face mounting pressure to improve customer experience amid declining satisfaction scores. According to &lt;a href="https://www.forrester.com/press-newsroom/forrester-2024-us-customer-experience-index/"&gt;&lt;u&gt;Forrester Research&amp;#x27;s 2024 Customer Experience Index&lt;/u&gt;&lt;/a&gt;, customer experience quality has declined for three consecutive years — an unprecedented trend. The report found that 39% of brands saw CX quality deteriorate, with declines across effectiveness, ease, and emotional connection.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://www.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions.html"&gt;&lt;u&gt;Deloitte&amp;#x27;s 2025 Technology, Media &amp;amp; Telecommunications Predictions report&lt;/u&gt;&lt;/a&gt; forecasts that 25% of enterprises using generative AI will deploy AI agents by 2025, growing to 50% by 2027. The report specifically highlighted AI&amp;#x27;s potential to enhance customer satisfaction by 15-20% while reducing cost to serve by 20-30% when properly implemented.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.gartner.com/en/newsroom/press-releases/2023-08-30-gartner-reveals-three-technologies-that-will-transform-customer-service-and-support-by-2028"&gt;&lt;u&gt;Gartner&lt;/u&gt;&lt;/a&gt; identified conversational user interfaces — the category Strella inhabits — as one of three technologies poised to transform customer service by 2028, noting that &amp;quot;customers increasingly expect to be able to interact with the applications they use in a natural way.&amp;quot;&lt;/p&gt;&lt;p&gt;Against this backdrop, Li sees substantial room for growth. &amp;quot;UX Research is a sub-sector of the $140B+ global market-research industry,&amp;quot; Li said. &amp;quot;This includes both the software layer historically (~$430M) and professional services spend on UX research, design, product strategy, etc. which is conservatively estimated to be ~$6.4B+ annually. As software in this vertical, led by Strella, becomes more powerful, we believe the TAM will continue to expand meaningfully.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making customer feedback accessible across the enterprise, not just research teams&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The founders describe their mission as &amp;quot;democratizing access to the customer&amp;quot; — making it possible for anyone in an organization to understand customer perspectives without waiting for dedicated research teams to complete months-long studies.&lt;/p&gt;&lt;p&gt;&amp;quot;Many, many, many positions in the organization would like to get customer feedback, but it&amp;#x27;s so hard right now,&amp;quot; Hylton said. With Strella, she explained, someone can &amp;quot;log into Strella and through a chat, create any highlight reel that you want and actually see customers in their own words answering the question that you have based on the research that&amp;#x27;s already been done.&amp;quot;&lt;/p&gt;&lt;p&gt;This video-first approach to research repositories changes organizational dynamics around customer feedback. &amp;quot;Then you can say, &amp;#x27;Okay, engineering team, we need to build this feature. And here&amp;#x27;s the customer actually saying it,&amp;#x27;&amp;quot; Hylton continued. &amp;quot;&amp;#x27;This is not me. This isn&amp;#x27;t politics. Here are seven customers saying they can&amp;#x27;t find the Checkout button.&amp;#x27; The fact that we are a very video-based platform really allows us to do that quickly and painlessly.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has moved decisively upmarket, with contract values now typically in the five-figure range and &amp;quot;several six figure contracts&amp;quot; signed, according to Krishnan. The pricing strategy reflects a premium positioning: &amp;quot;Our product is very good, it&amp;#x27;s very premium. We&amp;#x27;re charging based on the value it provides to customers,&amp;quot; Krishnan said, rather than competing on cost alone.&lt;/p&gt;&lt;p&gt;This approach appears to be working. The company reports 100% conversion from pilot programs to paid contracts and zero churn among its 40-45 customers, with month-over-month revenue growth of 50%.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The roadmap: Computer vision, agentic AI, and human-machine collaboration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Series A funding will primarily support scaling product and go-to-market teams. &amp;quot;We&amp;#x27;re really confident that we have product-market fit,&amp;quot; Hylton said. &amp;quot;And now the question is execution, and we want to hire a lot of really talented people to help us execute.&amp;quot;&lt;/p&gt;&lt;p&gt;On the product roadmap, Hylton emphasized continued focus on the participant experience as the key to winning the market. &amp;quot;Everything else is downstream of a joyful participant experience,&amp;quot; she said, including &amp;quot;the quality of insights, the amount you have to pay people to do the interviews, and the way that your customers feel about a company.&amp;quot;&lt;/p&gt;&lt;p&gt;Near-term priorities include adding visual capabilities so the AI moderator can respond to facial expressions and other nonverbal cues, and building more sophisticated collaboration features between human researchers and AI moderators. &amp;quot;Maybe you want to listen while an AI moderator is running a call and you might want to be able to jump in with specific questions,&amp;quot; Hylton said. &amp;quot;Or you want to run an interview yourself, but you want the moderator to be there as backup or to help you.&amp;quot;&lt;/p&gt;&lt;p&gt;These features move toward what the industry calls &amp;quot;agentic AI&amp;quot; — systems that can act more autonomously while still collaborating with humans. The founders see this human-AI collaboration, rather than full automation, as the sustainable path forward.&lt;/p&gt;&lt;p&gt;&amp;quot;We believe that a lot of the really strategic work that companies do will continue to be human moderated,&amp;quot; Hylton said. &amp;quot;And you can still do that through Strella and just use us for synthesis in those cases.&amp;quot;&lt;/p&gt;&lt;p&gt;For Li and Bessemer, the bet is on founders who understand this nuance. &amp;quot;Lydia and Priya exhibit the exact archetype of founders we are excited to partner with for the long term — customer-obsessed, transparent, thoughtful, and singularly driven towards the home-run scenario,&amp;quot; she said.&lt;/p&gt;&lt;p&gt;The company declined to disclose specific revenue figures or valuation. With the new funding, Strella has now raised $18 million total, including a &lt;a href="https://venturebeat.com/ai/strella-raises-4-million-to-automate-market-research-with-ai-powered-customer-interviews"&gt;&lt;u&gt;$4 million seed round led by Decibel Partners announced in October&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;As Strella scales, the founders remain focused on a vision where technology enhances rather than eliminates human judgment—where an engineering team doesn&amp;#x27;t just read a research report, but watches seven customers struggle to find the same button. Where a product manager can query months of accumulated interviews in seconds. Where companies don&amp;#x27;t choose between speed and depth, but get both.&lt;/p&gt;&lt;p&gt;&amp;quot;The interesting part of the business is actually collecting that proprietary dataset, collecting qualitative research at scale,&amp;quot; Hylton said, describing what she sees as Strella&amp;#x27;s long-term moat. Not replacing the researcher, but making everyone in the company one.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;One year after emerging from stealth, &lt;a href="https://www.strella.io/"&gt;&lt;u&gt;Strella&lt;/u&gt;&lt;/a&gt; has raised $14 million in Series A funding to expand its AI-powered customer research platform, the company announced Thursday. The round, led by &lt;a href="https://www.bvp.com/"&gt;&lt;u&gt;Bessemer Venture Partners&lt;/u&gt;&lt;/a&gt; with participation from &lt;a href="https://www.decibel.vc/"&gt;&lt;u&gt;Decibel Partners&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.bain.com/consulting-services/strategy/future-back-ventures/"&gt;&lt;u&gt;Bain Future Back Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.mvp-vc.com/"&gt;&lt;u&gt;MVP Ventures&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://645ventures.com/"&gt;&lt;u&gt;645 Ventures&lt;/u&gt;&lt;/a&gt;, comes as enterprises increasingly turn to artificial intelligence to understand customers faster and more deeply than traditional methods allow.&lt;/p&gt;&lt;p&gt;The investment marks a sharp acceleration for the startup founded by Lydia Hylton and Priya Krishnan, two former consultants and product managers who watched companies struggle with a customer research process that could take eight weeks from start to finish. Since October, Strella has grown revenue tenfold, quadrupled its customer base to more than 40 paying enterprises, and tripled its average contract values by moving upmarket to serve Fortune 500 companies.&lt;/p&gt;&lt;p&gt;&amp;quot;Research tends to be bookended by two very strategic steps: first, we have a problem—what research should we do? And second, we&amp;#x27;ve done the research—now what are we going to do with it?&amp;quot; said Hylton, Strella&amp;#x27;s CEO, in an exclusive interview with VentureBeat. &amp;quot;All the stuff in the middle tends to be execution and lower-skill work. We view Strella as doing that middle 90% of the work.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform now serves &lt;a href="https://www.amazon.com/"&gt;&lt;u&gt;Amazon&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.duolingo.com/"&gt;&lt;u&gt;Duolingo&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.apollographql.com/"&gt;&lt;u&gt;Apollo GraphQL&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.chobani.com/"&gt;&lt;u&gt;Chobani&lt;/u&gt;&lt;/a&gt;, collectively conducting thousands of AI-moderated interviews that deliver what the company claims is a 90% average time savings on manual research work. The company is approaching $1 million in revenue after beginning monetization only in January, with month-over-month growth of 50% and zero customer churn to date.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How AI-powered interviews compress eight-week research projects into days&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Strella&amp;#x27;s technology addresses a workflow that has frustrated product teams, marketers, and designers for decades. Traditional customer research requires writing interview guides, recruiting participants, scheduling calls, conducting interviews, taking notes, synthesizing findings, and creating presentations — a process that consumes weeks of highly-skilled labor and often delays critical product decisions.&lt;/p&gt;&lt;p&gt;The platform compresses that timeline to days by using AI to moderate voice-based interviews that run like Zoom calls, but with an artificial intelligence agent asking questions, following up on interesting responses, and detecting when participants are being evasive or fraudulent. The system then synthesizes findings automatically, creating highlight reels and charts from unstructured qualitative data.&lt;/p&gt;&lt;p&gt;&amp;quot;It used to take eight weeks. Now you can do it in the span of a couple days,&amp;quot; Hylton told VentureBeat. &amp;quot;The primary technology is through an AI-moderated interview. It&amp;#x27;s like being in a Zoom call with an AI instead of a human — it&amp;#x27;s completely free form and voice based.&amp;quot;&lt;/p&gt;&lt;p&gt;Critically, the platform also supports human moderators joining the same calls, reflecting the founders&amp;#x27; belief that humans won&amp;#x27;t disappear from the research process. &amp;quot;Human moderation won&amp;#x27;t go away, which is why we&amp;#x27;ve supported human moderation from our Genesis,&amp;quot; Hylton said. &amp;quot;Research tends to be bookended by two very strategic steps: we have a problem, what&amp;#x27;s the research that we should do? And we&amp;#x27;ve done the research, now what are we going to do with it? All the stuff in the middle tends to be execution and lower skill work. We view Strella as doing that middle 90% of the work.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why customers tell AI moderators the truth they won&amp;#x27;t share with humans&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of Strella&amp;#x27;s most surprising findings challenges assumptions about AI in qualitative research: participants appear more honest with AI moderators than with humans. The founders discovered this pattern repeatedly as customers ran head-to-head comparisons between traditional human-moderated studies and Strella&amp;#x27;s AI approach.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re a designer and you get on a Zoom call with a customer and you say, &amp;#x27;Do you like my design?&amp;#x27; they&amp;#x27;re always gonna say yes. They don&amp;#x27;t want to hurt your feelings,&amp;quot; Hylton explained. &amp;quot;But it&amp;#x27;s not a problem at all for Strella. They would tell you exactly what they think about it, which is really valuable. It&amp;#x27;s very hard to get honest feedback.&amp;quot;&lt;/p&gt;&lt;p&gt;Krishnan, Strella&amp;#x27;s COO, said companies initially worried about using AI and &amp;quot;eroding quality,&amp;quot; but the platform has &amp;quot;actually found the opposite to be true. People are much more open and honest with an AI moderator, and so the level of insight that you get is much richer because people are giving their unfiltered feedback.&amp;quot;&lt;/p&gt;&lt;p&gt;This dynamic has practical business implications. Brian Santiago, Senior Product Design Manager at Apollo GraphQL, said in a statement: &amp;quot;Before Strella, studies took weeks. Now we get insights in a day — sometimes in just a few hours. And because participants open up more with the AI moderator, the feedback is deeper and more honest.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform also addresses endemic fraud in online surveys, particularly when participants are compensated. Because Strella interviews happen on camera in real time, the AI moderator can detect when someone pauses suspiciously long — perhaps to consult ChatGPT — and flags them as potentially fraudulent. &amp;quot;We are fraud resistant,&amp;quot; Hylton said, contrasting this with traditional surveys where fraud rates can be substantial.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Solving mobile app research with persistent screen sharing technology&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A major focus of the Series A funding will be expanding &lt;a href="https://apps.apple.com/us/app/strella-mobile-interview/id6746277771"&gt;&lt;u&gt;Strella&amp;#x27;s recently-launched mobile application&lt;/u&gt;&lt;/a&gt;, which Krishnan identified as critical competitive differentiation. The mobile app enables persistent screen sharing during interviews — allowing researchers to watch users navigate mobile applications in real time while the AI moderator asks about their experience.&lt;/p&gt;&lt;p&gt;&amp;quot;We are the only player in the market that supports screen sharing on mobile,&amp;quot; Hylton said. &amp;quot;You know, I want to understand what are the pain points with my app? Why do people not seem to be able to find the checkout flow? Well, in order to do that effectively, you&amp;#x27;d like to see the user screen while they&amp;#x27;re doing an interview.&amp;quot;&lt;/p&gt;&lt;p&gt;For consumer-facing companies where mobile represents the primary customer interface, this capability opens entirely new use cases. The founders noted that &amp;quot;several of our customers didn&amp;#x27;t do research before&amp;quot; but have now built research practices around Strella because the platform finally made mobile research accessible at scale.&lt;/p&gt;&lt;p&gt;The platform also supports embedding traditional survey question types directly into the conversational interview, approaching what Hylton called &amp;quot;feature parity with a survey&amp;quot; while maintaining the engagement advantages of a natural conversation. Strella interviews regularly run 60 to 90 minutes with nearly 100% completion rates—a duration that would see 60-70% drop-off in a traditional survey format.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Strella differentiated in a market crowded with AI research startups&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Strella enters a market that appears crowded at first glance, with established players like &lt;a href="https://www.qualtrics.com/"&gt;&lt;u&gt;Qualtrics&lt;/u&gt;&lt;/a&gt; and a wave of AI-powered startups promising to transform customer research. The founders themselves initially pursued a different approach — synthetic respondents, or &amp;quot;digital twins&amp;quot; that simulate customer perspectives using large language models.&lt;/p&gt;&lt;p&gt;&amp;quot;We actually pivoted from that. That was our initial idea,&amp;quot; Hylton revealed, referring to synthetic respondents. &amp;quot;People are very intrigued by that concept, but found in practice, no willingness to pay right now.&amp;quot;&lt;/p&gt;&lt;p&gt;Recent research suggesting companies &lt;a href="https://venturebeat.com/ai/this-new-ai-technique-creates-digital-twin-consumers-and-it-could-kill-the"&gt;&lt;u&gt;could use language models as digital twins&lt;/u&gt;&lt;/a&gt; for customer feedback has reignited interest in that approach. But Hylton remains skeptical: &amp;quot;The capabilities of the LLMs as they are today are not good enough, in my opinion, to justify a standalone company. Right now you could just ask ChatGPT, &amp;#x27;What would new users of Duolingo think about this ad copy?&amp;#x27; You can do that. Adding the standalone idea of a synthetic panel is sort of just putting a wrapper on that.&amp;quot;&lt;/p&gt;&lt;p&gt;Instead, Strella&amp;#x27;s bet is that the real value lies in collecting proprietary qualitative data at scale — building what could become &amp;quot;the system of truth for all qualitative insights&amp;quot; within enterprises, as Lindsey Li, Vice President at Bessemer Venture Partners, described it.&lt;/p&gt;&lt;p&gt;Li, who led the investment just one year after Strella emerged from stealth, said the firm was convinced by both the technology and the team. &amp;quot;Strella has built highly differentiated technology that enables a continuous interview rather than a survey,&amp;quot; Li said. &amp;quot;We heard time and time again that customers loved this product experience relative to other offerings.&amp;quot;&lt;/p&gt;&lt;p&gt;On the defensibility question that concerns many AI investors, Li emphasized product execution over patents: &amp;quot;We think the long game here will be won with a million small product decisions, all of which must be driven by deep empathy for customer pain and an understanding of how best to address their needs. Lydia and Priya exhibit that in spades.&amp;quot;&lt;/p&gt;&lt;p&gt;The founders point to technical depth that&amp;#x27;s difficult to replicate. Most competitors started with adaptive surveys — text-based interfaces where users type responses and wait for the next question. Some have added voice, but typically as uploaded audio clips rather than free-flowing conversation.&lt;/p&gt;&lt;p&gt;&amp;quot;Our approach is fundamentally better, which is the fact that it is a free form conversation,&amp;quot; Hylton said. &amp;quot;You never have to control anything. You&amp;#x27;re never typing, there&amp;#x27;s no buttons, there&amp;#x27;s no upload and wait for the next question. It&amp;#x27;s completely free form, and that has been an extraordinarily hard product to build. There&amp;#x27;s a tremendous amount of IP in the way that we prompt our moderator, the way that we run analysis.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform also improves with use, learning from each customer&amp;#x27;s research patterns to fine-tune future interview guides and questions. &amp;quot;Our product gets better for our customers as they continue to use us,&amp;quot; Hylton said. All research accumulates in a central repository where teams can generate new insights by chatting with the data or creating visualizations from previously unstructured qualitative feedback.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Creating new research budgets instead of just automating existing ones&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps more important than displacing existing research is expanding the total market. Krishnan said growth has been &amp;quot;fundamentally related to our product&amp;quot; creating new research that wouldn&amp;#x27;t have happened otherwise.&lt;/p&gt;&lt;p&gt;&amp;quot;We have expanded the use cases in which people would conduct research,&amp;quot; Krishnan explained. &amp;quot;Several of our customers didn&amp;#x27;t do research before, have always wanted to do research, but didn&amp;#x27;t have a dedicated researcher or team at their company that was devoted to it, and have purchased Strella to kick off and enable their research practice. That&amp;#x27;s been really cool where we&amp;#x27;ve seen this market just opening up.&amp;quot;&lt;/p&gt;&lt;p&gt;This expansion comes as enterprises face mounting pressure to improve customer experience amid declining satisfaction scores. According to &lt;a href="https://www.forrester.com/press-newsroom/forrester-2024-us-customer-experience-index/"&gt;&lt;u&gt;Forrester Research&amp;#x27;s 2024 Customer Experience Index&lt;/u&gt;&lt;/a&gt;, customer experience quality has declined for three consecutive years — an unprecedented trend. The report found that 39% of brands saw CX quality deteriorate, with declines across effectiveness, ease, and emotional connection.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://www.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions.html"&gt;&lt;u&gt;Deloitte&amp;#x27;s 2025 Technology, Media &amp;amp; Telecommunications Predictions report&lt;/u&gt;&lt;/a&gt; forecasts that 25% of enterprises using generative AI will deploy AI agents by 2025, growing to 50% by 2027. The report specifically highlighted AI&amp;#x27;s potential to enhance customer satisfaction by 15-20% while reducing cost to serve by 20-30% when properly implemented.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.gartner.com/en/newsroom/press-releases/2023-08-30-gartner-reveals-three-technologies-that-will-transform-customer-service-and-support-by-2028"&gt;&lt;u&gt;Gartner&lt;/u&gt;&lt;/a&gt; identified conversational user interfaces — the category Strella inhabits — as one of three technologies poised to transform customer service by 2028, noting that &amp;quot;customers increasingly expect to be able to interact with the applications they use in a natural way.&amp;quot;&lt;/p&gt;&lt;p&gt;Against this backdrop, Li sees substantial room for growth. &amp;quot;UX Research is a sub-sector of the $140B+ global market-research industry,&amp;quot; Li said. &amp;quot;This includes both the software layer historically (~$430M) and professional services spend on UX research, design, product strategy, etc. which is conservatively estimated to be ~$6.4B+ annually. As software in this vertical, led by Strella, becomes more powerful, we believe the TAM will continue to expand meaningfully.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making customer feedback accessible across the enterprise, not just research teams&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The founders describe their mission as &amp;quot;democratizing access to the customer&amp;quot; — making it possible for anyone in an organization to understand customer perspectives without waiting for dedicated research teams to complete months-long studies.&lt;/p&gt;&lt;p&gt;&amp;quot;Many, many, many positions in the organization would like to get customer feedback, but it&amp;#x27;s so hard right now,&amp;quot; Hylton said. With Strella, she explained, someone can &amp;quot;log into Strella and through a chat, create any highlight reel that you want and actually see customers in their own words answering the question that you have based on the research that&amp;#x27;s already been done.&amp;quot;&lt;/p&gt;&lt;p&gt;This video-first approach to research repositories changes organizational dynamics around customer feedback. &amp;quot;Then you can say, &amp;#x27;Okay, engineering team, we need to build this feature. And here&amp;#x27;s the customer actually saying it,&amp;#x27;&amp;quot; Hylton continued. &amp;quot;&amp;#x27;This is not me. This isn&amp;#x27;t politics. Here are seven customers saying they can&amp;#x27;t find the Checkout button.&amp;#x27; The fact that we are a very video-based platform really allows us to do that quickly and painlessly.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has moved decisively upmarket, with contract values now typically in the five-figure range and &amp;quot;several six figure contracts&amp;quot; signed, according to Krishnan. The pricing strategy reflects a premium positioning: &amp;quot;Our product is very good, it&amp;#x27;s very premium. We&amp;#x27;re charging based on the value it provides to customers,&amp;quot; Krishnan said, rather than competing on cost alone.&lt;/p&gt;&lt;p&gt;This approach appears to be working. The company reports 100% conversion from pilot programs to paid contracts and zero churn among its 40-45 customers, with month-over-month revenue growth of 50%.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The roadmap: Computer vision, agentic AI, and human-machine collaboration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Series A funding will primarily support scaling product and go-to-market teams. &amp;quot;We&amp;#x27;re really confident that we have product-market fit,&amp;quot; Hylton said. &amp;quot;And now the question is execution, and we want to hire a lot of really talented people to help us execute.&amp;quot;&lt;/p&gt;&lt;p&gt;On the product roadmap, Hylton emphasized continued focus on the participant experience as the key to winning the market. &amp;quot;Everything else is downstream of a joyful participant experience,&amp;quot; she said, including &amp;quot;the quality of insights, the amount you have to pay people to do the interviews, and the way that your customers feel about a company.&amp;quot;&lt;/p&gt;&lt;p&gt;Near-term priorities include adding visual capabilities so the AI moderator can respond to facial expressions and other nonverbal cues, and building more sophisticated collaboration features between human researchers and AI moderators. &amp;quot;Maybe you want to listen while an AI moderator is running a call and you might want to be able to jump in with specific questions,&amp;quot; Hylton said. &amp;quot;Or you want to run an interview yourself, but you want the moderator to be there as backup or to help you.&amp;quot;&lt;/p&gt;&lt;p&gt;These features move toward what the industry calls &amp;quot;agentic AI&amp;quot; — systems that can act more autonomously while still collaborating with humans. The founders see this human-AI collaboration, rather than full automation, as the sustainable path forward.&lt;/p&gt;&lt;p&gt;&amp;quot;We believe that a lot of the really strategic work that companies do will continue to be human moderated,&amp;quot; Hylton said. &amp;quot;And you can still do that through Strella and just use us for synthesis in those cases.&amp;quot;&lt;/p&gt;&lt;p&gt;For Li and Bessemer, the bet is on founders who understand this nuance. &amp;quot;Lydia and Priya exhibit the exact archetype of founders we are excited to partner with for the long term — customer-obsessed, transparent, thoughtful, and singularly driven towards the home-run scenario,&amp;quot; she said.&lt;/p&gt;&lt;p&gt;The company declined to disclose specific revenue figures or valuation. With the new funding, Strella has now raised $18 million total, including a &lt;a href="https://venturebeat.com/ai/strella-raises-4-million-to-automate-market-research-with-ai-powered-customer-interviews"&gt;&lt;u&gt;$4 million seed round led by Decibel Partners announced in October&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;As Strella scales, the founders remain focused on a vision where technology enhances rather than eliminates human judgment—where an engineering team doesn&amp;#x27;t just read a research report, but watches seven customers struggle to find the same button. Where a product manager can query months of accumulated interviews in seconds. Where companies don&amp;#x27;t choose between speed and depth, but get both.&lt;/p&gt;&lt;p&gt;&amp;quot;The interesting part of the business is actually collecting that proprietary dataset, collecting qualitative research at scale,&amp;quot; Hylton said, describing what she sees as Strella&amp;#x27;s long-term moat. Not replacing the researcher, but making everyone in the company one.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/amazon-and-chobani-adopt-strellas-ai-interviews-for-customer-research-as</guid><pubDate>Thu, 16 Oct 2025 14:00:00 +0000</pubDate></item><item><title>Last 48 hours to save before TechCrunch Disrupt 2025 flash sale ends (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/only-48-hours-left-to-save-before-the-techcrunch-disrupt-2025-flash-sale-ends/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ticktock! &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits San Francisco’s Moscone West on October 27–29, and this is your final chance to lock in major savings before doors open. Ticket prices increase after tomorrow, October 17 at 11:59 p.m. PT, so don’t wait. &lt;strong&gt;Save up to $624&lt;/strong&gt; on your pass &lt;em&gt;right now,&lt;/em&gt; and if you’re coming with your team, you can &lt;strong&gt;save 15% to 30% on group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 2 days left" class="wp-image-3011644" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_2Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-disrupt"&gt;Why attend Disrupt?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is where the startup world converges. Join 10,000 founders, VCs, and tech innovators to hear &lt;strong&gt;250+&lt;/strong&gt; industry leaders across &lt;strong&gt;200+&lt;/strong&gt; sessions, explore startup breakthroughs from &lt;strong&gt;300+&lt;/strong&gt; showcasing startups, and experience the intensity of &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; — the iconic pitch competition that launched companies like Dropbox, Cloudflare, and Vurb.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-meet-the-leaders-taking-the-stages"&gt;Meet the leaders taking the stages&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Vinod Khosla, Founder of Khosla Ventures, speaks onstage during TechCrunch Disrupt 2024 Day 1 at Moscone Center on October 28, 2024 in San Francisco, California." class="wp-image-2907131" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2181599313.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This year’s &lt;strong&gt;speaker lineup&lt;/strong&gt; features impressive names sharing insights on the future of AI, funding, space, scaling breakthrough ideas, and more, including:&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Will Grannis&lt;/strong&gt;, CTO, Google Cloud&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jen Hoskins&lt;/strong&gt;, startups head of cloud and partnerships, Nvidia&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Sachin Kansal&lt;/strong&gt;, chief product officer, Uber Technologies&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Marc Manara&lt;/strong&gt;, head of startups, OpenAI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, chief product officer, Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tristan Thompson&lt;/strong&gt;, NBA Champion and Fintech Entrepreneur&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;And many more leaders from Zoom, Amazon, Tinder, Meta, and more&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Check out our full list of speakers here&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Sam Altman OpenAI OpenResearch" class="wp-image-2488152" height="454" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1173441590.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;David Paul Morris/Bloomberg / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-a-disrupt-pass-for-everyone-in-tech"&gt;A Disrupt pass for everyone in tech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is designed for anyone launching, operating, innovating, investing, and more. &lt;strong&gt;Choose the ticket&lt;/strong&gt; that best helps you reach your goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For founders:&lt;/strong&gt; Your pass opens doors to help you build invaluable connections with investors, potential partners, and mentors — plus exclusive access to startup how-to sessions designed to help you raise smarter and scale faster. &lt;strong&gt;Explore founder benefits →&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For investors:&lt;/strong&gt; Disrupt gives you front-row access to tomorrow’s most promising startups, curated deal flow, and private networking opportunities designed to spark your next big investment. &lt;strong&gt;See investor perks →&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Don’t pay more for the same seat! &lt;strong&gt;Secure your pass here&lt;/strong&gt;&lt;strong&gt; before the clock runs out tomorrow, October 17 at 11:59 p.m. PT &lt;/strong&gt;and join the leaders shaping what’s next in tech. &lt;strong&gt;Get passes for your team&lt;/strong&gt; with up to 30% discount here.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ticktock! &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits San Francisco’s Moscone West on October 27–29, and this is your final chance to lock in major savings before doors open. Ticket prices increase after tomorrow, October 17 at 11:59 p.m. PT, so don’t wait. &lt;strong&gt;Save up to $624&lt;/strong&gt; on your pass &lt;em&gt;right now,&lt;/em&gt; and if you’re coming with your team, you can &lt;strong&gt;save 15% to 30% on group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 2 days left" class="wp-image-3011644" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_2Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-disrupt"&gt;Why attend Disrupt?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is where the startup world converges. Join 10,000 founders, VCs, and tech innovators to hear &lt;strong&gt;250+&lt;/strong&gt; industry leaders across &lt;strong&gt;200+&lt;/strong&gt; sessions, explore startup breakthroughs from &lt;strong&gt;300+&lt;/strong&gt; showcasing startups, and experience the intensity of &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; — the iconic pitch competition that launched companies like Dropbox, Cloudflare, and Vurb.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-meet-the-leaders-taking-the-stages"&gt;Meet the leaders taking the stages&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Vinod Khosla, Founder of Khosla Ventures, speaks onstage during TechCrunch Disrupt 2024 Day 1 at Moscone Center on October 28, 2024 in San Francisco, California." class="wp-image-2907131" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2181599313.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This year’s &lt;strong&gt;speaker lineup&lt;/strong&gt; features impressive names sharing insights on the future of AI, funding, space, scaling breakthrough ideas, and more, including:&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Will Grannis&lt;/strong&gt;, CTO, Google Cloud&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jen Hoskins&lt;/strong&gt;, startups head of cloud and partnerships, Nvidia&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Sachin Kansal&lt;/strong&gt;, chief product officer, Uber Technologies&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Marc Manara&lt;/strong&gt;, head of startups, OpenAI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, chief product officer, Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tristan Thompson&lt;/strong&gt;, NBA Champion and Fintech Entrepreneur&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;And many more leaders from Zoom, Amazon, Tinder, Meta, and more&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Check out our full list of speakers here&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Sam Altman OpenAI OpenResearch" class="wp-image-2488152" height="454" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1173441590.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;David Paul Morris/Bloomberg / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-a-disrupt-pass-for-everyone-in-tech"&gt;A Disrupt pass for everyone in tech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is designed for anyone launching, operating, innovating, investing, and more. &lt;strong&gt;Choose the ticket&lt;/strong&gt; that best helps you reach your goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For founders:&lt;/strong&gt; Your pass opens doors to help you build invaluable connections with investors, potential partners, and mentors — plus exclusive access to startup how-to sessions designed to help you raise smarter and scale faster. &lt;strong&gt;Explore founder benefits →&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For investors:&lt;/strong&gt; Disrupt gives you front-row access to tomorrow’s most promising startups, curated deal flow, and private networking opportunities designed to spark your next big investment. &lt;strong&gt;See investor perks →&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Don’t pay more for the same seat! &lt;strong&gt;Secure your pass here&lt;/strong&gt;&lt;strong&gt; before the clock runs out tomorrow, October 17 at 11:59 p.m. PT &lt;/strong&gt;and join the leaders shaping what’s next in tech. &lt;strong&gt;Get passes for your team&lt;/strong&gt; with up to 30% discount here.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/only-48-hours-left-to-save-before-the-techcrunch-disrupt-2025-flash-sale-ends/</guid><pubDate>Thu, 16 Oct 2025 14:00:00 +0000</pubDate></item><item><title>General Intuition lands $134M seed to teach agents spatial reasoning using video game clips (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/general-intuition-lands-134m-seed-to-teach-agents-spatial-reasoning-using-video-game-clips/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Medal, a platform for uploading and sharing video game clips, has spun out a new frontier AI research lab that’s using its trove of gaming videos to train and build foundation models and AI agents that can understand how objects and entities move through space and time — a concept known as spatial-temporal reasoning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called General Intuition, the startup is betting that Medal’s dataset — which consists of 2 billion videos per year from 10 million monthly active users across tens of thousands of games — surpasses alternatives like Twitch or YouTube for training agents.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“When you play video games, you essentially transfer your perception, usually through a first-person view of the camera, to different environments,” Pim de Witte, CEO of Medal and General Intuition, told TechCrunch.&amp;nbsp; He noted that gamers who upload clips tend to post very negative or positive examples, which serve as really useful edge cases for training. “You get this selection bias towards precisely the kind of data you actually want to use for training work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This data moat is what reportedly attracted the attention of OpenAI, which late last year attempted to acquire Medal for $500 million, per The Information. (Neither OpenAI nor General Intuition would comment on the report.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s also what has led to General Intuition’s raising a whopping $133.7 million in seed funding, led by Khosla Ventures and General Catalyst with participation from Raine.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3058188" height="556" src="https://techcrunch.com/wp-content/uploads/2025/10/general_intuition_announcement_hero.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;General Intuition’s founding team.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;General Intuition&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup intends to use the funds to grow its team of researchers and engineers focused on training a general agent that can interact with the world around it, aiming for initial applications in gaming, and search-and-rescue drones.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Witte says the founding team has already made strides: General Intuition’s model can understand environments it wasn’t trained on and correctly predict actions within them. It’s able to do this purely through visual input; agents only see what a human player would see, and they move through space by following controller inputs. This approach, the company says, can transfer naturally to physical systems like robotic arms, drones, and autonomous vehicles, which are often manipulated by humans using video game controllers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;General Intuition’s next milestone is twofold: generating new simulated worlds for training other agents and autonomously navigating entirely unfamiliar physical environments.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That technical approach is shaping how the company plans to commercialize its technology and sets it apart from competitors building world models.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While General Intuition is also building world models on which to train its agents, such&amp;nbsp;models aren’t the product. Unlike other world model makers like DeepMind and World Labs, which are selling their world models Genie and Marble, respectively, for training agents and content creation, General Intuition is focusing on other use cases to avoid copyright issues.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our goal is not to produce models that compete with game developers,” de Witte said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, the startup’s gaming applications center around creating bots and non-player characters that can surpass traditional “deterministic bots,” or preprogrammed characters that produce the same output every time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The bots] can scale to any level of difficulty,” Moritz Baier-Lentz, a founding member of General Intuition and partner at Lightspeed Ventures, told TechCrunch. “It’s not compelling to create a god bot that beats everyone, but if you can scale gradually and fill in liquidity for any player situation so that their win rate is always around 50%, that will maximize their engagement and retention.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Witte also has a background in humanitarian work, which informs the startup’s focus on powering search-and-rescue drones, which sometimes have to navigate unfamiliar environments and extract information without GPS.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ultimately, de Witte and Baier-Lentz see General Intuition’s core functionality — spatial-temporal reasoning — as a crucial piece in the race toward artificial general intelligence (AGI). While major AI labs focus on building ever more powerful large language models, General Intuition believes true AGI requires something LLMs fundamentally lack.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As humans, we create text to describe what’s going on in our world, but in doing so, you lose a lot of information,” de Witte said. “You lose general intuition around spatial-temporal reasoning.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Medal, a platform for uploading and sharing video game clips, has spun out a new frontier AI research lab that’s using its trove of gaming videos to train and build foundation models and AI agents that can understand how objects and entities move through space and time — a concept known as spatial-temporal reasoning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called General Intuition, the startup is betting that Medal’s dataset — which consists of 2 billion videos per year from 10 million monthly active users across tens of thousands of games — surpasses alternatives like Twitch or YouTube for training agents.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“When you play video games, you essentially transfer your perception, usually through a first-person view of the camera, to different environments,” Pim de Witte, CEO of Medal and General Intuition, told TechCrunch.&amp;nbsp; He noted that gamers who upload clips tend to post very negative or positive examples, which serve as really useful edge cases for training. “You get this selection bias towards precisely the kind of data you actually want to use for training work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This data moat is what reportedly attracted the attention of OpenAI, which late last year attempted to acquire Medal for $500 million, per The Information. (Neither OpenAI nor General Intuition would comment on the report.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s also what has led to General Intuition’s raising a whopping $133.7 million in seed funding, led by Khosla Ventures and General Catalyst with participation from Raine.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3058188" height="556" src="https://techcrunch.com/wp-content/uploads/2025/10/general_intuition_announcement_hero.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;General Intuition’s founding team.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;General Intuition&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup intends to use the funds to grow its team of researchers and engineers focused on training a general agent that can interact with the world around it, aiming for initial applications in gaming, and search-and-rescue drones.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Witte says the founding team has already made strides: General Intuition’s model can understand environments it wasn’t trained on and correctly predict actions within them. It’s able to do this purely through visual input; agents only see what a human player would see, and they move through space by following controller inputs. This approach, the company says, can transfer naturally to physical systems like robotic arms, drones, and autonomous vehicles, which are often manipulated by humans using video game controllers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;General Intuition’s next milestone is twofold: generating new simulated worlds for training other agents and autonomously navigating entirely unfamiliar physical environments.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That technical approach is shaping how the company plans to commercialize its technology and sets it apart from competitors building world models.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While General Intuition is also building world models on which to train its agents, such&amp;nbsp;models aren’t the product. Unlike other world model makers like DeepMind and World Labs, which are selling their world models Genie and Marble, respectively, for training agents and content creation, General Intuition is focusing on other use cases to avoid copyright issues.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our goal is not to produce models that compete with game developers,” de Witte said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, the startup’s gaming applications center around creating bots and non-player characters that can surpass traditional “deterministic bots,” or preprogrammed characters that produce the same output every time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The bots] can scale to any level of difficulty,” Moritz Baier-Lentz, a founding member of General Intuition and partner at Lightspeed Ventures, told TechCrunch. “It’s not compelling to create a god bot that beats everyone, but if you can scale gradually and fill in liquidity for any player situation so that their win rate is always around 50%, that will maximize their engagement and retention.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Witte also has a background in humanitarian work, which informs the startup’s focus on powering search-and-rescue drones, which sometimes have to navigate unfamiliar environments and extract information without GPS.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ultimately, de Witte and Baier-Lentz see General Intuition’s core functionality — spatial-temporal reasoning — as a crucial piece in the race toward artificial general intelligence (AGI). While major AI labs focus on building ever more powerful large language models, General Intuition believes true AGI requires something LLMs fundamentally lack.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As humans, we create text to describe what’s going on in our world, but in doing so, you lose a lot of information,” de Witte said. “You lose general intuition around spatial-temporal reasoning.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/general-intuition-lands-134m-seed-to-teach-agents-spatial-reasoning-using-video-game-clips/</guid><pubDate>Thu, 16 Oct 2025 14:08:04 +0000</pubDate></item><item><title>Final 2 days to claim your exhibit table at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/final-2-days-to-claim-your-exhibit-table-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; takes place October 27-29 in San Francisco’s Moscone West, and exhibit space is nearly full. With less than two days left to secure your table, &lt;em&gt;now&lt;/em&gt; is the time to step in before a competitor takes your place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Showcase your brand to 10,000 founders, investors, media, and tech leaders on the hunt for the next breakthrough. Build a year’s worth of connections in just three days. Generate hot leads. Capture investor attention.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If your work is making waves, your vision excites, or your team is ready to grow, &lt;strong&gt;this is your moment&lt;/strong&gt; to shine at one of the most anticipated tech conferences of the year.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 exhibitor" class="wp-image-3040886" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/polygraf2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Silkroad &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-what-your-table-delivers"&gt;What your table delivers&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Three days of dedicated table space to showcase your innovation.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Custom tabletop signage featuring your logo to capture attention.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Direct access to qualified leads through the Disrupt mobile app.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 comped passes for you and your team to network, attend sessions, and meet key players.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsors receive recognition with branding across the website, app, and on-site signage before, during, and after the event.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;And more&lt;/strong&gt;.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Every conversation. Every connection. Every moment counts at Disrupt. Lock in your table by tomorrow, October 17, before a competitor takes your spotlight. &lt;strong&gt;Book now&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; takes place October 27-29 in San Francisco’s Moscone West, and exhibit space is nearly full. With less than two days left to secure your table, &lt;em&gt;now&lt;/em&gt; is the time to step in before a competitor takes your place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Showcase your brand to 10,000 founders, investors, media, and tech leaders on the hunt for the next breakthrough. Build a year’s worth of connections in just three days. Generate hot leads. Capture investor attention.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If your work is making waves, your vision excites, or your team is ready to grow, &lt;strong&gt;this is your moment&lt;/strong&gt; to shine at one of the most anticipated tech conferences of the year.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 exhibitor" class="wp-image-3040886" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/polygraf2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Silkroad &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-what-your-table-delivers"&gt;What your table delivers&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Three days of dedicated table space to showcase your innovation.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Custom tabletop signage featuring your logo to capture attention.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Direct access to qualified leads through the Disrupt mobile app.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 comped passes for you and your team to network, attend sessions, and meet key players.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsors receive recognition with branding across the website, app, and on-site signage before, during, and after the event.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;And more&lt;/strong&gt;.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Every conversation. Every connection. Every moment counts at Disrupt. Lock in your table by tomorrow, October 17, before a competitor takes your spotlight. &lt;strong&gt;Book now&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/final-2-days-to-claim-your-exhibit-table-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 16 Oct 2025 14:30:00 +0000</pubDate></item><item><title>Pinterest adds controls to let you  limit the amount of ‘AI slop’ in your feed (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/pinterest-adds-controls-to-let-you-limit-the-amount-of-ai-slop-in-your-feed/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following backlash over an increase in “AI slop” taking over users’ feeds, Pinterest on Thursday added new tools that let users limit how much AI-generated content they see on the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can now personalize their feeds to restrict generative AI imagery in select categories, and the company said it will make its existing GenAI content labels more noticeable in the days to come.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The site, widely used to browse and bookmark inspirational content and potential purchases, has come under fire from users who have complained about the massive uptick in GenAI content. The media has also been documenting the problem, while openly&amp;nbsp;wondering if AI has already ruined&amp;nbsp;Pinterest or if it could still be fixed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem, if left unresolved, could destroy Pinterest’s reputation and, ultimately, its bottom line.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI slop is potentially a tough nut to crack as more of the web fills up with AI-generated content and the quality of the AI content improves, making it less obvious to spot. Citing academic literature, Pinterest notes that GenAI content now makes up 57% of all online material.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address the issue, Pinterest earlier this year introduced “AI modified” labels that would appear on images whose metadata indicated AI generation, or if Pinterest’s own systems detected that the content was AI-generated. At the time, the company said it would “soon” introduce consumer-facing tools that would let users choose to see less AI content.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3058211" height="452" src="https://techcrunch.com/wp-content/uploads/2025/10/FilteringPins-UIDemo.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Pinterest&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Those tools have now arrived and will be available in the app’s “Settings” menu, under “Refine your recommendations.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Here, users will be able to configure whether they’d like to see less GenAI content in certain categories that are prone to AI-generated imagery, like beauty, art, fashion, and home décor. Pinterest said it will introduce more categories in the future, based on user feedback. Plus, if users want to modify their settings, they can do so at any time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, users can send feedback about AI imagery as they browse the site. If they see a Pin that’s not appealing because of its generative AI nature, they can tap the three-dot overflow menu and select a category to refine their preferences. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new controls are launching first on the website and Android and will roll out to iOS users over the weeks ahead, Pinterest said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our community is at the heart of everything we do,” said Matt Madrigal, Pinterest’s chief technology officer, in a statement about the launch. “With our new GenAI controls, we’re empowering people to personalize their Pinterest experience more than ever — striking the right balance between human creativity and AI innovation, and ensuring every feed truly reflects what inspires them most.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following backlash over an increase in “AI slop” taking over users’ feeds, Pinterest on Thursday added new tools that let users limit how much AI-generated content they see on the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can now personalize their feeds to restrict generative AI imagery in select categories, and the company said it will make its existing GenAI content labels more noticeable in the days to come.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The site, widely used to browse and bookmark inspirational content and potential purchases, has come under fire from users who have complained about the massive uptick in GenAI content. The media has also been documenting the problem, while openly&amp;nbsp;wondering if AI has already ruined&amp;nbsp;Pinterest or if it could still be fixed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem, if left unresolved, could destroy Pinterest’s reputation and, ultimately, its bottom line.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI slop is potentially a tough nut to crack as more of the web fills up with AI-generated content and the quality of the AI content improves, making it less obvious to spot. Citing academic literature, Pinterest notes that GenAI content now makes up 57% of all online material.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address the issue, Pinterest earlier this year introduced “AI modified” labels that would appear on images whose metadata indicated AI generation, or if Pinterest’s own systems detected that the content was AI-generated. At the time, the company said it would “soon” introduce consumer-facing tools that would let users choose to see less AI content.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3058211" height="452" src="https://techcrunch.com/wp-content/uploads/2025/10/FilteringPins-UIDemo.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Pinterest&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Those tools have now arrived and will be available in the app’s “Settings” menu, under “Refine your recommendations.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Here, users will be able to configure whether they’d like to see less GenAI content in certain categories that are prone to AI-generated imagery, like beauty, art, fashion, and home décor. Pinterest said it will introduce more categories in the future, based on user feedback. Plus, if users want to modify their settings, they can do so at any time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, users can send feedback about AI imagery as they browse the site. If they see a Pin that’s not appealing because of its generative AI nature, they can tap the three-dot overflow menu and select a category to refine their preferences. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new controls are launching first on the website and Android and will roll out to iOS users over the weeks ahead, Pinterest said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our community is at the heart of everything we do,” said Matt Madrigal, Pinterest’s chief technology officer, in a statement about the launch. “With our new GenAI controls, we’re empowering people to personalize their Pinterest experience more than ever — striking the right balance between human creativity and AI innovation, and ensuring every feed truly reflects what inspires them most.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/pinterest-adds-controls-to-let-you-limit-the-amount-of-ai-slop-in-your-feed/</guid><pubDate>Thu, 16 Oct 2025 15:15:50 +0000</pubDate></item><item><title>Unlocking the potential of SAF with book and claim in air freight (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/16/1123850/unlocking-the-potential-of-saf-with-book-and-claim-in-air-freight/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;Avelia&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Used in aviation, book and claim offers companies the ability to financially support the use of SAF even when it is not physically available at their locations.&lt;/p&gt;  &lt;p&gt;As companies that ship goods by air or provide air freight related services address a range of climate goals aiming to reduce emissions, the importance of sustainable aviation fuel (SAF) couldn’t be more pronounced. In its neat form, SAF has the potential to reduce life cycle GHG emissions by up to 80% compared to conventional jet fuel.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;In this exclusive webcast, leaders discuss the urgency for reducing air freight emissions for freight forwarders and shippers, and reasons why companies should use SAF. They also explain how companies can best make use of the book and claim model to support their emissions reduction strategies.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125583" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Shell-webcast-social-card-1200px-2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Learn from the leaders&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;What book and claim is and how companies can use it&lt;/li&gt;    &lt;li&gt;Why SAF use is so important&lt;/li&gt;    &lt;li&gt;How freight-forwarders and shippers can both potentially utilise and contribute to the benefits of SAF&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;strong&gt;Featured speakers&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Raman Ojha, President, Shell Aviation.&amp;nbsp;&lt;/strong&gt;Raman is responsible for Shell's global aviation business, which supplies fuels, lubricants, and lower carbon solutions, and offers a range of technical services globally. During almost 20 years at Shell, Raman has held leadership positions across a variety of industry sectors, including energy, lubricants, construction, and fertilisers. He has broad experience across both matured markets in the Americas and Europe, as well as developing markets including China, India, and Southeast Asia.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Bettina Paschke, VP ESG Accounting, Reporting &amp;amp; Controlling, DHL Express&lt;/strong&gt;. Bettina Paschke leads ESG Accounting, Reporting &amp;amp; Controlling, at DHL Express a division of DHL Group. In her role, she is responsible for ESG, including, EU Taxonomy Reporting, and Carbon Accounting. She has more than 20 years’ experience in Finance. In her role she is driving the Sustainable Aviation Fuel agenda at DHL Express and is engaged in various industry initiatives to allow reliable book and claim transactions.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Christoph Wolff, Chief Executive Officer at Smart Freight Centre&lt;/strong&gt;. Christoph Wolff is currently the Chief Executive Officer at Smart Freight Centre, leading programs focused on sustainability in freight transport. Prior to this role, Christoph served as the Senior Advisor and Director at ACME Group, a global leader in green energy solutions. With a background in various industries, Christoph has held positions such as Managing Director at European Climate Foundation and Senior Board Advisor at Ferrostaal GmbH. Christoph has also worked at Novatec, Solar Millennium AG, DB Schenker, McKinsey &amp;amp; Company, and served as an Assistant Professor at Northwestern University - Kellogg School of Management. Christoph holds multiple degrees from RWTH Aachen University and ETH Zürich, along with ongoing executive education at the University of Michigan.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;em&gt;This discussion is presented by MIT Technology Review Insights in association with Avelia.&amp;nbsp;Avelia is a Shell owned solution and brand that was developed with support from Amex GBT, Accenture and Energy Web Foundation.&amp;nbsp;&lt;/em&gt;The views from individuals not affiliated with Shell are their own and not those of Shell PLC or its affiliates. &lt;em&gt;Cautionary note | Shell Global&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Not all offerings are available in all jurisdictions. Depending on jurisdiction and local laws, Shell may offer the sale of Environmental Attributes (for which subject to applicable law and consultation with own advisors, buyers might be able to use such Environmental Attributes for their own emission reduction purposes) and/or Environmental Attribute Information (pursuant to which buyers are helping subsidize the use of SAF and lower overall aviation emissions at designated airports but no emission reduction claims may be made by buyers for their own emissions reduction purposes). Different offerings have different forms of contracts, and no assumptions should be made about a particular offering without reading the specific contractual language applicable to such offering.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;Avelia&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Used in aviation, book and claim offers companies the ability to financially support the use of SAF even when it is not physically available at their locations.&lt;/p&gt;  &lt;p&gt;As companies that ship goods by air or provide air freight related services address a range of climate goals aiming to reduce emissions, the importance of sustainable aviation fuel (SAF) couldn’t be more pronounced. In its neat form, SAF has the potential to reduce life cycle GHG emissions by up to 80% compared to conventional jet fuel.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;In this exclusive webcast, leaders discuss the urgency for reducing air freight emissions for freight forwarders and shippers, and reasons why companies should use SAF. They also explain how companies can best make use of the book and claim model to support their emissions reduction strategies.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125583" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Shell-webcast-social-card-1200px-2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Learn from the leaders&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;What book and claim is and how companies can use it&lt;/li&gt;    &lt;li&gt;Why SAF use is so important&lt;/li&gt;    &lt;li&gt;How freight-forwarders and shippers can both potentially utilise and contribute to the benefits of SAF&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;strong&gt;Featured speakers&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Raman Ojha, President, Shell Aviation.&amp;nbsp;&lt;/strong&gt;Raman is responsible for Shell's global aviation business, which supplies fuels, lubricants, and lower carbon solutions, and offers a range of technical services globally. During almost 20 years at Shell, Raman has held leadership positions across a variety of industry sectors, including energy, lubricants, construction, and fertilisers. He has broad experience across both matured markets in the Americas and Europe, as well as developing markets including China, India, and Southeast Asia.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Bettina Paschke, VP ESG Accounting, Reporting &amp;amp; Controlling, DHL Express&lt;/strong&gt;. Bettina Paschke leads ESG Accounting, Reporting &amp;amp; Controlling, at DHL Express a division of DHL Group. In her role, she is responsible for ESG, including, EU Taxonomy Reporting, and Carbon Accounting. She has more than 20 years’ experience in Finance. In her role she is driving the Sustainable Aviation Fuel agenda at DHL Express and is engaged in various industry initiatives to allow reliable book and claim transactions.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Christoph Wolff, Chief Executive Officer at Smart Freight Centre&lt;/strong&gt;. Christoph Wolff is currently the Chief Executive Officer at Smart Freight Centre, leading programs focused on sustainability in freight transport. Prior to this role, Christoph served as the Senior Advisor and Director at ACME Group, a global leader in green energy solutions. With a background in various industries, Christoph has held positions such as Managing Director at European Climate Foundation and Senior Board Advisor at Ferrostaal GmbH. Christoph has also worked at Novatec, Solar Millennium AG, DB Schenker, McKinsey &amp;amp; Company, and served as an Assistant Professor at Northwestern University - Kellogg School of Management. Christoph holds multiple degrees from RWTH Aachen University and ETH Zürich, along with ongoing executive education at the University of Michigan.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;em&gt;This discussion is presented by MIT Technology Review Insights in association with Avelia.&amp;nbsp;Avelia is a Shell owned solution and brand that was developed with support from Amex GBT, Accenture and Energy Web Foundation.&amp;nbsp;&lt;/em&gt;The views from individuals not affiliated with Shell are their own and not those of Shell PLC or its affiliates. &lt;em&gt;Cautionary note | Shell Global&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Not all offerings are available in all jurisdictions. Depending on jurisdiction and local laws, Shell may offer the sale of Environmental Attributes (for which subject to applicable law and consultation with own advisors, buyers might be able to use such Environmental Attributes for their own emission reduction purposes) and/or Environmental Attribute Information (pursuant to which buyers are helping subsidize the use of SAF and lower overall aviation emissions at designated airports but no emission reduction claims may be made by buyers for their own emissions reduction purposes). Different offerings have different forms of contracts, and no assumptions should be made about a particular offering without reading the specific contractual language applicable to such offering.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/16/1123850/unlocking-the-potential-of-saf-with-book-and-claim-in-air-freight/</guid><pubDate>Thu, 16 Oct 2025 15:16:19 +0000</pubDate></item><item><title>Apple loses another AI exec to Meta (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/apple-loses-another-ai-exec-to-meta/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ke Yang, the Apple executive leading the iPhone maker’s efforts to build AI-driven web search, is heading to Meta, according to a Bloomberg report. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang’s departure marks the latest in a string of exits from Apple’s AI unit, putting the company into jeopardy in the lead-up to a much-anticipated&amp;nbsp;Siri revamp scheduled for March. Ruoming Pang, Apple’s former head of AI models, left for Meta earlier this year. Roughly a dozen team members on Apple’s AIML (AI and machine learning) team also left the company. Several members joined Meta’s new Superintelligence Labs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A few weeks ago, Yang began overseeing the Answers, Knowledge, and Information (AKI) team, which is tasked with improving Siri’s functionality by allowing it to pull information from the web so Apple can better compete with rivals in the AI search market, like OpenAI, Perplexity, and Google. The new Siri also promises to be able to tap into personal data for more complex tasks. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bloomberg reports that Apple’s remaining team members expect more AI team members to jump ship in the coming months.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Apple and Meta for comment. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ke Yang, the Apple executive leading the iPhone maker’s efforts to build AI-driven web search, is heading to Meta, according to a Bloomberg report. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang’s departure marks the latest in a string of exits from Apple’s AI unit, putting the company into jeopardy in the lead-up to a much-anticipated&amp;nbsp;Siri revamp scheduled for March. Ruoming Pang, Apple’s former head of AI models, left for Meta earlier this year. Roughly a dozen team members on Apple’s AIML (AI and machine learning) team also left the company. Several members joined Meta’s new Superintelligence Labs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A few weeks ago, Yang began overseeing the Answers, Knowledge, and Information (AKI) team, which is tasked with improving Siri’s functionality by allowing it to pull information from the web so Apple can better compete with rivals in the AI search market, like OpenAI, Perplexity, and Google. The new Siri also promises to be able to tap into personal data for more complex tasks. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bloomberg reports that Apple’s remaining team members expect more AI team members to jump ship in the coming months.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Apple and Meta for comment. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/apple-loses-another-ai-exec-to-meta/</guid><pubDate>Thu, 16 Oct 2025 15:21:03 +0000</pubDate></item><item><title>Take our quiz: How much do you know about antimicrobial resistance? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/16/1125853/antimicrobial-resistance-quiz-antibiotics-infection/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/microbes-medicine.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;This week we had some terrifying news from the World Health Organization: Antibiotics are failing us. A growing number of bacterial infections aren’t responding to these medicines—including common ones that affect the blood, gut, and urinary tract. Get infected with one of these bugs, and there’s a fair chance antibiotics won’t help.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The scary truth is that a growing number of harmful bacteria and fungi are becoming resistant to drugs. Just a few weeks ago, the US Centers for Disease Control and Prevention published a report finding a sharp rise in infections caused by a dangerous type of bacteria that are resistant to some of the strongest antibiotics. Now, the WHO report shows that the problem is surging around the world.&lt;/p&gt;  &lt;p&gt;In this week’s Checkup, we’re trying something a bit different—a little quiz. You’ve probably heard about antimicrobial resistance (AMR) before, but how much do you know about microbes, antibiotics, and the scale of the problem? Here’s our attempt to put the “fun” in “fundamental threat to modern medicine.” Test your knowledge below!&lt;/p&gt;    &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/microbes-medicine.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;This week we had some terrifying news from the World Health Organization: Antibiotics are failing us. A growing number of bacterial infections aren’t responding to these medicines—including common ones that affect the blood, gut, and urinary tract. Get infected with one of these bugs, and there’s a fair chance antibiotics won’t help.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The scary truth is that a growing number of harmful bacteria and fungi are becoming resistant to drugs. Just a few weeks ago, the US Centers for Disease Control and Prevention published a report finding a sharp rise in infections caused by a dangerous type of bacteria that are resistant to some of the strongest antibiotics. Now, the WHO report shows that the problem is surging around the world.&lt;/p&gt;  &lt;p&gt;In this week’s Checkup, we’re trying something a bit different—a little quiz. You’ve probably heard about antimicrobial resistance (AMR) before, but how much do you know about microbes, antibiotics, and the scale of the problem? Here’s our attempt to put the “fun” in “fundamental threat to modern medicine.” Test your knowledge below!&lt;/p&gt;    &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/16/1125853/antimicrobial-resistance-quiz-antibiotics-infection/</guid><pubDate>Thu, 16 Oct 2025 15:31:16 +0000</pubDate></item><item><title>AI Safety Newsletter #64: New AGI Definition and Senate Bill Would Establish Liability for AI Harms (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-63-new-agi-definition</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: A new bill in the Senate would hold AI companies liable for harms their products create; China tightens its export controls on rare earth metals; a definition of AGI.&lt;/p&gt;&lt;p&gt;&lt;span&gt;As a reminder, we’re &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0c6be5ff-b04e-49eb-92bd-d11c7c81ae6e" rel="rel"&gt;hiring&lt;/a&gt;&lt;span&gt; a writer for the newsletter.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sens. Dick Durbin, (D-Ill) and Josh Hawley (R-Mo) &lt;/span&gt;&lt;a href="https://www.judiciary.senate.gov/imo/media/doc/One-Pager%20-%20AI%20LEAD%20Act.pdf" rel="rel"&gt;introduced&lt;/a&gt;&lt;span&gt; the &lt;/span&gt;&lt;em&gt;&lt;a href="https://www.judiciary.senate.gov/imo/media/doc/OLL25B47.pdf" rel="rel"&gt;AI LEAD Act&lt;/a&gt;&lt;/em&gt;&lt;span&gt;, which would establish a federal cause of action for people harmed by AI systems to sue AI companies.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Corporations are usually liable for harms their products create&lt;/strong&gt;&lt;span&gt;. When a company sells a product in the United States that harms someone, that person can generally sue that company for damages under the doctrine of product liability. Those suits force companies to internalize the harms their products create—and incentivize them to make their products safer.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Courts haven’t settled on whether AI systems are products.&lt;/strong&gt;&lt;span&gt; Early cases indicate that US courts are open to treating AI systems as products for the purposes of product liability. In a case against CharacterAI, a federal judge &lt;/span&gt;&lt;a href="https://www.transparencycoalition.ai/news/important-early-ruling-in-characterai-case-this-chatbot-is-a-product-not-speech" rel="rel"&gt;ruled&lt;/a&gt;&lt;span&gt; that the company’s system did count as a product. OpenAI is facing a similar &lt;/span&gt;&lt;a href="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Raine-v-OpenAI-Complaint-8-26-25.pdf" rel="rel"&gt;suit&lt;/a&gt;&lt;span&gt; brought in California state court. Nonetheless, the lack of legal certainty might deter potential plaintiffs from bringing suits.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;AI LEAD Act&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; would apply product liability to AI systems. &lt;/strong&gt;&lt;span&gt;The &lt;/span&gt;&lt;em&gt;AI LEAD Act &lt;/em&gt;&lt;span&gt;would clarify that AI systems are subject to product liability and establish a path for claims to be brought in federal court. In general, the act would hold AI companies liable for harms caused by their AI systems if the company:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Failed to exercise reasonable care in designing the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Failed to exercise reasonable care in providing instructions or warnings for the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Breaches a warranty it provided for the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Sold or distributed an AI system in a defective condition that permitted unreasonably dangerous misuse.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The deployers of an AI system are also liable for harm if they substantially modify or dangerously misuse the system.&lt;/p&gt;&lt;p&gt;The act also prohibits AI companies from limiting their liability though contracts with consumers, requires that foreign AI developers register agents for service of process with the US before placing their products on the US market, and permits states to establish stronger safety legislation if they so choose.&lt;/p&gt;&lt;p&gt;&lt;span&gt;China’s Ministry of Commerce &lt;/span&gt;&lt;a href="https://www.mofcom.gov.cn/zwgk/zcfb/art/2025/art_7fc9bff0fb4546ecb02f66ee77d0e5f6.html" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; new export controls on rare earth metals, set to take effect December 1. If aggressively enforced, the rules would give China control over a key part of the global AI and defense supply chains. It also unveiled curbs on the export of equipment used to manufacture electric vehicle batteries, effective November 8.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;China dominates global production of rare earths.&lt;/strong&gt;&lt;span&gt; China has a &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/04/13/business/china-rare-earths-exports.html" rel="rel"&gt;virtual monopoly&lt;/a&gt;&lt;span&gt; on the production of rare earth metals, which are vital to semiconductors, smartphones, AI systems, wind turbines, electric motors, and military hardware. According to the new rules, companies exporting products containing Chinese rare earths are required to obtain export licenses from China’s Ministry of Commerce. Exporting Chinese rare earths for military use is prohibited, and use in developing sub-14 nanometer chips will be reviewed on a case-by-case basis.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!IY3v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F579c41b1-9f1d-4f29-ab53-3c451e5e6e58_980x653.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="653" src="https://substackcdn.com/image/fetch/$s_!IY3v!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F579c41b1-9f1d-4f29-ab53-3c451e5e6e58_980x653.png" width="980" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;A Chinese rare earth mine. &lt;/span&gt;&lt;a href="https://apnews.com/article/china-earths-exports-trump-dad99d532f858f04d750d0b8c50e5ed6" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;If aggressively enforced, the new rules would likely disrupt AI supply chains.&lt;/strong&gt;&lt;span&gt; Rare earth metals are critical to companies producing AI hardware, and their restriction would cause downstream impacts to AI developers. Some analysts predicted they could even trigger a wider economic downturn. “If enforced aggressively,” &lt;/span&gt;&lt;a href="https://x.com/deanwball/status/1976260051351343195" rel="rel"&gt;wrote&lt;/a&gt;&lt;span&gt; Dean Ball on X, “this policy could mean ‘lights out’ for the US AI boom, and likely lead to a recession/economic crisis in the US in the short term.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;China may be using its monopoly as leverage to extract US concessions. &lt;/strong&gt;&lt;span&gt;China claims that the purpose of the controls are only to prevent its rare earth metals from being used in military applications—samarium, for example, is used by the U.S. to &lt;/span&gt;&lt;a href="https://www.csis.org/analysis/consequences-chinas-new-rare-earths-export-restrictions" rel="rel"&gt;manufacture&lt;/a&gt;&lt;span&gt; F-35 fighter jets and missile systems.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;However, the rules would give China effective control over the supply chains of several critical industries, including AI. The US is unlikely to accept that strategic vulnerability. US President Donald Trump &lt;/span&gt;&lt;a href="https://truthsocial.com/@realDonaldTrump/posts/115351840469973590" rel="rel"&gt;responded&lt;/a&gt;&lt;span&gt; to the new controls by announcing a 100 percent additional tariff on Chinese goods—on top of the existing 30 percent tariffs—as well as export controls on critical software, both going into effect November 1.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;China may walk back its controls to deescalate an economic confrontation with the US, or in exchange for reduced tariffs or greater access to frontier AI chips. In the long run, the US would be well-advised to build independent rare earth metal production capacity.&lt;/p&gt;&lt;p&gt;&lt;span&gt;A large group of people in AI—including Dan Hendrycks, Yoshua Bengio, Dawn Song, Max Tegmark, Eric Schmidt, Jaan Tallinn, Gary Marcus, and others—released a &lt;/span&gt;&lt;a href="https://agidefinition.ai/" rel="rel"&gt;paper&lt;/a&gt;&lt;span&gt; introducing a quantifiable framework for defining Artificial General Intelligence (AGI), aiming to standardize the term and measure the gap between current AI and human-level cognition.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI definitions are often nebulous.&lt;/strong&gt;&lt;span&gt; The paper argues that the term AGI currently acts as a “constantly moving goalpost.” As specialized AI systems master tasks previously thought to require human intellect, the criteria for AGI shift. This ambiguity hinders productive discussions about progress and obscures the actual distance to human-level intelligence.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The framework is grounded in theory.&lt;/strong&gt;&lt;span&gt; The authors define AGI as “an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.” To operationalize this, they ground their methodology in the Cattell-Horn-Carroll (CHC) theory, the most empirically validated model of human intelligence. The framework adapts established human psychometric tests to evaluate AI systems across ten core cognitive domains, resulting in a standardized “AGI Score” (0-100%).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Current models exhibit a “jagged” cognitive profile.&lt;/strong&gt;&lt;span&gt; Application of the framework reveals highly uneven capabilities. While models are proficient in knowledge-intensive domains (such as Math or Reading/Writing), they possess critical deficits in foundational cognitive machinery.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!PDPm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d55bd85-caa6-4252-8cc7-6470a89c5f19_1600x1158.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1054" src="https://substackcdn.com/image/fetch/$s_!PDPm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d55bd85-caa6-4252-8cc7-6470a89c5f19_1600x1158.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Long-term memory storage is the critical bottleneck.&lt;/strong&gt;&lt;span&gt; The most significant deficit identified is Long-Term Memory Storage, where current models score near 0%. This results in a form of “amnesia,” forcing the AI to re-learn context in every interaction. The paper notes that the reliance on massive context windows (Working Memory) is a “capability contortion” used to compensate for this lack of persistent memory.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The framework quantifies the gap to AGI.&lt;/strong&gt;&lt;span&gt; The resulting scores are intended to concretely quantify both rapid progress and the substantial gap remaining before AGI. The paper estimates GPT-4 at a 27% AGI score and the anticipated GPT-5 (2025) at 58%.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The paper can be accessed at &lt;/span&gt;&lt;a href="https://agidefinition.ai/" rel="rel"&gt;agidefinition.ai&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Governor Newsom &lt;/span&gt;&lt;a href="https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/" rel="rel"&gt;signed&lt;/a&gt;&lt;span&gt; SB-53 into law (&lt;/span&gt;&lt;a href="https://www.politico.com/news/2025/10/04/sacramento-california-ai-rules-00594082" rel="rel"&gt;Politico&lt;/a&gt;&lt;span&gt;).&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAISI &lt;/span&gt;&lt;a href="https://www.nist.gov/system/files/documents/2025/09/30/CAISI_Evaluation_of_DeepSeek_AI_Models.pdf" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; an evaluation of Deepseek’s AI models.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Select Committee on the CCP &lt;/span&gt;&lt;a href="https://selectcommitteeontheccp.house.gov/media/press-releases/new-investigation-reveals-american-and-allied-companies-boosted-the-ccp-s-semiconductor-industry-fueled-the-prc-s-military-ambitions-and-human-rights-abuses" rel="rel"&gt;found&lt;/a&gt;&lt;span&gt; that companies in the US and allied countries are selling semiconductor manufacturing equipment to China.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/sora-2/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; Sora 2, its latest video-generation model, along with a tiktok-style app.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Microsoft and Anthropic &lt;/span&gt;&lt;a href="https://www.reuters.com/business/retail-consumer/former-british-pm-sunak-joins-microsoft-anthropic-advisory-roles-2025-10-09/" rel="rel"&gt;hired&lt;/a&gt;&lt;span&gt; former UK Prime Minister Rishi Sunak into advisory roles.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic open-sourced &lt;/span&gt;&lt;a href="https://www.anthropic.com/research/petri-open-source-auditing" rel="rel"&gt;Petri&lt;/a&gt;&lt;span&gt;, a tool for automating AI behavior audits through multi-turn simulations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Karson Elmgren, Scott Singer, and Oliver Guest &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/is-china-serious-about-ai-safety" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; how China’s new AI safety body brings together leading experts—but faces obstacles to turning ambition into influence.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://x.com/_NathanCalvin/status/1976649051396620514" rel="rel"&gt;subpoenaed&lt;/a&gt;&lt;span&gt; the general counsel of Encode, a nonprofit that worked on SB 53.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers &lt;/span&gt;&lt;a href="https://x.com/Bin4ryDigit/status/1969291490011558157" rel="rel"&gt;discovered&lt;/a&gt;&lt;span&gt; an exploit of Unitree’s humanoid robots that lets attackers take control, embed themselves, and spread to nearby devices.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Budget Lab at Yale &lt;/span&gt;&lt;a href="https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a report evaluating AI’s effects on the labor market.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FLI announced the &lt;/span&gt;&lt;a href="https://keepthefuturehuman.ai/contest/" rel="rel"&gt;Keep The Future Human Creative Contest&lt;/a&gt;&lt;span&gt;, which offers $100,000+ in cash prizes for digital media that raises awareness of AI existential risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-63-new-agi-definition?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: A new bill in the Senate would hold AI companies liable for harms their products create; China tightens its export controls on rare earth metals; a definition of AGI.&lt;/p&gt;&lt;p&gt;&lt;span&gt;As a reminder, we’re &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0c6be5ff-b04e-49eb-92bd-d11c7c81ae6e" rel="rel"&gt;hiring&lt;/a&gt;&lt;span&gt; a writer for the newsletter.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sens. Dick Durbin, (D-Ill) and Josh Hawley (R-Mo) &lt;/span&gt;&lt;a href="https://www.judiciary.senate.gov/imo/media/doc/One-Pager%20-%20AI%20LEAD%20Act.pdf" rel="rel"&gt;introduced&lt;/a&gt;&lt;span&gt; the &lt;/span&gt;&lt;em&gt;&lt;a href="https://www.judiciary.senate.gov/imo/media/doc/OLL25B47.pdf" rel="rel"&gt;AI LEAD Act&lt;/a&gt;&lt;/em&gt;&lt;span&gt;, which would establish a federal cause of action for people harmed by AI systems to sue AI companies.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Corporations are usually liable for harms their products create&lt;/strong&gt;&lt;span&gt;. When a company sells a product in the United States that harms someone, that person can generally sue that company for damages under the doctrine of product liability. Those suits force companies to internalize the harms their products create—and incentivize them to make their products safer.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Courts haven’t settled on whether AI systems are products.&lt;/strong&gt;&lt;span&gt; Early cases indicate that US courts are open to treating AI systems as products for the purposes of product liability. In a case against CharacterAI, a federal judge &lt;/span&gt;&lt;a href="https://www.transparencycoalition.ai/news/important-early-ruling-in-characterai-case-this-chatbot-is-a-product-not-speech" rel="rel"&gt;ruled&lt;/a&gt;&lt;span&gt; that the company’s system did count as a product. OpenAI is facing a similar &lt;/span&gt;&lt;a href="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Raine-v-OpenAI-Complaint-8-26-25.pdf" rel="rel"&gt;suit&lt;/a&gt;&lt;span&gt; brought in California state court. Nonetheless, the lack of legal certainty might deter potential plaintiffs from bringing suits.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;AI LEAD Act&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; would apply product liability to AI systems. &lt;/strong&gt;&lt;span&gt;The &lt;/span&gt;&lt;em&gt;AI LEAD Act &lt;/em&gt;&lt;span&gt;would clarify that AI systems are subject to product liability and establish a path for claims to be brought in federal court. In general, the act would hold AI companies liable for harms caused by their AI systems if the company:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Failed to exercise reasonable care in designing the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Failed to exercise reasonable care in providing instructions or warnings for the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Breaches a warranty it provided for the AI system,&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Sold or distributed an AI system in a defective condition that permitted unreasonably dangerous misuse.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The deployers of an AI system are also liable for harm if they substantially modify or dangerously misuse the system.&lt;/p&gt;&lt;p&gt;The act also prohibits AI companies from limiting their liability though contracts with consumers, requires that foreign AI developers register agents for service of process with the US before placing their products on the US market, and permits states to establish stronger safety legislation if they so choose.&lt;/p&gt;&lt;p&gt;&lt;span&gt;China’s Ministry of Commerce &lt;/span&gt;&lt;a href="https://www.mofcom.gov.cn/zwgk/zcfb/art/2025/art_7fc9bff0fb4546ecb02f66ee77d0e5f6.html" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; new export controls on rare earth metals, set to take effect December 1. If aggressively enforced, the rules would give China control over a key part of the global AI and defense supply chains. It also unveiled curbs on the export of equipment used to manufacture electric vehicle batteries, effective November 8.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;China dominates global production of rare earths.&lt;/strong&gt;&lt;span&gt; China has a &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/04/13/business/china-rare-earths-exports.html" rel="rel"&gt;virtual monopoly&lt;/a&gt;&lt;span&gt; on the production of rare earth metals, which are vital to semiconductors, smartphones, AI systems, wind turbines, electric motors, and military hardware. According to the new rules, companies exporting products containing Chinese rare earths are required to obtain export licenses from China’s Ministry of Commerce. Exporting Chinese rare earths for military use is prohibited, and use in developing sub-14 nanometer chips will be reviewed on a case-by-case basis.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!IY3v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F579c41b1-9f1d-4f29-ab53-3c451e5e6e58_980x653.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="653" src="https://substackcdn.com/image/fetch/$s_!IY3v!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F579c41b1-9f1d-4f29-ab53-3c451e5e6e58_980x653.png" width="980" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;A Chinese rare earth mine. &lt;/span&gt;&lt;a href="https://apnews.com/article/china-earths-exports-trump-dad99d532f858f04d750d0b8c50e5ed6" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;If aggressively enforced, the new rules would likely disrupt AI supply chains.&lt;/strong&gt;&lt;span&gt; Rare earth metals are critical to companies producing AI hardware, and their restriction would cause downstream impacts to AI developers. Some analysts predicted they could even trigger a wider economic downturn. “If enforced aggressively,” &lt;/span&gt;&lt;a href="https://x.com/deanwball/status/1976260051351343195" rel="rel"&gt;wrote&lt;/a&gt;&lt;span&gt; Dean Ball on X, “this policy could mean ‘lights out’ for the US AI boom, and likely lead to a recession/economic crisis in the US in the short term.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;China may be using its monopoly as leverage to extract US concessions. &lt;/strong&gt;&lt;span&gt;China claims that the purpose of the controls are only to prevent its rare earth metals from being used in military applications—samarium, for example, is used by the U.S. to &lt;/span&gt;&lt;a href="https://www.csis.org/analysis/consequences-chinas-new-rare-earths-export-restrictions" rel="rel"&gt;manufacture&lt;/a&gt;&lt;span&gt; F-35 fighter jets and missile systems.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;However, the rules would give China effective control over the supply chains of several critical industries, including AI. The US is unlikely to accept that strategic vulnerability. US President Donald Trump &lt;/span&gt;&lt;a href="https://truthsocial.com/@realDonaldTrump/posts/115351840469973590" rel="rel"&gt;responded&lt;/a&gt;&lt;span&gt; to the new controls by announcing a 100 percent additional tariff on Chinese goods—on top of the existing 30 percent tariffs—as well as export controls on critical software, both going into effect November 1.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;China may walk back its controls to deescalate an economic confrontation with the US, or in exchange for reduced tariffs or greater access to frontier AI chips. In the long run, the US would be well-advised to build independent rare earth metal production capacity.&lt;/p&gt;&lt;p&gt;&lt;span&gt;A large group of people in AI—including Dan Hendrycks, Yoshua Bengio, Dawn Song, Max Tegmark, Eric Schmidt, Jaan Tallinn, Gary Marcus, and others—released a &lt;/span&gt;&lt;a href="https://agidefinition.ai/" rel="rel"&gt;paper&lt;/a&gt;&lt;span&gt; introducing a quantifiable framework for defining Artificial General Intelligence (AGI), aiming to standardize the term and measure the gap between current AI and human-level cognition.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AGI definitions are often nebulous.&lt;/strong&gt;&lt;span&gt; The paper argues that the term AGI currently acts as a “constantly moving goalpost.” As specialized AI systems master tasks previously thought to require human intellect, the criteria for AGI shift. This ambiguity hinders productive discussions about progress and obscures the actual distance to human-level intelligence.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The framework is grounded in theory.&lt;/strong&gt;&lt;span&gt; The authors define AGI as “an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.” To operationalize this, they ground their methodology in the Cattell-Horn-Carroll (CHC) theory, the most empirically validated model of human intelligence. The framework adapts established human psychometric tests to evaluate AI systems across ten core cognitive domains, resulting in a standardized “AGI Score” (0-100%).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Current models exhibit a “jagged” cognitive profile.&lt;/strong&gt;&lt;span&gt; Application of the framework reveals highly uneven capabilities. While models are proficient in knowledge-intensive domains (such as Math or Reading/Writing), they possess critical deficits in foundational cognitive machinery.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!PDPm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d55bd85-caa6-4252-8cc7-6470a89c5f19_1600x1158.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1054" src="https://substackcdn.com/image/fetch/$s_!PDPm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d55bd85-caa6-4252-8cc7-6470a89c5f19_1600x1158.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Long-term memory storage is the critical bottleneck.&lt;/strong&gt;&lt;span&gt; The most significant deficit identified is Long-Term Memory Storage, where current models score near 0%. This results in a form of “amnesia,” forcing the AI to re-learn context in every interaction. The paper notes that the reliance on massive context windows (Working Memory) is a “capability contortion” used to compensate for this lack of persistent memory.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The framework quantifies the gap to AGI.&lt;/strong&gt;&lt;span&gt; The resulting scores are intended to concretely quantify both rapid progress and the substantial gap remaining before AGI. The paper estimates GPT-4 at a 27% AGI score and the anticipated GPT-5 (2025) at 58%.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The paper can be accessed at &lt;/span&gt;&lt;a href="https://agidefinition.ai/" rel="rel"&gt;agidefinition.ai&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Governor Newsom &lt;/span&gt;&lt;a href="https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/" rel="rel"&gt;signed&lt;/a&gt;&lt;span&gt; SB-53 into law (&lt;/span&gt;&lt;a href="https://www.politico.com/news/2025/10/04/sacramento-california-ai-rules-00594082" rel="rel"&gt;Politico&lt;/a&gt;&lt;span&gt;).&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAISI &lt;/span&gt;&lt;a href="https://www.nist.gov/system/files/documents/2025/09/30/CAISI_Evaluation_of_DeepSeek_AI_Models.pdf" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; an evaluation of Deepseek’s AI models.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Select Committee on the CCP &lt;/span&gt;&lt;a href="https://selectcommitteeontheccp.house.gov/media/press-releases/new-investigation-reveals-american-and-allied-companies-boosted-the-ccp-s-semiconductor-industry-fueled-the-prc-s-military-ambitions-and-human-rights-abuses" rel="rel"&gt;found&lt;/a&gt;&lt;span&gt; that companies in the US and allied countries are selling semiconductor manufacturing equipment to China.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/sora-2/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; Sora 2, its latest video-generation model, along with a tiktok-style app.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Microsoft and Anthropic &lt;/span&gt;&lt;a href="https://www.reuters.com/business/retail-consumer/former-british-pm-sunak-joins-microsoft-anthropic-advisory-roles-2025-10-09/" rel="rel"&gt;hired&lt;/a&gt;&lt;span&gt; former UK Prime Minister Rishi Sunak into advisory roles.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic open-sourced &lt;/span&gt;&lt;a href="https://www.anthropic.com/research/petri-open-source-auditing" rel="rel"&gt;Petri&lt;/a&gt;&lt;span&gt;, a tool for automating AI behavior audits through multi-turn simulations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Karson Elmgren, Scott Singer, and Oliver Guest &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/is-china-serious-about-ai-safety" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; how China’s new AI safety body brings together leading experts—but faces obstacles to turning ambition into influence.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://x.com/_NathanCalvin/status/1976649051396620514" rel="rel"&gt;subpoenaed&lt;/a&gt;&lt;span&gt; the general counsel of Encode, a nonprofit that worked on SB 53.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers &lt;/span&gt;&lt;a href="https://x.com/Bin4ryDigit/status/1969291490011558157" rel="rel"&gt;discovered&lt;/a&gt;&lt;span&gt; an exploit of Unitree’s humanoid robots that lets attackers take control, embed themselves, and spread to nearby devices.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Budget Lab at Yale &lt;/span&gt;&lt;a href="https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a report evaluating AI’s effects on the labor market.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FLI announced the &lt;/span&gt;&lt;a href="https://keepthefuturehuman.ai/contest/" rel="rel"&gt;Keep The Future Human Creative Contest&lt;/a&gt;&lt;span&gt;, which offers $100,000+ in cash prizes for digital media that raises awareness of AI existential risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-63-new-agi-definition?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-63-new-agi-definition</guid><pubDate>Thu, 16 Oct 2025 15:56:30 +0000</pubDate></item><item><title>How Anthropic’s ‘Skills’ make Claude faster, cheaper, and more consistent for business workflows (AI | VentureBeat)</title><link>https://venturebeat.com/ai/how-anthropics-skills-make-claude-faster-cheaper-and-more-consistent-for</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; launched a new capability on Thursday that allows its &lt;a href="https://claude.ai/"&gt;&lt;u&gt;Claude AI&lt;/u&gt;&lt;/a&gt; assistant to tap into specialized expertise on demand, marking the company&amp;#x27;s latest effort to make artificial intelligence more practical for enterprise workflows as it chases rival OpenAI in the intensifying competition over AI-powered software development.&lt;/p&gt;&lt;p&gt;The feature, called &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt;, enables users to create folders containing instructions, code scripts, and reference materials that Claude can automatically load when relevant to a task. The system marks a fundamental shift in how organizations can customize AI assistants, moving beyond one-off prompts to reusable packages of domain expertise that work consistently across an entire company.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills are based on our belief and vision that as model intelligence continues to improve, we&amp;#x27;ll continue moving towards general-purpose agents that often have access to their own filesystem and computing environment,&amp;quot; said Mahesh Murag, a member of Anthropic&amp;#x27;s technical staff, in an exclusive interview with VentureBeat. &amp;quot;The agent is initially made aware only of the names and descriptions of each available skill and can choose to load more information about a particular skill when relevant to the task at hand.&amp;quot;&lt;/p&gt;&lt;p&gt;The launch comes as Anthropic, valued at &lt;a href="https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation"&gt;&lt;u&gt;$183 billion after a recent $13 billion funding round&lt;/u&gt;&lt;/a&gt;, projects its annual revenue could nearly triple to as much as $26 billion in 2026, according to a recent &lt;a href="https://www.reuters.com/business/retail-consumer/anthropic-aims-nearly-triple-annualized-revenue-2026-sources-say-2025-10-15/"&gt;&lt;u&gt;Reuters report&lt;/u&gt;&lt;/a&gt;. The company is currently approaching a $7 billion annual revenue run rate, up from $5 billion in August, fueled largely by enterprise adoption of its AI coding tools — a market where it faces fierce competition from OpenAI&amp;#x27;s recently upgraded Codex platform.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How &amp;#x27;progressive disclosure&amp;#x27; solves the context window problem&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; differ fundamentally from existing approaches to customizing AI assistants, such as prompt engineering or retrieval-augmented generation (RAG), Murag explained. The architecture relies on what Anthropic calls &amp;quot;progressive disclosure&amp;quot; — Claude initially sees only skill names and brief descriptions, then autonomously decides which skills to load based on the task at hand, accessing only the specific files and information needed at that moment.&lt;/p&gt;&lt;p&gt;&amp;quot;Unlike RAG, this relies on simple tools that let Claude manage and read files from a filesystem,&amp;quot; Murag told VentureBeat. &amp;quot;Skills can contain an unbounded amount of context to teach Claude how to complete a task or series of tasks. This is because Skills are based on the premise of an agent being able to autonomously and intelligently navigate a filesystem and execute code.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach allows organizations to bundle far more information than traditional context windows permit, while maintaining the speed and efficiency that enterprise users demand. A single skill can include step-by-step procedures, code templates, reference documents, brand guidelines, compliance checklists, and executable scripts — all organized in a folder structure that Claude navigates intelligently.&lt;/p&gt;&lt;p&gt;The system&amp;#x27;s composability provides another technical advantage. Multiple skills automatically stack together when needed for complex workflows. For instance, Claude might simultaneously invoke a company&amp;#x27;s brand guidelines skill, a financial reporting skill, and a presentation formatting skill to generate a quarterly investor deck — coordinating between all three without manual intervention.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What makes Skills different from OpenAI&amp;#x27;s Custom GPTs and Microsoft&amp;#x27;s Copilot&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic is positioning Skills as distinct from competing offerings like OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/introducing-gpts/"&gt;&lt;u&gt;Custom GPTs&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt;, though the features address similar enterprise needs around AI customization and consistency.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills&amp;#x27; combination of progressive disclosure, composability, and executable code bundling is unique in the market,&amp;quot; Murag said. &amp;quot;While other platforms require developers to build custom scaffolding, Skills let anyone — technical or not — create specialized agents by organizing procedural knowledge into files.&amp;quot;&lt;/p&gt;&lt;p&gt;The cross-platform portability also sets Skills apart. The same skill works identically across &lt;a href="http://claude.ai"&gt;&lt;u&gt;Claude.ai&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.claude.com/product/claude-code"&gt;&lt;u&gt;Claude Code&lt;/u&gt;&lt;/a&gt; (Anthropic&amp;#x27;s AI coding environment), the company&amp;#x27;s &lt;a href="https://www.claude.com/platform/api"&gt;&lt;u&gt;API&lt;/u&gt;&lt;/a&gt;, and the &lt;a href="https://docs.claude.com/en/api/agent-sdk/overview"&gt;&lt;u&gt;Claude Agent SDK&lt;/u&gt;&lt;/a&gt; for building custom AI agents. Organizations can develop a skill once and deploy it everywhere their teams use Claude, a significant advantage for enterprises seeking consistency.&lt;/p&gt;&lt;p&gt;The feature supports any programming language compatible with the underlying container environment, and Anthropic provides sandboxing for security — though the company acknowledges that allowing AI to execute code requires users to carefully vet which skills they trust.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Early customers report 8x productivity gains on finance workflows&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Early customer implementations reveal how organizations are applying &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; to automate complex knowledge work. At Japanese e-commerce giant &lt;a href="https://www.rakuten.com/"&gt;&lt;u&gt;Rakuten&lt;/u&gt;&lt;/a&gt;, the AI team is using Skills to transform finance operations that previously required manual coordination across multiple departments.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills streamline our management accounting and finance workflows,&amp;quot; said Yusuke Kaji, general manager of AI at Rakuten in a statement. &amp;quot;Claude processes multiple spreadsheets, catches critical anomalies, and generates reports using our procedures. What once took a day, we can now accomplish in an hour.&amp;quot;&lt;/p&gt;&lt;p&gt;That&amp;#x27;s an 8x improvement in productivity for specific workflows — the kind of measurable return on investment that enterprises increasingly demand from AI implementations. Mike Krieger, Anthropic&amp;#x27;s chief product officer and Instagram co-founder, recently noted that companies have moved past &amp;quot;&lt;a href="https://www.businessinsider.com/anthropic-cpo-companies-success-metrics-avoid-ai-fomo-2025-10"&gt;&lt;u&gt;AI FOMO&lt;/u&gt;&lt;/a&gt;&amp;quot; to requiring concrete success metrics.&lt;/p&gt;&lt;p&gt;Design platform &lt;a href="https://www.canva.com/"&gt;&lt;u&gt;Canva&lt;/u&gt;&lt;/a&gt; plans to integrate Skills into its own AI agent workflows. &amp;quot;Canva plans to leverage Skills to customize agents and expand what they can do,&amp;quot; said Anwar Haneef, general manager and head of ecosystem at Canva in a statement. &amp;quot;This unlocks new ways to bring Canva deeper into agentic workflows—helping teams capture their unique context and create stunning, high-quality designs effortlessly.&amp;quot;&lt;/p&gt;&lt;p&gt;Cloud storage provider &lt;a href="https://www.box.com/"&gt;&lt;u&gt;Box&lt;/u&gt;&lt;/a&gt; sees Skills as a way to make corporate content repositories more actionable. &amp;quot;Skills teaches Claude how to work with Box content,&amp;quot; said Yashodha Bhavnani, head of AI at Box. &amp;quot;Users can transform stored files into PowerPoint presentations, Excel spreadsheets, and Word documents that follow their organization&amp;#x27;s standards—saving hours of effort.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The enterprise security question: Who controls which AI skills employees can use?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For enterprise IT departments, &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; raise important questions about governance and control—particularly since the feature allows AI to execute arbitrary code in sandboxed environments. Anthropic has built administrative controls that allow enterprise customers to manage access at the organizational level.&lt;/p&gt;&lt;p&gt;&amp;quot;Enterprise admins control access to the Skills capability via admin settings, where they can enable or disable access and monitor usage patterns,&amp;quot; Murag said. &amp;quot;Once enabled at the organizational level, individual users still need to opt in.&amp;quot;&lt;/p&gt;&lt;p&gt;That two-layer consent model — organizational enablement plus individual opt-in — reflects lessons learned from previous enterprise AI deployments where blanket rollouts created compliance concerns. However, Anthropic&amp;#x27;s governance tools appear more limited than some enterprise customers might expect. The company doesn&amp;#x27;t currently offer granular controls over which specific skills employees can use, or detailed audit trails of custom skill content.&lt;/p&gt;&lt;p&gt;Organizations concerned about data security should note that Skills require Claude&amp;#x27;s code execution environment, which runs in isolated containers. Anthropic advises users to &amp;quot;stick to trusted sources&amp;quot; when installing skills and provides security documentation, but the company acknowledges this is an inherently higher-risk capability than traditional AI interactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From API to no-code: How Anthropic is making Skills accessible to everyone&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic is taking several approaches to make &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; accessible to users with varying technical sophistication. For non-technical users on &lt;a href="http://claude.ai"&gt;&lt;u&gt;Claude.ai&lt;/u&gt;&lt;/a&gt;, the company provides a &amp;quot;skill-creator&amp;quot; skill that interactively guides users through building new skills by asking questions about their workflow, then automatically generating the folder structure and documentation.&lt;/p&gt;&lt;p&gt;Developers working with &lt;a href="https://www.google.com/aclk?sa=L&amp;amp;ai=DChsSEwiggs2qraiQAxVWBa0GHdB6FzYYACICCAEQABoCcHY&amp;amp;ae=2&amp;amp;co=1&amp;amp;ase=2&amp;amp;gclid=CjwKCAjwr8LHBhBKEiwAy47uUvG3v5zXtZxMzYnFijKFAiDeYFa6OmWUAE1klOZDZ1ZjEL_wOnBjShoC9osQAvD_BwE&amp;amp;cid=CAASugHkaOdviUSYAhp033BnqKi_m1QUy4d_9UnHirVmZCJZSnrd1p-IH-JSwD7zHfKxN59LdDV3IiubJ9mStf_q5CSgrktsrI1deP4WXcf01uLZ1Z98vFRa-3nrliSupihKZ_9iT5Fce10TuciASCCUBAZwEf-wFTA8DNSuVCBEO3EiPAj-Wyo-9vFJk8uCLp_r8yi8DRP4fG0xKwlJwUzWtYpk2oD5f2zmd3ijjkWwZcEty0swPcvf09eh90Q&amp;amp;cce=2&amp;amp;category=acrcp_v1_71&amp;amp;sig=AOD64_06_nK0XQVMjJCrrzehYQwSZRJExA&amp;amp;q&amp;amp;nis=4&amp;amp;adurl&amp;amp;ved=2ahUKEwiD-8SqraiQAxXHyOYEHf8JB1wQ0Qx6BAgeEAE"&gt;&lt;u&gt;Anthropic&amp;#x27;s API&lt;/u&gt;&lt;/a&gt; get programmatic control through a new /skills endpoint and can manage skill versions through the Claude Console web interface. The feature requires enabling the Code Execution Tool beta in API requests. For Claude Code users, skills can be installed via plugins from the anthropics/skills GitHub marketplace, and teams can share skills through version control systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills are included in Max, Pro, Teams, and Enterprise plans at no additional cost,&amp;quot; Murag confirmed. &amp;quot;API usage follows standard API pricing,&amp;quot; meaning organizations pay only for the tokens consumed during skill execution, not for the skills themselves.&lt;/p&gt;&lt;p&gt;Anthropic provides several pre-built skills for common business tasks, including professional generation of Excel spreadsheets with formulas, PowerPoint presentations, Word documents, and fillable PDFs. These Anthropic-created skills will remain free.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why the Skills launch matters in the AI coding wars with OpenAI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Skills announcement arrives during a pivotal moment in Anthropic&amp;#x27;s competition with OpenAI, particularly around AI-assisted software development. Just one day before releasing Skills, Anthropic launched &lt;a href="https://venturebeat.com/ai/anthropic-is-giving-away-its-powerful-claude-haiku-4-5-ai-for-free-to-take"&gt;&lt;u&gt;Claude Haiku 4.5&lt;/u&gt;&lt;/a&gt;, a smaller and cheaper model that nonetheless matches the coding performance of &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Claude Sonnet 4&lt;/u&gt;&lt;/a&gt; — which was state-of-the-art when released just five months ago.&lt;/p&gt;&lt;p&gt;That rapid improvement curve reflects the breakneck pace of AI development, where today&amp;#x27;s frontier capabilities become tomorrow&amp;#x27;s commodity offerings. OpenAI has been pushing hard on coding tools as well, recently upgrading its &lt;a href="https://openai.com/codex/"&gt;&lt;u&gt;Codex platform&lt;/u&gt;&lt;/a&gt; with &lt;a href="https://openai.com/index/introducing-gpt-5/"&gt;&lt;u&gt;GPT-5&lt;/u&gt;&lt;/a&gt; and expanding &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&amp;#x27;s&lt;/u&gt;&lt;/a&gt; capabilities.&lt;/p&gt;&lt;p&gt;Anthropic&amp;#x27;s revenue trajectory — potentially reaching &lt;a href="https://www.reuters.com/business/retail-consumer/anthropic-aims-nearly-triple-annualized-revenue-2026-sources-say-2025-10-15/"&gt;&lt;u&gt;$26 billion in 2026&lt;/u&gt;&lt;/a&gt; from an estimated $9 billion by year-end 2025 — suggests the company is successfully converting enterprise interest into paying customers. The timing also follows Salesforce&amp;#x27;s announcement this week that it&amp;#x27;s deepening AI partnerships with both OpenAI and Anthropic to power its Agentforce platform, signaling that enterprises are adopting a multi-vendor approach rather than standardizing on a single provider.&lt;/p&gt;&lt;p&gt;Skills addresses a real pain point: the &amp;quot;prompt engineering&amp;quot; problem where effective AI usage depends on individual employees crafting elaborate instructions for routine tasks, with no way to share that expertise across teams. Skills transforms implicit knowledge into explicit, shareable assets. For startups and developers, the feature could accelerate product development significantly — adding sophisticated document generation capabilities that previously required dedicated engineering teams and weeks of development.&lt;/p&gt;&lt;p&gt;The composability aspect hints at a future where organizations build libraries of specialized skills that can be mixed and matched for increasingly complex workflows. A pharmaceutical company might develop skills for regulatory compliance, clinical trial analysis, molecular modeling, and patient data privacy that work together seamlessly — creating a customized AI assistant with deep domain expertise across multiple specialties.&lt;/p&gt;&lt;p&gt;Anthropic indicates it&amp;#x27;s working on simplified skill creation workflows and enterprise-wide deployment capabilities to make it easier for organizations to distribute skills across large teams. As the feature rolls out to Anthropic&amp;#x27;s more than 300,000 business customers, the true test will be whether organizations find Skills substantively more useful than existing customization approaches.&lt;/p&gt;&lt;p&gt;For now, Skills offers Anthropic&amp;#x27;s clearest articulation yet of its vision for AI agents: not generalists that try to do everything reasonably well, but intelligent systems that know when to access specialized expertise and can coordinate multiple domains of knowledge to accomplish complex tasks. If that vision catches on, the question won&amp;#x27;t be whether your company uses AI — it will be whether your AI knows how your company actually works.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; launched a new capability on Thursday that allows its &lt;a href="https://claude.ai/"&gt;&lt;u&gt;Claude AI&lt;/u&gt;&lt;/a&gt; assistant to tap into specialized expertise on demand, marking the company&amp;#x27;s latest effort to make artificial intelligence more practical for enterprise workflows as it chases rival OpenAI in the intensifying competition over AI-powered software development.&lt;/p&gt;&lt;p&gt;The feature, called &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt;, enables users to create folders containing instructions, code scripts, and reference materials that Claude can automatically load when relevant to a task. The system marks a fundamental shift in how organizations can customize AI assistants, moving beyond one-off prompts to reusable packages of domain expertise that work consistently across an entire company.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills are based on our belief and vision that as model intelligence continues to improve, we&amp;#x27;ll continue moving towards general-purpose agents that often have access to their own filesystem and computing environment,&amp;quot; said Mahesh Murag, a member of Anthropic&amp;#x27;s technical staff, in an exclusive interview with VentureBeat. &amp;quot;The agent is initially made aware only of the names and descriptions of each available skill and can choose to load more information about a particular skill when relevant to the task at hand.&amp;quot;&lt;/p&gt;&lt;p&gt;The launch comes as Anthropic, valued at &lt;a href="https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation"&gt;&lt;u&gt;$183 billion after a recent $13 billion funding round&lt;/u&gt;&lt;/a&gt;, projects its annual revenue could nearly triple to as much as $26 billion in 2026, according to a recent &lt;a href="https://www.reuters.com/business/retail-consumer/anthropic-aims-nearly-triple-annualized-revenue-2026-sources-say-2025-10-15/"&gt;&lt;u&gt;Reuters report&lt;/u&gt;&lt;/a&gt;. The company is currently approaching a $7 billion annual revenue run rate, up from $5 billion in August, fueled largely by enterprise adoption of its AI coding tools — a market where it faces fierce competition from OpenAI&amp;#x27;s recently upgraded Codex platform.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How &amp;#x27;progressive disclosure&amp;#x27; solves the context window problem&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; differ fundamentally from existing approaches to customizing AI assistants, such as prompt engineering or retrieval-augmented generation (RAG), Murag explained. The architecture relies on what Anthropic calls &amp;quot;progressive disclosure&amp;quot; — Claude initially sees only skill names and brief descriptions, then autonomously decides which skills to load based on the task at hand, accessing only the specific files and information needed at that moment.&lt;/p&gt;&lt;p&gt;&amp;quot;Unlike RAG, this relies on simple tools that let Claude manage and read files from a filesystem,&amp;quot; Murag told VentureBeat. &amp;quot;Skills can contain an unbounded amount of context to teach Claude how to complete a task or series of tasks. This is because Skills are based on the premise of an agent being able to autonomously and intelligently navigate a filesystem and execute code.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach allows organizations to bundle far more information than traditional context windows permit, while maintaining the speed and efficiency that enterprise users demand. A single skill can include step-by-step procedures, code templates, reference documents, brand guidelines, compliance checklists, and executable scripts — all organized in a folder structure that Claude navigates intelligently.&lt;/p&gt;&lt;p&gt;The system&amp;#x27;s composability provides another technical advantage. Multiple skills automatically stack together when needed for complex workflows. For instance, Claude might simultaneously invoke a company&amp;#x27;s brand guidelines skill, a financial reporting skill, and a presentation formatting skill to generate a quarterly investor deck — coordinating between all three without manual intervention.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What makes Skills different from OpenAI&amp;#x27;s Custom GPTs and Microsoft&amp;#x27;s Copilot&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic is positioning Skills as distinct from competing offerings like OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/introducing-gpts/"&gt;&lt;u&gt;Custom GPTs&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt;, though the features address similar enterprise needs around AI customization and consistency.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills&amp;#x27; combination of progressive disclosure, composability, and executable code bundling is unique in the market,&amp;quot; Murag said. &amp;quot;While other platforms require developers to build custom scaffolding, Skills let anyone — technical or not — create specialized agents by organizing procedural knowledge into files.&amp;quot;&lt;/p&gt;&lt;p&gt;The cross-platform portability also sets Skills apart. The same skill works identically across &lt;a href="http://claude.ai"&gt;&lt;u&gt;Claude.ai&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.claude.com/product/claude-code"&gt;&lt;u&gt;Claude Code&lt;/u&gt;&lt;/a&gt; (Anthropic&amp;#x27;s AI coding environment), the company&amp;#x27;s &lt;a href="https://www.claude.com/platform/api"&gt;&lt;u&gt;API&lt;/u&gt;&lt;/a&gt;, and the &lt;a href="https://docs.claude.com/en/api/agent-sdk/overview"&gt;&lt;u&gt;Claude Agent SDK&lt;/u&gt;&lt;/a&gt; for building custom AI agents. Organizations can develop a skill once and deploy it everywhere their teams use Claude, a significant advantage for enterprises seeking consistency.&lt;/p&gt;&lt;p&gt;The feature supports any programming language compatible with the underlying container environment, and Anthropic provides sandboxing for security — though the company acknowledges that allowing AI to execute code requires users to carefully vet which skills they trust.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Early customers report 8x productivity gains on finance workflows&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Early customer implementations reveal how organizations are applying &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; to automate complex knowledge work. At Japanese e-commerce giant &lt;a href="https://www.rakuten.com/"&gt;&lt;u&gt;Rakuten&lt;/u&gt;&lt;/a&gt;, the AI team is using Skills to transform finance operations that previously required manual coordination across multiple departments.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills streamline our management accounting and finance workflows,&amp;quot; said Yusuke Kaji, general manager of AI at Rakuten in a statement. &amp;quot;Claude processes multiple spreadsheets, catches critical anomalies, and generates reports using our procedures. What once took a day, we can now accomplish in an hour.&amp;quot;&lt;/p&gt;&lt;p&gt;That&amp;#x27;s an 8x improvement in productivity for specific workflows — the kind of measurable return on investment that enterprises increasingly demand from AI implementations. Mike Krieger, Anthropic&amp;#x27;s chief product officer and Instagram co-founder, recently noted that companies have moved past &amp;quot;&lt;a href="https://www.businessinsider.com/anthropic-cpo-companies-success-metrics-avoid-ai-fomo-2025-10"&gt;&lt;u&gt;AI FOMO&lt;/u&gt;&lt;/a&gt;&amp;quot; to requiring concrete success metrics.&lt;/p&gt;&lt;p&gt;Design platform &lt;a href="https://www.canva.com/"&gt;&lt;u&gt;Canva&lt;/u&gt;&lt;/a&gt; plans to integrate Skills into its own AI agent workflows. &amp;quot;Canva plans to leverage Skills to customize agents and expand what they can do,&amp;quot; said Anwar Haneef, general manager and head of ecosystem at Canva in a statement. &amp;quot;This unlocks new ways to bring Canva deeper into agentic workflows—helping teams capture their unique context and create stunning, high-quality designs effortlessly.&amp;quot;&lt;/p&gt;&lt;p&gt;Cloud storage provider &lt;a href="https://www.box.com/"&gt;&lt;u&gt;Box&lt;/u&gt;&lt;/a&gt; sees Skills as a way to make corporate content repositories more actionable. &amp;quot;Skills teaches Claude how to work with Box content,&amp;quot; said Yashodha Bhavnani, head of AI at Box. &amp;quot;Users can transform stored files into PowerPoint presentations, Excel spreadsheets, and Word documents that follow their organization&amp;#x27;s standards—saving hours of effort.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The enterprise security question: Who controls which AI skills employees can use?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For enterprise IT departments, &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; raise important questions about governance and control—particularly since the feature allows AI to execute arbitrary code in sandboxed environments. Anthropic has built administrative controls that allow enterprise customers to manage access at the organizational level.&lt;/p&gt;&lt;p&gt;&amp;quot;Enterprise admins control access to the Skills capability via admin settings, where they can enable or disable access and monitor usage patterns,&amp;quot; Murag said. &amp;quot;Once enabled at the organizational level, individual users still need to opt in.&amp;quot;&lt;/p&gt;&lt;p&gt;That two-layer consent model — organizational enablement plus individual opt-in — reflects lessons learned from previous enterprise AI deployments where blanket rollouts created compliance concerns. However, Anthropic&amp;#x27;s governance tools appear more limited than some enterprise customers might expect. The company doesn&amp;#x27;t currently offer granular controls over which specific skills employees can use, or detailed audit trails of custom skill content.&lt;/p&gt;&lt;p&gt;Organizations concerned about data security should note that Skills require Claude&amp;#x27;s code execution environment, which runs in isolated containers. Anthropic advises users to &amp;quot;stick to trusted sources&amp;quot; when installing skills and provides security documentation, but the company acknowledges this is an inherently higher-risk capability than traditional AI interactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From API to no-code: How Anthropic is making Skills accessible to everyone&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic is taking several approaches to make &lt;a href="http://anthropic.com/news/skills"&gt;&lt;u&gt;Skills&lt;/u&gt;&lt;/a&gt; accessible to users with varying technical sophistication. For non-technical users on &lt;a href="http://claude.ai"&gt;&lt;u&gt;Claude.ai&lt;/u&gt;&lt;/a&gt;, the company provides a &amp;quot;skill-creator&amp;quot; skill that interactively guides users through building new skills by asking questions about their workflow, then automatically generating the folder structure and documentation.&lt;/p&gt;&lt;p&gt;Developers working with &lt;a href="https://www.google.com/aclk?sa=L&amp;amp;ai=DChsSEwiggs2qraiQAxVWBa0GHdB6FzYYACICCAEQABoCcHY&amp;amp;ae=2&amp;amp;co=1&amp;amp;ase=2&amp;amp;gclid=CjwKCAjwr8LHBhBKEiwAy47uUvG3v5zXtZxMzYnFijKFAiDeYFa6OmWUAE1klOZDZ1ZjEL_wOnBjShoC9osQAvD_BwE&amp;amp;cid=CAASugHkaOdviUSYAhp033BnqKi_m1QUy4d_9UnHirVmZCJZSnrd1p-IH-JSwD7zHfKxN59LdDV3IiubJ9mStf_q5CSgrktsrI1deP4WXcf01uLZ1Z98vFRa-3nrliSupihKZ_9iT5Fce10TuciASCCUBAZwEf-wFTA8DNSuVCBEO3EiPAj-Wyo-9vFJk8uCLp_r8yi8DRP4fG0xKwlJwUzWtYpk2oD5f2zmd3ijjkWwZcEty0swPcvf09eh90Q&amp;amp;cce=2&amp;amp;category=acrcp_v1_71&amp;amp;sig=AOD64_06_nK0XQVMjJCrrzehYQwSZRJExA&amp;amp;q&amp;amp;nis=4&amp;amp;adurl&amp;amp;ved=2ahUKEwiD-8SqraiQAxXHyOYEHf8JB1wQ0Qx6BAgeEAE"&gt;&lt;u&gt;Anthropic&amp;#x27;s API&lt;/u&gt;&lt;/a&gt; get programmatic control through a new /skills endpoint and can manage skill versions through the Claude Console web interface. The feature requires enabling the Code Execution Tool beta in API requests. For Claude Code users, skills can be installed via plugins from the anthropics/skills GitHub marketplace, and teams can share skills through version control systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Skills are included in Max, Pro, Teams, and Enterprise plans at no additional cost,&amp;quot; Murag confirmed. &amp;quot;API usage follows standard API pricing,&amp;quot; meaning organizations pay only for the tokens consumed during skill execution, not for the skills themselves.&lt;/p&gt;&lt;p&gt;Anthropic provides several pre-built skills for common business tasks, including professional generation of Excel spreadsheets with formulas, PowerPoint presentations, Word documents, and fillable PDFs. These Anthropic-created skills will remain free.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why the Skills launch matters in the AI coding wars with OpenAI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Skills announcement arrives during a pivotal moment in Anthropic&amp;#x27;s competition with OpenAI, particularly around AI-assisted software development. Just one day before releasing Skills, Anthropic launched &lt;a href="https://venturebeat.com/ai/anthropic-is-giving-away-its-powerful-claude-haiku-4-5-ai-for-free-to-take"&gt;&lt;u&gt;Claude Haiku 4.5&lt;/u&gt;&lt;/a&gt;, a smaller and cheaper model that nonetheless matches the coding performance of &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Claude Sonnet 4&lt;/u&gt;&lt;/a&gt; — which was state-of-the-art when released just five months ago.&lt;/p&gt;&lt;p&gt;That rapid improvement curve reflects the breakneck pace of AI development, where today&amp;#x27;s frontier capabilities become tomorrow&amp;#x27;s commodity offerings. OpenAI has been pushing hard on coding tools as well, recently upgrading its &lt;a href="https://openai.com/codex/"&gt;&lt;u&gt;Codex platform&lt;/u&gt;&lt;/a&gt; with &lt;a href="https://openai.com/index/introducing-gpt-5/"&gt;&lt;u&gt;GPT-5&lt;/u&gt;&lt;/a&gt; and expanding &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&amp;#x27;s&lt;/u&gt;&lt;/a&gt; capabilities.&lt;/p&gt;&lt;p&gt;Anthropic&amp;#x27;s revenue trajectory — potentially reaching &lt;a href="https://www.reuters.com/business/retail-consumer/anthropic-aims-nearly-triple-annualized-revenue-2026-sources-say-2025-10-15/"&gt;&lt;u&gt;$26 billion in 2026&lt;/u&gt;&lt;/a&gt; from an estimated $9 billion by year-end 2025 — suggests the company is successfully converting enterprise interest into paying customers. The timing also follows Salesforce&amp;#x27;s announcement this week that it&amp;#x27;s deepening AI partnerships with both OpenAI and Anthropic to power its Agentforce platform, signaling that enterprises are adopting a multi-vendor approach rather than standardizing on a single provider.&lt;/p&gt;&lt;p&gt;Skills addresses a real pain point: the &amp;quot;prompt engineering&amp;quot; problem where effective AI usage depends on individual employees crafting elaborate instructions for routine tasks, with no way to share that expertise across teams. Skills transforms implicit knowledge into explicit, shareable assets. For startups and developers, the feature could accelerate product development significantly — adding sophisticated document generation capabilities that previously required dedicated engineering teams and weeks of development.&lt;/p&gt;&lt;p&gt;The composability aspect hints at a future where organizations build libraries of specialized skills that can be mixed and matched for increasingly complex workflows. A pharmaceutical company might develop skills for regulatory compliance, clinical trial analysis, molecular modeling, and patient data privacy that work together seamlessly — creating a customized AI assistant with deep domain expertise across multiple specialties.&lt;/p&gt;&lt;p&gt;Anthropic indicates it&amp;#x27;s working on simplified skill creation workflows and enterprise-wide deployment capabilities to make it easier for organizations to distribute skills across large teams. As the feature rolls out to Anthropic&amp;#x27;s more than 300,000 business customers, the true test will be whether organizations find Skills substantively more useful than existing customization approaches.&lt;/p&gt;&lt;p&gt;For now, Skills offers Anthropic&amp;#x27;s clearest articulation yet of its vision for AI agents: not generalists that try to do everything reasonably well, but intelligent systems that know when to access specialized expertise and can coordinate multiple domains of knowledge to accomplish complex tasks. If that vision catches on, the question won&amp;#x27;t be whether your company uses AI — it will be whether your AI knows how your company actually works.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-anthropics-skills-make-claude-faster-cheaper-and-more-consistent-for</guid><pubDate>Thu, 16 Oct 2025 16:00:00 +0000</pubDate></item><item><title>OpenAI thinks Elon Musk funded its biggest critics—who also hate Musk (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/openai-thinks-elon-musk-funded-its-biggest-critics-who-also-hate-musk/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Cutthroat” OpenAI accused of exploiting Musk fight to intimidate and silence critics.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2198388525-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2198388525-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Over the past week, OpenAI has faced backlash over subpoenas it sent to nonprofits accused of conspiring with Elon Musk to amplify public criticism of OpenAI as it sought to shift from a nonprofit to for-profit structure.&lt;/p&gt;
&lt;p&gt;The subpoenas are supposed to support OpenAI’s defense in a lawsuit Musk’s X Corp filed to block the for-profit transition. Seeking a “wide variety of documents”—including a sweeping request for all communications regarding Musk and all information on nonprofits’ funders and donations—OpenAI claimed that the subpoenas are intended to probe if Musk was involved in the actions or paid nonprofits to make critical comments, NBC News wrote in a report exhaustively documenting the controversy.&lt;/p&gt;
&lt;p&gt;But nonprofits have alleged it’s obvious that OpenAI is using the lawsuit to harass, silence, and intimidate its critics—most glaringly when it comes to targeting nonprofits that are even more publicly critical of Musk’s companies than they are of OpenAI.&lt;/p&gt;
&lt;p&gt;Emma Ruby-Sachs, executive director for Ekō—a nonprofit that serves as a global consumer watchdog holding the “biggest companies in the world accountable”—told NBC News that “the logical basis” for sending the subpoena “is so ridiculous that we have to assume this is just a tactic to scare us and get us to back off.”&lt;/p&gt;
&lt;p&gt;Ruby-Sachs noted that Ekō called for Musk to be fired as the head of DOGE earlier this year. Running a billboard in Times Square that showed a grinning Musk donning a crown, Ekō urged passersby to contact Congress if they “don’t want a king.”&lt;/p&gt;
&lt;p&gt;Further, Ekō had corresponded with OpenAI prior to receiving the subpoena, confirming that “we’re over 70 percent funded by small online donations from individuals, and we’ve run multiple campaigns against Elon Musk in the last year,” Ruby-Sachs said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“We are not in any way supported by or funded by Elon Musk and have a history of campaigning against him and his interests,” Ruby-Sachs told NBC News.&lt;/p&gt;
&lt;p&gt;Another nonprofit watchdog targeted by OpenAI was The Midas Project, which strives to make sure AI benefits everyone. Notably, Musk’s lawsuit accused OpenAI of abandoning its mission to benefit humanity in pursuit of immense profits.&lt;/p&gt;
&lt;p&gt;But the founder of The Midas Project, Tyler Johnston, was shocked to see his group portrayed as coordinating with Musk. He posted on X to clarify that Musk had nothing to do with the group’s “OpenAI Files,” which comprehensively document areas of concern with any plan to shift away from nonprofit governance.&lt;/p&gt;
&lt;p&gt;His post came after OpenAI’s chief strategy officer, Jason Kwon, wrote that “several organizations, some of them suddenly newly formed like the Midas Project, joined in and ran campaigns” backing Musk’s “opposition to OpenAI’s restructure.”&lt;/p&gt;
&lt;p&gt;“What are you talking about?” Johnston wrote. “We were formed 19 months ago. We’ve never spoken with or taken funding from Musk and [his] ilk, which we would have been happy to tell you if you asked a single time. In fact, we’ve said he runs xAI so horridly it makes OpenAI ‘saintly in comparison.'”&lt;/p&gt;
&lt;h2&gt;OpenAI acting like a “cutthroat” corporation?&lt;/h2&gt;
&lt;p&gt;Johnston complained that OpenAI’s subpoena had already hurt the Midas Project, as insurers had denied coverage based on news coverage. He accused OpenAI of not just trying to silence critics but possibly shut them down.&lt;/p&gt;
&lt;p&gt;“If you wanted to constrain an org’s speech, intimidation would be one strategy, but making them uninsurable is another, and maybe that’s what’s happened to us with this subpoena,” Johnston suggested.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Other nonprofits, like the San Francisco Foundation (SFF) and Encode, accused OpenAI of using subpoenas to potentially block or slow down legal interventions. Judith Bell, SFF’s chief impact officer, told NBC News that her nonprofit’s subpoena came after spearheading a petition to California’s attorney general to block OpenAI’s restructuring. And Encode’s general counsel, Nathan Calvin, was subpoenaed after sponsoring a California safety regulation meant to make it easier to monitor risks of frontier AI.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Unlike many of the targeted groups, Encode filed an amicus brief supporting Musk in the OpenAI lawsuit, with Calvin arguing that “OpenAI was founded as a nonprofit in order to protect” their commitment to building AI that benefits the public, “and the public interest requires they keep their word.”&lt;/p&gt;
&lt;p&gt;On X, Kwon said Encode had inserted itself in the lawsuit by filing the brief, claiming, “We issued a subpoena to ensure transparency around their involvement and funding. This is a routine step in litigation.”&lt;/p&gt;
&lt;p&gt;But Calvin alleged that OpenAI’s subpoena has little to do with the brief and more to do with Encode’s advocacy, NBC News reported.&lt;/p&gt;
&lt;p&gt;“I believe OpenAI used the pretext of their lawsuit against Elon Musk to intimidate their critics and imply that Elon is behind all of them,” Calvin said.&lt;/p&gt;
&lt;p&gt;While nonprofits raged over OpenAI’s alleged intimidation tactics, litigator Ray Seilie told NBC News that OpenAI’s request to subpoena Calvin could have been even more demanding.&lt;/p&gt;
&lt;p&gt;“If OpenAI had wanted to intimidate or harass him, they could have served him with a deposition subpoena, which would have required Calvin to sit down for a full day of questioning under oath by OpenAI’s lawyers in addition to providing documents,” Seilie said. “The fact that OpenAI only asked for documents suggests that they were sincerely looking for connections between Musk and Encode, even if they turned out to be wrong about their suspicion.”&lt;/p&gt;
&lt;p&gt;But Robert Weissman, co-president of a consumer advocacy group not yet targeted by OpenAI, Public Citizen, told NBC News that the subpoenas appear to seek private information from some of OpenAI’s loudest critics to “chill speech and deter them from speaking out.” The overly broad requests seem overtly shady, Weissman said, like “the kind of tactic you would expect from the most cutthroat for-profit corporation.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“This behavior is highly unusual,” Weissman said. “It’s 100 percent intended to intimidate.”&lt;/p&gt;
&lt;h2&gt;OpenAI faces criticism on subpoenas from within&lt;/h2&gt;
&lt;p&gt;Some current and former OpenAI employees were bothered enough to speak out about the subpoenas, including Joshua Achiam, OpenAI’s head of mission alignment. “This doesn’t seem great,” he wrote, sharing “thoughts” with the public and noting “all views are my own.”&lt;/p&gt;
&lt;p&gt;“Elon is certainly out to get us, and the man has got an extensive reach,” Achiam said. “But there is so much that is public that we can fight him on.”&lt;/p&gt;
&lt;p&gt;While claiming he would not be at OpenAI if the company didn’t have “an extremely sincere commitment to good,” he acknowledged that “we can’t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.”&lt;/p&gt;
&lt;p&gt;To Achiam, the main takeaway of the controversy—which he ranks below OpenAI’s prior scandal silencing employees with a non-disparagement clause—is that OpenAI’s public trust depends on the company receiving pushback from employees like him on any “dangerously incorrect use of power.”&lt;/p&gt;
&lt;p&gt;“Without someone speaking up once in a while it can get worse. So, this is my pushback,” Achiam wrote, closing a thread where the initial post got about 570,000 views but later posts only attracted around 30,000.&lt;/p&gt;
&lt;p&gt;“The clear lesson from that was: if we want to be a trusted power in the world, we have to earn that trust, and we can burn it all up if we ever even &lt;em&gt;seem&lt;/em&gt; to put the little guy in our crosshairs,” Achiam wrote.&lt;/p&gt;
&lt;p&gt;Meanwhile, Musk seized the moment to fan the flames of social media criticism, reposting an X post from Helen Toner, a former member of OpenAI’s board, who criticized OpenAI’s “dishonesty and intimidation” tactics in sending the subpoenas.&lt;/p&gt;
&lt;p&gt;“OpenAI was built on a lie,” Musk wrote in a post garnering almost 30 million views.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Cutthroat” OpenAI accused of exploiting Musk fight to intimidate and silence critics.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2198388525-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2198388525-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Over the past week, OpenAI has faced backlash over subpoenas it sent to nonprofits accused of conspiring with Elon Musk to amplify public criticism of OpenAI as it sought to shift from a nonprofit to for-profit structure.&lt;/p&gt;
&lt;p&gt;The subpoenas are supposed to support OpenAI’s defense in a lawsuit Musk’s X Corp filed to block the for-profit transition. Seeking a “wide variety of documents”—including a sweeping request for all communications regarding Musk and all information on nonprofits’ funders and donations—OpenAI claimed that the subpoenas are intended to probe if Musk was involved in the actions or paid nonprofits to make critical comments, NBC News wrote in a report exhaustively documenting the controversy.&lt;/p&gt;
&lt;p&gt;But nonprofits have alleged it’s obvious that OpenAI is using the lawsuit to harass, silence, and intimidate its critics—most glaringly when it comes to targeting nonprofits that are even more publicly critical of Musk’s companies than they are of OpenAI.&lt;/p&gt;
&lt;p&gt;Emma Ruby-Sachs, executive director for Ekō—a nonprofit that serves as a global consumer watchdog holding the “biggest companies in the world accountable”—told NBC News that “the logical basis” for sending the subpoena “is so ridiculous that we have to assume this is just a tactic to scare us and get us to back off.”&lt;/p&gt;
&lt;p&gt;Ruby-Sachs noted that Ekō called for Musk to be fired as the head of DOGE earlier this year. Running a billboard in Times Square that showed a grinning Musk donning a crown, Ekō urged passersby to contact Congress if they “don’t want a king.”&lt;/p&gt;
&lt;p&gt;Further, Ekō had corresponded with OpenAI prior to receiving the subpoena, confirming that “we’re over 70 percent funded by small online donations from individuals, and we’ve run multiple campaigns against Elon Musk in the last year,” Ruby-Sachs said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“We are not in any way supported by or funded by Elon Musk and have a history of campaigning against him and his interests,” Ruby-Sachs told NBC News.&lt;/p&gt;
&lt;p&gt;Another nonprofit watchdog targeted by OpenAI was The Midas Project, which strives to make sure AI benefits everyone. Notably, Musk’s lawsuit accused OpenAI of abandoning its mission to benefit humanity in pursuit of immense profits.&lt;/p&gt;
&lt;p&gt;But the founder of The Midas Project, Tyler Johnston, was shocked to see his group portrayed as coordinating with Musk. He posted on X to clarify that Musk had nothing to do with the group’s “OpenAI Files,” which comprehensively document areas of concern with any plan to shift away from nonprofit governance.&lt;/p&gt;
&lt;p&gt;His post came after OpenAI’s chief strategy officer, Jason Kwon, wrote that “several organizations, some of them suddenly newly formed like the Midas Project, joined in and ran campaigns” backing Musk’s “opposition to OpenAI’s restructure.”&lt;/p&gt;
&lt;p&gt;“What are you talking about?” Johnston wrote. “We were formed 19 months ago. We’ve never spoken with or taken funding from Musk and [his] ilk, which we would have been happy to tell you if you asked a single time. In fact, we’ve said he runs xAI so horridly it makes OpenAI ‘saintly in comparison.'”&lt;/p&gt;
&lt;h2&gt;OpenAI acting like a “cutthroat” corporation?&lt;/h2&gt;
&lt;p&gt;Johnston complained that OpenAI’s subpoena had already hurt the Midas Project, as insurers had denied coverage based on news coverage. He accused OpenAI of not just trying to silence critics but possibly shut them down.&lt;/p&gt;
&lt;p&gt;“If you wanted to constrain an org’s speech, intimidation would be one strategy, but making them uninsurable is another, and maybe that’s what’s happened to us with this subpoena,” Johnston suggested.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Other nonprofits, like the San Francisco Foundation (SFF) and Encode, accused OpenAI of using subpoenas to potentially block or slow down legal interventions. Judith Bell, SFF’s chief impact officer, told NBC News that her nonprofit’s subpoena came after spearheading a petition to California’s attorney general to block OpenAI’s restructuring. And Encode’s general counsel, Nathan Calvin, was subpoenaed after sponsoring a California safety regulation meant to make it easier to monitor risks of frontier AI.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Unlike many of the targeted groups, Encode filed an amicus brief supporting Musk in the OpenAI lawsuit, with Calvin arguing that “OpenAI was founded as a nonprofit in order to protect” their commitment to building AI that benefits the public, “and the public interest requires they keep their word.”&lt;/p&gt;
&lt;p&gt;On X, Kwon said Encode had inserted itself in the lawsuit by filing the brief, claiming, “We issued a subpoena to ensure transparency around their involvement and funding. This is a routine step in litigation.”&lt;/p&gt;
&lt;p&gt;But Calvin alleged that OpenAI’s subpoena has little to do with the brief and more to do with Encode’s advocacy, NBC News reported.&lt;/p&gt;
&lt;p&gt;“I believe OpenAI used the pretext of their lawsuit against Elon Musk to intimidate their critics and imply that Elon is behind all of them,” Calvin said.&lt;/p&gt;
&lt;p&gt;While nonprofits raged over OpenAI’s alleged intimidation tactics, litigator Ray Seilie told NBC News that OpenAI’s request to subpoena Calvin could have been even more demanding.&lt;/p&gt;
&lt;p&gt;“If OpenAI had wanted to intimidate or harass him, they could have served him with a deposition subpoena, which would have required Calvin to sit down for a full day of questioning under oath by OpenAI’s lawyers in addition to providing documents,” Seilie said. “The fact that OpenAI only asked for documents suggests that they were sincerely looking for connections between Musk and Encode, even if they turned out to be wrong about their suspicion.”&lt;/p&gt;
&lt;p&gt;But Robert Weissman, co-president of a consumer advocacy group not yet targeted by OpenAI, Public Citizen, told NBC News that the subpoenas appear to seek private information from some of OpenAI’s loudest critics to “chill speech and deter them from speaking out.” The overly broad requests seem overtly shady, Weissman said, like “the kind of tactic you would expect from the most cutthroat for-profit corporation.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“This behavior is highly unusual,” Weissman said. “It’s 100 percent intended to intimidate.”&lt;/p&gt;
&lt;h2&gt;OpenAI faces criticism on subpoenas from within&lt;/h2&gt;
&lt;p&gt;Some current and former OpenAI employees were bothered enough to speak out about the subpoenas, including Joshua Achiam, OpenAI’s head of mission alignment. “This doesn’t seem great,” he wrote, sharing “thoughts” with the public and noting “all views are my own.”&lt;/p&gt;
&lt;p&gt;“Elon is certainly out to get us, and the man has got an extensive reach,” Achiam said. “But there is so much that is public that we can fight him on.”&lt;/p&gt;
&lt;p&gt;While claiming he would not be at OpenAI if the company didn’t have “an extremely sincere commitment to good,” he acknowledged that “we can’t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.”&lt;/p&gt;
&lt;p&gt;To Achiam, the main takeaway of the controversy—which he ranks below OpenAI’s prior scandal silencing employees with a non-disparagement clause—is that OpenAI’s public trust depends on the company receiving pushback from employees like him on any “dangerously incorrect use of power.”&lt;/p&gt;
&lt;p&gt;“Without someone speaking up once in a while it can get worse. So, this is my pushback,” Achiam wrote, closing a thread where the initial post got about 570,000 views but later posts only attracted around 30,000.&lt;/p&gt;
&lt;p&gt;“The clear lesson from that was: if we want to be a trusted power in the world, we have to earn that trust, and we can burn it all up if we ever even &lt;em&gt;seem&lt;/em&gt; to put the little guy in our crosshairs,” Achiam wrote.&lt;/p&gt;
&lt;p&gt;Meanwhile, Musk seized the moment to fan the flames of social media criticism, reposting an X post from Helen Toner, a former member of OpenAI’s board, who criticized OpenAI’s “dishonesty and intimidation” tactics in sending the subpoenas.&lt;/p&gt;
&lt;p&gt;“OpenAI was built on a lie,” Musk wrote in a post garnering almost 30 million views.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/openai-thinks-elon-musk-funded-its-biggest-critics-who-also-hate-musk/</guid><pubDate>Thu, 16 Oct 2025 16:32:36 +0000</pubDate></item><item><title>Using AI to identify genetic variants in tumors with DeepSomatic (The latest research from Google)</title><link>https://research.google/blog/using-ai-to-identify-genetic-variants-in-tumors-with-deepsomatic/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Testing DeepSomatic’s ability to spot cancer-related variants&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We trained DeepSomatic on three of the breast cancer genomes and the two lung cancer genomes in the CASTLE reference dataset. We then tested DeepSomatic’s performance in several ways, including on the single breast cancer genome that was not included in its training data, and on chromosome 1 from each sample, which we also excluded from the training.&lt;/p&gt;&lt;p&gt;Results show that DeepSomatic models developed for each of the three major sequencing platforms performed better than other methods, identifying more tumor variants with higher accuracy. The tools used for comparison on short-read sequencing data were SomaticSniper, MuTect2 and Strelka2 (with SomaticSniper specifically for single nucleotide variants, or SNVs). For long-read sequencing data we compared against ClairS, a deep learning model trained on synthetic data.&lt;/p&gt;&lt;p&gt;In our tests DeepSomatic identified 329,011 somatic variants across the six reference cell lines and a seventh preserved sample. DeepSomatic does particularly well at identifying cancer variations that involve insertions and deletions (“Indels”) of genetic code. For these types of variants, DeepSomatic substantially increased the F1-score, a balanced measure of how well the model finds true variants in a sample (recall) while not making false positives (precision). On Illumina sequencing data the next-best method scored 80% at identifying Indels, while DeepSomatic scored 90%. On Pacific Biosciences sequencing data, the next-best method scored less than 50% at identifying Indels, and DeepSomatic scored more than 80%.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Testing DeepSomatic’s ability to spot cancer-related variants&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We trained DeepSomatic on three of the breast cancer genomes and the two lung cancer genomes in the CASTLE reference dataset. We then tested DeepSomatic’s performance in several ways, including on the single breast cancer genome that was not included in its training data, and on chromosome 1 from each sample, which we also excluded from the training.&lt;/p&gt;&lt;p&gt;Results show that DeepSomatic models developed for each of the three major sequencing platforms performed better than other methods, identifying more tumor variants with higher accuracy. The tools used for comparison on short-read sequencing data were SomaticSniper, MuTect2 and Strelka2 (with SomaticSniper specifically for single nucleotide variants, or SNVs). For long-read sequencing data we compared against ClairS, a deep learning model trained on synthetic data.&lt;/p&gt;&lt;p&gt;In our tests DeepSomatic identified 329,011 somatic variants across the six reference cell lines and a seventh preserved sample. DeepSomatic does particularly well at identifying cancer variations that involve insertions and deletions (“Indels”) of genetic code. For these types of variants, DeepSomatic substantially increased the F1-score, a balanced measure of how well the model finds true variants in a sample (recall) while not making false positives (precision). On Illumina sequencing data the next-best method scored 80% at identifying Indels, while DeepSomatic scored 90%. On Pacific Biosciences sequencing data, the next-best method scored less than 50% at identifying Indels, and DeepSomatic scored more than 80%.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/using-ai-to-identify-genetic-variants-in-tumors-with-deepsomatic/</guid><pubDate>Thu, 16 Oct 2025 16:33:00 +0000</pubDate></item><item><title>Open source GZDoom community splinters after creator inserts AI-generated code (AI – Ars Technica)</title><link>https://arstechnica.com/gaming/2025/10/civil-war-gzdoom-fan-developers-split-off-over-use-of-chatgpt-generated-code/</link><description>&lt;article class="double-column h-entry post-2122794 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-gaming tag-civil-war tag-developers tag-disagreement tag-doom tag-gzdoom tag-id-software tag-open-source"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        &lt;em&gt;UZDoom&lt;/em&gt; fork promises to fix other top-down leadership problems with the decades-old mod.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="400" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/gzdoom-640x400.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/gzdoom-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of &lt;em&gt;GZDoom&lt;/em&gt; developers going off to create their own fork of the game.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Prodigal's GZDOoom WADs

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;If you’ve even idly checked in on the robust world of &lt;em&gt;Doom&lt;/em&gt; fan development in recent years, you’ve probably encountered one of the hundreds of gameplay mods, WAD files, or entire commercial games based on &lt;em&gt;GZDoom&lt;/em&gt;. The open source &lt;em&gt;Doom&lt;/em&gt; port—which can trace its lineage back to the original launch of &lt;em&gt;ZDoom&lt;/em&gt; back in 1998—adds modern graphics rendering, quality-of-life additions, and incredibly deep modding features to the original &lt;em&gt;Doom&lt;/em&gt; source code that John Carmack released in 1997.&lt;/p&gt;
&lt;p&gt;Now, though, the community behind &lt;em&gt;GZDoom&lt;/em&gt; is publicly fracturing, with a large contingent of developers uniting behind a new fork called UZDoom. The move is in apparent protest of the leadership of &lt;em&gt;GZDoom&lt;/em&gt; creator and maintainer Cristoph Oelckers (aka Graf Zahl), who recently admitted to inserting untested AI-generated code into the &lt;em&gt;GZDoom&lt;/em&gt; codebase.&lt;/p&gt;
&lt;p&gt;“Due to some disagreements—some recent; some tolerated for close to 2 decades—with how collaboration should work, we’ve decided that the best course of action was to fork the project,” developer Nash Muhandes wrote on the DoomWorld forums Wednesday. “I don’t want to see the &lt;em&gt;GZDoom&lt;/em&gt; legacy die, as do most all of us, hence why I think the best thing to do is to continue development through a fork, while introducing a different development model that highly favors transparent collaboration between multiple people.”&lt;/p&gt;
&lt;h2&gt;AI-way or the highway&lt;/h2&gt;
&lt;p&gt;Zahl’s project leadership has generated plenty of friction within the &lt;em&gt;GZDoom&lt;/em&gt; development community over the years—this Reddit thread provides a brief history of some of the drama. But the inciting incident leading to this week’s &lt;em&gt;UZDoom&lt;/em&gt; split seems to center in large part on Zahl’s open use of AI-generated code in a recent &lt;em&gt;GZDoom&lt;/em&gt; update. While such use of AI coding tools is often hard to identify from the outside (as Zahl himself noted in a GitHub post), this particular instance was highlighted by Zahl’s own commented code snippet: “This is what ChatGPT told me for detecting dark mode on Linux.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That comment led to a lengthy discussion among developers about the use of “stolen scraped code that we have no way of verifying is compatible with the GPL,” as one described it. And while Zahl eventually removed the offending code, he also allegedly tried to remove the evidence that it ever existed by force-pushing an update to delete the discussion entirely.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;// This is what ChatGPT told me for detecting dark mode on&amp;nbsp;Linux.&lt;/div&gt;&lt;div class="pullquote-attribution"&gt;&lt;span&gt;Graf Zahl code comment&lt;/span&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Zahl defended the use of AI-generated snippets for “boilerplate code” that isn’t key to underlying game features. “I surely have my reservations about using AI for project specific code,” he wrote, “but this here is just superficial checks of system configuration settings that can be found on various websites—just with 10x the effort required.”&lt;/p&gt;
&lt;p&gt;But others in the community were adamant that there’s no place for AI tools in the workflow of an open source project like this. “If using code slop generated from ChatGPT or any other GenAI/AI chatbots is the future of this project, I’m sorry to say but I’m out,” GitHub user Cacodemon345 wrote, summarizing the feelings of many other developers.&lt;/p&gt;
&lt;h2&gt;A fork in the road&lt;/h2&gt;
&lt;p&gt;In a GitHub bug report posted Tuesday, user the-phinet laid out the disagreements over AI-generated code alongside other alleged issues with Zahl’s top-down approach to pushing out &lt;em&gt;GZDoom&lt;/em&gt; updates. In response, Zahl invited the development community to “feel free to fork the project” if they were so displeased.&lt;/p&gt;
&lt;p&gt;Plenty of &lt;em&gt;GZDoom&lt;/em&gt; developers quickly took that somewhat petulant response seriously. “You have just completely bricked &lt;em&gt;GZDoom&lt;/em&gt; with this bullshit,” developer Boondorl wrote. “Enjoy your dead project, I’m sure you’ll be happy to plink away at it all by yourself where people can finally stop yelling at you to do things.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2122803 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="540" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/selaco.jpg" width="960" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Entire commercial games like &lt;em&gt;Selaco&lt;/em&gt; are based on &lt;em&gt;GZDoom&lt;/em&gt;‘s open source engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Altered Orbit Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In a community update posted to the &lt;em&gt;ZDoom&lt;/em&gt; Discord, moderator Agent_Ash promised that the new &lt;em&gt;UZDoom&lt;/em&gt; will maintain compatibility with old &lt;em&gt;GZDoom&lt;/em&gt; saves and mods while adding new planned features in the future. But the new project will also provide “a more stable development structure with healthy collaboration and less power given to individual ‘project leads,'” Agent_Ash wrote.&lt;/p&gt;
&lt;p&gt;In a Reddit thread discussing the UZDoom fork, Muhandes detailed how “&lt;em&gt;UZDoom&lt;/em&gt; gets rid of the ‘one man decides everything’ / ‘my way or the highway’ development model. Everyone has to make pull requests that must be peer-reviewed thoroughly, and everything will be transparent—no one is allowed to commit directly to the master branch.”&lt;/p&gt;
&lt;p&gt;“I have never seen something I’ve worked so hard on, for the past 2+ decades—a life passion of mine, you could say—implode this hard,” Muhandes added on Bluesky.&lt;/p&gt;
&lt;p&gt;While &lt;em&gt;GZDoom&lt;/em&gt; will continue to exist, Agent_Ash wrote that “it’s reasonable to assume that &lt;em&gt;UZDoom&lt;/em&gt; will be the ‘main’ flagship version of the engine moving forward.” And while Zahl will be welcome to continue contributing to the new project, “&lt;em&gt;UZDoom&lt;/em&gt; will not be led by him and he’s not going to have a final say on new features and changes,” Agent_Ash added.&lt;/p&gt;
&lt;p&gt;The infighting over a modern source port of a 32-year-old game speaks highly of the deep cultural impact &lt;em&gt;Doom&lt;/em&gt; continues to have on multiple generations of fans. Going forward, it’s hard to say how this dramatic split will affect the continued development of what has become a load-bearing part of the game’s continued legacy. For now, though, the move highlights how the use of AI coding tools has become a non-negotiable flashpoint for many in the world of open-source game development.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ccff90; background-color: #33691e;"&gt;&lt;img alt="graylshaped" class="ars-avatar-image" src="https://cdn.arstechnica.net/civis/data/avatars/m/142/142039.jpg?1668039638" /&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              graylshaped
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I am under the impression that a primary benefit of the open source community is the transparency of its output, with an important side benefit being the engagement and involvement of those in the community on whose effort the project depends.&lt;p&gt;Tossing "AI" generated code in the mix seems rather to piss on those benefits.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-16T17:04:50+00:00"&gt;October 16, 2025 at 5:04 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2122794 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-gaming tag-civil-war tag-developers tag-disagreement tag-doom tag-gzdoom tag-id-software tag-open-source"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        &lt;em&gt;UZDoom&lt;/em&gt; fork promises to fix other top-down leadership problems with the decades-old mod.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="400" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/gzdoom-640x400.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/gzdoom-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of &lt;em&gt;GZDoom&lt;/em&gt; developers going off to create their own fork of the game.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Prodigal's GZDOoom WADs

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;If you’ve even idly checked in on the robust world of &lt;em&gt;Doom&lt;/em&gt; fan development in recent years, you’ve probably encountered one of the hundreds of gameplay mods, WAD files, or entire commercial games based on &lt;em&gt;GZDoom&lt;/em&gt;. The open source &lt;em&gt;Doom&lt;/em&gt; port—which can trace its lineage back to the original launch of &lt;em&gt;ZDoom&lt;/em&gt; back in 1998—adds modern graphics rendering, quality-of-life additions, and incredibly deep modding features to the original &lt;em&gt;Doom&lt;/em&gt; source code that John Carmack released in 1997.&lt;/p&gt;
&lt;p&gt;Now, though, the community behind &lt;em&gt;GZDoom&lt;/em&gt; is publicly fracturing, with a large contingent of developers uniting behind a new fork called UZDoom. The move is in apparent protest of the leadership of &lt;em&gt;GZDoom&lt;/em&gt; creator and maintainer Cristoph Oelckers (aka Graf Zahl), who recently admitted to inserting untested AI-generated code into the &lt;em&gt;GZDoom&lt;/em&gt; codebase.&lt;/p&gt;
&lt;p&gt;“Due to some disagreements—some recent; some tolerated for close to 2 decades—with how collaboration should work, we’ve decided that the best course of action was to fork the project,” developer Nash Muhandes wrote on the DoomWorld forums Wednesday. “I don’t want to see the &lt;em&gt;GZDoom&lt;/em&gt; legacy die, as do most all of us, hence why I think the best thing to do is to continue development through a fork, while introducing a different development model that highly favors transparent collaboration between multiple people.”&lt;/p&gt;
&lt;h2&gt;AI-way or the highway&lt;/h2&gt;
&lt;p&gt;Zahl’s project leadership has generated plenty of friction within the &lt;em&gt;GZDoom&lt;/em&gt; development community over the years—this Reddit thread provides a brief history of some of the drama. But the inciting incident leading to this week’s &lt;em&gt;UZDoom&lt;/em&gt; split seems to center in large part on Zahl’s open use of AI-generated code in a recent &lt;em&gt;GZDoom&lt;/em&gt; update. While such use of AI coding tools is often hard to identify from the outside (as Zahl himself noted in a GitHub post), this particular instance was highlighted by Zahl’s own commented code snippet: “This is what ChatGPT told me for detecting dark mode on Linux.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That comment led to a lengthy discussion among developers about the use of “stolen scraped code that we have no way of verifying is compatible with the GPL,” as one described it. And while Zahl eventually removed the offending code, he also allegedly tried to remove the evidence that it ever existed by force-pushing an update to delete the discussion entirely.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;// This is what ChatGPT told me for detecting dark mode on&amp;nbsp;Linux.&lt;/div&gt;&lt;div class="pullquote-attribution"&gt;&lt;span&gt;Graf Zahl code comment&lt;/span&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Zahl defended the use of AI-generated snippets for “boilerplate code” that isn’t key to underlying game features. “I surely have my reservations about using AI for project specific code,” he wrote, “but this here is just superficial checks of system configuration settings that can be found on various websites—just with 10x the effort required.”&lt;/p&gt;
&lt;p&gt;But others in the community were adamant that there’s no place for AI tools in the workflow of an open source project like this. “If using code slop generated from ChatGPT or any other GenAI/AI chatbots is the future of this project, I’m sorry to say but I’m out,” GitHub user Cacodemon345 wrote, summarizing the feelings of many other developers.&lt;/p&gt;
&lt;h2&gt;A fork in the road&lt;/h2&gt;
&lt;p&gt;In a GitHub bug report posted Tuesday, user the-phinet laid out the disagreements over AI-generated code alongside other alleged issues with Zahl’s top-down approach to pushing out &lt;em&gt;GZDoom&lt;/em&gt; updates. In response, Zahl invited the development community to “feel free to fork the project” if they were so displeased.&lt;/p&gt;
&lt;p&gt;Plenty of &lt;em&gt;GZDoom&lt;/em&gt; developers quickly took that somewhat petulant response seriously. “You have just completely bricked &lt;em&gt;GZDoom&lt;/em&gt; with this bullshit,” developer Boondorl wrote. “Enjoy your dead project, I’m sure you’ll be happy to plink away at it all by yourself where people can finally stop yelling at you to do things.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2122803 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="540" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/selaco.jpg" width="960" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Entire commercial games like &lt;em&gt;Selaco&lt;/em&gt; are based on &lt;em&gt;GZDoom&lt;/em&gt;‘s open source engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Altered Orbit Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In a community update posted to the &lt;em&gt;ZDoom&lt;/em&gt; Discord, moderator Agent_Ash promised that the new &lt;em&gt;UZDoom&lt;/em&gt; will maintain compatibility with old &lt;em&gt;GZDoom&lt;/em&gt; saves and mods while adding new planned features in the future. But the new project will also provide “a more stable development structure with healthy collaboration and less power given to individual ‘project leads,'” Agent_Ash wrote.&lt;/p&gt;
&lt;p&gt;In a Reddit thread discussing the UZDoom fork, Muhandes detailed how “&lt;em&gt;UZDoom&lt;/em&gt; gets rid of the ‘one man decides everything’ / ‘my way or the highway’ development model. Everyone has to make pull requests that must be peer-reviewed thoroughly, and everything will be transparent—no one is allowed to commit directly to the master branch.”&lt;/p&gt;
&lt;p&gt;“I have never seen something I’ve worked so hard on, for the past 2+ decades—a life passion of mine, you could say—implode this hard,” Muhandes added on Bluesky.&lt;/p&gt;
&lt;p&gt;While &lt;em&gt;GZDoom&lt;/em&gt; will continue to exist, Agent_Ash wrote that “it’s reasonable to assume that &lt;em&gt;UZDoom&lt;/em&gt; will be the ‘main’ flagship version of the engine moving forward.” And while Zahl will be welcome to continue contributing to the new project, “&lt;em&gt;UZDoom&lt;/em&gt; will not be led by him and he’s not going to have a final say on new features and changes,” Agent_Ash added.&lt;/p&gt;
&lt;p&gt;The infighting over a modern source port of a 32-year-old game speaks highly of the deep cultural impact &lt;em&gt;Doom&lt;/em&gt; continues to have on multiple generations of fans. Going forward, it’s hard to say how this dramatic split will affect the continued development of what has become a load-bearing part of the game’s continued legacy. For now, though, the move highlights how the use of AI coding tools has become a non-negotiable flashpoint for many in the world of open-source game development.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ccff90; background-color: #33691e;"&gt;&lt;img alt="graylshaped" class="ars-avatar-image" src="https://cdn.arstechnica.net/civis/data/avatars/m/142/142039.jpg?1668039638" /&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              graylshaped
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I am under the impression that a primary benefit of the open source community is the transparency of its output, with an important side benefit being the engagement and involvement of those in the community on whose effort the project depends.&lt;p&gt;Tossing "AI" generated code in the mix seems rather to piss on those benefits.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-16T17:04:50+00:00"&gt;October 16, 2025 at 5:04 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gaming/2025/10/civil-war-gzdoom-fan-developers-split-off-over-use-of-chatgpt-generated-code/</guid><pubDate>Thu, 16 Oct 2025 16:48:00 +0000</pubDate></item><item><title>The real reason Google DeepMind is working with a fusion energy startup (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/the-real-reason-google-deepmind-is-working-with-a-fusion-energy-startup/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2184776204.jpeg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Energy startup Commonwealth Fusion Systems (CFS) said Thursday it’s working with Google’s DeepMind division to fine tune — and even improve — the operation of its forthcoming Sparc reactor using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies’ plan will simulate the plasma that will burn inside CFS’s reactor using specialized DeepMind software known as Torax. They also plan on pairing Torax with AI models to help CFS figure out how best to achieve fusion power.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fusion power promises to deliver massive amounts of electricity with zero emissions from a near limitless source of fuel: water. AI-related companies have been bullish on fusion startups as a source of electricity to power energy-hungry data centers. Google appears to be eyeing them as potential customer as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t Google’s first foray into nuclear fusion. The tech company has worked with another fusion startup, TAE Technologies, to use AI to study how plasma behaves inside TAE’s fusion machine.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a reason Google keeps coming back to the problem: AI might be uniquely suited to making fusion power possible.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest challenges facing fusion startups is keeping the plasma inside a reactor hot enough for long enough. Unlike nuclear fission reactions, which are self-sustaining, fusion reactions are difficult to maintain outside of stars like the sun. Without that sort of mass and gravity, the plasma is constantly in danger of diffusing and snuffing itself out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In CFS’s reactors, powerful magnets substitute for gravity to help corral the plasma, but they’re not perfect. Reactor operators have to develop control software that can enable the device to continuously react to changing plasma conditions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Problem is, there are almost too many knobs to turn, certainly more than a human is capable of. That’s the sort of problem that AI excels at. Experts have cited AI as one of the key technologies that has enabled the industry’s remarkable advances over the past several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CFS is currently building Sparc, its demonstration reactor, in a suburb outside Boston. The device is about two-thirds completed, and when finished later in 2026, the startup is predicting that it will be the first fusion device capable of producing more power than the plant needs to run itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said Torax can be used with reinforcement learning or evolutionary search models to find the “most efficient and robust paths to generating net energy.” The two companies are also exploring whether AI can be used to control the reactor’s operation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In August, Google participated in CFS’s $863 million Series B2 round alongside Nvidia. Earlier this year, Google also said it would buy 200 megawatts of electricity from CFS’s first commercial power plant, Arc, which is planned to be built outside Richmond, Virginia. The tech company is also an investor in CFS competitor TAE Technologies.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2184776204.jpeg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Energy startup Commonwealth Fusion Systems (CFS) said Thursday it’s working with Google’s DeepMind division to fine tune — and even improve — the operation of its forthcoming Sparc reactor using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies’ plan will simulate the plasma that will burn inside CFS’s reactor using specialized DeepMind software known as Torax. They also plan on pairing Torax with AI models to help CFS figure out how best to achieve fusion power.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fusion power promises to deliver massive amounts of electricity with zero emissions from a near limitless source of fuel: water. AI-related companies have been bullish on fusion startups as a source of electricity to power energy-hungry data centers. Google appears to be eyeing them as potential customer as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t Google’s first foray into nuclear fusion. The tech company has worked with another fusion startup, TAE Technologies, to use AI to study how plasma behaves inside TAE’s fusion machine.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a reason Google keeps coming back to the problem: AI might be uniquely suited to making fusion power possible.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest challenges facing fusion startups is keeping the plasma inside a reactor hot enough for long enough. Unlike nuclear fission reactions, which are self-sustaining, fusion reactions are difficult to maintain outside of stars like the sun. Without that sort of mass and gravity, the plasma is constantly in danger of diffusing and snuffing itself out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In CFS’s reactors, powerful magnets substitute for gravity to help corral the plasma, but they’re not perfect. Reactor operators have to develop control software that can enable the device to continuously react to changing plasma conditions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Problem is, there are almost too many knobs to turn, certainly more than a human is capable of. That’s the sort of problem that AI excels at. Experts have cited AI as one of the key technologies that has enabled the industry’s remarkable advances over the past several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CFS is currently building Sparc, its demonstration reactor, in a suburb outside Boston. The device is about two-thirds completed, and when finished later in 2026, the startup is predicting that it will be the first fusion device capable of producing more power than the plant needs to run itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said Torax can be used with reinforcement learning or evolutionary search models to find the “most efficient and robust paths to generating net energy.” The two companies are also exploring whether AI can be used to control the reactor’s operation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In August, Google participated in CFS’s $863 million Series B2 round alongside Nvidia. Earlier this year, Google also said it would buy 200 megawatts of electricity from CFS’s first commercial power plant, Arc, which is planned to be built outside Richmond, Virginia. The tech company is also an investor in CFS competitor TAE Technologies.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/the-real-reason-google-deepmind-is-working-with-a-fusion-energy-startup/</guid><pubDate>Thu, 16 Oct 2025 18:06:08 +0000</pubDate></item><item><title>[NEW] Why AI startups are taking data into their own hands (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/why-ai-startups-are-taking-data-into-their-own-hands/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-1295429677.jpg?resize=1200,840" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For one week this summer, Taylor and her roommate wore GoPro cameras strapped to their foreheads as they painted, sculpted, and did household chores. They were training an AI vision model, carefully syncing their footage so the system could get multiple angles on the same behavior. It was difficult work in many ways, but they were well paid for it — and it allowed Taylor to spend most of her day making art.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We woke up, did our regular routine, and then strapped the cameras on our head and synced the times together,” she told me. “Then we would make our breakfast and clean the dishes. Then we’d go our separate ways and work on art.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;They were hired to produce five hours of synced footage each day, but Taylor quickly learned she needed to allot seven hours a day for the work, to leave enough time for breaks and physical recovery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It would give you headaches,” she said. “You take it off and there’s just a red square on your forehead.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor, who&amp;nbsp;asked not to give her last name, was working as a data freelancer for Turing, an AI company that connected her to TechCrunch. Turing’s goal wasn’t to teach the AI how to make oil paintings, but to gain more abstract skills around sequential problem-solving and visual reasoning. Unlike a large language model, Turing’s vision model would be trained entirely on video — and most of it would be collected directly by Turing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside artists like Taylor, Turing is contracting with chefs, construction workers, and electricians — anyone who works with their hands. Turing Chief AGI Officer Sudarshan Sivaraman told TechCrunch the manual collection is the only way to get a varied enough dataset.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are doing it for so many different kinds of blue-collar work, so that we have a diversity of data in the pre-training phase,” Sivaraman&amp;nbsp;told TechCrunch. “After we capture all this information, the models will be able to understand how a certain task is performed.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Turing’s work on vision models is part of a growing shift in how AI companies deal with data. Where training sets were once scraped freely from the web or collected from low-paid annotators, companies are now paying top dollar for carefully curated data. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the raw power of AI&amp;nbsp;already established, companies are looking to proprietary training data as a competitive advantage. And instead of farming out the task to contractors, they’re often taking on the work themselves.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The email company Fyxer, which uses AI models to sort emails and draft replies, is one example. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After some early experiments, founder Richard Hollingsworth discovered the best approach was to use an array of small models with tightly focused training data. Unlike Turing, Fyxer is building off someone else’s foundation model — but the underlying insight is the same. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We realized that the quality of the data, not the quantity, is the thing that really defines the performance,” Hollingsworth told me.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In practical terms, that meant some unconventional personnel choices. In the early days, Fyxer engineers and managers were sometimes outnumbered four to one by the executive assistants needed to train the model, Hollingsworth says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We used a lot of experienced executive assistants, because we needed to train on the fundamentals of whether an email should be responded to,” he told TechCrunch. “It’s a very people-oriented problem. Finding great people is very hard.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pace of data collection never slowed down, but over time Hollingsworth became more precious about the datasets, preferring smaller sets of more tightly curated datasets when it came time for post-training. As he puts it, “the quality of the data, not the quantity, is the thing that really defines the performance.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s particularly true when synthetic data is used, magnifying both the scope of possible training scenarios and the impact of any flaws in the original dataset. On the vision side, Turing estimates that 75% to 80% of its data is synthetic, extrapolated from the original GoPro videos. But that makes it even more important to keep the original dataset as high-quality as possible.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the pre-training data itself is not of good quality, then whatever you do with synthetic data is also not going to be of good quality,” Sivaraman says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond concerns of quality, there’s a powerful competitive logic behind keeping data collection in-house. For Fyxer, the hard work of data collection is one of the best moats the company has against competition. As Hollingsworth sees it, anyone can build an open source model into their product — but not everyone can find expert annotators to train it into a workable product.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the best way to do it is through data,” he told TechCrunch, “through building custom models, through high-quality, human-led data training.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: A previous version of this piece referred to Turing by an incorrect name. TechCrunch regrets the error.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-1295429677.jpg?resize=1200,840" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For one week this summer, Taylor and her roommate wore GoPro cameras strapped to their foreheads as they painted, sculpted, and did household chores. They were training an AI vision model, carefully syncing their footage so the system could get multiple angles on the same behavior. It was difficult work in many ways, but they were well paid for it — and it allowed Taylor to spend most of her day making art.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We woke up, did our regular routine, and then strapped the cameras on our head and synced the times together,” she told me. “Then we would make our breakfast and clean the dishes. Then we’d go our separate ways and work on art.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;They were hired to produce five hours of synced footage each day, but Taylor quickly learned she needed to allot seven hours a day for the work, to leave enough time for breaks and physical recovery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It would give you headaches,” she said. “You take it off and there’s just a red square on your forehead.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor, who&amp;nbsp;asked not to give her last name, was working as a data freelancer for Turing, an AI company that connected her to TechCrunch. Turing’s goal wasn’t to teach the AI how to make oil paintings, but to gain more abstract skills around sequential problem-solving and visual reasoning. Unlike a large language model, Turing’s vision model would be trained entirely on video — and most of it would be collected directly by Turing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside artists like Taylor, Turing is contracting with chefs, construction workers, and electricians — anyone who works with their hands. Turing Chief AGI Officer Sudarshan Sivaraman told TechCrunch the manual collection is the only way to get a varied enough dataset.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are doing it for so many different kinds of blue-collar work, so that we have a diversity of data in the pre-training phase,” Sivaraman&amp;nbsp;told TechCrunch. “After we capture all this information, the models will be able to understand how a certain task is performed.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Turing’s work on vision models is part of a growing shift in how AI companies deal with data. Where training sets were once scraped freely from the web or collected from low-paid annotators, companies are now paying top dollar for carefully curated data. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the raw power of AI&amp;nbsp;already established, companies are looking to proprietary training data as a competitive advantage. And instead of farming out the task to contractors, they’re often taking on the work themselves.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The email company Fyxer, which uses AI models to sort emails and draft replies, is one example. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After some early experiments, founder Richard Hollingsworth discovered the best approach was to use an array of small models with tightly focused training data. Unlike Turing, Fyxer is building off someone else’s foundation model — but the underlying insight is the same. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We realized that the quality of the data, not the quantity, is the thing that really defines the performance,” Hollingsworth told me.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In practical terms, that meant some unconventional personnel choices. In the early days, Fyxer engineers and managers were sometimes outnumbered four to one by the executive assistants needed to train the model, Hollingsworth says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We used a lot of experienced executive assistants, because we needed to train on the fundamentals of whether an email should be responded to,” he told TechCrunch. “It’s a very people-oriented problem. Finding great people is very hard.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pace of data collection never slowed down, but over time Hollingsworth became more precious about the datasets, preferring smaller sets of more tightly curated datasets when it came time for post-training. As he puts it, “the quality of the data, not the quantity, is the thing that really defines the performance.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s particularly true when synthetic data is used, magnifying both the scope of possible training scenarios and the impact of any flaws in the original dataset. On the vision side, Turing estimates that 75% to 80% of its data is synthetic, extrapolated from the original GoPro videos. But that makes it even more important to keep the original dataset as high-quality as possible.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the pre-training data itself is not of good quality, then whatever you do with synthetic data is also not going to be of good quality,” Sivaraman says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond concerns of quality, there’s a powerful competitive logic behind keeping data collection in-house. For Fyxer, the hard work of data collection is one of the best moats the company has against competition. As Hollingsworth sees it, anyone can build an open source model into their product — but not everyone can find expert annotators to train it into a workable product.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the best way to do it is through data,” he told TechCrunch, “through building custom models, through high-quality, human-led data training.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: A previous version of this piece referred to Turing by an incorrect name. TechCrunch regrets the error.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/why-ai-startups-are-taking-data-into-their-own-hands/</guid><pubDate>Thu, 16 Oct 2025 19:08:00 +0000</pubDate></item><item><title>[NEW] Kayak launches an ‘AI Mode’ for travel questions, search, and bookings (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/16/kayak-launches-an-ai-mode-for-travel-questions-search-and-bookings/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Travel search engine Kayak will now allow users to research trips ahead of booking using AI. The company this week launched an “AI Mode” feature that lets users ask travel-related questions as well as compare and book flights, hotels, and cars, through an AI chatbot integrated on the company’s website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is currently available across both desktop and mobile web, and takes advantage of Kayak’s integration with ChatGPT to deliver contextual results. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout follows the company’s April launch of Kayak.ai, built as a testing ground for working with AI technology. That site also combined Kayak’s data and tools with OpenAI’s technology, letting its tech team try out AI features ahead of bringing them over to Kayak.com&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Essentially, the AI Mode feature offers the same functionality as the Kayak.ai website but is now built directly into Kayak’s website. The company suggests users could ask the chatbot for travel ideas, like locations to fly to for under a certain price point, the best deals to a preferred destination, comparing hotel amenities, finding nonstop flights and rental car options, and more.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a screenshot showing the Kayak &amp;quot;AI mode&amp;quot; on its website, shown on an iPhone." class="wp-image-3058392" height="4096" src="https://techcrunch.com/wp-content/uploads/2025/10/Mweb_cursor.jpg" width="2334" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kayak&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, users can ask the AI more open-ended questions, like “I want to party for NYE — where should I go?” to get recommendations without having specific destinations in mind. Or they could learn when the best time to fly somewhere would be, based on ticket prices. (Kayak has shared other AI prompt ideas on its own blog.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature could be useful in helping consumers in the earlier stages of travel planning, when they’re just exploring ideas. However, it remains to be seen if AI users readily convert to paying customers using these methods. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI Mode is initially available in English in the United States but will expand to other countries and languages later in the month. The company also plans to roll out the feature to more platforms and add support for voice-based requests “soon.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="another screenshot of the AI Mode on the Kayak.com website." class="wp-image-3058395" height="4265" src="https://techcrunch.com/wp-content/uploads/2025/10/Mweb_iPhone-14-Pro-1.jpg" width="2430" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kayak&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Travel is an area that’s being explored by AI providers and travel companies alike, as online booking can be a frustrating and tedious experience for consumers as it stands today. To test consumer demand for AI solutions, OpenAI recently announced deals with travel companies like Expedia and Booking.com (the latter is also owned by Kayak’s parent company, Booking Holdings). As a result, those services can now operate as apps inside ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By comparison, Kayak’s decision to run the AI chatbot on its own site could provide the company with more direct access to consumer insights about the AI’s use.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Travel search engine Kayak will now allow users to research trips ahead of booking using AI. The company this week launched an “AI Mode” feature that lets users ask travel-related questions as well as compare and book flights, hotels, and cars, through an AI chatbot integrated on the company’s website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is currently available across both desktop and mobile web, and takes advantage of Kayak’s integration with ChatGPT to deliver contextual results. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout follows the company’s April launch of Kayak.ai, built as a testing ground for working with AI technology. That site also combined Kayak’s data and tools with OpenAI’s technology, letting its tech team try out AI features ahead of bringing them over to Kayak.com&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Essentially, the AI Mode feature offers the same functionality as the Kayak.ai website but is now built directly into Kayak’s website. The company suggests users could ask the chatbot for travel ideas, like locations to fly to for under a certain price point, the best deals to a preferred destination, comparing hotel amenities, finding nonstop flights and rental car options, and more.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a screenshot showing the Kayak &amp;quot;AI mode&amp;quot; on its website, shown on an iPhone." class="wp-image-3058392" height="4096" src="https://techcrunch.com/wp-content/uploads/2025/10/Mweb_cursor.jpg" width="2334" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kayak&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, users can ask the AI more open-ended questions, like “I want to party for NYE — where should I go?” to get recommendations without having specific destinations in mind. Or they could learn when the best time to fly somewhere would be, based on ticket prices. (Kayak has shared other AI prompt ideas on its own blog.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature could be useful in helping consumers in the earlier stages of travel planning, when they’re just exploring ideas. However, it remains to be seen if AI users readily convert to paying customers using these methods. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI Mode is initially available in English in the United States but will expand to other countries and languages later in the month. The company also plans to roll out the feature to more platforms and add support for voice-based requests “soon.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="another screenshot of the AI Mode on the Kayak.com website." class="wp-image-3058395" height="4265" src="https://techcrunch.com/wp-content/uploads/2025/10/Mweb_iPhone-14-Pro-1.jpg" width="2430" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kayak&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Travel is an area that’s being explored by AI providers and travel companies alike, as online booking can be a frustrating and tedious experience for consumers as it stands today. To test consumer demand for AI solutions, OpenAI recently announced deals with travel companies like Expedia and Booking.com (the latter is also owned by Kayak’s parent company, Booking Holdings). As a result, those services can now operate as apps inside ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By comparison, Kayak’s decision to run the AI chatbot on its own site could provide the company with more direct access to consumer insights about the AI’s use.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/16/kayak-launches-an-ai-mode-for-travel-questions-search-and-bookings/</guid><pubDate>Thu, 16 Oct 2025 19:23:07 +0000</pubDate></item><item><title>[NEW] OnePlus unveils OxygenOS 16 update with deep Gemini integration (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/10/oneplus-unveils-oxygenos-16-update-with-deep-gemini-integration/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Does your phone even have a Mind Space?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="OnePlus Mind Space" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/OP-mind-space-640x360.jpg" width="640" /&gt;
                  &lt;img alt="OnePlus Mind Space" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/OP-mind-space-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OnePlus

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;OnePlus is expected to take the wraps off the OnePlus 15 in the next few weeks, but before that, it’s giving us a look at the software that will run on it. OxygenOS 16, which is based on Android 16, will also come to the company’s other supported phones, and it’s going to include a heaping helping of AI features. OnePlus was slower than most smartphone makers to embrace AI, but it’s full-steam ahead now with new Gemini integrations.&lt;/p&gt;
&lt;p&gt;OxygenOS 16 is described by OnePlus in grandiose terms as “a defiant rebellion for authenticity.” In the real world, this update is doing a lot of the same things as other AI-heavy smartphones. It’s not &lt;em&gt;all &lt;/em&gt;AI—OnePlus notes that OxygenOS 16 will include revamped animations that have been carefully designed for smoothness, as well as the O+ remote app that gives you remote access to Windows and Mac PCs. The lock screen is also more customizable, borrowing a page from the likes of Apple and Samsung.&lt;/p&gt;
&lt;p&gt;OnePlus began embracing AI in June, when it launched a feature called Mind Space on the OnePlus 13S. That phone was only for the Indian market, but the rest of the world will get this and more with OxygenOS 16. At launch, Mind Space would collect your screenshots and brief voice messages. Mind Space would analyze the screenshots to create calendar entries and not much else.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The updated Android software expands what you can add to Mind Space and uses Gemini. For starters, you can add scrolling screenshots and voice memos up to 60 seconds in length. This provides more data for the AI to generate content. For example, if you take screenshots of hotel listings and airline flights, you can tell Gemini to use your Mind Space content to create a trip itinerary. This will be fully integrated with the phone and won’t require a separate subscription to Google’s AI tools.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2122848 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="oneplus-oxygen-os16" class="fullwidth full" height="1200" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/oneplus-oxygen-os161-copy.jpg" width="2000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OnePlus

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Mind Space isn’t a totally new idea—it’s quite similar to AI features like Nothing’s Essential Space and Google’s Pixel Screenshots and Journal. The idea is that if you give an AI model enough data on your thoughts and plans, it can provide useful insights. That’s still hypothetical based on what we’ve seen from other smartphone OEMs, but that’s not stopping OnePlus from fully embracing AI in Android 16.&lt;/p&gt;
&lt;p&gt;In addition to beefing up Mind Space, OxygenOS 16 will also add system-wide AI writing tools, which is another common AI add-on. Like the systems from Apple, Google, and Samsung, you will be able to use the OnePlus writing tools to adjust text, proofread, and generate summaries.&lt;/p&gt;
&lt;p&gt;OnePlus will make OxygenOS 16 available starting October 17 as an open beta. You’ll need a OnePlus device from the past three years to run the software, both in the beta phase and when it’s finally released. As for that, OnePlus hasn’t offered a specific date. The initial OxygenOS 16 release will be with the OnePlus 15 devices, with releases for other supported phones and tablets coming later.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Does your phone even have a Mind Space?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="OnePlus Mind Space" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/OP-mind-space-640x360.jpg" width="640" /&gt;
                  &lt;img alt="OnePlus Mind Space" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/OP-mind-space-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OnePlus

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;OnePlus is expected to take the wraps off the OnePlus 15 in the next few weeks, but before that, it’s giving us a look at the software that will run on it. OxygenOS 16, which is based on Android 16, will also come to the company’s other supported phones, and it’s going to include a heaping helping of AI features. OnePlus was slower than most smartphone makers to embrace AI, but it’s full-steam ahead now with new Gemini integrations.&lt;/p&gt;
&lt;p&gt;OxygenOS 16 is described by OnePlus in grandiose terms as “a defiant rebellion for authenticity.” In the real world, this update is doing a lot of the same things as other AI-heavy smartphones. It’s not &lt;em&gt;all &lt;/em&gt;AI—OnePlus notes that OxygenOS 16 will include revamped animations that have been carefully designed for smoothness, as well as the O+ remote app that gives you remote access to Windows and Mac PCs. The lock screen is also more customizable, borrowing a page from the likes of Apple and Samsung.&lt;/p&gt;
&lt;p&gt;OnePlus began embracing AI in June, when it launched a feature called Mind Space on the OnePlus 13S. That phone was only for the Indian market, but the rest of the world will get this and more with OxygenOS 16. At launch, Mind Space would collect your screenshots and brief voice messages. Mind Space would analyze the screenshots to create calendar entries and not much else.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The updated Android software expands what you can add to Mind Space and uses Gemini. For starters, you can add scrolling screenshots and voice memos up to 60 seconds in length. This provides more data for the AI to generate content. For example, if you take screenshots of hotel listings and airline flights, you can tell Gemini to use your Mind Space content to create a trip itinerary. This will be fully integrated with the phone and won’t require a separate subscription to Google’s AI tools.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2122848 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="oneplus-oxygen-os16" class="fullwidth full" height="1200" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/oneplus-oxygen-os161-copy.jpg" width="2000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OnePlus

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Mind Space isn’t a totally new idea—it’s quite similar to AI features like Nothing’s Essential Space and Google’s Pixel Screenshots and Journal. The idea is that if you give an AI model enough data on your thoughts and plans, it can provide useful insights. That’s still hypothetical based on what we’ve seen from other smartphone OEMs, but that’s not stopping OnePlus from fully embracing AI in Android 16.&lt;/p&gt;
&lt;p&gt;In addition to beefing up Mind Space, OxygenOS 16 will also add system-wide AI writing tools, which is another common AI add-on. Like the systems from Apple, Google, and Samsung, you will be able to use the OnePlus writing tools to adjust text, proofread, and generate summaries.&lt;/p&gt;
&lt;p&gt;OnePlus will make OxygenOS 16 available starting October 17 as an open beta. You’ll need a OnePlus device from the past three years to run the software, both in the beta phase and when it’s finally released. As for that, OnePlus hasn’t offered a specific date. The initial OxygenOS 16 release will be with the OnePlus 15 devices, with releases for other supported phones and tablets coming later.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/10/oneplus-unveils-oxygenos-16-update-with-deep-gemini-integration/</guid><pubDate>Thu, 16 Oct 2025 20:05:19 +0000</pubDate></item><item><title>[NEW] Ars Live recap: Is the AI bubble about to pop? Ed Zitron weighs in. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/ars-live-recap-is-the-ai-bubble-about-to-pop-ed-zitron-weighs-in/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Despite connection hiccups, we covered OpenAI's finances, nuclear power, and Sam Altman.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday of last week, Ars Technica hosted a live conversation with Ed Zitron, host of the Better Offline podcast and one of tech’s most vocal AI critics, to discuss whether the generative AI industry is experiencing a bubble and when it might burst. My Internet connection had other plans, though, dropping out multiple times and forcing Ars Technica’s Lee Hutchinson to jump in as an excellent emergency backup host.&lt;/p&gt;
&lt;p&gt;During the times my connection cooperated, Zitron and I covered OpenAI’s financial issues, lofty infrastructure promises, and why the AI hype machine keeps rolling despite some arguably shaky economics underneath. Lee’s probing questions about per-user costs revealed a potential flaw in AI subscription models: Companies can’t predict whether a user will cost them $2 or $10,000 per month.&lt;/p&gt;
&lt;p&gt;You can watch a recording of the event on YouTube or in the window below.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Our discussion with Ed Zitron. Click here for transcript.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;h2&gt;“A 50 billion-dollar industry pretending to be a trillion-dollar one”&lt;/h2&gt;
&lt;p&gt;I started by asking Zitron the most direct question I could: “Why are you so mad about AI?” His answer got right to the heart of his critique: the disconnect between AI’s actual capabilities and how it’s being sold. “Because everybody’s acting like it’s something it isn’t,” Zitron said. “They’re acting like it’s this panacea that will be the future of software growth, the future of hardware growth, the future of compute.”&lt;/p&gt;
&lt;p&gt;In one of his newsletters, Zitron describes the generative AI market as “a 50 billion dollar revenue industry masquerading as a one trillion-dollar one.” He pointed to OpenAI’s financial burn rate (losing an estimated $9.7 billion in the first half of 2025 alone) as evidence that the economics don’t work, coupled with a heavy dose of pessimism about AI in general.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2108866 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2212801534.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Donald Trump listens as Nvidia CEO Jensen Huang speaks at the White House during an event on “Investing in America” on April 30, 2025, in Washington, DC.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Andrew Harnik / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;“The models just do not have the efficacy,” Zitron said during our conversation. “AI agents is one of the most egregious lies the tech industry has ever told. Autonomous agents don’t exist.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He contrasted the relatively small revenue generated by AI companies with the massive capital expenditures flowing into the sector. Even major cloud providers and chip makers are showing strain. Oracle reportedly lost $100 million in three months after installing Nvidia’s new Blackwell GPUs, which Zitron noted are “extremely power-hungry and expensive to run.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Finding utility despite the hype&lt;/h2&gt;
&lt;p&gt;I pushed back against some of Zitron’s broader dismissals of AI by sharing my own experience. I use AI chatbots frequently for brainstorming useful ideas and helping me see them from different angles. “I find I use AI models as sort of knowledge translators and framework translators,” I explained.&lt;/p&gt;
&lt;p&gt;After experiencing brain fog from repeated bouts of COVID over the years, I’ve also found tools like ChatGPT and Claude especially helpful for memory augmentation that pierces through brain fog: describing something in a roundabout, fuzzy way and quickly getting an answer I can then verify. Along these lines, I’ve previously written about how people in a UK study found AI assistants useful accessibility tools.&lt;/p&gt;
&lt;p&gt;Zitron acknowledged this could be useful for me personally but declined to draw any larger conclusions from my one data point. “I understand how that might be helpful; that’s cool,” he said. “I’m glad that that helps you in that way; it’s not a trillion-dollar use case.”&lt;/p&gt;
&lt;p&gt;He also shared his own attempts at using AI tools, including experimenting with Claude Code despite not being a coder himself.&lt;/p&gt;
&lt;p&gt;“If I liked [AI] somehow, it would be actually a more interesting story because I’d be talking about something I liked that was also onerously expensive,” Zitron explained. “But it doesn’t even do that, and it’s actually one of my core frustrations, it’s like this massive over-promise thing. I’m an early adopter guy. I will buy early crap all the time. I bought an Apple Vision Pro, like, what more do you say there? I’m ready to accept issues, but AI is all issues, it’s all filler, no killer; it’s very strange.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Zitron and I agree that current AI assistants are being marketed beyond their actual capabilities. As I often say, AI models are not people, and they are not good factual references. As such, they cannot replace human decision-making and cannot wholesale replace human intellectual labor (at the moment). Instead, I see AI models as augmentations of human capability: as tools rather than autonomous entities.&lt;/p&gt;
&lt;h2&gt;Computing costs: History versus reality&lt;/h2&gt;
&lt;p&gt;Even though Zitron and I found some common ground about AI hype, I expressed a belief that criticism over the cost and power requirements of operating AI models will eventually not become an issue.&lt;/p&gt;
&lt;p&gt;I attempted to make that case by noting that computing costs historically trend downward over time, referencing the Air Force’s SAGE computer system from the 1950s: a four-story building that performed 75,000 operations per second while consuming two megawatts of power. Today, pocket-sized phones deliver millions of times more computing power in a way that would be impossible, power consumption-wise, in the 1950s.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1821593 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="center large" height="486" src="https://cdn.arstechnica.net/wp-content/uploads/2021/12/GettyImages-837581308-640x486.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The blockhouse for the Semi-Automatic Ground Environment at Stewart Air Force Base, Newburgh, New York.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Denver Post via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;“I think it will eventually work that way,” I said, suggesting that AI inference costs might follow similar patterns of improvement over years and that AI tools will eventually become commodity components of computer operating systems. Basically, even if AI models stay inefficient, AI models of a certain baseline usefulness and capability will still be cheaper to train and run in the future because the computing systems they run on will be faster, cheaper, and less power-hungry as well.&lt;/p&gt;
&lt;p&gt;Zitron pushed back on this optimism, saying that AI costs are currently moving in the wrong direction. “The costs are going up, unilaterally across the board,” he said. Even newer systems like Cerebras and Grok can generate results faster but not cheaper. He also questioned whether integrating AI into operating systems would prove useful even if the technology became profitable, since AI models struggle with deterministic commands and consistent behavior.&lt;/p&gt;
&lt;h2&gt;The power problem and circular investments&lt;/h2&gt;
&lt;p&gt;One of Zitron’s most pointed criticisms during the discussion centered on OpenAI’s infrastructure promises. The company has pledged to build data centers requiring 10 gigawatts of power capacity (equivalent to 10 nuclear power plants, I once pointed out) for its Stargate project in Abilene, Texas. According to Zitron’s research, the town currently has only 350 megawatts of generating capacity and a 200-megawatt substation.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“A gigawatt of power is a lot, and it’s not like &lt;em&gt;Red Alert 2&lt;/em&gt;,” Zitron said, referencing the real-time strategy game. “You don’t just build a power station and it happens. There are months of actual physics to make sure that it doesn’t kill everyone.”&lt;/p&gt;
&lt;p&gt;He believes many announced data centers will never be completed, calling the infrastructure promises “castles on sand” that nobody in the financial press seems willing to question directly.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2097196 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-1024x683.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anton Petrus via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;After another technical blackout on my end, I came back online and asked Zitron to define the scope of the AI bubble. He says it has evolved from one bubble (foundation models) into two or three, now including AI compute companies like CoreWeave and the market’s obsession with Nvidia.&lt;/p&gt;
&lt;p&gt;Zitron highlighted what he sees as essentially circular investment schemes propping up the industry. He pointed to OpenAI’s $300 billion deal with Oracle and Nvidia’s relationship with CoreWeave as examples. “CoreWeave, they literally… They funded CoreWeave, became their biggest customer, then CoreWeave took that contract and those GPUs and used them as collateral to raise debt to buy more GPUs,” Zitron explained.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;When will the bubble pop?&lt;/h2&gt;
&lt;p&gt;Zitron predicted the bubble would burst within the next year and a half, though he acknowledged it could happen sooner. He expects a cascade of events rather than a single dramatic collapse: An AI startup will run out of money, triggering panic among other startups and their venture capital backers, creating a fire-sale environment that makes future fundraising impossible.&lt;/p&gt;
&lt;p&gt;“It’s not gonna be one Bear Stearns moment,” Zitron explained. “It’s gonna be a succession of events until the markets freak out.”&lt;/p&gt;
&lt;p&gt;The crux of the problem, according to Zitron, is Nvidia. The chip maker’s stock represents 7 to 8 percent of the S&amp;amp;P 500’s value, and the broader market has become dependent on Nvidia’s continued hyper growth. When Nvidia posted “only” 55 percent year-over-year growth in January, the market wobbled.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Nvidia’s growth is why the bubble is inflated,” Zitron said. “If their growth goes down, the bubble will burst.”&lt;/p&gt;
&lt;p&gt;He also warned of broader consequences: “I think there’s a depression coming. I think once the markets work out that tech doesn’t grow forever, they’re gonna flush the toilet aggressively on Silicon Valley.” This connects to his larger thesis: that the tech industry has run out of genuine hyper-growth opportunities and is trying to manufacture one with AI.&lt;/p&gt;
&lt;p&gt;“Is there anything that would falsify your premise of this bubble and crash happening?” I asked. “What if you’re wrong?”&lt;/p&gt;
&lt;p&gt;“I’ve been answering ‘What if you’re wrong?’ for a year-and-a-half to two years, so I’m not bothered by that question, so the thing that would have to prove me right would’ve already needed to happen,” he said. Amid a longer exposition about Sam Altman, Zitron said, “The thing that would’ve had to happen with inference would’ve had to be… it would have to be hundredths of a cent per million tokens, they would have to be printing money, and then, it would have to be way more useful. It would have to have efficacy that it does not have, the hallucination problems… would have to be fixable, and on top of this, someone would have to fix agents.”&lt;/p&gt;
&lt;h2&gt;A positivity challenge&lt;/h2&gt;
&lt;p&gt;Near the end of our conversation, I wondered if I could flip the script, so to speak, and see if he could say something positive or optimistic, although I chose the most challenging subject possible for him. “What’s the best thing about Sam Altman,” I asked. “Can you say anything nice about him at all?”&lt;/p&gt;
&lt;p&gt;“I understand why you’re asking this,” Zitron started, “but I wanna be clear: Sam Altman is going to be the reason the markets take a crap. Sam Altman has lied to everyone. Sam Altman has been lying forever.” He continued, “Like the Pied Piper, he’s led the markets into an abyss, and yes, people should have known better, but I hope at the end of this, Sam Altman is seen for what he is, which is a con artist and a very successful one.”&lt;/p&gt;
&lt;p&gt;Then he added, “You know what? I’ll say something nice about him, he’s really good at making people say, ‘Yes.'”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Despite connection hiccups, we covered OpenAI's finances, nuclear power, and Sam Altman.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday of last week, Ars Technica hosted a live conversation with Ed Zitron, host of the Better Offline podcast and one of tech’s most vocal AI critics, to discuss whether the generative AI industry is experiencing a bubble and when it might burst. My Internet connection had other plans, though, dropping out multiple times and forcing Ars Technica’s Lee Hutchinson to jump in as an excellent emergency backup host.&lt;/p&gt;
&lt;p&gt;During the times my connection cooperated, Zitron and I covered OpenAI’s financial issues, lofty infrastructure promises, and why the AI hype machine keeps rolling despite some arguably shaky economics underneath. Lee’s probing questions about per-user costs revealed a potential flaw in AI subscription models: Companies can’t predict whether a user will cost them $2 or $10,000 per month.&lt;/p&gt;
&lt;p&gt;You can watch a recording of the event on YouTube or in the window below.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Our discussion with Ed Zitron. Click here for transcript.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;h2&gt;“A 50 billion-dollar industry pretending to be a trillion-dollar one”&lt;/h2&gt;
&lt;p&gt;I started by asking Zitron the most direct question I could: “Why are you so mad about AI?” His answer got right to the heart of his critique: the disconnect between AI’s actual capabilities and how it’s being sold. “Because everybody’s acting like it’s something it isn’t,” Zitron said. “They’re acting like it’s this panacea that will be the future of software growth, the future of hardware growth, the future of compute.”&lt;/p&gt;
&lt;p&gt;In one of his newsletters, Zitron describes the generative AI market as “a 50 billion dollar revenue industry masquerading as a one trillion-dollar one.” He pointed to OpenAI’s financial burn rate (losing an estimated $9.7 billion in the first half of 2025 alone) as evidence that the economics don’t work, coupled with a heavy dose of pessimism about AI in general.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2108866 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2212801534.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Donald Trump listens as Nvidia CEO Jensen Huang speaks at the White House during an event on “Investing in America” on April 30, 2025, in Washington, DC.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Andrew Harnik / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;“The models just do not have the efficacy,” Zitron said during our conversation. “AI agents is one of the most egregious lies the tech industry has ever told. Autonomous agents don’t exist.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He contrasted the relatively small revenue generated by AI companies with the massive capital expenditures flowing into the sector. Even major cloud providers and chip makers are showing strain. Oracle reportedly lost $100 million in three months after installing Nvidia’s new Blackwell GPUs, which Zitron noted are “extremely power-hungry and expensive to run.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Finding utility despite the hype&lt;/h2&gt;
&lt;p&gt;I pushed back against some of Zitron’s broader dismissals of AI by sharing my own experience. I use AI chatbots frequently for brainstorming useful ideas and helping me see them from different angles. “I find I use AI models as sort of knowledge translators and framework translators,” I explained.&lt;/p&gt;
&lt;p&gt;After experiencing brain fog from repeated bouts of COVID over the years, I’ve also found tools like ChatGPT and Claude especially helpful for memory augmentation that pierces through brain fog: describing something in a roundabout, fuzzy way and quickly getting an answer I can then verify. Along these lines, I’ve previously written about how people in a UK study found AI assistants useful accessibility tools.&lt;/p&gt;
&lt;p&gt;Zitron acknowledged this could be useful for me personally but declined to draw any larger conclusions from my one data point. “I understand how that might be helpful; that’s cool,” he said. “I’m glad that that helps you in that way; it’s not a trillion-dollar use case.”&lt;/p&gt;
&lt;p&gt;He also shared his own attempts at using AI tools, including experimenting with Claude Code despite not being a coder himself.&lt;/p&gt;
&lt;p&gt;“If I liked [AI] somehow, it would be actually a more interesting story because I’d be talking about something I liked that was also onerously expensive,” Zitron explained. “But it doesn’t even do that, and it’s actually one of my core frustrations, it’s like this massive over-promise thing. I’m an early adopter guy. I will buy early crap all the time. I bought an Apple Vision Pro, like, what more do you say there? I’m ready to accept issues, but AI is all issues, it’s all filler, no killer; it’s very strange.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Zitron and I agree that current AI assistants are being marketed beyond their actual capabilities. As I often say, AI models are not people, and they are not good factual references. As such, they cannot replace human decision-making and cannot wholesale replace human intellectual labor (at the moment). Instead, I see AI models as augmentations of human capability: as tools rather than autonomous entities.&lt;/p&gt;
&lt;h2&gt;Computing costs: History versus reality&lt;/h2&gt;
&lt;p&gt;Even though Zitron and I found some common ground about AI hype, I expressed a belief that criticism over the cost and power requirements of operating AI models will eventually not become an issue.&lt;/p&gt;
&lt;p&gt;I attempted to make that case by noting that computing costs historically trend downward over time, referencing the Air Force’s SAGE computer system from the 1950s: a four-story building that performed 75,000 operations per second while consuming two megawatts of power. Today, pocket-sized phones deliver millions of times more computing power in a way that would be impossible, power consumption-wise, in the 1950s.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1821593 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="center large" height="486" src="https://cdn.arstechnica.net/wp-content/uploads/2021/12/GettyImages-837581308-640x486.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The blockhouse for the Semi-Automatic Ground Environment at Stewart Air Force Base, Newburgh, New York.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Denver Post via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;“I think it will eventually work that way,” I said, suggesting that AI inference costs might follow similar patterns of improvement over years and that AI tools will eventually become commodity components of computer operating systems. Basically, even if AI models stay inefficient, AI models of a certain baseline usefulness and capability will still be cheaper to train and run in the future because the computing systems they run on will be faster, cheaper, and less power-hungry as well.&lt;/p&gt;
&lt;p&gt;Zitron pushed back on this optimism, saying that AI costs are currently moving in the wrong direction. “The costs are going up, unilaterally across the board,” he said. Even newer systems like Cerebras and Grok can generate results faster but not cheaper. He also questioned whether integrating AI into operating systems would prove useful even if the technology became profitable, since AI models struggle with deterministic commands and consistent behavior.&lt;/p&gt;
&lt;h2&gt;The power problem and circular investments&lt;/h2&gt;
&lt;p&gt;One of Zitron’s most pointed criticisms during the discussion centered on OpenAI’s infrastructure promises. The company has pledged to build data centers requiring 10 gigawatts of power capacity (equivalent to 10 nuclear power plants, I once pointed out) for its Stargate project in Abilene, Texas. According to Zitron’s research, the town currently has only 350 megawatts of generating capacity and a 200-megawatt substation.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“A gigawatt of power is a lot, and it’s not like &lt;em&gt;Red Alert 2&lt;/em&gt;,” Zitron said, referencing the real-time strategy game. “You don’t just build a power station and it happens. There are months of actual physics to make sure that it doesn’t kill everyone.”&lt;/p&gt;
&lt;p&gt;He believes many announced data centers will never be completed, calling the infrastructure promises “castles on sand” that nobody in the financial press seems willing to question directly.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2097196 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-1024x683.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anton Petrus via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;After another technical blackout on my end, I came back online and asked Zitron to define the scope of the AI bubble. He says it has evolved from one bubble (foundation models) into two or three, now including AI compute companies like CoreWeave and the market’s obsession with Nvidia.&lt;/p&gt;
&lt;p&gt;Zitron highlighted what he sees as essentially circular investment schemes propping up the industry. He pointed to OpenAI’s $300 billion deal with Oracle and Nvidia’s relationship with CoreWeave as examples. “CoreWeave, they literally… They funded CoreWeave, became their biggest customer, then CoreWeave took that contract and those GPUs and used them as collateral to raise debt to buy more GPUs,” Zitron explained.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;When will the bubble pop?&lt;/h2&gt;
&lt;p&gt;Zitron predicted the bubble would burst within the next year and a half, though he acknowledged it could happen sooner. He expects a cascade of events rather than a single dramatic collapse: An AI startup will run out of money, triggering panic among other startups and their venture capital backers, creating a fire-sale environment that makes future fundraising impossible.&lt;/p&gt;
&lt;p&gt;“It’s not gonna be one Bear Stearns moment,” Zitron explained. “It’s gonna be a succession of events until the markets freak out.”&lt;/p&gt;
&lt;p&gt;The crux of the problem, according to Zitron, is Nvidia. The chip maker’s stock represents 7 to 8 percent of the S&amp;amp;P 500’s value, and the broader market has become dependent on Nvidia’s continued hyper growth. When Nvidia posted “only” 55 percent year-over-year growth in January, the market wobbled.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Nvidia’s growth is why the bubble is inflated,” Zitron said. “If their growth goes down, the bubble will burst.”&lt;/p&gt;
&lt;p&gt;He also warned of broader consequences: “I think there’s a depression coming. I think once the markets work out that tech doesn’t grow forever, they’re gonna flush the toilet aggressively on Silicon Valley.” This connects to his larger thesis: that the tech industry has run out of genuine hyper-growth opportunities and is trying to manufacture one with AI.&lt;/p&gt;
&lt;p&gt;“Is there anything that would falsify your premise of this bubble and crash happening?” I asked. “What if you’re wrong?”&lt;/p&gt;
&lt;p&gt;“I’ve been answering ‘What if you’re wrong?’ for a year-and-a-half to two years, so I’m not bothered by that question, so the thing that would have to prove me right would’ve already needed to happen,” he said. Amid a longer exposition about Sam Altman, Zitron said, “The thing that would’ve had to happen with inference would’ve had to be… it would have to be hundredths of a cent per million tokens, they would have to be printing money, and then, it would have to be way more useful. It would have to have efficacy that it does not have, the hallucination problems… would have to be fixable, and on top of this, someone would have to fix agents.”&lt;/p&gt;
&lt;h2&gt;A positivity challenge&lt;/h2&gt;
&lt;p&gt;Near the end of our conversation, I wondered if I could flip the script, so to speak, and see if he could say something positive or optimistic, although I chose the most challenging subject possible for him. “What’s the best thing about Sam Altman,” I asked. “Can you say anything nice about him at all?”&lt;/p&gt;
&lt;p&gt;“I understand why you’re asking this,” Zitron started, “but I wanna be clear: Sam Altman is going to be the reason the markets take a crap. Sam Altman has lied to everyone. Sam Altman has been lying forever.” He continued, “Like the Pied Piper, he’s led the markets into an abyss, and yes, people should have known better, but I hope at the end of this, Sam Altman is seen for what he is, which is a con artist and a very successful one.”&lt;/p&gt;
&lt;p&gt;Then he added, “You know what? I’ll say something nice about him, he’s really good at making people say, ‘Yes.'”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/ars-live-recap-is-the-ai-bubble-about-to-pop-ed-zitron-weighs-in/</guid><pubDate>Thu, 16 Oct 2025 20:25:08 +0000</pubDate></item></channel></rss>