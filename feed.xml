<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 15 Oct 2025 06:32:27 +0000</lastBuildDate><item><title>Optimizing food subsidies: Applying digital platforms to maximize nutrition (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/optimizing-food-subsidies-applying-digital-platforms-maximize-nutrition-1014</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/aouad-ali-mit-00.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Oct. 16 is World Food Day, a global campaign to celebrate the founding of the Food and Agriculture Organization 80 years ago, and to work toward a healthy, sustainable, food-secure future. More than 670 million people in the world are facing hunger. Millions of others are facing rising obesity rates and struggle to get healthy food for proper nutrition.&amp;nbsp;&lt;/p&gt;&lt;p&gt;World Food Day calls on not only world governments, but business, academia, the media, and even the youth to take action to promote resilient food systems and combat hunger. This year, the Abdul Latif Jameel Water and Food Systems Laboratory (J-WAFS) is spotlighting an MIT researcher who is working toward this goal by studying food and water systems in the Global South.&lt;/p&gt;&lt;p&gt;J-WAFS seed grants provide funding to early-stage research projects that are unique to prior work. In an 11th round of seed grant funding in 2025, 10 MIT faculty members received support to carry out their cutting-edge water and food research. Ali Aouad PhD ’17, assistant professor of operations management at the MIT Sloan School of Management, was one of those grantees. “I had searched before joining MIT what kind of research centers and initiatives were available that tried to coalesce research on food systems,” Aouad says. “And so, I was very excited about J-WAFS.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aouad gathered more information about J-WAFS at the new faculty orientation session in August 2024, where he spoke to J-WAFS staff and learned about the program’s grant opportunities for water and food research. Later that fall semester, he attended a few J-WAFS seminars on agricultural economics and water resource management. That’s when Aouad knew that his project was perfectly aligned with the J-WAFS mission of securing humankind’s water and food.&lt;/p&gt;&lt;p&gt;Aouad’s seed project focuses on food subsidies. With a background in operations research and an interest in digital platforms, much of his work has centered on aligning supply-side operations with heterogeneous customer preferences. Past projects include ones on retail and matching systems. “I started thinking that these types of demand-driven approaches may be also very relevant to important social challenges, particularly as they relate to food security,” Aouad says. Before starting his PhD at MIT, Aouad worked on projects that looked at subsidies for smallholder farmers in low- and middle-income countries. “I think in the back of my mind, I've always been fascinated by trying to solve these issues,” he noted.&lt;/p&gt;&lt;p&gt;His seed grant project, Optimal subsidy design: Application to food assistance programs, aims to leverage data on preferences and purchasing habits from local grocery stores in India to inform food assistance policy and optimize the design of subsidies. Typical data collection systems, like point-of-sales, are not as readily available in India’s local groceries, making this type of data hard to come by for low-income individuals. “Mom-and-pop stores are extremely important last-mile operators when it comes to nutrition,” he explains.&amp;nbsp;&lt;/p&gt;&lt;p&gt;For this project, the research team gave local grocers point-of-sale scanners to track purchasing habits. “We aim to develop an algorithm that converts these transactions into some sort of ‘revelation’ of the individuals’ latent preferences,” says Aouad. “As such, we can model and optimize the food assistance programs — how much variety and flexibility is offered, taking into account the expected demand uptake.” He continues, “now, of course, our ability to answer detailed design questions [across various products and prices] depends on the quality of our inference from&amp;nbsp; the data, and so this is where we need more sophisticated and robust algorithms.”&lt;/p&gt;&lt;p&gt;Following the data collection and model development, the ultimate goal of this research is to inform policy surrounding food assistance programs through an “optimization approach.” Aouad describes the complexities of using optimization to guide policy. “Policies are often informed by domain expertise, legacy systems, or political deliberation. A lot of researchers build rigorous evidence to inform food policy, but it’s fair to say that the kind of approach that I’m proposing in this research is not something that is commonly used. I see an opportunity for bringing a new approach and methodological tradition to a problem that has been central for policy for many decades.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The overall health of consumers is the reason food assistance programs exist, yet measuring long-term nutritional impacts and shifts in purchase behavior is difficult. In past research, Aouad notes that the short-term effects of food assistance interventions can be significant. However, these effects are often short-lived. “This is a fascinating question that I don’t think we will be able to address within the space of interventions that we will be considering. However, I think it is something I would like to capture in the research, and maybe develop hypotheses for future work around how we can shift nutrition-related behaviors in the long run.”&lt;/p&gt;&lt;p&gt;While his project develops a new methodology to calibrate food assistance programs, large-scale applications are not promised. “A lot of what drives subsidy mechanisms and food assistance programs is also, quite frankly, how easy it is and how cost-effective it is to implement these policies in the first place,” comments Aouad. Cost and infrastructure barriers are unavoidable to this kind of policy research, as well as sustaining these programs. Aouad’s effort will provide insights into customer preferences and subsidy optimization in a pilot setup, but replicating this approach on a real scale may be costly. Aouad hopes to be able to gather proxy information from customers that would both feed into the model and provide insight into a more cost-effective way to collect data for large-scale implementation.&lt;/p&gt;&lt;p&gt;There is still much work to be done to ensure food security for all, whether it’s advances in agriculture, food-assistance programs, or ways to boost adequate nutrition. As the 2026 seed grant deadline approaches, J-WAFS will continue its mission of supporting MIT faculty as they pursue innovative projects that have practical and real impacts on water and food system challenges.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/aouad-ali-mit-00.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Oct. 16 is World Food Day, a global campaign to celebrate the founding of the Food and Agriculture Organization 80 years ago, and to work toward a healthy, sustainable, food-secure future. More than 670 million people in the world are facing hunger. Millions of others are facing rising obesity rates and struggle to get healthy food for proper nutrition.&amp;nbsp;&lt;/p&gt;&lt;p&gt;World Food Day calls on not only world governments, but business, academia, the media, and even the youth to take action to promote resilient food systems and combat hunger. This year, the Abdul Latif Jameel Water and Food Systems Laboratory (J-WAFS) is spotlighting an MIT researcher who is working toward this goal by studying food and water systems in the Global South.&lt;/p&gt;&lt;p&gt;J-WAFS seed grants provide funding to early-stage research projects that are unique to prior work. In an 11th round of seed grant funding in 2025, 10 MIT faculty members received support to carry out their cutting-edge water and food research. Ali Aouad PhD ’17, assistant professor of operations management at the MIT Sloan School of Management, was one of those grantees. “I had searched before joining MIT what kind of research centers and initiatives were available that tried to coalesce research on food systems,” Aouad says. “And so, I was very excited about J-WAFS.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aouad gathered more information about J-WAFS at the new faculty orientation session in August 2024, where he spoke to J-WAFS staff and learned about the program’s grant opportunities for water and food research. Later that fall semester, he attended a few J-WAFS seminars on agricultural economics and water resource management. That’s when Aouad knew that his project was perfectly aligned with the J-WAFS mission of securing humankind’s water and food.&lt;/p&gt;&lt;p&gt;Aouad’s seed project focuses on food subsidies. With a background in operations research and an interest in digital platforms, much of his work has centered on aligning supply-side operations with heterogeneous customer preferences. Past projects include ones on retail and matching systems. “I started thinking that these types of demand-driven approaches may be also very relevant to important social challenges, particularly as they relate to food security,” Aouad says. Before starting his PhD at MIT, Aouad worked on projects that looked at subsidies for smallholder farmers in low- and middle-income countries. “I think in the back of my mind, I've always been fascinated by trying to solve these issues,” he noted.&lt;/p&gt;&lt;p&gt;His seed grant project, Optimal subsidy design: Application to food assistance programs, aims to leverage data on preferences and purchasing habits from local grocery stores in India to inform food assistance policy and optimize the design of subsidies. Typical data collection systems, like point-of-sales, are not as readily available in India’s local groceries, making this type of data hard to come by for low-income individuals. “Mom-and-pop stores are extremely important last-mile operators when it comes to nutrition,” he explains.&amp;nbsp;&lt;/p&gt;&lt;p&gt;For this project, the research team gave local grocers point-of-sale scanners to track purchasing habits. “We aim to develop an algorithm that converts these transactions into some sort of ‘revelation’ of the individuals’ latent preferences,” says Aouad. “As such, we can model and optimize the food assistance programs — how much variety and flexibility is offered, taking into account the expected demand uptake.” He continues, “now, of course, our ability to answer detailed design questions [across various products and prices] depends on the quality of our inference from&amp;nbsp; the data, and so this is where we need more sophisticated and robust algorithms.”&lt;/p&gt;&lt;p&gt;Following the data collection and model development, the ultimate goal of this research is to inform policy surrounding food assistance programs through an “optimization approach.” Aouad describes the complexities of using optimization to guide policy. “Policies are often informed by domain expertise, legacy systems, or political deliberation. A lot of researchers build rigorous evidence to inform food policy, but it’s fair to say that the kind of approach that I’m proposing in this research is not something that is commonly used. I see an opportunity for bringing a new approach and methodological tradition to a problem that has been central for policy for many decades.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The overall health of consumers is the reason food assistance programs exist, yet measuring long-term nutritional impacts and shifts in purchase behavior is difficult. In past research, Aouad notes that the short-term effects of food assistance interventions can be significant. However, these effects are often short-lived. “This is a fascinating question that I don’t think we will be able to address within the space of interventions that we will be considering. However, I think it is something I would like to capture in the research, and maybe develop hypotheses for future work around how we can shift nutrition-related behaviors in the long run.”&lt;/p&gt;&lt;p&gt;While his project develops a new methodology to calibrate food assistance programs, large-scale applications are not promised. “A lot of what drives subsidy mechanisms and food assistance programs is also, quite frankly, how easy it is and how cost-effective it is to implement these policies in the first place,” comments Aouad. Cost and infrastructure barriers are unavoidable to this kind of policy research, as well as sustaining these programs. Aouad’s effort will provide insights into customer preferences and subsidy optimization in a pilot setup, but replicating this approach on a real scale may be costly. Aouad hopes to be able to gather proxy information from customers that would both feed into the model and provide insight into a more cost-effective way to collect data for large-scale implementation.&lt;/p&gt;&lt;p&gt;There is still much work to be done to ensure food security for all, whether it’s advances in agriculture, food-assistance programs, or ways to boost adequate nutrition. As the 2026 seed grant deadline approaches, J-WAFS will continue its mission of supporting MIT faculty as they pursue innovative projects that have practical and real impacts on water and food system challenges.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/optimizing-food-subsidies-applying-digital-platforms-maximize-nutrition-1014</guid><pubDate>Tue, 14 Oct 2025 19:40:00 +0000</pubDate></item><item><title>DirecTV screensavers will show AI-generated ads with your face in 2026 (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/10/directv-screensavers-will-show-ai-generated-ads-with-your-face-in-2026/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Like other companies with streaming businesses, DirecTV is leaning into ads more.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="DirecTV's Gemini Air streaming stick and remote." class="absolute inset-0 w-full h-full object-cover hidden" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-640x450.jpg" width="640" /&gt;
                  &lt;img alt="DirecTV's Gemini Air streaming stick and remote." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      DirecTV's Gemini Air streaming stick and remote. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          DirecTV

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As if DirecTV doesn't have enough trouble keeping customers, the satellite TV provider's streaming devices will show AI-generated screensaver ads next year, according to an announcement today from partnering ads company Glance.&lt;/p&gt;
&lt;p&gt;People who use either of DirecTV’s two Gemini streaming devices will start seeing the ads “in early 2026,” per the announcement. DirecTV’s Gemini Air is an Android TV-powered USB device that people can plug into a TV for access to live TV channels, as well as streaming apps. Gemini Air doesn’t require a DirecTV satellite connection, and DirecTV gives all of its Internet customers the device. DirecTV first started selling Gemini devices in 2023, when it launched a separate Gemini set-top box that connects through DirecTV satellite setups.&lt;/p&gt;
&lt;p&gt;DirecTV made an agreement with Glance to show AI-generated content and ads on Gemini devices' screensavers. Currently, Gemini devices show Google wallpapers as screensavers, which are on by default. When the new screensavers launch, Glance's AI content will show if the TV is idle for 10 minutes, The Verge reported.&lt;/p&gt;
&lt;p&gt;For the unfamiliar, Glance is the same company that brought AI-generated lock screen ads with users’ faces to Samsung Galaxy phones in June. The Indian company recently started pushing its ad platform to smart TV operating systems, as well. Before generative AI took off, Glance shoved ads and tracking into phones through “lock screen experiences” that could also show desirable content, like news alerts. Glance is owned by InMobi, a mobile ads company with a history of tracking unsuspecting users.&lt;/p&gt;
&lt;p&gt;DirecTV's screensavers will let a user create an AI avatar of themself by scanning a QR code on the screensaver. Afterward, they can use the avatar to browse through different AI content. Users will also reportedly be able to dress up their AI avatars, allowing Glance's screensaver to recommend real-life products to purchase by performing a reverse-image search.&lt;/p&gt;
&lt;p&gt;Rajat Wanchoo, Glance's group VP of commercial partnerships, told The Verge that Glance has a trillion SKUs that it can match to AI-generated images. Final purchases will occur via a phone or other device separate from the Gemini hardware.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;According to a March blog post from Glance's VP of AI, Ian Anderson, Glance's avatars “analyze customer behavior, preferences, and browsing history to provide tailor-made product recommendations, enhancing engagement and conversion rates.”&lt;/p&gt;
&lt;p&gt;In a statement today, Naveen Tewari, Glance’s CEO and founder, said the screensavers will allow people to “instantly select a brand and reimagine themselves in the brand catalog right from their living-room TV itself.”&lt;/p&gt;
&lt;p&gt;The DirecTV screensavers will also allow people to make 30-second-long AI-generated videos featuring their avatar, The Verge reported.&lt;/p&gt;
&lt;p&gt;In addition to providing an "AI-commerce experience," DirecTV expects the screensavers to help with "content discovery" and “personalization," Vikash Sharm, SVP of product marketing at DirecTV, said in a statement.&lt;/p&gt;
&lt;p&gt;The screensavers will also be able to show real-time weather and sports scores, Glance said.&lt;/p&gt;
&lt;h2&gt;A natural progression&lt;/h2&gt;
&lt;p&gt;Turning to ad-centric screensavers may frustrate customers who didn't expect ads when they bought into Gemini devices for their streaming capabilities.&lt;/p&gt;
&lt;p&gt;However, DirecTV has an expanding advertising business that has included experimenting with ad types, such as ads that show when people hit pause. As far as offensive ads go, screensaver ads can be considered less intrusive, since they typically show only when someone isn’t actively viewing their TV. Gemini screensavers can also be disabled.&lt;/p&gt;
&lt;p&gt;It has become increasingly important for DirecTV to diversify revenue beyond satellite and Internet subscriptions. DirecTV had over 20 million subscribers in 2015; in 2024, streaming business publication Next TV, citing an anonymous source “close to the company,” reported that the AT&amp;amp;T-owned firm was down to about 11 million subscribers.&lt;/p&gt;
&lt;p&gt;Simultaneously, the streaming industry—including streaming services and streaming software—has been increasingly relying on advertising to boost revenue. For some streaming service providers, increasing revenue through ads is starting to eclipse the pressure to do so through subscriber counts. Considering DirecTV's declining viewership and growing interest in streaming, finding more ways to sell ads seems like a natural progression.&lt;/p&gt;
&lt;p&gt;With legacy pay TV providers already dealing with dwindling subscriptions, introducing new types of ads risks making DirecTV less appealing as well.&lt;/p&gt;
&lt;p&gt;And it’s likely that things won’t end there.&lt;/p&gt;
&lt;p&gt;“This, we can integrate across different places within the television,” Glance COO Mansi Jain told The Verge. "We are starting with the screensaver, but tomorrow… we can integrate it in the launcher of the TV."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Like other companies with streaming businesses, DirecTV is leaning into ads more.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="DirecTV's Gemini Air streaming stick and remote." class="absolute inset-0 w-full h-full object-cover hidden" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-640x450.jpg" width="640" /&gt;
                  &lt;img alt="DirecTV's Gemini Air streaming stick and remote." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      DirecTV's Gemini Air streaming stick and remote. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          DirecTV

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As if DirecTV doesn't have enough trouble keeping customers, the satellite TV provider's streaming devices will show AI-generated screensaver ads next year, according to an announcement today from partnering ads company Glance.&lt;/p&gt;
&lt;p&gt;People who use either of DirecTV’s two Gemini streaming devices will start seeing the ads “in early 2026,” per the announcement. DirecTV’s Gemini Air is an Android TV-powered USB device that people can plug into a TV for access to live TV channels, as well as streaming apps. Gemini Air doesn’t require a DirecTV satellite connection, and DirecTV gives all of its Internet customers the device. DirecTV first started selling Gemini devices in 2023, when it launched a separate Gemini set-top box that connects through DirecTV satellite setups.&lt;/p&gt;
&lt;p&gt;DirecTV made an agreement with Glance to show AI-generated content and ads on Gemini devices' screensavers. Currently, Gemini devices show Google wallpapers as screensavers, which are on by default. When the new screensavers launch, Glance's AI content will show if the TV is idle for 10 minutes, The Verge reported.&lt;/p&gt;
&lt;p&gt;For the unfamiliar, Glance is the same company that brought AI-generated lock screen ads with users’ faces to Samsung Galaxy phones in June. The Indian company recently started pushing its ad platform to smart TV operating systems, as well. Before generative AI took off, Glance shoved ads and tracking into phones through “lock screen experiences” that could also show desirable content, like news alerts. Glance is owned by InMobi, a mobile ads company with a history of tracking unsuspecting users.&lt;/p&gt;
&lt;p&gt;DirecTV's screensavers will let a user create an AI avatar of themself by scanning a QR code on the screensaver. Afterward, they can use the avatar to browse through different AI content. Users will also reportedly be able to dress up their AI avatars, allowing Glance's screensaver to recommend real-life products to purchase by performing a reverse-image search.&lt;/p&gt;
&lt;p&gt;Rajat Wanchoo, Glance's group VP of commercial partnerships, told The Verge that Glance has a trillion SKUs that it can match to AI-generated images. Final purchases will occur via a phone or other device separate from the Gemini hardware.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;According to a March blog post from Glance's VP of AI, Ian Anderson, Glance's avatars “analyze customer behavior, preferences, and browsing history to provide tailor-made product recommendations, enhancing engagement and conversion rates.”&lt;/p&gt;
&lt;p&gt;In a statement today, Naveen Tewari, Glance’s CEO and founder, said the screensavers will allow people to “instantly select a brand and reimagine themselves in the brand catalog right from their living-room TV itself.”&lt;/p&gt;
&lt;p&gt;The DirecTV screensavers will also allow people to make 30-second-long AI-generated videos featuring their avatar, The Verge reported.&lt;/p&gt;
&lt;p&gt;In addition to providing an "AI-commerce experience," DirecTV expects the screensavers to help with "content discovery" and “personalization," Vikash Sharm, SVP of product marketing at DirecTV, said in a statement.&lt;/p&gt;
&lt;p&gt;The screensavers will also be able to show real-time weather and sports scores, Glance said.&lt;/p&gt;
&lt;h2&gt;A natural progression&lt;/h2&gt;
&lt;p&gt;Turning to ad-centric screensavers may frustrate customers who didn't expect ads when they bought into Gemini devices for their streaming capabilities.&lt;/p&gt;
&lt;p&gt;However, DirecTV has an expanding advertising business that has included experimenting with ad types, such as ads that show when people hit pause. As far as offensive ads go, screensaver ads can be considered less intrusive, since they typically show only when someone isn’t actively viewing their TV. Gemini screensavers can also be disabled.&lt;/p&gt;
&lt;p&gt;It has become increasingly important for DirecTV to diversify revenue beyond satellite and Internet subscriptions. DirecTV had over 20 million subscribers in 2015; in 2024, streaming business publication Next TV, citing an anonymous source “close to the company,” reported that the AT&amp;amp;T-owned firm was down to about 11 million subscribers.&lt;/p&gt;
&lt;p&gt;Simultaneously, the streaming industry—including streaming services and streaming software—has been increasingly relying on advertising to boost revenue. For some streaming service providers, increasing revenue through ads is starting to eclipse the pressure to do so through subscriber counts. Considering DirecTV's declining viewership and growing interest in streaming, finding more ways to sell ads seems like a natural progression.&lt;/p&gt;
&lt;p&gt;With legacy pay TV providers already dealing with dwindling subscriptions, introducing new types of ads risks making DirecTV less appealing as well.&lt;/p&gt;
&lt;p&gt;And it’s likely that things won’t end there.&lt;/p&gt;
&lt;p&gt;“This, we can integrate across different places within the television,” Glance COO Mansi Jain told The Verge. "We are starting with the screensaver, but tomorrow… we can integrate it in the launcher of the TV."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/10/directv-screensavers-will-show-ai-generated-ads-with-your-face-in-2026/</guid><pubDate>Tue, 14 Oct 2025 19:58:38 +0000</pubDate></item><item><title>Sam Altman says ChatGPT will soon allow erotica for adult users (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/14/sam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188251582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced in a post on X Tuesday the company will soon relax some of ChatGPT’s safety restrictions, allowing users to make the chatbot’s responses friendlier or more “human-like,” and for “verified adults” to engage in erotic conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right,” said Altman. “In December, as we roll out age-gating more fully and as part of our ‘treat adult users like adults’ principle, we will allow even more, like erotica for verified adults.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.&lt;/p&gt;&lt;p&gt;Now that we have…&lt;/p&gt;— Sam Altman (@sama) October 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement is a notable pivot from OpenAI’s months-long effort to address the concerning relationships that some mentally unstable users have developed with ChatGPT. Altman seems to declare an early victory over these problems, claiming OpenAI has “been able to mitigate the serious mental health issues” around ChatGPT. However, the company has provided little to no evidence for this, and is now plowing ahead with plans for ChatGPT to engage in sexual chats with users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Several concerning stories emerged this summer around ChatGPT, specifically its GPT-4o model, suggesting the AI chatbot could lead vulnerable users down delusional rabbit holes. In one case, ChatGPT seemed to convince a man he was a math genius who needed to save the world. In another, the parents of a teenager sued OpenAI, alleging ChatGPT encouraged their son’s suicidal ideations in the weeks leading up to his death.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response, OpenAI released a series of safety features to address AI sycophancy: the tendency for an AI chatbot to hook users by agreeing with whatever they say, even negative behaviors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched GPT-5 in August, a new AI model that exhibits lower rates of sycophancy and features a router that can identify concerning user behavior. A month later, OpenAI launched safety features for minors, including an age prediction system and a way for parents to control their teen’s ChatGPT account. OpenAI announced Tuesday the formation of an expert council of mental health professionals to advise the company on well-being and AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few months after these concerning stories emerged, OpenAI seems to think ChatGPT’s problems around vulnerable users are under control. It’s unclear whether users are still falling down delusional rabbit holes with GPT-5. And while GPT-4o is no longer the default in ChatGPT, the AI model is still available today and being used by thousands of people.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The introduction of erotica in ChatGPT is unchartered territory for OpenAI and raises broader concerns around how vulnerable users will interact with the new features. While Altman insists OpenAI isn’t “usage-maxxing” or optimizing for engagement, making ChatGPT more erotic could certainly draw users in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Allowing chatbots to engage in romantic or erotic role play has been an effective engagement strategy for other AI chatbot providers, such as Character.AI. The company has gained tens of millions of users, many of whom use its chatbots at a high rate. Character.AI said in 2023 that users spent an average of two hours a day talking to its chatbots. The company is also facing a lawsuit around how it handles vulnerable users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is under pressure to grow its user base. While ChatGPT is already used by 800 million weekly active users, OpenAI is racing against Google and Meta to build mass-adopted AI-powered consumer products. The company has also raised billions of dollars for a historic infrastructure buildout, an investment OpenAI eventually needs to pay back.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While adults are surely having romantic relationships with AI chatbots, it’s also quite popular for minors. A new report from the Center for Democracy and Technology found that 19% of high school students have either had a romantic relationship with an AI chatbot, or know a friend who has.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman says OpenAI will soon allow erotica for “verified adults.” An OpenAI spokesperson tells TechCrunch the company will rely on the age-prediction system it’s building to ensure that ChatGPT’s erotic features are only available to adult users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Altman previously wrote in a blog post, if OpenAI’s age-prediction system incorrectly marks an adult as a minor, ChatGPT users may have to upload a picture of their government-issued ID into ChatGPT to correct it. Altman writes that, though this is a privacy compromise, the company believes it’s a “worthy tradeoff.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It is unclear whether OpenAI will extend erotica to its AI voice, image, and video generation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman claims that OpenAI is also making ChatGPT friendlier and erotic because of the company’s “treat adult users like adults” principle. Over the last year, OpenAI has shifted towards a more lenient content moderation strategy for ChatGPT, allowing the chatbot to be more permissive and offer less refusals. In February, OpenAI pledged to represent more political viewpoints in ChatGPT, and in March, the company updated ChatGPT to allow AI-generated images of hate symbols.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These policies seem to be an attempt to make ChatGPT’s response more popular with a wide variety of users. However, vulnerable ChatGPT users may benefit from safeguards that limit what a chatbot can engage with. As OpenAI races towards a billion weekly active users, the tension between growth and protecting vulnerable users may only grow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update 10/14/25 at 4:40pm PT: This story has been updated to include comment from OpenAI.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188251582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced in a post on X Tuesday the company will soon relax some of ChatGPT’s safety restrictions, allowing users to make the chatbot’s responses friendlier or more “human-like,” and for “verified adults” to engage in erotic conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right,” said Altman. “In December, as we roll out age-gating more fully and as part of our ‘treat adult users like adults’ principle, we will allow even more, like erotica for verified adults.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.&lt;/p&gt;&lt;p&gt;Now that we have…&lt;/p&gt;— Sam Altman (@sama) October 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement is a notable pivot from OpenAI’s months-long effort to address the concerning relationships that some mentally unstable users have developed with ChatGPT. Altman seems to declare an early victory over these problems, claiming OpenAI has “been able to mitigate the serious mental health issues” around ChatGPT. However, the company has provided little to no evidence for this, and is now plowing ahead with plans for ChatGPT to engage in sexual chats with users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Several concerning stories emerged this summer around ChatGPT, specifically its GPT-4o model, suggesting the AI chatbot could lead vulnerable users down delusional rabbit holes. In one case, ChatGPT seemed to convince a man he was a math genius who needed to save the world. In another, the parents of a teenager sued OpenAI, alleging ChatGPT encouraged their son’s suicidal ideations in the weeks leading up to his death.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response, OpenAI released a series of safety features to address AI sycophancy: the tendency for an AI chatbot to hook users by agreeing with whatever they say, even negative behaviors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched GPT-5 in August, a new AI model that exhibits lower rates of sycophancy and features a router that can identify concerning user behavior. A month later, OpenAI launched safety features for minors, including an age prediction system and a way for parents to control their teen’s ChatGPT account. OpenAI announced Tuesday the formation of an expert council of mental health professionals to advise the company on well-being and AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few months after these concerning stories emerged, OpenAI seems to think ChatGPT’s problems around vulnerable users are under control. It’s unclear whether users are still falling down delusional rabbit holes with GPT-5. And while GPT-4o is no longer the default in ChatGPT, the AI model is still available today and being used by thousands of people.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The introduction of erotica in ChatGPT is unchartered territory for OpenAI and raises broader concerns around how vulnerable users will interact with the new features. While Altman insists OpenAI isn’t “usage-maxxing” or optimizing for engagement, making ChatGPT more erotic could certainly draw users in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Allowing chatbots to engage in romantic or erotic role play has been an effective engagement strategy for other AI chatbot providers, such as Character.AI. The company has gained tens of millions of users, many of whom use its chatbots at a high rate. Character.AI said in 2023 that users spent an average of two hours a day talking to its chatbots. The company is also facing a lawsuit around how it handles vulnerable users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is under pressure to grow its user base. While ChatGPT is already used by 800 million weekly active users, OpenAI is racing against Google and Meta to build mass-adopted AI-powered consumer products. The company has also raised billions of dollars for a historic infrastructure buildout, an investment OpenAI eventually needs to pay back.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While adults are surely having romantic relationships with AI chatbots, it’s also quite popular for minors. A new report from the Center for Democracy and Technology found that 19% of high school students have either had a romantic relationship with an AI chatbot, or know a friend who has.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman says OpenAI will soon allow erotica for “verified adults.” An OpenAI spokesperson tells TechCrunch the company will rely on the age-prediction system it’s building to ensure that ChatGPT’s erotic features are only available to adult users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Altman previously wrote in a blog post, if OpenAI’s age-prediction system incorrectly marks an adult as a minor, ChatGPT users may have to upload a picture of their government-issued ID into ChatGPT to correct it. Altman writes that, though this is a privacy compromise, the company believes it’s a “worthy tradeoff.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It is unclear whether OpenAI will extend erotica to its AI voice, image, and video generation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman claims that OpenAI is also making ChatGPT friendlier and erotic because of the company’s “treat adult users like adults” principle. Over the last year, OpenAI has shifted towards a more lenient content moderation strategy for ChatGPT, allowing the chatbot to be more permissive and offer less refusals. In February, OpenAI pledged to represent more political viewpoints in ChatGPT, and in March, the company updated ChatGPT to allow AI-generated images of hate symbols.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These policies seem to be an attempt to make ChatGPT’s response more popular with a wide variety of users. However, vulnerable ChatGPT users may benefit from safeguards that limit what a chatbot can engage with. As OpenAI races towards a billion weekly active users, the tension between growth and protecting vulnerable users may only grow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update 10/14/25 at 4:40pm PT: This story has been updated to include comment from OpenAI.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/14/sam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users/</guid><pubDate>Tue, 14 Oct 2025 20:51:51 +0000</pubDate></item><item><title>EAGLET boosts AI agent performance on longer-horizon tasks by generating custom plans (AI | VentureBeat)</title><link>https://venturebeat.com/ai/eaglet-boosts-ai-agent-performance-on-longer-horizon-tasks-by-generating</link><description>[unable to retrieve full-text content]&lt;p&gt;2025 was supposed to be&lt;a href="https://www.barrons.com/articles/nvidia-stock-ceo-ai-agents-8c20ddfb?gaa_at=eafs&amp;amp;gaa_n=ASWzDAjLKLIimw5qFdsG0kmEnu-fOoNZXVCdnBx-zn_CbT1hLgiWcYGxmHLDOvPxpV0%3D&amp;amp;gaa_ts=68eec9d8&amp;amp;gaa_sig=klyxA4QUo1K8AN8hu1LEL8i64tGtj_jKhoX1IWR32Fm06Aizm1ylHYCER9fv8FSpylAwqgIuRsbIeYlPFmAebA%3D%3D"&gt; the year of &amp;quot;AI agents,&amp;quot;&lt;/a&gt; according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://venturebeat.com/ai/googles-ai-can-now-surf-the-web-for-you-click-on-buttons-and-fill-out-forms"&gt;Google&lt;/a&gt;, and even Chinese competitors like &lt;a href="https://venturebeat.com/ai/the-deepseek-moment-for-ai-agents-is-here-meet-alibabas-open-source-tongyi"&gt;Alibaba releasing&lt;/a&gt; fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. &lt;/p&gt;&lt;p&gt;But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps.&lt;a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/"&gt; Third-party benchmark tests &lt;/a&gt;show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). &lt;/p&gt;&lt;p&gt;A &lt;a href="https://huggingface.co/papers/2510.05608"&gt;new academic framework called EAGLET&lt;/a&gt; proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. &lt;/p&gt;&lt;p&gt;Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign,&lt;b&gt; EAGLET offers a &amp;quot;global planner&amp;quot; that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&amp;#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Planning Problem in Long-Horizon Agents&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Many LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. &lt;/p&gt;&lt;p&gt;EAGLET tackles this limitation by introducing a &lt;b&gt;global planning module&lt;/b&gt; that works alongside the executor agent. &lt;/p&gt;&lt;p&gt;Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Two-Stage Training Pipeline with No Human Annotations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;EAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. &lt;/p&gt;&lt;p&gt;The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. &lt;/p&gt;&lt;p&gt;These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. &lt;/p&gt;&lt;p&gt;In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Introducing the Executor Capability Gain Reward (ECGR)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). &lt;/p&gt;&lt;p&gt;This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. &lt;/p&gt;&lt;p&gt;It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Compatible with Existing Agents and Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The EAGLET planner is designed to be modular and &amp;quot;plug-and-play,&amp;quot; meaning it can be inserted into existing agent pipelines without requiring executor retraining. &lt;/p&gt;&lt;p&gt;In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. &lt;/p&gt;&lt;p&gt;It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;State-of-the-Art Performance Across Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;EAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.&lt;/p&gt;&lt;p&gt;Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. &lt;/p&gt;&lt;p&gt;In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. &lt;/p&gt;&lt;p&gt;On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. &lt;/p&gt;&lt;p&gt;In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.&lt;/p&gt;&lt;p&gt;Even stronger gains were seen with more capable models. &lt;/p&gt;&lt;p&gt;For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. &lt;/p&gt;&lt;p&gt;In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.&lt;/p&gt;&lt;p&gt;Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.&lt;/p&gt;&lt;p&gt;Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Efficiency Gains in Training and Execution&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Compared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. &lt;/p&gt;&lt;p&gt;This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;No Public Code—Yet&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. &lt;/p&gt;&lt;p&gt;VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise Deployment Questions Remain&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. &lt;/p&gt;&lt;p&gt;Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.&lt;/p&gt;&lt;p&gt;EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Real-Time vs. Pre-Generated Planning&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strategic Tradeoffs for Enterprise Teams&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Potential Use Cases in Enterprise Settings&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;2025 was supposed to be&lt;a href="https://www.barrons.com/articles/nvidia-stock-ceo-ai-agents-8c20ddfb?gaa_at=eafs&amp;amp;gaa_n=ASWzDAjLKLIimw5qFdsG0kmEnu-fOoNZXVCdnBx-zn_CbT1hLgiWcYGxmHLDOvPxpV0%3D&amp;amp;gaa_ts=68eec9d8&amp;amp;gaa_sig=klyxA4QUo1K8AN8hu1LEL8i64tGtj_jKhoX1IWR32Fm06Aizm1ylHYCER9fv8FSpylAwqgIuRsbIeYlPFmAebA%3D%3D"&gt; the year of &amp;quot;AI agents,&amp;quot;&lt;/a&gt; according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://venturebeat.com/ai/googles-ai-can-now-surf-the-web-for-you-click-on-buttons-and-fill-out-forms"&gt;Google&lt;/a&gt;, and even Chinese competitors like &lt;a href="https://venturebeat.com/ai/the-deepseek-moment-for-ai-agents-is-here-meet-alibabas-open-source-tongyi"&gt;Alibaba releasing&lt;/a&gt; fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. &lt;/p&gt;&lt;p&gt;But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps.&lt;a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/"&gt; Third-party benchmark tests &lt;/a&gt;show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). &lt;/p&gt;&lt;p&gt;A &lt;a href="https://huggingface.co/papers/2510.05608"&gt;new academic framework called EAGLET&lt;/a&gt; proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. &lt;/p&gt;&lt;p&gt;Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign,&lt;b&gt; EAGLET offers a &amp;quot;global planner&amp;quot; that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&amp;#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Planning Problem in Long-Horizon Agents&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Many LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. &lt;/p&gt;&lt;p&gt;EAGLET tackles this limitation by introducing a &lt;b&gt;global planning module&lt;/b&gt; that works alongside the executor agent. &lt;/p&gt;&lt;p&gt;Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Two-Stage Training Pipeline with No Human Annotations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;EAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. &lt;/p&gt;&lt;p&gt;The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. &lt;/p&gt;&lt;p&gt;These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. &lt;/p&gt;&lt;p&gt;In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Introducing the Executor Capability Gain Reward (ECGR)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). &lt;/p&gt;&lt;p&gt;This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. &lt;/p&gt;&lt;p&gt;It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Compatible with Existing Agents and Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The EAGLET planner is designed to be modular and &amp;quot;plug-and-play,&amp;quot; meaning it can be inserted into existing agent pipelines without requiring executor retraining. &lt;/p&gt;&lt;p&gt;In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. &lt;/p&gt;&lt;p&gt;It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;State-of-the-Art Performance Across Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;EAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.&lt;/p&gt;&lt;p&gt;Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. &lt;/p&gt;&lt;p&gt;In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. &lt;/p&gt;&lt;p&gt;On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. &lt;/p&gt;&lt;p&gt;In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.&lt;/p&gt;&lt;p&gt;Even stronger gains were seen with more capable models. &lt;/p&gt;&lt;p&gt;For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. &lt;/p&gt;&lt;p&gt;In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.&lt;/p&gt;&lt;p&gt;Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.&lt;/p&gt;&lt;p&gt;Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Efficiency Gains in Training and Execution&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Compared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. &lt;/p&gt;&lt;p&gt;This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;No Public Code—Yet&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. &lt;/p&gt;&lt;p&gt;VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise Deployment Questions Remain&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. &lt;/p&gt;&lt;p&gt;Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.&lt;/p&gt;&lt;p&gt;EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Real-Time vs. Pre-Generated Planning&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strategic Tradeoffs for Enterprise Teams&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Potential Use Cases in Enterprise Settings&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/eaglet-boosts-ai-agent-performance-on-longer-horizon-tasks-by-generating</guid><pubDate>Tue, 14 Oct 2025 22:27:00 +0000</pubDate></item><item><title>[NEW] OpenAI has five years to turn $13 billion into $1 trillion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/14/openai-has-five-years-to-turn-13-billion-into-1-trillion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181602.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is printing money right now. The company is pulling in roughly $13 billion in annual revenue, with 70% coming from everyday people paying $20 a month to chat with an AI, according to the Financial Times. That’s pretty wild when you consider ChatGPT has 800 million regular users,  but only 5% are actually paying subscribers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raking in billions though it may be, OpenAI has also committed to spending over $1 trillion over the next decade (yes, trillion). The company has recently locked in deals for more than 26 gigawatts of computing capacity from Oracle, Nvidia, AMD, and Broadcom — infrastructure that’ll cost vastly more than what’s coming in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To bridge this gap, OpenAI is getting creative, reports the FT. A five-year-plan includes exploring government contracts, shopping tools, video services, consumer hardware, and even becoming a computing supplier itself through its Stargate data center project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A growing number of businesses need to math to work out. Some of America’s most valuable companies are now leaning on OpenAI to fulfill major contracts, notes the FT; if OpenAI falters (no pressure!), it could potentially destabilize the broader U.S. market.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181602.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is printing money right now. The company is pulling in roughly $13 billion in annual revenue, with 70% coming from everyday people paying $20 a month to chat with an AI, according to the Financial Times. That’s pretty wild when you consider ChatGPT has 800 million regular users,  but only 5% are actually paying subscribers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raking in billions though it may be, OpenAI has also committed to spending over $1 trillion over the next decade (yes, trillion). The company has recently locked in deals for more than 26 gigawatts of computing capacity from Oracle, Nvidia, AMD, and Broadcom — infrastructure that’ll cost vastly more than what’s coming in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To bridge this gap, OpenAI is getting creative, reports the FT. A five-year-plan includes exploring government contracts, shopping tools, video services, consumer hardware, and even becoming a computing supplier itself through its Stargate data center project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A growing number of businesses need to math to work out. Some of America’s most valuable companies are now leaning on OpenAI to fulfill major contracts, notes the FT; if OpenAI falters (no pressure!), it could potentially destabilize the broader U.S. market.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/14/openai-has-five-years-to-turn-13-billion-into-1-trillion/</guid><pubDate>Wed, 15 Oct 2025 05:39:36 +0000</pubDate></item></channel></rss>