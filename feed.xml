<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 16 Feb 2026 02:29:34 +0000</lastBuildDate><item><title> ()</title><link>https://arstechnica.com/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/feed/</guid></item><item><title>Hollywood isn’t happy about the new Seedance 2.0 video generator (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1263876301.jpeg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hollywood organizations are pushing back against a new AI video model called Seedance 2.0, which they say has quickly become a tool for “blatant” copyright infringement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ByteDance, the Chinese company that recently finalized a deal to sell TikTok’s U.S. operations (it retains a stake in the new joint venture), launched Seedance 2.0 earlier this week.&amp;nbsp; According to the Wall Street Journal, the updated model is currently available to Chinese users of ByteDance’s Jianying app, and the company says it will soon be available to global users of its CapCut app.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to tools such as OpenAI’s Sora, Seedance allows users to create videos (currently limited to 15 seconds in length) by just entering a text prompt. And like Sora, Seedance quickly drew criticism for an apparent lack of guardrails around the ability to create videos using the likeness of real people, as well as studios’ intellectual property.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After one X user posted a brief video showing Tom Cruise fighting Brad Pitt, which they said was created by “a 2 line prompt in seedance 2,” “Deadpool” screenwriter Rhett Reese responded, “I hate to say it. It’s likely over for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Motion Picture Association soon issued a statement from CEO Charles Rivkin demanding that ByteDance “immediately cease its infringing activity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of U.S. copyrighted works on a massive scale,” Rivkin said. “By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Human Artistry Campaign — an initiative backed by Hollywood unions and trade groups — condemned Seedance 2.0 as “an attack on every creator around the world,” while the actors’ union SAG-AFTRA said it “stands with the studios in condemning the blatant infringement enabled by Bytedance’s new AI video model Seedance 2.0.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Seedance videos have apparently featured Disney-owned characters such as Spider-Man, Darth Vader, and Grogu, better known as Baby Yoda, prompting the company to take legal action. Axios reports that Disney has sent a cease-and-desist letter accusing ByteDance of a “virtual smash-and-grab of Disney’s IP”and claiming the Chinese company is “hijacking Disney’s characters by reproducing, distributing, and creating derivative works featuring those characters.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney isn’t necessarily opposed to working with AI companies — while it has reportedly sent a cease-and-desist letter to Google over similar issues, it has signed a three-year licensing deal with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Variety reports that Paramount followed suit by sending Bytedance a cease-and-desist letter on Saturday. The letter claimed that “much of the content that the Seed Platforms produce contains vivid depictions of Paramount’s famous and iconic franchises and characters” and that this content “is often indistinguishable, both visually and audibly” from Paramount’s films and TV shows.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to ByteDance for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was originally published on February 14, 2026. It has been updated to include information about Paramount’s cease-and-desist letter.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1263876301.jpeg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hollywood organizations are pushing back against a new AI video model called Seedance 2.0, which they say has quickly become a tool for “blatant” copyright infringement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ByteDance, the Chinese company that recently finalized a deal to sell TikTok’s U.S. operations (it retains a stake in the new joint venture), launched Seedance 2.0 earlier this week.&amp;nbsp; According to the Wall Street Journal, the updated model is currently available to Chinese users of ByteDance’s Jianying app, and the company says it will soon be available to global users of its CapCut app.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to tools such as OpenAI’s Sora, Seedance allows users to create videos (currently limited to 15 seconds in length) by just entering a text prompt. And like Sora, Seedance quickly drew criticism for an apparent lack of guardrails around the ability to create videos using the likeness of real people, as well as studios’ intellectual property.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After one X user posted a brief video showing Tom Cruise fighting Brad Pitt, which they said was created by “a 2 line prompt in seedance 2,” “Deadpool” screenwriter Rhett Reese responded, “I hate to say it. It’s likely over for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Motion Picture Association soon issued a statement from CEO Charles Rivkin demanding that ByteDance “immediately cease its infringing activity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of U.S. copyrighted works on a massive scale,” Rivkin said. “By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Human Artistry Campaign — an initiative backed by Hollywood unions and trade groups — condemned Seedance 2.0 as “an attack on every creator around the world,” while the actors’ union SAG-AFTRA said it “stands with the studios in condemning the blatant infringement enabled by Bytedance’s new AI video model Seedance 2.0.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Seedance videos have apparently featured Disney-owned characters such as Spider-Man, Darth Vader, and Grogu, better known as Baby Yoda, prompting the company to take legal action. Axios reports that Disney has sent a cease-and-desist letter accusing ByteDance of a “virtual smash-and-grab of Disney’s IP”and claiming the Chinese company is “hijacking Disney’s characters by reproducing, distributing, and creating derivative works featuring those characters.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney isn’t necessarily opposed to working with AI companies — while it has reportedly sent a cease-and-desist letter to Google over similar issues, it has signed a three-year licensing deal with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Variety reports that Paramount followed suit by sending Bytedance a cease-and-desist letter on Saturday. The letter claimed that “much of the content that the Seed Platforms produce contains vivid depictions of Paramount’s famous and iconic franchises and characters” and that this content “is often indistinguishable, both visually and audibly” from Paramount’s films and TV shows.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to ByteDance for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was originally published on February 14, 2026. It has been updated to include information about Paramount’s cease-and-desist letter.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/</guid><pubDate>Sun, 15 Feb 2026 15:41:16 +0000</pubDate></item><item><title>The enterprise AI land grab is on. Glean is building the layer beneath the interface. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2259183688.jpg?w=1024" /&gt;&lt;/div&gt;&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt;
&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The battle for enterprise AI is heating up. Microsoft is bundling Copilot into Office. Google is pushing Gemini into Workspace. OpenAI and Anthropic are selling directly to enterprises. Every SaaS vendor now ships an AI assistant.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In the scramble for the interface, Glean is betting on something less visible: becoming the intelligence layer beneath it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seven years ago, Glean set out to be the Google for enterprise — an AI-powered search tool designed to index and search across a company’s SaaS tool library, from Slack to Jira, Google Drive to Salesforce. Today, the company’s strategy has shifted from building a better enterprise chatbot to becoming the connective tissue between models and enterprise systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The layer we built initially – a good search product – required us to deeply understand people and how they work and what their preferences are,” Jain told TechCrunch on last week’s episode of Equity, which we recorded at Web Summit Qatar. “All of that is now becoming foundational in terms of building high quality agents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He says that while large language models are powerful, they’re also generic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The AI models themselves don’t really understand anything about your business,” Jain said. “They don’t know who the different people are, they don’t know what kind of work you do, what kind of products you build. So you have to connect the reasoning and generative power of the models with the context inside your company.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glean’s pitch is that it already maps that context and can sit between the model and the enterprise data.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Glean Assistant is often the entry point for customers — a familiar chat interface powered by a mix of leading proprietary (ie, ChatGPT, Gemini, Claude) and open-source models, grounded in the company’s internal data. But what keeps customers, Jain argues, is everything underneath it.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;First is model access. Rather than forcing companies to commit to a single LLM provider, Glean acts as the abstraction layer, allowing enterprises to switch between or combine models as capabilities evolve. That’s why Jain says he doesn’t see OpenAI, Anthropic, or Google as competition, but rather as partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our product gets better because we’re able to leverage the innovation that they are making in the market,” Jain said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Second are the connectors. Glean integrates deeply with systems like Slack, Jira, Salesforce, and Google Drive to map how information flows across them and enable agents to act inside those tools.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And third, and perhaps most important, is governance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You need to build a permissions-aware governance layer and retrieval layer that is able to bring the right information, but knowing who’s asking that question so that it filters the information based on their access rights,” Jain said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In large organizations, that layer can be the difference between piloting AI solutions and deploying them at scale. Enterprises can’t simply load all their internal data into a model and create a wrapper to sort out the solutions later, says Jain.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also critical is ensuring the models don’t hallucinate. Jain says its system verifies model outputs against source documents, generates line-by-line citations, and ensures that responses respect existing access rights.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether that middle layer survives as platform giants push deeper into the stack. Microsoft and Google already control much of the enterprise workflow surface area, and they’re hungry for more. If Copilot or Gemini can access the same internal systems with the same permissions, does a standalone intelligence layer still matter?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jain argues enterprises don’t want to be locked into a single model or productivity suite and would rather opt for a neutral infrastructure layer rather than a vertically integrated assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors have bought into that thesis. Glean raised a $150 million Series F in June 2025, nearly doubling its valuation to $7.2 billion. Unlike the frontier AI labs, Glean doesn’t need massive compute budgets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a very healthy, fast-growing business,” Jain said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2259183688.jpg?w=1024" /&gt;&lt;/div&gt;&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt;
&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The battle for enterprise AI is heating up. Microsoft is bundling Copilot into Office. Google is pushing Gemini into Workspace. OpenAI and Anthropic are selling directly to enterprises. Every SaaS vendor now ships an AI assistant.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In the scramble for the interface, Glean is betting on something less visible: becoming the intelligence layer beneath it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seven years ago, Glean set out to be the Google for enterprise — an AI-powered search tool designed to index and search across a company’s SaaS tool library, from Slack to Jira, Google Drive to Salesforce. Today, the company’s strategy has shifted from building a better enterprise chatbot to becoming the connective tissue between models and enterprise systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The layer we built initially – a good search product – required us to deeply understand people and how they work and what their preferences are,” Jain told TechCrunch on last week’s episode of Equity, which we recorded at Web Summit Qatar. “All of that is now becoming foundational in terms of building high quality agents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He says that while large language models are powerful, they’re also generic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The AI models themselves don’t really understand anything about your business,” Jain said. “They don’t know who the different people are, they don’t know what kind of work you do, what kind of products you build. So you have to connect the reasoning and generative power of the models with the context inside your company.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glean’s pitch is that it already maps that context and can sit between the model and the enterprise data.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Glean Assistant is often the entry point for customers — a familiar chat interface powered by a mix of leading proprietary (ie, ChatGPT, Gemini, Claude) and open-source models, grounded in the company’s internal data. But what keeps customers, Jain argues, is everything underneath it.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;First is model access. Rather than forcing companies to commit to a single LLM provider, Glean acts as the abstraction layer, allowing enterprises to switch between or combine models as capabilities evolve. That’s why Jain says he doesn’t see OpenAI, Anthropic, or Google as competition, but rather as partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our product gets better because we’re able to leverage the innovation that they are making in the market,” Jain said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Second are the connectors. Glean integrates deeply with systems like Slack, Jira, Salesforce, and Google Drive to map how information flows across them and enable agents to act inside those tools.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And third, and perhaps most important, is governance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You need to build a permissions-aware governance layer and retrieval layer that is able to bring the right information, but knowing who’s asking that question so that it filters the information based on their access rights,” Jain said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In large organizations, that layer can be the difference between piloting AI solutions and deploying them at scale. Enterprises can’t simply load all their internal data into a model and create a wrapper to sort out the solutions later, says Jain.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also critical is ensuring the models don’t hallucinate. Jain says its system verifies model outputs against source documents, generates line-by-line citations, and ensures that responses respect existing access rights.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether that middle layer survives as platform giants push deeper into the stack. Microsoft and Google already control much of the enterprise workflow surface area, and they’re hungry for more. If Copilot or Gemini can access the same internal systems with the same permissions, does a standalone intelligence layer still matter?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jain argues enterprises don’t want to be locked into a single model or productivity suite and would rather opt for a neutral infrastructure layer rather than a vertically integrated assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors have bought into that thesis. Glean raised a $150 million Series F in June 2025, nearly doubling its valuation to $7.2 billion. Unlike the frontier AI labs, Glean doesn’t need massive compute budgets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a very healthy, fast-growing business,” Jain said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/</guid><pubDate>Sun, 15 Feb 2026 17:30:00 +0000</pubDate></item><item><title>[NEW] India has 100M weekly active ChatGPT users, Sam Altman says (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/india-has-100m-weekly-active-chatgpt-users-sam-altman-says/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/chatgpt-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;India has 100 million weekly active ChatGPT users, making the country one of OpenAI’s largest markets globally, CEO Sam Altman said ahead of a government-hosted AI summit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Sunday, Altman outlined ChatGPT’s growing adoption in India in an article published in the Indian English daily Times of India, as OpenAI prepares to formally participate in the five-day India AI Impact Summit in New Delhi, beginning Monday. Altman is attending the event alongside senior executives from several of the world’s leading AI companies.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The growth comes as OpenAI, like other leading AI firms, looks to India’s young population and its more than a billion internet users to fuel global expansion. The ChatGPT maker opened a New Delhi office in August 2025 after months of groundwork in the country, and has adjusted its approach for India’s price-sensitive market, including rolling out a sub-$5 ChatGPT Go tier that was later made free for a year for Indian users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the article, Altman said India is ChatGPT’s second-largest user base after the United States, highlighting the South Asian nation’s growing weight in OpenAI’s global strategy. The disclosure comes as ChatGPT’s overall usage has surged worldwide, with the platform reaching 800 million weekly active users as of October 2025 and reported to be approaching 900 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also highlighted the role of students in driving adoption, saying India has the largest number of student users of ChatGPT globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indian students have become a key growth segment for leading AI companies more broadly, as rivals race to embed their tools in classrooms and learning workflows. Google has similarly targeted the market, offering Indian students a free one-year subscription to its AI Pro plan in September 2025. Separately, India accounts for the highest global usage of Gemini for learning, Chris Phillips, Google’s vice president and general manager for education, said last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With its focus on access, practical Al literacy, and the infrastructure that supports widespread adoption, India is well positioned to broaden who benefits from the technology and to help shape how democratic AI is adopted at scale,” Altman wrote.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth also highlights a broader challenge for AI companies in India: translating widespread adoption into sustained economic impact. Indian government initiatives such as the IndiaAI Mission — a national program aimed at expanding computing capacity, supporting startups and accelerating AI adoption in public services — seek to address those gaps. However, the country’s price-sensitive market and infrastructure constraints have made monetization and large-scale deployment more complex than in developed economies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Given India’s size, it also risks forfeiting a vital opportunity to advance democratic AI in emerging markets around the world,” Altman wrote, warning that uneven access and adoption could concentrate AI’s economic gains in too few hands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also signaled that OpenAI plans to deepen its engagement with the Indian government, writing that the company would soon announce new partnerships aimed at expanding access to AI across the country. He did not provide details, but said the focus would be on widening reach and enabling more people to put AI tools to practical use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The India AI Impact Summit is expected to draw a wide cross-section of global technology and political leaders, including Anthropic CEO Dario Amodei, Sundar Pichai of Google, and senior Indian business figures such as Mukesh Ambani and Nandan Nilekani. Political leaders including Emmanuel Macron, Sheikh Khaled bin Mohamed bin Zayed Al Nahyan, and Luiz Inácio Lula da Silva are also expected to attend, spotlighting India’s ambition to position itself as a central player in global AI debates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For global AI firms, including OpenAI, the summit underscores how India’s vast user base is translating into growing influence over how the technology evolves.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/chatgpt-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;India has 100 million weekly active ChatGPT users, making the country one of OpenAI’s largest markets globally, CEO Sam Altman said ahead of a government-hosted AI summit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Sunday, Altman outlined ChatGPT’s growing adoption in India in an article published in the Indian English daily Times of India, as OpenAI prepares to formally participate in the five-day India AI Impact Summit in New Delhi, beginning Monday. Altman is attending the event alongside senior executives from several of the world’s leading AI companies.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The growth comes as OpenAI, like other leading AI firms, looks to India’s young population and its more than a billion internet users to fuel global expansion. The ChatGPT maker opened a New Delhi office in August 2025 after months of groundwork in the country, and has adjusted its approach for India’s price-sensitive market, including rolling out a sub-$5 ChatGPT Go tier that was later made free for a year for Indian users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the article, Altman said India is ChatGPT’s second-largest user base after the United States, highlighting the South Asian nation’s growing weight in OpenAI’s global strategy. The disclosure comes as ChatGPT’s overall usage has surged worldwide, with the platform reaching 800 million weekly active users as of October 2025 and reported to be approaching 900 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also highlighted the role of students in driving adoption, saying India has the largest number of student users of ChatGPT globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indian students have become a key growth segment for leading AI companies more broadly, as rivals race to embed their tools in classrooms and learning workflows. Google has similarly targeted the market, offering Indian students a free one-year subscription to its AI Pro plan in September 2025. Separately, India accounts for the highest global usage of Gemini for learning, Chris Phillips, Google’s vice president and general manager for education, said last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With its focus on access, practical Al literacy, and the infrastructure that supports widespread adoption, India is well positioned to broaden who benefits from the technology and to help shape how democratic AI is adopted at scale,” Altman wrote.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth also highlights a broader challenge for AI companies in India: translating widespread adoption into sustained economic impact. Indian government initiatives such as the IndiaAI Mission — a national program aimed at expanding computing capacity, supporting startups and accelerating AI adoption in public services — seek to address those gaps. However, the country’s price-sensitive market and infrastructure constraints have made monetization and large-scale deployment more complex than in developed economies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Given India’s size, it also risks forfeiting a vital opportunity to advance democratic AI in emerging markets around the world,” Altman wrote, warning that uneven access and adoption could concentrate AI’s economic gains in too few hands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also signaled that OpenAI plans to deepen its engagement with the Indian government, writing that the company would soon announce new partnerships aimed at expanding access to AI across the country. He did not provide details, but said the focus would be on widening reach and enabling more people to put AI tools to practical use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The India AI Impact Summit is expected to draw a wide cross-section of global technology and political leaders, including Anthropic CEO Dario Amodei, Sundar Pichai of Google, and senior Indian business figures such as Mukesh Ambani and Nandan Nilekani. Political leaders including Emmanuel Macron, Sheikh Khaled bin Mohamed bin Zayed Al Nahyan, and Luiz Inácio Lula da Silva are also expected to attend, spotlighting India’s ambition to position itself as a central player in global AI debates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For global AI firms, including OpenAI, the summit underscores how India’s vast user base is translating into growing influence over how the technology evolves.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/india-has-100m-weekly-active-chatgpt-users-sam-altman-says/</guid><pubDate>Sun, 15 Feb 2026 18:00:00 +0000</pubDate></item><item><title>[NEW] Anthropic and the Pentagon are reportedly arguing over Claude usage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/</guid><pubDate>Sun, 15 Feb 2026 21:11:28 +0000</pubDate></item><item><title>[NEW] Longtime NPR host David Greene sues Google over NotebookLM voice (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;David Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, &amp;amp; Center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other features, Google’s NotebookLM allows users to generate a podcast with AI hosts. A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;David Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, &amp;amp; Center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other features, Google’s NotebookLM allows users to generate a podcast with AI hosts. A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/</guid><pubDate>Sun, 15 Feb 2026 22:07:51 +0000</pubDate></item><item><title>[NEW] OpenClaw creator Peter Steinberger joins OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?resize=1200,839" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Peter Steinberger, who created the AI personal assistant now known as OpenClaw, has joined OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants. (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?resize=1200,839" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Peter Steinberger, who created the AI personal assistant now known as OpenClaw, has joined OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants. (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</guid><pubDate>Sun, 15 Feb 2026 22:28:02 +0000</pubDate></item><item><title>[NEW] Blackstone backs Neysa in up to $1.2B financing as India pushes to build domestic AI infrastructure (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackstone and co-investors, including Teachers’ Venture Growth, TVS Capital, 360 ONE Assets, and Nexus Venture Partners, have agreed to invest up to $600 million of primary equity in Neysa, giving Blackstone a majority stake, Blackstone and Neysa told TechCrunch. The Mumbai-headquartered startup also plans to raise an additional $600 million in debt financing as it expands GPU capacity, a sharp increase from the $50 million it had raised previously.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal comes as demand for AI computing surges globally, creating supply constraints for specialized chips and data center capacity needed to train and run large models. Newer AI-focused infrastructure providers — often referred to as “neo-clouds” — have emerged to bridge that gap by offering dedicated GPU capacity and faster deployment than traditional hyperscalers, particularly for enterprises and AI labs with specific regulatory, latency, or customisation requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa operates in this emerging segment, positioning itself as a provider of customized, GPU-first infrastructure for enterprises, government agencies, and AI developers in India, where demand for local compute is still at an early but rapidly expanding stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of customers want hand-holding, and a lot of them want round-the-clock support with a 15-minute response and a couple of our resolutions. And so those are the kinds of things that we provide that some of the hyperscalers don’t,” said Neysa co-founder and CEO Sharad Sanghi.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093253" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/neysa-co-founder-ceo-sharad-sanghi.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nesya co-founder and CEO Sharad Sanghi&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Neysa&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ganesh Mani, a senior managing director at Blackstone Private Equity, said his firm estimates that India currently has fewer than 60,000 GPUs deployed — and it expects the figure to scale up nearly 30 times to more than two million in the coming years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That expansion is being driven by a combination of government demand, enterprises in regulated sectors such as financial services and healthcare that need to keep data local, and AI developers building models within India, Mani told TechCrunch. Global AI labs, many of which count India among their largest user bases, are also increasingly looking to deploy computing capacity closer to users to reduce latency and meet data requirements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The investment also builds on Blackstone’s broader push into data center and AI infrastructure globally. The firm has previously backed large-scale data centre platforms such as QTS and AirTrunk, as well as specialized AI infrastructure providers including CoreWeave in the U.S. and Firmus in Australia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa develops and operates GPU-based AI infrastructure that enables enterprises, researchers, and public sector clients to train, fine-tune, and deploy AI models locally. The startup currently has about 1,200 GPUs live and plans to sharply scale that capacity, targeting deployments of more than 20,000 GPUs over time as customer demand accelerates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are seeing a demand that we are going to more than triple our capacity next year,” Sanghi said. “Some of the conversations we are having are at a fairly advanced stage; if they go through, then we could see it sooner rather than later. We could see in the next nine months.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sanghi told TechCrunch that the bulk of the new capital will be used to deploy large-scale GPU clusters, including compute, networking and storage, while a smaller portion will go toward research and development and building out Neysa’s software platforms for orchestration, observability, and security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa aims to more than triple its revenue next year as demand for AI workloads accelerates, with ambitions to expand beyond India over time, Sanghi said. Founded in 2023, the startup employs 110 people across offices in Mumbai, Bengaluru, and Chennai.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackstone and co-investors, including Teachers’ Venture Growth, TVS Capital, 360 ONE Assets, and Nexus Venture Partners, have agreed to invest up to $600 million of primary equity in Neysa, giving Blackstone a majority stake, Blackstone and Neysa told TechCrunch. The Mumbai-headquartered startup also plans to raise an additional $600 million in debt financing as it expands GPU capacity, a sharp increase from the $50 million it had raised previously.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal comes as demand for AI computing surges globally, creating supply constraints for specialized chips and data center capacity needed to train and run large models. Newer AI-focused infrastructure providers — often referred to as “neo-clouds” — have emerged to bridge that gap by offering dedicated GPU capacity and faster deployment than traditional hyperscalers, particularly for enterprises and AI labs with specific regulatory, latency, or customisation requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa operates in this emerging segment, positioning itself as a provider of customized, GPU-first infrastructure for enterprises, government agencies, and AI developers in India, where demand for local compute is still at an early but rapidly expanding stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of customers want hand-holding, and a lot of them want round-the-clock support with a 15-minute response and a couple of our resolutions. And so those are the kinds of things that we provide that some of the hyperscalers don’t,” said Neysa co-founder and CEO Sharad Sanghi.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093253" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/neysa-co-founder-ceo-sharad-sanghi.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nesya co-founder and CEO Sharad Sanghi&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Neysa&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ganesh Mani, a senior managing director at Blackstone Private Equity, said his firm estimates that India currently has fewer than 60,000 GPUs deployed — and it expects the figure to scale up nearly 30 times to more than two million in the coming years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That expansion is being driven by a combination of government demand, enterprises in regulated sectors such as financial services and healthcare that need to keep data local, and AI developers building models within India, Mani told TechCrunch. Global AI labs, many of which count India among their largest user bases, are also increasingly looking to deploy computing capacity closer to users to reduce latency and meet data requirements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The investment also builds on Blackstone’s broader push into data center and AI infrastructure globally. The firm has previously backed large-scale data centre platforms such as QTS and AirTrunk, as well as specialized AI infrastructure providers including CoreWeave in the U.S. and Firmus in Australia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa develops and operates GPU-based AI infrastructure that enables enterprises, researchers, and public sector clients to train, fine-tune, and deploy AI models locally. The startup currently has about 1,200 GPUs live and plans to sharply scale that capacity, targeting deployments of more than 20,000 GPUs over time as customer demand accelerates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are seeing a demand that we are going to more than triple our capacity next year,” Sanghi said. “Some of the conversations we are having are at a fairly advanced stage; if they go through, then we could see it sooner rather than later. We could see in the next nine months.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sanghi told TechCrunch that the bulk of the new capital will be used to deploy large-scale GPU clusters, including compute, networking and storage, while a smaller portion will go toward research and development and building out Neysa’s software platforms for orchestration, observability, and security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa aims to more than triple its revenue next year as demand for AI workloads accelerates, with ambitions to expand beyond India over time, Sanghi said. Founded in 2023, the startup employs 110 people across offices in Mumbai, Bengaluru, and Chennai.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</guid><pubDate>Mon, 16 Feb 2026 00:30:00 +0000</pubDate></item><item><title>[NEW] As AI data centers hit power limits, Peak XV backs Indian startup C2i to fix the bottleneck (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Power, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play, system-level power solutions designed to cut energy losses and improve the economics of large-scale AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;C2i (which stands for control conversion and intelligence) has raised $15 million in a Series A round led by Peak XV Partners, with participation from Yali Deeptech and TDK Ventures, bringing the two-year-old startup’s total funding to $19 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The investment comes as data-center energy demand accelerates worldwide. Electricity consumption from data centers is projected to nearly triple by 2035, per a December 2025 report from BloombergNEF, while Goldman Sachs Research estimates data-center power demand could surge 175% by 2030 from 2023 levels — the equivalent of adding another top-10 power-consuming country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that strain comes not from generating electricity but from converting it efficiently inside data centers, where high-voltage power must be stepped down thousands of times before it reaches GPUs. This process currently wastes about 15% to 20% of energy, C2i’s co-founder and CTO Preetam Tadeparthy said in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What used to be 400 volts has already moved to 800 volts, and will likely go higher,” Tadeparthy told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2024 by former Texas Instruments power executives Ram Anant, Vikram Gakhar, Preetam Tadeparthy, and Dattatreya Suryanarayana, along with Harsha S. B and Muthusubramanian N. V, C2i is redesigning power delivery as a single, plug-and-play “grid-to-GPU” system spanning the data-center bus to the processor itself.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093188" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/c2i-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;C2i co-founders Vikram Gakhar, Preetam Tadeparthy, Ram Anant, and Dattatreya Suryanarayana (Left to right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;C2i&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;By treating power conversion, control and packaging as an integrated platform, C2i estimates it can cut end-to-end losses by around 10% — roughly 100 kilowatts saved for every megawatt consumed — with knock-on effects for cooling costs, GPU utilisation and overall data-center economics.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“All that translates directly to total cost of ownership, revenue, and profitability,” Tadeparthy said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Peak XV Partners (which split from Sequoia Capital in 2023), the attraction lies in how power costs shape the economics of AI infrastructure at scale. Rajan Anandan, the venture firm’s managing director, told TechCrunch that after the upfront capital investment in servers and facilities, energy costs become the dominant ongoing expense for data centers, making even incremental efficiency gains highly valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you can reduce energy costs by, call it, 10 to 30%, that’s like a huge number,” Anandan said. “You’re talking about tens of billions of dollars.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The claims will be tested quickly. C2i expects its first two silicon designs to return from fabrication between April and June, after which the startup plans to validate performance with data-center operators and hyperscalers that have asked to review the data, according to Tadeparthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Bengaluru-based startup has built a team of about 65 engineers and is setting up customer-facing operations in the U.S. and Taiwan as it prepares for early deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Power delivery is one of the most entrenched parts of the data-center stack, long dominated by large incumbents with deep balance sheets and years-long qualification cycles. While many newer companies focus on improving individual components, redesigning power delivery end-to-end requires coordinating silicon, packaging, and system architecture simultaneously — a capital-intensive approach that few startups attempt and one that can take years to prove in production environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anandan said the real question now is execution, noting that all startups face technology, market, and team risks when betting on how industries evolve. In C2i’s case, he said, the feedback loop should be relatively short. “We’ll know in the next six months,” said Anandan, pointing to upcoming silicon and early customer validation as the moment when the thesis will be tested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bet also reflects how India’s semiconductor design ecosystem has matured in recent years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way you should look at semiconductors in India is, this is like 2008 e-commerce,” said Anandan. “It’s just getting started.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He pointed to the depth of engineering talent — with a growing share of global chip designers based in the country — alongside government-backed design-linked incentives that have lowered the cost and risk of tape-outs, making it increasingly viable for startups to build globally competitive semiconductor products from India rather than operate only as captive design centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether those conditions translate into a globally competitive product will become clearer over the coming months, as C2i begins validating its system-level power solutions with customers.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Power, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play, system-level power solutions designed to cut energy losses and improve the economics of large-scale AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;C2i (which stands for control conversion and intelligence) has raised $15 million in a Series A round led by Peak XV Partners, with participation from Yali Deeptech and TDK Ventures, bringing the two-year-old startup’s total funding to $19 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The investment comes as data-center energy demand accelerates worldwide. Electricity consumption from data centers is projected to nearly triple by 2035, per a December 2025 report from BloombergNEF, while Goldman Sachs Research estimates data-center power demand could surge 175% by 2030 from 2023 levels — the equivalent of adding another top-10 power-consuming country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that strain comes not from generating electricity but from converting it efficiently inside data centers, where high-voltage power must be stepped down thousands of times before it reaches GPUs. This process currently wastes about 15% to 20% of energy, C2i’s co-founder and CTO Preetam Tadeparthy said in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What used to be 400 volts has already moved to 800 volts, and will likely go higher,” Tadeparthy told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2024 by former Texas Instruments power executives Ram Anant, Vikram Gakhar, Preetam Tadeparthy, and Dattatreya Suryanarayana, along with Harsha S. B and Muthusubramanian N. V, C2i is redesigning power delivery as a single, plug-and-play “grid-to-GPU” system spanning the data-center bus to the processor itself.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093188" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/c2i-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;C2i co-founders Vikram Gakhar, Preetam Tadeparthy, Ram Anant, and Dattatreya Suryanarayana (Left to right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;C2i&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;By treating power conversion, control and packaging as an integrated platform, C2i estimates it can cut end-to-end losses by around 10% — roughly 100 kilowatts saved for every megawatt consumed — with knock-on effects for cooling costs, GPU utilisation and overall data-center economics.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“All that translates directly to total cost of ownership, revenue, and profitability,” Tadeparthy said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Peak XV Partners (which split from Sequoia Capital in 2023), the attraction lies in how power costs shape the economics of AI infrastructure at scale. Rajan Anandan, the venture firm’s managing director, told TechCrunch that after the upfront capital investment in servers and facilities, energy costs become the dominant ongoing expense for data centers, making even incremental efficiency gains highly valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you can reduce energy costs by, call it, 10 to 30%, that’s like a huge number,” Anandan said. “You’re talking about tens of billions of dollars.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The claims will be tested quickly. C2i expects its first two silicon designs to return from fabrication between April and June, after which the startup plans to validate performance with data-center operators and hyperscalers that have asked to review the data, according to Tadeparthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Bengaluru-based startup has built a team of about 65 engineers and is setting up customer-facing operations in the U.S. and Taiwan as it prepares for early deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Power delivery is one of the most entrenched parts of the data-center stack, long dominated by large incumbents with deep balance sheets and years-long qualification cycles. While many newer companies focus on improving individual components, redesigning power delivery end-to-end requires coordinating silicon, packaging, and system architecture simultaneously — a capital-intensive approach that few startups attempt and one that can take years to prove in production environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anandan said the real question now is execution, noting that all startups face technology, market, and team risks when betting on how industries evolve. In C2i’s case, he said, the feedback loop should be relatively short. “We’ll know in the next six months,” said Anandan, pointing to upcoming silicon and early customer validation as the moment when the thesis will be tested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bet also reflects how India’s semiconductor design ecosystem has matured in recent years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way you should look at semiconductors in India is, this is like 2008 e-commerce,” said Anandan. “It’s just getting started.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He pointed to the depth of engineering talent — with a growing share of global chip designers based in the country — alongside government-backed design-linked incentives that have lowered the cost and risk of tape-outs, making it increasingly viable for startups to build globally competitive semiconductor products from India rather than operate only as captive design centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether those conditions translate into a globally competitive product will become clearer over the coming months, as C2i begins validating its system-level power solutions with customers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</guid><pubDate>Mon, 16 Feb 2026 01:00:00 +0000</pubDate></item></channel></rss>