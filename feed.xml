<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 01 Aug 2025 02:09:44 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>OpenAI to launch AI data center in Norway, its first in Europe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/openai-to-launch-ai-data-center-in-norway-its-first-in-europe/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2173788627.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI said Thursday that it plans to launch Stargate Norway, its first AI data center in Europe, in partnership with British AI cloud infrastructure provider Nscale and Norwegian energy infrastructure firm Aker. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale will design and build the site, and it will be a 50/50 joint venture between the two companies. OpenAI will be an “off-taker” in the project, buying capacity from the data center.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes as Europe races to achieve AI sovereignty and invest in data centers and compute power. Earlier this week, the bloc unveiled details of its multibillion-dollar investment into AI infrastructure, including €10 billion ($11.8 billion) to set up 13 AI factories and €20 billion as an initial investment in the factories. Data sovereignty is key to that mission, due to the sensitive nature of business and government data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale and OpenAI told TechCrunch that Stargate Norway isn’t a part of the European Union’s plans to scale AI at home. Nscale CEO Josh Payne told CNBC that part of the purpose of this project is to “leverage European sovereign compute” for the benefit of the continent. Norway’s AI ecosystem, like startups and scientific researchers, will get priority access to the center.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNBC also reported that Nscale and Aker have each committed around $1 billion to the initial 20 megawatt (MW) phase of the project. OpenAI says Stargate Norway will initially deliver 230 MW capacity, with plans to expand to 290 MW, and will run on 100,000 Nvidia GPUs by the end of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The site will be located near Narvik, a small town in northern Norway. OpenAI said in a blog post the region is notable for its access to hydropower, a cool climate, and a “mature industrial base.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The facility will run entirely on renewable power and is expected to incorporate closed-loop, direct-to-chip liquid cooling to ensure maximum cooling efficiency,” said OpenAI. “Additionally, excess heat from the GPU systems will be made available to support low-carbon enterprises in the region.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per the EU AI Act, which took effect in August 2024 and bans systems with “unacceptable risk,” companies building data centers must take steps to protect the environment and be transparent about the energy consumption of AI models. Additionally, the bloc’s Energy Efficiency Directive emphasizes energy efficiency in the ICT sector, which includes data centers. The directive also directs data centers exceeding certain energy input thresholds to recover waste heat.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Stargate Norway announcement comes seven months after OpenAI announced it would invest $500 billion into 10 gigawatts of AI infrastructure in the United States over the next four years, in partnership with Oracle and SoftBank. The deal also follows the launch of Stargate UAE earlier this year, and a recently signed deal with the U.K. government to accelerate AI adoption and boost infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to clarify that Stargate Norway is separate from the EU’s investment into AI infrastructure.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2173788627.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI said Thursday that it plans to launch Stargate Norway, its first AI data center in Europe, in partnership with British AI cloud infrastructure provider Nscale and Norwegian energy infrastructure firm Aker. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale will design and build the site, and it will be a 50/50 joint venture between the two companies. OpenAI will be an “off-taker” in the project, buying capacity from the data center.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes as Europe races to achieve AI sovereignty and invest in data centers and compute power. Earlier this week, the bloc unveiled details of its multibillion-dollar investment into AI infrastructure, including €10 billion ($11.8 billion) to set up 13 AI factories and €20 billion as an initial investment in the factories. Data sovereignty is key to that mission, due to the sensitive nature of business and government data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale and OpenAI told TechCrunch that Stargate Norway isn’t a part of the European Union’s plans to scale AI at home. Nscale CEO Josh Payne told CNBC that part of the purpose of this project is to “leverage European sovereign compute” for the benefit of the continent. Norway’s AI ecosystem, like startups and scientific researchers, will get priority access to the center.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNBC also reported that Nscale and Aker have each committed around $1 billion to the initial 20 megawatt (MW) phase of the project. OpenAI says Stargate Norway will initially deliver 230 MW capacity, with plans to expand to 290 MW, and will run on 100,000 Nvidia GPUs by the end of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The site will be located near Narvik, a small town in northern Norway. OpenAI said in a blog post the region is notable for its access to hydropower, a cool climate, and a “mature industrial base.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The facility will run entirely on renewable power and is expected to incorporate closed-loop, direct-to-chip liquid cooling to ensure maximum cooling efficiency,” said OpenAI. “Additionally, excess heat from the GPU systems will be made available to support low-carbon enterprises in the region.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per the EU AI Act, which took effect in August 2024 and bans systems with “unacceptable risk,” companies building data centers must take steps to protect the environment and be transparent about the energy consumption of AI models. Additionally, the bloc’s Energy Efficiency Directive emphasizes energy efficiency in the ICT sector, which includes data centers. The directive also directs data centers exceeding certain energy input thresholds to recover waste heat.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Stargate Norway announcement comes seven months after OpenAI announced it would invest $500 billion into 10 gigawatts of AI infrastructure in the United States over the next four years, in partnership with Oracle and SoftBank. The deal also follows the launch of Stargate UAE earlier this year, and a recently signed deal with the U.K. government to accelerate AI adoption and boost infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to clarify that Stargate Norway is separate from the EU’s investment into AI infrastructure.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/openai-to-launch-ai-data-center-in-norway-its-first-in-europe/</guid><pubDate>Thu, 31 Jul 2025 14:54:37 +0000</pubDate></item><item><title>Shah Muhammad, Sweco: How AI is building the future of our cities (AI News)</title><link>https://www.artificialintelligence-news.com/news/shah-muhammad-sweco-how-ai-is-building-future-of-our-cities/</link><description>&lt;p&gt;Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, offers his insights into how AI is building the cities of the future.&lt;/p&gt;&lt;p&gt;Ever been stuck in traffic and thought, “Surely, there’s a better way to design this city?” Or walked past a giant new building and wondered if it would be an energy-guzzling monster?&lt;/p&gt;&lt;p&gt;For decades, building our towns and cities has been a slow, complicated process, often relying on educated guesswork. But what if we could give city planners superpowers? What if they could test-drive a dozen different futures before a single shovel hits the ground?&lt;/p&gt;&lt;p&gt;That’s exactly what’s starting to happen. And the secret ingredient is AI.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, and has given his insights on how AI is building the future of our cities." class="wp-image-107259" height="683" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai.jpeg" width="683" /&gt;&lt;/figure&gt;&lt;p&gt;“AI is revolutionising urban design and infrastructure planning at Sweco by optimising processes, enhancing decision-making, and improving sustainability outcomes,” Shah explains. “It allows us to analyse vast amounts of data, simulate various scenarios, and create more efficient and resilient urban environments.”&lt;/p&gt;&lt;p&gt;Shah is saying that AI gives his team the ability to ask the big questions that will impact people’s lives when designing the cities of the future: “What’s the smartest way to build this neighbourhood to cut down on traffic jams and pollution? How can we design a building that stays cool in a heatwave without huge electricity bills?” The AI can run the numbers on thousands of possibilities to find the best path forward.&lt;/p&gt;&lt;p&gt;Of course, the real world is messy. It’s not a neat and tidy computer simulation. It’s full of unpredictable weather, unexpected delays, and the beautiful chaos of human life. This is the number one headache.&lt;/p&gt;&lt;p&gt;“The biggest challenge in applying data-driven models to physical environments is the complexity and variability of real-world conditions,” Shah says. “Ensuring that models accurately represent these conditions and can adapt to changing conditions is crucial.”&lt;/p&gt;&lt;p&gt;So, how do they deal with that? They start with the basics. They get their house in order. Before they even think about AI, they make sure the information it learns from is rock-solid and trustworthy.&lt;/p&gt;&lt;p&gt;“To ensure data quality and interoperability across projects, we implement rigorous data governance practices, standardise data formats, and use interoperable software tools,” he says.&lt;/p&gt;&lt;p&gt;That might sound a bit technical, but think of it this way: they’re making sure everyone on the team is singing from the same hymn sheet. When all the different software tools can talk to each other and everyone trusts the information, the AI can do its job properly. It “enables seamless data exchange and collaboration among different teams and stakeholders.”&lt;/p&gt;&lt;p&gt;But of all the things AI can do, this next part might be the most hopeful when using it to design future cities. It shows that this technology can have a real heart.&lt;/p&gt;&lt;p&gt;“There are many projects where AI has made a measurable impact on sustainability, making it hard to single out one,” he reflects. “However, if I were to choose, I would highlight a project where AI was used to preserve biodiversity by identifying endangered species and providing this information to researchers.”&lt;/p&gt;&lt;p&gt;In this scenario, technology is giving nature a voice in the planning meeting. It’s like the AI raising its hand and saying, “Hang on, let’s be careful here, there’s a family of rare birds living in this area.” It allows us to build with respect for the world around us.&lt;/p&gt;&lt;p&gt;So, what’s the next chapter? According to Shah, it’s about turning that crystal ball into a real-time guide.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“According to me, the biggest opportunity for AI in the AEC sector lies in predictive analytics and automation,” Shah explains. “By anticipating future trends, identifying potential issues early, and automating routine tasks, AI can greatly enhance efficiency, reduce costs, and improve the overall quality of projects.”&lt;/p&gt;&lt;p&gt;This could mean safer bridges, roads that need fewer repairs, and less disruption to our lives. It means freeing up talented people from the boring tasks to focus on building the cities of the future that are more in tune with the people who call them home.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Shah Muhammad is speaking at &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt; in Amsterdam on 24-25 September 2025 where he will be hosting a presentation on ‘Leveraging Generative and Agentic AI for Intelligent Process Automation’. Find out more about the event and how to attend &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, offers his insights into how AI is building the cities of the future.&lt;/p&gt;&lt;p&gt;Ever been stuck in traffic and thought, “Surely, there’s a better way to design this city?” Or walked past a giant new building and wondered if it would be an energy-guzzling monster?&lt;/p&gt;&lt;p&gt;For decades, building our towns and cities has been a slow, complicated process, often relying on educated guesswork. But what if we could give city planners superpowers? What if they could test-drive a dozen different futures before a single shovel hits the ground?&lt;/p&gt;&lt;p&gt;That’s exactly what’s starting to happen. And the secret ingredient is AI.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, and has given his insights on how AI is building the future of our cities." class="wp-image-107259" height="683" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai.jpeg" width="683" /&gt;&lt;/figure&gt;&lt;p&gt;“AI is revolutionising urban design and infrastructure planning at Sweco by optimising processes, enhancing decision-making, and improving sustainability outcomes,” Shah explains. “It allows us to analyse vast amounts of data, simulate various scenarios, and create more efficient and resilient urban environments.”&lt;/p&gt;&lt;p&gt;Shah is saying that AI gives his team the ability to ask the big questions that will impact people’s lives when designing the cities of the future: “What’s the smartest way to build this neighbourhood to cut down on traffic jams and pollution? How can we design a building that stays cool in a heatwave without huge electricity bills?” The AI can run the numbers on thousands of possibilities to find the best path forward.&lt;/p&gt;&lt;p&gt;Of course, the real world is messy. It’s not a neat and tidy computer simulation. It’s full of unpredictable weather, unexpected delays, and the beautiful chaos of human life. This is the number one headache.&lt;/p&gt;&lt;p&gt;“The biggest challenge in applying data-driven models to physical environments is the complexity and variability of real-world conditions,” Shah says. “Ensuring that models accurately represent these conditions and can adapt to changing conditions is crucial.”&lt;/p&gt;&lt;p&gt;So, how do they deal with that? They start with the basics. They get their house in order. Before they even think about AI, they make sure the information it learns from is rock-solid and trustworthy.&lt;/p&gt;&lt;p&gt;“To ensure data quality and interoperability across projects, we implement rigorous data governance practices, standardise data formats, and use interoperable software tools,” he says.&lt;/p&gt;&lt;p&gt;That might sound a bit technical, but think of it this way: they’re making sure everyone on the team is singing from the same hymn sheet. When all the different software tools can talk to each other and everyone trusts the information, the AI can do its job properly. It “enables seamless data exchange and collaboration among different teams and stakeholders.”&lt;/p&gt;&lt;p&gt;But of all the things AI can do, this next part might be the most hopeful when using it to design future cities. It shows that this technology can have a real heart.&lt;/p&gt;&lt;p&gt;“There are many projects where AI has made a measurable impact on sustainability, making it hard to single out one,” he reflects. “However, if I were to choose, I would highlight a project where AI was used to preserve biodiversity by identifying endangered species and providing this information to researchers.”&lt;/p&gt;&lt;p&gt;In this scenario, technology is giving nature a voice in the planning meeting. It’s like the AI raising its hand and saying, “Hang on, let’s be careful here, there’s a family of rare birds living in this area.” It allows us to build with respect for the world around us.&lt;/p&gt;&lt;p&gt;So, what’s the next chapter? According to Shah, it’s about turning that crystal ball into a real-time guide.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“According to me, the biggest opportunity for AI in the AEC sector lies in predictive analytics and automation,” Shah explains. “By anticipating future trends, identifying potential issues early, and automating routine tasks, AI can greatly enhance efficiency, reduce costs, and improve the overall quality of projects.”&lt;/p&gt;&lt;p&gt;This could mean safer bridges, roads that need fewer repairs, and less disruption to our lives. It means freeing up talented people from the boring tasks to focus on building the cities of the future that are more in tune with the people who call them home.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Shah Muhammad is speaking at &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt; in Amsterdam on 24-25 September 2025 where he will be hosting a presentation on ‘Leveraging Generative and Agentic AI for Intelligent Process Automation’. Find out more about the event and how to attend &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/shah-muhammad-sweco-how-ai-is-building-future-of-our-cities/</guid><pubDate>Thu, 31 Jul 2025 16:44:13 +0000</pubDate></item><item><title>Quora’s Poe releases a developer API with access to a bouquet of AI models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/quoras-poe-is-releasing-an-api-for-developers-to-easily-access-a-boquet-of-models/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Quora’s AI platform Poe announced on Thursday that it’s releasing an API that allows developers to easily access different models or bots for their own applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The API doesn’t require a separate fee. Instead, usage is tracked via Poe’s existing point-based subscription plans, where each model call costs a set number of points. For instance, low-quality image generation through GPT-4o in a 1:1 aspect ratio and 1024 x 1024 size would cost 328 points.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, Poe’s plans include the $4.99 per month plan (10,000 points per day), the $19.99/mo plan (1 million points per month), the $49.99/mo plan (2.5 million points per month), the $99.99/mo plan (5 million points per month), and the $249.99/mo plan (12.5 million points per month).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers will also be able to buy additional points at a rate of $30 for 1 million tokens. Add-on tokens don’t come in a fixed package, so customers can pay any dollar amount to get tokens based on that rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Through this API, developers can power tools like Cursor, Cline, Continue, Roo, and any others that work with OpenAI-compatible chat completion APIs. The platform currently provides access to more than 100 models across voice, text, image, and video generation. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These multimodal models include Imagen 4, GPT Image 1, Flux Kontext, Seedream 3.0, Veo 3, Runway Gen 4 Turbo, Kling 2.1, ElevenLabs, and Lyria.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3032708" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/API_architecture_D.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Quora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Currently, we are working on allowing developers to take a private bot they have built on Poe and use that through an API. Plus, we are thinking about better key management for developers for the API product,” Gareth Jones, Poe’s product lead for creators and developers, told TechCrunch over a call.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While API provides a way for developers to use different models, Poe also offers tools aimed at consumers. Earlier this year, the company introduced a new way to allow users to easily create AI-powered apps. It also offers templates to build server bots, prompt bots, and image generation bots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, developers will need to pick and manage model use manually. Jones said that the company will consider adding budget management functionality in the future, based on developer feedback.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Quora’s AI platform Poe announced on Thursday that it’s releasing an API that allows developers to easily access different models or bots for their own applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The API doesn’t require a separate fee. Instead, usage is tracked via Poe’s existing point-based subscription plans, where each model call costs a set number of points. For instance, low-quality image generation through GPT-4o in a 1:1 aspect ratio and 1024 x 1024 size would cost 328 points.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, Poe’s plans include the $4.99 per month plan (10,000 points per day), the $19.99/mo plan (1 million points per month), the $49.99/mo plan (2.5 million points per month), the $99.99/mo plan (5 million points per month), and the $249.99/mo plan (12.5 million points per month).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers will also be able to buy additional points at a rate of $30 for 1 million tokens. Add-on tokens don’t come in a fixed package, so customers can pay any dollar amount to get tokens based on that rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Through this API, developers can power tools like Cursor, Cline, Continue, Roo, and any others that work with OpenAI-compatible chat completion APIs. The platform currently provides access to more than 100 models across voice, text, image, and video generation. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These multimodal models include Imagen 4, GPT Image 1, Flux Kontext, Seedream 3.0, Veo 3, Runway Gen 4 Turbo, Kling 2.1, ElevenLabs, and Lyria.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3032708" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/API_architecture_D.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Quora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Currently, we are working on allowing developers to take a private bot they have built on Poe and use that through an API. Plus, we are thinking about better key management for developers for the API product,” Gareth Jones, Poe’s product lead for creators and developers, told TechCrunch over a call.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While API provides a way for developers to use different models, Poe also offers tools aimed at consumers. Earlier this year, the company introduced a new way to allow users to easily create AI-powered apps. It also offers templates to build server bots, prompt bots, and image generation bots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, developers will need to pick and manage model use manually. Jones said that the company will consider adding budget management functionality in the future, based on developer feedback.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/quoras-poe-is-releasing-an-api-for-developers-to-easily-access-a-boquet-of-models/</guid><pubDate>Thu, 31 Jul 2025 17:00:00 +0000</pubDate></item><item><title>Design and development shop the Iconfactory is selling some apps — and AI is partially to blame (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/design-and-development-shop-the-iconfactory-is-selling-some-apps-and-ai-is-partially-to-blame/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Tapestry-Quicklinks-New.jpg?resize=1200,683" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At one point, an app called Twitterrific was one of the most popular iPhone apps for browsing Twitter. These days, the company behind that app, and the many apps that followed, is struggling. And AI may partially be to blame.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Wednesday, the company known as the Iconfactory admitted it was at a crossroads and was putting up several of its apps for sale due to a lack of resources. While the announcement positioned the matter as a situation where the Iconfactory’s app catalog had simply grown to include too many apps to keep up with and not enough time to do so, the reality is that the business today has no choice but to focus on the apps that offer a better return on investment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Side products can no longer be maintained, even if they have “loads of happy and loyal customers,” as the Iconfactory’s co-founder, Ged Maheux, says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says that it will continue to work on apps like Tapestry, Linea Sketch, Wallaroo, and Tot, as well as its new project involving Retro Pixel Portraits, but is accepting “serious offers” for the other apps. These sales will include intellectual property and source code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of particular interest is that the company points to AI significantly affecting its business as the reason.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT and other AI services are basically killing @Iconfactory, and I’m not exaggerating or being hyperbolical,” Iconfactory developer Sean Heber said in a Mastodon post earlier this month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue isn’t that people are using AI instead of mobile apps, but how vibe coding is affecting the need for app design firms like theirs. Besides building its own apps, the Iconfactory generated revenue by offering app design services, which include things like icon design (hence the name), app design, marketing asset creation, plus branding and consulting services.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These services helped fuel the business that’s now being destroyed by AI. “I know nothing I say is going to get anyone to stop using ChatGPT and generating a new app icon in 5 minutes for the app that you also had ChatGPT write for you in a few hours, but I’m not sure what the rest of us are supposed to do about making enough money to, ya know, live,” Heber wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another issue for the longtime app makers at the Iconfactory was the shutdown of its most popular app, Twitterrific, which was killed by Elon Musk in 2023 when the company (now known as X) officially banned all third-party clients. The move put Twitterrific, Tweetbot, and other apps almost instantly out of business, leading the Iconfactory to plead with its users to decline their App Store refunds to help them stay afloat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That, too, has affected the Iconfactory’s future, Heber admitted in his posts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“First Twitter/Elon killed our main app revenue that kept the lights on around here, then generative AI exploded to land a final blow to design revenue,” he wrote. “I think perhaps because @Iconfactory design is quite good people have this impression that we’re sitting here on a pile of money or something and some huge powerhouse — nope. We’ve been barely making it since Elon/Twitter. There’s only 6 of us and there’s no war chest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After shutting down Twitterrific, the Iconfactory turned to the open social web as a way to generate a new revenue stream. It launched an app called Tapestry, which allows users to track sources across the open web, including RSS feeds, YouTube, Bluesky, podcasts, Mastodon, Reddit, Tumblr, Micro.blog, and others. The app offers a variety of clever tools for organizing sources, making feeds, muting and hiding content you don’t want to see, and more. It also offered a way for third-party developers to extend Tapestry with add-ons called Connectors, allowing users to add even more open feeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That app will remain a part of the company’s efforts for now — a Mac app is in the works — but even its future could be uncertain. For one thing, open social media platforms like Mastodon and Bluesky are still dwarfed by tech giants, which means consumer demand for something like Tapestry is fairly niche. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Heber shared, the app’s Kickstarter was a bit of a “Hail Mary” on the company’s part, but people aren’t subscribing in great enough numbers to make up for the revenue that Twitterrific once brought in, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If AI continues to commoditize the business of app making, the Iconfactory won’t be alone in suffering the consequences. But vibe-coded apps aren’t necessarily what consumers need, not only because of the lack of human input, but also the lax security some of these apps offer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reached for comment, Maheux agreed that AI had “definitely put a damper on the design side of our services,” though it hasn’t “killed” the company yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many indie developers have adopted AI for an inexpensive or free solution for graphical work like app icons, which has been a core part of the services we offer. We still do, of course, but the frequency of developers coming to us for these services has declined greatly in the last few years,” he told TechCrunch via email. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also cited other factors impacting the business, like Apple’s graphical system, SF Symbols, that developers can use instead. Consumers are tiring of subscriptions for everything. Plus, he points out that the cost of everything has increased over the years, while the cost of apps has not, making it harder to make a living as a small business developer.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’ve had to expand our offerings into other areas like UX consulting, coding consultation, and side revenue services to try and make up the revenue from this lost design work. Apple’s introduction of Liquid Glass has offered some new opportunities for design work and consultation, and we’ve been working with a handful of companies on this, so that’s been hopeful,” he noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication with company comment.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Tapestry-Quicklinks-New.jpg?resize=1200,683" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At one point, an app called Twitterrific was one of the most popular iPhone apps for browsing Twitter. These days, the company behind that app, and the many apps that followed, is struggling. And AI may partially be to blame.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Wednesday, the company known as the Iconfactory admitted it was at a crossroads and was putting up several of its apps for sale due to a lack of resources. While the announcement positioned the matter as a situation where the Iconfactory’s app catalog had simply grown to include too many apps to keep up with and not enough time to do so, the reality is that the business today has no choice but to focus on the apps that offer a better return on investment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Side products can no longer be maintained, even if they have “loads of happy and loyal customers,” as the Iconfactory’s co-founder, Ged Maheux, says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says that it will continue to work on apps like Tapestry, Linea Sketch, Wallaroo, and Tot, as well as its new project involving Retro Pixel Portraits, but is accepting “serious offers” for the other apps. These sales will include intellectual property and source code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of particular interest is that the company points to AI significantly affecting its business as the reason.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT and other AI services are basically killing @Iconfactory, and I’m not exaggerating or being hyperbolical,” Iconfactory developer Sean Heber said in a Mastodon post earlier this month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue isn’t that people are using AI instead of mobile apps, but how vibe coding is affecting the need for app design firms like theirs. Besides building its own apps, the Iconfactory generated revenue by offering app design services, which include things like icon design (hence the name), app design, marketing asset creation, plus branding and consulting services.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These services helped fuel the business that’s now being destroyed by AI. “I know nothing I say is going to get anyone to stop using ChatGPT and generating a new app icon in 5 minutes for the app that you also had ChatGPT write for you in a few hours, but I’m not sure what the rest of us are supposed to do about making enough money to, ya know, live,” Heber wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another issue for the longtime app makers at the Iconfactory was the shutdown of its most popular app, Twitterrific, which was killed by Elon Musk in 2023 when the company (now known as X) officially banned all third-party clients. The move put Twitterrific, Tweetbot, and other apps almost instantly out of business, leading the Iconfactory to plead with its users to decline their App Store refunds to help them stay afloat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That, too, has affected the Iconfactory’s future, Heber admitted in his posts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“First Twitter/Elon killed our main app revenue that kept the lights on around here, then generative AI exploded to land a final blow to design revenue,” he wrote. “I think perhaps because @Iconfactory design is quite good people have this impression that we’re sitting here on a pile of money or something and some huge powerhouse — nope. We’ve been barely making it since Elon/Twitter. There’s only 6 of us and there’s no war chest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After shutting down Twitterrific, the Iconfactory turned to the open social web as a way to generate a new revenue stream. It launched an app called Tapestry, which allows users to track sources across the open web, including RSS feeds, YouTube, Bluesky, podcasts, Mastodon, Reddit, Tumblr, Micro.blog, and others. The app offers a variety of clever tools for organizing sources, making feeds, muting and hiding content you don’t want to see, and more. It also offered a way for third-party developers to extend Tapestry with add-ons called Connectors, allowing users to add even more open feeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That app will remain a part of the company’s efforts for now — a Mac app is in the works — but even its future could be uncertain. For one thing, open social media platforms like Mastodon and Bluesky are still dwarfed by tech giants, which means consumer demand for something like Tapestry is fairly niche. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Heber shared, the app’s Kickstarter was a bit of a “Hail Mary” on the company’s part, but people aren’t subscribing in great enough numbers to make up for the revenue that Twitterrific once brought in, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If AI continues to commoditize the business of app making, the Iconfactory won’t be alone in suffering the consequences. But vibe-coded apps aren’t necessarily what consumers need, not only because of the lack of human input, but also the lax security some of these apps offer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reached for comment, Maheux agreed that AI had “definitely put a damper on the design side of our services,” though it hasn’t “killed” the company yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many indie developers have adopted AI for an inexpensive or free solution for graphical work like app icons, which has been a core part of the services we offer. We still do, of course, but the frequency of developers coming to us for these services has declined greatly in the last few years,” he told TechCrunch via email. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also cited other factors impacting the business, like Apple’s graphical system, SF Symbols, that developers can use instead. Consumers are tiring of subscriptions for everything. Plus, he points out that the cost of everything has increased over the years, while the cost of apps has not, making it harder to make a living as a small business developer.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’ve had to expand our offerings into other areas like UX consulting, coding consultation, and side revenue services to try and make up the revenue from this lost design work. Apple’s introduction of Liquid Glass has offered some new opportunities for design work and consultation, and we’ve been working with a handful of companies on this, so that’s been hopeful,” he noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication with company comment.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/design-and-development-shop-the-iconfactory-is-selling-some-apps-and-ai-is-partially-to-blame/</guid><pubDate>Thu, 31 Jul 2025 17:36:05 +0000</pubDate></item><item><title>AI Safety Newsletter #60: The AI Action Plan (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The Trump Administration publishes its AI Action Plan; OpenAI released ChatGPT Agent and announced that an experimental model achieved gold medal-level performance on the 2025 International Mathematical Olympiad.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;On the 23rd, the White House &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/articles/2025/07/white-house-unveils-americas-ai-action-plan/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; its &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf" rel="rel"&gt;AI Action Plan&lt;/a&gt;&lt;span&gt;. The document is the outcome of a January &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/01/31/2025-02172/removing-barriers-to-american-leadership-in-artificial-intelligence" rel="rel"&gt;executive order&lt;/a&gt;&lt;span&gt; that required the President’s Science Advisor, ‘AI and Crypto Czar’, and National Security Advisor (currently Michael Kratsios, David Sacks, and Marco Rubio) to submit a plan to “sustain and enhance America's global AI dominance in order to promote human flourishing, economic competitiveness, and national security.” President Trump also delivered an &lt;/span&gt;&lt;a href="https://www.pbs.org/newshour/politics/watch-live-trump-reveals-ai-action-plan-shaped-by-his-tech-supporters-after-revoking-biden-policy" rel="rel"&gt;hour-long speech&lt;/a&gt;&lt;span&gt; on the plan, and signed &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/07/28/2025-14218/promoting-the-export-of-the-american-ai-technology-stack" rel="rel"&gt;three&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/" rel="rel"&gt;executive&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/07/28/2025-14217/preventing-woke-ai-in-the-federal-government" rel="rel"&gt;orders&lt;/a&gt;&lt;span&gt; beginning to implement some of its policies.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!yeVV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf95488b-7af9-4342-aec3-fddfd3b5ee7c_1400x933.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="933" src="https://substackcdn.com/image/fetch/$s_!yeVV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf95488b-7af9-4342-aec3-fddfd3b5ee7c_1400x933.png" width="1400" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Trump displaying an executive order at the “Winning the AI Race” summit. &lt;/span&gt;&lt;a href="https://www.wsj.com/articles/federal-ai-plan-targets-burdensome-state-regulations-b6dff028" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;The AI Action Plan lists several dozen policies across three pillars—accelerating innovation, building American AI infrastructure, and leading in international diplomacy and security—that will guide the Trump Administration’s approach to AI.&lt;/p&gt;&lt;p&gt;The central policy agenda outlined is to accelerate US AI development and deployment. For example, it proposes streamlining permitting for AI infrastructure (such as semiconductor manufacturing facilities, data centers, and energy infrastructure) adopting AI in the federal government and military, and funding AI research. But there’s a lot more in the plan, too: both a surprisingly strong focus on AI safety, as well as some items of concern.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Plan includes several policies that advance AI safety. &lt;/strong&gt;&lt;span&gt;While most of the plan’s policies are intended to accelerate AI development and deployment, it also correctly observes that AI development will only benefit Americans if done safely. Accordingly, it proposes several policies that advance AI safety. Some of the policies most relevant to AI safety include:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Invest in AI Interpretability, Control, and Robustness Breakthroughs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Build an AI Evaluations Ecosystem&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bolster Critical Infrastructure Cybersecurity&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Promote Secure-By-Design AI Technologies and Applications&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Promote Mature Federal Capacity for AI Incident Response&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Strengthen AI Compute Export Control Enforcement (this proposes location verification for AI chips)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ensure that the U.S. Government is at the Forefront of Evaluating National Security Risks in Frontier Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Invest in Biosecurity&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;While&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;not comprehensive, these policies are a great step in the right direction—and much better than might have been expected given the administration’s previous &lt;/span&gt;&lt;a href="https://www.presidency.ucsb.edu/documents/remarks-the-vice-president-the-artificial-intelligence-action-summit-paris-france" rel="rel"&gt;rhetorical disregard&lt;/a&gt;&lt;span&gt; for AI safety.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Overall,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;the plan introduces sensible policies that reflect the expertise of those who developed it. However, it is also shaped by the larger policy agenda of the Trump Administration, which may conflict with AI safety goals. We discuss some areas of potential concern below.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan does not want state AI legislation. &lt;/strong&gt;&lt;span&gt;One section proposes that the Federal government “should not allow AI-related Federal funding to be directed toward states with burdensome AI regulations that waste these funds, but should also not interfere with states’ rights to pass prudent laws that are not unduly restrictive to innovation.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This rule is less strict than Sen. Cruz’s failed AI regulation moratorium. But what constitutes a “burdensome” regulation will vary depending on who you ask (particularly if you ask frontier AI companies). In response to the plan, both Congressional Democrats and Rep. Marjorie Taylor Greene &lt;/span&gt;&lt;a href="https://beyer.house.gov/news/documentsingle.aspx?DocumentID=8605" rel="rel"&gt;expressed&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://x.com/repmtg/status/1948400163875152237" rel="rel"&gt;concern&lt;/a&gt;&lt;span&gt; about stifling state AI regulation.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan has a partisan view on what constitutes ideological bias.&lt;/strong&gt;&lt;span&gt; In a section on ensuring that AI “objectively reflects truth,” one policy instructs NIST to “revise the NIST AI Risk Management Framework to eliminate references to misinformation, Diversity, Equity, and Inclusion, and climate change.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A policy to promote objectivity in AI models could be great. However, that policy could itself be weaponized to promote ideological ends. In their &lt;/span&gt;&lt;a href="https://beyer.house.gov/news/documentsingle.aspx?DocumentID=8605" rel="rel"&gt;response&lt;/a&gt;&lt;span&gt;, Congressional Democrats wrote that “we support true AI neutrality—AI models trained on facts and science—but the administration's fixation on ‘anti-woke’ inputs is definitionally not neutral.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan endorses open-weight models.&lt;/strong&gt;&lt;span&gt; It writes that, “while the decision of whether and how to release an open or closed model is fundamentally up to the developer, the Federal government should create a supportive environment for open models.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Encouraging US companies to release open-weight models with dangerous capabilities would be a bad policy. But the specific policies the plan lists stop short of that—they mostly just provide resources to academic researchers (who are unlikely to develop frontier models) through the National AI Research Resource (NAIRR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan forgoes AI nonproliferation. &lt;/strong&gt;&lt;span&gt;The plan argues that the US “must meet global demand for AI by exporting its full AI technology stack—hardware, models, software, applications, and standards—to all countries willing to join America’s AI alliance.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This plan’s rationale for this policy is that countries might otherwise look to acquire Chinese AI exports. However, it also continues the Trump Administration's reversal of the Biden-era policy (see the &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/01/15/2025-00636/framework-for-artificial-intelligence-diffusion" rel="rel"&gt;AI Diffusion Framework&lt;/a&gt;&lt;span&gt;) that sought to prevent the proliferation of dangerous AI capabilities abroad. While exporting American AI might strengthen the US’ position in the AI race, it also threatens to proliferate dangerous AI capabilities to malicious actors if the US does not ensure that other states implement robust security standards.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan advances a zero-sum race narrative. &lt;/strong&gt;&lt;span&gt;Kratsios, Sacks, and Rubio write that the promise of AI “is ours to seize, or to lose.” That is, they assume that the alternative to “AI dominance” is to give up AI’s benefits.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This argument is misleading—or at least underdeveloped. While there are reasons to support a US lead in AI, AI progress has the potential to benefit Americans whether or not the US “dominates” international AI development. Historically, general purpose technologies like AI &lt;/span&gt;&lt;a href="https://press.princeton.edu/books/paperback/9780691260341/technology-and-the-rise-of-great-powers" rel="rel"&gt;diffuse&lt;/a&gt;&lt;span&gt; across national boundaries. For example, technologies electricity and the internet have benefited people around the world, and not just within the nations that led their development.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The real motivation behind the AI race narrative in Washington is not seizing AI’s benefits, but rather competition over the balance of international power between the US and China. While there are reasons to be concerned about AI development dominated by China, racing towards US dominance is not the only alternative—and &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/why-racing-to-artificial-superintelligence-would-undermine-americas-national-security" rel="rel"&gt;creates&lt;/a&gt;&lt;span&gt; its own risks. In order to preserve international security, the US will need to &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim" rel="rel"&gt;proactively manage&lt;/a&gt;&lt;span&gt;—rather than just accelerate—a US-China AI race.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;On Thursday, OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/introducing-chatgpt-agent/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; a new agent mode for ChatGPT, which integrates Operator, Deep Research, and chatbot functionality into a unified system.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The system, ‘ChatGPT agent,’ has access to its own virtual computer, and OpenAI highlights that it can book flights and reservations, create slides and spreadsheets, and make online purchases. It can also connect to users’ personal accounts, for example, Google Calendar, Gmail, and GitHub.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT agent achieves SOTA performance on HLE and FrontierMath.&lt;/strong&gt;&lt;span&gt; ChatGPT agent’s capabilities extend beyond basic online automation—it achieves SOTA performance on several benchmarks measuring expert-level knowledge and reasoning. For example, ChatGPT agent gets 23% on Humanity’s Last Exam (HLE), when it does not use tools. When it uses tools like browsers and computer code, it gets 41.6%. This is similar to Grok 4, which gets 25.4% on HLE without tools and 44.4% with tools.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!YR3_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32c045cf-daf7-4254-8cdc-4dd861f2c397_884x802.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="802" src="https://substackcdn.com/image/fetch/$s_!YR3_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32c045cf-daf7-4254-8cdc-4dd861f2c397_884x802.png" width="884" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;OpenAI&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;also evaluated&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;ChatGPT agent against benchmarks measuring real-world task completion. OpenAI reports it performs better than humans nearly 50% of the time on an internal benchmark capturing diverse economically important tasks—an incredible claim that has yet to be reproduced. OpenAI also reports it surpasses human performance on data science tasks, and achieves state of the art results (though less than human) on tasks involving spreadsheets and web browsing.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!_NBd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39879533-bbcb-4b77-a1b9-67d248591bf5_1446x852.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="852" src="https://substackcdn.com/image/fetch/$s_!_NBd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39879533-bbcb-4b77-a1b9-67d248591bf5_1446x852.png" width="1446" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Greater autonomy introduces new risks.&lt;/strong&gt;&lt;span&gt; OpenAI published a &lt;/span&gt;&lt;a href="https://openai.com/index/chatgpt-agent-system-card/" rel="rel"&gt;system card&lt;/a&gt;&lt;span&gt; detailing ChatGPT agent’s risks. ChatGPT agent has access to user data and can take actions on the web, meaning that mistakes are higher stakes. OpenAI also highlighted the risk of adversarial manipulation through prompt injection, in which malicious websites could try to manipulate ChatGPT’s behavior, such as to reveal personal information about the user.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT agent poses ‘high’ biological and chemical risk.&lt;/strong&gt;&lt;span&gt; ChatGPT agent is also the first system that OpenAI is treating as posing ‘high’ biological and chemical risk. According to the company’s &lt;/span&gt;&lt;a href="https://openai.com/index/updating-our-preparedness-framework/" rel="rel"&gt;Preparedness Framework&lt;/a&gt;&lt;span&gt;, that means the system could provide meaningful assistance to non-experts in creating known biological or chemical threats.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI says it’s activated several safeguards against these risks, including “comprehensive threat modeling, dual-use refusal training, always-on classifiers and reasoning monitors, and clear enforcement pipelines.” It also launched a &lt;/span&gt;&lt;a href="https://openai.com/bio-bug-bounty/" rel="rel"&gt;bug bounty program&lt;/a&gt;&lt;span&gt; for researchers to red team these safeguards.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OpenAI and Google DeepMind claim gold medal-level performance on the 2025 IMO. &lt;/strong&gt;&lt;span&gt;On Friday, OpenAI also &lt;/span&gt;&lt;a href="https://x.com/alexwei_/status/1946477742855532918" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that an experimental model had achieved gold medal-level performance on the 2025 International Mathematical Olympiad (IMO), solving five out of six questions. (A few human competitors &lt;/span&gt;&lt;a href="https://www.imo-official.org/year_individual_r.aspx?year=2025" rel="rel"&gt;scored&lt;/a&gt;&lt;span&gt; a perfect six out of six).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gold medal-level performance on the IMO has been a major goal in AI research for years, but only recently has seemed within reach. Last year, Google’s AlphaProof and AlphaGeometry 2 &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/" rel="rel"&gt;achieved&lt;/a&gt;&lt;span&gt; silver medal-level performance on the 2024 IMO, making gold-level performance this year plausible. On Monday, Google &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that its own reasoning LLM had achieved gold medal-level performance on the 2025 IMO, also solving five out of six questions.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OpenAI and Google used general reasoning LLMs.&lt;/strong&gt;&lt;span&gt; Where the capabilities of Google’s AlphaProof and AlphaGeometry 2 systems were narrowly focused on IMO-style math questions, OpenAI’s model is &lt;/span&gt;&lt;a href="https://x.com/polynoamial/status/1946478250974200272" rel="rel"&gt;apparently&lt;/a&gt;&lt;span&gt; not IMO-specific (or even math-specific), but instead a general reasoning LLM allowed to think for hours at a time. OpenAI published the model’s answers on the 2025 IMO &lt;/span&gt;&lt;a href="https://github.com/aw31/openai-imo-2025-proofs/" rel="rel"&gt;here&lt;/a&gt;&lt;span&gt;. Similarly, Google’s gold-winning performance used an advanced version of Gemini Deep Think—a general reasoning model that uses natural language.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;According to Nvidia's CEO, the US &lt;/span&gt;&lt;a href="https://apnews.com/article/nvidia-china-ai-chips-h20-trump-91588c36559bc881b8e010a9ed95cf0a" rel="rel"&gt;approved&lt;/a&gt;&lt;span&gt; the sale of Nvidia's H20 chips to China. Reuters reported that Nvidia &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/nvidia-orders-300000-h20-chips-tsmc-due-robust-china-demand-sources-say-2025-07-29/" rel="rel"&gt;ordered&lt;/a&gt;&lt;span&gt; 300,000 H20s from TSMC to meet expected Chinese demand.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Pentagon’s &lt;/span&gt;&lt;a href="https://comptroller.defense.gov/Portals/45/Documents/defbudget/FY2026/FY2026_Budget_Request.pdf" rel="rel"&gt;FY2026 budget request&lt;/a&gt;&lt;span&gt; called for $13.4 billion for autonomous systems.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Pentagon also &lt;/span&gt;&lt;a href="https://www.nextgov.com/acquisition/2025/07/pentagon-awards-multiple-companies-200m-contracts-ai-tools/406698/" rel="rel"&gt;awarded&lt;/a&gt;&lt;span&gt; Anthropic, Google, OpenAI and xAI each $200 million contracts to develop AI for national security applications.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;China &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; plans for an international AI governance organization.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The UK government &lt;/span&gt;&lt;a href="https://www.gov.uk/government/news/ai-security-institute-launches-international-coalition-to-safeguard-ai-development" rel="rel"&gt;launched&lt;/a&gt;&lt;span&gt; a £15m million-funded alignment research project.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Meta has &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/07/18/meta-refuses-to-sign-eus-ai-code-of-practice/" rel="rel"&gt;refused&lt;/a&gt;&lt;span&gt; to sign the EU’s GPAI Code of Practice.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic announced it &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/eu-code-practice" rel="rel"&gt;will&lt;/a&gt;&lt;span&gt; join OpenAI, Mistral and (likely) Microsoft in signing the Code of Practice.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;At a summit in Pennsylvania, President Trump &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/07/15/us/politics/trump-ai-pittsburgh-speech.html" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; more than $90 billion in private AI infrastructure investment in the state, which is led by Blackstone and Google.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Isobel Moure, Tim O'Reilly and Ilan Strauss &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/open-protocols-prevent-ai-monopolies" rel="rel"&gt;argue&lt;/a&gt;&lt;span&gt; that open protocols can prevent AI monopolies.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dane A. Morey, Mike Rayo, and David Woods &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/how-ai-can-degrade-human-performance-in-high-stakes-settings" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; how AI can degrade human performance in high-stakes settings.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anton Leicht &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/in-the-race-for-ai-supremacy-can-countries-stay-neutral" rel="rel"&gt;analyzes&lt;/a&gt;&lt;span&gt; whether, in the race for AI supremacy, countries can stay neutral.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://report2025.seismic.org/" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; from the Seismic Foundation found that people believe AI will make their lives worse, but ranks the issue low on their list of social priorities.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A YouGov &lt;/span&gt;&lt;a href="https://d3nkl3psvxxpe9.cloudfront.net/documents/Trump_Issue_Handling_poll_results.pdf" rel="rel"&gt;poll&lt;/a&gt;&lt;span&gt; found a -14 approval rating of Trump’s handling of AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://www.commonsensemedia.org/press-releases/nearly-3-in-4-teens-have-used-ai-companions-new-national-survey-finds" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; from Common Sense Media found that 3 in 4 teens have used AI companions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Rand published a &lt;/span&gt;&lt;a href="https://www.rand.org/pubs/working_papers/WRA4077-1.html" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; on verifying international AI agreements.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAIS is hiring a software engineer. Apply &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/24e7c67e-8a7e-401c-b87f-6d664ee51726" rel="rel"&gt;here&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The Trump Administration publishes its AI Action Plan; OpenAI released ChatGPT Agent and announced that an experimental model achieved gold medal-level performance on the 2025 International Mathematical Olympiad.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;On the 23rd, the White House &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/articles/2025/07/white-house-unveils-americas-ai-action-plan/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; its &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf" rel="rel"&gt;AI Action Plan&lt;/a&gt;&lt;span&gt;. The document is the outcome of a January &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/01/31/2025-02172/removing-barriers-to-american-leadership-in-artificial-intelligence" rel="rel"&gt;executive order&lt;/a&gt;&lt;span&gt; that required the President’s Science Advisor, ‘AI and Crypto Czar’, and National Security Advisor (currently Michael Kratsios, David Sacks, and Marco Rubio) to submit a plan to “sustain and enhance America's global AI dominance in order to promote human flourishing, economic competitiveness, and national security.” President Trump also delivered an &lt;/span&gt;&lt;a href="https://www.pbs.org/newshour/politics/watch-live-trump-reveals-ai-action-plan-shaped-by-his-tech-supporters-after-revoking-biden-policy" rel="rel"&gt;hour-long speech&lt;/a&gt;&lt;span&gt; on the plan, and signed &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/07/28/2025-14218/promoting-the-export-of-the-american-ai-technology-stack" rel="rel"&gt;three&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/" rel="rel"&gt;executive&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/07/28/2025-14217/preventing-woke-ai-in-the-federal-government" rel="rel"&gt;orders&lt;/a&gt;&lt;span&gt; beginning to implement some of its policies.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!yeVV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf95488b-7af9-4342-aec3-fddfd3b5ee7c_1400x933.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="933" src="https://substackcdn.com/image/fetch/$s_!yeVV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf95488b-7af9-4342-aec3-fddfd3b5ee7c_1400x933.png" width="1400" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Trump displaying an executive order at the “Winning the AI Race” summit. &lt;/span&gt;&lt;a href="https://www.wsj.com/articles/federal-ai-plan-targets-burdensome-state-regulations-b6dff028" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;The AI Action Plan lists several dozen policies across three pillars—accelerating innovation, building American AI infrastructure, and leading in international diplomacy and security—that will guide the Trump Administration’s approach to AI.&lt;/p&gt;&lt;p&gt;The central policy agenda outlined is to accelerate US AI development and deployment. For example, it proposes streamlining permitting for AI infrastructure (such as semiconductor manufacturing facilities, data centers, and energy infrastructure) adopting AI in the federal government and military, and funding AI research. But there’s a lot more in the plan, too: both a surprisingly strong focus on AI safety, as well as some items of concern.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Plan includes several policies that advance AI safety. &lt;/strong&gt;&lt;span&gt;While most of the plan’s policies are intended to accelerate AI development and deployment, it also correctly observes that AI development will only benefit Americans if done safely. Accordingly, it proposes several policies that advance AI safety. Some of the policies most relevant to AI safety include:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Invest in AI Interpretability, Control, and Robustness Breakthroughs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Build an AI Evaluations Ecosystem&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bolster Critical Infrastructure Cybersecurity&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Promote Secure-By-Design AI Technologies and Applications&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Promote Mature Federal Capacity for AI Incident Response&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Strengthen AI Compute Export Control Enforcement (this proposes location verification for AI chips)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ensure that the U.S. Government is at the Forefront of Evaluating National Security Risks in Frontier Models&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Invest in Biosecurity&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;While&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;not comprehensive, these policies are a great step in the right direction—and much better than might have been expected given the administration’s previous &lt;/span&gt;&lt;a href="https://www.presidency.ucsb.edu/documents/remarks-the-vice-president-the-artificial-intelligence-action-summit-paris-france" rel="rel"&gt;rhetorical disregard&lt;/a&gt;&lt;span&gt; for AI safety.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Overall,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;the plan introduces sensible policies that reflect the expertise of those who developed it. However, it is also shaped by the larger policy agenda of the Trump Administration, which may conflict with AI safety goals. We discuss some areas of potential concern below.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan does not want state AI legislation. &lt;/strong&gt;&lt;span&gt;One section proposes that the Federal government “should not allow AI-related Federal funding to be directed toward states with burdensome AI regulations that waste these funds, but should also not interfere with states’ rights to pass prudent laws that are not unduly restrictive to innovation.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This rule is less strict than Sen. Cruz’s failed AI regulation moratorium. But what constitutes a “burdensome” regulation will vary depending on who you ask (particularly if you ask frontier AI companies). In response to the plan, both Congressional Democrats and Rep. Marjorie Taylor Greene &lt;/span&gt;&lt;a href="https://beyer.house.gov/news/documentsingle.aspx?DocumentID=8605" rel="rel"&gt;expressed&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://x.com/repmtg/status/1948400163875152237" rel="rel"&gt;concern&lt;/a&gt;&lt;span&gt; about stifling state AI regulation.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan has a partisan view on what constitutes ideological bias.&lt;/strong&gt;&lt;span&gt; In a section on ensuring that AI “objectively reflects truth,” one policy instructs NIST to “revise the NIST AI Risk Management Framework to eliminate references to misinformation, Diversity, Equity, and Inclusion, and climate change.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A policy to promote objectivity in AI models could be great. However, that policy could itself be weaponized to promote ideological ends. In their &lt;/span&gt;&lt;a href="https://beyer.house.gov/news/documentsingle.aspx?DocumentID=8605" rel="rel"&gt;response&lt;/a&gt;&lt;span&gt;, Congressional Democrats wrote that “we support true AI neutrality—AI models trained on facts and science—but the administration's fixation on ‘anti-woke’ inputs is definitionally not neutral.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan endorses open-weight models.&lt;/strong&gt;&lt;span&gt; It writes that, “while the decision of whether and how to release an open or closed model is fundamentally up to the developer, the Federal government should create a supportive environment for open models.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Encouraging US companies to release open-weight models with dangerous capabilities would be a bad policy. But the specific policies the plan lists stop short of that—they mostly just provide resources to academic researchers (who are unlikely to develop frontier models) through the National AI Research Resource (NAIRR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan forgoes AI nonproliferation. &lt;/strong&gt;&lt;span&gt;The plan argues that the US “must meet global demand for AI by exporting its full AI technology stack—hardware, models, software, applications, and standards—to all countries willing to join America’s AI alliance.”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This plan’s rationale for this policy is that countries might otherwise look to acquire Chinese AI exports. However, it also continues the Trump Administration's reversal of the Biden-era policy (see the &lt;/span&gt;&lt;a href="https://www.federalregister.gov/documents/2025/01/15/2025-00636/framework-for-artificial-intelligence-diffusion" rel="rel"&gt;AI Diffusion Framework&lt;/a&gt;&lt;span&gt;) that sought to prevent the proliferation of dangerous AI capabilities abroad. While exporting American AI might strengthen the US’ position in the AI race, it also threatens to proliferate dangerous AI capabilities to malicious actors if the US does not ensure that other states implement robust security standards.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The plan advances a zero-sum race narrative. &lt;/strong&gt;&lt;span&gt;Kratsios, Sacks, and Rubio write that the promise of AI “is ours to seize, or to lose.” That is, they assume that the alternative to “AI dominance” is to give up AI’s benefits.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This argument is misleading—or at least underdeveloped. While there are reasons to support a US lead in AI, AI progress has the potential to benefit Americans whether or not the US “dominates” international AI development. Historically, general purpose technologies like AI &lt;/span&gt;&lt;a href="https://press.princeton.edu/books/paperback/9780691260341/technology-and-the-rise-of-great-powers" rel="rel"&gt;diffuse&lt;/a&gt;&lt;span&gt; across national boundaries. For example, technologies electricity and the internet have benefited people around the world, and not just within the nations that led their development.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The real motivation behind the AI race narrative in Washington is not seizing AI’s benefits, but rather competition over the balance of international power between the US and China. While there are reasons to be concerned about AI development dominated by China, racing towards US dominance is not the only alternative—and &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/why-racing-to-artificial-superintelligence-would-undermine-americas-national-security" rel="rel"&gt;creates&lt;/a&gt;&lt;span&gt; its own risks. In order to preserve international security, the US will need to &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim" rel="rel"&gt;proactively manage&lt;/a&gt;&lt;span&gt;—rather than just accelerate—a US-China AI race.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;On Thursday, OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/introducing-chatgpt-agent/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; a new agent mode for ChatGPT, which integrates Operator, Deep Research, and chatbot functionality into a unified system.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The system, ‘ChatGPT agent,’ has access to its own virtual computer, and OpenAI highlights that it can book flights and reservations, create slides and spreadsheets, and make online purchases. It can also connect to users’ personal accounts, for example, Google Calendar, Gmail, and GitHub.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT agent achieves SOTA performance on HLE and FrontierMath.&lt;/strong&gt;&lt;span&gt; ChatGPT agent’s capabilities extend beyond basic online automation—it achieves SOTA performance on several benchmarks measuring expert-level knowledge and reasoning. For example, ChatGPT agent gets 23% on Humanity’s Last Exam (HLE), when it does not use tools. When it uses tools like browsers and computer code, it gets 41.6%. This is similar to Grok 4, which gets 25.4% on HLE without tools and 44.4% with tools.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!YR3_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32c045cf-daf7-4254-8cdc-4dd861f2c397_884x802.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="802" src="https://substackcdn.com/image/fetch/$s_!YR3_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32c045cf-daf7-4254-8cdc-4dd861f2c397_884x802.png" width="884" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;OpenAI&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;also evaluated&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;ChatGPT agent against benchmarks measuring real-world task completion. OpenAI reports it performs better than humans nearly 50% of the time on an internal benchmark capturing diverse economically important tasks—an incredible claim that has yet to be reproduced. OpenAI also reports it surpasses human performance on data science tasks, and achieves state of the art results (though less than human) on tasks involving spreadsheets and web browsing.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!_NBd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39879533-bbcb-4b77-a1b9-67d248591bf5_1446x852.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="852" src="https://substackcdn.com/image/fetch/$s_!_NBd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39879533-bbcb-4b77-a1b9-67d248591bf5_1446x852.png" width="1446" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Greater autonomy introduces new risks.&lt;/strong&gt;&lt;span&gt; OpenAI published a &lt;/span&gt;&lt;a href="https://openai.com/index/chatgpt-agent-system-card/" rel="rel"&gt;system card&lt;/a&gt;&lt;span&gt; detailing ChatGPT agent’s risks. ChatGPT agent has access to user data and can take actions on the web, meaning that mistakes are higher stakes. OpenAI also highlighted the risk of adversarial manipulation through prompt injection, in which malicious websites could try to manipulate ChatGPT’s behavior, such as to reveal personal information about the user.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ChatGPT agent poses ‘high’ biological and chemical risk.&lt;/strong&gt;&lt;span&gt; ChatGPT agent is also the first system that OpenAI is treating as posing ‘high’ biological and chemical risk. According to the company’s &lt;/span&gt;&lt;a href="https://openai.com/index/updating-our-preparedness-framework/" rel="rel"&gt;Preparedness Framework&lt;/a&gt;&lt;span&gt;, that means the system could provide meaningful assistance to non-experts in creating known biological or chemical threats.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI says it’s activated several safeguards against these risks, including “comprehensive threat modeling, dual-use refusal training, always-on classifiers and reasoning monitors, and clear enforcement pipelines.” It also launched a &lt;/span&gt;&lt;a href="https://openai.com/bio-bug-bounty/" rel="rel"&gt;bug bounty program&lt;/a&gt;&lt;span&gt; for researchers to red team these safeguards.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OpenAI and Google DeepMind claim gold medal-level performance on the 2025 IMO. &lt;/strong&gt;&lt;span&gt;On Friday, OpenAI also &lt;/span&gt;&lt;a href="https://x.com/alexwei_/status/1946477742855532918" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that an experimental model had achieved gold medal-level performance on the 2025 International Mathematical Olympiad (IMO), solving five out of six questions. (A few human competitors &lt;/span&gt;&lt;a href="https://www.imo-official.org/year_individual_r.aspx?year=2025" rel="rel"&gt;scored&lt;/a&gt;&lt;span&gt; a perfect six out of six).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gold medal-level performance on the IMO has been a major goal in AI research for years, but only recently has seemed within reach. Last year, Google’s AlphaProof and AlphaGeometry 2 &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/" rel="rel"&gt;achieved&lt;/a&gt;&lt;span&gt; silver medal-level performance on the 2024 IMO, making gold-level performance this year plausible. On Monday, Google &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that its own reasoning LLM had achieved gold medal-level performance on the 2025 IMO, also solving five out of six questions.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OpenAI and Google used general reasoning LLMs.&lt;/strong&gt;&lt;span&gt; Where the capabilities of Google’s AlphaProof and AlphaGeometry 2 systems were narrowly focused on IMO-style math questions, OpenAI’s model is &lt;/span&gt;&lt;a href="https://x.com/polynoamial/status/1946478250974200272" rel="rel"&gt;apparently&lt;/a&gt;&lt;span&gt; not IMO-specific (or even math-specific), but instead a general reasoning LLM allowed to think for hours at a time. OpenAI published the model’s answers on the 2025 IMO &lt;/span&gt;&lt;a href="https://github.com/aw31/openai-imo-2025-proofs/" rel="rel"&gt;here&lt;/a&gt;&lt;span&gt;. Similarly, Google’s gold-winning performance used an advanced version of Gemini Deep Think—a general reasoning model that uses natural language.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;According to Nvidia's CEO, the US &lt;/span&gt;&lt;a href="https://apnews.com/article/nvidia-china-ai-chips-h20-trump-91588c36559bc881b8e010a9ed95cf0a" rel="rel"&gt;approved&lt;/a&gt;&lt;span&gt; the sale of Nvidia's H20 chips to China. Reuters reported that Nvidia &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/nvidia-orders-300000-h20-chips-tsmc-due-robust-china-demand-sources-say-2025-07-29/" rel="rel"&gt;ordered&lt;/a&gt;&lt;span&gt; 300,000 H20s from TSMC to meet expected Chinese demand.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Pentagon’s &lt;/span&gt;&lt;a href="https://comptroller.defense.gov/Portals/45/Documents/defbudget/FY2026/FY2026_Budget_Request.pdf" rel="rel"&gt;FY2026 budget request&lt;/a&gt;&lt;span&gt; called for $13.4 billion for autonomous systems.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Pentagon also &lt;/span&gt;&lt;a href="https://www.nextgov.com/acquisition/2025/07/pentagon-awards-multiple-companies-200m-contracts-ai-tools/406698/" rel="rel"&gt;awarded&lt;/a&gt;&lt;span&gt; Anthropic, Google, OpenAI and xAI each $200 million contracts to develop AI for national security applications.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;China &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; plans for an international AI governance organization.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The UK government &lt;/span&gt;&lt;a href="https://www.gov.uk/government/news/ai-security-institute-launches-international-coalition-to-safeguard-ai-development" rel="rel"&gt;launched&lt;/a&gt;&lt;span&gt; a £15m million-funded alignment research project.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Meta has &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/07/18/meta-refuses-to-sign-eus-ai-code-of-practice/" rel="rel"&gt;refused&lt;/a&gt;&lt;span&gt; to sign the EU’s GPAI Code of Practice.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic announced it &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/eu-code-practice" rel="rel"&gt;will&lt;/a&gt;&lt;span&gt; join OpenAI, Mistral and (likely) Microsoft in signing the Code of Practice.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;At a summit in Pennsylvania, President Trump &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/07/15/us/politics/trump-ai-pittsburgh-speech.html" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; more than $90 billion in private AI infrastructure investment in the state, which is led by Blackstone and Google.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Isobel Moure, Tim O'Reilly and Ilan Strauss &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/open-protocols-prevent-ai-monopolies" rel="rel"&gt;argue&lt;/a&gt;&lt;span&gt; that open protocols can prevent AI monopolies.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dane A. Morey, Mike Rayo, and David Woods &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/how-ai-can-degrade-human-performance-in-high-stakes-settings" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; how AI can degrade human performance in high-stakes settings.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anton Leicht &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/in-the-race-for-ai-supremacy-can-countries-stay-neutral" rel="rel"&gt;analyzes&lt;/a&gt;&lt;span&gt; whether, in the race for AI supremacy, countries can stay neutral.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://report2025.seismic.org/" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; from the Seismic Foundation found that people believe AI will make their lives worse, but ranks the issue low on their list of social priorities.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A YouGov &lt;/span&gt;&lt;a href="https://d3nkl3psvxxpe9.cloudfront.net/documents/Trump_Issue_Handling_poll_results.pdf" rel="rel"&gt;poll&lt;/a&gt;&lt;span&gt; found a -14 approval rating of Trump’s handling of AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://www.commonsensemedia.org/press-releases/nearly-3-in-4-teens-have-used-ai-companions-new-national-survey-finds" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; from Common Sense Media found that 3 in 4 teens have used AI companions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Rand published a &lt;/span&gt;&lt;a href="https://www.rand.org/pubs/working_papers/WRA4077-1.html" rel="rel"&gt;report&lt;/a&gt;&lt;span&gt; on verifying international AI agreements.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAIS is hiring a software engineer. Apply &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/24e7c67e-8a7e-401c-b87f-6d664ee51726" rel="rel"&gt;here&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action</guid><pubDate>Thu, 31 Jul 2025 17:43:20 +0000</pubDate></item><item><title>[NEW] Your public ChatGPT queries are getting indexed by Google and other search engines (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/your-public-chatgpt-queries-are-getting-indexed-by-google-and-other-search-engines/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Search-in-ChatGPT.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 7/31/25 4:10pm PT: Hours after this article was published, OpenAI said it removed the feature from ChatGPT that allowed users to make their public conversations discoverable by search engines. The company says this was a short-lived experiment that ultimately “introduced too many opportunities for folks to accidentally share things they didn’t intend to.” The original story follows.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a strange glimpse into the human mind: If you filter search results on Google, Bing, and other search engines to only include URLs from the domain “https://chatgpt.com/share,” you can find strangers’ conversations with ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sometimes, these shared conversation links are pretty dull — people ask for help renovating their bathroom, understanding astrophysics, and finding recipe ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another case, one user asks ChatGPT to rewrite their resume for a particular job application (judging by this person’s LinkedIn, which was easy to find based on the details in the chat log, they did not get the job). Someone else is asking questions that sound like they came out of an incel forum. Another person asks the snarky, hostile AI assistant if they can microwave a metal fork (for the record: no), but they continue to ask the AI increasingly absurd and trollish questions, eventually leading it to create a guide called “How to Use a Microwave Without Summoning Satan: A Beginner’s Guide.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT does not make these conversations public by default. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A conversation would be appended with a “/share” URL only if the user deliberately clicks the “share” button on their own chat and then clicks a second “create link” button. The service also declares that “your name, custom instructions, and any messages you add after sharing stay private.” After clicking through to create a link, users can toggle whether or not they want that link to be discoverable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users may not anticipate that other search engines will index their shared ChatGPT links, potentially betraying personal information (my apologies to the person whose LinkedIn I discovered).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though unintentional, this is a norm that was established in part by Google. When people share public links to files from Google Drive, such as documents with the “Anyone with link can view” setting, Google may index them in Search. However, Google generally does not surface links to Drive documents that have not been publicly posted on the web — for example, a document may appear in search if it is linked on a trusted website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to ChatGPT, these chats were indexed as part of an experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT chats are not public unless you choose to share them,” an OpenAI spokesperson told TechCrunch. “We’ve been testing ways to make it easier to share helpful conversations, while keeping users in control, and we recently ended an experiment to have chats appear in search engine results if you explicitly opted in when sharing.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While search engines like Google control the algorithms that determine what content gets surface for search terms, the search engines themselves cannot control what gets indexed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither Google nor any other search engine controls what pages are made public on the web,” a Google spokesperson told TechCrunch. “Publishers of these pages have full control over whether they are indexed by search engines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated, 7/31/25, 5:30 pm ET with comment and additional context from OpenAI.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Search-in-ChatGPT.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 7/31/25 4:10pm PT: Hours after this article was published, OpenAI said it removed the feature from ChatGPT that allowed users to make their public conversations discoverable by search engines. The company says this was a short-lived experiment that ultimately “introduced too many opportunities for folks to accidentally share things they didn’t intend to.” The original story follows.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a strange glimpse into the human mind: If you filter search results on Google, Bing, and other search engines to only include URLs from the domain “https://chatgpt.com/share,” you can find strangers’ conversations with ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sometimes, these shared conversation links are pretty dull — people ask for help renovating their bathroom, understanding astrophysics, and finding recipe ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another case, one user asks ChatGPT to rewrite their resume for a particular job application (judging by this person’s LinkedIn, which was easy to find based on the details in the chat log, they did not get the job). Someone else is asking questions that sound like they came out of an incel forum. Another person asks the snarky, hostile AI assistant if they can microwave a metal fork (for the record: no), but they continue to ask the AI increasingly absurd and trollish questions, eventually leading it to create a guide called “How to Use a Microwave Without Summoning Satan: A Beginner’s Guide.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT does not make these conversations public by default. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A conversation would be appended with a “/share” URL only if the user deliberately clicks the “share” button on their own chat and then clicks a second “create link” button. The service also declares that “your name, custom instructions, and any messages you add after sharing stay private.” After clicking through to create a link, users can toggle whether or not they want that link to be discoverable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users may not anticipate that other search engines will index their shared ChatGPT links, potentially betraying personal information (my apologies to the person whose LinkedIn I discovered).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though unintentional, this is a norm that was established in part by Google. When people share public links to files from Google Drive, such as documents with the “Anyone with link can view” setting, Google may index them in Search. However, Google generally does not surface links to Drive documents that have not been publicly posted on the web — for example, a document may appear in search if it is linked on a trusted website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to ChatGPT, these chats were indexed as part of an experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT chats are not public unless you choose to share them,” an OpenAI spokesperson told TechCrunch. “We’ve been testing ways to make it easier to share helpful conversations, while keeping users in control, and we recently ended an experiment to have chats appear in search engine results if you explicitly opted in when sharing.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While search engines like Google control the algorithms that determine what content gets surface for search terms, the search engines themselves cannot control what gets indexed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither Google nor any other search engine controls what pages are made public on the web,” a Google spokesperson told TechCrunch. “Publishers of these pages have full control over whether they are indexed by search engines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated, 7/31/25, 5:30 pm ET with comment and additional context from OpenAI.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/your-public-chatgpt-queries-are-getting-indexed-by-google-and-other-search-engines/</guid><pubDate>Thu, 31 Jul 2025 19:23:07 +0000</pubDate></item><item><title>[NEW] Enterprises prefer Anthropic’s AI models over anyone else’s, including OpenAI’s (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/enterprises-prefer-anthropics-ai-models-over-anyone-elses-including-openais/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s AI models are now the top choice for enterprises, surpassing OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic now holds 32% of the enterprise large language model market share by usage, according to a report from Menlo Ventures released on Thursday. OpenAI holds the second-largest market share by usage among enterprises, with 25%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The figure marks a strong reversal from even just a couple of years ago. Since 2023, OpenAI has seen its market share among enterprises decline sharply, according to the report, as Anthropic’s has steadily risen over the same timeframe. OpenAI held 50% of the enterprise market share by usage just two years ago while Anthropic had 12%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has seen enterprise usage for its models increase over the last few years as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has an even larger market share when it comes to coding, with 42% of the enterprise market share, the largest market share by a wide margin. Enterprise usage of Anthropic’s AI models are more than double OpenAI’s, when it comes to coding, which garnered 21% of overall market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s release of its Claude 3.5 Sonnet model in June 2024 is what laid the foundation for the company’s surge in usage, according to the report. The release of Claude 3.7 Sonnet  in February 2025 only accelerated that momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Menlo Ventures align with anecdotal chatter in the industry, which suggested that enterprise and startup developers preferred Claude over OpenAI’s ChatGPT. Meanwhile, OpenAI has a strong foothold on the consumer side of the house. The company reported last week that its users send more than 2.5 billion prompts to ChatGPT a day.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Menlo Ventures report found enterprises prefer closed models, which Anthropic and OpenAI use. More than half of enterprises replied that they don’t use open source models at all. Only 13% of enterprise daily workloads use open source models as of mid-year 2025, down from 19% at the beginning of the year. Meta still maintains dominance in the open source market.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s AI models are now the top choice for enterprises, surpassing OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic now holds 32% of the enterprise large language model market share by usage, according to a report from Menlo Ventures released on Thursday. OpenAI holds the second-largest market share by usage among enterprises, with 25%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The figure marks a strong reversal from even just a couple of years ago. Since 2023, OpenAI has seen its market share among enterprises decline sharply, according to the report, as Anthropic’s has steadily risen over the same timeframe. OpenAI held 50% of the enterprise market share by usage just two years ago while Anthropic had 12%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has seen enterprise usage for its models increase over the last few years as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has an even larger market share when it comes to coding, with 42% of the enterprise market share, the largest market share by a wide margin. Enterprise usage of Anthropic’s AI models are more than double OpenAI’s, when it comes to coding, which garnered 21% of overall market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s release of its Claude 3.5 Sonnet model in June 2024 is what laid the foundation for the company’s surge in usage, according to the report. The release of Claude 3.7 Sonnet  in February 2025 only accelerated that momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Menlo Ventures align with anecdotal chatter in the industry, which suggested that enterprise and startup developers preferred Claude over OpenAI’s ChatGPT. Meanwhile, OpenAI has a strong foothold on the consumer side of the house. The company reported last week that its users send more than 2.5 billion prompts to ChatGPT a day.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Menlo Ventures report found enterprises prefer closed models, which Anthropic and OpenAI use. More than half of enterprises replied that they don’t use open source models at all. Only 13% of enterprise daily workloads use open source models as of mid-year 2025, down from 19% at the beginning of the year. Meta still maintains dominance in the open source market.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/enterprises-prefer-anthropics-ai-models-over-anyone-elses-including-openais/</guid><pubDate>Thu, 31 Jul 2025 20:32:49 +0000</pubDate></item><item><title>[NEW] Apple plans to ‘significantly’ grow AI investments, Cook says (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/apple-plans-to-significantly-grow-ai-investments-cook-says/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/tim-cook-2025-GettyImages-2223580830.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday signaled that it’s getting more serious about its plans to catch up in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments,” CEO Tim Cook said on the Q3 2025 earnings call with investors. “Apple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone, and that’s at the heart of our AI strategy,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cook expanded on those comments on the call, noting that Apple was “reallocating a fair number of people” to focus on AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a great, great team and we’re putting all of our energy behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI investments are also driving increased CapEx spending, which was up year-to-date, the company said. However, Apple pointed out that it still employed a hybrid model where it relies on third parties to make capital investments, which is why the figure won’t grow exponentially. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ahead of its call, the company shared in an interview with CNBC that it’s open to M&amp;amp;A to accelerate its roadmap. The company told the outlet that it has already acquired seven companies this year. None was “huge” in terms of dollar amount, Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the call, he added that Apple was making acquisitions at the rate of one every several weeks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has been criticized for having been caught off guard by the AI era; it has announced a number of AI features that it has, so far, failed to ship. The company was even accused of showing off an improved AI-powered version of Siri that wasn’t close to being ready to launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Apple has defended itself by saying that it doesn’t need to rush — that launching the wrong features or the wrong products just to be first would be a mistake. That’s especially true if those products don’t work as promised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Apple says it has launched more than 20 Apple Intelligence features, including visual intelligence, cleanup, and writing tools. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Later this year, Apple plans to launch AI features like live translation and an AI-powered workout buddy, but the more personalized Siri’s improvements have been delayed to 2026. On the call with investors, Cook said the company was “making good progress” on the Siri update. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also shared his thoughts on how AI may impact the iPhone business if new hardware were to emerge. For instance, Meta CEO Mark Zuckerberg earlier this week suggested that AI glasses would be the form factor for interacting with the new technology, and those without them would be left behind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cook, naturally, disagreed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s difficult to see a world where iPhone’s not living in it,” he said. “That doesn’t mean that we are not thinking about other things, as well, but I think that the [AI] devices are likely to be complementary devices, not substitutions.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec declined to answer a question about which AI technologies it believed would ultimately be commoditized, saying that would give away part of its strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple delivered better-than-expected iPhone sales and record revenue in Q3, which saw its stock pop in after-hours trading.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with more details from the earnings call. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/tim-cook-2025-GettyImages-2223580830.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday signaled that it’s getting more serious about its plans to catch up in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments,” CEO Tim Cook said on the Q3 2025 earnings call with investors. “Apple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone, and that’s at the heart of our AI strategy,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cook expanded on those comments on the call, noting that Apple was “reallocating a fair number of people” to focus on AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a great, great team and we’re putting all of our energy behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI investments are also driving increased CapEx spending, which was up year-to-date, the company said. However, Apple pointed out that it still employed a hybrid model where it relies on third parties to make capital investments, which is why the figure won’t grow exponentially. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ahead of its call, the company shared in an interview with CNBC that it’s open to M&amp;amp;A to accelerate its roadmap. The company told the outlet that it has already acquired seven companies this year. None was “huge” in terms of dollar amount, Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the call, he added that Apple was making acquisitions at the rate of one every several weeks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has been criticized for having been caught off guard by the AI era; it has announced a number of AI features that it has, so far, failed to ship. The company was even accused of showing off an improved AI-powered version of Siri that wasn’t close to being ready to launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Apple has defended itself by saying that it doesn’t need to rush — that launching the wrong features or the wrong products just to be first would be a mistake. That’s especially true if those products don’t work as promised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Apple says it has launched more than 20 Apple Intelligence features, including visual intelligence, cleanup, and writing tools. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Later this year, Apple plans to launch AI features like live translation and an AI-powered workout buddy, but the more personalized Siri’s improvements have been delayed to 2026. On the call with investors, Cook said the company was “making good progress” on the Siri update. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also shared his thoughts on how AI may impact the iPhone business if new hardware were to emerge. For instance, Meta CEO Mark Zuckerberg earlier this week suggested that AI glasses would be the form factor for interacting with the new technology, and those without them would be left behind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cook, naturally, disagreed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s difficult to see a world where iPhone’s not living in it,” he said. “That doesn’t mean that we are not thinking about other things, as well, but I think that the [AI] devices are likely to be complementary devices, not substitutions.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec declined to answer a question about which AI technologies it believed would ultimately be commoditized, saying that would give away part of its strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple delivered better-than-expected iPhone sales and record revenue in Q3, which saw its stock pop in after-hours trading.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with more details from the earnings call. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/apple-plans-to-significantly-grow-ai-investments-cook-says/</guid><pubDate>Thu, 31 Jul 2025 21:21:41 +0000</pubDate></item><item><title>[NEW] YouTube’s selfie collection, AI age checks are concerning, privacy experts say (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/youtubes-selfie-collection-ai-age-checks-are-concerning-privacy-experts-say/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Any YouTuber wrongly labeled a teen must provide an ID, credit card, or selfie.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Privacy experts are demanding transparency after YouTube announced it would test using AI to estimate user ages in the US ahead of a wider rollout of the age check system.&lt;/p&gt;
&lt;p&gt;Throughout the first half of August, YouTube will begin interpreting "a variety of signals" to determine if certain users are under 18. No new user data will be collected, but those signals could include things like "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account," YouTube said.&lt;/p&gt;
&lt;p&gt;Anyone determined to be too young will automatically be hit with protections, with YouTube disabling their personalized advertising, "turning on digital wellbeing tools," and "limiting repetitive views of some kinds of content" determined to be harmful or too mature.&lt;/p&gt;
&lt;p&gt;YouTube claims it has been estimating age in other markets "for some time, where it is working well." But it's clearly not a perfect system, as the company has set up an appeals process for any adults accidentally flagged as teens by AI.&lt;/p&gt;
&lt;p&gt;That appeals process seems problematic, privacy experts told Ars,&amp;nbsp; as it requires users to submit a government ID, credit card, or selfie to verify their actual age. YouTube does not specify in its blog what will happen with this data. Asked for comment, YouTube would only confirm to Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;"I think we can assume that means it will be retained for other purposes," David Greene, senior staff attorney and civil liberties director for the Electronic Frontier Foundation (EFF), told Ars. But the lack of transparency leaves users guessing about those other purposes, as risks of leaks or breaches seemingly risk exposing vulnerable users who rely on anonymity to use YouTube.&lt;/p&gt;
&lt;p&gt;Greene told Ars that YouTube's statement on data retention is even weaker and stands in "stark contrast" to "hollow statements" sometimes made by companies, such as "we'll do our best to protect your data" or "we've been assured that the third-party vendor we use will not retain the data."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Suzanne Bernstein, who serves as counsel for the Electronic Privacy Information Center (EPIC), said it's "tough" to rely on any company's promises when it comes to using data for other purposes, like enhancing its user profiles or selling data to third parties. She suggested that users would be better informed if YouTube shared more information about how data collected for reverse age checks is stored, whether it's ever sold, and, perhaps most importantly, how soon it's deleted.&lt;/p&gt;
&lt;p&gt;Until then, "discomfort with certain appeals processes which require providing really sensitive personal information is totally understandable," Bernstein said.&lt;/p&gt;
&lt;p&gt;"I think the increased surveillance of user behavior is not privacy protective," Bernstein said. "The most privacy protective option involves retaining the least amount of information and certainly not sharing it with third parties, which is not something that YouTube here has promised to do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;What’s worse, sharing a selfie or a credit card?&lt;/h2&gt;
&lt;p&gt;In addition to a lack of transparency around the data retention practices, Bernstein noted that YouTube is not being very transparent about how effective its AI age checks are—which is a recurring AI industry pattern that's often repeated as the tech is hyped across many sectors. Greene noted that YouTube does not seem to have conducted any external audits on the AI system or provided any "academic way of looking at it."&lt;/p&gt;
&lt;p&gt;Neither expert felt comfortable quantifying a potential error rate, but it's likely that AI could guess users' ages wrong. Even the best age-estimation tech has about a two-year error window on each side, experts pointed out. That could mean users between 16 and 20 are especially susceptible to incorrect age estimations—with potential errors going both ways, perhaps labeling teens as adults or adults as teens—in addition to perhaps anyone whose viewing habits strike the system as immature.&lt;/p&gt;
&lt;p&gt;Companies launching AI tools that heighten data privacy risks—especially on platforms as big and irreplaceable for many as YouTube—is part of the reason why groups like the EFF and EPIC push for state or federal legislation to minimize consumer data collection and provide other protections to help put personal data back under users' control, no matter how tech evolves. Bernstein suggested that users alarmed by the AI age checks should "encourage legislators to require significant privacy and data security safeguards for any kind of age assurance" systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bernstein and Greene agreed that due to the lack of comprehensive data privacy legislation, YouTubers who want to appeal AI mistakes do not have great options.&lt;/p&gt;
&lt;p&gt;"They're all bad," Greene said. But in particular, sharing selfies or any "kind of biometric age estimation tools without significant privacy and data security safeguards" is risky, Bernstein said.&lt;/p&gt;
&lt;p&gt;As Greene explained, any biometric data collection "is really bad and creepy and inhibiting to users who are sensitive" about "identifying themselves while online line," such as political dissidents or victims of abuse. Suddenly, it could be their "burden" to "submit biometric information or government ID in order to use the service," Greene said. That's a huge change for people used to being on YouTube without using their real name or without allowing their information to be traced across the Internet.&lt;/p&gt;
&lt;p&gt;"A breach of biometric information is far more significant than a breach of some other information," Greene said. "So we should be concerned about them collecting selfies."&lt;/p&gt;
&lt;p&gt;But that doesn't mean the selfie option is the worst choice for everyone who can't abandon YouTube, Greene noted. Each user will have to assess their own risks, with some likely more vulnerable to having their identity exposed and others likely more vulnerable to having financial data exposed.&lt;/p&gt;
&lt;p&gt;Greene expects that the more pressure platforms and websites face to age-gate services, the more radically it could change people's relationships with the Internet. On a platform where creators reliably generate the highest earnings, YouTube's AI age checks could possibly serve as a harbinger of a future Internet where every popular account can be unmasked and linked to a known entity.&lt;/p&gt;
&lt;p&gt;"Once you get into this bad situation where it's impossible to use these services anonymously, then it really depends on someone's own threat model about what's going to be the least harmful way for them to use the site," Greene said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Any YouTuber wrongly labeled a teen must provide an ID, credit card, or selfie.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Privacy experts are demanding transparency after YouTube announced it would test using AI to estimate user ages in the US ahead of a wider rollout of the age check system.&lt;/p&gt;
&lt;p&gt;Throughout the first half of August, YouTube will begin interpreting "a variety of signals" to determine if certain users are under 18. No new user data will be collected, but those signals could include things like "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account," YouTube said.&lt;/p&gt;
&lt;p&gt;Anyone determined to be too young will automatically be hit with protections, with YouTube disabling their personalized advertising, "turning on digital wellbeing tools," and "limiting repetitive views of some kinds of content" determined to be harmful or too mature.&lt;/p&gt;
&lt;p&gt;YouTube claims it has been estimating age in other markets "for some time, where it is working well." But it's clearly not a perfect system, as the company has set up an appeals process for any adults accidentally flagged as teens by AI.&lt;/p&gt;
&lt;p&gt;That appeals process seems problematic, privacy experts told Ars,&amp;nbsp; as it requires users to submit a government ID, credit card, or selfie to verify their actual age. YouTube does not specify in its blog what will happen with this data. Asked for comment, YouTube would only confirm to Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;"I think we can assume that means it will be retained for other purposes," David Greene, senior staff attorney and civil liberties director for the Electronic Frontier Foundation (EFF), told Ars. But the lack of transparency leaves users guessing about those other purposes, as risks of leaks or breaches seemingly risk exposing vulnerable users who rely on anonymity to use YouTube.&lt;/p&gt;
&lt;p&gt;Greene told Ars that YouTube's statement on data retention is even weaker and stands in "stark contrast" to "hollow statements" sometimes made by companies, such as "we'll do our best to protect your data" or "we've been assured that the third-party vendor we use will not retain the data."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Suzanne Bernstein, who serves as counsel for the Electronic Privacy Information Center (EPIC), said it's "tough" to rely on any company's promises when it comes to using data for other purposes, like enhancing its user profiles or selling data to third parties. She suggested that users would be better informed if YouTube shared more information about how data collected for reverse age checks is stored, whether it's ever sold, and, perhaps most importantly, how soon it's deleted.&lt;/p&gt;
&lt;p&gt;Until then, "discomfort with certain appeals processes which require providing really sensitive personal information is totally understandable," Bernstein said.&lt;/p&gt;
&lt;p&gt;"I think the increased surveillance of user behavior is not privacy protective," Bernstein said. "The most privacy protective option involves retaining the least amount of information and certainly not sharing it with third parties, which is not something that YouTube here has promised to do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;What’s worse, sharing a selfie or a credit card?&lt;/h2&gt;
&lt;p&gt;In addition to a lack of transparency around the data retention practices, Bernstein noted that YouTube is not being very transparent about how effective its AI age checks are—which is a recurring AI industry pattern that's often repeated as the tech is hyped across many sectors. Greene noted that YouTube does not seem to have conducted any external audits on the AI system or provided any "academic way of looking at it."&lt;/p&gt;
&lt;p&gt;Neither expert felt comfortable quantifying a potential error rate, but it's likely that AI could guess users' ages wrong. Even the best age-estimation tech has about a two-year error window on each side, experts pointed out. That could mean users between 16 and 20 are especially susceptible to incorrect age estimations—with potential errors going both ways, perhaps labeling teens as adults or adults as teens—in addition to perhaps anyone whose viewing habits strike the system as immature.&lt;/p&gt;
&lt;p&gt;Companies launching AI tools that heighten data privacy risks—especially on platforms as big and irreplaceable for many as YouTube—is part of the reason why groups like the EFF and EPIC push for state or federal legislation to minimize consumer data collection and provide other protections to help put personal data back under users' control, no matter how tech evolves. Bernstein suggested that users alarmed by the AI age checks should "encourage legislators to require significant privacy and data security safeguards for any kind of age assurance" systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bernstein and Greene agreed that due to the lack of comprehensive data privacy legislation, YouTubers who want to appeal AI mistakes do not have great options.&lt;/p&gt;
&lt;p&gt;"They're all bad," Greene said. But in particular, sharing selfies or any "kind of biometric age estimation tools without significant privacy and data security safeguards" is risky, Bernstein said.&lt;/p&gt;
&lt;p&gt;As Greene explained, any biometric data collection "is really bad and creepy and inhibiting to users who are sensitive" about "identifying themselves while online line," such as political dissidents or victims of abuse. Suddenly, it could be their "burden" to "submit biometric information or government ID in order to use the service," Greene said. That's a huge change for people used to being on YouTube without using their real name or without allowing their information to be traced across the Internet.&lt;/p&gt;
&lt;p&gt;"A breach of biometric information is far more significant than a breach of some other information," Greene said. "So we should be concerned about them collecting selfies."&lt;/p&gt;
&lt;p&gt;But that doesn't mean the selfie option is the worst choice for everyone who can't abandon YouTube, Greene noted. Each user will have to assess their own risks, with some likely more vulnerable to having their identity exposed and others likely more vulnerable to having financial data exposed.&lt;/p&gt;
&lt;p&gt;Greene expects that the more pressure platforms and websites face to age-gate services, the more radically it could change people's relationships with the Internet. On a platform where creators reliably generate the highest earnings, YouTube's AI age checks could possibly serve as a harbinger of a future Internet where every popular account can be unmasked and linked to a known entity.&lt;/p&gt;
&lt;p&gt;"Once you get into this bad situation where it's impossible to use these services anonymously, then it really depends on someone's own threat model about what's going to be the least harmful way for them to use the site," Greene said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/youtubes-selfie-collection-ai-age-checks-are-concerning-privacy-experts-say/</guid><pubDate>Thu, 31 Jul 2025 21:27:34 +0000</pubDate></item><item><title>[NEW] Reddit revenue soars as it bets on AI and advertising (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/reddit-revenue-soars-as-it-bets-on-ai-and-advertising/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/reddit-ipo-v2.webp?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit reported its second-quarter earnings on Thursday, and it’s clear that the company’s focus on AI has ramped up considerably.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One significant area of investment is growing its advertising business, supported by its AI-powered marketing tools. The results revealed that the majority of Reddit’s revenue continues to come from ads, which brought in $465 million, representing 93% of the company’s total revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last month, Reddit launched two new features for advertisers: Reddit Insights, a tool that leverages the billions of posts and comments on the platform to spot trends and offer real-time insights for campaign strategies, and Conversation Summary Add-ons, which let advertisers include Reddit user discussions directly in ads, showing public opinions about products or brands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also saw growth in its “other revenue” category, which includes its data licensing business — meaning its deals with AI providers for access to its data. Reddit said the category jumped 24% year-over-year to $35 million, up from $28.1 million in the same period a year prior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reddit has already established content licensing agreements with major players in AI, including Google and OpenAI. Although these deals are still new, the results from the second quarter point out a steady income stream that has significant potential for the long haul.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another key AI-powered feature is the Reddit Answers tool, which launched in December. This tool, which offers answers in a conversational interface, has attracted 6 million weekly users, a considerable jump from 1 million users in the previous quarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to shareholders, Reddit CEO Steve Huffman said the platform is working to integrate the tool “more deeply into the core search experience” to make “search a central feature across Reddit.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/reddit-ipo-v2.webp?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit reported its second-quarter earnings on Thursday, and it’s clear that the company’s focus on AI has ramped up considerably.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One significant area of investment is growing its advertising business, supported by its AI-powered marketing tools. The results revealed that the majority of Reddit’s revenue continues to come from ads, which brought in $465 million, representing 93% of the company’s total revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last month, Reddit launched two new features for advertisers: Reddit Insights, a tool that leverages the billions of posts and comments on the platform to spot trends and offer real-time insights for campaign strategies, and Conversation Summary Add-ons, which let advertisers include Reddit user discussions directly in ads, showing public opinions about products or brands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also saw growth in its “other revenue” category, which includes its data licensing business — meaning its deals with AI providers for access to its data. Reddit said the category jumped 24% year-over-year to $35 million, up from $28.1 million in the same period a year prior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reddit has already established content licensing agreements with major players in AI, including Google and OpenAI. Although these deals are still new, the results from the second quarter point out a steady income stream that has significant potential for the long haul.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another key AI-powered feature is the Reddit Answers tool, which launched in December. This tool, which offers answers in a conversational interface, has attracted 6 million weekly users, a considerable jump from 1 million users in the previous quarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to shareholders, Reddit CEO Steve Huffman said the platform is working to integrate the tool “more deeply into the core search experience” to make “search a central feature across Reddit.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/reddit-revenue-soars-as-it-bets-on-ai-and-advertising/</guid><pubDate>Thu, 31 Jul 2025 22:13:23 +0000</pubDate></item><item><title>[NEW] Developer survey shows trust in AI coding tools is falling as usage rises (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "AI solutions that are almost right, but not quite" lead to more debugging work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The tab key on a Keychron K1" class="absolute inset-0 w-full h-full object-cover hidden" height="374" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-640x374.jpg" width="640" /&gt;
                  &lt;img alt="The tab key on a Keychron K1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You need to do more than just hit tab on suggestions.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI tools are widely used by software developers, but those devs and their managers are still grappling with figuring out how exactly to best put the tools to use, with growing pains emerging along the way.&lt;/p&gt;
&lt;p&gt;That's the takeaway from the latest survey of 49,000 professional developers by community and information hub StackOverflow, which itself has been heavily impacted by the addition of large language models (LLMs) to developer workflows.&lt;/p&gt;
&lt;p&gt;The survey found that four in five developers use AI tools in their workflow in 2025—a portion that has been rapidly growing in recent years. That said, "trust in the accuracy of AI has fallen from 40 percent in previous years to just 29 percent this year."&lt;/p&gt;
&lt;p&gt;The disparity between those two metrics illustrates the evolving and complex impact of AI tools like GitHub Copilot or Cursor on the profession. There's relatively little debate among developers that the tools are or ought to be useful, but people are still figuring out what the best applications (and limits) are.&lt;/p&gt;
&lt;p&gt;When asked what their top frustration with AI tools was, 45 percent of respondents said they struggled with "AI solutions that are almost right, but not quite"—the single largest reported problem. That's because unlike outputs that are clearly wrong, these can introduce insidious bugs or other problems that are difficult to immediately identify and relatively time-consuming to troubleshoot, especially for junior developers who approached the work with a false sense of confidence thanks to their reliance on AI.&lt;/p&gt;
&lt;p&gt;As a result, more than a third of the developers in the survey "report that some of their visits to Stack Overflow are a result of AI-related issues." That is to say, code suggestions they accepted from an LLM-based tool introduced problems they then had to turn to other people to solve.&lt;/p&gt;
&lt;p&gt;Even as major improvements have recently come via reasoning-optimized models, that close-but-not-quite unreliability is unlikely to ever vanish completely; it's endemic to the very nature of how the predictive technology works.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That's why 72 percent of the survey participants said that "vibe coding" is not part of their professional work; some feel it's too unreliable, and it can introduce hard-to-debug issues that are not appropriate for production.&lt;/p&gt;
&lt;h2&gt;Why devs use the tools anyway&lt;/h2&gt;
&lt;p&gt;So given all that skepticism and frustration, why are devs still using the tools? Well, in some cases, their managers are trying to force them to. But more commonly, it's because the tools are still clearly useful—it's just important not to misapply them.&lt;/p&gt;
&lt;p&gt;It's important that managers and individual contributors bring AI tools into the workflow alongside robust training to ensure a deep understanding of best practices so the tools aren't misused in a way that creates more problems than it solves or that wastes more time than it saves.&lt;/p&gt;
&lt;p&gt;Developers need to be less trusting of things like Copilot autocomplete suggestions, treating them more as a starting point rather than just hitting tab and moving on. Tools like that are best suited for a sort of limited pair programming relationship: asking the LLM to find problems or suggest more elegant solutions that you take into critical consideration, not to suggest complete methods that you take at face value.&lt;/p&gt;
&lt;p&gt;They can also be useful for learning. The opportunity to always be learning by continually building familiarity with new languages, frameworks, or methodologies is one of the things that draws some people to the job, and LLMs can reduce friction in that process by answering questions in a more targeted way than is possible with laborious searches through often incomplete technical documentation—exactly the sort of thing that people have historically used StackOverflow for in the past.&lt;/p&gt;
&lt;p&gt;"Although we have seen a decline in traffic, in no way is it as dramatic as some would indicate," StackOverflow Chief Product and Technology Officer Jody Bailey said in a comment to VentureBeat. StackOverflow plans to commit some of its resources both to expanding AI tool literacy and to fostering community discussions that help solve issues that are specific to workflows that involve those tools.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "AI solutions that are almost right, but not quite" lead to more debugging work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The tab key on a Keychron K1" class="absolute inset-0 w-full h-full object-cover hidden" height="374" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-640x374.jpg" width="640" /&gt;
                  &lt;img alt="The tab key on a Keychron K1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You need to do more than just hit tab on suggestions.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI tools are widely used by software developers, but those devs and their managers are still grappling with figuring out how exactly to best put the tools to use, with growing pains emerging along the way.&lt;/p&gt;
&lt;p&gt;That's the takeaway from the latest survey of 49,000 professional developers by community and information hub StackOverflow, which itself has been heavily impacted by the addition of large language models (LLMs) to developer workflows.&lt;/p&gt;
&lt;p&gt;The survey found that four in five developers use AI tools in their workflow in 2025—a portion that has been rapidly growing in recent years. That said, "trust in the accuracy of AI has fallen from 40 percent in previous years to just 29 percent this year."&lt;/p&gt;
&lt;p&gt;The disparity between those two metrics illustrates the evolving and complex impact of AI tools like GitHub Copilot or Cursor on the profession. There's relatively little debate among developers that the tools are or ought to be useful, but people are still figuring out what the best applications (and limits) are.&lt;/p&gt;
&lt;p&gt;When asked what their top frustration with AI tools was, 45 percent of respondents said they struggled with "AI solutions that are almost right, but not quite"—the single largest reported problem. That's because unlike outputs that are clearly wrong, these can introduce insidious bugs or other problems that are difficult to immediately identify and relatively time-consuming to troubleshoot, especially for junior developers who approached the work with a false sense of confidence thanks to their reliance on AI.&lt;/p&gt;
&lt;p&gt;As a result, more than a third of the developers in the survey "report that some of their visits to Stack Overflow are a result of AI-related issues." That is to say, code suggestions they accepted from an LLM-based tool introduced problems they then had to turn to other people to solve.&lt;/p&gt;
&lt;p&gt;Even as major improvements have recently come via reasoning-optimized models, that close-but-not-quite unreliability is unlikely to ever vanish completely; it's endemic to the very nature of how the predictive technology works.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That's why 72 percent of the survey participants said that "vibe coding" is not part of their professional work; some feel it's too unreliable, and it can introduce hard-to-debug issues that are not appropriate for production.&lt;/p&gt;
&lt;h2&gt;Why devs use the tools anyway&lt;/h2&gt;
&lt;p&gt;So given all that skepticism and frustration, why are devs still using the tools? Well, in some cases, their managers are trying to force them to. But more commonly, it's because the tools are still clearly useful—it's just important not to misapply them.&lt;/p&gt;
&lt;p&gt;It's important that managers and individual contributors bring AI tools into the workflow alongside robust training to ensure a deep understanding of best practices so the tools aren't misused in a way that creates more problems than it solves or that wastes more time than it saves.&lt;/p&gt;
&lt;p&gt;Developers need to be less trusting of things like Copilot autocomplete suggestions, treating them more as a starting point rather than just hitting tab and moving on. Tools like that are best suited for a sort of limited pair programming relationship: asking the LLM to find problems or suggest more elegant solutions that you take into critical consideration, not to suggest complete methods that you take at face value.&lt;/p&gt;
&lt;p&gt;They can also be useful for learning. The opportunity to always be learning by continually building familiarity with new languages, frameworks, or methodologies is one of the things that draws some people to the job, and LLMs can reduce friction in that process by answering questions in a more targeted way than is possible with laborious searches through often incomplete technical documentation—exactly the sort of thing that people have historically used StackOverflow for in the past.&lt;/p&gt;
&lt;p&gt;"Although we have seen a decline in traffic, in no way is it as dramatic as some would indicate," StackOverflow Chief Product and Technology Officer Jody Bailey said in a comment to VentureBeat. StackOverflow plans to commit some of its resources both to expanding AI tool literacy and to fostering community discussions that help solve issues that are specific to workflows that involve those tools.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/</guid><pubDate>Thu, 31 Jul 2025 22:39:22 +0000</pubDate></item><item><title>What’s the real cost of chasing AGI? Power consolidation is just the start, says the AI Now Institute. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</guid><pubDate>Thu, 31 Jul 2025 23:25:36 +0000</pubDate></item><item><title>[NEW] Amazon CEO wants to put ads in your Alexa+ conversations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/amazon-ceo-wants-to-put-ads-in-your-alexa-conversations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon CEO Andy Jassy sees an opportunity to deliver ads to users during their conversations with the company’s AI-powered digital assistant, Alexa+, he said during Amazon’s second-quarter earnings call Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People are excited about the devices that they can buy from us that has Alexa+ enabled in it. People do a lot of shopping [with Alexa+]; it’s a delightful shopping experience that will keep getting better,” said Jassy on the call with investors and Wall Street analysts. “I think over time, there will be opportunities, as people are engaging in more multi-turn conversations, to have advertising play a role to help people find discovery, and also as a lever to drive revenue.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon says it has rolled out Alexa+ to millions of customers, part of an effort to make its legacy digital assistant capable of agentic behaviors and more natural to talk to. Alexa+ is Amazon’s answer to generative AI voice assistants from OpenAI, Google, and Perplexity that have made legacy systems feel outdated. However, the business models behind generative AI products remain unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has made Alexa+ free for Prime customers (who pay $14.99 a month) and added a $20-a-month subscription tier for Alexa+ on its own. Jassy suggested on Thursday that Alexa+ could eventually include subscription tiers beyond what’s available today — perhaps an ad-free tier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up until now, ads have only appeared in Alexa in limited ways. Users may occasionally see a visual ad on Amazon’s smart display device, the Echo Show, or hear a pre-recorded ad in between songs on one of Alexa’s smart speakers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Jassy’s description of an AI-generated ad that Alexa+ delivers in a multistep conversation, which could help users find new products, is uncharted territory for Amazon and the broader tech industry. Marketers have expressed interest in advertising in AI chatbots, and specifically Alexa+, but exactly how remains unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s competitors in the AI space seem to think advertising is a promising business model for generative AI, too. Google is exploring how to infuse ads into its AI-powered search experience, AI mode. OpenAI CEO Sam Altman said he’s open to a “tasteful” form of advertising in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon is spending a fortune to catch up in the AI race. In the second quarter of 2025, Amazon’s capital expenditures rose to $31.4 billion, up 90% from the same period last year. A large part of that increased spending is to develop Amazon’s in-house AI chips and build out data centers to support AI models. While the revenue of Amazon’s cloud business, AWS, grew 18% in the second quarter, the company likely needs to generate new business to pay for these investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy is betting that users will talk to Alexa+ more than Alexa, which could drive more advertising and more shopping on Amazon.com. However, early reviews of Alexa+ have been mixed. Amazon has reportedly struggled to ship some of Alexa+’s more complicated features, and the rollout has been slower than many expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot to figure out before Amazon puts ads in Alexa+. Like most AI models, Alexa+ is not immune to hallucinations. Before advertisers agree to make Alexa+ a spokesperson for their products, Amazon may have to come up with some ways to ensure that its AI will not offer false advertising for a product.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jassy seems enthusiastic about making advertising a larger part of Amazon business. Amazon’s advertising revenue went up 22% in the second quarter, compared to the same period last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Delivering ads in AI chatbot conversations may also raise privacy concerns. People tend to talk more with AI chatbots compared to deterministic assistants, like the traditional Alexa and Siri products. As a result, generative AI chatbots tend to collect more information on users. Some users might be unsettled by having that information sold to advertisers and having ads appear in their natural language conversations with AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon CEO Andy Jassy sees an opportunity to deliver ads to users during their conversations with the company’s AI-powered digital assistant, Alexa+, he said during Amazon’s second-quarter earnings call Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People are excited about the devices that they can buy from us that has Alexa+ enabled in it. People do a lot of shopping [with Alexa+]; it’s a delightful shopping experience that will keep getting better,” said Jassy on the call with investors and Wall Street analysts. “I think over time, there will be opportunities, as people are engaging in more multi-turn conversations, to have advertising play a role to help people find discovery, and also as a lever to drive revenue.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon says it has rolled out Alexa+ to millions of customers, part of an effort to make its legacy digital assistant capable of agentic behaviors and more natural to talk to. Alexa+ is Amazon’s answer to generative AI voice assistants from OpenAI, Google, and Perplexity that have made legacy systems feel outdated. However, the business models behind generative AI products remain unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has made Alexa+ free for Prime customers (who pay $14.99 a month) and added a $20-a-month subscription tier for Alexa+ on its own. Jassy suggested on Thursday that Alexa+ could eventually include subscription tiers beyond what’s available today — perhaps an ad-free tier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up until now, ads have only appeared in Alexa in limited ways. Users may occasionally see a visual ad on Amazon’s smart display device, the Echo Show, or hear a pre-recorded ad in between songs on one of Alexa’s smart speakers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Jassy’s description of an AI-generated ad that Alexa+ delivers in a multistep conversation, which could help users find new products, is uncharted territory for Amazon and the broader tech industry. Marketers have expressed interest in advertising in AI chatbots, and specifically Alexa+, but exactly how remains unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s competitors in the AI space seem to think advertising is a promising business model for generative AI, too. Google is exploring how to infuse ads into its AI-powered search experience, AI mode. OpenAI CEO Sam Altman said he’s open to a “tasteful” form of advertising in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon is spending a fortune to catch up in the AI race. In the second quarter of 2025, Amazon’s capital expenditures rose to $31.4 billion, up 90% from the same period last year. A large part of that increased spending is to develop Amazon’s in-house AI chips and build out data centers to support AI models. While the revenue of Amazon’s cloud business, AWS, grew 18% in the second quarter, the company likely needs to generate new business to pay for these investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy is betting that users will talk to Alexa+ more than Alexa, which could drive more advertising and more shopping on Amazon.com. However, early reviews of Alexa+ have been mixed. Amazon has reportedly struggled to ship some of Alexa+’s more complicated features, and the rollout has been slower than many expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot to figure out before Amazon puts ads in Alexa+. Like most AI models, Alexa+ is not immune to hallucinations. Before advertisers agree to make Alexa+ a spokesperson for their products, Amazon may have to come up with some ways to ensure that its AI will not offer false advertising for a product.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jassy seems enthusiastic about making advertising a larger part of Amazon business. Amazon’s advertising revenue went up 22% in the second quarter, compared to the same period last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Delivering ads in AI chatbot conversations may also raise privacy concerns. People tend to talk more with AI chatbots compared to deterministic assistants, like the traditional Alexa and Siri products. As a result, generative AI chatbots tend to collect more information on users. Some users might be unsettled by having that information sold to advertisers and having ads appear in their natural language conversations with AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/amazon-ceo-wants-to-put-ads-in-your-alexa-conversations/</guid><pubDate>Thu, 31 Jul 2025 23:34:53 +0000</pubDate></item><item><title>[NEW] Female-founded semiconductor AI startup SixSense raises $8.5M (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/female-founded-semiconductor-ai-startup-sixsense-raises-funding/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A Singapore-based deep tech startup called SixSense has developed an AI-powered platform that helps semiconductor manufacturers predict and detect potential chip defects on production lines in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It has raised $8.5 million in Series A bringing its total funding to around $12 million. The round was led by Peak XV’s Surge (formerly Sequoia India &amp;amp; SEA), with participation from Alpha Intelligence Capital, FEBE, and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2018 by engineers Akanksha Jagwani (CTO) and Avni Agarwal (CEO), SixSense aims to address a fundamental challenge in semiconductor manufacturing: converting raw production data, from defect images to equipment signals, into real-time insights that help factories prevent quality issues and improve yield.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the sheer volume of data generated on the fab floor, what stood out to the co-founders was a surprising lack of real-time intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Akanksha brings a deep understanding of manufacturing, quality control, and software automation through her experience building automation solutions for manufacturers like Hyundai Motors and GE and led product development at startups like Embibe. Agarwal adds technical experience from her time at Visa, where she built large-scale data analytics systems, some of which were later protected as trade secrets. A skilled coder with a strong background in mathematics, she had long been interested in applying AI to traditional industries beyond fintech.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-3033008" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/WhatsApp-Image-2025-07-29-at-15.59.51-2-1.jpeg?w=345" width="345" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SixSense&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Together, the duo evaluated sectors from aviation to automotive before landing on semiconductors. Despite the semiconductor industry’s reputation for precision, inspection processes remain largely manual and fragmented, Agarwal told TechCrunch. After speaking with more than 50 engineers, it became clear there’s significant room to modernize how quality checks are done, she added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fabs today are filled with dashboards, SPC charts, and inline inspection systems, but most only display data without further analysis, Agarwal said. “The burden of using it for decision-making still falls on engineers: [they must] spot patterns, investigate anomalies, and trace root causes. That’s time-consuming, subjective, and doesn’t scale well with increasing process complexity.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense provides engineers with early warnings to address potential issues before they escalate with capabilities such as defect detection, root cause analysis, and failure prediction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense’s platform is also specifically designed to be used by process engineers rather than data scientists, Agarwal said. “Process engineers can fine-tune models using their own fab data, deploy them in under two days, and trust the results — all without writing a single line of code. That’s what makes the platform both powerful and practical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The competitive landscape includes in-house engineering teams using tools like Cognex and Halcon, inspection equipment makers integrating AI into their systems, and startups including Landing.ai and Robovision.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SixSense’s AI platform is already in use at major semiconductor manufacturers like GlobalFoundries and JCET, with more than 100 million chips processed to date. Customers have reported up to 30% faster production cycles, a 1-2% boost in yield, and a 90% reduction in manual inspection work, the founders said. The system is compatible with inspection equipment that covers over 60% of the global market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our target customers are large-scale chipmakers — including foundries, outsourced semiconductor assembly and test providers (OSATs), and integrated device manufacturers (IDMs),” Agarwal said. “We’re already working with fabs in Singapore, Malaysia, Taiwan, and Israel, and are now expanding into the U.S.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geopolitical tensions, especially between the U.S. and China, are reshaping where chips are made, driving new manufacturing investments across the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing fabs and OSATs expand aggressively in Malaysia, Singapore, Vietnam, India, and the U.S. — and that’s a tailwind for us. Why? Because we’re already based in the region, and many of these new facilities are starting fresh — without legacy systems weighing them down. That makes them far more open to AI-native approaches like ours from day one,” Agarwal told TechCrunch. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A Singapore-based deep tech startup called SixSense has developed an AI-powered platform that helps semiconductor manufacturers predict and detect potential chip defects on production lines in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It has raised $8.5 million in Series A bringing its total funding to around $12 million. The round was led by Peak XV’s Surge (formerly Sequoia India &amp;amp; SEA), with participation from Alpha Intelligence Capital, FEBE, and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2018 by engineers Akanksha Jagwani (CTO) and Avni Agarwal (CEO), SixSense aims to address a fundamental challenge in semiconductor manufacturing: converting raw production data, from defect images to equipment signals, into real-time insights that help factories prevent quality issues and improve yield.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the sheer volume of data generated on the fab floor, what stood out to the co-founders was a surprising lack of real-time intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Akanksha brings a deep understanding of manufacturing, quality control, and software automation through her experience building automation solutions for manufacturers like Hyundai Motors and GE and led product development at startups like Embibe. Agarwal adds technical experience from her time at Visa, where she built large-scale data analytics systems, some of which were later protected as trade secrets. A skilled coder with a strong background in mathematics, she had long been interested in applying AI to traditional industries beyond fintech.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-3033008" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/WhatsApp-Image-2025-07-29-at-15.59.51-2-1.jpeg?w=345" width="345" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SixSense&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Together, the duo evaluated sectors from aviation to automotive before landing on semiconductors. Despite the semiconductor industry’s reputation for precision, inspection processes remain largely manual and fragmented, Agarwal told TechCrunch. After speaking with more than 50 engineers, it became clear there’s significant room to modernize how quality checks are done, she added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fabs today are filled with dashboards, SPC charts, and inline inspection systems, but most only display data without further analysis, Agarwal said. “The burden of using it for decision-making still falls on engineers: [they must] spot patterns, investigate anomalies, and trace root causes. That’s time-consuming, subjective, and doesn’t scale well with increasing process complexity.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense provides engineers with early warnings to address potential issues before they escalate with capabilities such as defect detection, root cause analysis, and failure prediction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense’s platform is also specifically designed to be used by process engineers rather than data scientists, Agarwal said. “Process engineers can fine-tune models using their own fab data, deploy them in under two days, and trust the results — all without writing a single line of code. That’s what makes the platform both powerful and practical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The competitive landscape includes in-house engineering teams using tools like Cognex and Halcon, inspection equipment makers integrating AI into their systems, and startups including Landing.ai and Robovision.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SixSense’s AI platform is already in use at major semiconductor manufacturers like GlobalFoundries and JCET, with more than 100 million chips processed to date. Customers have reported up to 30% faster production cycles, a 1-2% boost in yield, and a 90% reduction in manual inspection work, the founders said. The system is compatible with inspection equipment that covers over 60% of the global market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our target customers are large-scale chipmakers — including foundries, outsourced semiconductor assembly and test providers (OSATs), and integrated device manufacturers (IDMs),” Agarwal said. “We’re already working with fabs in Singapore, Malaysia, Taiwan, and Israel, and are now expanding into the U.S.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geopolitical tensions, especially between the U.S. and China, are reshaping where chips are made, driving new manufacturing investments across the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing fabs and OSATs expand aggressively in Malaysia, Singapore, Vietnam, India, and the U.S. — and that’s a tailwind for us. Why? Because we’re already based in the region, and many of these new facilities are starting fresh — without legacy systems weighing them down. That makes them far more open to AI-native approaches like ours from day one,” Agarwal told TechCrunch. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/female-founded-semiconductor-ai-startup-sixsense-raises-funding/</guid><pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate></item></channel></rss>