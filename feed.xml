<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 23 Sep 2025 01:37:22 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>5 days left to save up to $668 on your TechCrunch Disrupt 2025 pass (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/5-days-left-to-save-up-to-668-on-your-techcrunch-disrupt-2025-pass-dont-pay-more-for-the-same-seat/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s still time — but just barely. Register for&lt;strong&gt; &lt;/strong&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; by September 26 and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices rise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Disrupt 2025&lt;/strong&gt; gives you an exclusive look at tomorrow’s tech. &lt;strong&gt;Founders&lt;/strong&gt; can connect with the right investors and partners to scale their startups. &lt;strong&gt;Investors&lt;/strong&gt; can discover their next portfolio company. Tech innovators and visionaries can glimpse the future of technology while building the connections that help them grow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With 10,000 tech and VC leaders in one place, you’re bound to find the insights and relationships you need. Join us for the 20th anniversary of TechCrunch — Disrupt 2025 takes place October 27-29 at San Francisco’s Moscone West. &lt;strong&gt;Register now to pocket big savings&lt;/strong&gt; before this week ends.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 5 days left" class="wp-image-3010128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_5Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-at-disrupt-2025-you-ll"&gt;At Disrupt 2025, you’ll:&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Box CEO Aaron Levie on stage at TechCrunch Disrupt in San Francisco in 2019." class="wp-image-2833981" height="454" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1178603809.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Connect with thousands&lt;/strong&gt; of founders, investors, and operators. Discover your next startup investment, find the right investor to scale, or meet the key operators shaping the tech landscape. From curated meetings to impromptu encounters in the Expo Hall, or a spontaneous introduction at the investor/founder-exclusive Deal Flow Cafe — there’s no better place to forge the connections that help you grow.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Explore what’s next across all five industry stages&lt;/strong&gt; over three full days. Eyeballing an IPO? Head to the &lt;strong&gt;Going Public Stage&lt;/strong&gt;. Thinking of launching, or already launched? The &lt;strong&gt;Builders Stage&lt;/strong&gt; offers three days of programming packed with tactical insights to help founders at every stage scale faster. Scaling an AI startup, or just fascinated by AI? Don’t miss two full days at the &lt;strong&gt;AI Stage&lt;/strong&gt;. Curious about space tech? The &lt;strong&gt;Space Stage&lt;/strong&gt; delivers a full day of orbital insights. And on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;, hear from some of the biggest names in today’s tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Experience the intense Startup Battlefield 200&lt;/strong&gt; pitch competition, where the top 20 TechCrunch-vetted early-stage startups pitch on the Disrupt Stage for a $100,000 prize. Hear seasoned VCs give feedback on what makes a winning pitch, and what it takes to build a viable startup.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2331246" height="356" src="https://techcrunch.com/wp-content/uploads/2022/06/roundtable_1200x628.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Witness the future of tech with 100+ startups&lt;/strong&gt; showcasing in the bustling Expo Hall and throughout the venue. Meet brands pushing innovation to the forefront of the tech ecosystem, and try hands-on demos of their cutting-edge products. &lt;strong&gt;Want your brand in the spotlight for all three days?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-september-26-is-the-last-day-for-ticket-savings"&gt;September 26 is the last day for ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;You have until September 26 at 11:59 p.m. PT to &lt;strong&gt;secure up to $668 in ticket savings&lt;/strong&gt;. Whether you’re a founder looking to scale or prepare for an IPO, a tech innovator seeking a firsthand look at tomorrow’s tech, or an investor hunting for the next big opportunity, don’t miss Disrupt 2025. &lt;strong&gt;Register your pass now.&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s still time — but just barely. Register for&lt;strong&gt; &lt;/strong&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; by September 26 and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices rise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Disrupt 2025&lt;/strong&gt; gives you an exclusive look at tomorrow’s tech. &lt;strong&gt;Founders&lt;/strong&gt; can connect with the right investors and partners to scale their startups. &lt;strong&gt;Investors&lt;/strong&gt; can discover their next portfolio company. Tech innovators and visionaries can glimpse the future of technology while building the connections that help them grow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With 10,000 tech and VC leaders in one place, you’re bound to find the insights and relationships you need. Join us for the 20th anniversary of TechCrunch — Disrupt 2025 takes place October 27-29 at San Francisco’s Moscone West. &lt;strong&gt;Register now to pocket big savings&lt;/strong&gt; before this week ends.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 5 days left" class="wp-image-3010128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_5Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-at-disrupt-2025-you-ll"&gt;At Disrupt 2025, you’ll:&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Box CEO Aaron Levie on stage at TechCrunch Disrupt in San Francisco in 2019." class="wp-image-2833981" height="454" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1178603809.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Connect with thousands&lt;/strong&gt; of founders, investors, and operators. Discover your next startup investment, find the right investor to scale, or meet the key operators shaping the tech landscape. From curated meetings to impromptu encounters in the Expo Hall, or a spontaneous introduction at the investor/founder-exclusive Deal Flow Cafe — there’s no better place to forge the connections that help you grow.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Explore what’s next across all five industry stages&lt;/strong&gt; over three full days. Eyeballing an IPO? Head to the &lt;strong&gt;Going Public Stage&lt;/strong&gt;. Thinking of launching, or already launched? The &lt;strong&gt;Builders Stage&lt;/strong&gt; offers three days of programming packed with tactical insights to help founders at every stage scale faster. Scaling an AI startup, or just fascinated by AI? Don’t miss two full days at the &lt;strong&gt;AI Stage&lt;/strong&gt;. Curious about space tech? The &lt;strong&gt;Space Stage&lt;/strong&gt; delivers a full day of orbital insights. And on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;, hear from some of the biggest names in today’s tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Experience the intense Startup Battlefield 200&lt;/strong&gt; pitch competition, where the top 20 TechCrunch-vetted early-stage startups pitch on the Disrupt Stage for a $100,000 prize. Hear seasoned VCs give feedback on what makes a winning pitch, and what it takes to build a viable startup.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2331246" height="356" src="https://techcrunch.com/wp-content/uploads/2022/06/roundtable_1200x628.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Witness the future of tech with 100+ startups&lt;/strong&gt; showcasing in the bustling Expo Hall and throughout the venue. Meet brands pushing innovation to the forefront of the tech ecosystem, and try hands-on demos of their cutting-edge products. &lt;strong&gt;Want your brand in the spotlight for all three days?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-september-26-is-the-last-day-for-ticket-savings"&gt;September 26 is the last day for ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;You have until September 26 at 11:59 p.m. PT to &lt;strong&gt;secure up to $668 in ticket savings&lt;/strong&gt;. Whether you’re a founder looking to scale or prepare for an IPO, a tech innovator seeking a firsthand look at tomorrow’s tech, or an investor hunting for the next big opportunity, don’t miss Disrupt 2025. &lt;strong&gt;Register your pass now.&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/5-days-left-to-save-up-to-668-on-your-techcrunch-disrupt-2025-pass-dont-pay-more-for-the-same-seat/</guid><pubDate>Mon, 22 Sep 2025 14:00:00 +0000</pubDate></item><item><title>Using AI to assist in rare disease diagnosis (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/using-ai-to-assist-in-rare-disease-diagnosis/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Icons representing individual and group connections to a central computer monitor with a globe, symbolizing online connectivity, set against a gradient background transitioning from blue to pink." class="wp-image-1143080" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/AItoAssistDiagnosis-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In the promising and rapidly evolving field of genetic analysis, the ability to accurately interpret whole genome sequencing data is crucial for diagnosing and improving outcomes for people with rare genetic diseases. Yet despite technological advancements, genetic professionals face steep challenges in managing and synthesizing the vast amounts of data required for these analyses. Fewer than 50% of&amp;nbsp;initial&amp;nbsp;cases yield a diagnosis, and while reanalysis can lead to new findings, the process remains&amp;nbsp;time-consuming and complex.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To better understand and address these challenges, Microsoft Research—in collaboration with Drexel University and the Broad Institute​​—conducted a comprehensive study titled&amp;nbsp;&lt;em&gt;AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/em&gt;&amp;nbsp;The study was recently published in a special edition of&amp;nbsp;&lt;em&gt;ACM Transactions on Interactive Intelligent Systems&lt;/em&gt;&amp;nbsp;journal focused on generative AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The study focused on integrating generative AI to support the complex, time-intensive, and information-dense sensemaking tasks inherent in whole genome sequencing analysis. Through detailed empirical research and collaborative design sessions with experts in the field, we identified key obstacles genetic professionals face and proposed AI-driven solutions to enhance their workflows.&amp;nbsp;​&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;​We&amp;nbsp;developed strategies for how generative AI can help synthesize biomedical data, enabling AI-expert collaboration to increase the diagnoses of previously unsolved rare diseases—ultimately aiming to improve patients’ quality of life and life expectancy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="whole-genome-sequencing-in-rare-disease-diagnosis"&gt;Whole genome sequencing in rare disease diagnosis&lt;/h2&gt;



&lt;p&gt;Rare diseases affect up to half a billion people globally and obtaining a diagnosis can take multiple years. These diagnoses often involve specialist consultations, laboratory tests, imaging studies, and invasive procedures. Whole genome sequencing is used to identify genetic variants responsible for these diseases by comparing a patient’s DNA sequence to reference genomes.&amp;nbsp;​​Genetic professionals use bioinformatics tools such as&amp;nbsp;&lt;em&gt;seqr,&amp;nbsp;&lt;/em&gt;an open-source, web-based tool for rare disease case analysis and project management to assist them in filtering and prioritizing&amp;nbsp; &amp;gt; 1 million variants to determine their potential role in disease.&amp;nbsp;A critical component of&amp;nbsp;their&amp;nbsp;work is sensemaking: the process of searching, filtering, and synthesizing data to build, refine, and present models from complex sets of gene and variant information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;​​The multi-step sequencing process​​​&amp;nbsp;typically takes three to 12 weeks and requires extensive amounts of evidence and time to synthesize and aggregate information&amp;nbsp;​​to understand the gene and variant effects for the patient.&amp;nbsp;If a patient’s case goes unsolved, their whole genome sequencing data is set aside until enough time has passed to warrant a reanalysis​​. This creates a backlog of patient cases​​. The ability to easily&amp;nbsp;identify&amp;nbsp;when new scientific evidence&amp;nbsp;emerges&amp;nbsp;and when to reanalyze an unsolved patient case is key to shortening the time patients suffer with an unknown rare disease diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="the-promise-of-ai-systems-to-assist-with-complex-human-tasks"&gt;The promise of AI systems to assist with complex human tasks&lt;/h2&gt;



&lt;p&gt;Approximately 87% of AI systems never reach deployment&amp;nbsp;​simply because they solve​​​&amp;nbsp;the wrong problems.&amp;nbsp;​​Understanding the AI support desired by different types of professionals, their current workflows, and AI capabilities is critical to successful AI system deployment and use. Matching technology capabilities with user tasks is particularly challenging in AI design because AI models can generate numerous outputs, and their capabilities can be unclear.&amp;nbsp;​To design an effective​​​&amp;nbsp;AI-based system​, one needs to identify​&amp;nbsp;​​tasks AI can support,&amp;nbsp;​​determine​​​​​​&amp;nbsp;the appropriate level of AI involvement, and&amp;nbsp;​​design​​​​​​&amp;nbsp;user-AI interactions. This necessitates considering how humans interact with technology and how&amp;nbsp;​​AI&amp;nbsp;can best be incorporated into workflows and tools.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="study-objectives-and-co-designing-a-genetic-ai-assistant"&gt;Study objectives and co-designing a genetic AI assistant&lt;/h2&gt;



&lt;p&gt;Our study aimed to understand the current challenges and needs of genetic professionals performing whole genome sequencing analyses and explore the tasks where they want an AI assistant to support them in their work. The first phase of our study involved interviews with 17 genetics professionals to better understand their workflows, tools, and challenges. They included genetic analysts directly involved in interpreting data, as well as other roles participating in whole genome sequencing. In the second phase of our study, we conducted co-design sessions with study participants on how an AI assistant could support their workflows. We then developed a prototype of an AI assistant, which was further tested and refined with study participants in follow-up design walk-through sessions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="identifying-challenges-in-whole-genome-sequencing-analysis"&gt;Identifying challenges in whole genome sequencing analysis&lt;/h2&gt;



&lt;p&gt;Through our in-depth interviews with genetic professionals, our study uncovered three critical challenges in whole genome sequencing analysis:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;Information Overload&lt;/em&gt;: Genetic analysts need to gather and synthesize vast amounts of data from multiple sources. This task is incredibly time-consuming and prone to human error.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Collaborative Sharing&lt;/em&gt;: Sharing findings with others in the field can be cumbersome and inefficient, often relying on outdated methods that slow the collaborative analysis process.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Prioritizing Reanalysis&lt;/em&gt;: Given the continuous influx of new scientific discoveries, prioritizing unsolved cases to reanalyze is a daunting challenge. Analysts need a systematic approach to identify cases that might benefit most from reanalysis.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Genetic professionals highlighted the time-consuming nature of gathering and synthesizing information about genes and variants from different data sources. Other genetic professionals may have insights into certain genes and variants, but sharing and interpreting information with others for collaborative sensemaking requires significant time and effort. Although new scientific findings could affect unsolved cases through reanalysis, prioritizing cases based on new findings was challenging given the number of unsolved cases and limited time of genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="co-designing-with-experts-and-ai-human-sensemaking-tasks"&gt;Co-designing with experts and AI-human sensemaking tasks&lt;/h2&gt;



&lt;p&gt;Our study participants prioritized two potential tasks of an AI assistant. The first task was flagging cases for reanalysis based on new scientific findings. The assistant would alert analysts to unsolved cases that could benefit from new research, providing relevant updates drawn from recent publications. The second task focused on aggregating and synthesizing information about genes and variants from the scientific literature. This feature would compile essential information from numerous scientific papers about genes and variants, presenting it in a user-friendly format and saving analysts significant time and effort. Participants emphasized the need to balance selectivity with comprehensiveness in the evidence they review. They also envisioned collaborating with other genetic professionals to interpret, edit, and verify artifacts generated by the AI assistant.&lt;/p&gt;



&lt;p&gt;Genetic professionals require both broad and focused evidence at different stages of their workflow. The AI assistant prototypes were designed to allow flexible filtering and thorough evidence aggregation, ensuring users can delve into comprehensive data or selectively focus on pertinent details. The prototypes included features for collaborative sensemaking, enabling users to interpret, edit, and verify AI-generated information collectively. This&amp;nbsp;​​approach not only&amp;nbsp;​underscores​​​&amp;nbsp;the trustworthiness of AI outputs, but also facilitates shared understanding and decision-making among genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="design-implications-for-expert-ai-sensemaking"&gt;Design implications for expert-AI sensemaking&lt;/h2&gt;



&lt;p&gt;In the&amp;nbsp;shifting frontiers of genome sequence analysis,&amp;nbsp;leveraging generative AI to enhance sensemaking offers intriguing possibilities​​. The task of staying&amp;nbsp;​​current​​​​​​, synthesizing information from diverse sources, and making informed decisions&amp;nbsp;​​is challenging​​​​​​.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our study participants emphasized the hurdles in integrating data from multiple sources without losing critical components, documenting decision rationales, and fostering collaborative environments. Generative AI models, with their advanced capabilities, have started to address these challenges by automatically generating interactive artifacts to support sensemaking. However, the effectiveness of such systems hinges on careful design considerations,&amp;nbsp;​​particularly in how they facilitate distributed sensemaking, support both initial and ongoing sensemaking, and combine evidence from multiple modalities. We next discuss three design considerations for using generative AI models to support sensemaking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="distributed-expert-ai-sensemaking-design"&gt;Distributed expert-AI sensemaking design&lt;/h2&gt;



&lt;p&gt;Generative AI models can create artifacts that aid an individual user’s sensemaking process; however, the true potential lies in sharing these artifacts among users to foster collective understanding and efficiency. Participants in our study emphasized the importance of explainability, feedback, and trust when interacting with AI-generated content.&amp;nbsp;​​​​​​​​​​Trust is gained by​​​​​​&amp;nbsp;viewing portions of artifacts marked as correct by other users, or observing edits made to AI-generated information​​.&amp;nbsp;​​Some​​​​​​&amp;nbsp;users​, however,​&amp;nbsp;cautioned against over-reliance on AI, which could obscure underlying inaccuracies. Thus, design strategies should ensure that any corrections are clearly marked&amp;nbsp;​​and annotated​​​​​​. Furthermore, to enhance distributed sensemaking, visibility of others’ notes and context-specific synthesis through AI can streamline the process​​.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="initial-expert-ai-sensemaking-and-re-sensemaking-design"&gt;Initial expert-AI sensemaking and re-sensemaking design&lt;/h2&gt;



&lt;p&gt;In our fast-paced, information-driven world,&amp;nbsp;​​it is essential to understand a situation both&amp;nbsp;initially&amp;nbsp;and again when new information arises.​​&amp;nbsp;​​Sensemaking is inherently temporal, reflecting and shaping our understanding of time as we revisit tasks to reevaluate past decisions or incorporate new information. Generative AI plays a pivotal role here by transforming static data into dynamic artifacts that evolve, offering a comprehensive view of past rationales. Such AI-generated artifacts provide continuity, allowing users—both&amp;nbsp;original decision-makers or new individuals—to access the rationale behind decisions made in earlier task instances. By continuously editing and updating these artifacts, generative AI highlights new information since the last review, supporting ongoing understanding and decision-making.&amp;nbsp;Moreover, AI systems enhance&amp;nbsp;​​transparency​​​​​​&amp;nbsp;by summarizing previous notes and questions, offering insights into earlier thought processes and facilitating a deeper understanding of how conclusions were drawn. This reflective capability not only can reinforce initial sensemaking efforts but also equips users with the clarity needed for informed re-sensemaking as new data emerges.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="combining-evidence-from-multiple-modalities-to-enhance-ai-expert-sensemaking"&gt;Combining evidence from multiple modalities to enhance AI-expert sensemaking&lt;/h2&gt;



&lt;p&gt;​​​The​​​​​​&amp;nbsp;ability to combine evidence from multiple modalities is essential for effective sensemaking. Users often need to integrate diverse types of data—text, images, spatial coordinates, and more—into a coherent narrative to make informed decisions. Consider the case of search and rescue operations, where workers must rapidly synthesize information from texts, photographs, and GPS data to strategize their efforts. Recent advancements in multimodal generative AI models have empowered users by incorporating and synthesizing these varied inputs into a unified, comprehensive view. For instance, a participant in our study illustrated this capability by using a generative AI model to merge text from scientific publications with a visual gene structure depiction. This integration&amp;nbsp;​​could create​​​​​​&amp;nbsp;an image that contextualizes an individual’s genetic variant within the&amp;nbsp;​​context​​​​​​&amp;nbsp;of documented variants. Such advanced synthesis enables users to capture complex relationships and insights briefly, streamlining decision-making and expanding the potential for innovative solutions across diverse fields.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="sensemaking-process-with-ai-assistant"&gt;Sensemaking Process with AI Assistant&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines." class="wp-image-1142535" height="481" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/FIG1_Mandi-Hall.png" width="952" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;We explored the potential of generative AI&amp;nbsp;to support​​ genetic professionals​&amp;nbsp;​in diagnosing rare diseases​​. By designing an AI-based assistant, we aim to streamline whole genome sequencing analysis, helping professionals diagnose rare genetic diseases more efficiently. Our study unfolded in two key phases:&amp;nbsp;​pinpointing​​​&amp;nbsp;existing challenges in analysis, and design ideation, where we crafted a prototype AI assistant. This tool is designed to boost diagnostic yield and cut down diagnosis time by flagging cases for reanalysis and synthesizing crucial gene and variant data. Despite valuable findings, more research is needed​​. Future research will involve testing the AI assistant in real-time, task-based user testing with genetic professionals to assess the AI’s impact on their workflow. The promise of AI advancements lies in solving the right user problems and building the appropriate solutions, achieved through collaboration among model developers, domain experts, system designers, and HCI researchers. By fostering these collaborations, we aim to develop robust, personalized AI assistants tailored to specific domains.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="join-the-conversation"&gt;Join the conversation&lt;/h2&gt;



&lt;p&gt;Join us as we continue to explore the transformative potential of generative AI in genetic analysis, and please read the full text publication&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Follow us on social media, share this post with your network, and let us know your thoughts on how AI can transform genetic research. If interested in our other related research work, check out&amp;nbsp;Evidence Aggregator: AI reasoning applied to rare disease diagnosis.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Icons representing individual and group connections to a central computer monitor with a globe, symbolizing online connectivity, set against a gradient background transitioning from blue to pink." class="wp-image-1143080" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/AItoAssistDiagnosis-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In the promising and rapidly evolving field of genetic analysis, the ability to accurately interpret whole genome sequencing data is crucial for diagnosing and improving outcomes for people with rare genetic diseases. Yet despite technological advancements, genetic professionals face steep challenges in managing and synthesizing the vast amounts of data required for these analyses. Fewer than 50% of&amp;nbsp;initial&amp;nbsp;cases yield a diagnosis, and while reanalysis can lead to new findings, the process remains&amp;nbsp;time-consuming and complex.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To better understand and address these challenges, Microsoft Research—in collaboration with Drexel University and the Broad Institute​​—conducted a comprehensive study titled&amp;nbsp;&lt;em&gt;AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/em&gt;&amp;nbsp;The study was recently published in a special edition of&amp;nbsp;&lt;em&gt;ACM Transactions on Interactive Intelligent Systems&lt;/em&gt;&amp;nbsp;journal focused on generative AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The study focused on integrating generative AI to support the complex, time-intensive, and information-dense sensemaking tasks inherent in whole genome sequencing analysis. Through detailed empirical research and collaborative design sessions with experts in the field, we identified key obstacles genetic professionals face and proposed AI-driven solutions to enhance their workflows.&amp;nbsp;​&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;​We&amp;nbsp;developed strategies for how generative AI can help synthesize biomedical data, enabling AI-expert collaboration to increase the diagnoses of previously unsolved rare diseases—ultimately aiming to improve patients’ quality of life and life expectancy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="whole-genome-sequencing-in-rare-disease-diagnosis"&gt;Whole genome sequencing in rare disease diagnosis&lt;/h2&gt;



&lt;p&gt;Rare diseases affect up to half a billion people globally and obtaining a diagnosis can take multiple years. These diagnoses often involve specialist consultations, laboratory tests, imaging studies, and invasive procedures. Whole genome sequencing is used to identify genetic variants responsible for these diseases by comparing a patient’s DNA sequence to reference genomes.&amp;nbsp;​​Genetic professionals use bioinformatics tools such as&amp;nbsp;&lt;em&gt;seqr,&amp;nbsp;&lt;/em&gt;an open-source, web-based tool for rare disease case analysis and project management to assist them in filtering and prioritizing&amp;nbsp; &amp;gt; 1 million variants to determine their potential role in disease.&amp;nbsp;A critical component of&amp;nbsp;their&amp;nbsp;work is sensemaking: the process of searching, filtering, and synthesizing data to build, refine, and present models from complex sets of gene and variant information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;​​The multi-step sequencing process​​​&amp;nbsp;typically takes three to 12 weeks and requires extensive amounts of evidence and time to synthesize and aggregate information&amp;nbsp;​​to understand the gene and variant effects for the patient.&amp;nbsp;If a patient’s case goes unsolved, their whole genome sequencing data is set aside until enough time has passed to warrant a reanalysis​​. This creates a backlog of patient cases​​. The ability to easily&amp;nbsp;identify&amp;nbsp;when new scientific evidence&amp;nbsp;emerges&amp;nbsp;and when to reanalyze an unsolved patient case is key to shortening the time patients suffer with an unknown rare disease diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="the-promise-of-ai-systems-to-assist-with-complex-human-tasks"&gt;The promise of AI systems to assist with complex human tasks&lt;/h2&gt;



&lt;p&gt;Approximately 87% of AI systems never reach deployment&amp;nbsp;​simply because they solve​​​&amp;nbsp;the wrong problems.&amp;nbsp;​​Understanding the AI support desired by different types of professionals, their current workflows, and AI capabilities is critical to successful AI system deployment and use. Matching technology capabilities with user tasks is particularly challenging in AI design because AI models can generate numerous outputs, and their capabilities can be unclear.&amp;nbsp;​To design an effective​​​&amp;nbsp;AI-based system​, one needs to identify​&amp;nbsp;​​tasks AI can support,&amp;nbsp;​​determine​​​​​​&amp;nbsp;the appropriate level of AI involvement, and&amp;nbsp;​​design​​​​​​&amp;nbsp;user-AI interactions. This necessitates considering how humans interact with technology and how&amp;nbsp;​​AI&amp;nbsp;can best be incorporated into workflows and tools.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="study-objectives-and-co-designing-a-genetic-ai-assistant"&gt;Study objectives and co-designing a genetic AI assistant&lt;/h2&gt;



&lt;p&gt;Our study aimed to understand the current challenges and needs of genetic professionals performing whole genome sequencing analyses and explore the tasks where they want an AI assistant to support them in their work. The first phase of our study involved interviews with 17 genetics professionals to better understand their workflows, tools, and challenges. They included genetic analysts directly involved in interpreting data, as well as other roles participating in whole genome sequencing. In the second phase of our study, we conducted co-design sessions with study participants on how an AI assistant could support their workflows. We then developed a prototype of an AI assistant, which was further tested and refined with study participants in follow-up design walk-through sessions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="identifying-challenges-in-whole-genome-sequencing-analysis"&gt;Identifying challenges in whole genome sequencing analysis&lt;/h2&gt;



&lt;p&gt;Through our in-depth interviews with genetic professionals, our study uncovered three critical challenges in whole genome sequencing analysis:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;Information Overload&lt;/em&gt;: Genetic analysts need to gather and synthesize vast amounts of data from multiple sources. This task is incredibly time-consuming and prone to human error.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Collaborative Sharing&lt;/em&gt;: Sharing findings with others in the field can be cumbersome and inefficient, often relying on outdated methods that slow the collaborative analysis process.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Prioritizing Reanalysis&lt;/em&gt;: Given the continuous influx of new scientific discoveries, prioritizing unsolved cases to reanalyze is a daunting challenge. Analysts need a systematic approach to identify cases that might benefit most from reanalysis.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Genetic professionals highlighted the time-consuming nature of gathering and synthesizing information about genes and variants from different data sources. Other genetic professionals may have insights into certain genes and variants, but sharing and interpreting information with others for collaborative sensemaking requires significant time and effort. Although new scientific findings could affect unsolved cases through reanalysis, prioritizing cases based on new findings was challenging given the number of unsolved cases and limited time of genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="co-designing-with-experts-and-ai-human-sensemaking-tasks"&gt;Co-designing with experts and AI-human sensemaking tasks&lt;/h2&gt;



&lt;p&gt;Our study participants prioritized two potential tasks of an AI assistant. The first task was flagging cases for reanalysis based on new scientific findings. The assistant would alert analysts to unsolved cases that could benefit from new research, providing relevant updates drawn from recent publications. The second task focused on aggregating and synthesizing information about genes and variants from the scientific literature. This feature would compile essential information from numerous scientific papers about genes and variants, presenting it in a user-friendly format and saving analysts significant time and effort. Participants emphasized the need to balance selectivity with comprehensiveness in the evidence they review. They also envisioned collaborating with other genetic professionals to interpret, edit, and verify artifacts generated by the AI assistant.&lt;/p&gt;



&lt;p&gt;Genetic professionals require both broad and focused evidence at different stages of their workflow. The AI assistant prototypes were designed to allow flexible filtering and thorough evidence aggregation, ensuring users can delve into comprehensive data or selectively focus on pertinent details. The prototypes included features for collaborative sensemaking, enabling users to interpret, edit, and verify AI-generated information collectively. This&amp;nbsp;​​approach not only&amp;nbsp;​underscores​​​&amp;nbsp;the trustworthiness of AI outputs, but also facilitates shared understanding and decision-making among genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="design-implications-for-expert-ai-sensemaking"&gt;Design implications for expert-AI sensemaking&lt;/h2&gt;



&lt;p&gt;In the&amp;nbsp;shifting frontiers of genome sequence analysis,&amp;nbsp;leveraging generative AI to enhance sensemaking offers intriguing possibilities​​. The task of staying&amp;nbsp;​​current​​​​​​, synthesizing information from diverse sources, and making informed decisions&amp;nbsp;​​is challenging​​​​​​.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our study participants emphasized the hurdles in integrating data from multiple sources without losing critical components, documenting decision rationales, and fostering collaborative environments. Generative AI models, with their advanced capabilities, have started to address these challenges by automatically generating interactive artifacts to support sensemaking. However, the effectiveness of such systems hinges on careful design considerations,&amp;nbsp;​​particularly in how they facilitate distributed sensemaking, support both initial and ongoing sensemaking, and combine evidence from multiple modalities. We next discuss three design considerations for using generative AI models to support sensemaking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="distributed-expert-ai-sensemaking-design"&gt;Distributed expert-AI sensemaking design&lt;/h2&gt;



&lt;p&gt;Generative AI models can create artifacts that aid an individual user’s sensemaking process; however, the true potential lies in sharing these artifacts among users to foster collective understanding and efficiency. Participants in our study emphasized the importance of explainability, feedback, and trust when interacting with AI-generated content.&amp;nbsp;​​​​​​​​​​Trust is gained by​​​​​​&amp;nbsp;viewing portions of artifacts marked as correct by other users, or observing edits made to AI-generated information​​.&amp;nbsp;​​Some​​​​​​&amp;nbsp;users​, however,​&amp;nbsp;cautioned against over-reliance on AI, which could obscure underlying inaccuracies. Thus, design strategies should ensure that any corrections are clearly marked&amp;nbsp;​​and annotated​​​​​​. Furthermore, to enhance distributed sensemaking, visibility of others’ notes and context-specific synthesis through AI can streamline the process​​.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="initial-expert-ai-sensemaking-and-re-sensemaking-design"&gt;Initial expert-AI sensemaking and re-sensemaking design&lt;/h2&gt;



&lt;p&gt;In our fast-paced, information-driven world,&amp;nbsp;​​it is essential to understand a situation both&amp;nbsp;initially&amp;nbsp;and again when new information arises.​​&amp;nbsp;​​Sensemaking is inherently temporal, reflecting and shaping our understanding of time as we revisit tasks to reevaluate past decisions or incorporate new information. Generative AI plays a pivotal role here by transforming static data into dynamic artifacts that evolve, offering a comprehensive view of past rationales. Such AI-generated artifacts provide continuity, allowing users—both&amp;nbsp;original decision-makers or new individuals—to access the rationale behind decisions made in earlier task instances. By continuously editing and updating these artifacts, generative AI highlights new information since the last review, supporting ongoing understanding and decision-making.&amp;nbsp;Moreover, AI systems enhance&amp;nbsp;​​transparency​​​​​​&amp;nbsp;by summarizing previous notes and questions, offering insights into earlier thought processes and facilitating a deeper understanding of how conclusions were drawn. This reflective capability not only can reinforce initial sensemaking efforts but also equips users with the clarity needed for informed re-sensemaking as new data emerges.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="combining-evidence-from-multiple-modalities-to-enhance-ai-expert-sensemaking"&gt;Combining evidence from multiple modalities to enhance AI-expert sensemaking&lt;/h2&gt;



&lt;p&gt;​​​The​​​​​​&amp;nbsp;ability to combine evidence from multiple modalities is essential for effective sensemaking. Users often need to integrate diverse types of data—text, images, spatial coordinates, and more—into a coherent narrative to make informed decisions. Consider the case of search and rescue operations, where workers must rapidly synthesize information from texts, photographs, and GPS data to strategize their efforts. Recent advancements in multimodal generative AI models have empowered users by incorporating and synthesizing these varied inputs into a unified, comprehensive view. For instance, a participant in our study illustrated this capability by using a generative AI model to merge text from scientific publications with a visual gene structure depiction. This integration&amp;nbsp;​​could create​​​​​​&amp;nbsp;an image that contextualizes an individual’s genetic variant within the&amp;nbsp;​​context​​​​​​&amp;nbsp;of documented variants. Such advanced synthesis enables users to capture complex relationships and insights briefly, streamlining decision-making and expanding the potential for innovative solutions across diverse fields.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="sensemaking-process-with-ai-assistant"&gt;Sensemaking Process with AI Assistant&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines." class="wp-image-1142535" height="481" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/FIG1_Mandi-Hall.png" width="952" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;We explored the potential of generative AI&amp;nbsp;to support​​ genetic professionals​&amp;nbsp;​in diagnosing rare diseases​​. By designing an AI-based assistant, we aim to streamline whole genome sequencing analysis, helping professionals diagnose rare genetic diseases more efficiently. Our study unfolded in two key phases:&amp;nbsp;​pinpointing​​​&amp;nbsp;existing challenges in analysis, and design ideation, where we crafted a prototype AI assistant. This tool is designed to boost diagnostic yield and cut down diagnosis time by flagging cases for reanalysis and synthesizing crucial gene and variant data. Despite valuable findings, more research is needed​​. Future research will involve testing the AI assistant in real-time, task-based user testing with genetic professionals to assess the AI’s impact on their workflow. The promise of AI advancements lies in solving the right user problems and building the appropriate solutions, achieved through collaboration among model developers, domain experts, system designers, and HCI researchers. By fostering these collaborations, we aim to develop robust, personalized AI assistants tailored to specific domains.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="join-the-conversation"&gt;Join the conversation&lt;/h2&gt;



&lt;p&gt;Join us as we continue to explore the transformative potential of generative AI in genetic analysis, and please read the full text publication&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Follow us on social media, share this post with your network, and let us know your thoughts on how AI can transform genetic research. If interested in our other related research work, check out&amp;nbsp;Evidence Aggregator: AI reasoning applied to rare disease diagnosis.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/using-ai-to-assist-in-rare-disease-diagnosis/</guid><pubDate>Mon, 22 Sep 2025 14:17:03 +0000</pubDate></item><item><title>Clock’s ticking: Get hands-on experience volunteering at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/clocks-ticking-get-hands-on-experience-volunteering-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;September 30 is the final deadline to &lt;strong&gt;apply to volunteer&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — and we’re officially in countdown mode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you dream of launching your own startup, building community, or producing global-scale events, volunteering gives you an unmatched, behind-the-scenes look at how a world-class tech conference comes to life in San Francisco.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2363054" height="356" src="https://techcrunch.com/wp-content/uploads/2022/07/volunteer_header.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-as-a-volunteer-you-ll"&gt;&lt;strong&gt; As a volunteer, you’ll:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Get free access to Disrupt when you’re not on shift.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Gain hands-on experience with event production, logistics, and registration.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Meet startup founders, investors, speakers, and other tech enthusiasts.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Walk away with real connections and an insider’s view of the startup ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-apply-before-this-once-a-year-chance-passes"&gt;Apply before this once-a-year chance passes&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re ready to level up your experience and join the action in San Francisco, now’s the time to step up. Only accepting applications from Bay Area residents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Apply to volunteer before September 30&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;September 30 is the final deadline to &lt;strong&gt;apply to volunteer&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — and we’re officially in countdown mode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you dream of launching your own startup, building community, or producing global-scale events, volunteering gives you an unmatched, behind-the-scenes look at how a world-class tech conference comes to life in San Francisco.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2363054" height="356" src="https://techcrunch.com/wp-content/uploads/2022/07/volunteer_header.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-as-a-volunteer-you-ll"&gt;&lt;strong&gt; As a volunteer, you’ll:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Get free access to Disrupt when you’re not on shift.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Gain hands-on experience with event production, logistics, and registration.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Meet startup founders, investors, speakers, and other tech enthusiasts.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Walk away with real connections and an insider’s view of the startup ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-apply-before-this-once-a-year-chance-passes"&gt;Apply before this once-a-year chance passes&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re ready to level up your experience and join the action in San Francisco, now’s the time to step up. Only accepting applications from Bay Area residents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Apply to volunteer before September 30&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/clocks-ticking-get-hands-on-experience-volunteering-at-techcrunch-disrupt-2025/</guid><pubDate>Mon, 22 Sep 2025 15:30:00 +0000</pubDate></item><item><title>Public trust deficit is a major hurdle for AI growth (AI News)</title><link>https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/</link><description>&lt;p&gt;While politicians tout AI’s promise of growth and efficiency, a new report reveals a public trust deficit in the technology. Many are deeply sceptical, creating a major headache for governments’ plans.&lt;/p&gt;&lt;p&gt;A deep dive by the Tony Blair Institute for Global Change (TBI) and Ipsos has put some hard numbers on this feeling of unease. It turns out that a lack of trust is the biggest single reason people are shying away from using generative AI. It’s not just a vague worry; it’s a genuine barrier holding back the AI revolution politicians are so excited about.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-public-trust-in-ai-increases-with-usage"&gt;Public trust in AI increases with usage&lt;/h3&gt;&lt;p&gt;The report shows an interesting split in how we see AI. On one hand, more than half of us have dabbled with generative AI tools in the last year. That’s pretty fast adoption for a technology that was barely on the public radar a few years ago.&lt;/p&gt;&lt;p&gt;However, nearly half the country has never used AI, either at home or for work. This creates a huge divide in how people feel about AI and its growth. The data suggests the more you use AI, the more you tend to trust it.&lt;/p&gt;&lt;p&gt;For people who have never used AI, 56 percent see it as a risk to society. But for the folks who use it every week, that number is cut by more than half, dropping to 26 percent. It’s a classic case of familiarity breeding comfort. If you’ve never had a positive experience with AI, it’s much easier to believe the scary headlines. Seeing its limitations first-hand also helps to counter fears that everyone is about to be replaced by AI.&lt;/p&gt;&lt;p&gt;This divide in public trust towards AI is also shaped by who you are. Younger people are generally more optimistic, while older generations are warier. Professionals in the tech world feel ready for what’s coming, but those in sectors like healthcare and education? They’re feeling far less confident, even though their jobs are likely to be more affected by AI growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-it-s-not-what-you-do-it-s-the-way-that-you-do-it"&gt;It’s not what you do, it’s the way that you do it&lt;/h3&gt;&lt;p&gt;Among the most revealing parts of the report is that our feelings about AI change depending on the job it’s doing.&lt;/p&gt;&lt;p&gt;We’re quite happy for AI to help sort out traffic jams or speed up cancer detection. Why? Because we can see the direct, positive benefit to our lives. It’s technology that’s clearly working for us.&lt;/p&gt;&lt;p&gt;But ask people how they feel about AI monitoring their performance at work or being used to target them with political ads, and the mood sours instantly. The acceptance plummets. This shows our concerns aren’t really about the growth of AI itself, but about its purpose.&lt;/p&gt;&lt;p&gt;We want to know that AI is being used for good and that rules are in place so that big tech companies aren’t left completely in the driver’s seat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-do-we-increase-public-trust-in-ai-to-support-growth"&gt;How do we increase public trust in AI to support growth?&lt;/h3&gt;&lt;p&gt;The TBI report doesn’t just point out the problem; it offers a clear path forward to build what it calls “justified trust.”&lt;/p&gt;&lt;p&gt;First, the government needs to change the way it talks about AI. Forget abstract promises of boosting GDP. Instead, talk about what it means for people’s lives: getting a hospital appointment faster, making public services easier to use, or cutting down your daily commute. Show, don’t just tell about the benefits of AI growth.&lt;/p&gt;&lt;p&gt;Next, prove it works. When AI is used in public services, we need to see the evidence that it’s actually making things better for real people, not just more efficient for a spreadsheet. The measure of success should be our experience, not just a technical benchmark.&lt;/p&gt;&lt;p&gt;Of course, none of this works without proper rules and training. Regulators need the power and know-how to keep AI in check, and we all need access to training to feel confident using these new tools safely and effectively. The goal is to make AI something we can all work with, not something that feels like it’s being done to us.&lt;/p&gt;&lt;p&gt;Building public trust in AI to support its growth is about building trust in the people and institutions in charge of it. If the government can show that it’s committed to making AI work for everyone, it might just bring the public along for the ride.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Trump jokes about AI while US and UK sign new tech deal&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;While politicians tout AI’s promise of growth and efficiency, a new report reveals a public trust deficit in the technology. Many are deeply sceptical, creating a major headache for governments’ plans.&lt;/p&gt;&lt;p&gt;A deep dive by the Tony Blair Institute for Global Change (TBI) and Ipsos has put some hard numbers on this feeling of unease. It turns out that a lack of trust is the biggest single reason people are shying away from using generative AI. It’s not just a vague worry; it’s a genuine barrier holding back the AI revolution politicians are so excited about.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-public-trust-in-ai-increases-with-usage"&gt;Public trust in AI increases with usage&lt;/h3&gt;&lt;p&gt;The report shows an interesting split in how we see AI. On one hand, more than half of us have dabbled with generative AI tools in the last year. That’s pretty fast adoption for a technology that was barely on the public radar a few years ago.&lt;/p&gt;&lt;p&gt;However, nearly half the country has never used AI, either at home or for work. This creates a huge divide in how people feel about AI and its growth. The data suggests the more you use AI, the more you tend to trust it.&lt;/p&gt;&lt;p&gt;For people who have never used AI, 56 percent see it as a risk to society. But for the folks who use it every week, that number is cut by more than half, dropping to 26 percent. It’s a classic case of familiarity breeding comfort. If you’ve never had a positive experience with AI, it’s much easier to believe the scary headlines. Seeing its limitations first-hand also helps to counter fears that everyone is about to be replaced by AI.&lt;/p&gt;&lt;p&gt;This divide in public trust towards AI is also shaped by who you are. Younger people are generally more optimistic, while older generations are warier. Professionals in the tech world feel ready for what’s coming, but those in sectors like healthcare and education? They’re feeling far less confident, even though their jobs are likely to be more affected by AI growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-it-s-not-what-you-do-it-s-the-way-that-you-do-it"&gt;It’s not what you do, it’s the way that you do it&lt;/h3&gt;&lt;p&gt;Among the most revealing parts of the report is that our feelings about AI change depending on the job it’s doing.&lt;/p&gt;&lt;p&gt;We’re quite happy for AI to help sort out traffic jams or speed up cancer detection. Why? Because we can see the direct, positive benefit to our lives. It’s technology that’s clearly working for us.&lt;/p&gt;&lt;p&gt;But ask people how they feel about AI monitoring their performance at work or being used to target them with political ads, and the mood sours instantly. The acceptance plummets. This shows our concerns aren’t really about the growth of AI itself, but about its purpose.&lt;/p&gt;&lt;p&gt;We want to know that AI is being used for good and that rules are in place so that big tech companies aren’t left completely in the driver’s seat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-do-we-increase-public-trust-in-ai-to-support-growth"&gt;How do we increase public trust in AI to support growth?&lt;/h3&gt;&lt;p&gt;The TBI report doesn’t just point out the problem; it offers a clear path forward to build what it calls “justified trust.”&lt;/p&gt;&lt;p&gt;First, the government needs to change the way it talks about AI. Forget abstract promises of boosting GDP. Instead, talk about what it means for people’s lives: getting a hospital appointment faster, making public services easier to use, or cutting down your daily commute. Show, don’t just tell about the benefits of AI growth.&lt;/p&gt;&lt;p&gt;Next, prove it works. When AI is used in public services, we need to see the evidence that it’s actually making things better for real people, not just more efficient for a spreadsheet. The measure of success should be our experience, not just a technical benchmark.&lt;/p&gt;&lt;p&gt;Of course, none of this works without proper rules and training. Regulators need the power and know-how to keep AI in check, and we all need access to training to feel confident using these new tools safely and effectively. The goal is to make AI something we can all work with, not something that feels like it’s being done to us.&lt;/p&gt;&lt;p&gt;Building public trust in AI to support its growth is about building trust in the people and institutions in charge of it. If the government can show that it’s committed to making AI work for everyone, it might just bring the public along for the ride.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Trump jokes about AI while US and UK sign new tech deal&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/</guid><pubDate>Mon, 22 Sep 2025 15:47:14 +0000</pubDate></item><item><title>Oracle promotes two presidents to co-CEO role (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/oracle-promotes-two-presidents-to-co-ceo-role/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2015/09/456307736.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Oracle is shaking up its&amp;nbsp;executive&amp;nbsp;suite as&amp;nbsp;it sets its sights set on AI infrastructure dominance.&amp;nbsp;The company announced Monday that it is promoting&amp;nbsp;Clay Magouyrk and Mike Sicilia&amp;nbsp;to&amp;nbsp;co-CEO&amp;nbsp;roles.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Magouyrk&amp;nbsp;joined Oracle in 2014 from Amazon Web Services. He&amp;nbsp;was a founding member of&amp;nbsp;Oracle’s cloud engineering team and has served as the president of Oracle’s cloud infrastructure business unit&amp;nbsp;for more than a decade.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sicilia&amp;nbsp;has served as the president of Oracle’s industries division since&amp;nbsp;June. He held&amp;nbsp;several&amp;nbsp;different roles&amp;nbsp;at the company since he&amp;nbsp;joined through&amp;nbsp;Oracle’s acquisition of project portfolio management&amp;nbsp;company&amp;nbsp;Primavera Systems in 2008.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Safra Catz, who has&amp;nbsp;been Oracle’s CEO since&amp;nbsp;2014,&amp;nbsp;is moving into a&amp;nbsp;new role as the executive vice chair of Oracle’s board of directors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, Oracle is recognized as the cloud of choice for both AI training and inferencing.&amp;nbsp;I’m&amp;nbsp;very proud&amp;nbsp;of that,” Catz said in a statement. “Oracle’s technology and business have never been stronger. And our breathtaking growth rate points to an even more prosperous future. At this time of strength is the right moment to pass the CEO role to the next generation of capable executives.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While traditionally known as a cloud infrastructure provider, Oracle has recently started to cement its place in the AI infrastructure race as well.&amp;nbsp;Earlier this year, the company announced its participation in the&amp;nbsp;$500 billion&amp;nbsp;Stargate Project,&amp;nbsp;alongside OpenAI and SoftBank,&amp;nbsp;to build data centers and AI infrastructure in the U.S.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, it was reported that the company inked a&amp;nbsp;landmark&amp;nbsp;deal with OpenAI&amp;nbsp;to&amp;nbsp;supply the&amp;nbsp;AI company with&amp;nbsp;$300 billion&amp;nbsp;worth of&amp;nbsp;compute. On Friday,&amp;nbsp;Reuters reported that the company was signing a smaller —&amp;nbsp;but still sizable —&amp;nbsp;$20 billion&amp;nbsp;compute&amp;nbsp;deal&amp;nbsp;with Meta.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Oracle for more information on the transition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2015/09/456307736.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Oracle is shaking up its&amp;nbsp;executive&amp;nbsp;suite as&amp;nbsp;it sets its sights set on AI infrastructure dominance.&amp;nbsp;The company announced Monday that it is promoting&amp;nbsp;Clay Magouyrk and Mike Sicilia&amp;nbsp;to&amp;nbsp;co-CEO&amp;nbsp;roles.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Magouyrk&amp;nbsp;joined Oracle in 2014 from Amazon Web Services. He&amp;nbsp;was a founding member of&amp;nbsp;Oracle’s cloud engineering team and has served as the president of Oracle’s cloud infrastructure business unit&amp;nbsp;for more than a decade.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sicilia&amp;nbsp;has served as the president of Oracle’s industries division since&amp;nbsp;June. He held&amp;nbsp;several&amp;nbsp;different roles&amp;nbsp;at the company since he&amp;nbsp;joined through&amp;nbsp;Oracle’s acquisition of project portfolio management&amp;nbsp;company&amp;nbsp;Primavera Systems in 2008.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Safra Catz, who has&amp;nbsp;been Oracle’s CEO since&amp;nbsp;2014,&amp;nbsp;is moving into a&amp;nbsp;new role as the executive vice chair of Oracle’s board of directors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, Oracle is recognized as the cloud of choice for both AI training and inferencing.&amp;nbsp;I’m&amp;nbsp;very proud&amp;nbsp;of that,” Catz said in a statement. “Oracle’s technology and business have never been stronger. And our breathtaking growth rate points to an even more prosperous future. At this time of strength is the right moment to pass the CEO role to the next generation of capable executives.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While traditionally known as a cloud infrastructure provider, Oracle has recently started to cement its place in the AI infrastructure race as well.&amp;nbsp;Earlier this year, the company announced its participation in the&amp;nbsp;$500 billion&amp;nbsp;Stargate Project,&amp;nbsp;alongside OpenAI and SoftBank,&amp;nbsp;to build data centers and AI infrastructure in the U.S.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, it was reported that the company inked a&amp;nbsp;landmark&amp;nbsp;deal with OpenAI&amp;nbsp;to&amp;nbsp;supply the&amp;nbsp;AI company with&amp;nbsp;$300 billion&amp;nbsp;worth of&amp;nbsp;compute. On Friday,&amp;nbsp;Reuters reported that the company was signing a smaller —&amp;nbsp;but still sizable —&amp;nbsp;$20 billion&amp;nbsp;compute&amp;nbsp;deal&amp;nbsp;with Meta.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Oracle for more information on the transition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/oracle-promotes-two-presidents-to-co-ceo-role/</guid><pubDate>Mon, 22 Sep 2025 16:45:19 +0000</pubDate></item><item><title>Google’s Gemini AI is coming to your TV (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/googles-gemini-ai-is-coming-to-your-tv/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google’s AI assistant, Gemini, is coming to your TV. On Monday, the company announced it’s introducing Gemini for Google TV, allowing TV owners to engage in free-flowing, natural language conversations with the AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When fully rolled out, this expansion of Gemini to a new platform will bring Google’s AI to over 300 million active Google TV and other Android TV OS-powered devices. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of TV-related questions, Google suggests its Gemini AI could be used to help people with different interests settle on something to watch that they would both like, or to catch you up on what you missed in a past season of a favorite show. You could also get Gemini to help you find a movie or show when you can’t remember the title or ask about a title’s reviews to help determine if it’s worth watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, because it’s Gemini, you can ask any other type of question, too, just as you could with the AI chatbot on your smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; For instance, kids and parents could use the AI to get homework help or brainstorm school project ideas, families could use Gemini to plan their next vacation, or individual users could leverage the AI to teach themselves a new skill, among other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a photo of a Google TV showing a response on screen showing a prompt: &amp;quot;explain why volcanoes erupt to my third grader&amp;quot;." class="wp-image-3048543" height="562" src="https://techcrunch.com/wp-content/uploads/2025/09/Volcano_Gemini_TV-Shell.width-1000.format-webp.webp" width="1000" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company stresses that Gemini’s addition doesn’t mean that you won’t be able to do the same things you used to be able to do through the (non-AI) Google Assistant integration. Those commands will still work, says Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gemini rollout to Google TV begins on the TCL QM9K series starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the year, Gemini will arrive on the Google TV Streamer, Walmart onn 4K Pro, 2025 Hisense U7, U8, and UX models, and 2025 TCL QM7K, QM8K, and X11K models. More functionality will be added over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google’s AI assistant, Gemini, is coming to your TV. On Monday, the company announced it’s introducing Gemini for Google TV, allowing TV owners to engage in free-flowing, natural language conversations with the AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When fully rolled out, this expansion of Gemini to a new platform will bring Google’s AI to over 300 million active Google TV and other Android TV OS-powered devices. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of TV-related questions, Google suggests its Gemini AI could be used to help people with different interests settle on something to watch that they would both like, or to catch you up on what you missed in a past season of a favorite show. You could also get Gemini to help you find a movie or show when you can’t remember the title or ask about a title’s reviews to help determine if it’s worth watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, because it’s Gemini, you can ask any other type of question, too, just as you could with the AI chatbot on your smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; For instance, kids and parents could use the AI to get homework help or brainstorm school project ideas, families could use Gemini to plan their next vacation, or individual users could leverage the AI to teach themselves a new skill, among other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a photo of a Google TV showing a response on screen showing a prompt: &amp;quot;explain why volcanoes erupt to my third grader&amp;quot;." class="wp-image-3048543" height="562" src="https://techcrunch.com/wp-content/uploads/2025/09/Volcano_Gemini_TV-Shell.width-1000.format-webp.webp" width="1000" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company stresses that Gemini’s addition doesn’t mean that you won’t be able to do the same things you used to be able to do through the (non-AI) Google Assistant integration. Those commands will still work, says Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gemini rollout to Google TV begins on the TCL QM9K series starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the year, Gemini will arrive on the Google TV Streamer, Walmart onn 4K Pro, 2025 Hisense U7, U8, and UX models, and 2025 TCL QM7K, QM8K, and X11K models. More functionality will be added over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/googles-gemini-ai-is-coming-to-your-tv/</guid><pubDate>Mon, 22 Sep 2025 16:56:53 +0000</pubDate></item><item><title>Nvidia plans to invest up to $100B in OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/nvidia-plans-to-invest-up-to-100b-in-openai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia announced Monday it plans to invest up to $100 billion in OpenAI as part of a deal to build out massive data centers for training and running AI models. The companies say they signed a letter of intent to deploy 10 gigawatts — enough to power millions of homes — worth of Nvidia systems to power OpenAI’s next generation of AI infrastructure. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal may help OpenAI as it reduces its reliance on Microsoft, its largest investor and supplier of cloud computing resources. In January, Microsoft announced changes to its partnership with OpenAI, allowing the ChatGPT-maker to build additional AI infrastructure with other partners. Since then, OpenAI has teamed up with various partners on AI data center projects, such as Stargate. Nvidia says the deal will complement existing partnerships OpenAI has, including agreements with Microsoft, Oracle, and SoftBank.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it will work with Nvidia as a “preferred strategic compute and networking partner” for its AI factory growth. It’s unclear whether Nvidia’s investment will be paid out in chips, cloud credits, cash, or otherwise.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia announced Monday it plans to invest up to $100 billion in OpenAI as part of a deal to build out massive data centers for training and running AI models. The companies say they signed a letter of intent to deploy 10 gigawatts — enough to power millions of homes — worth of Nvidia systems to power OpenAI’s next generation of AI infrastructure. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal may help OpenAI as it reduces its reliance on Microsoft, its largest investor and supplier of cloud computing resources. In January, Microsoft announced changes to its partnership with OpenAI, allowing the ChatGPT-maker to build additional AI infrastructure with other partners. Since then, OpenAI has teamed up with various partners on AI data center projects, such as Stargate. Nvidia says the deal will complement existing partnerships OpenAI has, including agreements with Microsoft, Oracle, and SoftBank.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it will work with Nvidia as a “preferred strategic compute and networking partner” for its AI factory growth. It’s unclear whether Nvidia’s investment will be paid out in chips, cloud credits, cash, or otherwise.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/nvidia-plans-to-invest-up-to-100b-in-openai/</guid><pubDate>Mon, 22 Sep 2025 17:24:33 +0000</pubDate></item><item><title>The billion-dollar infrastructure deals powering the AI boom (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/the-billion-dollar-infrastructure-deals-powering-the-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1297856112.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It takes a lot of computing power to run an AI product – and as the tech industry races to tap the power of AI models, there’s a parallel race underway to build the infrastructure that will power them. On a recent earnings call, Nvidia CEO Jensen Huang estimated that between $3 and $4 trillion will be spent on AI infrastructure by the end of the decade – with much of that money coming from AI companies themselves. Along the way, they’re placing immense strain on power grids, and pushing the industry’s building capacity to its limit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, we’ve laid out everything we know about the biggest AI infrastructure projects, including major spending from Meta, Oracle, Microsoft, Google, and OpenAI. We’ll keep it updated as the boom continues, and the numbers climb even higher.&lt;/p&gt;







&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Microsoft’s $1 billion investment in OpenAI&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is arguably the deal that kicked off the whole contemporary AI boom: in 2019, Microsoft made a $1 billion investment in a buzzy non-profit called OpenAI, known mostly for its association with Elon Musk. Crucially, the deal made Microsoft the exclusive cloud provider for OpenAI – and as the demands of model-training became more intense, more of Microsoft’s investment started to come in the form of Azure cloud credit rather than cash. It was a great deal for both sides: Microsoft was able to claim more Azure sales, and OpenAI got more money for its biggest single expense. In the years that followed, Microsoft would build its investment up to nearly $14 billion – a move that is set to pay off enormously when OpenAI converts into a for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership between the two companies has unwound more recently. In January, OpenAI announced it would no longer be using Microsoft’s cloud exclusively, instead giving the company a right of first refusal on future infrastructure demands but pursuing others if Azure couldn’t meet their needs. More recently, Microsoft began exploring other foundation models to power its AI products, establishing even more independence from the AI giant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s arrangement with Microsoft was so successful that it’s become a common practice for AI services to sign on with a particular cloud provider. Anthropic has received $8 billion in investment from Amazon, while making kernel-level modifications on the company’s hardware to make it better-suited for AI training. Google Cloud has also signed on smaller AI companies like Loveable and Windsurf as “primary computing partners,” although those deals did not involve any investment. And even OpenAI has gone back to the well, receiving a $100 billion investment from Nvidia in September, giving it capacity to buy even more of the company’s GPUs.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The rise of Oracle&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On June 30th 2025, Oracle revealed in an SEC filing that it had signed a $30 billion cloud services deal with an unnamed partner, more than the company’s cloud revenues for all of the previous fiscal year. OpenAI was eventually revealed as the partner, securing Oracle a spot alongside Google as one of the OpenAI’s string of post-Microsoft hosting partners. Unsurprisingly, the company’s stock went shooting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, it happened again. On September 10th, Oracle revealed a five-year, $300 billion deal for compute power, set to begin in 2027. Oracle’s stock climbed even higher, briefly making founder Larry Ellison the richest man in the world. The sheer scale of the deal is stunning: OpenAI does not have $300 billion to spend, so the figure presumes immense growth for both companies, and more than a little faith. But before a single dollar is spent, the deal has already cemented Oracle as one of the leading AI infrastructure providers – and a financial force to be reckoned with.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Building tomorrow’s hyperscale data centers&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For companies like Meta that already have significant legacy infrastructure, the story is more complicated – although equally expensive. Mark Zuckerberg has said that Meta plans to spend $600 billion on US infrastructure through the end of 2028. In just the first half of 2025, the company spent $30 billion more than the previous year, driven largely by the company’s growing AI ambitions. Some of that spending goes toward big ticket cloud contracts, like a recent $10 billion deal with Google Cloud, but even more resources are being poured into two massive new data centers. A new 2,250-acre site in Louisiana, dubbed Hyperion, will cost an estimated $10 billion to build out and provide an estimated 5 gigawatts of compute power. Notably, the site includes an arrangement with a local nuclear power plant to handle the increased energy load. A smaller site in Ohio, called Prometheus, is expected to come online in 2026, powered by natural gas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of buildout comes with real environmental costs. Elon Musk’s xAI built its own hybrid data center and power-generation plant in South Memphis, Tennessee. The plant has quickly become one of the county’s largest emitters of smog-producing chemicals, thanks to a string of natural gas turbines that experts say violate the Clean Air Act.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The Stargate moonshot&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days after his second inauguration, President Trump announced a joint venture between SoftBank, OpenAI and Oracle, meant to spend $500 billion building AI infrastructure in the United States. Named “Stargate” after the 1994 film, the project arrived with incredible amounts of hype, with Trump calling it “the largest AI infrastructure project in history. Sam Altman seemed to agree, saying, ​​”I think this will be the most important project of this era.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In broad strokes, the plan was for SoftBank to provide the funding, with Oracle handling the buildout with input from OpenAI. Overseeing it all was Trump, who promised to clear away any regulatory hurdles that might slow down the build. But there were doubts from the beginning, including from Elon Musk, Altman’s business rival, who claimed the project did not have the available funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the hype has died down, the project has lost some momentum. In August, Bloomberg reported that the partners were failing to reach consensus. Nonetheless, the project has moved forward with the construction of eight data centers in Abilene, Texas, with construction on the final building set to be finished by the end of 2026.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1297856112.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It takes a lot of computing power to run an AI product – and as the tech industry races to tap the power of AI models, there’s a parallel race underway to build the infrastructure that will power them. On a recent earnings call, Nvidia CEO Jensen Huang estimated that between $3 and $4 trillion will be spent on AI infrastructure by the end of the decade – with much of that money coming from AI companies themselves. Along the way, they’re placing immense strain on power grids, and pushing the industry’s building capacity to its limit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, we’ve laid out everything we know about the biggest AI infrastructure projects, including major spending from Meta, Oracle, Microsoft, Google, and OpenAI. We’ll keep it updated as the boom continues, and the numbers climb even higher.&lt;/p&gt;







&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Microsoft’s $1 billion investment in OpenAI&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is arguably the deal that kicked off the whole contemporary AI boom: in 2019, Microsoft made a $1 billion investment in a buzzy non-profit called OpenAI, known mostly for its association with Elon Musk. Crucially, the deal made Microsoft the exclusive cloud provider for OpenAI – and as the demands of model-training became more intense, more of Microsoft’s investment started to come in the form of Azure cloud credit rather than cash. It was a great deal for both sides: Microsoft was able to claim more Azure sales, and OpenAI got more money for its biggest single expense. In the years that followed, Microsoft would build its investment up to nearly $14 billion – a move that is set to pay off enormously when OpenAI converts into a for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership between the two companies has unwound more recently. In January, OpenAI announced it would no longer be using Microsoft’s cloud exclusively, instead giving the company a right of first refusal on future infrastructure demands but pursuing others if Azure couldn’t meet their needs. More recently, Microsoft began exploring other foundation models to power its AI products, establishing even more independence from the AI giant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s arrangement with Microsoft was so successful that it’s become a common practice for AI services to sign on with a particular cloud provider. Anthropic has received $8 billion in investment from Amazon, while making kernel-level modifications on the company’s hardware to make it better-suited for AI training. Google Cloud has also signed on smaller AI companies like Loveable and Windsurf as “primary computing partners,” although those deals did not involve any investment. And even OpenAI has gone back to the well, receiving a $100 billion investment from Nvidia in September, giving it capacity to buy even more of the company’s GPUs.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The rise of Oracle&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On June 30th 2025, Oracle revealed in an SEC filing that it had signed a $30 billion cloud services deal with an unnamed partner, more than the company’s cloud revenues for all of the previous fiscal year. OpenAI was eventually revealed as the partner, securing Oracle a spot alongside Google as one of the OpenAI’s string of post-Microsoft hosting partners. Unsurprisingly, the company’s stock went shooting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, it happened again. On September 10th, Oracle revealed a five-year, $300 billion deal for compute power, set to begin in 2027. Oracle’s stock climbed even higher, briefly making founder Larry Ellison the richest man in the world. The sheer scale of the deal is stunning: OpenAI does not have $300 billion to spend, so the figure presumes immense growth for both companies, and more than a little faith. But before a single dollar is spent, the deal has already cemented Oracle as one of the leading AI infrastructure providers – and a financial force to be reckoned with.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Building tomorrow’s hyperscale data centers&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For companies like Meta that already have significant legacy infrastructure, the story is more complicated – although equally expensive. Mark Zuckerberg has said that Meta plans to spend $600 billion on US infrastructure through the end of 2028. In just the first half of 2025, the company spent $30 billion more than the previous year, driven largely by the company’s growing AI ambitions. Some of that spending goes toward big ticket cloud contracts, like a recent $10 billion deal with Google Cloud, but even more resources are being poured into two massive new data centers. A new 2,250-acre site in Louisiana, dubbed Hyperion, will cost an estimated $10 billion to build out and provide an estimated 5 gigawatts of compute power. Notably, the site includes an arrangement with a local nuclear power plant to handle the increased energy load. A smaller site in Ohio, called Prometheus, is expected to come online in 2026, powered by natural gas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of buildout comes with real environmental costs. Elon Musk’s xAI built its own hybrid data center and power-generation plant in South Memphis, Tennessee. The plant has quickly become one of the county’s largest emitters of smog-producing chemicals, thanks to a string of natural gas turbines that experts say violate the Clean Air Act.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The Stargate moonshot&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days after his second inauguration, President Trump announced a joint venture between SoftBank, OpenAI and Oracle, meant to spend $500 billion building AI infrastructure in the United States. Named “Stargate” after the 1994 film, the project arrived with incredible amounts of hype, with Trump calling it “the largest AI infrastructure project in history. Sam Altman seemed to agree, saying, ​​”I think this will be the most important project of this era.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In broad strokes, the plan was for SoftBank to provide the funding, with Oracle handling the buildout with input from OpenAI. Overseeing it all was Trump, who promised to clear away any regulatory hurdles that might slow down the build. But there were doubts from the beginning, including from Elon Musk, Altman’s business rival, who claimed the project did not have the available funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the hype has died down, the project has lost some momentum. In August, Bloomberg reported that the partners were failing to reach consensus. Nonetheless, the project has moved forward with the construction of eight data centers in Abilene, Texas, with construction on the final building set to be finished by the end of 2026.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/the-billion-dollar-infrastructure-deals-powering-the-ai-boom/</guid><pubDate>Mon, 22 Sep 2025 17:35:27 +0000</pubDate></item><item><title>DeepMind AI safety report explores the perils of “misaligned” AI (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/09/deepmind-ai-safety-report-explores-the-perils-of-misaligned-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind releases version 3.0 of its AI Frontier Safety Framework with new tips to stop bad bots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Jacob Porczyki/Nurphoto

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Generative AI models are far from perfect, but that hasn't stopped businesses and even governments from giving these robots important tasks. But what happens when AI goes bad? Researchers at Google DeepMind spend a lot of time thinking about how generative AI systems can become threats, detailing it all in the company's Frontier Safety Framework. DeepMind recently released version 3.0&amp;nbsp;of the framework to explore more ways AI could go off the rails, including the possibility that models could ignore user attempts to shut them down.&lt;/p&gt;
&lt;p&gt;DeepMind's safety framework is based on so-called "critical capability levels" (CCLs). These are essentially risk assessment rubrics that aim to measure an AI model's capabilities and define the point at which its behavior becomes dangerous in areas like cybersecurity or biosciences. The document also details the ways developers can address the CCLs DeepMind identifies in their own models.&lt;/p&gt;
&lt;p&gt;Google and other firms that have delved deeply into generative AI employ a number of techniques to prevent AI from acting maliciously. Although calling an AI "malicious" lends it intentionality that fancy estimation architectures don't have. What we're talking about here is the possibility of misuse or malfunction that is baked into the nature of generative AI systems.&lt;/p&gt;
&lt;p&gt;The updated framework (PDF) says that developers should take precautions to ensure model security. Specifically, it calls for proper safeguarding of model weights for more powerful AI systems. The researchers fear that exfiltration of model weights would give bad actors the chance to disable the guardrails that have been designed to prevent malicious behavior. This could lead to CCLs like a bot that creates more effective malware or assists in designing biological weapons.&lt;/p&gt;
&lt;p&gt;DeepMind also calls out the possibility that an AI could be tuned to be manipulative and systematically change people's beliefs—this CCL seems pretty plausible given how people grow attached to chatbots. However, the team doesn't have a great answer here, noting that this is a "low-velocity" threat, and our existing "social defenses" should be enough to do the job without new restrictions that could stymie innovation. This might assume too much of people, though.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind also addresses something of a meta-concern about AI. The researchers say that a powerful AI in the wrong hands could be dangerous if it is used to accelerate machine learning research, resulting in the creation of more capable and unrestricted AI models. DeepMind says this could "have a significant effect on society’s ability to adapt to and govern powerful AI models." DeepMind ranks this as a more severe threat than most other CCLs.&lt;/p&gt;
&lt;h2&gt;The misaligned AI&lt;/h2&gt;
&lt;p&gt;Most AI security mitigations follow from the assumption that the model is at least trying to follow instructions. Despite years of hallucination, researchers have not managed to make these models completely trustworthy or accurate, but it's possible that a model's incentives could be warped, either accidentally or on purpose. If a misaligned AI begins to actively work against humans or ignore instructions, that's a new kind of problem that goes beyond simple hallucination.&lt;/p&gt;
&lt;p&gt;Version 3 of the Frontier Safety Framework introduces an "exploratory approach" to understanding the risks of a misaligned AI. There have already been documented instances of generative AI models engaging in deception and defiant behavior, and DeepMind researchers express concern that it may be difficult to monitor for this kind of behavior in the future.&lt;/p&gt;
&lt;p&gt;A misaligned AI might ignore human instructions, produce fraudulent outputs, or refuse to stop operating when requested. For the time being, there's a fairly straightforward way to combat this outcome. Today's most advanced simulated reasoning models produce "scratchpad" outputs during the thinking process. Devs are advised to use an automated monitor to double-check the model's chain-of-thought output for evidence misalignment or deception.&lt;/p&gt;
&lt;p&gt;Google says this CCL could become more severe in the future. The team believes models in the coming years may evolve to have effective simulated reasoning without producing a verifiable chain of thought. So your overseer guardrail wouldn't be able to peer into the reasoning process of such a model. For this theoretical advanced AI, it may be impossible to completely rule out that the model is working against the interests of its human operator.&lt;/p&gt;
&lt;p&gt;The framework doesn't have a good solution to this problem just yet. DeepMind says it is researching possible mitigations for a misaligned AI, but it's hard to know when or if this problem will become a reality. These "thinking" models have only been common for about a year, and there's still a lot we don't know about how they arrive at a given output.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind releases version 3.0 of its AI Frontier Safety Framework with new tips to stop bad bots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Jacob Porczyki/Nurphoto

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Generative AI models are far from perfect, but that hasn't stopped businesses and even governments from giving these robots important tasks. But what happens when AI goes bad? Researchers at Google DeepMind spend a lot of time thinking about how generative AI systems can become threats, detailing it all in the company's Frontier Safety Framework. DeepMind recently released version 3.0&amp;nbsp;of the framework to explore more ways AI could go off the rails, including the possibility that models could ignore user attempts to shut them down.&lt;/p&gt;
&lt;p&gt;DeepMind's safety framework is based on so-called "critical capability levels" (CCLs). These are essentially risk assessment rubrics that aim to measure an AI model's capabilities and define the point at which its behavior becomes dangerous in areas like cybersecurity or biosciences. The document also details the ways developers can address the CCLs DeepMind identifies in their own models.&lt;/p&gt;
&lt;p&gt;Google and other firms that have delved deeply into generative AI employ a number of techniques to prevent AI from acting maliciously. Although calling an AI "malicious" lends it intentionality that fancy estimation architectures don't have. What we're talking about here is the possibility of misuse or malfunction that is baked into the nature of generative AI systems.&lt;/p&gt;
&lt;p&gt;The updated framework (PDF) says that developers should take precautions to ensure model security. Specifically, it calls for proper safeguarding of model weights for more powerful AI systems. The researchers fear that exfiltration of model weights would give bad actors the chance to disable the guardrails that have been designed to prevent malicious behavior. This could lead to CCLs like a bot that creates more effective malware or assists in designing biological weapons.&lt;/p&gt;
&lt;p&gt;DeepMind also calls out the possibility that an AI could be tuned to be manipulative and systematically change people's beliefs—this CCL seems pretty plausible given how people grow attached to chatbots. However, the team doesn't have a great answer here, noting that this is a "low-velocity" threat, and our existing "social defenses" should be enough to do the job without new restrictions that could stymie innovation. This might assume too much of people, though.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind also addresses something of a meta-concern about AI. The researchers say that a powerful AI in the wrong hands could be dangerous if it is used to accelerate machine learning research, resulting in the creation of more capable and unrestricted AI models. DeepMind says this could "have a significant effect on society’s ability to adapt to and govern powerful AI models." DeepMind ranks this as a more severe threat than most other CCLs.&lt;/p&gt;
&lt;h2&gt;The misaligned AI&lt;/h2&gt;
&lt;p&gt;Most AI security mitigations follow from the assumption that the model is at least trying to follow instructions. Despite years of hallucination, researchers have not managed to make these models completely trustworthy or accurate, but it's possible that a model's incentives could be warped, either accidentally or on purpose. If a misaligned AI begins to actively work against humans or ignore instructions, that's a new kind of problem that goes beyond simple hallucination.&lt;/p&gt;
&lt;p&gt;Version 3 of the Frontier Safety Framework introduces an "exploratory approach" to understanding the risks of a misaligned AI. There have already been documented instances of generative AI models engaging in deception and defiant behavior, and DeepMind researchers express concern that it may be difficult to monitor for this kind of behavior in the future.&lt;/p&gt;
&lt;p&gt;A misaligned AI might ignore human instructions, produce fraudulent outputs, or refuse to stop operating when requested. For the time being, there's a fairly straightforward way to combat this outcome. Today's most advanced simulated reasoning models produce "scratchpad" outputs during the thinking process. Devs are advised to use an automated monitor to double-check the model's chain-of-thought output for evidence misalignment or deception.&lt;/p&gt;
&lt;p&gt;Google says this CCL could become more severe in the future. The team believes models in the coming years may evolve to have effective simulated reasoning without producing a verifiable chain of thought. So your overseer guardrail wouldn't be able to peer into the reasoning process of such a model. For this theoretical advanced AI, it may be impossible to completely rule out that the model is working against the interests of its human operator.&lt;/p&gt;
&lt;p&gt;The framework doesn't have a good solution to this problem just yet. DeepMind says it is researching possible mitigations for a misaligned AI, but it's hard to know when or if this problem will become a reality. These "thinking" models have only been common for about a year, and there's still a lot we don't know about how they arrive at a given output.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/09/deepmind-ai-safety-report-explores-the-perils-of-misaligned-ai/</guid><pubDate>Mon, 22 Sep 2025 18:18:00 +0000</pubDate></item><item><title>[NEW] NVIDIA, OpenAI Announce ‘the Biggest AI Infrastructure Deployment in History’ (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/openai-nvidia/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;OpenAI and NVIDIA just announced a landmark AI infrastructure partnership — an initiative that will scale OpenAI’s compute with multi-gigawatt data centers powered by millions of NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;To discuss what this means for the next generation of AI development and deployment, the two companies’ CEOs, and the president of OpenAI, spoke this morning with CNBC’s Jon Fortt.&lt;/p&gt;
&lt;p&gt;“This is the biggest AI infrastructure project in history,” said NVIDIA founder and CEO Jensen Huang in the interview. “This partnership is about building an AI infrastructure that enables AI to go from the labs into the world.”&lt;/p&gt;
&lt;p&gt;Through the partnership, OpenAI will deploy at least 10 gigawatts of NVIDIA systems for OpenAI’s next-generation AI infrastructure, including the NVIDIA Vera Rubin platform. NVIDIA also intends to invest up to $100 billion in OpenAI progressively as each gigawatt is deployed.&lt;/p&gt;
&lt;p&gt;“There’s no partner but NVIDIA that can do this at this kind of scale, at this kind of speed,” said Sam Altman, CEO of OpenAI.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignright size-large wp-image-85178" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/OAI_Altmanquote-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;The million-GPU AI factories built through this agreement will help OpenAI meet the training and inference demands of its next frontier of AI models.&lt;/p&gt;
&lt;p&gt;“Building this infrastructure is critical to everything we want to do,” Altman said. “This is the fuel that we need to drive improvement, drive better models, drive revenue, drive everything.”&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_85172"&gt;&lt;img alt="alt" class="wp-image-85172 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jhh-oai-announce-sep25-press-1920x1080-1504-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-85172"&gt;(L to R): OpenAI President Greg Brockman, NVIDIA Founder and CEO Jensen Huang, and OpenAI CEO Sam Altman&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Building Million-GPU Infrastructure to Meet AI Demand&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Since the launch of OpenAI’s ChatGPT — which in 2022 became the fastest application in history to reach 100 million users — the company has grown its user base to more than 700 million weekly active users and delivered increasingly advanced capabilities, including support for agentic AI, AI reasoning, multimodal data and longer context windows.&lt;/p&gt;
&lt;p&gt;To support its next phase of growth, the company’s AI infrastructure must scale up to meet not only training but inference demands of the most advanced models for&amp;nbsp; agentic and reasoning AI users worldwide.&lt;/p&gt;
&lt;p&gt;“The cost per unit of intelligence will keep falling and falling and falling, and we think that’s great,” said Altman. “But on the other side, the frontier of AI, maximum intellectual capability, is going up and up. And that enables more and more use — and a lot of it.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85184" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/SamAltman-Quote.png" width="1020" /&gt;&lt;/p&gt;
&lt;p&gt;Without enough computational resources, Altman explained, people would have to choose between impactful use cases, for example either researching a cancer cure or offering free education.&lt;/p&gt;
&lt;p&gt;“No one wants to make that choice,” he said. “And so increasingly, as we see this, the answer is just much more capacity so that we can serve the massive need and opportunity.”&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_34361"&gt;&lt;img alt="NVIDIA CEO opens the GPU tray on DGX-1 presented to OpenAI in San Francisco." class="wp-image-34361" height="493" src="https://blogs.nvidia.com/wp-content/uploads/2016/08/15OpenAI_inside_tray_cropped.jpg" width="400" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-34361"&gt;In 2016, NVIDIA CEO Jensen Huang hand-delivered the first NVIDIA DGX system to OpenAI’s headquarters in San Francisco.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The first gigawatt of NVIDIA systems built with NVIDIA Vera Rubin GPUs will generate their first tokens in the second half of 2026.&lt;/p&gt;
&lt;p&gt;The partnership expands on a long-standing collaboration between NVIDIA and OpenAI, which began with Huang hand-delivering the first NVIDIA DGX system to the company in 2016.&lt;/p&gt;
&lt;p&gt;“This is a billion times more computational power than that initial server,” said Greg Brockman, president of OpenAI. “We’re able to actually create new breakthroughs, new models…to empower every individual and business because we’ll be able to reach the next level of scale.”&lt;/p&gt;
&lt;p&gt;Huang emphasized that though this is the start of a massive buildout of AI infrastructure around the world, it’s just the beginning.&lt;/p&gt;
&lt;p&gt;“We’re literally going to connect intelligence to every application, to every use case, to every device — and we’re just at the beginning,” Huang said. “This is the first 10 gigawatts, I assure you of that.”&lt;/p&gt;
&lt;p&gt;Watch the CNBC interview below.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;OpenAI and NVIDIA just announced a landmark AI infrastructure partnership — an initiative that will scale OpenAI’s compute with multi-gigawatt data centers powered by millions of NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;To discuss what this means for the next generation of AI development and deployment, the two companies’ CEOs, and the president of OpenAI, spoke this morning with CNBC’s Jon Fortt.&lt;/p&gt;
&lt;p&gt;“This is the biggest AI infrastructure project in history,” said NVIDIA founder and CEO Jensen Huang in the interview. “This partnership is about building an AI infrastructure that enables AI to go from the labs into the world.”&lt;/p&gt;
&lt;p&gt;Through the partnership, OpenAI will deploy at least 10 gigawatts of NVIDIA systems for OpenAI’s next-generation AI infrastructure, including the NVIDIA Vera Rubin platform. NVIDIA also intends to invest up to $100 billion in OpenAI progressively as each gigawatt is deployed.&lt;/p&gt;
&lt;p&gt;“There’s no partner but NVIDIA that can do this at this kind of scale, at this kind of speed,” said Sam Altman, CEO of OpenAI.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignright size-large wp-image-85178" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/OAI_Altmanquote-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;The million-GPU AI factories built through this agreement will help OpenAI meet the training and inference demands of its next frontier of AI models.&lt;/p&gt;
&lt;p&gt;“Building this infrastructure is critical to everything we want to do,” Altman said. “This is the fuel that we need to drive improvement, drive better models, drive revenue, drive everything.”&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_85172"&gt;&lt;img alt="alt" class="wp-image-85172 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jhh-oai-announce-sep25-press-1920x1080-1504-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-85172"&gt;(L to R): OpenAI President Greg Brockman, NVIDIA Founder and CEO Jensen Huang, and OpenAI CEO Sam Altman&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Building Million-GPU Infrastructure to Meet AI Demand&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Since the launch of OpenAI’s ChatGPT — which in 2022 became the fastest application in history to reach 100 million users — the company has grown its user base to more than 700 million weekly active users and delivered increasingly advanced capabilities, including support for agentic AI, AI reasoning, multimodal data and longer context windows.&lt;/p&gt;
&lt;p&gt;To support its next phase of growth, the company’s AI infrastructure must scale up to meet not only training but inference demands of the most advanced models for&amp;nbsp; agentic and reasoning AI users worldwide.&lt;/p&gt;
&lt;p&gt;“The cost per unit of intelligence will keep falling and falling and falling, and we think that’s great,” said Altman. “But on the other side, the frontier of AI, maximum intellectual capability, is going up and up. And that enables more and more use — and a lot of it.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85184" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/SamAltman-Quote.png" width="1020" /&gt;&lt;/p&gt;
&lt;p&gt;Without enough computational resources, Altman explained, people would have to choose between impactful use cases, for example either researching a cancer cure or offering free education.&lt;/p&gt;
&lt;p&gt;“No one wants to make that choice,” he said. “And so increasingly, as we see this, the answer is just much more capacity so that we can serve the massive need and opportunity.”&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_34361"&gt;&lt;img alt="NVIDIA CEO opens the GPU tray on DGX-1 presented to OpenAI in San Francisco." class="wp-image-34361" height="493" src="https://blogs.nvidia.com/wp-content/uploads/2016/08/15OpenAI_inside_tray_cropped.jpg" width="400" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-34361"&gt;In 2016, NVIDIA CEO Jensen Huang hand-delivered the first NVIDIA DGX system to OpenAI’s headquarters in San Francisco.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The first gigawatt of NVIDIA systems built with NVIDIA Vera Rubin GPUs will generate their first tokens in the second half of 2026.&lt;/p&gt;
&lt;p&gt;The partnership expands on a long-standing collaboration between NVIDIA and OpenAI, which began with Huang hand-delivering the first NVIDIA DGX system to the company in 2016.&lt;/p&gt;
&lt;p&gt;“This is a billion times more computational power than that initial server,” said Greg Brockman, president of OpenAI. “We’re able to actually create new breakthroughs, new models…to empower every individual and business because we’ll be able to reach the next level of scale.”&lt;/p&gt;
&lt;p&gt;Huang emphasized that though this is the start of a massive buildout of AI infrastructure around the world, it’s just the beginning.&lt;/p&gt;
&lt;p&gt;“We’re literally going to connect intelligence to every application, to every use case, to every device — and we’re just at the beginning,” Huang said. “This is the first 10 gigawatts, I assure you of that.”&lt;/p&gt;
&lt;p&gt;Watch the CNBC interview below.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/openai-nvidia/</guid><pubDate>Mon, 22 Sep 2025 18:38:58 +0000</pubDate></item><item><title>[NEW] Inside the mind of Elad Gil: Early-stage investing and next-gen innovation at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/elad-gil-one-of-techs-sharpest-minds-on-early-bets-breakout-growth-and-whats-coming-next-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ahead of the curve — he practically lives there. Before most of the world had even asked ChatGPT its first question, &lt;strong&gt;Elad Gil&lt;/strong&gt; was writing early checks into companies like Perplexity, Character.AI, and Harvey. That’s just a slice of his story. His track record spans seed and Series A investments in over 30 unicorns and involvement with some of the most iconic names in tech, including Stripe, Airbnb, Coinbase, Instacart, Notion, Figma, Flexport, GitLab, and many more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This October, Gil takes the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; in San Francisco for a one-on-one fireside chat. He’ll cover his approach to spotting breakout potential early, decoding emerging markets, and what’s next across AI, crypto, health tech, and enterprise SaaS.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now before September 26, 11:59 p.m., to save up to $668 on your pass!&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Elad Gil" class="wp-image-3034899" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Elad-Gil-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With operating experience at Google and Twitter, multiple founder wins, and a portfolio reading like a who’s who of tech success stories, Gil blends operator empathy with investor clarity. His bestselling book &lt;em&gt;High Growth Handbook&lt;/em&gt; is required reading for startup leaders scaling fast, and his ability to predict market shifts is second to none.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this conversation, he’ll go deep on early-stage investing, frontier technologies, and what it takes to build a category-defining company — from the inside out. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-early-insights-from-a-silicon-valley-powerhouse"&gt;Early insights from a Silicon Valley powerhouse&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ startup and VC leaders October 27–29 at Moscone West in San Francisco. From headline-making sessions to hands-on networking, Disrupt is where the future of tech gets built — and this fireside with Elad Gil is a rare opportunity to learn from one of Silicon Valley’s most prolific investors. &lt;strong&gt;Register here to save up to $668&lt;/strong&gt; with Regular Bird pricing before rates increase on September 26, 11:59 p.m. PT.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ahead of the curve — he practically lives there. Before most of the world had even asked ChatGPT its first question, &lt;strong&gt;Elad Gil&lt;/strong&gt; was writing early checks into companies like Perplexity, Character.AI, and Harvey. That’s just a slice of his story. His track record spans seed and Series A investments in over 30 unicorns and involvement with some of the most iconic names in tech, including Stripe, Airbnb, Coinbase, Instacart, Notion, Figma, Flexport, GitLab, and many more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This October, Gil takes the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; in San Francisco for a one-on-one fireside chat. He’ll cover his approach to spotting breakout potential early, decoding emerging markets, and what’s next across AI, crypto, health tech, and enterprise SaaS.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now before September 26, 11:59 p.m., to save up to $668 on your pass!&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Elad Gil" class="wp-image-3034899" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Elad-Gil-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With operating experience at Google and Twitter, multiple founder wins, and a portfolio reading like a who’s who of tech success stories, Gil blends operator empathy with investor clarity. His bestselling book &lt;em&gt;High Growth Handbook&lt;/em&gt; is required reading for startup leaders scaling fast, and his ability to predict market shifts is second to none.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this conversation, he’ll go deep on early-stage investing, frontier technologies, and what it takes to build a category-defining company — from the inside out. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-early-insights-from-a-silicon-valley-powerhouse"&gt;Early insights from a Silicon Valley powerhouse&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ startup and VC leaders October 27–29 at Moscone West in San Francisco. From headline-making sessions to hands-on networking, Disrupt is where the future of tech gets built — and this fireside with Elad Gil is a rare opportunity to learn from one of Silicon Valley’s most prolific investors. &lt;strong&gt;Register here to save up to $668&lt;/strong&gt; with Regular Bird pricing before rates increase on September 26, 11:59 p.m. PT.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/elad-gil-one-of-techs-sharpest-minds-on-early-bets-breakout-growth-and-whats-coming-next-at-techcrunch-disrupt-2025/</guid><pubDate>Mon, 22 Sep 2025 19:00:00 +0000</pubDate></item><item><title>[NEW] MIT affiliates win AI for Math grants to accelerate mathematical discovery (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/ai-for-math-grants-accelerate-mathematical-discovery-0922</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-mathematics-roe-sutherland.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT Department of Mathematics researchers David Roe ’06 and Andrew Sutherland ’90, PhD ’07 are among the inaugural recipients of the Renaissance Philanthropy and XTX Markets’ AI for Math grants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Four additional MIT alumni — Anshula Gandhi ’19, Viktor Kunčak SM ’01, PhD ’07; Gireeja Ranade ’07; and Damiano Testa PhD ’05 — were also honored for separate projects.&lt;/p&gt;&lt;p&gt;The first 29 winning projects will support mathematicians and researchers at universities and organizations working to develop artificial intelligence systems that help advance mathematical discovery and research across several key tasks.&lt;/p&gt;&lt;p&gt;Roe and Sutherland, along with&amp;nbsp;Chris Birkbeck&amp;nbsp;of the University of East Anglia,&amp;nbsp;will use their grant&amp;nbsp;to boost automated theorem proving by building connections between the&amp;nbsp;L-Functions and Modular Forms Database&amp;nbsp;(LMFDB) and the&amp;nbsp;Lean4 mathematics library&amp;nbsp;(mathlib).&lt;/p&gt;&lt;p&gt;“Automated theorem provers are quite technically involved, but their development is under-resourced,” says&amp;nbsp;Sutherland. With AI technologies such as large language models (LLMs), the barrier to entry for these formal tools is dropping rapidly, making formal verification frameworks accessible to working mathematicians.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Mathlib is a large, community-driven mathematical library for the&amp;nbsp;Lean&amp;nbsp;theorem prover, a formal system that verifies the correctness of every step in a proof.&amp;nbsp;Mathlib currently contains on the order of 10&lt;sup&gt;5&lt;/sup&gt; mathematical results (such as lemmas, propositions, and theorems). The LMFDB,&amp;nbsp;a massive, collaborative online resource that serves as a kind of “encyclopedia” of modern number theory,&amp;nbsp;contains more than 10&lt;sup&gt;9&lt;/sup&gt; concrete statements.&amp;nbsp;Sutherland&amp;nbsp;and Roe are managing editors of the LMFDB.&lt;/p&gt;&lt;p&gt;Roe and Sutherland’s grant will be used for a&amp;nbsp;project that aims to augment both systems, making the LMFDB’s results available within mathlib as assertions that have not yet been formally proved, and providing precise formal definitions of the numerical data stored within the LMFDB. This bridge will benefit both human mathematicians and AI agents, and provide a framework for connecting other mathematical databases to formal theorem-proving systems.&lt;/p&gt;&lt;p&gt;The main obstacles to automating mathematical discovery and proof are the limited amount of formalized math knowledge, the high cost of formalizing complex results, and the gap between what is computationally accessible and what is feasible to formalize.&lt;/p&gt;&lt;p&gt;To address these obstacles, the researchers will use the funding to build tools for accessing the LMFDB from mathlib, making a large database of unformalized mathematical knowledge accessible to a formal proof system. This approach enables proof assistants to identify specific targets for formalization without the need to formalize the entire LMFDB corpus in advance.&lt;/p&gt;&lt;p&gt;“Making a large database of unformalized number-theoretic facts available within mathlib will provide a powerful technique for mathematical discovery, because the set of facts an agent might wish to consider while searching for a theorem or proof is exponentially larger than the set of facts that eventually need to be formalized in actually proving the theorem,” says Roe.&lt;/p&gt;&lt;p&gt;The researchers note that proving new theorems at the frontier of mathematical knowledge often&amp;nbsp;involves steps that rely on a nontrivial computation. For example, Andrew Wiles’ proof of Fermat’s Last Theorem uses what is known as the “3-5 trick” at a crucial point in the proof.&lt;/p&gt;&lt;p&gt;“This trick depends on the fact that the modular curve X_0(15) has only finitely many rational points, and none of those rational points correspond to a semi-stable elliptic curve,” according to&amp;nbsp;Sutherland. “This fact was known well before Wiles’ work, and is easy to verify using computational tools available in modern computer algebra systems, but it is not something one can realistically prove using pencil and paper, nor is it necessarily easy to formalize.”&lt;/p&gt;&lt;p&gt;While formal theorem provers are being connected to computer algebra systems for more efficient verification, tapping into computational outputs in existing mathematical databases offers several other benefits.&lt;/p&gt;&lt;p&gt;Using stored results leverages the thousands of CPU-years of computation time already spent in creating the LMFDB, saving money that would be needed to redo these computations. Having precomputed information available also makes it feasible to search for examples or counterexamples without knowing ahead of time how broad the search can be. In addition, mathematical databases are curated repositories, not simply a random collection of facts.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The fact that number theorists emphasized the role of the conductor in databases of elliptic curves has already proved to be crucial to one notable mathematical discovery made using machine learning tools:&amp;nbsp;murmurations,” says&amp;nbsp;Sutherland.&lt;/p&gt;&lt;p&gt;“Our next steps are to build a team, engage with both the LMFDB and mathlib communities, start to formalize the definitions that underpin the elliptic curve, number field, and modular form sections of the LMFDB, and make it possible to run LMFDB searches from within mathlib,” says Roe. “If you are an MIT student interested in getting involved, feel free to reach out!”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-mathematics-roe-sutherland.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT Department of Mathematics researchers David Roe ’06 and Andrew Sutherland ’90, PhD ’07 are among the inaugural recipients of the Renaissance Philanthropy and XTX Markets’ AI for Math grants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Four additional MIT alumni — Anshula Gandhi ’19, Viktor Kunčak SM ’01, PhD ’07; Gireeja Ranade ’07; and Damiano Testa PhD ’05 — were also honored for separate projects.&lt;/p&gt;&lt;p&gt;The first 29 winning projects will support mathematicians and researchers at universities and organizations working to develop artificial intelligence systems that help advance mathematical discovery and research across several key tasks.&lt;/p&gt;&lt;p&gt;Roe and Sutherland, along with&amp;nbsp;Chris Birkbeck&amp;nbsp;of the University of East Anglia,&amp;nbsp;will use their grant&amp;nbsp;to boost automated theorem proving by building connections between the&amp;nbsp;L-Functions and Modular Forms Database&amp;nbsp;(LMFDB) and the&amp;nbsp;Lean4 mathematics library&amp;nbsp;(mathlib).&lt;/p&gt;&lt;p&gt;“Automated theorem provers are quite technically involved, but their development is under-resourced,” says&amp;nbsp;Sutherland. With AI technologies such as large language models (LLMs), the barrier to entry for these formal tools is dropping rapidly, making formal verification frameworks accessible to working mathematicians.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Mathlib is a large, community-driven mathematical library for the&amp;nbsp;Lean&amp;nbsp;theorem prover, a formal system that verifies the correctness of every step in a proof.&amp;nbsp;Mathlib currently contains on the order of 10&lt;sup&gt;5&lt;/sup&gt; mathematical results (such as lemmas, propositions, and theorems). The LMFDB,&amp;nbsp;a massive, collaborative online resource that serves as a kind of “encyclopedia” of modern number theory,&amp;nbsp;contains more than 10&lt;sup&gt;9&lt;/sup&gt; concrete statements.&amp;nbsp;Sutherland&amp;nbsp;and Roe are managing editors of the LMFDB.&lt;/p&gt;&lt;p&gt;Roe and Sutherland’s grant will be used for a&amp;nbsp;project that aims to augment both systems, making the LMFDB’s results available within mathlib as assertions that have not yet been formally proved, and providing precise formal definitions of the numerical data stored within the LMFDB. This bridge will benefit both human mathematicians and AI agents, and provide a framework for connecting other mathematical databases to formal theorem-proving systems.&lt;/p&gt;&lt;p&gt;The main obstacles to automating mathematical discovery and proof are the limited amount of formalized math knowledge, the high cost of formalizing complex results, and the gap between what is computationally accessible and what is feasible to formalize.&lt;/p&gt;&lt;p&gt;To address these obstacles, the researchers will use the funding to build tools for accessing the LMFDB from mathlib, making a large database of unformalized mathematical knowledge accessible to a formal proof system. This approach enables proof assistants to identify specific targets for formalization without the need to formalize the entire LMFDB corpus in advance.&lt;/p&gt;&lt;p&gt;“Making a large database of unformalized number-theoretic facts available within mathlib will provide a powerful technique for mathematical discovery, because the set of facts an agent might wish to consider while searching for a theorem or proof is exponentially larger than the set of facts that eventually need to be formalized in actually proving the theorem,” says Roe.&lt;/p&gt;&lt;p&gt;The researchers note that proving new theorems at the frontier of mathematical knowledge often&amp;nbsp;involves steps that rely on a nontrivial computation. For example, Andrew Wiles’ proof of Fermat’s Last Theorem uses what is known as the “3-5 trick” at a crucial point in the proof.&lt;/p&gt;&lt;p&gt;“This trick depends on the fact that the modular curve X_0(15) has only finitely many rational points, and none of those rational points correspond to a semi-stable elliptic curve,” according to&amp;nbsp;Sutherland. “This fact was known well before Wiles’ work, and is easy to verify using computational tools available in modern computer algebra systems, but it is not something one can realistically prove using pencil and paper, nor is it necessarily easy to formalize.”&lt;/p&gt;&lt;p&gt;While formal theorem provers are being connected to computer algebra systems for more efficient verification, tapping into computational outputs in existing mathematical databases offers several other benefits.&lt;/p&gt;&lt;p&gt;Using stored results leverages the thousands of CPU-years of computation time already spent in creating the LMFDB, saving money that would be needed to redo these computations. Having precomputed information available also makes it feasible to search for examples or counterexamples without knowing ahead of time how broad the search can be. In addition, mathematical databases are curated repositories, not simply a random collection of facts.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The fact that number theorists emphasized the role of the conductor in databases of elliptic curves has already proved to be crucial to one notable mathematical discovery made using machine learning tools:&amp;nbsp;murmurations,” says&amp;nbsp;Sutherland.&lt;/p&gt;&lt;p&gt;“Our next steps are to build a team, engage with both the LMFDB and mathlib communities, start to formalize the definitions that underpin the elliptic curve, number field, and modular form sections of the LMFDB, and make it possible to run LMFDB searches from within mathlib,” says Roe. “If you are an MIT student interested in getting involved, feel free to reach out!”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/ai-for-math-grants-accelerate-mathematical-discovery-0922</guid><pubDate>Mon, 22 Sep 2025 19:15:00 +0000</pubDate></item><item><title>[NEW] OpenAI and Nvidia’s $100B AI plan will require power equal to 10 nuclear reactors (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/openai-and-nvidias-100b-ai-plan-will-require-power-equal-to-10-nuclear-reactors/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "This is a giant project," Nvidia CEO said of new 10-gigawatt AI infrastructure deal.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-640x427.jpg" width="640" /&gt;
                  &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anton Petrus via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, OpenAI and Nvidia jointly announced a letter of intent for a strategic partnership to deploy at least 10 gigawatts of Nvidia systems for OpenAI's AI infrastructure, with Nvidia planning to invest up to $100 billion as the systems roll out. The companies said the first gigawatt of Nvidia systems will come online in the second half of 2026 using Nvidia's Vera Rubin platform.&lt;/p&gt;
&lt;p&gt;"Everything starts with compute," said Sam Altman, CEO of OpenAI, in the announcement. "Compute infrastructure will be the basis for the economy of the future, and we will utilize what we're building with NVIDIA to both create new AI breakthroughs and empower people and businesses with them at scale."&lt;/p&gt;
&lt;p&gt;The 10-gigawatt project represents an astoundingly ambitious and as-yet-unproven scale for AI infrastructure. Nvidia CEO Jensen Huang told CNBC that the planned 10 gigawatts equals the power consumption of between 4 million and 5 million graphics processing units, which matches the company's total GPU shipments for this year and doubles last year's volume. "This is a giant project," Huang said in an interview alongside Altman and OpenAI President Greg Brockman.&lt;/p&gt;
&lt;p&gt;To put that power demand in perspective, 10 gigawatts equals the output of roughly 10 nuclear reactors, which typically output about 1 gigawatt per facility. Current data center energy consumption ranges from 10 megawatts to 1 gigawatt, with most large facilities consuming between 50 and 100 megawatts. OpenAI's planned infrastructure would dwarf existing installations, requiring as much electricity as multiple major cities.&lt;/p&gt;
&lt;p&gt;The partnership follows OpenAI's rapid user growth to 700 million weekly active users. Nvidia's stock rose nearly 4 percent on Monday following the announcement, adding roughly $170 billion to its market capitalization. The partnership establishes Nvidia as OpenAI's preferred strategic compute and networking partner, alongside OpenAI's existing relationships with Microsoft, Oracle, SoftBank, and the recently announced Stargate project partners.&lt;/p&gt;
&lt;p&gt;The partnership announcement comes a week after Nvidia disclosed a $5 billion investment in Intel, taking a 4 percent stake in its longtime competitor as the two companies plan to co-develop custom data center and PC products.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bryn Talkington, managing partner at Requisite Capital Management, noted the circular nature of the investment structure to CNBC. "Nvidia invests $100 billion in OpenAI, which then OpenAI turns back and gives it back to Nvidia," Talkington told CNBC. "I feel like this is going to be very virtuous for Jensen."&lt;/p&gt;
&lt;h2&gt;Racing for nuclear power&lt;/h2&gt;
&lt;p&gt;In an August earnings call, Huang told investors that building one gigawatt of data center capacity costs between $50 billion and $60 billion, with about $35 billion going toward Nvidia chips and systems. At that rate, the 10 gigawatt project could require total investment exceeding $500 billion.&lt;/p&gt;
&lt;p&gt;While the companies did not specify power sources in their announcement, the massive energy requirements have driven other tech giants to nuclear partnerships for similar projects. In September 2024, Microsoft signed a 20-year agreement to restart a Three Mile Island reactor for 835 megawatts, while in May of this year, Amazon Web Services purchased a data center next to Pennsylvania's Susquehanna nuclear plant with plans to use up to 960 megawatts.&lt;/p&gt;
&lt;p&gt;Other massive AI infrastructure projects are emerging across the US. In July, officials in Cheyenne, Wyoming, announced plans for an AI data center that would eventually scale to 10 gigawatts—consuming more electricity than all homes in the state combined, even in its earliest 1.8 gigawatt phase. Whether it's connected to OpenAI's plans remains unclear.&lt;/p&gt;
&lt;p&gt;Altman's ambition for mega-sized datacenter deals now stretches back over a year. In September of last year, Constellation Energy CEO Joe Dominguez told Bloomberg he had heard Altman wanted five to seven data centers of 5 gigawatts each. Alex de Vries of Digiconomist told Fortune that seven 5-gigawatt units would have "twice the power consumption of New York State combined."&lt;/p&gt;
&lt;p&gt;The planned infrastructure buildout would significantly increase global energy consumption, which also raises environmental concerns. The International Energy Agency estimates that global data centers already consumed roughly 1.5 percent of global electricity in 2024. OpenAI's project also faces practical constraints. Existing power grid connections represent bottlenecks in power-constrained markets, with utilities struggling to keep pace with rapid AI expansion that could push global data center electricity demand to 945 terawatt hours by 2030, according to the International Energy Agency.&lt;/p&gt;
&lt;p&gt;The companies said they expect to finalize details in the coming weeks. Huang told CNBC the $100 billion investment comes on top of all Nvidia's existing commitments and was not included in the company's recent financial forecasts to investors.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "This is a giant project," Nvidia CEO said of new 10-gigawatt AI infrastructure deal.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-640x427.jpg" width="640" /&gt;
                  &lt;img alt="An orange, cloudy sky backlights a set of electrical wires on large pylons, leading away from the cooling towers of a nuclear power plant." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1540176964-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anton Petrus via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, OpenAI and Nvidia jointly announced a letter of intent for a strategic partnership to deploy at least 10 gigawatts of Nvidia systems for OpenAI's AI infrastructure, with Nvidia planning to invest up to $100 billion as the systems roll out. The companies said the first gigawatt of Nvidia systems will come online in the second half of 2026 using Nvidia's Vera Rubin platform.&lt;/p&gt;
&lt;p&gt;"Everything starts with compute," said Sam Altman, CEO of OpenAI, in the announcement. "Compute infrastructure will be the basis for the economy of the future, and we will utilize what we're building with NVIDIA to both create new AI breakthroughs and empower people and businesses with them at scale."&lt;/p&gt;
&lt;p&gt;The 10-gigawatt project represents an astoundingly ambitious and as-yet-unproven scale for AI infrastructure. Nvidia CEO Jensen Huang told CNBC that the planned 10 gigawatts equals the power consumption of between 4 million and 5 million graphics processing units, which matches the company's total GPU shipments for this year and doubles last year's volume. "This is a giant project," Huang said in an interview alongside Altman and OpenAI President Greg Brockman.&lt;/p&gt;
&lt;p&gt;To put that power demand in perspective, 10 gigawatts equals the output of roughly 10 nuclear reactors, which typically output about 1 gigawatt per facility. Current data center energy consumption ranges from 10 megawatts to 1 gigawatt, with most large facilities consuming between 50 and 100 megawatts. OpenAI's planned infrastructure would dwarf existing installations, requiring as much electricity as multiple major cities.&lt;/p&gt;
&lt;p&gt;The partnership follows OpenAI's rapid user growth to 700 million weekly active users. Nvidia's stock rose nearly 4 percent on Monday following the announcement, adding roughly $170 billion to its market capitalization. The partnership establishes Nvidia as OpenAI's preferred strategic compute and networking partner, alongside OpenAI's existing relationships with Microsoft, Oracle, SoftBank, and the recently announced Stargate project partners.&lt;/p&gt;
&lt;p&gt;The partnership announcement comes a week after Nvidia disclosed a $5 billion investment in Intel, taking a 4 percent stake in its longtime competitor as the two companies plan to co-develop custom data center and PC products.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bryn Talkington, managing partner at Requisite Capital Management, noted the circular nature of the investment structure to CNBC. "Nvidia invests $100 billion in OpenAI, which then OpenAI turns back and gives it back to Nvidia," Talkington told CNBC. "I feel like this is going to be very virtuous for Jensen."&lt;/p&gt;
&lt;h2&gt;Racing for nuclear power&lt;/h2&gt;
&lt;p&gt;In an August earnings call, Huang told investors that building one gigawatt of data center capacity costs between $50 billion and $60 billion, with about $35 billion going toward Nvidia chips and systems. At that rate, the 10 gigawatt project could require total investment exceeding $500 billion.&lt;/p&gt;
&lt;p&gt;While the companies did not specify power sources in their announcement, the massive energy requirements have driven other tech giants to nuclear partnerships for similar projects. In September 2024, Microsoft signed a 20-year agreement to restart a Three Mile Island reactor for 835 megawatts, while in May of this year, Amazon Web Services purchased a data center next to Pennsylvania's Susquehanna nuclear plant with plans to use up to 960 megawatts.&lt;/p&gt;
&lt;p&gt;Other massive AI infrastructure projects are emerging across the US. In July, officials in Cheyenne, Wyoming, announced plans for an AI data center that would eventually scale to 10 gigawatts—consuming more electricity than all homes in the state combined, even in its earliest 1.8 gigawatt phase. Whether it's connected to OpenAI's plans remains unclear.&lt;/p&gt;
&lt;p&gt;Altman's ambition for mega-sized datacenter deals now stretches back over a year. In September of last year, Constellation Energy CEO Joe Dominguez told Bloomberg he had heard Altman wanted five to seven data centers of 5 gigawatts each. Alex de Vries of Digiconomist told Fortune that seven 5-gigawatt units would have "twice the power consumption of New York State combined."&lt;/p&gt;
&lt;p&gt;The planned infrastructure buildout would significantly increase global energy consumption, which also raises environmental concerns. The International Energy Agency estimates that global data centers already consumed roughly 1.5 percent of global electricity in 2024. OpenAI's project also faces practical constraints. Existing power grid connections represent bottlenecks in power-constrained markets, with utilities struggling to keep pace with rapid AI expansion that could push global data center electricity demand to 945 terawatt hours by 2030, according to the International Energy Agency.&lt;/p&gt;
&lt;p&gt;The companies said they expect to finalize details in the coming weeks. Huang told CNBC the $100 billion investment comes on top of all Nvidia's existing commitments and was not included in the company's recent financial forecasts to investors.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/openai-and-nvidias-100b-ai-plan-will-require-power-equal-to-10-nuclear-reactors/</guid><pubDate>Mon, 22 Sep 2025 19:17:28 +0000</pubDate></item><item><title>[NEW] The Oakland Ballers let an AI manage the team. What could go wrong? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/the-oakland-ballers-let-an-ai-manage-the-team-what-could-go-wrong/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/Oakland-Ballers.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a classic Simpsons episode in which the sly businessman Mr. Burns recruits real Major League Baseball players to join his company softball team in order to win a bet. But when the championship is on the line, Mr. Burns pulls eight-time National League all-star Darryl Strawberry for a substitute, Homer Simpson.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You’re a left-hander, and so is the pitcher. If I send up a right-handed batter, it’s called playing the percentages,” Mr. Burns says to Strawberry. “It’s what smart managers do to win ballgames.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;High-level baseball is very mathematically-driven, with teams hiring dozens of data engineers to study granular statistics that can inform managerial decisions. But like Mr. Burns in that Simpsons episode, it’s tempting to overanalyze baseball statistics to the point of absurdity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Oakland Ballers, an independent Pioneer League baseball team, took that concept of “playing the percentages” to the next level: they let an AI manage the team for a game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Ballers were founded by edtech entrepreneur Paul Freedman as a salve to the departure of the beloved Oakland A’s, the Major League baseball team that owner John Fisher ripped away from local fans in what’s regarded as one of the most insidious managerial moves in sports history. Though they’re not a Major League team, the Oakland Ballers – coyly, the Oakland B’s – established an unprecedented national community of fans who rallied around the team in protest of the A’s departure. After just two seasons, the Ballers just won Oakland’s first baseball title since 1989.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The Oakland Ballers uniquely have the experience of being like a major league team in a minor league market,” Freedman told TechCrunch. “We can have creative flexibility. We can play with things and experiment with things way before the MLB or NBA or any of those leagues could do something.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Minor league baseball organizations are often called upon to test new technology before it gets implemented in the majors, like challenging calls with instant replay footage or the automated ball-strike system. The Ballers embraced this attitude, especially given Freedman’s own background in tech, but have added in a dash of whimsy, piloting things that would never actually debut in Major League Baseball.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, this meant partnering with Fan Controlled Sports to let fans make managerial decisions during one late season game. The Ballers ended up losing that game, in part because fans advocated for the funniest possible managerial decisions, rather than the savviest – at one point, the fans called upon a pitcher to pinch hit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This time around, once the team clinched their postseason berth, the Ballers partnered with the AI company Distillery to commission AI software that could manage a baseball game in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Baseball is the perfect place to do an initial experiment like this, because it is so data-driven, and decisions are made very analytically,” Freedman told TechCrunch. “You have the pace to be able to do something literally after every pitch.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Distillery trained OpenAI’s ChatGPT on over a century’s worth of baseball data and analytics, including Ballers games, to approximate what decisions Ballers manager Aaron Miles would make.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What the AI did was figure out what our human coach would have done – the ingenuity on strategy and the concepts came from [Miles], and the ability to use the data and recognize patterns… is what the AI did throughout the course of the game,” Freedman said. “So I think the role of human ingenuity is safe for now, and AI is a tool to be deployed to optimize decisions, but not to make them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI-controlled game went smoothly – in fact, the AI made all of the same choices regarding pitching changes, lineup construction, and pinch hitters that Miles would have made. The only time that Miles had to override the AI was to replace the starting catcher with his backup, since he was sick.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Miles took his temporary replacement by AI in stride – perhaps because he knows that his job is not actually in jeopardy. In a video posted to the Ballers’ Instagram, Miles walks to home plate before the game to shake hands with the opposing team’s manager – only instead of offering his own hand, he extends the tablet running the AI out for a handshake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the use of AI struck a nerve for Oakland fans, who see companies like OpenAI – which powered Distillery’s baseball AI – as enterprises that prioritize “winning” the AI race over shipping products that have been properly tested for safety. For many fans, the AI experiment felt like a betrayal, similar to the kind of corporate greed that pushed three professional sports franchises out of Oakland in five years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There goes the Ballers trying to appeal to Bay Area techies instead of baseball fans,” one commenter wrote. “It’s so over for Oakland.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This backlash wasn’t what the Ballers expected, and Freedman does not intend to repeat this AI experiment. But the reaction of the fans models a larger cultural tension in baseball and beyond. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It never feels good to have your fans be like, ‘We hate this,’” Freedman said. “But it’s not a bad thing that there’s more of a conversation about the pluses and minuses of this new technology now, as opposed to like, a decade later when it’s too late.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/Oakland-Ballers.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a classic Simpsons episode in which the sly businessman Mr. Burns recruits real Major League Baseball players to join his company softball team in order to win a bet. But when the championship is on the line, Mr. Burns pulls eight-time National League all-star Darryl Strawberry for a substitute, Homer Simpson.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You’re a left-hander, and so is the pitcher. If I send up a right-handed batter, it’s called playing the percentages,” Mr. Burns says to Strawberry. “It’s what smart managers do to win ballgames.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;High-level baseball is very mathematically-driven, with teams hiring dozens of data engineers to study granular statistics that can inform managerial decisions. But like Mr. Burns in that Simpsons episode, it’s tempting to overanalyze baseball statistics to the point of absurdity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Oakland Ballers, an independent Pioneer League baseball team, took that concept of “playing the percentages” to the next level: they let an AI manage the team for a game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Ballers were founded by edtech entrepreneur Paul Freedman as a salve to the departure of the beloved Oakland A’s, the Major League baseball team that owner John Fisher ripped away from local fans in what’s regarded as one of the most insidious managerial moves in sports history. Though they’re not a Major League team, the Oakland Ballers – coyly, the Oakland B’s – established an unprecedented national community of fans who rallied around the team in protest of the A’s departure. After just two seasons, the Ballers just won Oakland’s first baseball title since 1989.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The Oakland Ballers uniquely have the experience of being like a major league team in a minor league market,” Freedman told TechCrunch. “We can have creative flexibility. We can play with things and experiment with things way before the MLB or NBA or any of those leagues could do something.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Minor league baseball organizations are often called upon to test new technology before it gets implemented in the majors, like challenging calls with instant replay footage or the automated ball-strike system. The Ballers embraced this attitude, especially given Freedman’s own background in tech, but have added in a dash of whimsy, piloting things that would never actually debut in Major League Baseball.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, this meant partnering with Fan Controlled Sports to let fans make managerial decisions during one late season game. The Ballers ended up losing that game, in part because fans advocated for the funniest possible managerial decisions, rather than the savviest – at one point, the fans called upon a pitcher to pinch hit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This time around, once the team clinched their postseason berth, the Ballers partnered with the AI company Distillery to commission AI software that could manage a baseball game in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Baseball is the perfect place to do an initial experiment like this, because it is so data-driven, and decisions are made very analytically,” Freedman told TechCrunch. “You have the pace to be able to do something literally after every pitch.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Distillery trained OpenAI’s ChatGPT on over a century’s worth of baseball data and analytics, including Ballers games, to approximate what decisions Ballers manager Aaron Miles would make.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What the AI did was figure out what our human coach would have done – the ingenuity on strategy and the concepts came from [Miles], and the ability to use the data and recognize patterns… is what the AI did throughout the course of the game,” Freedman said. “So I think the role of human ingenuity is safe for now, and AI is a tool to be deployed to optimize decisions, but not to make them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI-controlled game went smoothly – in fact, the AI made all of the same choices regarding pitching changes, lineup construction, and pinch hitters that Miles would have made. The only time that Miles had to override the AI was to replace the starting catcher with his backup, since he was sick.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Miles took his temporary replacement by AI in stride – perhaps because he knows that his job is not actually in jeopardy. In a video posted to the Ballers’ Instagram, Miles walks to home plate before the game to shake hands with the opposing team’s manager – only instead of offering his own hand, he extends the tablet running the AI out for a handshake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the use of AI struck a nerve for Oakland fans, who see companies like OpenAI – which powered Distillery’s baseball AI – as enterprises that prioritize “winning” the AI race over shipping products that have been properly tested for safety. For many fans, the AI experiment felt like a betrayal, similar to the kind of corporate greed that pushed three professional sports franchises out of Oakland in five years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There goes the Ballers trying to appeal to Bay Area techies instead of baseball fans,” one commenter wrote. “It’s so over for Oakland.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This backlash wasn’t what the Ballers expected, and Freedman does not intend to repeat this AI experiment. But the reaction of the fans models a larger cultural tension in baseball and beyond. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It never feels good to have your fans be like, ‘We hate this,’” Freedman said. “But it’s not a bad thing that there’s more of a conversation about the pluses and minuses of this new technology now, as opposed to like, a decade later when it’s too late.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/the-oakland-ballers-let-an-ai-manage-the-team-what-could-go-wrong/</guid><pubDate>Mon, 22 Sep 2025 20:15:32 +0000</pubDate></item><item><title>[NEW] Facebook is getting an AI dating assistant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/facebook-is-getting-an-ai-dating-assistant/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/06/robots-love.jpg?resize=1200,704" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Monday that it’s bringing an AI assistant to Facebook Dating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This chatbot is intended to help users find matches who are more closely tailored to what they are looking for. For example, Meta might suggest users ask it to find “a Brooklyn girl in tech” or a user could ask the AI to help refine their profile.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta also says that it’s “helping people avoid swipe fatigue” with a new feature called Meet Cute, which gives users a weekly “surprise match” chosen based on its algorithm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says Facebook Dating matches among adults ages 18 to 29 have increased 10% year-over-year growth, with hundreds of thousands of users in that age group creating Facebook Dating profiles each month. That’s small compared to competitors like Tinder, which has about 50 million daily active users, and Hinge’s 10 million daily active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI features have already become the norm in mainstream dating apps. Even newer dating apps like Sitch have attempted to differentiate themselves with their AI features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Match Group — the owner of Tinder, Hinge, OKCupid, and others — entered a partnership with OpenAI last year, which is part of the dating giant’s $20 million-plus investment in AI. That’s a big bet, especially given the financial struggles of Match Group, which has lost about 68% of its stock price in the last five years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, this investment has produced features like an AI photo selector tool to Tinder, which scans your cameral roll to help choose profile images, as well as AI-powered matching. Hinge has a feature that lets users improve their responses to profile prompts with AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble has added similar AI features, and founder Whitney Wolfe Herd even ruffled some feathers last year when she suggested that one day, users could have personal “AI concierges” that go on dates with other people’s AI to determine compatibility.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/06/robots-love.jpg?resize=1200,704" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Monday that it’s bringing an AI assistant to Facebook Dating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This chatbot is intended to help users find matches who are more closely tailored to what they are looking for. For example, Meta might suggest users ask it to find “a Brooklyn girl in tech” or a user could ask the AI to help refine their profile.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta also says that it’s “helping people avoid swipe fatigue” with a new feature called Meet Cute, which gives users a weekly “surprise match” chosen based on its algorithm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says Facebook Dating matches among adults ages 18 to 29 have increased 10% year-over-year growth, with hundreds of thousands of users in that age group creating Facebook Dating profiles each month. That’s small compared to competitors like Tinder, which has about 50 million daily active users, and Hinge’s 10 million daily active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI features have already become the norm in mainstream dating apps. Even newer dating apps like Sitch have attempted to differentiate themselves with their AI features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Match Group — the owner of Tinder, Hinge, OKCupid, and others — entered a partnership with OpenAI last year, which is part of the dating giant’s $20 million-plus investment in AI. That’s a big bet, especially given the financial struggles of Match Group, which has lost about 68% of its stock price in the last five years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, this investment has produced features like an AI photo selector tool to Tinder, which scans your cameral roll to help choose profile images, as well as AI-powered matching. Hinge has a feature that lets users improve their responses to profile prompts with AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble has added similar AI features, and founder Whitney Wolfe Herd even ruffled some feathers last year when she suggested that one day, users could have personal “AI concierges” that go on dates with other people’s AI to determine compatibility.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/facebook-is-getting-an-ai-dating-assistant/</guid><pubDate>Mon, 22 Sep 2025 20:27:06 +0000</pubDate></item></channel></rss>