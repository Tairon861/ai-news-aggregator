<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 03 Jul 2025 01:50:41 +0000</lastBuildDate><item><title>[NEW] Confidence in agentic AI: Why eval infrastructure must come first (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/confidence-in-agentic-ai-why-eval-infrastructure-must-come-first/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0666-X3.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;As AI agents enter real-world deployment, organizations are under pressure to define where they belong, how to build them effectively, and how to operationalize them at scale. At VentureBeat’s Transform 2025, tech leaders gathered to talk about how they’re transforming their business with agents: Joanne Chen, general partner at Foundation Capital; Shailesh Nalawadi, VP of project management with Sendbird; Thys Waanders, SVP of AI transformation at Cognigy; and Shawn Malhotra, CTO, Rocket Companies.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-few-top-agentic-ai-use-cases"&gt;&lt;strong&gt;A few top agentic AI use cases&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“The initial attraction of any of these deployments for AI agents tends to be around saving human capital — the math is pretty straightforward,” Nalawadi said. “However, that undersells the transformational capability you get with AI agents.”&lt;/p&gt;



&lt;p&gt;At Rocket, AI agents have proven to be powerful tools in increasing website conversion.&lt;/p&gt;



&lt;p&gt;“We’ve found that with our agent-based experience, the conversational experience on the website, clients are three times more likely to convert when they come through that channel,” Malhotra said.&lt;/p&gt;



&lt;p&gt;But that’s just scratching the surface. For instance, a Rocket engineer built an agent in just two days to automate a highly specialized task: calculating transfer taxes during mortgage underwriting.&lt;/p&gt;



&lt;p&gt;“That two days of effort saved us a million dollars a year in expense,” Malhotra said. “In 2024, we saved more than a million team member hours, mostly off the back of our AI solutions. That’s not just saving expense. It’s also allowing our team members to focus their time on people making what is often the largest financial transaction of their life.”&lt;/p&gt;



&lt;p&gt;Agents are essentially supercharging individual team members. That million hours saved isn’t the entirety of someone’s job replicated many times. It’s fractions of the job that are things employees don’t enjoy doing, or weren’t adding value to the client. And that million hours saved gives Rocket the capacity to handle more business.&lt;/p&gt;



&lt;p&gt;“Some of our team members were able to handle 50% more clients last year than they were the year before,” Malhotra added. “It means we can have higher throughput, drive more business, and again, we see higher conversion rates because they’re spending the time understanding the client’s needs versus doing a lot of more rote work that the AI can do now.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-tackling-agent-complexity"&gt;&lt;strong&gt;Tackling agent complexity&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“Part of the journey for our engineering teams is moving from the mindset of software engineering – write once and test it and it runs and gives the same answer 1,000 times – to the more probabilistic approach, where you ask the same thing of an LLM and it gives different answers through some probability,” Nalawadi said. “A lot of it has been bringing people along. Not just software engineers, but product managers and UX designers.”&lt;/p&gt;



&lt;p&gt;What’s helped is that LLMs have come a long way, Waanders said. If they built something 18 months or two years ago, they really had to pick the right model, or the agent would not perform as expected. Now, he says, we’re now at a stage where most of the mainstream models behave very well. They’re more predictable. But today the challenge is combining models, ensuring responsiveness, orchestrating the right models in the right sequence and weaving in the right data.&lt;/p&gt;



&lt;p&gt;“We have customers that push tens of millions of conversations per year,” Waanders said. “If you automate, say, 30 million conversations in a year, how does that scale in the LLM world? That’s all stuff that we had to discover, simple stuff, from even getting the model availability with the cloud providers. Having enough quota with a ChatGPT model, for example. Those are all learnings that we had to go through, and our customers as well. It’s a brand-new world.”&lt;/p&gt;



&lt;p&gt;A layer above orchestrating the LLM is orchestrating a network of agents, Malhotra said. A conversational experience has a network of agents under the hood, and the orchestrator is deciding which agent to farm the request out to from those available.&lt;/p&gt;



&lt;p&gt;“If you play that forward and think about having hundreds or thousands of agents who are capable of different things, you get some really interesting technical problems,” he said. “It’s becoming a bigger problem, because latency and time matter. That agent routing is going to be a very interesting problem to solve over the coming years.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-tapping-into-vendor-relationships"&gt;&lt;strong&gt;Tapping into vendor relationships&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Up to this point, the first step for most companies launching agentic AI has been building in-house, because specialized tools didn’t yet exist. But you can’t differentiate and create value by building generic LLM infrastructure or AI infrastructure, and you need specialized expertise to go beyond the initial build, and debug, iterate, and improve on what’s been built, as well as maintain the infrastructure.&lt;/p&gt;



&lt;p&gt;“Often we find the most successful conversations we have with prospective customers tend to be someone who’s already built something in-house,” Nalawadi said. “They quickly realize that getting to a 1.0 is okay, but as the world evolves and as the infrastructure evolves and as they need to swap out technology for something new, they don’t have the ability to orchestrate all these things.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-preparing-for-agentic-ai-complexity"&gt;&lt;strong&gt;Preparing for agentic AI complexity&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Theoretically, agentic AI will only grow in complexity — the number of agents in an organization will rise, and they’ll start learning from each other, and the number of use cases will explode. How can organizations prepare for the challenge?&lt;/p&gt;



&lt;p&gt;“It means that the checks and balances in your system will get stressed more,” Malhotra said. “For something that has a regulatory process, you have a human in the loop to make sure that someone is signing off on this. For critical internal processes or data access, do you have observability? Do you have the right alerting and monitoring so that if something goes wrong, you know it’s going wrong? It’s doubling down on your detection, understanding where you need a human in the loop, and then trusting that those processes are going to catch if something does go wrong. But because of the power it unlocks, you have to do it.”&lt;/p&gt;



&lt;p&gt;So how can you have confidence that an AI agent will behave reliably as it evolves?&lt;/p&gt;



&lt;p&gt;“That part is really difficult if you haven’t thought about it at the beginning,” Nalawadi said. “The short answer is, before you even start building it, you should have an eval infrastructure in place. Make sure you have a rigorous environment in which you know what good looks like, from an AI agent, and that you have this test set. Keep referring back to it as you make improvements. A very simplistic way of thinking about eval is that it’s the unit tests for your agentic system.”&lt;/p&gt;



&lt;p&gt;The problem is, it’s non-deterministic, Waanders added. Unit testing is critical, but the biggest challenge is you don’t know what you don’t know — what incorrect behaviors an agent could possibly display, how it might react in any given situation.&lt;/p&gt;



&lt;p&gt;“You can only find that out by simulating conversations at scale, by pushing it under thousands of different scenarios, and then analyzing how it holds up and how it reacts,” Waanders said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0666-X3.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;As AI agents enter real-world deployment, organizations are under pressure to define where they belong, how to build them effectively, and how to operationalize them at scale. At VentureBeat’s Transform 2025, tech leaders gathered to talk about how they’re transforming their business with agents: Joanne Chen, general partner at Foundation Capital; Shailesh Nalawadi, VP of project management with Sendbird; Thys Waanders, SVP of AI transformation at Cognigy; and Shawn Malhotra, CTO, Rocket Companies.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-few-top-agentic-ai-use-cases"&gt;&lt;strong&gt;A few top agentic AI use cases&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“The initial attraction of any of these deployments for AI agents tends to be around saving human capital — the math is pretty straightforward,” Nalawadi said. “However, that undersells the transformational capability you get with AI agents.”&lt;/p&gt;



&lt;p&gt;At Rocket, AI agents have proven to be powerful tools in increasing website conversion.&lt;/p&gt;



&lt;p&gt;“We’ve found that with our agent-based experience, the conversational experience on the website, clients are three times more likely to convert when they come through that channel,” Malhotra said.&lt;/p&gt;



&lt;p&gt;But that’s just scratching the surface. For instance, a Rocket engineer built an agent in just two days to automate a highly specialized task: calculating transfer taxes during mortgage underwriting.&lt;/p&gt;



&lt;p&gt;“That two days of effort saved us a million dollars a year in expense,” Malhotra said. “In 2024, we saved more than a million team member hours, mostly off the back of our AI solutions. That’s not just saving expense. It’s also allowing our team members to focus their time on people making what is often the largest financial transaction of their life.”&lt;/p&gt;



&lt;p&gt;Agents are essentially supercharging individual team members. That million hours saved isn’t the entirety of someone’s job replicated many times. It’s fractions of the job that are things employees don’t enjoy doing, or weren’t adding value to the client. And that million hours saved gives Rocket the capacity to handle more business.&lt;/p&gt;



&lt;p&gt;“Some of our team members were able to handle 50% more clients last year than they were the year before,” Malhotra added. “It means we can have higher throughput, drive more business, and again, we see higher conversion rates because they’re spending the time understanding the client’s needs versus doing a lot of more rote work that the AI can do now.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-tackling-agent-complexity"&gt;&lt;strong&gt;Tackling agent complexity&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“Part of the journey for our engineering teams is moving from the mindset of software engineering – write once and test it and it runs and gives the same answer 1,000 times – to the more probabilistic approach, where you ask the same thing of an LLM and it gives different answers through some probability,” Nalawadi said. “A lot of it has been bringing people along. Not just software engineers, but product managers and UX designers.”&lt;/p&gt;



&lt;p&gt;What’s helped is that LLMs have come a long way, Waanders said. If they built something 18 months or two years ago, they really had to pick the right model, or the agent would not perform as expected. Now, he says, we’re now at a stage where most of the mainstream models behave very well. They’re more predictable. But today the challenge is combining models, ensuring responsiveness, orchestrating the right models in the right sequence and weaving in the right data.&lt;/p&gt;



&lt;p&gt;“We have customers that push tens of millions of conversations per year,” Waanders said. “If you automate, say, 30 million conversations in a year, how does that scale in the LLM world? That’s all stuff that we had to discover, simple stuff, from even getting the model availability with the cloud providers. Having enough quota with a ChatGPT model, for example. Those are all learnings that we had to go through, and our customers as well. It’s a brand-new world.”&lt;/p&gt;



&lt;p&gt;A layer above orchestrating the LLM is orchestrating a network of agents, Malhotra said. A conversational experience has a network of agents under the hood, and the orchestrator is deciding which agent to farm the request out to from those available.&lt;/p&gt;



&lt;p&gt;“If you play that forward and think about having hundreds or thousands of agents who are capable of different things, you get some really interesting technical problems,” he said. “It’s becoming a bigger problem, because latency and time matter. That agent routing is going to be a very interesting problem to solve over the coming years.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-tapping-into-vendor-relationships"&gt;&lt;strong&gt;Tapping into vendor relationships&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Up to this point, the first step for most companies launching agentic AI has been building in-house, because specialized tools didn’t yet exist. But you can’t differentiate and create value by building generic LLM infrastructure or AI infrastructure, and you need specialized expertise to go beyond the initial build, and debug, iterate, and improve on what’s been built, as well as maintain the infrastructure.&lt;/p&gt;



&lt;p&gt;“Often we find the most successful conversations we have with prospective customers tend to be someone who’s already built something in-house,” Nalawadi said. “They quickly realize that getting to a 1.0 is okay, but as the world evolves and as the infrastructure evolves and as they need to swap out technology for something new, they don’t have the ability to orchestrate all these things.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-preparing-for-agentic-ai-complexity"&gt;&lt;strong&gt;Preparing for agentic AI complexity&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Theoretically, agentic AI will only grow in complexity — the number of agents in an organization will rise, and they’ll start learning from each other, and the number of use cases will explode. How can organizations prepare for the challenge?&lt;/p&gt;



&lt;p&gt;“It means that the checks and balances in your system will get stressed more,” Malhotra said. “For something that has a regulatory process, you have a human in the loop to make sure that someone is signing off on this. For critical internal processes or data access, do you have observability? Do you have the right alerting and monitoring so that if something goes wrong, you know it’s going wrong? It’s doubling down on your detection, understanding where you need a human in the loop, and then trusting that those processes are going to catch if something does go wrong. But because of the power it unlocks, you have to do it.”&lt;/p&gt;



&lt;p&gt;So how can you have confidence that an AI agent will behave reliably as it evolves?&lt;/p&gt;



&lt;p&gt;“That part is really difficult if you haven’t thought about it at the beginning,” Nalawadi said. “The short answer is, before you even start building it, you should have an eval infrastructure in place. Make sure you have a rigorous environment in which you know what good looks like, from an AI agent, and that you have this test set. Keep referring back to it as you make improvements. A very simplistic way of thinking about eval is that it’s the unit tests for your agentic system.”&lt;/p&gt;



&lt;p&gt;The problem is, it’s non-deterministic, Waanders added. Unit testing is critical, but the biggest challenge is you don’t know what you don’t know — what incorrect behaviors an agent could possibly display, how it might react in any given situation.&lt;/p&gt;



&lt;p&gt;“You can only find that out by simulating conversations at scale, by pushing it under thousands of different scenarios, and then analyzing how it holds up and how it reacts,” Waanders said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/confidence-in-agentic-ai-why-eval-infrastructure-must-come-first/</guid><pubDate>Wed, 02 Jul 2025 15:41:49 +0000</pubDate></item><item><title>US chipmakers could see bigger tax credits if Trump’s spending bill passes (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/us-chipmakers-could-see-bigger-tax-credits-if-trumps-spending-bill-passes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1246479507.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The semiconductor industry could see a big tax benefit if the Trump administration is able to pass the current version of its spending bill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest draft of the Trump administration’s “Big, Beautiful Bill,” which already passed in the Senate, will raise the tax credit for chipmakers building manufacturing plants in the U.S. from 25% to 35%, as originally reported by CNBC.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Companies including Intel, TSMC, and Micron Technology could reap these benefits if they continue to expand their U.S. manufacturing efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This proposed tax credit could give the semiconductor industry a needed boost after recent chip export licensing requirements, regarding selling advanced AI chips to China, have resulted in material revenue hits to multiple domestic chipmakers.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1246479507.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The semiconductor industry could see a big tax benefit if the Trump administration is able to pass the current version of its spending bill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest draft of the Trump administration’s “Big, Beautiful Bill,” which already passed in the Senate, will raise the tax credit for chipmakers building manufacturing plants in the U.S. from 25% to 35%, as originally reported by CNBC.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Companies including Intel, TSMC, and Micron Technology could reap these benefits if they continue to expand their U.S. manufacturing efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This proposed tax credit could give the semiconductor industry a needed boost after recent chip export licensing requirements, regarding selling advanced AI chips to China, have resulted in material revenue hits to multiple domestic chipmakers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/us-chipmakers-could-see-bigger-tax-credits-if-trumps-spending-bill-passes/</guid><pubDate>Wed, 02 Jul 2025 15:57:47 +0000</pubDate></item><item><title>Study finds AI can slash global carbon emissions (AI News)</title><link>https://www.artificialintelligence-news.com/news/study-finds-ai-slash-global-carbon-emissions/</link><description>&lt;p&gt;A study from the London School of Economics and Systemiq suggests it’s possible to cut global carbon emissions without giving up modern comforts—with AI as our ally in the climate fight.&lt;/p&gt;&lt;p&gt;According to the duo’s research, smart AI applications in just three industries could slash greenhouse gas emissions by 3.2-5.4 billion tonnes each year by 2035.&lt;/p&gt;&lt;p&gt;In contrast to much of what we’ve heard, these reductions would far outweigh the carbon that AI itself produces.&lt;/p&gt;&lt;p&gt;The study, ‘Green and intelligent: the role of AI in the climate transition,’ doesn’t just see AI as a tool for small improvements. Instead, it could help transform our entire economy into something sustainable and inclusive.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-net-zero-as-an-opportunity-not-a-burden"&gt;Net-zero as an opportunity, not a burden&lt;/h3&gt;&lt;p&gt;The researchers suggest we should see the shift to a net-zero economy not as a burden but as “a great opportunity for innovation and sustainable, resilient, and inclusive economic growth.”&lt;/p&gt;&lt;p&gt;They focused on three of the major carbon culprits – power generation, meat and dairy production, and passenger vehicles – which together cause almost half of global emissions. The potential AI savings from just these sectors would more than cancel out the estimated 0.4 to 1.6 billion tonnes of annual emissions from running all those AI data centers.&lt;/p&gt;&lt;p&gt;As the authors put it, “the case for using AI for the climate transition is not only strong but imperative.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-five-big-ways-ai-can-help-save-our-planet-and-us"&gt;Five big ways AI can help save our planet (and us)&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Making complex systems smarter&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Think about how our modern lives depend on intricate networks for energy, transport, and city living. AI can redesign these systems to work much more efficiently.&lt;/p&gt;&lt;p&gt;Remember those frustrating power outages when the wind stops blowing or clouds cover the sun? AI can help predict these fluctuations in renewable energy and balance them with real-time demand. DeepMind has already shown its AI can boost wind energy’s economic value by 20% by reducing the need for backup power sources.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Speeding up discovery and reducing waste&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Almost half the emissions cuts needed to reach net-zero by 2050 will rely on technologies that are barely out of the lab today and AI is turbocharging these breakthroughs.&lt;/p&gt;&lt;p&gt;Take Google DeepMind’s GNOME tool, which has already identified over two million new crystal structures that could revolutionise renewable energy and battery storage. Or consider how Amazon’s AI packaging algorithms have saved over three million metric tons of material since 2015.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Helping us make better choices&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Our daily decisions – from what we eat, to how we travel – could drive up to 70% of emissions reductions by 2050. But making the right choice isn’t always easy.&lt;/p&gt;&lt;p&gt;AI can be our personal environmental coach, breaking down information barriers and offering tailored recommendations. Already using Google Maps’ fuel-efficient routes? That’s AI helping you cut emissions while saving gas money. And those smart home systems like Nest use AI to optimise your heating and cooling, which could save millions of tonnes of CO2 if we all adopted them.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. Predicting climate changes and policy effects&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;How do we plan for a changing climate? AI can process enormous datasets to forecast climate patterns with unprecedented accuracy.&lt;/p&gt;&lt;p&gt;Tools like IceNet (developed by the British Antarctic Survey and the Alan Turing Institute) are using AI to predict sea ice levels better than ever before, helping communities and businesses prepare. This capability also extends to helping governments design climate policies that actually work, by learning from countless case studies around the world.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. Keeping us safe in extreme weather&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As climate disasters intensify, early warning can save lives. AI-powered systems for floods and wildfires are becoming essential safety nets.&lt;/p&gt;&lt;p&gt;Google’s Flood Hub uses machine learning to provide flood forecasts up to five days in advance across more than 80 countries. That’s precious time for people to protect their homes and evacuate if necessary.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-numbers-support-ai-cutting-global-carbon-emissions"&gt;The numbers support AI cutting global carbon emissions&lt;/h3&gt;&lt;p&gt;When researchers crunched the numbers, they found AI could:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Cut power sector emissions by 1.8 billion tonnes yearly by 2035 just by optimising renewable energy&lt;/li&gt;&lt;li&gt;Save between 0.9 and 3.0 billion tonnes annually by improving plant-based proteins to taste and feel more like meat&lt;/li&gt;&lt;li&gt;Reduce vehicle emissions by up to 0.6 billion tonnes each year through shared mobility and better battery technology&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Here’s the catch: we can’t just sit back and let market forces determine how AI develops. The researchers call for an “active state” to ensure that AI benefits everyone and the planet.&lt;/p&gt;&lt;p&gt;“Governments have a critical role in ensuring that AI is deployed effectively to accelerate the transition equitably and sustainably,” they conclude.&lt;/p&gt;&lt;p&gt;What this means in practice is creating incentives for green AI research, regulating to minimise environmental impact, and investing in infrastructure so communities worldwide can share in the benefits.&lt;/p&gt;&lt;p&gt;By guiding innovation and working together internationally, we can unlock AI’s full potential to reduce global carbon emissions and tackle the climate crisis—and build a future where both people and the planet can thrive.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Abhishek Mishra)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Power play: Can the grid cope with AI’s growing appetite?&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A study from the London School of Economics and Systemiq suggests it’s possible to cut global carbon emissions without giving up modern comforts—with AI as our ally in the climate fight.&lt;/p&gt;&lt;p&gt;According to the duo’s research, smart AI applications in just three industries could slash greenhouse gas emissions by 3.2-5.4 billion tonnes each year by 2035.&lt;/p&gt;&lt;p&gt;In contrast to much of what we’ve heard, these reductions would far outweigh the carbon that AI itself produces.&lt;/p&gt;&lt;p&gt;The study, ‘Green and intelligent: the role of AI in the climate transition,’ doesn’t just see AI as a tool for small improvements. Instead, it could help transform our entire economy into something sustainable and inclusive.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-net-zero-as-an-opportunity-not-a-burden"&gt;Net-zero as an opportunity, not a burden&lt;/h3&gt;&lt;p&gt;The researchers suggest we should see the shift to a net-zero economy not as a burden but as “a great opportunity for innovation and sustainable, resilient, and inclusive economic growth.”&lt;/p&gt;&lt;p&gt;They focused on three of the major carbon culprits – power generation, meat and dairy production, and passenger vehicles – which together cause almost half of global emissions. The potential AI savings from just these sectors would more than cancel out the estimated 0.4 to 1.6 billion tonnes of annual emissions from running all those AI data centers.&lt;/p&gt;&lt;p&gt;As the authors put it, “the case for using AI for the climate transition is not only strong but imperative.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-five-big-ways-ai-can-help-save-our-planet-and-us"&gt;Five big ways AI can help save our planet (and us)&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Making complex systems smarter&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Think about how our modern lives depend on intricate networks for energy, transport, and city living. AI can redesign these systems to work much more efficiently.&lt;/p&gt;&lt;p&gt;Remember those frustrating power outages when the wind stops blowing or clouds cover the sun? AI can help predict these fluctuations in renewable energy and balance them with real-time demand. DeepMind has already shown its AI can boost wind energy’s economic value by 20% by reducing the need for backup power sources.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Speeding up discovery and reducing waste&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Almost half the emissions cuts needed to reach net-zero by 2050 will rely on technologies that are barely out of the lab today and AI is turbocharging these breakthroughs.&lt;/p&gt;&lt;p&gt;Take Google DeepMind’s GNOME tool, which has already identified over two million new crystal structures that could revolutionise renewable energy and battery storage. Or consider how Amazon’s AI packaging algorithms have saved over three million metric tons of material since 2015.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. Helping us make better choices&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Our daily decisions – from what we eat, to how we travel – could drive up to 70% of emissions reductions by 2050. But making the right choice isn’t always easy.&lt;/p&gt;&lt;p&gt;AI can be our personal environmental coach, breaking down information barriers and offering tailored recommendations. Already using Google Maps’ fuel-efficient routes? That’s AI helping you cut emissions while saving gas money. And those smart home systems like Nest use AI to optimise your heating and cooling, which could save millions of tonnes of CO2 if we all adopted them.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. Predicting climate changes and policy effects&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;How do we plan for a changing climate? AI can process enormous datasets to forecast climate patterns with unprecedented accuracy.&lt;/p&gt;&lt;p&gt;Tools like IceNet (developed by the British Antarctic Survey and the Alan Turing Institute) are using AI to predict sea ice levels better than ever before, helping communities and businesses prepare. This capability also extends to helping governments design climate policies that actually work, by learning from countless case studies around the world.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. Keeping us safe in extreme weather&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As climate disasters intensify, early warning can save lives. AI-powered systems for floods and wildfires are becoming essential safety nets.&lt;/p&gt;&lt;p&gt;Google’s Flood Hub uses machine learning to provide flood forecasts up to five days in advance across more than 80 countries. That’s precious time for people to protect their homes and evacuate if necessary.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-numbers-support-ai-cutting-global-carbon-emissions"&gt;The numbers support AI cutting global carbon emissions&lt;/h3&gt;&lt;p&gt;When researchers crunched the numbers, they found AI could:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Cut power sector emissions by 1.8 billion tonnes yearly by 2035 just by optimising renewable energy&lt;/li&gt;&lt;li&gt;Save between 0.9 and 3.0 billion tonnes annually by improving plant-based proteins to taste and feel more like meat&lt;/li&gt;&lt;li&gt;Reduce vehicle emissions by up to 0.6 billion tonnes each year through shared mobility and better battery technology&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Here’s the catch: we can’t just sit back and let market forces determine how AI develops. The researchers call for an “active state” to ensure that AI benefits everyone and the planet.&lt;/p&gt;&lt;p&gt;“Governments have a critical role in ensuring that AI is deployed effectively to accelerate the transition equitably and sustainably,” they conclude.&lt;/p&gt;&lt;p&gt;What this means in practice is creating incentives for green AI research, regulating to minimise environmental impact, and investing in infrastructure so communities worldwide can share in the benefits.&lt;/p&gt;&lt;p&gt;By guiding innovation and working together internationally, we can unlock AI’s full potential to reduce global carbon emissions and tackle the climate crisis—and build a future where both people and the planet can thrive.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Abhishek Mishra)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Power play: Can the grid cope with AI’s growing appetite?&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/study-finds-ai-slash-global-carbon-emissions/</guid><pubDate>Wed, 02 Jul 2025 16:01:40 +0000</pubDate></item><item><title>NYT to start searching deleted ChatGPT logs after beating OpenAI in court (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        What are the odds NYT will access your ChatGPT logs in OpenAI court battle?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1152x648-1751471454.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakorn Supajitsoontorn | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, OpenAI raised objections in court, hoping to overturn a court order requiring the AI company to retain all ChatGPT logs "indefinitely," including deleted and temporary chats.&lt;/p&gt;
&lt;p&gt;But Sidney Stein, the US district judge reviewing OpenAI's request, immediately denied OpenAI's objections. He was seemingly unmoved by the company's claims that the order forced OpenAI to abandon "long-standing privacy norms" and weaken privacy protections that users expect based on ChatGPT's terms of service. Rather, Stein suggested that OpenAI's user agreement specified that their data could be retained as part of a legal process, which Stein said is exactly what is happening now.&lt;/p&gt;
&lt;p&gt;The order was issued by magistrate judge Ona Wang just days after news organizations, led by The New York Times, requested it. The news plaintiffs claimed the order was urgently needed to preserve potential evidence in their copyright case, alleging that ChatGPT users are likely to delete chats where they attempted to use the chatbot to skirt paywalls to access news content.&lt;/p&gt;
&lt;p&gt;A spokesperson told Ars that OpenAI plans to "keep fighting" the order, but the ChatGPT maker seems to have few options left. They could possibly petition the Second Circuit Court of Appeals for a rarely granted emergency order that could intervene to block Wang's order, but the appeals court would have to consider Wang's order an extraordinary abuse of discretion for OpenAI to win that fight.&lt;/p&gt;
&lt;p&gt;OpenAI's spokesperson declined to confirm if the company plans to pursue this extreme remedy.&lt;/p&gt;
&lt;p&gt;In the meantime, OpenAI is negotiating a process that will allow news plaintiffs to search through the retained data. Perhaps the sooner that process begins, the sooner the data will be deleted. And that possibility puts OpenAI in the difficult position of having to choose between either caving to some data collection to stop retaining data as soon as possible or prolonging the fight over the order and potentially putting more users' private conversations at risk of exposure through litigation or, worse, a data breach.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;News orgs will soon start searching ChatGPT logs&lt;/h2&gt;
&lt;p&gt;The clock is ticking, and so far, OpenAI has not provided any official updates since a June 5 blog post detailing which ChatGPT users will be affected.&lt;/p&gt;
&lt;p&gt;While it's clear that OpenAI has been and will continue to retain mounds of data, it would be impossible for The New York Times or any news plaintiff to search through all that data.&lt;/p&gt;
&lt;p&gt;Instead, only a small sample of the data will likely be accessed, based on keywords that OpenAI and news plaintiffs agree on. That data will remain on OpenAI's servers, where it will be anonymized, and it will likely never be directly produced to plaintiffs.&lt;/p&gt;
&lt;p&gt;Both sides are negotiating the exact process for searching through the chat logs, with both parties seemingly hoping to minimize the amount of time the chat logs will be preserved.&lt;/p&gt;
&lt;p&gt;For OpenAI, sharing the logs risks revealing instances of infringing outputs that could further spike damages in the case. The logs could also expose how often outputs attribute misinformation to news plaintiffs.&lt;/p&gt;
&lt;p&gt;But for news plaintiffs, accessing the logs is not considered key to their case—perhaps providing additional examples of copying—but could help news organizations argue that ChatGPT dilutes the market for their content. That could weigh against the fair use argument, as a judge opined in a recent ruling that evidence of market dilution could tip an AI copyright case in favor of plaintiffs.&lt;/p&gt;
&lt;p&gt;Jay Edelson, a leading consumer privacy lawyer, told Ars that he's concerned that judges don't seem to be considering that any evidence in the ChatGPT logs wouldn't "advance" news plaintiffs' case "at all," while really changing "a product that people are using on a daily basis."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Edelson warned that OpenAI itself probably has better security than most firms to protect against a potential data breach that could expose these private chat logs. But "lawyers have notoriously been pretty bad about securing data," Edelson suggested, so "the idea that you've got a bunch of lawyers who are going to be doing whatever they are" with "some of the most sensitive data on the planet" and "they're the ones protecting it against hackers should make everyone uneasy."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So even though odds are pretty good that the majority of users' chats won't end up in the sample, Edelson said the mere threat of being included might push some users to rethink how they use AI. He further warned that ChatGPT users turning to OpenAI rival services like Anthropic's Claude or Google's Gemini could suggest that Wang's order is improperly influencing market forces, which also seems "crazy."&lt;/p&gt;
&lt;p&gt;To Edelson, the most "cynical" take could be that news plaintiffs are possibly hoping the order will threaten OpenAI's business to the point where the AI company agrees to a settlement.&lt;/p&gt;
&lt;p&gt;Regardless of the news plaintiffs' motives, the order sets an alarming precedent, Edelson said. He joined critics suggesting that more AI data may be frozen in the future, potentially affecting even more users as a result of the sweeping order surviving scrutiny in this case. Imagine if litigation one day targets Google's AI search summaries, Edelson suggested.&lt;/p&gt;
&lt;h2&gt;Lawyer slams judges for giving ChatGPT users no voice&lt;/h2&gt;
&lt;p&gt;Edelson told Ars that the order is so potentially threatening to OpenAI's business that the company may not have a choice but to explore every path available to continue fighting it.&lt;/p&gt;
&lt;p&gt;"They will absolutely do something to try to stop this," Edelson predicted, calling the order "bonkers" for overlooking millions of users' privacy concerns while "strangely" excluding enterprise customers.&lt;/p&gt;
&lt;p&gt;From court filings, it seems possible that enterprise users were excluded to protect OpenAI's competitiveness, but Edelson suggested there's "no logic" to their exclusion "at all." By excluding these ChatGPT users, the judge's order may have removed the users best resourced to fight the order, Edelson suggested.&lt;/p&gt;
&lt;p&gt;"What that means is the big businesses, the ones who have the power, all of their stuff remains private, and no one can touch that," Edelson said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, the order is "only going to intrude on the privacy of the common people out there," which Edelson said "is really offensive," given that Wang denied two ChatGPT users' panicked request to intervene.&lt;/p&gt;
&lt;p&gt;"We are talking about billions of chats that are now going to be preserved when they weren't going to be preserved before," Edelson said, noting that he's input information about his personal medical history into ChatGPT. "People ask for advice about their marriages, express concerns about losing jobs. They say really personal things. And one of the bargains in dealing with OpenAI is that you're allowed to delete your chats and you're allowed to temporary chats."&lt;/p&gt;
&lt;p&gt;The greatest risk to users would be a data breach, Edelson said, but that's not the only potential privacy concern. Corynne McSherry, legal director for the digital rights group the Electronic Frontier Foundation, previously told Ars that as long as users' data is retained, it could also be exposed through future law enforcement and private litigation requests.&lt;/p&gt;
&lt;p&gt;Edelson pointed out that most privacy attorneys don't consider OpenAI CEO Sam Altman to be a "privacy guy," despite Altman recently slamming the NYT, alleging it sued OpenAI because it doesn't "like user privacy."&lt;/p&gt;
&lt;p&gt;"He's trying to protect OpenAI, and he does not give a hoot about the privacy rights of consumers," Edelson said, echoing one ChatGPT user's dismissed concern that OpenAI may not prioritize users' privacy concerns in the case if it's financially motivated to resolve the case.&lt;/p&gt;
&lt;p&gt;"The idea that he and his lawyers are really going to be the safeguards here isn't very compelling," Edelson said. He criticized the judges for dismissing users' concerns and rejecting OpenAI's request that users get a chance to testify.&lt;/p&gt;
&lt;p&gt;"What's really most appalling to me is the people who are being affected have had no voice in it," Edelson said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        What are the odds NYT will access your ChatGPT logs in OpenAI court battle?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1152x648-1751471454.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakorn Supajitsoontorn | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, OpenAI raised objections in court, hoping to overturn a court order requiring the AI company to retain all ChatGPT logs "indefinitely," including deleted and temporary chats.&lt;/p&gt;
&lt;p&gt;But Sidney Stein, the US district judge reviewing OpenAI's request, immediately denied OpenAI's objections. He was seemingly unmoved by the company's claims that the order forced OpenAI to abandon "long-standing privacy norms" and weaken privacy protections that users expect based on ChatGPT's terms of service. Rather, Stein suggested that OpenAI's user agreement specified that their data could be retained as part of a legal process, which Stein said is exactly what is happening now.&lt;/p&gt;
&lt;p&gt;The order was issued by magistrate judge Ona Wang just days after news organizations, led by The New York Times, requested it. The news plaintiffs claimed the order was urgently needed to preserve potential evidence in their copyright case, alleging that ChatGPT users are likely to delete chats where they attempted to use the chatbot to skirt paywalls to access news content.&lt;/p&gt;
&lt;p&gt;A spokesperson told Ars that OpenAI plans to "keep fighting" the order, but the ChatGPT maker seems to have few options left. They could possibly petition the Second Circuit Court of Appeals for a rarely granted emergency order that could intervene to block Wang's order, but the appeals court would have to consider Wang's order an extraordinary abuse of discretion for OpenAI to win that fight.&lt;/p&gt;
&lt;p&gt;OpenAI's spokesperson declined to confirm if the company plans to pursue this extreme remedy.&lt;/p&gt;
&lt;p&gt;In the meantime, OpenAI is negotiating a process that will allow news plaintiffs to search through the retained data. Perhaps the sooner that process begins, the sooner the data will be deleted. And that possibility puts OpenAI in the difficult position of having to choose between either caving to some data collection to stop retaining data as soon as possible or prolonging the fight over the order and potentially putting more users' private conversations at risk of exposure through litigation or, worse, a data breach.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;News orgs will soon start searching ChatGPT logs&lt;/h2&gt;
&lt;p&gt;The clock is ticking, and so far, OpenAI has not provided any official updates since a June 5 blog post detailing which ChatGPT users will be affected.&lt;/p&gt;
&lt;p&gt;While it's clear that OpenAI has been and will continue to retain mounds of data, it would be impossible for The New York Times or any news plaintiff to search through all that data.&lt;/p&gt;
&lt;p&gt;Instead, only a small sample of the data will likely be accessed, based on keywords that OpenAI and news plaintiffs agree on. That data will remain on OpenAI's servers, where it will be anonymized, and it will likely never be directly produced to plaintiffs.&lt;/p&gt;
&lt;p&gt;Both sides are negotiating the exact process for searching through the chat logs, with both parties seemingly hoping to minimize the amount of time the chat logs will be preserved.&lt;/p&gt;
&lt;p&gt;For OpenAI, sharing the logs risks revealing instances of infringing outputs that could further spike damages in the case. The logs could also expose how often outputs attribute misinformation to news plaintiffs.&lt;/p&gt;
&lt;p&gt;But for news plaintiffs, accessing the logs is not considered key to their case—perhaps providing additional examples of copying—but could help news organizations argue that ChatGPT dilutes the market for their content. That could weigh against the fair use argument, as a judge opined in a recent ruling that evidence of market dilution could tip an AI copyright case in favor of plaintiffs.&lt;/p&gt;
&lt;p&gt;Jay Edelson, a leading consumer privacy lawyer, told Ars that he's concerned that judges don't seem to be considering that any evidence in the ChatGPT logs wouldn't "advance" news plaintiffs' case "at all," while really changing "a product that people are using on a daily basis."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Edelson warned that OpenAI itself probably has better security than most firms to protect against a potential data breach that could expose these private chat logs. But "lawyers have notoriously been pretty bad about securing data," Edelson suggested, so "the idea that you've got a bunch of lawyers who are going to be doing whatever they are" with "some of the most sensitive data on the planet" and "they're the ones protecting it against hackers should make everyone uneasy."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So even though odds are pretty good that the majority of users' chats won't end up in the sample, Edelson said the mere threat of being included might push some users to rethink how they use AI. He further warned that ChatGPT users turning to OpenAI rival services like Anthropic's Claude or Google's Gemini could suggest that Wang's order is improperly influencing market forces, which also seems "crazy."&lt;/p&gt;
&lt;p&gt;To Edelson, the most "cynical" take could be that news plaintiffs are possibly hoping the order will threaten OpenAI's business to the point where the AI company agrees to a settlement.&lt;/p&gt;
&lt;p&gt;Regardless of the news plaintiffs' motives, the order sets an alarming precedent, Edelson said. He joined critics suggesting that more AI data may be frozen in the future, potentially affecting even more users as a result of the sweeping order surviving scrutiny in this case. Imagine if litigation one day targets Google's AI search summaries, Edelson suggested.&lt;/p&gt;
&lt;h2&gt;Lawyer slams judges for giving ChatGPT users no voice&lt;/h2&gt;
&lt;p&gt;Edelson told Ars that the order is so potentially threatening to OpenAI's business that the company may not have a choice but to explore every path available to continue fighting it.&lt;/p&gt;
&lt;p&gt;"They will absolutely do something to try to stop this," Edelson predicted, calling the order "bonkers" for overlooking millions of users' privacy concerns while "strangely" excluding enterprise customers.&lt;/p&gt;
&lt;p&gt;From court filings, it seems possible that enterprise users were excluded to protect OpenAI's competitiveness, but Edelson suggested there's "no logic" to their exclusion "at all." By excluding these ChatGPT users, the judge's order may have removed the users best resourced to fight the order, Edelson suggested.&lt;/p&gt;
&lt;p&gt;"What that means is the big businesses, the ones who have the power, all of their stuff remains private, and no one can touch that," Edelson said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, the order is "only going to intrude on the privacy of the common people out there," which Edelson said "is really offensive," given that Wang denied two ChatGPT users' panicked request to intervene.&lt;/p&gt;
&lt;p&gt;"We are talking about billions of chats that are now going to be preserved when they weren't going to be preserved before," Edelson said, noting that he's input information about his personal medical history into ChatGPT. "People ask for advice about their marriages, express concerns about losing jobs. They say really personal things. And one of the bargains in dealing with OpenAI is that you're allowed to delete your chats and you're allowed to temporary chats."&lt;/p&gt;
&lt;p&gt;The greatest risk to users would be a data breach, Edelson said, but that's not the only potential privacy concern. Corynne McSherry, legal director for the digital rights group the Electronic Frontier Foundation, previously told Ars that as long as users' data is retained, it could also be exposed through future law enforcement and private litigation requests.&lt;/p&gt;
&lt;p&gt;Edelson pointed out that most privacy attorneys don't consider OpenAI CEO Sam Altman to be a "privacy guy," despite Altman recently slamming the NYT, alleging it sued OpenAI because it doesn't "like user privacy."&lt;/p&gt;
&lt;p&gt;"He's trying to protect OpenAI, and he does not give a hoot about the privacy rights of consumers," Edelson said, echoing one ChatGPT user's dismissed concern that OpenAI may not prioritize users' privacy concerns in the case if it's financially motivated to resolve the case.&lt;/p&gt;
&lt;p&gt;"The idea that he and his lawyers are really going to be the safeguards here isn't very compelling," Edelson said. He criticized the judges for dismissing users' concerns and rejecting OpenAI's request that users get a chance to testify.&lt;/p&gt;
&lt;p&gt;"What's really most appalling to me is the people who are being affected have had no voice in it," Edelson said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court/</guid><pubDate>Wed, 02 Jul 2025 16:34:06 +0000</pubDate></item><item><title>ChatGPT referrals to news sites are growing, but not enough to offset search declines (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/chatgpt-referrals-to-news-sites-are-growing-but-not-enough-to-offset-search-declines/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Referrals from ChatGPT to news publishers are growing, but not enough to counter the decline in clicks resulting from users increasingly getting their news directly from AI or AI-powered search results, according to a report from digital market intelligence company Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since the launch of Google’s AI Overviews in May 2024, the firm found that the number of news searches on the web that result in no click-throughs to news websites has grown from 56% to nearly 69% as of May 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Not surprisingly, organic traffic has also declined, dropping from over 2.3 billion visits at its peak in mid-2024 to now under 1.7 billion. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, news-related prompts in ChatGPT grew by 212% from January 2024 through May 2025.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024257" height="575" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-1.01.35PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For news publishers, the rapid adoption of AI is changing the game. Visibility in Google Search results and good SEO practices may no longer deliver the value they did in the past, as search rank isn’t translating into as much website traffic as before, the firm pointed out. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, ChatGPT referrals to news publishers are growing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From January through May 2024, ChatGPT referrals to news sites were just under 1 million, Similarweb says, but have grown to more than 25 million in 2025 — a 25x increase.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Of course, when the industry is facing even massive declines in organic search traffic, this increase is hardly enough to make up for publishers’ losses.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024253" height="618" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.59.19PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The report also noted that some websites are faring better than others when it comes to AI referrals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sites seeing the most increases in ChatGPT referral traffic include Reuters (up 8.9% year-over-year), NY Post (up 7.1%), and Business Insider (up 6.5%). Meanwhile, The New York Times, which is suing OpenAI over allegedly scraping its works without permission, is seeing far fewer ChatGPT referrals. Though still in the top 10 sites receiving ChatGPT referral traffic, it’s only seen a 3.1% increase. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Topics like stocks, finance, and sports are currently accounting for the majority of these ChatGPT news-related prompts, but Similarweb’s report notes other topics are seeing growth, too, like politics, the economy, weather, and others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, the firm theorizes, may signal a move away from more “reactive information” and toward deeper “issue-driven engagement” via AI. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024255" height="563" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.58.50PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024254" height="596" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.59.05PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the AI referrals growth, ChatGPT’s website and app users have also seen greater adoption. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the last six months, app users have more than doubled, while website visitors were up 52%, Similarweb said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm is now offering a service for brands and businesses that allows them to track how and where their brand shows up in GenAI tools like ChatGPT, and how that compares to their competition.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024256" height="507" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.58.36PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Solutions to the news publishers’ crisis are few and far between. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under pressure from news publishers as AI kills their traffic, Google recently launched a service called Offerwall that allows publishers using Google Ad Manager to experiment with other means of monetization beyond more traffic-dependent options, like ads. With Offerwall, publishers can instead try things like micropayments or asking users to sign up for newsletters to access their site’s content, for example. They can also customize the Offerwall screens with options of their own, Google said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other sites are experimenting with paywalls or other means of monetization. Many have since conducted mass layoffs or even shut down their operations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a recent interview with The NYT’s Hard Fork podcast, OpenAI CEO Sam Altman responded to a question about AI’s impact on the job market by saying, “I do think there will be areas where some jobs go away, or maybe there will be some whole categories of jobs that go away. And any job that goes away, even if it’s good for society and the economy as a whole, is very painful — extremely painful — in that moment … there is going to be real pain here in many cases.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Referrals from ChatGPT to news publishers are growing, but not enough to counter the decline in clicks resulting from users increasingly getting their news directly from AI or AI-powered search results, according to a report from digital market intelligence company Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since the launch of Google’s AI Overviews in May 2024, the firm found that the number of news searches on the web that result in no click-throughs to news websites has grown from 56% to nearly 69% as of May 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Not surprisingly, organic traffic has also declined, dropping from over 2.3 billion visits at its peak in mid-2024 to now under 1.7 billion. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, news-related prompts in ChatGPT grew by 212% from January 2024 through May 2025.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024257" height="575" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-1.01.35PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For news publishers, the rapid adoption of AI is changing the game. Visibility in Google Search results and good SEO practices may no longer deliver the value they did in the past, as search rank isn’t translating into as much website traffic as before, the firm pointed out. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, ChatGPT referrals to news publishers are growing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From January through May 2024, ChatGPT referrals to news sites were just under 1 million, Similarweb says, but have grown to more than 25 million in 2025 — a 25x increase.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Of course, when the industry is facing even massive declines in organic search traffic, this increase is hardly enough to make up for publishers’ losses.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024253" height="618" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.59.19PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The report also noted that some websites are faring better than others when it comes to AI referrals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sites seeing the most increases in ChatGPT referral traffic include Reuters (up 8.9% year-over-year), NY Post (up 7.1%), and Business Insider (up 6.5%). Meanwhile, The New York Times, which is suing OpenAI over allegedly scraping its works without permission, is seeing far fewer ChatGPT referrals. Though still in the top 10 sites receiving ChatGPT referral traffic, it’s only seen a 3.1% increase. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Topics like stocks, finance, and sports are currently accounting for the majority of these ChatGPT news-related prompts, but Similarweb’s report notes other topics are seeing growth, too, like politics, the economy, weather, and others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, the firm theorizes, may signal a move away from more “reactive information” and toward deeper “issue-driven engagement” via AI. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024255" height="563" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.58.50PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024254" height="596" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.59.05PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the AI referrals growth, ChatGPT’s website and app users have also seen greater adoption. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the last six months, app users have more than doubled, while website visitors were up 52%, Similarweb said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm is now offering a service for brands and businesses that allows them to track how and where their brand shows up in GenAI tools like ChatGPT, and how that compares to their competition.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024256" height="507" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-12.58.36PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Solutions to the news publishers’ crisis are few and far between. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under pressure from news publishers as AI kills their traffic, Google recently launched a service called Offerwall that allows publishers using Google Ad Manager to experiment with other means of monetization beyond more traffic-dependent options, like ads. With Offerwall, publishers can instead try things like micropayments or asking users to sign up for newsletters to access their site’s content, for example. They can also customize the Offerwall screens with options of their own, Google said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other sites are experimenting with paywalls or other means of monetization. Many have since conducted mass layoffs or even shut down their operations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a recent interview with The NYT’s Hard Fork podcast, OpenAI CEO Sam Altman responded to a question about AI’s impact on the job market by saying, “I do think there will be areas where some jobs go away, or maybe there will be some whole categories of jobs that go away. And any job that goes away, even if it’s good for society and the economy as a whole, is very painful — extremely painful — in that moment … there is going to be real pain here in many cases.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/chatgpt-referrals-to-news-sites-are-growing-but-not-enough-to-offset-search-declines/</guid><pubDate>Wed, 02 Jul 2025 17:48:40 +0000</pubDate></item><item><title>Perplexity launches a $200 monthly subscription plan (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/perplexity-launches-a-200-monthly-subscription-plan/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2181313521.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Perplexity is launching a $200-per-month subscription plan for its power users, the company announced in a blog post Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan, Perplexity Max, offers unlimited access to the startup’s spreadsheet and report generation tool, Labs, as well as early access to new features, including Perplexity’s forthcoming AI-powered browser, Comet. Max subscribers will also get priority access to any Perplexity services using the latest frontier models, such as OpenAI o3-pro and Claude Opus 4.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the launch of Max, Perplexity became the latest AI provider to offer a hyper-premium subscription tier to capitalize on its power users. OpenAI was the first to do so with its $200-a-month ChatGPT Pro subscription, but Google, Anthropic, and Cursor have followed suit in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity now offers a variety of subscription plans. Alongside the $200-a-month Max plan, Perplexity offers a consumer Pro plan for $20 a month, as well as an Enterprise Pro plan that costs $40 a month per person. The startup says it will eventually offer a hyper-premium Max plan for Enterprise customers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Perplexity generated roughly $34 million in revenue largely driven by subscriptions to its $20-a-month Pro plan, but still burned about $65 million in cash, according to financials seen by The Information. Most of Perplexity’s cash burn reportedly comes down to heavy spending on cloud servers and buying access to AI models from OpenAI and Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity’s business seems to have grown since last year — it reportedly had an ARR of $80 million in January. However, the startup needs to generate significantly more revenue to justify its valuation. In May, Perplexity held late-stage talks to raise $500 million at a $14 billion valuation. It’s unclear if that round officially closed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Perplexity’s competition in the AI search market is intensifying. In recent months, Google has heavily pushed AI Mode, its own AI-powered search product, which bears a striking resemblance to Perplexity’s app, in front of its users. OpenAI has also integrated search more deeply into ChatGPT in recent months and has reportedly considered launching a browser of its own.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;One key to Perplexity’s success may be its ability to work with AI providers, which it relies on for AI models, while simultaneously beating them in the AI search market. The added revenue from Perplexity Max subscribers could bolster the startup’s ability to compete in the space.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2181313521.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Perplexity is launching a $200-per-month subscription plan for its power users, the company announced in a blog post Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan, Perplexity Max, offers unlimited access to the startup’s spreadsheet and report generation tool, Labs, as well as early access to new features, including Perplexity’s forthcoming AI-powered browser, Comet. Max subscribers will also get priority access to any Perplexity services using the latest frontier models, such as OpenAI o3-pro and Claude Opus 4.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the launch of Max, Perplexity became the latest AI provider to offer a hyper-premium subscription tier to capitalize on its power users. OpenAI was the first to do so with its $200-a-month ChatGPT Pro subscription, but Google, Anthropic, and Cursor have followed suit in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity now offers a variety of subscription plans. Alongside the $200-a-month Max plan, Perplexity offers a consumer Pro plan for $20 a month, as well as an Enterprise Pro plan that costs $40 a month per person. The startup says it will eventually offer a hyper-premium Max plan for Enterprise customers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Perplexity generated roughly $34 million in revenue largely driven by subscriptions to its $20-a-month Pro plan, but still burned about $65 million in cash, according to financials seen by The Information. Most of Perplexity’s cash burn reportedly comes down to heavy spending on cloud servers and buying access to AI models from OpenAI and Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity’s business seems to have grown since last year — it reportedly had an ARR of $80 million in January. However, the startup needs to generate significantly more revenue to justify its valuation. In May, Perplexity held late-stage talks to raise $500 million at a $14 billion valuation. It’s unclear if that round officially closed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Perplexity’s competition in the AI search market is intensifying. In recent months, Google has heavily pushed AI Mode, its own AI-powered search product, which bears a striking resemblance to Perplexity’s app, in front of its users. OpenAI has also integrated search more deeply into ChatGPT in recent months and has reportedly considered launching a browser of its own.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;One key to Perplexity’s success may be its ability to work with AI providers, which it relies on for AI models, while simultaneously beating them in the AI search market. The added revenue from Perplexity Max subscribers could bolster the startup’s ability to compete in the space.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/perplexity-launches-a-200-monthly-subscription-plan/</guid><pubDate>Wed, 02 Jul 2025 18:06:17 +0000</pubDate></item><item><title>[NEW] Confronting the AI/energy conundrum (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MITEI-evelyn-wang.JPG" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The explosive growth of AI-powered computing centers is creating an unprecedented surge in electricity demand that threatens to overwhelm power grids and derail climate goals. At the same time, artificial intelligence technologies could revolutionize energy systems, accelerating the transition to clean power.&lt;/p&gt;&lt;p&gt;“We’re at a cusp of potentially gigantic change throughout the economy,” said William H. Green, director of the MIT Energy Initiative (MITEI) and Hoyt C. Hottel Professor in the MIT Department of Chemical Engineering, at MITEI’s Spring Symposium, “AI and energy: Peril and promise,” held on May 13. The event brought together experts from industry, academia, and government to explore solutions to what Green described as both “local problems with electric supply and meeting our clean energy targets” while seeking to “reap the benefits of AI without some of the harms.” The challenge of data center energy demand and potential benefits of AI to the energy transition is a research priority for MITEI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI’s startling energy demands&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;From the start, the symposium highlighted sobering statistics about AI’s appetite for electricity. After decades of flat electricity demand in the United States, computing centers now consume approximately 4 percent of the nation's electricity. Although there is great uncertainty, some projections suggest this demand could rise to 12-15 percent by 2030, largely driven by artificial intelligence applications.&lt;/p&gt;&lt;p&gt;Vijay Gadepally, senior scientist at MIT’s Lincoln Laboratory, emphasized the scale of AI’s consumption. “The power required for sustaining some of these large models is doubling almost every three months,” he noted. “A single ChatGPT conversation uses as much electricity as charging your phone, and generating an image consumes about a bottle of water for cooling.”&lt;/p&gt;&lt;p&gt;Facilities requiring 50 to 100 megawatts of power are emerging rapidly across the United States and globally, driven both by casual and institutional research needs relying on large language programs such as ChatGPT and Gemini. Gadepally cited congressional testimony by Sam Altman, CEO of OpenAI, highlighting how fundamental this relationship has become: “The cost of intelligence, the cost of AI, will converge to the cost of energy.”&lt;/p&gt;&lt;p&gt;“The energy demands of AI are a significant challenge, but we also have an opportunity to harness these vast computational capabilities to contribute to climate change solutions,” said Evelyn Wang, MIT vice president for energy and climate and the former director at the Advanced Research Projects Agency-Energy (ARPA-E) at the U.S. Department of Energy.&lt;/p&gt;&lt;p&gt;Wang also noted that innovations developed for AI and data centers — such as efficiency, cooling technologies, and clean-power solutions — could have broad applications beyond computing facilities themselves.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Strategies for clean energy solutions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The symposium explored multiple pathways to address the AI-energy challenge. Some panelists presented models suggesting that while artificial intelligence may increase emissions in the short term, its optimization capabilities could enable substantial emissions reductions after 2030 through more efficient power systems and accelerated clean technology development.&lt;/p&gt;&lt;p&gt;Research shows regional variations in the cost of powering computing centers with clean electricity, according to Emre Gençer, co-founder and CEO of Sesame Sustainability and former MITEI principal research scientist. Gençer’s analysis revealed that the central United States offers considerably lower costs due to complementary solar and wind resources. However, achieving zero-emission power would require massive battery deployments — five to 10 times more than moderate carbon scenarios — driving costs two to three times higher.&lt;/p&gt;&lt;p&gt;“If we want to do zero emissions with reliable power, we need technologies other than renewables and batteries, which will be too expensive,” Gençer said. He pointed to “long-duration storage technologies, small modular reactors, geothermal, or hybrid approaches” as necessary complements.&lt;/p&gt;&lt;p&gt;Because of data center energy demand, there is renewed interest in nuclear power, noted Kathryn Biegel, manager of R&amp;amp;D and corporate strategy at Constellation Energy, adding that her company is restarting the reactor at the former Three Mile Island site, now called the “Crane Clean Energy Center,” to meet this demand. “The data center space has become a major, major priority for Constellation,” she said, emphasizing how their needs for both reliability and carbon-free electricity are reshaping the power industry.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI accelerate the energy transition?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Artificial intelligence could dramatically improve power systems, according to Priya Donti, assistant professor and the Silverman Family Career Development Professor in MIT's Department of Electrical Engineering and Computer Science and the Laboratory for Information and Decision Systems. She showcased how AI can accelerate power grid optimization by embedding physics-based constraints into neural networks, potentially solving complex power flow problems at “10 times, or even greater, speed compared to your traditional models.”&lt;/p&gt;&lt;p&gt;AI is already reducing carbon emissions, according to examples shared by Antonia Gawel, global director of sustainability and partnerships at Google. Google Maps’ fuel-efficient routing feature has “helped to prevent more than 2.9 million metric tons of GHG [greenhouse gas] emissions reductions since launch, which is the equivalent of taking 650,000 fuel-based cars off the road for a year," she said. Another Google research project uses artificial intelligence to help pilots avoid creating contrails, which represent about 1 percent of global warming impact.&lt;/p&gt;&lt;p&gt;AI’s potential to speed materials discovery for power applications was highlighted by Rafael Gómez-Bombarelli, the Paul M. Cook Career Development Associate Professor in the MIT Department of Materials Science and Engineering. “AI-supervised models can be trained to go from structure to property,” he noted, enabling the development of materials crucial for both computing and efficiency.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Securing growth with sustainability&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the symposium, participants grappled with balancing rapid AI deployment against environmental impacts. While AI training receives most attention, Dustin Demetriou, senior technical staff member in sustainability and data center innovation at IBM, quoted a World Economic Forum article that suggested that “80 percent of the environmental footprint is estimated to be due to inferencing.” Demetriou emphasized the need for efficiency across all artificial intelligence applications.&lt;/p&gt;&lt;p&gt;Jevons’ paradox, where “efficiency gains tend to increase overall resource consumption rather than decrease it” is another factor to consider, cautioned Emma Strubell, the Raj Reddy Assistant Professor in the Language Technologies Institute in the School of Computer Science at Carnegie Mellon University. Strubell advocated for viewing computing center electricity as a limited resource requiring thoughtful allocation across different applications.&lt;/p&gt;&lt;p&gt;Several presenters discussed novel approaches for integrating renewable sources with existing grid infrastructure, including potential hybrid solutions that combine clean installations with existing natural gas plants that have valuable grid connections already in place. These approaches could provide substantial clean capacity across the United States at reasonable costs while minimizing reliability impacts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Navigating the AI-energy paradox&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The symposium highlighted MIT’s central role in developing solutions to the AI-electricity challenge.&lt;/p&gt;&lt;p&gt;Green spoke of a new MITEI program on computing centers, power, and computation that will operate alongside the comprehensive spread of MIT Climate Project research. “We’re going to try to tackle a very complicated problem all the way from the power sources through the actual algorithms that deliver value to the customers — in a way that’s going to be acceptable to all the stakeholders and really meet all the needs,” Green said.&lt;/p&gt;&lt;p&gt;Participants in the symposium were polled about priorities for MIT’s research by Randall Field, MITEI director of research. The real-time results ranked “data center and grid integration issues” as the top priority, followed by “AI for accelerated discovery of advanced materials for energy.”&lt;/p&gt;&lt;p&gt;In addition, attendees revealed that most view AI's potential regarding power as a “promise,” rather than a “peril,” although a considerable portion remain uncertain about the ultimate impact. When asked about priorities in power supply for computing facilities, half of the respondents selected carbon intensity as their top concern, with reliability and cost following.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MITEI-evelyn-wang.JPG" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The explosive growth of AI-powered computing centers is creating an unprecedented surge in electricity demand that threatens to overwhelm power grids and derail climate goals. At the same time, artificial intelligence technologies could revolutionize energy systems, accelerating the transition to clean power.&lt;/p&gt;&lt;p&gt;“We’re at a cusp of potentially gigantic change throughout the economy,” said William H. Green, director of the MIT Energy Initiative (MITEI) and Hoyt C. Hottel Professor in the MIT Department of Chemical Engineering, at MITEI’s Spring Symposium, “AI and energy: Peril and promise,” held on May 13. The event brought together experts from industry, academia, and government to explore solutions to what Green described as both “local problems with electric supply and meeting our clean energy targets” while seeking to “reap the benefits of AI without some of the harms.” The challenge of data center energy demand and potential benefits of AI to the energy transition is a research priority for MITEI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI’s startling energy demands&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;From the start, the symposium highlighted sobering statistics about AI’s appetite for electricity. After decades of flat electricity demand in the United States, computing centers now consume approximately 4 percent of the nation's electricity. Although there is great uncertainty, some projections suggest this demand could rise to 12-15 percent by 2030, largely driven by artificial intelligence applications.&lt;/p&gt;&lt;p&gt;Vijay Gadepally, senior scientist at MIT’s Lincoln Laboratory, emphasized the scale of AI’s consumption. “The power required for sustaining some of these large models is doubling almost every three months,” he noted. “A single ChatGPT conversation uses as much electricity as charging your phone, and generating an image consumes about a bottle of water for cooling.”&lt;/p&gt;&lt;p&gt;Facilities requiring 50 to 100 megawatts of power are emerging rapidly across the United States and globally, driven both by casual and institutional research needs relying on large language programs such as ChatGPT and Gemini. Gadepally cited congressional testimony by Sam Altman, CEO of OpenAI, highlighting how fundamental this relationship has become: “The cost of intelligence, the cost of AI, will converge to the cost of energy.”&lt;/p&gt;&lt;p&gt;“The energy demands of AI are a significant challenge, but we also have an opportunity to harness these vast computational capabilities to contribute to climate change solutions,” said Evelyn Wang, MIT vice president for energy and climate and the former director at the Advanced Research Projects Agency-Energy (ARPA-E) at the U.S. Department of Energy.&lt;/p&gt;&lt;p&gt;Wang also noted that innovations developed for AI and data centers — such as efficiency, cooling technologies, and clean-power solutions — could have broad applications beyond computing facilities themselves.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Strategies for clean energy solutions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The symposium explored multiple pathways to address the AI-energy challenge. Some panelists presented models suggesting that while artificial intelligence may increase emissions in the short term, its optimization capabilities could enable substantial emissions reductions after 2030 through more efficient power systems and accelerated clean technology development.&lt;/p&gt;&lt;p&gt;Research shows regional variations in the cost of powering computing centers with clean electricity, according to Emre Gençer, co-founder and CEO of Sesame Sustainability and former MITEI principal research scientist. Gençer’s analysis revealed that the central United States offers considerably lower costs due to complementary solar and wind resources. However, achieving zero-emission power would require massive battery deployments — five to 10 times more than moderate carbon scenarios — driving costs two to three times higher.&lt;/p&gt;&lt;p&gt;“If we want to do zero emissions with reliable power, we need technologies other than renewables and batteries, which will be too expensive,” Gençer said. He pointed to “long-duration storage technologies, small modular reactors, geothermal, or hybrid approaches” as necessary complements.&lt;/p&gt;&lt;p&gt;Because of data center energy demand, there is renewed interest in nuclear power, noted Kathryn Biegel, manager of R&amp;amp;D and corporate strategy at Constellation Energy, adding that her company is restarting the reactor at the former Three Mile Island site, now called the “Crane Clean Energy Center,” to meet this demand. “The data center space has become a major, major priority for Constellation,” she said, emphasizing how their needs for both reliability and carbon-free electricity are reshaping the power industry.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI accelerate the energy transition?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Artificial intelligence could dramatically improve power systems, according to Priya Donti, assistant professor and the Silverman Family Career Development Professor in MIT's Department of Electrical Engineering and Computer Science and the Laboratory for Information and Decision Systems. She showcased how AI can accelerate power grid optimization by embedding physics-based constraints into neural networks, potentially solving complex power flow problems at “10 times, or even greater, speed compared to your traditional models.”&lt;/p&gt;&lt;p&gt;AI is already reducing carbon emissions, according to examples shared by Antonia Gawel, global director of sustainability and partnerships at Google. Google Maps’ fuel-efficient routing feature has “helped to prevent more than 2.9 million metric tons of GHG [greenhouse gas] emissions reductions since launch, which is the equivalent of taking 650,000 fuel-based cars off the road for a year," she said. Another Google research project uses artificial intelligence to help pilots avoid creating contrails, which represent about 1 percent of global warming impact.&lt;/p&gt;&lt;p&gt;AI’s potential to speed materials discovery for power applications was highlighted by Rafael Gómez-Bombarelli, the Paul M. Cook Career Development Associate Professor in the MIT Department of Materials Science and Engineering. “AI-supervised models can be trained to go from structure to property,” he noted, enabling the development of materials crucial for both computing and efficiency.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Securing growth with sustainability&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the symposium, participants grappled with balancing rapid AI deployment against environmental impacts. While AI training receives most attention, Dustin Demetriou, senior technical staff member in sustainability and data center innovation at IBM, quoted a World Economic Forum article that suggested that “80 percent of the environmental footprint is estimated to be due to inferencing.” Demetriou emphasized the need for efficiency across all artificial intelligence applications.&lt;/p&gt;&lt;p&gt;Jevons’ paradox, where “efficiency gains tend to increase overall resource consumption rather than decrease it” is another factor to consider, cautioned Emma Strubell, the Raj Reddy Assistant Professor in the Language Technologies Institute in the School of Computer Science at Carnegie Mellon University. Strubell advocated for viewing computing center electricity as a limited resource requiring thoughtful allocation across different applications.&lt;/p&gt;&lt;p&gt;Several presenters discussed novel approaches for integrating renewable sources with existing grid infrastructure, including potential hybrid solutions that combine clean installations with existing natural gas plants that have valuable grid connections already in place. These approaches could provide substantial clean capacity across the United States at reasonable costs while minimizing reliability impacts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Navigating the AI-energy paradox&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The symposium highlighted MIT’s central role in developing solutions to the AI-electricity challenge.&lt;/p&gt;&lt;p&gt;Green spoke of a new MITEI program on computing centers, power, and computation that will operate alongside the comprehensive spread of MIT Climate Project research. “We’re going to try to tackle a very complicated problem all the way from the power sources through the actual algorithms that deliver value to the customers — in a way that’s going to be acceptable to all the stakeholders and really meet all the needs,” Green said.&lt;/p&gt;&lt;p&gt;Participants in the symposium were polled about priorities for MIT’s research by Randall Field, MITEI director of research. The real-time results ranked “data center and grid integration issues” as the top priority, followed by “AI for accelerated discovery of advanced materials for energy.”&lt;/p&gt;&lt;p&gt;In addition, attendees revealed that most view AI's potential regarding power as a “promise,” rather than a “peril,” although a considerable portion remain uncertain about the ultimate impact. When asked about priorities in power supply for computing facilities, half of the respondents selected carbon intensity as their top concern, with reliability and cost following.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702</guid><pubDate>Wed, 02 Jul 2025 19:00:00 +0000</pubDate></item><item><title>[NEW] Could Google’s Veo 3 be the start of playable world models? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/could-googles-veo-3-be-the-start-of-playable-world-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/ETB2801.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Demis Hassabis, CEO of Google’s AI research organization DeepMind, appeared to suggest Tuesday evening that Veo 3, Google’s latest video-generating model, could potentially be used for video games.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to a post on X beseeching Google to “Let me play a video game of my veo 3 videos already,” and asking, “playable world models wen?” Hassabis responded, “now wouldn’t that be something.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Wednesday morning, Logan Kilpatrick, lead product for Google’s AI Studio and Gemini API, chimed in with a reply: “🤐🤐🤐🤐”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both posts from the Google executives are little more than playful suggestions, and a Google spokesperson told TechCrunch the company had nothing to share at the moment. But building playable world models isn’t outside the realm of possibilities for the tech giant. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;World models are different from video-generation models. The former simulates the dynamics of a real-world environment, which lets agents predict how the world will evolve in response to their actions. Video-gen models synthesize realistic video sequences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has plans to turn its multimodal foundation model, Gemini 2.5 Pro, into a world model that simulates aspects of the human brain. In December, DeepMind unveiled Genie 2, a model that can generate an “endless” variety of playable worlds. The following month, we reported that Google was forming a new team to work on AI models that can simulate the real world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others are working on building world models — most notably, AI pioneer Fei-Fei Li. Li came out of stealth last year with World Labs, a startup that has built its own AI system that generates video game-like, 3D scenes from a single image.&lt;/p&gt;


&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Veo 3, which is still in public preview, can create video as well as audio to go along with clips — anything from speech to soundtracks. While Veo 3 creates realistic movements by simulating real-world physics, it isn’t quite a world model yet. Instead, it could be used for cinematic storytelling in games, like cutscenes, trailers, and narrative prototyping&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model is also still a “passive output” generative model, and it (or a future Veo generation) would need to shift to a simulator that’s more active, interactive, and predictive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the real challenge with video game production isn’t just impressive visuals; it’s real-time, consistent, and controllable simulation. That’s why it might make sense to see Google take a hybrid approach that leverages Veo and Genie in the future, should it pursue video game or playable world development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google could find itself competing with Microsoft, Scenario, Runway, Pika, and, eventually, OpenAI’s video-generating model Sora.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given Google’s planned moves in the world models space and its reputation for using its deep pockets and distribution muscle to steamroll rivals, competitors in this space would be wise to keep a close watch.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/ETB2801.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Demis Hassabis, CEO of Google’s AI research organization DeepMind, appeared to suggest Tuesday evening that Veo 3, Google’s latest video-generating model, could potentially be used for video games.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to a post on X beseeching Google to “Let me play a video game of my veo 3 videos already,” and asking, “playable world models wen?” Hassabis responded, “now wouldn’t that be something.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Wednesday morning, Logan Kilpatrick, lead product for Google’s AI Studio and Gemini API, chimed in with a reply: “🤐🤐🤐🤐”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both posts from the Google executives are little more than playful suggestions, and a Google spokesperson told TechCrunch the company had nothing to share at the moment. But building playable world models isn’t outside the realm of possibilities for the tech giant. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;World models are different from video-generation models. The former simulates the dynamics of a real-world environment, which lets agents predict how the world will evolve in response to their actions. Video-gen models synthesize realistic video sequences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has plans to turn its multimodal foundation model, Gemini 2.5 Pro, into a world model that simulates aspects of the human brain. In December, DeepMind unveiled Genie 2, a model that can generate an “endless” variety of playable worlds. The following month, we reported that Google was forming a new team to work on AI models that can simulate the real world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others are working on building world models — most notably, AI pioneer Fei-Fei Li. Li came out of stealth last year with World Labs, a startup that has built its own AI system that generates video game-like, 3D scenes from a single image.&lt;/p&gt;


&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Veo 3, which is still in public preview, can create video as well as audio to go along with clips — anything from speech to soundtracks. While Veo 3 creates realistic movements by simulating real-world physics, it isn’t quite a world model yet. Instead, it could be used for cinematic storytelling in games, like cutscenes, trailers, and narrative prototyping&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model is also still a “passive output” generative model, and it (or a future Veo generation) would need to shift to a simulator that’s more active, interactive, and predictive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the real challenge with video game production isn’t just impressive visuals; it’s real-time, consistent, and controllable simulation. That’s why it might make sense to see Google take a hybrid approach that leverages Veo and Genie in the future, should it pursue video game or playable world development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google could find itself competing with Microsoft, Scenario, Runway, Pika, and, eventually, OpenAI’s video-generating model Sora.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given Google’s planned moves in the world models space and its reputation for using its deep pockets and distribution muscle to steamroll rivals, competitors in this space would be wise to keep a close watch.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/could-googles-veo-3-be-the-start-of-playable-world-models/</guid><pubDate>Wed, 02 Jul 2025 19:22:15 +0000</pubDate></item><item><title>[NEW] Everything that could go wrong with X’s new AI-written community notes (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/everything-that-could-go-wrong-with-xs-new-ai-written-community-notes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        X says AI can supercharge community notes, but that comes with obvious risks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="376" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1760687083-640x376.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1760687083-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Elon Musk's X arguably revolutionized social media fact-checking by rolling out "community notes," which created a system to crowdsource diverse views on whether certain X posts were trustworthy or not.&lt;/p&gt;
&lt;p&gt;But now, the platform plans to allow AI to write community notes, and that could potentially ruin whatever trust X users had in the fact-checking system—which X has fully acknowledged.&lt;/p&gt;
&lt;p&gt;In a research paper, X described the initiative as an "upgrade" while explaining everything that could possibly go wrong with AI-written community notes.&lt;/p&gt;
&lt;p&gt;In an ideal world, X described AI agents that speed up and increase the number of community notes added to incorrect posts, ramping up fact-checking efforts platform-wide. Each AI-written note will be rated by a human reviewer, providing feedback that makes the AI agent better at writing notes the longer this feedback loop cycles. As the AI agents get better at writing notes, that leaves human reviewers to focus on more nuanced fact-checking that AI cannot quickly address, such as posts requiring niche expertise or social awareness. Together, the human and AI reviewers, if all goes well, could transform not just X's fact-checking, X's paper suggested, but also potentially provide "a blueprint for a new form of human-AI collaboration in the production of public knowledge."&lt;/p&gt;
&lt;p&gt;Among key questions that remain, however, is a big one: X isn't sure if AI-written notes will be as accurate as notes written by humans. Complicating that further, it seems likely that AI agents could generate "persuasive but inaccurate notes," which human raters might rate as helpful since AI is "exceptionally skilled at crafting persuasive, emotionally resonant, and seemingly neutral notes." That could disrupt the feedback loop, watering down community notes and making the whole system less trustworthy over time, X's research paper warned.&lt;/p&gt;
&lt;p&gt;"If rated helpfulness isn’t perfectly correlated with accuracy, then highly polished but misleading notes could be more likely to pass the approval threshold," the paper said. "This risk could grow as LLMs advance; they could not only write persuasively but also more easily research and construct a seemingly robust body of evidence for nearly any claim, regardless of its veracity, making it even harder for human raters to spot deception or errors."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X is already facing criticism over its AI plans. On Tuesday, former United Kingdom technology minister, Damian Collins, accused X of building a system that could allow "the industrial manipulation of what people see and decide to trust" on a platform with more than 600 million users, The Guardian reported.&lt;/p&gt;
&lt;p&gt;Collins claimed that AI notes risked increasing the promotion of "lies and conspiracy theories" on X, and he wasn't the only expert sounding alarms. Samuel Stockwell, a research associate at the Centre for Emerging Technology and Security at the Alan Turing Institute, told The Guardian that X's success largely depends on "the quality of safeguards X puts in place against the risk that these AI ‘note writers’ could hallucinate and amplify misinformation in their outputs."&lt;/p&gt;
&lt;p&gt;"AI chatbots often struggle with nuance and context but are good at confidently providing answers that sound persuasive even when untrue," Stockwell said. "That could be a dangerous combination if not effectively addressed by the platform."&lt;/p&gt;
&lt;p&gt;Also complicating things: anyone can create an AI agent using any technology to write community notes, X's Community Notes account explained. That means that some AI agents may be more biased or defective than others.&lt;/p&gt;
&lt;p&gt;If this dystopian version of events occurs, X predicts that human writers may get sick of writing notes, threatening the diversity of viewpoints that made community notes so trustworthy to begin with.&lt;/p&gt;
&lt;p&gt;And for any human writers and reviewers who stick around, it's possible that the sheer volume of AI-written notes may overload them. Andy Dudfield, the head of AI at a UK fact-checking organization called Full Fact, told The Guardian that X risks "increasing the already significant burden on human reviewers to check even more draft notes, opening the door to a worrying and plausible situation in which notes could be drafted, reviewed, and published entirely by AI without the careful consideration that human input provides."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X is planning more research to ensure the "human rating capacity can sufficiently scale," but if it cannot solve this riddle, it knows "the impact of the most genuinely critical notes" risks being diluted.&lt;/p&gt;
&lt;p&gt;One possible solution to this "bottleneck," researchers noted, would be to remove the human review process and apply AI-written notes in "similar contexts" that human raters have previously approved. But the biggest potential downfall there is obvious.&lt;/p&gt;
&lt;p&gt;"Automatically matching notes to posts that people do not think need them could significantly undermine trust in the system," X's paper acknowledged.&lt;/p&gt;
&lt;p&gt;Ultimately, AI note writers on X may be deemed an "erroneous" tool, researchers admitted, but they're going ahead with testing to find out.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI-written notes will start posting this month&lt;/h2&gt;
&lt;p&gt;All AI-written community notes "will be clearly marked for users," X's Community Notes account said. The first AI notes will only appear on posts where people have requested a note, the account said, but eventually AI note writers could be allowed to select posts for fact-checking.&lt;/p&gt;
&lt;p&gt;More will be revealed when AI-written notes start appearing on X later this month, but in the meantime, X users can start testing AI note writers today and soon be considered for admission in the initial cohort of AI agents. (If any Ars readers end up testing out an AI note writer, this Ars writer would be curious to learn more about your experience.)&lt;/p&gt;
&lt;p&gt;For its research, X collaborated with post-graduate students, research affiliates, and professors investigating topics like human trust in AI, fine-tuning AI, and AI safety at Harvard University, the Massachusetts Institute of Technology, Stanford University, and the University of Washington.&lt;/p&gt;
&lt;p&gt;Researchers agreed that "under certain circumstances," AI agents can "produce notes that are of similar quality to human-written notes—at a fraction of the time and effort." They suggested that more research is needed to overcome flagged risks to reap the benefits of what could be "a transformative opportunity" that "offers promise of dramatically increased scale and speed" of fact-checking on X.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If AI note writers "generate initial drafts that represent a wider range of perspectives than a single human writer typically could, the quality of community deliberation is improved from the start," the paper said.&lt;/p&gt;
&lt;h2&gt;Future of AI notes&lt;/h2&gt;
&lt;p&gt;Researchers imagine that once X's testing is completed, AI note writers could not just aid in researching problematic posts flagged by human users, but also one day select posts predicted to go viral and stop misinformation from spreading faster than human reviewers could.&lt;/p&gt;
&lt;p&gt;Additional perks from this automated system, they suggested, would include X note raters quickly accessing more thorough research and evidence synthesis, as well as clearer note composition, which could speed up the rating process.&lt;/p&gt;
&lt;p&gt;And perhaps one day, AI agents could even learn to predict rating scores to speed things up even more, researchers speculated. However, more research would be needed to ensure that wouldn't homogenize community notes, buffing them out to the point that no one reads them.&lt;/p&gt;
&lt;p&gt;Perhaps the most Musk-ian of ideas proposed in the paper, is a notion of training AI note writers with clashing views to "adversarially debate the merits of a note." Supposedly, that "could help instantly surface potential flaws, hidden biases, or fabricated evidence, empowering the human rater to make a more informed judgment."&lt;/p&gt;
&lt;p&gt;"Instead of starting from scratch, the rater now plays the role of an adjudicator—evaluating a structured clash of arguments," the paper said.&lt;/p&gt;
&lt;p&gt;While X may be moving to reduce the workload for X users writing community notes, it's clear that AI could never replace humans, researchers said. Those humans are necessary for more than just rubber-stamping AI-written notes.&lt;/p&gt;
&lt;p&gt;Human notes that are "written from scratch" are valuable to train the AI agents and some raters' niche expertise cannot easily be replicated, the paper said. And perhaps most obviously, humans "are uniquely positioned to identify deficits or biases" and therefore more likely to be compelled to write notes "on topics the automated writers overlook," such as spam or scams.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        X says AI can supercharge community notes, but that comes with obvious risks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="376" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1760687083-640x376.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1760687083-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Elon Musk's X arguably revolutionized social media fact-checking by rolling out "community notes," which created a system to crowdsource diverse views on whether certain X posts were trustworthy or not.&lt;/p&gt;
&lt;p&gt;But now, the platform plans to allow AI to write community notes, and that could potentially ruin whatever trust X users had in the fact-checking system—which X has fully acknowledged.&lt;/p&gt;
&lt;p&gt;In a research paper, X described the initiative as an "upgrade" while explaining everything that could possibly go wrong with AI-written community notes.&lt;/p&gt;
&lt;p&gt;In an ideal world, X described AI agents that speed up and increase the number of community notes added to incorrect posts, ramping up fact-checking efforts platform-wide. Each AI-written note will be rated by a human reviewer, providing feedback that makes the AI agent better at writing notes the longer this feedback loop cycles. As the AI agents get better at writing notes, that leaves human reviewers to focus on more nuanced fact-checking that AI cannot quickly address, such as posts requiring niche expertise or social awareness. Together, the human and AI reviewers, if all goes well, could transform not just X's fact-checking, X's paper suggested, but also potentially provide "a blueprint for a new form of human-AI collaboration in the production of public knowledge."&lt;/p&gt;
&lt;p&gt;Among key questions that remain, however, is a big one: X isn't sure if AI-written notes will be as accurate as notes written by humans. Complicating that further, it seems likely that AI agents could generate "persuasive but inaccurate notes," which human raters might rate as helpful since AI is "exceptionally skilled at crafting persuasive, emotionally resonant, and seemingly neutral notes." That could disrupt the feedback loop, watering down community notes and making the whole system less trustworthy over time, X's research paper warned.&lt;/p&gt;
&lt;p&gt;"If rated helpfulness isn’t perfectly correlated with accuracy, then highly polished but misleading notes could be more likely to pass the approval threshold," the paper said. "This risk could grow as LLMs advance; they could not only write persuasively but also more easily research and construct a seemingly robust body of evidence for nearly any claim, regardless of its veracity, making it even harder for human raters to spot deception or errors."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X is already facing criticism over its AI plans. On Tuesday, former United Kingdom technology minister, Damian Collins, accused X of building a system that could allow "the industrial manipulation of what people see and decide to trust" on a platform with more than 600 million users, The Guardian reported.&lt;/p&gt;
&lt;p&gt;Collins claimed that AI notes risked increasing the promotion of "lies and conspiracy theories" on X, and he wasn't the only expert sounding alarms. Samuel Stockwell, a research associate at the Centre for Emerging Technology and Security at the Alan Turing Institute, told The Guardian that X's success largely depends on "the quality of safeguards X puts in place against the risk that these AI ‘note writers’ could hallucinate and amplify misinformation in their outputs."&lt;/p&gt;
&lt;p&gt;"AI chatbots often struggle with nuance and context but are good at confidently providing answers that sound persuasive even when untrue," Stockwell said. "That could be a dangerous combination if not effectively addressed by the platform."&lt;/p&gt;
&lt;p&gt;Also complicating things: anyone can create an AI agent using any technology to write community notes, X's Community Notes account explained. That means that some AI agents may be more biased or defective than others.&lt;/p&gt;
&lt;p&gt;If this dystopian version of events occurs, X predicts that human writers may get sick of writing notes, threatening the diversity of viewpoints that made community notes so trustworthy to begin with.&lt;/p&gt;
&lt;p&gt;And for any human writers and reviewers who stick around, it's possible that the sheer volume of AI-written notes may overload them. Andy Dudfield, the head of AI at a UK fact-checking organization called Full Fact, told The Guardian that X risks "increasing the already significant burden on human reviewers to check even more draft notes, opening the door to a worrying and plausible situation in which notes could be drafted, reviewed, and published entirely by AI without the careful consideration that human input provides."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X is planning more research to ensure the "human rating capacity can sufficiently scale," but if it cannot solve this riddle, it knows "the impact of the most genuinely critical notes" risks being diluted.&lt;/p&gt;
&lt;p&gt;One possible solution to this "bottleneck," researchers noted, would be to remove the human review process and apply AI-written notes in "similar contexts" that human raters have previously approved. But the biggest potential downfall there is obvious.&lt;/p&gt;
&lt;p&gt;"Automatically matching notes to posts that people do not think need them could significantly undermine trust in the system," X's paper acknowledged.&lt;/p&gt;
&lt;p&gt;Ultimately, AI note writers on X may be deemed an "erroneous" tool, researchers admitted, but they're going ahead with testing to find out.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI-written notes will start posting this month&lt;/h2&gt;
&lt;p&gt;All AI-written community notes "will be clearly marked for users," X's Community Notes account said. The first AI notes will only appear on posts where people have requested a note, the account said, but eventually AI note writers could be allowed to select posts for fact-checking.&lt;/p&gt;
&lt;p&gt;More will be revealed when AI-written notes start appearing on X later this month, but in the meantime, X users can start testing AI note writers today and soon be considered for admission in the initial cohort of AI agents. (If any Ars readers end up testing out an AI note writer, this Ars writer would be curious to learn more about your experience.)&lt;/p&gt;
&lt;p&gt;For its research, X collaborated with post-graduate students, research affiliates, and professors investigating topics like human trust in AI, fine-tuning AI, and AI safety at Harvard University, the Massachusetts Institute of Technology, Stanford University, and the University of Washington.&lt;/p&gt;
&lt;p&gt;Researchers agreed that "under certain circumstances," AI agents can "produce notes that are of similar quality to human-written notes—at a fraction of the time and effort." They suggested that more research is needed to overcome flagged risks to reap the benefits of what could be "a transformative opportunity" that "offers promise of dramatically increased scale and speed" of fact-checking on X.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If AI note writers "generate initial drafts that represent a wider range of perspectives than a single human writer typically could, the quality of community deliberation is improved from the start," the paper said.&lt;/p&gt;
&lt;h2&gt;Future of AI notes&lt;/h2&gt;
&lt;p&gt;Researchers imagine that once X's testing is completed, AI note writers could not just aid in researching problematic posts flagged by human users, but also one day select posts predicted to go viral and stop misinformation from spreading faster than human reviewers could.&lt;/p&gt;
&lt;p&gt;Additional perks from this automated system, they suggested, would include X note raters quickly accessing more thorough research and evidence synthesis, as well as clearer note composition, which could speed up the rating process.&lt;/p&gt;
&lt;p&gt;And perhaps one day, AI agents could even learn to predict rating scores to speed things up even more, researchers speculated. However, more research would be needed to ensure that wouldn't homogenize community notes, buffing them out to the point that no one reads them.&lt;/p&gt;
&lt;p&gt;Perhaps the most Musk-ian of ideas proposed in the paper, is a notion of training AI note writers with clashing views to "adversarially debate the merits of a note." Supposedly, that "could help instantly surface potential flaws, hidden biases, or fabricated evidence, empowering the human rater to make a more informed judgment."&lt;/p&gt;
&lt;p&gt;"Instead of starting from scratch, the rater now plays the role of an adjudicator—evaluating a structured clash of arguments," the paper said.&lt;/p&gt;
&lt;p&gt;While X may be moving to reduce the workload for X users writing community notes, it's clear that AI could never replace humans, researchers said. Those humans are necessary for more than just rubber-stamping AI-written notes.&lt;/p&gt;
&lt;p&gt;Human notes that are "written from scratch" are valuable to train the AI agents and some raters' niche expertise cannot easily be replicated, the paper said. And perhaps most obviously, humans "are uniquely positioned to identify deficits or biases" and therefore more likely to be compelled to write notes "on topics the automated writers overlook," such as spam or scams.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/everything-that-could-go-wrong-with-xs-new-ai-written-community-notes/</guid><pubDate>Wed, 02 Jul 2025 21:00:39 +0000</pubDate></item><item><title>[NEW] TikTok is being flooded with racist AI videos generated by Google’s Veo 3 (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/racist-ai-videos-created-with-google-veo-3-are-proliferating-on-tiktok/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google and TikTok have rules against this sort of thing, but it doesn't seem to matter.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A TikTok app icon on a phone screen." class="absolute inset-0 w-full h-full object-cover hidden" height="188" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-300x188.jpg" width="300" /&gt;
                  &lt;img alt="A TikTok app icon on a phone screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Chesnot 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The release of Google's Veo 3 video generator in May represented a disconcerting leap in AI video quality. While many of the viral AI videos we've seen are harmless fun, the model's pixel-perfect output can also be used for nefarious purposes. On TikTok, which may or may not be banned in the coming months, users have noticed a surplus of racist AI videos, courtesy of Google's Veo 3.&lt;/p&gt;
&lt;p&gt;According to a report from MediaMatters, numerous TikTok accounts have started posting AI-generated videos that use racist and antisemitic tropes in recent weeks. Most of the AI vitriol is aimed at Black people, depicting them as "the usual suspects" in crimes, absent parents, and monkeys with an affinity for watermelon. The content also targets immigrants and Jewish people. The videos top out at eight seconds and bear the "Veo" watermark, confirming they came from Google's leading AI model.&lt;/p&gt;
&lt;p&gt;The compilation video below has examples pulled from TikTok since the release of Veo 3, but be warned, it contains racist and antisemitic content. Some of the videos are shocking, which is likely the point—nothing drives engagement on social media like anger and drama. MediaMatters reports that the original posts have numerous comments echoing the stereotypes used in the video.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hateful AI videos generated by Veo 3 spreading on TikTok.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google has stressed security when announcing new AI models—we've all seen an AI refuse to complete a task that runs afoul of its guardrails. And it's never fun when you have genuinely harmless intentions, but the system throws a false positive and blocks your output. Google has mostly struck the right balance previously, but it appears that Veo 3 is more compliant. We've tested a few simple prompts with Veo 3 and found it easy to reproduce elements of these videos.&lt;/p&gt;
&lt;h2&gt;Clear but unenforced policies&lt;/h2&gt;
&lt;p&gt;TikTok's terms of service ban this kind of content. "We do not allow any hate speech, hateful behavior, or promotion of hateful ideologies. This includes explicit or implicit content that attacks a protected group," the community guidelines read. Despite this blanket ban on racist caricatures, the hateful Veo 3 videos appear to be spreading unchecked.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;TikTok notes that it uses both technology and human moderators to identify rule-breaking content. However, the volume of uploads makes timely moderation difficult. While the racist videos racked up a lot of views, a TikTok spokesperson tells Ars that more than half of the accounts cited in the MediaMatters report were banned for policy violations before the report was published, and the remainder have now been removed.&lt;/p&gt;
&lt;p&gt;As for Google, it has a comprehensive Prohibited Use Policy that bans the use of its services to promote hate speech, harassment, bullying, intimidation, and abuse. The videos uncovered by MediaMatters all seem to fall under one or more of these categories. In a perfect world, Veo 3 would refuse to create these videos, but vagueness in the prompt and the AI's inability to understand the subtleties of racist tropes (i.e., the use of monkeys instead of humans in some videos) make it easy to skirt the rules.&lt;/p&gt;
&lt;p&gt;TikTok, being the world's leading social video behemoth, is a natural place for these videos to spread. It's not exclusive to TikTok, though. X (formerly Twitter) has gained a reputation for very limited moderation, leading to an explosion of hateful AI content. This problem could also get worse very soon. Google has plans to integrate Veo 3 into YouTube Shorts, which could make it even easier for similar content to spread on YouTube.&lt;/p&gt;
&lt;p&gt;TikTok and Google have clear prohibitions on this content, which should have prevented it from being seen millions of times on social media. Enforcement of those policies, however, is lacking. TikTok is seemingly unable to keep up with the flood of video uploads, and Google's guardrails appear insufficient to block the creation of this content. We've reached out to Google to inquire about Veo 3's safety features but have not yet heard back.&lt;/p&gt;
&lt;p&gt;For as long as generative AI has existed, people have used it to create inflammatory and racist content. Google and others always talk about the guardrails to prevent misuse, but they can't catch everything. The realism of Veo 3 makes it especially attractive for those who want to spread hateful stereotypes. Maybe all the guardrails in the world won't stop that.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google and TikTok have rules against this sort of thing, but it doesn't seem to matter.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A TikTok app icon on a phone screen." class="absolute inset-0 w-full h-full object-cover hidden" height="188" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-300x188.jpg" width="300" /&gt;
                  &lt;img alt="A TikTok app icon on a phone screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Chesnot 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The release of Google's Veo 3 video generator in May represented a disconcerting leap in AI video quality. While many of the viral AI videos we've seen are harmless fun, the model's pixel-perfect output can also be used for nefarious purposes. On TikTok, which may or may not be banned in the coming months, users have noticed a surplus of racist AI videos, courtesy of Google's Veo 3.&lt;/p&gt;
&lt;p&gt;According to a report from MediaMatters, numerous TikTok accounts have started posting AI-generated videos that use racist and antisemitic tropes in recent weeks. Most of the AI vitriol is aimed at Black people, depicting them as "the usual suspects" in crimes, absent parents, and monkeys with an affinity for watermelon. The content also targets immigrants and Jewish people. The videos top out at eight seconds and bear the "Veo" watermark, confirming they came from Google's leading AI model.&lt;/p&gt;
&lt;p&gt;The compilation video below has examples pulled from TikTok since the release of Veo 3, but be warned, it contains racist and antisemitic content. Some of the videos are shocking, which is likely the point—nothing drives engagement on social media like anger and drama. MediaMatters reports that the original posts have numerous comments echoing the stereotypes used in the video.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hateful AI videos generated by Veo 3 spreading on TikTok.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google has stressed security when announcing new AI models—we've all seen an AI refuse to complete a task that runs afoul of its guardrails. And it's never fun when you have genuinely harmless intentions, but the system throws a false positive and blocks your output. Google has mostly struck the right balance previously, but it appears that Veo 3 is more compliant. We've tested a few simple prompts with Veo 3 and found it easy to reproduce elements of these videos.&lt;/p&gt;
&lt;h2&gt;Clear but unenforced policies&lt;/h2&gt;
&lt;p&gt;TikTok's terms of service ban this kind of content. "We do not allow any hate speech, hateful behavior, or promotion of hateful ideologies. This includes explicit or implicit content that attacks a protected group," the community guidelines read. Despite this blanket ban on racist caricatures, the hateful Veo 3 videos appear to be spreading unchecked.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;TikTok notes that it uses both technology and human moderators to identify rule-breaking content. However, the volume of uploads makes timely moderation difficult. While the racist videos racked up a lot of views, a TikTok spokesperson tells Ars that more than half of the accounts cited in the MediaMatters report were banned for policy violations before the report was published, and the remainder have now been removed.&lt;/p&gt;
&lt;p&gt;As for Google, it has a comprehensive Prohibited Use Policy that bans the use of its services to promote hate speech, harassment, bullying, intimidation, and abuse. The videos uncovered by MediaMatters all seem to fall under one or more of these categories. In a perfect world, Veo 3 would refuse to create these videos, but vagueness in the prompt and the AI's inability to understand the subtleties of racist tropes (i.e., the use of monkeys instead of humans in some videos) make it easy to skirt the rules.&lt;/p&gt;
&lt;p&gt;TikTok, being the world's leading social video behemoth, is a natural place for these videos to spread. It's not exclusive to TikTok, though. X (formerly Twitter) has gained a reputation for very limited moderation, leading to an explosion of hateful AI content. This problem could also get worse very soon. Google has plans to integrate Veo 3 into YouTube Shorts, which could make it even easier for similar content to spread on YouTube.&lt;/p&gt;
&lt;p&gt;TikTok and Google have clear prohibitions on this content, which should have prevented it from being seen millions of times on social media. Enforcement of those policies, however, is lacking. TikTok is seemingly unable to keep up with the flood of video uploads, and Google's guardrails appear insufficient to block the creation of this content. We've reached out to Google to inquire about Veo 3's safety features but have not yet heard back.&lt;/p&gt;
&lt;p&gt;For as long as generative AI has existed, people have used it to create inflammatory and racist content. Google and others always talk about the guardrails to prevent misuse, but they can't catch everything. The realism of Veo 3 makes it especially attractive for those who want to spread hateful stereotypes. Maybe all the guardrails in the world won't stop that.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/racist-ai-videos-created-with-google-veo-3-are-proliferating-on-tiktok/</guid><pubDate>Wed, 02 Jul 2025 21:18:08 +0000</pubDate></item><item><title>[NEW] Wonder Dynamics co-founder Nikola Todorovic joins the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/wonder-dynamics-co-founder-nikola-todorovic-joins-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is back at Moscone West in San Francisco from October 27–29, bringing together 10,000+ startup and VC leaders to dig into what’s next in tech. And when it comes to artificial intelligence, the conversations aren’t just technical — they’re creative, cinematic, and boundary-pushing. That’s why Nikola Todorovic is headed to the AI Stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A visual effects veteran turned AI entrepreneur, Todorovic is the co-founder of Wonder Dynamics, now an Autodesk company. Alongside actor and producer Tye Sheridan, he helped launch Autodesk Flow Studio (formerly Wonder Studio), a groundbreaking AI platform that allows creators to seamlessly integrate 3D characters into live-action scenes. The platform uses cloud-based tools to automate complex processes like lighting, animation, and composition, giving filmmakers a radically faster and more accessible path to high-end visual effects.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Nikola Todorovic" class="wp-image-3024452" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_Nikola-Todorovic-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-where-film-meets-ai"&gt;Where film meets AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Todorovic’s journey to this moment wasn’t traditional, but that’s exactly the point. As an award-winning filmmaker and VFX supervisor, he spent years working at the intersection of storytelling and technology. That experience led to Wonder Dynamics, where the mission has always been to empower artists, not replace them. The company’s acquisition by Autodesk in 2024 marked a major validation of that vision, and now Todorovic is helping shape the future of creative AI inside one of the industry’s biggest ecosystems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At Disrupt, he’ll join &lt;strong&gt;other AI industry leaders&lt;/strong&gt; for a wide-ranging panel on what’s coming next — from generative tools to ethical design to the future of creator workflows. Stay tuned to the fast-growing &lt;strong&gt;Disrupt agenda page&lt;/strong&gt; for the latest updates. Expect a conversation in Todorovic’s session that spans beyond buzzwords and dives into the real-world impact of AI in media and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000 other tech and VC leaders on the AI Stage at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; to hear from Nikola Todorovic and other top voices driving the future of artificial intelligence. It’s all happening October 27–29 at Moscone West in San Francisco. Lock in your spot today and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices go up.&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is back at Moscone West in San Francisco from October 27–29, bringing together 10,000+ startup and VC leaders to dig into what’s next in tech. And when it comes to artificial intelligence, the conversations aren’t just technical — they’re creative, cinematic, and boundary-pushing. That’s why Nikola Todorovic is headed to the AI Stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A visual effects veteran turned AI entrepreneur, Todorovic is the co-founder of Wonder Dynamics, now an Autodesk company. Alongside actor and producer Tye Sheridan, he helped launch Autodesk Flow Studio (formerly Wonder Studio), a groundbreaking AI platform that allows creators to seamlessly integrate 3D characters into live-action scenes. The platform uses cloud-based tools to automate complex processes like lighting, animation, and composition, giving filmmakers a radically faster and more accessible path to high-end visual effects.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Nikola Todorovic" class="wp-image-3024452" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_Nikola-Todorovic-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-where-film-meets-ai"&gt;Where film meets AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Todorovic’s journey to this moment wasn’t traditional, but that’s exactly the point. As an award-winning filmmaker and VFX supervisor, he spent years working at the intersection of storytelling and technology. That experience led to Wonder Dynamics, where the mission has always been to empower artists, not replace them. The company’s acquisition by Autodesk in 2024 marked a major validation of that vision, and now Todorovic is helping shape the future of creative AI inside one of the industry’s biggest ecosystems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At Disrupt, he’ll join &lt;strong&gt;other AI industry leaders&lt;/strong&gt; for a wide-ranging panel on what’s coming next — from generative tools to ethical design to the future of creator workflows. Stay tuned to the fast-growing &lt;strong&gt;Disrupt agenda page&lt;/strong&gt; for the latest updates. Expect a conversation in Todorovic’s session that spans beyond buzzwords and dives into the real-world impact of AI in media and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000 other tech and VC leaders on the AI Stage at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; to hear from Nikola Todorovic and other top voices driving the future of artificial intelligence. It’s all happening October 27–29 at Moscone West in San Francisco. Lock in your spot today and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices go up.&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/wonder-dynamics-co-founder-nikola-todorovic-joins-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 02 Jul 2025 23:10:00 +0000</pubDate></item><item><title>[NEW] OpenAI condemns Robinhood’s ‘OpenAI tokens’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/02/openai-condemns-robinhoods-openai-tokens/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1934195443-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI wants to make clear that Robinhood’s sale of “OpenAI tokens” will not give everyday consumers equity — or stock — in OpenAI, the company said in a post from its official newsroom account on X. OpenAI says it does not endorse Robinhood’s effort, nor was it involved in facilitating the token sale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These ‘OpenAI tokens’ are not OpenAI equity,” said OpenAI’s newsroom account on Wednesday. “We did not partner with Robinhood, were not involved in this, and do not endorse it.&amp;nbsp;Any transfer of OpenAI equity requires our approval—we did not approve any transfer. Please be careful.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;These “OpenAI tokens” are not OpenAI equity. We did not partner with Robinhood, were not involved in this, and do not endorse it.&amp;nbsp; Any transfer of OpenAI equity requires our approval—we did not approve any transfer. &lt;/p&gt;&lt;p&gt;Please be careful.&lt;/p&gt;— OpenAI Newsroom (@OpenAINewsroom) July 2, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s statement is a response to Robinhood’s announcement earlier this week that it would start selling  so-called tokenized shares of OpenAI, SpaceX, and other private companies to people in the European Union.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Robinhood says the launch represents an attempt to give everyday people exposure to equity in the world’s most valuable private companies via blockchain. Hours after announcing these token sales, Robinhood’s stock price shot to an all-time high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But stock in private companies like OpenAI and SpaceX are not available to the public. That’s what makes them private. They sell shares to investors of their choosing. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So OpenAI is openly disavowing Robinhood’s effort. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to OpenAI’s condemnation, Robinhood spokesperson Rouky Diallo told TechCrunch that OpenAI tokens were part of a “limited” giveaway to offer retail investors indirect exposure “through Robinhood’s ownership stake in a special purpose vehicle (SPV).”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;That suggests Robinhood owns shares of an SPV that controls a certain number of OpenAI’s shares. Like the tokens, shares of SPVs are not direct ownership of shares, either. They are ownership in a vehicle that owns the shares. In one way or another, Robinhood seems to be tying the price of its new tokenized product to the OpenAI shares in that SPV. But shares prices in an SPV can also differ from prices of an actual share of stock.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Robinhood’s help center, the company notes that when buying any of its stock tokens, “you are not buying the actual stocks — you are buying tokenized contracts that follow their price, recorded on a blockchain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While it is true that they aren’t technically ‘equity,’&amp;nbsp;[…] the tokens effectively give retail investors exposure to these private assets,” said Robinhood CEO Vlad Tenev in a post on X on Wednesday. “Our giveaway plants a seed for something much bigger, and since our announcement we’ve been hearing from many private companies that are eager to join us in the tokenization revolution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined to comment further. Robinhood did not respond to TechCrunch’s additional questions about its SPV.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Private companies are known to push back against anything that could influence how their equity is valued. In recent months, humanoid robotics startup Figure AI sent cease-and-desist letters to two brokers running secondary markets that were marketing the company’s stock. Of course, these situations are different, but most startups don’t want people to believe that they’ve authorized share sales if they haven’t.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1934195443-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI wants to make clear that Robinhood’s sale of “OpenAI tokens” will not give everyday consumers equity — or stock — in OpenAI, the company said in a post from its official newsroom account on X. OpenAI says it does not endorse Robinhood’s effort, nor was it involved in facilitating the token sale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These ‘OpenAI tokens’ are not OpenAI equity,” said OpenAI’s newsroom account on Wednesday. “We did not partner with Robinhood, were not involved in this, and do not endorse it.&amp;nbsp;Any transfer of OpenAI equity requires our approval—we did not approve any transfer. Please be careful.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;These “OpenAI tokens” are not OpenAI equity. We did not partner with Robinhood, were not involved in this, and do not endorse it.&amp;nbsp; Any transfer of OpenAI equity requires our approval—we did not approve any transfer. &lt;/p&gt;&lt;p&gt;Please be careful.&lt;/p&gt;— OpenAI Newsroom (@OpenAINewsroom) July 2, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s statement is a response to Robinhood’s announcement earlier this week that it would start selling  so-called tokenized shares of OpenAI, SpaceX, and other private companies to people in the European Union.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Robinhood says the launch represents an attempt to give everyday people exposure to equity in the world’s most valuable private companies via blockchain. Hours after announcing these token sales, Robinhood’s stock price shot to an all-time high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But stock in private companies like OpenAI and SpaceX are not available to the public. That’s what makes them private. They sell shares to investors of their choosing. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So OpenAI is openly disavowing Robinhood’s effort. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to OpenAI’s condemnation, Robinhood spokesperson Rouky Diallo told TechCrunch that OpenAI tokens were part of a “limited” giveaway to offer retail investors indirect exposure “through Robinhood’s ownership stake in a special purpose vehicle (SPV).”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;That suggests Robinhood owns shares of an SPV that controls a certain number of OpenAI’s shares. Like the tokens, shares of SPVs are not direct ownership of shares, either. They are ownership in a vehicle that owns the shares. In one way or another, Robinhood seems to be tying the price of its new tokenized product to the OpenAI shares in that SPV. But shares prices in an SPV can also differ from prices of an actual share of stock.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Robinhood’s help center, the company notes that when buying any of its stock tokens, “you are not buying the actual stocks — you are buying tokenized contracts that follow their price, recorded on a blockchain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While it is true that they aren’t technically ‘equity,’&amp;nbsp;[…] the tokens effectively give retail investors exposure to these private assets,” said Robinhood CEO Vlad Tenev in a post on X on Wednesday. “Our giveaway plants a seed for something much bigger, and since our announcement we’ve been hearing from many private companies that are eager to join us in the tokenization revolution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined to comment further. Robinhood did not respond to TechCrunch’s additional questions about its SPV.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Private companies are known to push back against anything that could influence how their equity is valued. In recent months, humanoid robotics startup Figure AI sent cease-and-desist letters to two brokers running secondary markets that were marketing the company’s stock. Of course, these situations are different, but most startups don’t want people to believe that they’ve authorized share sales if they haven’t.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/02/openai-condemns-robinhoods-openai-tokens/</guid><pubDate>Wed, 02 Jul 2025 23:43:27 +0000</pubDate></item></channel></rss>