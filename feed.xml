<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 19 Nov 2025 01:46:00 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>How AI tax startup Blue J torched its entire business model for ChatGPT—and became a $300 million company (AI | VentureBeat)</title><link>https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and</link><description>[unable to retrieve full-text content]&lt;p&gt;In the winter of 2022, as the tech world was becoming mesmerized by the sudden, explosive arrival of OpenAI’s ChatGPT, &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;Benjamin Alarie&lt;/u&gt;&lt;/a&gt; faced a pivotal choice. His legal tech startup, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt;, had a respectable business built on the AI of a bygone era, serving hundreds of law firms with predictive models. But it had hit a ceiling.&lt;/p&gt;&lt;p&gt;Alarie, a &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;tenured tax law professor&lt;/u&gt;&lt;/a&gt; at the &lt;a href="https://www.utoronto.ca/"&gt;&lt;u&gt;University of Toronto&lt;/u&gt;&lt;/a&gt;, saw the nascent, error-prone, yet powerful capabilities of large language models not as a curiosity, but as the future. He made a high-stakes decision: to pivot his entire company, which had been painstakingly built over nearly a decade, and rebuild it from the ground up on this unproven technology.&lt;/p&gt;&lt;p&gt;That bet has paid off handsomely. Blue J has since quietly secured a &lt;a href="https://finance.yahoo.com/news/blue-j-announces-122m-series-100000765.html"&gt;&lt;u&gt;$122 million Series D&lt;/u&gt;&lt;/a&gt; funding round co-led by &lt;a href="https://www.oakhcft.com/"&gt;&lt;u&gt;Oak HC/FT&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://sapphireventures.com/"&gt;&lt;u&gt;Sapphire Ventures&lt;/u&gt;&lt;/a&gt;, placing the company&amp;#x27;s valuation at &lt;a href="https://www.theglobeandmail.com/business/article-torontos-blue-j-legal-raises-167-million-as-demand-for-its-chatgpt/"&gt;&lt;u&gt;over $300 million&lt;/u&gt;&lt;/a&gt;. The move transformed Blue J from a niche player into one of Canada&amp;#x27;s fastest-growing legal tech firms, multiplying its revenue roughly twelve-fold and attracting 10 to 15 new customers every day.&lt;/p&gt;&lt;p&gt;The company now serves more than 3,500 organizations, including global accounting giant &lt;a href="https://kpmg.com/uk/en.html"&gt;&lt;u&gt;KPMG UK&lt;/u&gt;&lt;/a&gt; and several Fortune 500 companies. It is tackling a critical bottleneck in the professional services industry: a severe and worsening talent shortage. &lt;a href="https://www.kent.edu/business/accountant-shortage-united-states-everything-you-need-know"&gt;&lt;u&gt;The U.S. has 340,000 fewer accountants than it did five years ago&lt;/u&gt;&lt;/a&gt;, and with 75% of current CPAs expected to retire in the next decade, firms are desperate for tools that can amplify the productivity of their remaining experts.&lt;/p&gt;&lt;p&gt;“What once took tax professionals 15 hours of manual research to do can now be completed in about 15 seconds with Blue J,” Alarie, the company&amp;#x27;s CEO, said in an exclusive interview with VentureBeat. &amp;quot;That value proposition—we can take hours of work and turn it into seconds of work—that is driving a lot of this.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;When the dean&amp;#x27;s biography was wrong: the moment that changed everything&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alarie vividly remembers January 2023, when the dean of the law school stopped by his office for New Year&amp;#x27;s greetings. He asked her about ChatGPT and prompted the AI to describe her. ChatGPT confidently generated a biography. Some details were accurate. Others were completely fabricated.&lt;/p&gt;&lt;p&gt;&amp;quot;She was like, &amp;#x27;Okay, this is really kind of scary. This is wrong, and this has implications,&amp;#x27;&amp;quot; Alarie said. Yet that moment of obvious failure didn&amp;#x27;t deter him. Instead, it crystallized his conviction.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s first iteration, launched in 2015, used supervised machine learning to build predictive models that could forecast judicial outcomes on specific tax issues. While technically sophisticated, it had a fundamental flaw: it couldn&amp;#x27;t answer every tax research question.&lt;/p&gt;&lt;p&gt;&amp;quot;The challenge was it couldn&amp;#x27;t answer every tax research question, which was really the holy grail,&amp;quot; Alarie said. Customers loved the tool when it applied to their problem, but would quickly abandon it when it didn&amp;#x27;t. Revenue plateaued around $2 million annually.&lt;/p&gt;&lt;p&gt;Despite ChatGPT&amp;#x27;s notorious hallucinations, Alarie convinced his board to make the pivot. &amp;quot;I had this conviction that if we continued down that path, we weren&amp;#x27;t going to be able to address our number one limitation,&amp;quot; he said. &amp;quot;Large language models seemed like a very promising direction.&amp;quot;&lt;/p&gt;&lt;p&gt;He gave his team six months to deliver a working product.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 90-second responses to 3 million queries: How Blue J tamed AI hallucinations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;By August 2023, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; was ready to launch. What they released was, in Alarie&amp;#x27;s candid assessment, &amp;quot;super janky.&amp;quot; The system took 90 seconds to respond. About half the answers had issues. The &lt;a href="https://www.ibm.com/think/topics/net-promoter-score"&gt;&lt;u&gt;Net Promoter Score&lt;/u&gt;&lt;/a&gt; registered at just 20.&lt;/p&gt;&lt;p&gt;What transformed that flawed product into today&amp;#x27;s platform — with response times measured in seconds, a dissatisfaction rate of just one in 700 queries, and an NPS score in the mid-80s — was relentless focus on three strategic pillars.&lt;/p&gt;&lt;p&gt;First is proprietary content at massive scale. &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; secured exclusive licensing with &lt;a href="https://www.bluej.com/blog/tax-notes-news-and-commentaryin-ask-blue-j?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8gv8eN0VUk5K0KpOGKmC3M6H&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOaLxuKFmZR9otFp5M1er_t_p8gixKHhUXWCf4Lkky64zSQVl4l40QgaArObEALw_wcB"&gt;&lt;u&gt;Tax Analysts (Tax Notes)&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.businesswire.com/news/home/20250903168687/en/Blue-J-and-IBFD-Unveil-AI-Platform-for-Instant-Cross-Border-Tax-Research"&gt;&lt;u&gt;IBFD&lt;/u&gt;&lt;/a&gt;, the Amsterdam-based global tax authority covering 220+ jurisdictions. &amp;quot;We are the only platform on earth that takes in the best U.S. tax information from Tax Notes and the best global tax information from IBFD,&amp;quot; Alarie said.&lt;/p&gt;&lt;p&gt;Second is deep human expertise. Blue J employs tax experts led by &lt;a href="https://www.bluej.com/about-us"&gt;&lt;u&gt;Susan Massey&lt;/u&gt;&lt;/a&gt;, who spent 13 years at the &lt;a href="https://www.irs.gov/about-irs/office-of-chief-counsel-at-a-glance"&gt;&lt;u&gt;IRS Office of Chief Counsel&lt;/u&gt;&lt;/a&gt; as Branch Chief for Corporate Tax. Her team constantly tests the AI and refines its performance.&lt;/p&gt;&lt;p&gt;Third is an unprecedented feedback flywheel. With over 3 million tax research queries processed in 2025, Blue J is amassing unparalleled data. Each query generates feedback that flows back into the system.&lt;/p&gt;&lt;p&gt;Weekly active user rates hover between 75% and 85%, compared to 15% to 25% for traditional platforms. &amp;quot;A charitable ratio is like we&amp;#x27;re five times more intensively used,&amp;quot; Alarie noted.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Blue J&amp;#x27;s early access partnership with OpenAI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J maintains an &lt;a href="https://openai.com/index/blue-j/"&gt;&lt;u&gt;unusually close relationship with OpenAI&lt;/u&gt;&lt;/a&gt; that has proven crucial to its success. &amp;quot;We have a very good relationship with OpenAI, and we get early access to their models,&amp;quot;Alarie said. &amp;quot;It&amp;#x27;s quite collaborative. We give them a lot of really high quality feedback about how well different versions of forthcoming models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;This feedback proves valuable because Blue J has developed what Alarie calls &amp;quot;ecologically valid&amp;quot; test questions — drawn from actual tax professional queries, with correct answers determined by Blue J&amp;#x27;s expert team. This helps OpenAI improve performance on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;The company tests models from all major providers — &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://gemini.google.com/app"&gt;&lt;u&gt;Google&amp;#x27;s Gemini&lt;/u&gt;&lt;/a&gt;, and open-source alternatives — continuously evaluating which performs best. &amp;quot;We&amp;#x27;re not necessarily 100% committed to any particular provider,&amp;quot; he explained. &amp;quot;We&amp;#x27;re testing all the time.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach helps &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; navigate a challenging business model: charging approximately $1,500 per seat annually for unlimited queries while absorbing variable compute costs. &amp;quot;We&amp;#x27;ve pre-committed to delivering them a really good user experience, unlimited tax research answers at a fixed price,&amp;quot; Alarie said. &amp;quot;We&amp;#x27;re absorbing a lot of that risk.&amp;quot;&lt;/p&gt;&lt;p&gt;Competition among foundation model providers creates downward pressure on API pricing, while Blue J&amp;#x27;s conservative usage modeling has proven accurate. Gross revenue retention exceeds 99%, while net revenue retention reaches 130% — considered best-in-class for SaaS businesses.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taking on Thomson Reuters and LexisNexis with 75% weekly engagement&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; faces competition from established publishers like &lt;a href="https://www.thomsonreuters.com/en"&gt;&lt;u&gt;Thomson Reuters&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.lexisnexis.com/en-us/gateway.page"&gt;&lt;u&gt;LexisNexis&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://pro.bloombergtax.com/discover/bloomberg-tax-suite-demo-request/?trackingcode=BTSS24112987&amp;amp;utm_medium=paidsearch&amp;amp;utm_source=google&amp;amp;keyword=bloomberg%20tax&amp;amp;matchtype=e&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=9457544822&amp;amp;gbraid=0AAAAAD_kFA38giYJV5mEqqUUM_e_Bd11j&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOYA_YF4kYIxnHQPMofjBCuaKzvTAwp3cwxeBIaIyG6nGY9ni0tVn28aAqE0EALw_wcB"&gt;&lt;u&gt;Bloomberg&lt;/u&gt;&lt;/a&gt;, all of which announced AI capabilities throughout 2023 and 2024. Yet Blue J&amp;#x27;s engagement metrics suggest it has captured significant momentum, growing from just 200 customers in 2021 to over 3,500 organizations today.&lt;/p&gt;&lt;p&gt;The daily updates prove crucial. While the tax code itself changes only when Congress acts, the ecosystem evolves constantly through IRS regulations, new rulings, and court cases. All 50 states modify their tax codes regularly.&lt;/p&gt;&lt;p&gt;&amp;quot;Things are changing literally every day,&amp;quot; Alarie said. &amp;quot;Every day we&amp;#x27;re updating the materials, and that&amp;#x27;s just the U.S. We cover Canada, we cover the UK. The aspirations are truly global for this thing.&amp;quot;&lt;/p&gt;&lt;p&gt;Alarie&amp;#x27;s ambitions extend beyond building a successful startup. As author of the award-winning book &amp;quot;&lt;a href="https://www.bluej.com/blog/the-legal-singularity-a-vision-of-ai-driven-legal-systems?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8iHj3mHQ1PxHjT5IGoPk6hS3&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOY12FNLsxFtKsY3CynN6nBeW43r0qystVycPX4N7qFSfk51y-MYkY4aAhHuEALw_wcB"&gt;&lt;u&gt;The Legal Singularity&lt;/u&gt;&lt;/a&gt;&amp;quot; and faculty affiliate at the &lt;a href="https://vectorinstitute.ai/"&gt;&lt;u&gt;Vector Institute for Artificial Intelligence&lt;/u&gt;&lt;/a&gt;, he has spent years contemplating AI&amp;#x27;s long-term impact on law.&lt;/p&gt;&lt;p&gt;In academic papers published in Tax Notes throughout &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4476510"&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730883"&gt;&lt;u&gt;2024&lt;/u&gt;&lt;/a&gt;, he chronicled generative AI&amp;#x27;s rise, predicting that &amp;quot;clients will become substantially more sophisticated&amp;quot; and that AI would push human experts toward higher-value strategic roles rather than routine research.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Blue J&amp;#x27;s $122 million plan: From tax research to &amp;#x27;global tax cognition&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;a href="https://www.bluej.com/blog/blue-j-announces-122m-series-d-financing-led-by-oak-hc-ft-and-sapphire-ventures"&gt;&lt;u&gt;Series D funding&lt;/u&gt;&lt;/a&gt;, which brought total capital raised to over $133 million, will fuel aggressive geographic and product expansion. Blue J already operates in the U.S., Canada, and the U.K., with plans to eventually cover 220+ jurisdictions through its IBFD partnership.&lt;/p&gt;&lt;p&gt;Future capabilities could include automated memo generation, tax form completion, document drafting, and conversational history maintaining context across sessions—transforming Blue J from a research tool into what Alarie describes as &amp;quot;the operating layer for global tax cognition.&amp;quot;&lt;/p&gt;&lt;p&gt;For all its success, Blue J operates in a domain where errors carry serious consequences. The hallucination problem hasn&amp;#x27;t been eliminated — it&amp;#x27;s been minimized through careful engineering, content curation, and human oversight. Blue J has trained its models to acknowledge when they cannot answer a question rather than fabricate information.&lt;/p&gt;&lt;p&gt;The business also faces economic risks if compute costs spiral or usage patterns exceed projections. And subtler questions loom about professional judgment: as AI systems become more capable, will users defer to outputs without sufficient critical evaluation?&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 15 hours to 15 seconds: What Blue J&amp;#x27;s AI pivot teaches every industry&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J&amp;#x27;s transformation offers lessons beyond tax software. The company&amp;#x27;s willingness to abandon eight years of proprietary technology and rebuild on an initially unreliable foundation required both courage and calculated risk-taking.&lt;/p&gt;&lt;p&gt;The decision paid off not because generative AI was inherently superior to supervised machine learning in all dimensions, but because it addressed the right problem: comprehensiveness rather than precision in narrow domains. Tax professionals didn&amp;#x27;t need 95% accuracy on 5% of questions. They needed good-enough accuracy on 100% of questions.&lt;/p&gt;&lt;p&gt;The improvement from an NPS of 20 to 84 in just over two years reflects relentless iteration informed by massive data collection. The content partnerships created differentiation that pure technology couldn&amp;#x27;t replicate. The team of tax experts provided domain knowledge necessary to ensure reliability.&lt;/p&gt;&lt;p&gt;Most fundamentally, Blue J recognized that the real competition wasn&amp;#x27;t other AI startups or even established publishers. It was the old way of doing things — the 15 hours of manual research, the institutional knowledge locked in retiring professionals&amp;#x27; heads.&lt;/p&gt;&lt;p&gt;&amp;quot;People are like, &amp;#x27;What does Blue J do? They provide better tax answers. Okay, I think we need that,&amp;#x27;&amp;quot; Alarie reflected.&lt;/p&gt;&lt;p&gt;As AI transforms profession after profession, that clarity of purpose may matter more than technological sophistication. The future belongs not to those who build the most advanced AI, but to those who most effectively harness it to solve problems humans actually have.&lt;/p&gt;&lt;p&gt;For a tax law professor who started with frustration about inefficient research methods, building a $300 million company marks an audacious endpoint. For the thousands of professionals now answering complex questions in 15 seconds instead of 15 hours, it represents the future of their profession, arriving faster than most expected.&lt;/p&gt;&lt;p&gt;The bet on ChatGPT when it was still hallucinating biographies has become a validation that sometimes the riskiest move is not to move at all.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In the winter of 2022, as the tech world was becoming mesmerized by the sudden, explosive arrival of OpenAI’s ChatGPT, &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;Benjamin Alarie&lt;/u&gt;&lt;/a&gt; faced a pivotal choice. His legal tech startup, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt;, had a respectable business built on the AI of a bygone era, serving hundreds of law firms with predictive models. But it had hit a ceiling.&lt;/p&gt;&lt;p&gt;Alarie, a &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;tenured tax law professor&lt;/u&gt;&lt;/a&gt; at the &lt;a href="https://www.utoronto.ca/"&gt;&lt;u&gt;University of Toronto&lt;/u&gt;&lt;/a&gt;, saw the nascent, error-prone, yet powerful capabilities of large language models not as a curiosity, but as the future. He made a high-stakes decision: to pivot his entire company, which had been painstakingly built over nearly a decade, and rebuild it from the ground up on this unproven technology.&lt;/p&gt;&lt;p&gt;That bet has paid off handsomely. Blue J has since quietly secured a &lt;a href="https://finance.yahoo.com/news/blue-j-announces-122m-series-100000765.html"&gt;&lt;u&gt;$122 million Series D&lt;/u&gt;&lt;/a&gt; funding round co-led by &lt;a href="https://www.oakhcft.com/"&gt;&lt;u&gt;Oak HC/FT&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://sapphireventures.com/"&gt;&lt;u&gt;Sapphire Ventures&lt;/u&gt;&lt;/a&gt;, placing the company&amp;#x27;s valuation at &lt;a href="https://www.theglobeandmail.com/business/article-torontos-blue-j-legal-raises-167-million-as-demand-for-its-chatgpt/"&gt;&lt;u&gt;over $300 million&lt;/u&gt;&lt;/a&gt;. The move transformed Blue J from a niche player into one of Canada&amp;#x27;s fastest-growing legal tech firms, multiplying its revenue roughly twelve-fold and attracting 10 to 15 new customers every day.&lt;/p&gt;&lt;p&gt;The company now serves more than 3,500 organizations, including global accounting giant &lt;a href="https://kpmg.com/uk/en.html"&gt;&lt;u&gt;KPMG UK&lt;/u&gt;&lt;/a&gt; and several Fortune 500 companies. It is tackling a critical bottleneck in the professional services industry: a severe and worsening talent shortage. &lt;a href="https://www.kent.edu/business/accountant-shortage-united-states-everything-you-need-know"&gt;&lt;u&gt;The U.S. has 340,000 fewer accountants than it did five years ago&lt;/u&gt;&lt;/a&gt;, and with 75% of current CPAs expected to retire in the next decade, firms are desperate for tools that can amplify the productivity of their remaining experts.&lt;/p&gt;&lt;p&gt;“What once took tax professionals 15 hours of manual research to do can now be completed in about 15 seconds with Blue J,” Alarie, the company&amp;#x27;s CEO, said in an exclusive interview with VentureBeat. &amp;quot;That value proposition—we can take hours of work and turn it into seconds of work—that is driving a lot of this.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;When the dean&amp;#x27;s biography was wrong: the moment that changed everything&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alarie vividly remembers January 2023, when the dean of the law school stopped by his office for New Year&amp;#x27;s greetings. He asked her about ChatGPT and prompted the AI to describe her. ChatGPT confidently generated a biography. Some details were accurate. Others were completely fabricated.&lt;/p&gt;&lt;p&gt;&amp;quot;She was like, &amp;#x27;Okay, this is really kind of scary. This is wrong, and this has implications,&amp;#x27;&amp;quot; Alarie said. Yet that moment of obvious failure didn&amp;#x27;t deter him. Instead, it crystallized his conviction.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s first iteration, launched in 2015, used supervised machine learning to build predictive models that could forecast judicial outcomes on specific tax issues. While technically sophisticated, it had a fundamental flaw: it couldn&amp;#x27;t answer every tax research question.&lt;/p&gt;&lt;p&gt;&amp;quot;The challenge was it couldn&amp;#x27;t answer every tax research question, which was really the holy grail,&amp;quot; Alarie said. Customers loved the tool when it applied to their problem, but would quickly abandon it when it didn&amp;#x27;t. Revenue plateaued around $2 million annually.&lt;/p&gt;&lt;p&gt;Despite ChatGPT&amp;#x27;s notorious hallucinations, Alarie convinced his board to make the pivot. &amp;quot;I had this conviction that if we continued down that path, we weren&amp;#x27;t going to be able to address our number one limitation,&amp;quot; he said. &amp;quot;Large language models seemed like a very promising direction.&amp;quot;&lt;/p&gt;&lt;p&gt;He gave his team six months to deliver a working product.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 90-second responses to 3 million queries: How Blue J tamed AI hallucinations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;By August 2023, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; was ready to launch. What they released was, in Alarie&amp;#x27;s candid assessment, &amp;quot;super janky.&amp;quot; The system took 90 seconds to respond. About half the answers had issues. The &lt;a href="https://www.ibm.com/think/topics/net-promoter-score"&gt;&lt;u&gt;Net Promoter Score&lt;/u&gt;&lt;/a&gt; registered at just 20.&lt;/p&gt;&lt;p&gt;What transformed that flawed product into today&amp;#x27;s platform — with response times measured in seconds, a dissatisfaction rate of just one in 700 queries, and an NPS score in the mid-80s — was relentless focus on three strategic pillars.&lt;/p&gt;&lt;p&gt;First is proprietary content at massive scale. &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; secured exclusive licensing with &lt;a href="https://www.bluej.com/blog/tax-notes-news-and-commentaryin-ask-blue-j?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8gv8eN0VUk5K0KpOGKmC3M6H&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOaLxuKFmZR9otFp5M1er_t_p8gixKHhUXWCf4Lkky64zSQVl4l40QgaArObEALw_wcB"&gt;&lt;u&gt;Tax Analysts (Tax Notes)&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.businesswire.com/news/home/20250903168687/en/Blue-J-and-IBFD-Unveil-AI-Platform-for-Instant-Cross-Border-Tax-Research"&gt;&lt;u&gt;IBFD&lt;/u&gt;&lt;/a&gt;, the Amsterdam-based global tax authority covering 220+ jurisdictions. &amp;quot;We are the only platform on earth that takes in the best U.S. tax information from Tax Notes and the best global tax information from IBFD,&amp;quot; Alarie said.&lt;/p&gt;&lt;p&gt;Second is deep human expertise. Blue J employs tax experts led by &lt;a href="https://www.bluej.com/about-us"&gt;&lt;u&gt;Susan Massey&lt;/u&gt;&lt;/a&gt;, who spent 13 years at the &lt;a href="https://www.irs.gov/about-irs/office-of-chief-counsel-at-a-glance"&gt;&lt;u&gt;IRS Office of Chief Counsel&lt;/u&gt;&lt;/a&gt; as Branch Chief for Corporate Tax. Her team constantly tests the AI and refines its performance.&lt;/p&gt;&lt;p&gt;Third is an unprecedented feedback flywheel. With over 3 million tax research queries processed in 2025, Blue J is amassing unparalleled data. Each query generates feedback that flows back into the system.&lt;/p&gt;&lt;p&gt;Weekly active user rates hover between 75% and 85%, compared to 15% to 25% for traditional platforms. &amp;quot;A charitable ratio is like we&amp;#x27;re five times more intensively used,&amp;quot; Alarie noted.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Blue J&amp;#x27;s early access partnership with OpenAI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J maintains an &lt;a href="https://openai.com/index/blue-j/"&gt;&lt;u&gt;unusually close relationship with OpenAI&lt;/u&gt;&lt;/a&gt; that has proven crucial to its success. &amp;quot;We have a very good relationship with OpenAI, and we get early access to their models,&amp;quot;Alarie said. &amp;quot;It&amp;#x27;s quite collaborative. We give them a lot of really high quality feedback about how well different versions of forthcoming models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;This feedback proves valuable because Blue J has developed what Alarie calls &amp;quot;ecologically valid&amp;quot; test questions — drawn from actual tax professional queries, with correct answers determined by Blue J&amp;#x27;s expert team. This helps OpenAI improve performance on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;The company tests models from all major providers — &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://gemini.google.com/app"&gt;&lt;u&gt;Google&amp;#x27;s Gemini&lt;/u&gt;&lt;/a&gt;, and open-source alternatives — continuously evaluating which performs best. &amp;quot;We&amp;#x27;re not necessarily 100% committed to any particular provider,&amp;quot; he explained. &amp;quot;We&amp;#x27;re testing all the time.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach helps &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; navigate a challenging business model: charging approximately $1,500 per seat annually for unlimited queries while absorbing variable compute costs. &amp;quot;We&amp;#x27;ve pre-committed to delivering them a really good user experience, unlimited tax research answers at a fixed price,&amp;quot; Alarie said. &amp;quot;We&amp;#x27;re absorbing a lot of that risk.&amp;quot;&lt;/p&gt;&lt;p&gt;Competition among foundation model providers creates downward pressure on API pricing, while Blue J&amp;#x27;s conservative usage modeling has proven accurate. Gross revenue retention exceeds 99%, while net revenue retention reaches 130% — considered best-in-class for SaaS businesses.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taking on Thomson Reuters and LexisNexis with 75% weekly engagement&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; faces competition from established publishers like &lt;a href="https://www.thomsonreuters.com/en"&gt;&lt;u&gt;Thomson Reuters&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.lexisnexis.com/en-us/gateway.page"&gt;&lt;u&gt;LexisNexis&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://pro.bloombergtax.com/discover/bloomberg-tax-suite-demo-request/?trackingcode=BTSS24112987&amp;amp;utm_medium=paidsearch&amp;amp;utm_source=google&amp;amp;keyword=bloomberg%20tax&amp;amp;matchtype=e&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=9457544822&amp;amp;gbraid=0AAAAAD_kFA38giYJV5mEqqUUM_e_Bd11j&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOYA_YF4kYIxnHQPMofjBCuaKzvTAwp3cwxeBIaIyG6nGY9ni0tVn28aAqE0EALw_wcB"&gt;&lt;u&gt;Bloomberg&lt;/u&gt;&lt;/a&gt;, all of which announced AI capabilities throughout 2023 and 2024. Yet Blue J&amp;#x27;s engagement metrics suggest it has captured significant momentum, growing from just 200 customers in 2021 to over 3,500 organizations today.&lt;/p&gt;&lt;p&gt;The daily updates prove crucial. While the tax code itself changes only when Congress acts, the ecosystem evolves constantly through IRS regulations, new rulings, and court cases. All 50 states modify their tax codes regularly.&lt;/p&gt;&lt;p&gt;&amp;quot;Things are changing literally every day,&amp;quot; Alarie said. &amp;quot;Every day we&amp;#x27;re updating the materials, and that&amp;#x27;s just the U.S. We cover Canada, we cover the UK. The aspirations are truly global for this thing.&amp;quot;&lt;/p&gt;&lt;p&gt;Alarie&amp;#x27;s ambitions extend beyond building a successful startup. As author of the award-winning book &amp;quot;&lt;a href="https://www.bluej.com/blog/the-legal-singularity-a-vision-of-ai-driven-legal-systems?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8iHj3mHQ1PxHjT5IGoPk6hS3&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOY12FNLsxFtKsY3CynN6nBeW43r0qystVycPX4N7qFSfk51y-MYkY4aAhHuEALw_wcB"&gt;&lt;u&gt;The Legal Singularity&lt;/u&gt;&lt;/a&gt;&amp;quot; and faculty affiliate at the &lt;a href="https://vectorinstitute.ai/"&gt;&lt;u&gt;Vector Institute for Artificial Intelligence&lt;/u&gt;&lt;/a&gt;, he has spent years contemplating AI&amp;#x27;s long-term impact on law.&lt;/p&gt;&lt;p&gt;In academic papers published in Tax Notes throughout &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4476510"&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730883"&gt;&lt;u&gt;2024&lt;/u&gt;&lt;/a&gt;, he chronicled generative AI&amp;#x27;s rise, predicting that &amp;quot;clients will become substantially more sophisticated&amp;quot; and that AI would push human experts toward higher-value strategic roles rather than routine research.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Blue J&amp;#x27;s $122 million plan: From tax research to &amp;#x27;global tax cognition&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;a href="https://www.bluej.com/blog/blue-j-announces-122m-series-d-financing-led-by-oak-hc-ft-and-sapphire-ventures"&gt;&lt;u&gt;Series D funding&lt;/u&gt;&lt;/a&gt;, which brought total capital raised to over $133 million, will fuel aggressive geographic and product expansion. Blue J already operates in the U.S., Canada, and the U.K., with plans to eventually cover 220+ jurisdictions through its IBFD partnership.&lt;/p&gt;&lt;p&gt;Future capabilities could include automated memo generation, tax form completion, document drafting, and conversational history maintaining context across sessions—transforming Blue J from a research tool into what Alarie describes as &amp;quot;the operating layer for global tax cognition.&amp;quot;&lt;/p&gt;&lt;p&gt;For all its success, Blue J operates in a domain where errors carry serious consequences. The hallucination problem hasn&amp;#x27;t been eliminated — it&amp;#x27;s been minimized through careful engineering, content curation, and human oversight. Blue J has trained its models to acknowledge when they cannot answer a question rather than fabricate information.&lt;/p&gt;&lt;p&gt;The business also faces economic risks if compute costs spiral or usage patterns exceed projections. And subtler questions loom about professional judgment: as AI systems become more capable, will users defer to outputs without sufficient critical evaluation?&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 15 hours to 15 seconds: What Blue J&amp;#x27;s AI pivot teaches every industry&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J&amp;#x27;s transformation offers lessons beyond tax software. The company&amp;#x27;s willingness to abandon eight years of proprietary technology and rebuild on an initially unreliable foundation required both courage and calculated risk-taking.&lt;/p&gt;&lt;p&gt;The decision paid off not because generative AI was inherently superior to supervised machine learning in all dimensions, but because it addressed the right problem: comprehensiveness rather than precision in narrow domains. Tax professionals didn&amp;#x27;t need 95% accuracy on 5% of questions. They needed good-enough accuracy on 100% of questions.&lt;/p&gt;&lt;p&gt;The improvement from an NPS of 20 to 84 in just over two years reflects relentless iteration informed by massive data collection. The content partnerships created differentiation that pure technology couldn&amp;#x27;t replicate. The team of tax experts provided domain knowledge necessary to ensure reliability.&lt;/p&gt;&lt;p&gt;Most fundamentally, Blue J recognized that the real competition wasn&amp;#x27;t other AI startups or even established publishers. It was the old way of doing things — the 15 hours of manual research, the institutional knowledge locked in retiring professionals&amp;#x27; heads.&lt;/p&gt;&lt;p&gt;&amp;quot;People are like, &amp;#x27;What does Blue J do? They provide better tax answers. Okay, I think we need that,&amp;#x27;&amp;quot; Alarie reflected.&lt;/p&gt;&lt;p&gt;As AI transforms profession after profession, that clarity of purpose may matter more than technological sophistication. The future belongs not to those who build the most advanced AI, but to those who most effectively harness it to solve problems humans actually have.&lt;/p&gt;&lt;p&gt;For a tax law professor who started with frustration about inefficient research methods, building a $300 million company marks an audacious endpoint. For the thousands of professionals now answering complex questions in 15 seconds instead of 15 hours, it represents the future of their profession, arriving faster than most expected.&lt;/p&gt;&lt;p&gt;The bet on ChatGPT when it was still hallucinating biographies has become a validation that sometimes the riskiest move is not to move at all.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and</guid><pubDate>Tue, 18 Nov 2025 14:00:00 +0000</pubDate></item><item><title>Stack Overflow is remaking itself into an AI data provider (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/stack-overflow-is-remaking-itself-into-an-ai-data-provider/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/stack-overflow-symbol-orange.png?w=1037" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of Microsoft’s Ignite conference, Stack Overflow on Tuesday revealed a new set of products that aims to position it as a valuable part of the enterprise AI stack. This new version of the company, built around the Stack Internal enterprise product, looks to remake its classic problem-solving forum into a tool for translating human expertise into an AI-accessible format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its simplest, Stack Internal is an enterprise version of the web forum, but with the additional security and admin controls you’d expect. The new tools are specifically designed to feed into internal AI agents using the model context protocol, with certain variations designed specifically for Stack Overflow.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As CEO Prashanth Chandrasekar tells it, Stack Overflow was already seeing a number of enterprise customers use its API for training, which inspired the new product direction. The company also has content deals with a number of AI labs, allowing them to train models on public Stack Overflow data in exchange for a blanket fee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Chandrasekar wouldn’t name specific clients or figures, he described the arrangements as “very similar to the Reddit deals,” which have brought in more than $200 million for that platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A critical part of the new products is a layer of metadata that Stack Internal exports alongside the question and answer pairs. That data includes basic information like who answered the question and when, as well as content tags and more complex assessments of internal coherence. These factors are then used to create a general reliability score, which informs the AI agent how much each answer can be trusted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The customer can set up their own tagging system or we can dynamically create that for them,” said CTO Jody Bailey. “What we’ll be doing in the future is really leveraging that knowledge graph to connect concepts and pieces of information, rather than requiring the AI systems to do that on their own.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Stack Internal is producing tools for enterprise agents, it isn’t building those agents itself, so it’s difficult to say what the final product will be able to do. But Bailey is particularly excited about the writing function, which would allow agents to create their own Stack Overflow queries if they can’t answer a question or notice a knowledge gap.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Bailey sees it, that read-write functionality means that, “as we continue to evolve, it will require less and less effort from developers to capture the unique information about the way they operate their business.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/stack-overflow-symbol-orange.png?w=1037" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of Microsoft’s Ignite conference, Stack Overflow on Tuesday revealed a new set of products that aims to position it as a valuable part of the enterprise AI stack. This new version of the company, built around the Stack Internal enterprise product, looks to remake its classic problem-solving forum into a tool for translating human expertise into an AI-accessible format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its simplest, Stack Internal is an enterprise version of the web forum, but with the additional security and admin controls you’d expect. The new tools are specifically designed to feed into internal AI agents using the model context protocol, with certain variations designed specifically for Stack Overflow.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As CEO Prashanth Chandrasekar tells it, Stack Overflow was already seeing a number of enterprise customers use its API for training, which inspired the new product direction. The company also has content deals with a number of AI labs, allowing them to train models on public Stack Overflow data in exchange for a blanket fee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Chandrasekar wouldn’t name specific clients or figures, he described the arrangements as “very similar to the Reddit deals,” which have brought in more than $200 million for that platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A critical part of the new products is a layer of metadata that Stack Internal exports alongside the question and answer pairs. That data includes basic information like who answered the question and when, as well as content tags and more complex assessments of internal coherence. These factors are then used to create a general reliability score, which informs the AI agent how much each answer can be trusted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The customer can set up their own tagging system or we can dynamically create that for them,” said CTO Jody Bailey. “What we’ll be doing in the future is really leveraging that knowledge graph to connect concepts and pieces of information, rather than requiring the AI systems to do that on their own.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Stack Internal is producing tools for enterprise agents, it isn’t building those agents itself, so it’s difficult to say what the final product will be able to do. But Bailey is particularly excited about the writing function, which would allow agents to create their own Stack Overflow queries if they can’t answer a question or notice a knowledge gap.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Bailey sees it, that read-write functionality means that, “as we continue to evolve, it will require less and less effort from developers to capture the unique information about the way they operate their business.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/stack-overflow-is-remaking-itself-into-an-ai-data-provider/</guid><pubDate>Tue, 18 Nov 2025 14:00:00 +0000</pubDate></item><item><title>Microsoft, NVIDIA and Anthropic Announce Strategic Partnerships (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/microsoft-nvidia-anthropic-announce-partnership/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/microsoft-nvidia-anthropic-corp-blog-1280x680-2.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today, Microsoft, NVIDIA and Anthropic announced new strategic partnerships. Anthropic is scaling its rapidly growing Claude AI model on Microsoft Azure, powered by NVIDIA, which will broaden access to Claude and provide Azure enterprise customers with expanded model choice and new capabilities. Anthropic has committed to purchase $30 billion of Azure compute capacity and to contract additional compute capacity up to 1 gigawatt.&lt;/p&gt;
&lt;p&gt;For the first time, NVIDIA and Anthropic are establishing a deep technology partnership to support Anthropic’s future growth. Anthropic and NVIDIA will collaborate on design and engineering, with the goal of optimizing Anthropic models for the best possible performance, efficiency and TCO, and optimizing future NVIDIA architectures for Anthropic workloads. Anthropic’s compute commitment will initially be up to 1 gigawatt of compute capacity with NVIDIA Grace Blackwell and Vera Rubin systems.&lt;/p&gt;
&lt;p&gt;Microsoft and Anthropic are also expanding their existing partnership to provide broader access to Claude for businesses. Customers of Microsoft Azure AI Foundry will be able to access Anthropic’s frontier Claude models including Claude Sonnet 4.5, Claude Opus 4.1 and Claude Haiku 4.5. This partnership will make Claude the only frontier LLM model available on all three of the world’s most prominent cloud services. Azure customers will gain expanded choice in models and access to new Claude-specific capabilities.&lt;/p&gt;
&lt;p&gt;Microsoft has also committed to continuing access for Claude across Microsoft’s Copilot family, including GitHub Copilot and Copilot Studio.&lt;/p&gt;
&lt;p&gt;As part of the partnership, NVIDIA and Microsoft are committing to invest up to $10 billion and up to $5 billion respectively in Anthropic.&lt;/p&gt;
&lt;p&gt;Anthropic cofounder and CEO Dario Amodei, Microsoft Chairman and CEO Satya Nadella, and NVIDIA founder and CEO Jensen Huang gathered to discuss the new partnerships:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Today’s announcement was published simultaneously on the Microsoft, NVIDIA and Anthropic newsrooms.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/microsoft-nvidia-anthropic-corp-blog-1280x680-2.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today, Microsoft, NVIDIA and Anthropic announced new strategic partnerships. Anthropic is scaling its rapidly growing Claude AI model on Microsoft Azure, powered by NVIDIA, which will broaden access to Claude and provide Azure enterprise customers with expanded model choice and new capabilities. Anthropic has committed to purchase $30 billion of Azure compute capacity and to contract additional compute capacity up to 1 gigawatt.&lt;/p&gt;
&lt;p&gt;For the first time, NVIDIA and Anthropic are establishing a deep technology partnership to support Anthropic’s future growth. Anthropic and NVIDIA will collaborate on design and engineering, with the goal of optimizing Anthropic models for the best possible performance, efficiency and TCO, and optimizing future NVIDIA architectures for Anthropic workloads. Anthropic’s compute commitment will initially be up to 1 gigawatt of compute capacity with NVIDIA Grace Blackwell and Vera Rubin systems.&lt;/p&gt;
&lt;p&gt;Microsoft and Anthropic are also expanding their existing partnership to provide broader access to Claude for businesses. Customers of Microsoft Azure AI Foundry will be able to access Anthropic’s frontier Claude models including Claude Sonnet 4.5, Claude Opus 4.1 and Claude Haiku 4.5. This partnership will make Claude the only frontier LLM model available on all three of the world’s most prominent cloud services. Azure customers will gain expanded choice in models and access to new Claude-specific capabilities.&lt;/p&gt;
&lt;p&gt;Microsoft has also committed to continuing access for Claude across Microsoft’s Copilot family, including GitHub Copilot and Copilot Studio.&lt;/p&gt;
&lt;p&gt;As part of the partnership, NVIDIA and Microsoft are committing to invest up to $10 billion and up to $5 billion respectively in Anthropic.&lt;/p&gt;
&lt;p&gt;Anthropic cofounder and CEO Dario Amodei, Microsoft Chairman and CEO Satya Nadella, and NVIDIA founder and CEO Jensen Huang gathered to discuss the new partnerships:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Today’s announcement was published simultaneously on the Microsoft, NVIDIA and Anthropic newsrooms.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/microsoft-nvidia-anthropic-announce-partnership/</guid><pubDate>Tue, 18 Nov 2025 15:00:00 +0000</pubDate></item><item><title>Franklin Templeton &amp; Wand AI bring agentic AI to asset management (AI News)</title><link>https://www.artificialintelligence-news.com/news/franklin-templeton-wand-ai-bring-agentic-ai-to-asset-management/</link><description>&lt;p&gt;Firms in the asset management industry are turning increasingly to generative and agentic AI to streamline operations, improve decision-making, and uncover new sources of alpha (the measure of an investment strategy’s ability to outperform the market after accounting for risk). The trend is continuing with the latest partnership between Franklin Templeton and Wand AI, marking a shift toward more autonomous, data-driven investment processes.&lt;/p&gt;&lt;p&gt;Franklin Resources, operating as Franklin Templeton, has entered into a strategic partnership with enterprise AI platform, Wand AI, to begin the enterprise deployment of agentic AI in Franklin Templeton’s worldwide platform. Wand’s Autonomous Workforce and Agent Management technologies have enabled Franklin to implement agentic AI at scale, accelerating data-driven decision-making in its investment processes.&lt;/p&gt;&lt;p&gt;The collaboration has moved from initial small-scale pilot programmes to fully operational AI systems, strengthening the partnership between the two companies. The first implementations concentrated on high-value applications of AI in Franklin Templeton’s investment teams, but now both have plans to mass-deploy intelligent agents in various departments.&lt;/p&gt;&lt;p&gt;The company plans to extend the use of Wand AI’s intelligent agent in 2026, a move designed to drive digital transformation in the organisation and enhance investment research.&lt;/p&gt;&lt;p&gt;Franklin hopes to ensure AI systems are managed responsibly under strict oversight, compliance, and risk control, therefore maintaining trust and transparency. Vasundhara Chetluru, Head of AI Platform at Franklin Templeton, said, “With strong governance in place, we are demonstrating that AI can deliver secure, scalable, and measurable value.”&lt;/p&gt;&lt;p&gt;Rotem Alaluf, CEO of Wand AI, commented on the company’s AI vision, saying its mission is to “elevate AI from experimental technology to a fully integrated, adaptive workforce that drives enterprise-wide transformation and delivers significant business impact.”&lt;/p&gt;&lt;p&gt;Alaluf said AI agents can “seamlessly collaborate with human teams and operate at scale in complex, highly regulated environments to achieve transformative results,” but only when these are “properly governed, orchestrated, and deployed as a unified agentic workforce.”&lt;/p&gt;&lt;h2&gt;AI takes centre stage in asset management&lt;/h2&gt;&lt;p&gt;Other companies in the sector are also going all-in on AI.&amp;nbsp;Goldman Sachs has implemented AI at scale, with CEO, David Solomon, pinpointing the technology as a key force in economic growth. He is on the record as saying the opportunity presented by AI is “enormous.”&lt;/p&gt;&lt;p&gt;According to the Goldman Sachs report, “AI: In a Bubble?”, the company estimates that generative AI could create US $20 trillion of economic value in the long term. The report suggests AI has the capacity to create up to a 15% uplift in US labour productivity, if adopted at scale.&lt;/p&gt;&lt;p&gt;In June 2025, Goldman Sachs (GS) expanded its use of AI by launching a generative-AI assistant inside the firm, joining an increasing list of big banks that were already using the technology for operations.&lt;/p&gt;&lt;p&gt;The GS AI assistant was designed to help with tasks including drafting initial content, completing data analysis, and summarising complex documents. This has improved productivity in teams, freeing thousands of employees to prioritise higher-value strategic work, the bank says.&lt;/p&gt;&lt;p&gt;Such moves signal a shift away from AI niche-use cases and pilot projects to border enterprise deployments in major institutions, aimed at enhancing productivity and operational support.&lt;/p&gt;&lt;p&gt;While David Solomon acknowledges that AI presents an “enormous” opportunity, he has emphasised that there will be “winners and losers.” Some capital investments will not yield return, according to Solomon, which is why he says clients must be diligent in their AI investments.&lt;/p&gt;&lt;p&gt;Solomon has also noted how technology has already transformed the composition of the GS workforce make-up over the last twenty-five years. Today, the bank employs 13,000 engineers, illustrating the change in job functions over time. Rather than roles disappearing with technological advancement, Solomon believes economies and workforces adapt to change. “At the end of the day, we have an incredibly flexible, nimble economy. We have a great ability to adapt and adjust,” he said.&lt;/p&gt;&lt;p&gt;“Yes, there will be job functions that shift and change, but I’m excited about it. If you take a three-to-five-year view, it’s giving us more capacity to invest in our business,” he said.&lt;/p&gt;&lt;p&gt;Goldman Sachs and Franklin Temleton are part of a wider trend of financial institutions accelerating AI adoption. Solomon said, “I can’t find a CEO that I’m talking to, in any industry, that is not focused on how they can re-imagine and automate processes in their business to create operating efficiency and productivity.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Trading Floor at the New York Stock Exchange during the Zendesk IPO” by Scott Beale is licensed under CC BY-NC-ND 2.0)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Firms in the asset management industry are turning increasingly to generative and agentic AI to streamline operations, improve decision-making, and uncover new sources of alpha (the measure of an investment strategy’s ability to outperform the market after accounting for risk). The trend is continuing with the latest partnership between Franklin Templeton and Wand AI, marking a shift toward more autonomous, data-driven investment processes.&lt;/p&gt;&lt;p&gt;Franklin Resources, operating as Franklin Templeton, has entered into a strategic partnership with enterprise AI platform, Wand AI, to begin the enterprise deployment of agentic AI in Franklin Templeton’s worldwide platform. Wand’s Autonomous Workforce and Agent Management technologies have enabled Franklin to implement agentic AI at scale, accelerating data-driven decision-making in its investment processes.&lt;/p&gt;&lt;p&gt;The collaboration has moved from initial small-scale pilot programmes to fully operational AI systems, strengthening the partnership between the two companies. The first implementations concentrated on high-value applications of AI in Franklin Templeton’s investment teams, but now both have plans to mass-deploy intelligent agents in various departments.&lt;/p&gt;&lt;p&gt;The company plans to extend the use of Wand AI’s intelligent agent in 2026, a move designed to drive digital transformation in the organisation and enhance investment research.&lt;/p&gt;&lt;p&gt;Franklin hopes to ensure AI systems are managed responsibly under strict oversight, compliance, and risk control, therefore maintaining trust and transparency. Vasundhara Chetluru, Head of AI Platform at Franklin Templeton, said, “With strong governance in place, we are demonstrating that AI can deliver secure, scalable, and measurable value.”&lt;/p&gt;&lt;p&gt;Rotem Alaluf, CEO of Wand AI, commented on the company’s AI vision, saying its mission is to “elevate AI from experimental technology to a fully integrated, adaptive workforce that drives enterprise-wide transformation and delivers significant business impact.”&lt;/p&gt;&lt;p&gt;Alaluf said AI agents can “seamlessly collaborate with human teams and operate at scale in complex, highly regulated environments to achieve transformative results,” but only when these are “properly governed, orchestrated, and deployed as a unified agentic workforce.”&lt;/p&gt;&lt;h2&gt;AI takes centre stage in asset management&lt;/h2&gt;&lt;p&gt;Other companies in the sector are also going all-in on AI.&amp;nbsp;Goldman Sachs has implemented AI at scale, with CEO, David Solomon, pinpointing the technology as a key force in economic growth. He is on the record as saying the opportunity presented by AI is “enormous.”&lt;/p&gt;&lt;p&gt;According to the Goldman Sachs report, “AI: In a Bubble?”, the company estimates that generative AI could create US $20 trillion of economic value in the long term. The report suggests AI has the capacity to create up to a 15% uplift in US labour productivity, if adopted at scale.&lt;/p&gt;&lt;p&gt;In June 2025, Goldman Sachs (GS) expanded its use of AI by launching a generative-AI assistant inside the firm, joining an increasing list of big banks that were already using the technology for operations.&lt;/p&gt;&lt;p&gt;The GS AI assistant was designed to help with tasks including drafting initial content, completing data analysis, and summarising complex documents. This has improved productivity in teams, freeing thousands of employees to prioritise higher-value strategic work, the bank says.&lt;/p&gt;&lt;p&gt;Such moves signal a shift away from AI niche-use cases and pilot projects to border enterprise deployments in major institutions, aimed at enhancing productivity and operational support.&lt;/p&gt;&lt;p&gt;While David Solomon acknowledges that AI presents an “enormous” opportunity, he has emphasised that there will be “winners and losers.” Some capital investments will not yield return, according to Solomon, which is why he says clients must be diligent in their AI investments.&lt;/p&gt;&lt;p&gt;Solomon has also noted how technology has already transformed the composition of the GS workforce make-up over the last twenty-five years. Today, the bank employs 13,000 engineers, illustrating the change in job functions over time. Rather than roles disappearing with technological advancement, Solomon believes economies and workforces adapt to change. “At the end of the day, we have an incredibly flexible, nimble economy. We have a great ability to adapt and adjust,” he said.&lt;/p&gt;&lt;p&gt;“Yes, there will be job functions that shift and change, but I’m excited about it. If you take a three-to-five-year view, it’s giving us more capacity to invest in our business,” he said.&lt;/p&gt;&lt;p&gt;Goldman Sachs and Franklin Temleton are part of a wider trend of financial institutions accelerating AI adoption. Solomon said, “I can’t find a CEO that I’m talking to, in any industry, that is not focused on how they can re-imagine and automate processes in their business to create operating efficiency and productivity.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Trading Floor at the New York Stock Exchange during the Zendesk IPO” by Scott Beale is licensed under CC BY-NC-ND 2.0)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/franklin-templeton-wand-ai-bring-agentic-ai-to-asset-management/</guid><pubDate>Tue, 18 Nov 2025 15:09:52 +0000</pubDate></item><item><title>Generative UI: A rich, custom, visual interactive user experience for any prompt (The latest research from Google)</title><link>https://research.google/blog/generative-ui-a-rich-custom-visual-interactive-user-experience-for-any-prompt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Generative UI is a powerful capability in which an AI model generates not only content but an entire user experience. Today we introduce a novel implementation of generative UI, which dynamically creates immersive visual experiences and interactive interfaces — such as web pages, games, tools, and applications — that are automatically designed and fully customized in response to any question, instruction, or prompt. These prompts can be as simple as a single word, or as long as needed for detailed instructions. These new types of interfaces are markedly different from the static, predefined interfaces in which AI models typically render content.&lt;/p&gt;&lt;p&gt;In our new paper, “Generative UI: LLMs are Effective UI Generators”, we describe the core principles that enabled our implementation of generative UI and demonstrate the effective viability of this new paradigm. Our evaluations indicate that, when ignoring generation speed, the interfaces from our generative UI implementations are strongly preferred by human raters compared to standard LLM outputs. This work represents a first step toward fully AI-generated user experiences, where users automatically get dynamic interfaces tailored to their needs, rather than having to select from an existing catalog of applications.&lt;/p&gt;&lt;p&gt;Our research on generative UI, also referred to as generative interfaces, comes to life today in the Gemini app through an experiment called dynamic view and in AI Mode in Google Search.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Generative UI is a powerful capability in which an AI model generates not only content but an entire user experience. Today we introduce a novel implementation of generative UI, which dynamically creates immersive visual experiences and interactive interfaces — such as web pages, games, tools, and applications — that are automatically designed and fully customized in response to any question, instruction, or prompt. These prompts can be as simple as a single word, or as long as needed for detailed instructions. These new types of interfaces are markedly different from the static, predefined interfaces in which AI models typically render content.&lt;/p&gt;&lt;p&gt;In our new paper, “Generative UI: LLMs are Effective UI Generators”, we describe the core principles that enabled our implementation of generative UI and demonstrate the effective viability of this new paradigm. Our evaluations indicate that, when ignoring generation speed, the interfaces from our generative UI implementations are strongly preferred by human raters compared to standard LLM outputs. This work represents a first step toward fully AI-generated user experiences, where users automatically get dynamic interfaces tailored to their needs, rather than having to select from an existing catalog of applications.&lt;/p&gt;&lt;p&gt;Our research on generative UI, also referred to as generative interfaces, comes to life today in the Gemini app through an experiment called dynamic view and in AI Mode in Google Search.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/generative-ui-a-rich-custom-visual-interactive-user-experience-for-any-prompt/</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI benchmarks (AI | VentureBeat)</title><link>https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and</link><description>[unable to retrieve full-text content]&lt;p&gt;After more than a month of rumors and feverish speculation — including &lt;a href="https://polymarket.com/event/gemini-3pt0-released-by"&gt;Polymarket wagering on the release date&lt;/a&gt; — Google today &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;unveiled Gemini 3&lt;/a&gt;, its newest proprietary frontier model family and the company’s most comprehensive AI release since the Gemini line debuted in 2023. &lt;/p&gt;&lt;p&gt;The models are proprietary (closed-source), available exclusively through Google products, developer platforms, and paid APIs, including &lt;a href="https://aistudio.google.com/"&gt;Google AI Studio&lt;/a&gt;, &lt;a href="https://cloud.google.com/vertex-ai?hl=en"&gt;Vertex AI&lt;/a&gt;, the&lt;a href="https://github.com/google-gemini/gemini-cli"&gt; Gemini command line interface (CLI)&lt;/a&gt; for developers, and third-party integrations across the broader integrated developer environment (IDE) ecosystem.&lt;/p&gt;&lt;p&gt;Gemini 3 arrives as a full portfolio, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro:&lt;/b&gt; the flagship frontier model&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Deep Think: &lt;/b&gt;an enhanced reasoning mode&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Generative interface models powering Visual Layout and Dynamic View&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini Agent&lt;/b&gt; for multi-step task execution&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 engine&lt;/b&gt; embedded in &lt;b&gt;Google Antigravity&lt;/b&gt;, the company’s new agent-first development environment.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;quot;This is the best model in the world, by a crazy wide margin!&amp;quot; wrote&lt;a href="https://x.com/YiTayML/status/1990817918784000420"&gt; Google DeepMind Research Scientist Yi Tay on X&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Indeed, already, independent AI benchmarking and analysis organization &lt;a href="https://x.com/ArtificialAnlys/status/1990813106478715098"&gt;Artificial Analysis has crowned Gemini 3 Pro the &amp;quot;new leader in AI&amp;quot;&lt;/a&gt; globally, achieving the top score of 73 on the organization&amp;#x27;s index, leaping Google from its former placement of 9th overall with the preceding Gemini 2.5 Pro model, which scored 60 behind OpenAI, Moonshot AI, xAI, Anthropic and MiniMax models. As &lt;a href="https://x.com/ArtificialAnlys/status/1990813109188243599"&gt;Artificial Analysis wrote on X&lt;/a&gt;: &amp;quot;For the first time, Google has the most intelligent model.&amp;quot;&lt;/p&gt;&lt;p&gt;Another independent leaderboard site, LMArena reported that &lt;b&gt;Gemini 3 Pro ranked first in the world across all of its major evaluation tracks&lt;/b&gt;, including text reasoning, vision, coding, and web development. &lt;/p&gt;&lt;p&gt;In a public post, the &lt;a href="https://x.com/arena/status/1990813759938703570"&gt;@arena account on X&lt;/a&gt; said the model surpassed even the newly released (hours old) Grok-4.1, as well as Claude 4.5, and GPT-5-class systems in categories such as math, long-form queries, creative writing, and several occupational benchmarks. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The post also highlighted the scale of gains over Gemini 2.5 Pro, including a 50-point jump in text Elo, a 70-point increase in vision, and a 280-point rise in web-development tasks. &lt;/p&gt;&lt;p&gt;While these results reflect live community voting and remain preliminary, they signal unusually broad performance improvements across domains where previous Gemini models trailed competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What It Means For Google In the Hotly Competitive AI Race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch represents one of Google’s largest, most tightly coordinated model releases. &lt;/p&gt;&lt;p&gt;Gemini 3 is shipping simultaneously across Google Search, the Gemini app, Google AI Studio, Vertex AI, and a range of developer tools. &lt;/p&gt;&lt;p&gt;Executives emphasized that this integration reflects Google’s control of tensor processing unit (TPU — its homegrown Nvidia GPU rival chips) hardware, data center infrastructure, and consumer products. &lt;/p&gt;&lt;p&gt;According to the company, the Gemini app now has more than 650 million monthly active users, more than 13 million developers build with Google’s AI tools, and more than 2 billion monthly users engage with Gemini-powered AI Overviews in Search.&lt;/p&gt;&lt;p&gt;At the center of the release is a shift toward agentic AI — systems that plan, act, navigate interfaces, and coordinate tools, rather than just generating text. &lt;/p&gt;&lt;p&gt;Gemini 3 is designed to translate high-level instructions into multi-step workflows across devices and applications, with the ability to generate functional interfaces, run tools, and manage complex tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Major Performance Gains Over Gemini 2.5 Pro&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 Pro introduces large gains over Gemini 2.5 Pro across reasoning, mathematics, multimodality, tool use, coding, and long-horizon planning. Google’s benchmark disclosures show substantial improvements in many categories.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro debuted at the top of the LMArena&lt;/b&gt; text-reasoning leaderboard, posting a &lt;b&gt;preliminary Elo score of 1501&lt;/b&gt; based on pre-release community voting — the first LLM to ever cross the 1500 threshold.&lt;/p&gt;&lt;p&gt;That places it above &lt;b&gt;xAI’s newly announced Grok-4.1-thinking model (1484) and Grok-4.1 (1465), &lt;/b&gt;both of which were unveiled just hours earlier, as well as above Gemini 2.5 Pro (1451) and recent Claude Sonnet and Opus releases. &lt;/p&gt;&lt;p&gt;While LMArena covers only text-reasoning performance and the results are labeled preliminary, this ranking positions Gemini 3 Pro as the strongest publicly evaluated model on that benchmark as of its launch day — though not necessarily the top performer in the world across all modalities, tasks, or evaluation suites.&lt;/p&gt;&lt;p&gt;In mathematical and scientific reasoning, Gemini 3 Pro scored 95 percent on AIME 2025 without tools and 100 percent with code execution, compared to 88 percent for its predecessor. &lt;/p&gt;&lt;p&gt;On GPQA Diamond, it reached 91.9 percent, up from 86.4 percent. The model also recorded a major jump on MathArena Apex, reaching 23.4 percent versus 0.5 percent for Gemini 2.5 Pro, and delivered 31.1 percent on ARC-AGI-2 compared to 4.9 percent previously.&lt;/p&gt;&lt;p&gt;ARC-AGI-2 is the second-generation version of the Abstraction and Reasoning Corpus (ARC), a benchmark introduced by AI researcher François Chollet to measure &lt;i&gt;generalization&lt;/i&gt;, not memorization. &lt;/p&gt;&lt;p&gt;Unlike typical multiple-choice or dataset-based evaluations, ARC-AGI-2 presents models with tiny grid-based puzzles that require discovering and applying abstract rules. &lt;/p&gt;&lt;p&gt;Each task provides a few input–output examples, and the model must infer the underlying transformation and apply it to a new test case. The problems span visual pattern recognition, symbolic manipulation, object transformations, spatial reasoning, and rule induction — all designed to test reasoning capabilities that do not depend on training-set familiarity.&lt;/p&gt;&lt;p&gt;The new ARC-AGI-2 variant is deliberately constructed to be &lt;b&gt;out-of-distribution and resistant to memorization&lt;/b&gt;, making it one of the most difficult benchmarks for large language models. Its tasks are engineered to stress-test whether a model can infer a previously unseen rule purely from examples, a proxy for early forms of generalized problem-solving. &lt;/p&gt;&lt;p&gt;Astonishingly, the &amp;quot;Deep Think&amp;quot; version of Gemini 3, designed to take longer to solve problems and use more reasoning, scored &lt;b&gt;45.1%,&lt;/b&gt; representing a substantial jump over prior frontier models, which typically score in the mid-teens to low-twenties. It also far exceeds Gemini 3 Pro’s &lt;b&gt;31.1%&lt;/b&gt; and is an order-of-magnitude improvement over older Gemini releases. &lt;/p&gt;&lt;p&gt;These results suggest that Deep Think’s architecture is particularly effective at multi-step hypothesis generation, checking, and revision — the specific capabilities ARC-AGI-2 is designed to measure.&lt;/p&gt;&lt;p&gt;Multimodal performance increased across the board. Gemini 3 Pro scored 81 percent on MMMU-Pro, up from 68 percent, and 87.6 percent on Video-MMMU, compared to 83.6 percent. Its result on ScreenSpot-Pro, a key benchmark for agentic computer use, rose from 11.4 percent to 72.7 percent. Document understanding and chart reasoning also improved.&lt;/p&gt;&lt;p&gt;Coding and tool-use performance showed equally significant gains. The model’s LiveCodeBench Pro score reached 2,439, up from 1,775. On Terminal-Bench 2.0 it achieved 54.2 percent versus 32.6 percent previously. SWE-Bench Verified, which measures agentic coding through structured fixes, increased from 59.6 percent to 76.2 percent. The model also posted 85.4 percent on t2-bench, up from 54.9 percent.&lt;/p&gt;&lt;p&gt;Long-context and planning benchmarks indicate more stable multi-step behavior. Gemini 3 achieved 77 percent on MRCR v2 at 128k context (versus 58 percent) and 26.3 percent at 1 million tokens (versus 16.4 percent). Its Vending-Bench 2 score reached $5,478.16, compared to $573.64 for Gemini 2.5 Pro, reflecting stronger consistency during long-running decision processes.&lt;/p&gt;&lt;p&gt;Language understanding scores improved on SimpleQA Verified (72.1 percent versus 54.5 percent), MMLU (91.8 percent versus 89.5 percent), and the FACTS Benchmark Suite (70.5 percent versus 63.4 percent), supporting more reliable fact-based work in regulated sectors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Generative Interfaces Move Gemini Beyond Text&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 introduces a new class of generative interface capabilities in the consumer-facing Google Search AI Mode and for developers through Google AI Studio.&lt;/p&gt;&lt;p&gt;Visual Layout produces structured, magazine-style pages with images, diagrams, and modules tailored to the query. &lt;/p&gt;&lt;p&gt;Dynamic View generates functional interface components such as calculators, simulations, galleries, and interactive graphs. &lt;/p&gt;&lt;p&gt;These experiences will be available starting today globally in Google Search’s AI Mode, enabling models to surface information in visual, interactive formats beyond static text.&lt;/p&gt;&lt;p&gt;Developers can reproduce similar UI elements through Google AI Studio and the Gemini API, but the full consumer-facing interface types are not available as direct API outputs; instead, developers receive the underlying code or schema to render these components themselves. The branded Visual Layout and Dynamic View formats are therefore specific to Search and not exposed as standalone API features.&lt;/p&gt;&lt;p&gt;Google says the model analyzes user intent to construct the layout best suited to a task. In practice, this includes everything from automatically building diagrams for scientific concepts to generating custom UI components that respond to user input.&lt;/p&gt;&lt;p&gt;Google held a press call the day before the Gemini 3 announcement to brief reporters on the model family, its intended use cases, and how it differed from earlier Gemini releases. The call was led by multiple Google and DeepMind executives who walked through the model’s capabilities and framed Gemini 3 as a step toward more reliable, multi-step agentic systems that can operate across Google’s ecosystem.&lt;/p&gt;&lt;p&gt;During the briefing, speakers emphasized that Gemini 3 was engineered to support more consistent long-horizon reasoning, better tool use, and smoother planning loops than Gemini 2.5 Pro. &lt;/p&gt;&lt;p&gt;One presenter said the model benefits from an architecture that allows it to generate and evaluate multiple hypotheses in parallel, improving reliability on mathematically hard questions and complex procedural tasks. &lt;/p&gt;&lt;p&gt;Another speaker explained that Gemini 3’s improved spatial reasoning enables more robust interaction with interface elements, which supports agentic workflows across screens and applications.&lt;/p&gt;&lt;p&gt;Presenters highlighted growing enterprise adoption, noting strong demand for multimodal analysis, structured document reasoning, and agentic coding tools. They said Gemini 3’s performance on multimodal and scientific benchmarks reflected Google’s focus on grounded, verifiable reasoning. And they discussed Gemini 3&amp;#x27;s safety processes and improvements, including reduced sycophancy, stronger prompt-injection resistance, and a more structured evaluation pipeline guided by &lt;a href="https://deepmind.google/blog/introducing-the-frontier-safety-framework/"&gt;Google’s Frontier Safety Framework&lt;/a&gt; introduced back in 2024.&lt;/p&gt;&lt;p&gt;A portion of the call was dedicated to developer experience. Google described updates to its AI Studio and API that allow developers to control thinking depth, adjust model “resolution,” and combine new grounding tools with URL context and Search. &lt;/p&gt;&lt;p&gt;Demoes showed Gemini 3 generating application interfaces, managing tool sequences, and debugging code in Antigravity, illustrating the model’s shift toward agentic operation rather than single-step generation.&lt;/p&gt;&lt;p&gt;The call positioned Gemini 3 as an upgrade across reasoning, planning, multimodal understanding, and developer workflows, with Google framing these advances as the foundation for its next generation of agent-driven products and enterprise services.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gemini Agent Introduces Multi-Step Workflow Automation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini Agent marks Google’s effort to move beyond conversational assistance toward operational AI. The system coordinates multi-step tasks across tools like Gmail, Calendar, Canvas, and live browsing. It reviews inboxes, drafts replies, prepares plans, triages information, and reasons through complex workflows, while requiring user approval before performing sensitive actions.&lt;/p&gt;&lt;p&gt;On a press call with journalists ahead of the release yesterday, Google said the agent is designed to handle multi-turn planning and tool-use sequences with consistency that was not feasible in earlier generations. &lt;/p&gt;&lt;p&gt;It is rolling out first to Google AI Ultra subscribers in the Gemini app.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Google Antigravity and Developer Toolchain Integration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Antigravity is Google’s new agent-first development environment designed around Gemini 3. Developers collaborate with agents across an editor, terminal, and browser. The system orchestrates full-stack tasks, including code generation, UI prototyping, debugging, live execution, and report generation.&lt;/p&gt;&lt;p&gt;Across the broader developer ecosystem, Google AI Studio now includes a Build mode that automatically wires the right models and APIs to speed up AI-native app creation. Annotations support allows developers to attach prompts to UI elements for faster iteration. Spatial reasoning improvements enable agents to interpret mouse movements, screen annotations, and multi-window layouts to operate computer interfaces more effectively.&lt;/p&gt;&lt;p&gt;Developers also gain new reasoning controls through “thinking level” and “model resolution” parameters in the Gemini API, along with stricter validation of thought signatures for multi-turn consistency. A hosted server-side bash tool supports secure, multi-language code generation and prototyping. Grounding with Google Search and URL context can now be combined to extract structured information for downstream tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise Impact and Adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprise teams gain multimodal understanding, agentic coding, and long-horizon planning needed for production use cases. The new model unifies analysis of documents, audio, video, workflows, and logs. Improvements in spatial and visual reasoning support robotics, autonomous systems, and scenarios requiring navigation of screens and applications. High-frame-rate video understanding helps developers detect events in fast-moving environments.&lt;/p&gt;&lt;p&gt;Gemini 3’s structured document understanding capabilities support legal review, complex form processing, and regulated workflows. Its ability to generate functional interfaces and prototypes with minimal prompting reduces engineering cycles. In addition, the gains in system reliability, tool-calling stability, and context retention make multi-step planning viable for operations like financial forecasting, customer support automation, supply chain modeling, and predictive maintenance.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Developer and API Pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google has disclosed initial API pricing for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;In preview, the model is priced at $2 per million input tokens and $12 per million output tokens for prompts up to 200,000 tokens in Google AI Studio and Vertex AI. For prompts that require more than 200,000 tokens, the input pricing doubles to $2 per 1M tok, while the output rises to $18 per 1M tok.&lt;/p&gt;&lt;p&gt;When compared to the API pricing for other frontier AI models from rival labs, Gemini 3 is priced in the mid-high range, which may impact adoption as cheaper and open-source (permissively licensed) Chinese models &lt;a href="https://x.com/stevehou/status/1990488315351732691"&gt;have increasingly come to be adopted by U.S. startups&lt;/a&gt;. Here&amp;#x27;s how it stacks up:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Total Cost&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Source&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 4.5 Turbo&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.11&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.45&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.56&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 5.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Qwen3 (Coder ex.)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-5.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://openai.com/pricing"&gt;OpenAI&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (≤200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (≤200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$2.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$12.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$14.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$17.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (&amp;gt;200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$4.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$18.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$22.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Grok 4 (0709)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$18.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://x.ai/dev/docs/models"&gt;xAI API&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$75.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$90.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://docs.anthropic.com/claude/docs/models-overview"&gt;Anthropic&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Gemini 3 Pro is also available at no charge with rate limits in Google AI Studio for experimentation.&lt;/p&gt;&lt;p&gt;The company has not yet announced pricing for Gemini 3 Deep Think, extended context windows, generative interfaces, or tool invocation. &lt;/p&gt;&lt;p&gt;Enterprises planning deployment at scale will require these details to estimate operational costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Multimodal, Visual, and Spatial Reasoning Enhancements&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3’s improvements in embodied and spatial reasoning support pointing and trajectory prediction, task progression, and complex screen parsing. These capabilities extend to desktop and mobile environments, enabling agents to interpret screen elements, respond to on-screen context, and unlock new forms of computer-use automation.&lt;/p&gt;&lt;p&gt;The model also delivers improved video reasoning with high-frame-rate understanding for analyzing fast-moving scenes, along with long-context video recall for synthesizing narratives across hours of footage. Google’s examples show the model generating full interactive demo apps directly from prompts, illustrating the depth of multimodal and agentic integration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Vibe Coding and Agentic Code Generation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 advances Google’s concept of “vibe coding,” where natural language acts as the primary syntax. The model can translate high-level ideas into full applications with a single prompt, handling multi-step planning, code generation, and visual design. Enterprise partners like Figma, JetBrains, Cursor, Replit, and Cline report stronger instruction following, more stable agentic operation, and better long-context code manipulation compared to prior models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Rumors and Rumblings&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the weeks leading up to the announcement, X became a hub of speculation about Gemini 3. &lt;/p&gt;&lt;p&gt;Well-known accounts such as @slow_developer suggested internal builds were significantly ahead of Gemini 2.5 Pro and likely exceeded competitor performance in reasoning and tool use. Others, including @synthwavedd and @VraserX, noted mixed behavior in early checkpoints but acknowledged Google’s advantage in TPU hardware and training data. &lt;/p&gt;&lt;p&gt;Viral clips from users like @lepadphone and @StijnSmits showed the model generating websites, animations, and UI layouts from single prompts, adding to the momentum.&lt;/p&gt;&lt;p&gt;Prediction markets on Polymarket amplified the speculation. Whale accounts drove the odds of a mid-November release sharply upward, prompting widespread debate about insider activity. A temporary dip during a global Cloudflare outage became a moment of humor and conspiracy before odds surged again.&lt;/p&gt;&lt;p&gt;The key moment came when users including &lt;a href="https://x.com/cheatyyyy/status/1990737403867263183"&gt;@cheatyyyy&lt;/a&gt; shared what appeared to be an internal model-card benchmark table for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;The image circulated rapidly, with commentary from figures like @deedydas and @kimmonismus arguing the numbers suggested a significant lead. &lt;/p&gt;&lt;p&gt;When Google published the official benchmarks, they matched the leaked table exactly, confirming the document’s authenticity.&lt;/p&gt;&lt;p&gt;By launch day, enthusiasm reached a peak. A brief “Geminiii” post from Sundar Pichai triggered widespread attention, and early testers quickly shared real examples of Gemini 3 generating interfaces, full apps, and complex visual designs. &lt;/p&gt;&lt;p&gt;While some concerns about pricing and efficiency appeared, the dominant sentiment framed the launch as a turning point for Google and a display of its full-stack AI capabilities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Safety and Evaluation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google says Gemini 3 is its most secure model yet, with reduced sycophancy, stronger prompt-injection resistance, and better protection against misuse. The company partnered with external groups, including Apollo and Vaultis, and conducted evaluations using its Frontier Safety Framework.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Deployment Across Google Products&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 is available across Google Search AI Mode, the Gemini app, Google AI Studio, Vertex AI, the Gemini CLI, and Google’s new agentic development platform, Antigravity. Google says additional Gemini 3 variants will arrive later.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Conclusion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 represents Google’s largest step forward in reasoning, multimodality, enterprise reliability, and agentic capabilities. The model’s performance gains over Gemini 2.5 Pro are substantial across mathematical reasoning, vision, coding, and planning. Generative interfaces, Gemini Agent, and Antigravity demonstrate a shift toward systems that not only respond to prompts but plan tasks, construct interfaces, and coordinate tools. Combined with an unusually intense hype and leak cycle, the launch marks a significant moment in the AI landscape as Google moves aggressively to expand its presence across both consumer-facing and enterprise-facing AI workflows.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;After more than a month of rumors and feverish speculation — including &lt;a href="https://polymarket.com/event/gemini-3pt0-released-by"&gt;Polymarket wagering on the release date&lt;/a&gt; — Google today &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;unveiled Gemini 3&lt;/a&gt;, its newest proprietary frontier model family and the company’s most comprehensive AI release since the Gemini line debuted in 2023. &lt;/p&gt;&lt;p&gt;The models are proprietary (closed-source), available exclusively through Google products, developer platforms, and paid APIs, including &lt;a href="https://aistudio.google.com/"&gt;Google AI Studio&lt;/a&gt;, &lt;a href="https://cloud.google.com/vertex-ai?hl=en"&gt;Vertex AI&lt;/a&gt;, the&lt;a href="https://github.com/google-gemini/gemini-cli"&gt; Gemini command line interface (CLI)&lt;/a&gt; for developers, and third-party integrations across the broader integrated developer environment (IDE) ecosystem.&lt;/p&gt;&lt;p&gt;Gemini 3 arrives as a full portfolio, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro:&lt;/b&gt; the flagship frontier model&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Deep Think: &lt;/b&gt;an enhanced reasoning mode&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Generative interface models powering Visual Layout and Dynamic View&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini Agent&lt;/b&gt; for multi-step task execution&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 engine&lt;/b&gt; embedded in &lt;b&gt;Google Antigravity&lt;/b&gt;, the company’s new agent-first development environment.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;quot;This is the best model in the world, by a crazy wide margin!&amp;quot; wrote&lt;a href="https://x.com/YiTayML/status/1990817918784000420"&gt; Google DeepMind Research Scientist Yi Tay on X&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Indeed, already, independent AI benchmarking and analysis organization &lt;a href="https://x.com/ArtificialAnlys/status/1990813106478715098"&gt;Artificial Analysis has crowned Gemini 3 Pro the &amp;quot;new leader in AI&amp;quot;&lt;/a&gt; globally, achieving the top score of 73 on the organization&amp;#x27;s index, leaping Google from its former placement of 9th overall with the preceding Gemini 2.5 Pro model, which scored 60 behind OpenAI, Moonshot AI, xAI, Anthropic and MiniMax models. As &lt;a href="https://x.com/ArtificialAnlys/status/1990813109188243599"&gt;Artificial Analysis wrote on X&lt;/a&gt;: &amp;quot;For the first time, Google has the most intelligent model.&amp;quot;&lt;/p&gt;&lt;p&gt;Another independent leaderboard site, LMArena reported that &lt;b&gt;Gemini 3 Pro ranked first in the world across all of its major evaluation tracks&lt;/b&gt;, including text reasoning, vision, coding, and web development. &lt;/p&gt;&lt;p&gt;In a public post, the &lt;a href="https://x.com/arena/status/1990813759938703570"&gt;@arena account on X&lt;/a&gt; said the model surpassed even the newly released (hours old) Grok-4.1, as well as Claude 4.5, and GPT-5-class systems in categories such as math, long-form queries, creative writing, and several occupational benchmarks. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The post also highlighted the scale of gains over Gemini 2.5 Pro, including a 50-point jump in text Elo, a 70-point increase in vision, and a 280-point rise in web-development tasks. &lt;/p&gt;&lt;p&gt;While these results reflect live community voting and remain preliminary, they signal unusually broad performance improvements across domains where previous Gemini models trailed competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What It Means For Google In the Hotly Competitive AI Race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch represents one of Google’s largest, most tightly coordinated model releases. &lt;/p&gt;&lt;p&gt;Gemini 3 is shipping simultaneously across Google Search, the Gemini app, Google AI Studio, Vertex AI, and a range of developer tools. &lt;/p&gt;&lt;p&gt;Executives emphasized that this integration reflects Google’s control of tensor processing unit (TPU — its homegrown Nvidia GPU rival chips) hardware, data center infrastructure, and consumer products. &lt;/p&gt;&lt;p&gt;According to the company, the Gemini app now has more than 650 million monthly active users, more than 13 million developers build with Google’s AI tools, and more than 2 billion monthly users engage with Gemini-powered AI Overviews in Search.&lt;/p&gt;&lt;p&gt;At the center of the release is a shift toward agentic AI — systems that plan, act, navigate interfaces, and coordinate tools, rather than just generating text. &lt;/p&gt;&lt;p&gt;Gemini 3 is designed to translate high-level instructions into multi-step workflows across devices and applications, with the ability to generate functional interfaces, run tools, and manage complex tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Major Performance Gains Over Gemini 2.5 Pro&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 Pro introduces large gains over Gemini 2.5 Pro across reasoning, mathematics, multimodality, tool use, coding, and long-horizon planning. Google’s benchmark disclosures show substantial improvements in many categories.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro debuted at the top of the LMArena&lt;/b&gt; text-reasoning leaderboard, posting a &lt;b&gt;preliminary Elo score of 1501&lt;/b&gt; based on pre-release community voting — the first LLM to ever cross the 1500 threshold.&lt;/p&gt;&lt;p&gt;That places it above &lt;b&gt;xAI’s newly announced Grok-4.1-thinking model (1484) and Grok-4.1 (1465), &lt;/b&gt;both of which were unveiled just hours earlier, as well as above Gemini 2.5 Pro (1451) and recent Claude Sonnet and Opus releases. &lt;/p&gt;&lt;p&gt;While LMArena covers only text-reasoning performance and the results are labeled preliminary, this ranking positions Gemini 3 Pro as the strongest publicly evaluated model on that benchmark as of its launch day — though not necessarily the top performer in the world across all modalities, tasks, or evaluation suites.&lt;/p&gt;&lt;p&gt;In mathematical and scientific reasoning, Gemini 3 Pro scored 95 percent on AIME 2025 without tools and 100 percent with code execution, compared to 88 percent for its predecessor. &lt;/p&gt;&lt;p&gt;On GPQA Diamond, it reached 91.9 percent, up from 86.4 percent. The model also recorded a major jump on MathArena Apex, reaching 23.4 percent versus 0.5 percent for Gemini 2.5 Pro, and delivered 31.1 percent on ARC-AGI-2 compared to 4.9 percent previously.&lt;/p&gt;&lt;p&gt;ARC-AGI-2 is the second-generation version of the Abstraction and Reasoning Corpus (ARC), a benchmark introduced by AI researcher François Chollet to measure &lt;i&gt;generalization&lt;/i&gt;, not memorization. &lt;/p&gt;&lt;p&gt;Unlike typical multiple-choice or dataset-based evaluations, ARC-AGI-2 presents models with tiny grid-based puzzles that require discovering and applying abstract rules. &lt;/p&gt;&lt;p&gt;Each task provides a few input–output examples, and the model must infer the underlying transformation and apply it to a new test case. The problems span visual pattern recognition, symbolic manipulation, object transformations, spatial reasoning, and rule induction — all designed to test reasoning capabilities that do not depend on training-set familiarity.&lt;/p&gt;&lt;p&gt;The new ARC-AGI-2 variant is deliberately constructed to be &lt;b&gt;out-of-distribution and resistant to memorization&lt;/b&gt;, making it one of the most difficult benchmarks for large language models. Its tasks are engineered to stress-test whether a model can infer a previously unseen rule purely from examples, a proxy for early forms of generalized problem-solving. &lt;/p&gt;&lt;p&gt;Astonishingly, the &amp;quot;Deep Think&amp;quot; version of Gemini 3, designed to take longer to solve problems and use more reasoning, scored &lt;b&gt;45.1%,&lt;/b&gt; representing a substantial jump over prior frontier models, which typically score in the mid-teens to low-twenties. It also far exceeds Gemini 3 Pro’s &lt;b&gt;31.1%&lt;/b&gt; and is an order-of-magnitude improvement over older Gemini releases. &lt;/p&gt;&lt;p&gt;These results suggest that Deep Think’s architecture is particularly effective at multi-step hypothesis generation, checking, and revision — the specific capabilities ARC-AGI-2 is designed to measure.&lt;/p&gt;&lt;p&gt;Multimodal performance increased across the board. Gemini 3 Pro scored 81 percent on MMMU-Pro, up from 68 percent, and 87.6 percent on Video-MMMU, compared to 83.6 percent. Its result on ScreenSpot-Pro, a key benchmark for agentic computer use, rose from 11.4 percent to 72.7 percent. Document understanding and chart reasoning also improved.&lt;/p&gt;&lt;p&gt;Coding and tool-use performance showed equally significant gains. The model’s LiveCodeBench Pro score reached 2,439, up from 1,775. On Terminal-Bench 2.0 it achieved 54.2 percent versus 32.6 percent previously. SWE-Bench Verified, which measures agentic coding through structured fixes, increased from 59.6 percent to 76.2 percent. The model also posted 85.4 percent on t2-bench, up from 54.9 percent.&lt;/p&gt;&lt;p&gt;Long-context and planning benchmarks indicate more stable multi-step behavior. Gemini 3 achieved 77 percent on MRCR v2 at 128k context (versus 58 percent) and 26.3 percent at 1 million tokens (versus 16.4 percent). Its Vending-Bench 2 score reached $5,478.16, compared to $573.64 for Gemini 2.5 Pro, reflecting stronger consistency during long-running decision processes.&lt;/p&gt;&lt;p&gt;Language understanding scores improved on SimpleQA Verified (72.1 percent versus 54.5 percent), MMLU (91.8 percent versus 89.5 percent), and the FACTS Benchmark Suite (70.5 percent versus 63.4 percent), supporting more reliable fact-based work in regulated sectors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Generative Interfaces Move Gemini Beyond Text&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 introduces a new class of generative interface capabilities in the consumer-facing Google Search AI Mode and for developers through Google AI Studio.&lt;/p&gt;&lt;p&gt;Visual Layout produces structured, magazine-style pages with images, diagrams, and modules tailored to the query. &lt;/p&gt;&lt;p&gt;Dynamic View generates functional interface components such as calculators, simulations, galleries, and interactive graphs. &lt;/p&gt;&lt;p&gt;These experiences will be available starting today globally in Google Search’s AI Mode, enabling models to surface information in visual, interactive formats beyond static text.&lt;/p&gt;&lt;p&gt;Developers can reproduce similar UI elements through Google AI Studio and the Gemini API, but the full consumer-facing interface types are not available as direct API outputs; instead, developers receive the underlying code or schema to render these components themselves. The branded Visual Layout and Dynamic View formats are therefore specific to Search and not exposed as standalone API features.&lt;/p&gt;&lt;p&gt;Google says the model analyzes user intent to construct the layout best suited to a task. In practice, this includes everything from automatically building diagrams for scientific concepts to generating custom UI components that respond to user input.&lt;/p&gt;&lt;p&gt;Google held a press call the day before the Gemini 3 announcement to brief reporters on the model family, its intended use cases, and how it differed from earlier Gemini releases. The call was led by multiple Google and DeepMind executives who walked through the model’s capabilities and framed Gemini 3 as a step toward more reliable, multi-step agentic systems that can operate across Google’s ecosystem.&lt;/p&gt;&lt;p&gt;During the briefing, speakers emphasized that Gemini 3 was engineered to support more consistent long-horizon reasoning, better tool use, and smoother planning loops than Gemini 2.5 Pro. &lt;/p&gt;&lt;p&gt;One presenter said the model benefits from an architecture that allows it to generate and evaluate multiple hypotheses in parallel, improving reliability on mathematically hard questions and complex procedural tasks. &lt;/p&gt;&lt;p&gt;Another speaker explained that Gemini 3’s improved spatial reasoning enables more robust interaction with interface elements, which supports agentic workflows across screens and applications.&lt;/p&gt;&lt;p&gt;Presenters highlighted growing enterprise adoption, noting strong demand for multimodal analysis, structured document reasoning, and agentic coding tools. They said Gemini 3’s performance on multimodal and scientific benchmarks reflected Google’s focus on grounded, verifiable reasoning. And they discussed Gemini 3&amp;#x27;s safety processes and improvements, including reduced sycophancy, stronger prompt-injection resistance, and a more structured evaluation pipeline guided by &lt;a href="https://deepmind.google/blog/introducing-the-frontier-safety-framework/"&gt;Google’s Frontier Safety Framework&lt;/a&gt; introduced back in 2024.&lt;/p&gt;&lt;p&gt;A portion of the call was dedicated to developer experience. Google described updates to its AI Studio and API that allow developers to control thinking depth, adjust model “resolution,” and combine new grounding tools with URL context and Search. &lt;/p&gt;&lt;p&gt;Demoes showed Gemini 3 generating application interfaces, managing tool sequences, and debugging code in Antigravity, illustrating the model’s shift toward agentic operation rather than single-step generation.&lt;/p&gt;&lt;p&gt;The call positioned Gemini 3 as an upgrade across reasoning, planning, multimodal understanding, and developer workflows, with Google framing these advances as the foundation for its next generation of agent-driven products and enterprise services.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gemini Agent Introduces Multi-Step Workflow Automation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini Agent marks Google’s effort to move beyond conversational assistance toward operational AI. The system coordinates multi-step tasks across tools like Gmail, Calendar, Canvas, and live browsing. It reviews inboxes, drafts replies, prepares plans, triages information, and reasons through complex workflows, while requiring user approval before performing sensitive actions.&lt;/p&gt;&lt;p&gt;On a press call with journalists ahead of the release yesterday, Google said the agent is designed to handle multi-turn planning and tool-use sequences with consistency that was not feasible in earlier generations. &lt;/p&gt;&lt;p&gt;It is rolling out first to Google AI Ultra subscribers in the Gemini app.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Google Antigravity and Developer Toolchain Integration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Antigravity is Google’s new agent-first development environment designed around Gemini 3. Developers collaborate with agents across an editor, terminal, and browser. The system orchestrates full-stack tasks, including code generation, UI prototyping, debugging, live execution, and report generation.&lt;/p&gt;&lt;p&gt;Across the broader developer ecosystem, Google AI Studio now includes a Build mode that automatically wires the right models and APIs to speed up AI-native app creation. Annotations support allows developers to attach prompts to UI elements for faster iteration. Spatial reasoning improvements enable agents to interpret mouse movements, screen annotations, and multi-window layouts to operate computer interfaces more effectively.&lt;/p&gt;&lt;p&gt;Developers also gain new reasoning controls through “thinking level” and “model resolution” parameters in the Gemini API, along with stricter validation of thought signatures for multi-turn consistency. A hosted server-side bash tool supports secure, multi-language code generation and prototyping. Grounding with Google Search and URL context can now be combined to extract structured information for downstream tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise Impact and Adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprise teams gain multimodal understanding, agentic coding, and long-horizon planning needed for production use cases. The new model unifies analysis of documents, audio, video, workflows, and logs. Improvements in spatial and visual reasoning support robotics, autonomous systems, and scenarios requiring navigation of screens and applications. High-frame-rate video understanding helps developers detect events in fast-moving environments.&lt;/p&gt;&lt;p&gt;Gemini 3’s structured document understanding capabilities support legal review, complex form processing, and regulated workflows. Its ability to generate functional interfaces and prototypes with minimal prompting reduces engineering cycles. In addition, the gains in system reliability, tool-calling stability, and context retention make multi-step planning viable for operations like financial forecasting, customer support automation, supply chain modeling, and predictive maintenance.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Developer and API Pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google has disclosed initial API pricing for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;In preview, the model is priced at $2 per million input tokens and $12 per million output tokens for prompts up to 200,000 tokens in Google AI Studio and Vertex AI. For prompts that require more than 200,000 tokens, the input pricing doubles to $2 per 1M tok, while the output rises to $18 per 1M tok.&lt;/p&gt;&lt;p&gt;When compared to the API pricing for other frontier AI models from rival labs, Gemini 3 is priced in the mid-high range, which may impact adoption as cheaper and open-source (permissively licensed) Chinese models &lt;a href="https://x.com/stevehou/status/1990488315351732691"&gt;have increasingly come to be adopted by U.S. startups&lt;/a&gt;. Here&amp;#x27;s how it stacks up:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Total Cost&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Source&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 4.5 Turbo&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.11&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.45&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.56&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 5.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Qwen3 (Coder ex.)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-5.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://openai.com/pricing"&gt;OpenAI&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (≤200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (≤200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$2.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$12.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$14.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$17.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (&amp;gt;200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$4.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$18.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$22.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Grok 4 (0709)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$18.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://x.ai/dev/docs/models"&gt;xAI API&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$75.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$90.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://docs.anthropic.com/claude/docs/models-overview"&gt;Anthropic&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Gemini 3 Pro is also available at no charge with rate limits in Google AI Studio for experimentation.&lt;/p&gt;&lt;p&gt;The company has not yet announced pricing for Gemini 3 Deep Think, extended context windows, generative interfaces, or tool invocation. &lt;/p&gt;&lt;p&gt;Enterprises planning deployment at scale will require these details to estimate operational costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Multimodal, Visual, and Spatial Reasoning Enhancements&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3’s improvements in embodied and spatial reasoning support pointing and trajectory prediction, task progression, and complex screen parsing. These capabilities extend to desktop and mobile environments, enabling agents to interpret screen elements, respond to on-screen context, and unlock new forms of computer-use automation.&lt;/p&gt;&lt;p&gt;The model also delivers improved video reasoning with high-frame-rate understanding for analyzing fast-moving scenes, along with long-context video recall for synthesizing narratives across hours of footage. Google’s examples show the model generating full interactive demo apps directly from prompts, illustrating the depth of multimodal and agentic integration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Vibe Coding and Agentic Code Generation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 advances Google’s concept of “vibe coding,” where natural language acts as the primary syntax. The model can translate high-level ideas into full applications with a single prompt, handling multi-step planning, code generation, and visual design. Enterprise partners like Figma, JetBrains, Cursor, Replit, and Cline report stronger instruction following, more stable agentic operation, and better long-context code manipulation compared to prior models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Rumors and Rumblings&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the weeks leading up to the announcement, X became a hub of speculation about Gemini 3. &lt;/p&gt;&lt;p&gt;Well-known accounts such as @slow_developer suggested internal builds were significantly ahead of Gemini 2.5 Pro and likely exceeded competitor performance in reasoning and tool use. Others, including @synthwavedd and @VraserX, noted mixed behavior in early checkpoints but acknowledged Google’s advantage in TPU hardware and training data. &lt;/p&gt;&lt;p&gt;Viral clips from users like @lepadphone and @StijnSmits showed the model generating websites, animations, and UI layouts from single prompts, adding to the momentum.&lt;/p&gt;&lt;p&gt;Prediction markets on Polymarket amplified the speculation. Whale accounts drove the odds of a mid-November release sharply upward, prompting widespread debate about insider activity. A temporary dip during a global Cloudflare outage became a moment of humor and conspiracy before odds surged again.&lt;/p&gt;&lt;p&gt;The key moment came when users including &lt;a href="https://x.com/cheatyyyy/status/1990737403867263183"&gt;@cheatyyyy&lt;/a&gt; shared what appeared to be an internal model-card benchmark table for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;The image circulated rapidly, with commentary from figures like @deedydas and @kimmonismus arguing the numbers suggested a significant lead. &lt;/p&gt;&lt;p&gt;When Google published the official benchmarks, they matched the leaked table exactly, confirming the document’s authenticity.&lt;/p&gt;&lt;p&gt;By launch day, enthusiasm reached a peak. A brief “Geminiii” post from Sundar Pichai triggered widespread attention, and early testers quickly shared real examples of Gemini 3 generating interfaces, full apps, and complex visual designs. &lt;/p&gt;&lt;p&gt;While some concerns about pricing and efficiency appeared, the dominant sentiment framed the launch as a turning point for Google and a display of its full-stack AI capabilities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Safety and Evaluation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google says Gemini 3 is its most secure model yet, with reduced sycophancy, stronger prompt-injection resistance, and better protection against misuse. The company partnered with external groups, including Apollo and Vaultis, and conducted evaluations using its Frontier Safety Framework.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Deployment Across Google Products&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 is available across Google Search AI Mode, the Gemini app, Google AI Studio, Vertex AI, the Gemini CLI, and Google’s new agentic development platform, Antigravity. Google says additional Gemini 3 variants will arrive later.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Conclusion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 represents Google’s largest step forward in reasoning, multimodality, enterprise reliability, and agentic capabilities. The model’s performance gains over Gemini 2.5 Pro are substantial across mathematical reasoning, vision, coding, and planning. Generative interfaces, Gemini Agent, and Antigravity demonstrate a shift toward systems that not only respond to prompts but plan tasks, construct interfaces, and coordinate tools. Combined with an unusually intense hype and leak cycle, the launch marks a significant moment in the AI landscape as Google moves aggressively to expand its presence across both consumer-facing and enterprise-facing AI workflows.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Writer's AI agents can actually do your work—not just chat about it (AI | VentureBeat)</title><link>https://venturebeat.com/ai/writers-ai-agents-can-actually-do-your-work-not-just-chat-about-it</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://writer.com/"&gt;&lt;u&gt;Writer&lt;/u&gt;&lt;/a&gt;, a San Francisco-based artificial intelligence startup, is launching a unified AI agent platform designed to let any employee automate complex business workflows without writing code — a capability the company says distinguishes it from consumer-oriented tools like &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Microsoft Copilot&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The platform, called &lt;a href="https://writer.com/product/writer-agent/"&gt;&lt;u&gt;Writer Agent&lt;/u&gt;&lt;/a&gt;, combines chat-based assistance with autonomous task execution in a single interface. Starting Tuesday, enterprise customers can use natural language to instruct the AI to create presentations, analyze financial data, generate marketing campaigns, or coordinate across multiple business systems like Salesforce, Slack, and Google Workspace—then save those workflows as reusable &amp;quot;Playbooks&amp;quot; that run automatically on schedules.&lt;/p&gt;&lt;p&gt;The announcement comes as enterprises struggle to move AI initiatives beyond pilot programs into production at scale. Writer CEO May Habib has been outspoken about this challenge, recently revealing that 42% of Fortune 500 executives surveyed by her company said AI is &amp;quot;&lt;a href="https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for"&gt;&lt;u&gt;tearing their company apart&lt;/u&gt;&lt;/a&gt;&amp;quot; due to coordination failures between departments.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re delivering an agent interface that is both incredibly powerful and radically simple to transform individual productivity into organizational impact,&amp;quot; Habib said in a statement. &amp;quot;Writer Agent is the difference between a single sales rep asking a chatbot to write an outreach email and an enterprise ensuring that 1,000 reps are all sending on-brand, compliant, and contextually-aware messages to target accounts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Writer is putting workflow automation in the hands of non-technical workers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform&amp;#x27;s core innovation centers on making workflow automation accessible to non-technical employees—what Writer executives call &amp;quot;democratizing who gets to be a builder.&amp;quot;&lt;/p&gt;&lt;p&gt;In an exclusive interview with VentureBeat, Doris Jwo, Writer&amp;#x27;s director of product management, demonstrated how the system works: A user types a request in plain English — for example, &amp;quot;Create a two-page partnership proposal between [Company A] and [Company B], make it a branded deck, include impact metrics and partnership tiers.&amp;quot;&lt;/p&gt;&lt;p&gt;The AI agent then breaks down that request into discrete steps, conducts web research, generates graphics and charts on the fly, creates individual slides with sourced information, and assembles a complete presentation. The entire process, which might take an employee hours or days, can be completed in 10-12 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;The agent basically looks at the request, breaks it down, does research, understands what pieces it needs, creates a detailed plan at a step-by-step level,&amp;quot; Jwo explained during a product demonstration. &amp;quot;It might say, &amp;#x27;I need to do web research,&amp;#x27; or &amp;#x27;This user needs information from Gong or Slack,&amp;#x27; and it reaches out to those connectors, grabs the data, and executes the plan.&amp;quot;&lt;/p&gt;&lt;p&gt;Crucially, users can save these multi-step processes as Playbooks—reusable templates that colleagues can deploy with a single click. Routines allow those Playbooks to run automatically at scheduled intervals, essentially putting knowledge work &amp;quot;on autopilot.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Security and compliance controls: Writer&amp;#x27;s answer to enterprise IT concerns&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer positions these enterprise-focused controls as a key differentiator from competitors. While &lt;a href="https://microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; offer powerful AI capabilities, Writer&amp;#x27;s executives argue those tools weren&amp;#x27;t designed from the ground up for the security, compliance, and governance requirements of large regulated organizations.&lt;/p&gt;&lt;p&gt;&amp;quot;All of the products you mentioned are great products, but even Copilot is very much focused on personal productivity—summarizing email, for example, which is important, but that&amp;#x27;s not the component we&amp;#x27;re focusing on,&amp;quot; said Matan-Paul Shetrit, Writer&amp;#x27;s director of product management, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Shetrit emphasized Writer&amp;#x27;s &amp;quot;trust, security, and interoperability&amp;quot; approach. IT administrators can granularly control what the AI can access — for instance, preventing market research agents from mentioning competitors, or restricting which employees can use web search capabilities. All activity is logged with detailed audit trails showing exactly what data the agent touched and what actions it took.&lt;/p&gt;&lt;p&gt;&amp;quot;These fine-grained controls are what make products enterprise-ready,&amp;quot; Shetrit said. &amp;quot;We can deploy to tens of thousands or hundreds of thousands of employees while maintaining the security and guardrails you need for that scale.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture reflects &lt;a href="https://writer.com/company/about/"&gt;&lt;u&gt;Writer&amp;#x27;s origin story&lt;/u&gt;&lt;/a&gt;. Unlike OpenAI or Anthropic, which started as research labs and later added enterprise offerings, Writer has targeted Fortune 500 companies since its 2020 founding. &amp;quot;We&amp;#x27;re not a research lab that went to consumer and is dabbling in enterprise,&amp;quot; Shetrit said. &amp;quot;We are first and foremost targeting the Global 2000 and Fortune 500, and our research is in service of these customers&amp;#x27; needs.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Writer&amp;#x27;s strategy to connect AI agents across enterprise software systems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A critical technical component is Writer&amp;#x27;s approach to system integrations. The platform includes pre-built connectors to more than a dozen enterprise applications—&lt;a href="https://workspace.google.com/lp/business/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Google+Workspace-Core-346911454270&amp;amp;utm_term=google%20workspace&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=20159848966&amp;amp;gclid=CjwKCAiAz_DIBhBJEiwAVH2XwDbhidrT22spa5fU8uNyySir49xeTOAji42tQEy7zvzTZpUAL4TFgRoCLz8QAvD_BwE"&gt;&lt;u&gt;Google Workspace&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.microsoft.com/en-us/microsoft-365"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.snowflake.com/en/"&gt;&lt;u&gt;Snowflake&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://asana.com/"&gt;&lt;u&gt;Asana&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.atlassian.com/"&gt;&lt;u&gt;Atlassian&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.databricks.com/"&gt;&lt;u&gt;Databricks&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt;—allowing the AI to retrieve information and take actions across those systems.&lt;/p&gt;&lt;p&gt;Writer built these connectors using the &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI system integrations, but added what Shetrit described as an &amp;quot;enterprise-ready&amp;quot; layer on top.&lt;/p&gt;&lt;p&gt;&amp;quot;We took a first-principle approach of: You have this MCP connector infrastructure—how do you build it in a way that&amp;#x27;s enterprise-ready?&amp;quot; Shetrit explained. &amp;quot;What we have today in the industry is definitely not it.&amp;quot;&lt;/p&gt;&lt;p&gt;The system can write and execute code on the fly to handle unexpected scenarios. If a user uploads an unfamiliar file format, for instance, the agent will generate code to extract and process the text without requiring a human to intervene.&lt;/p&gt;&lt;p&gt;Jwo demonstrated this capability with a daily workflow she runs: Every morning at 10 a.m., a Routine automatically summarizes her Google Calendar meetings, identifies external participants, finds their LinkedIn profiles, and sends the summary to her via Slack — all without her involvement.&lt;/p&gt;&lt;p&gt;&amp;quot;This was pretty simple, but you can imagine for a salesperson it might say, &amp;#x27;At the end of the day, wrap up a summary of all the calls I had, send me action items, post it to the account-specific Slack channel, and tag these folks so they can accomplish those workflows,&amp;#x27;&amp;quot; Jwo said. &amp;quot;That can run continuously each day, each week, or on demand.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From mortgage lenders to CPG brands: Real-world AI agent use cases across industries&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform is attracting customers across multiple industries. &lt;a href="https://www.newamericanfunding.com/"&gt;&lt;u&gt;New American Funding&lt;/u&gt;&lt;/a&gt;, a mortgage lender, uses Writer Agent to automate marketing workflows. Senior Content Marketing Manager Karen Rodriguez uploads Asana project tickets with creative briefs, and the AI executes tasks like updating email campaigns or transforming articles into social media carousels, video scripts, and captions.&lt;/p&gt;&lt;p&gt;Other use cases span financial services teams creating investment dashboards with &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt; data, consumer packaged goods companies brainstorming new product lines based on social media trends, and marketing teams generating partnership presentations with branded assets.&lt;/p&gt;&lt;p&gt;Writer has added customers including &lt;a href="https://www.tiktok.com/en/"&gt;&lt;u&gt;TikTok&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.cmcsa.com/"&gt;&lt;u&gt;Comcast&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.keurigdrpepper.com/"&gt;&lt;u&gt;Keurig Dr Pepper&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.caa.com/"&gt;&lt;u&gt;CAA&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.aptitudehealth.com/"&gt;&lt;u&gt;Aptitude Health&lt;/u&gt;&lt;/a&gt;, joining an existing base that includes &lt;a href="https://www.accenture.com/"&gt;&lt;u&gt;Accenture&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.qualcomm.com/"&gt;&lt;u&gt;Qualcomm&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.uber.com/"&gt;&lt;u&gt;Uber&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://investor.vanguard.com/corporate-portal"&gt;&lt;u&gt;Vanguard&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.marriott.com/default.mi"&gt;&lt;u&gt;Marriott&lt;/u&gt;&lt;/a&gt;. The company now serves more than 300 enterprises and has secured over $50 million in signed contracts, with projections to double that to $100 million this year.&lt;/p&gt;&lt;p&gt;The startup&amp;#x27;s net retention rate — a measure of how much existing customers expand their usage — stands at 160%, meaning customers on average increase their spending by 60% after initial contracts. Twenty customers who started with $200,000-$300,000 contracts now spend about $1 million annually, according to company data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&amp;#x27;Vibe working&amp;#x27;: Writer&amp;#x27;s vision for AI-powered productivity beyond coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer executives frame the platform as enabling what they call &amp;quot;vibe working&amp;quot; — a playful reference to the popular term &amp;quot;vibe coding,&amp;quot; which describes AI tools like Cursor that dramatically accelerate software development.&lt;/p&gt;&lt;p&gt;&amp;quot;We used to call it transformation when we took 12 steps and made them nine. That&amp;#x27;s optimizing the world as it is,&amp;quot; Habib said at Writer&amp;#x27;s AI Leaders Forum earlier this month, according to &lt;a href="https://www.forbes.com/sites/stevenwolfepereira/2025/11/08/what-writers-ai-leaders-forum-revealed-about-enterprise-ai/"&gt;&lt;u&gt;Forbes&lt;/u&gt;&lt;/a&gt;. &amp;quot;We can now create a new world. That is the greenfield mindset.&amp;quot;&lt;/p&gt;&lt;p&gt;Shetrit echoed this framing: &amp;quot;Vibe coding is the theme of 2025. Our view is that ‘vibe working’ is the theme of 2026. How do you bring the same productivity gains you&amp;#x27;ve seen with coding agents into the workspace in a way that non-technical users can maximize them?&amp;quot;&lt;/p&gt;&lt;p&gt;The platform is powered by &lt;a href="https://writer.com/engineering/long-context-palmyra-x5/"&gt;&lt;u&gt;Palmyra X5&lt;/u&gt;&lt;/a&gt;, Writer&amp;#x27;s proprietary large language model featuring a one-million-token context window — among the largest commercially available. Writer trained the model for approximately $700,000, a fraction of the estimated $100 million OpenAI spent on GPT-4, by using synthetic data and techniques that halt training when returns diminish.&lt;/p&gt;&lt;p&gt;The model can process one million tokens in about 22 seconds and costs 60 cents per million input tokens and $6 per million output tokens — significantly cheaper than comparable offerings, according to company specifications.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making AI Decisions Visible: Writer&amp;#x27;s Approach to Trust and Transparency&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A distinctive aspect of Writer&amp;#x27;s approach is transparency into the AI&amp;#x27;s decision-making process. The interface displays the agent&amp;#x27;s step-by-step reasoning, showing which data sources it accessed, what code it generated, and how it arrived at outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s a very clear exhibition of how the agent is thinking, what it&amp;#x27;s doing, what it&amp;#x27;s touching,&amp;quot; Shetrit said. &amp;quot;This is important for the end user to trust it, but also important for the IT person or security professional to see what&amp;#x27;s going on.&amp;quot;&lt;/p&gt;&lt;p&gt;This &amp;quot;supervision&amp;quot; model goes beyond simple observability of API calls to encompass what Shetrit described as &amp;quot;a superset of observability&amp;quot; — giving organizations the ability to not just monitor but control AI behavior through policies and permissions.&lt;/p&gt;&lt;p&gt;Session logs capture all agent activity when enabled by administrators, and users can submit feedback on every output to help improve system performance. The platform also emphasizes providing sources and citations for generated content, allowing users to verify information.&lt;/p&gt;&lt;p&gt;&amp;quot;With any sort of chat assistant, agentic or not, trust but verify is really important,&amp;quot; Jwo said. &amp;quot;That&amp;#x27;s part of the pillars of us building this and making it enterprise-grade.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Writer Agent Costs—and Why It&amp;#x27;s Included in the Base Platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer is including all the new capabilities—Playbooks, Routines, Connectors, and Personality customization—as part of its core platform without additional charges, according to Jwo.&lt;/p&gt;&lt;p&gt;&amp;quot;This is fully included as part of the Writer platform,&amp;quot; she said. &amp;quot;We&amp;#x27;re not charging additional for using Writer Agent.&amp;quot;&lt;/p&gt;&lt;p&gt;The &amp;quot;Personality&amp;quot; feature allows individual users, teams, or entire organizations to customize the AI&amp;#x27;s communication style, ensuring generated content matches brand voice and tone guidelines. This works alongside company-level controls that enforce terminology and style requirements.&lt;/p&gt;&lt;p&gt;For highly structured, repetitive tasks, Writer also offers a library of more than 100 pre-built agents and an AI Studio for building custom multi-agent systems aligned with specific business use cases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Race to Define Enterprise AI: Can Purpose-Built Platforms Beat Tech Giants?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch crystallizes a fundamental tension in how enterprises will adopt AI at scale. While consumer-facing AI tools emphasize individual productivity gains, companies need systems that work reliably across thousands of employees, integrate with existing software infrastructure, maintain regulatory compliance, and deliver measurable business impact.&lt;/p&gt;&lt;p&gt;Writer&amp;#x27;s wager is that these requirements demand purpose-built enterprise platforms rather than consumer tools adapted for business use. The company&amp;#x27;s &lt;a href="https://techcrunch.com/2024/11/12/generative-ai-startup-writer-raises-200m-at-a-1-9b-valuation/"&gt;&lt;u&gt;$1.9 billion valuation&lt;/u&gt;&lt;/a&gt; — achieved in a November 2024 funding round that raised $200 million — suggests investors see merit in this thesis. Backers include &lt;a href="https://www.premjiinvest.com/"&gt;&lt;u&gt;Premji Invest&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://radical.vc/"&gt;&lt;u&gt;Radical Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.iconiqcapital.com/growth"&gt;&lt;u&gt;ICONIQ Growth&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://salesforceventures.com/"&gt;&lt;u&gt;Salesforce Ventures&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.adobe.com/ventures.html"&gt;&lt;u&gt;Adobe Ventures&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yet the competitive landscape remains formidable. Microsoft and Google command enormous distribution advantages through their existing enterprise software relationships. OpenAI and Anthropic possess research capabilities that have produced breakthrough models. Whether Writer can maintain its differentiation as these giants expand their enterprise offerings will test the startup&amp;#x27;s core premise: that serving Fortune 500 companies from day one creates advantages that research labs turned enterprise vendors cannot easily replicate.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re entering an era where if you can describe a better way to work, you can build it,&amp;quot; Jwo said. &amp;quot;The new Writer Agent democratizes who gets to be a builder, empowering the operational experts and creative problem-solvers in every department to become the architects of their own transformation. That&amp;#x27;s how you unlock innovation that competitors can&amp;#x27;t replicate.&amp;quot;&lt;/p&gt;&lt;p&gt;The promise is alluring — AI capabilities powerful enough to transform how work gets done, accessible enough for any employee to use, and controlled enough for enterprises to deploy safely at scale. Whether Writer can deliver on that promise at the speed and scale required will determine if its vision of &amp;quot;vibe working&amp;quot; becomes the 2026 theme Shetrit predicts, or just another ambitious attempt to solve enterprise AI&amp;#x27;s execution problem.&lt;/p&gt;&lt;p&gt;But one thing is certain: In a market where 85% of AI initiatives fail to escape pilot purgatory, Writer is betting that the winners won&amp;#x27;t be the companies with the most powerful models—they&amp;#x27;ll be the ones that make those models actually work inside the enterprise.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://writer.com/"&gt;&lt;u&gt;Writer&lt;/u&gt;&lt;/a&gt;, a San Francisco-based artificial intelligence startup, is launching a unified AI agent platform designed to let any employee automate complex business workflows without writing code — a capability the company says distinguishes it from consumer-oriented tools like &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Microsoft Copilot&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The platform, called &lt;a href="https://writer.com/product/writer-agent/"&gt;&lt;u&gt;Writer Agent&lt;/u&gt;&lt;/a&gt;, combines chat-based assistance with autonomous task execution in a single interface. Starting Tuesday, enterprise customers can use natural language to instruct the AI to create presentations, analyze financial data, generate marketing campaigns, or coordinate across multiple business systems like Salesforce, Slack, and Google Workspace—then save those workflows as reusable &amp;quot;Playbooks&amp;quot; that run automatically on schedules.&lt;/p&gt;&lt;p&gt;The announcement comes as enterprises struggle to move AI initiatives beyond pilot programs into production at scale. Writer CEO May Habib has been outspoken about this challenge, recently revealing that 42% of Fortune 500 executives surveyed by her company said AI is &amp;quot;&lt;a href="https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for"&gt;&lt;u&gt;tearing their company apart&lt;/u&gt;&lt;/a&gt;&amp;quot; due to coordination failures between departments.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re delivering an agent interface that is both incredibly powerful and radically simple to transform individual productivity into organizational impact,&amp;quot; Habib said in a statement. &amp;quot;Writer Agent is the difference between a single sales rep asking a chatbot to write an outreach email and an enterprise ensuring that 1,000 reps are all sending on-brand, compliant, and contextually-aware messages to target accounts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Writer is putting workflow automation in the hands of non-technical workers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform&amp;#x27;s core innovation centers on making workflow automation accessible to non-technical employees—what Writer executives call &amp;quot;democratizing who gets to be a builder.&amp;quot;&lt;/p&gt;&lt;p&gt;In an exclusive interview with VentureBeat, Doris Jwo, Writer&amp;#x27;s director of product management, demonstrated how the system works: A user types a request in plain English — for example, &amp;quot;Create a two-page partnership proposal between [Company A] and [Company B], make it a branded deck, include impact metrics and partnership tiers.&amp;quot;&lt;/p&gt;&lt;p&gt;The AI agent then breaks down that request into discrete steps, conducts web research, generates graphics and charts on the fly, creates individual slides with sourced information, and assembles a complete presentation. The entire process, which might take an employee hours or days, can be completed in 10-12 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;The agent basically looks at the request, breaks it down, does research, understands what pieces it needs, creates a detailed plan at a step-by-step level,&amp;quot; Jwo explained during a product demonstration. &amp;quot;It might say, &amp;#x27;I need to do web research,&amp;#x27; or &amp;#x27;This user needs information from Gong or Slack,&amp;#x27; and it reaches out to those connectors, grabs the data, and executes the plan.&amp;quot;&lt;/p&gt;&lt;p&gt;Crucially, users can save these multi-step processes as Playbooks—reusable templates that colleagues can deploy with a single click. Routines allow those Playbooks to run automatically at scheduled intervals, essentially putting knowledge work &amp;quot;on autopilot.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Security and compliance controls: Writer&amp;#x27;s answer to enterprise IT concerns&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer positions these enterprise-focused controls as a key differentiator from competitors. While &lt;a href="https://microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; offer powerful AI capabilities, Writer&amp;#x27;s executives argue those tools weren&amp;#x27;t designed from the ground up for the security, compliance, and governance requirements of large regulated organizations.&lt;/p&gt;&lt;p&gt;&amp;quot;All of the products you mentioned are great products, but even Copilot is very much focused on personal productivity—summarizing email, for example, which is important, but that&amp;#x27;s not the component we&amp;#x27;re focusing on,&amp;quot; said Matan-Paul Shetrit, Writer&amp;#x27;s director of product management, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Shetrit emphasized Writer&amp;#x27;s &amp;quot;trust, security, and interoperability&amp;quot; approach. IT administrators can granularly control what the AI can access — for instance, preventing market research agents from mentioning competitors, or restricting which employees can use web search capabilities. All activity is logged with detailed audit trails showing exactly what data the agent touched and what actions it took.&lt;/p&gt;&lt;p&gt;&amp;quot;These fine-grained controls are what make products enterprise-ready,&amp;quot; Shetrit said. &amp;quot;We can deploy to tens of thousands or hundreds of thousands of employees while maintaining the security and guardrails you need for that scale.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture reflects &lt;a href="https://writer.com/company/about/"&gt;&lt;u&gt;Writer&amp;#x27;s origin story&lt;/u&gt;&lt;/a&gt;. Unlike OpenAI or Anthropic, which started as research labs and later added enterprise offerings, Writer has targeted Fortune 500 companies since its 2020 founding. &amp;quot;We&amp;#x27;re not a research lab that went to consumer and is dabbling in enterprise,&amp;quot; Shetrit said. &amp;quot;We are first and foremost targeting the Global 2000 and Fortune 500, and our research is in service of these customers&amp;#x27; needs.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Writer&amp;#x27;s strategy to connect AI agents across enterprise software systems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A critical technical component is Writer&amp;#x27;s approach to system integrations. The platform includes pre-built connectors to more than a dozen enterprise applications—&lt;a href="https://workspace.google.com/lp/business/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Google+Workspace-Core-346911454270&amp;amp;utm_term=google%20workspace&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=20159848966&amp;amp;gclid=CjwKCAiAz_DIBhBJEiwAVH2XwDbhidrT22spa5fU8uNyySir49xeTOAji42tQEy7zvzTZpUAL4TFgRoCLz8QAvD_BwE"&gt;&lt;u&gt;Google Workspace&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.microsoft.com/en-us/microsoft-365"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.snowflake.com/en/"&gt;&lt;u&gt;Snowflake&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://asana.com/"&gt;&lt;u&gt;Asana&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.atlassian.com/"&gt;&lt;u&gt;Atlassian&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.databricks.com/"&gt;&lt;u&gt;Databricks&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt;—allowing the AI to retrieve information and take actions across those systems.&lt;/p&gt;&lt;p&gt;Writer built these connectors using the &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI system integrations, but added what Shetrit described as an &amp;quot;enterprise-ready&amp;quot; layer on top.&lt;/p&gt;&lt;p&gt;&amp;quot;We took a first-principle approach of: You have this MCP connector infrastructure—how do you build it in a way that&amp;#x27;s enterprise-ready?&amp;quot; Shetrit explained. &amp;quot;What we have today in the industry is definitely not it.&amp;quot;&lt;/p&gt;&lt;p&gt;The system can write and execute code on the fly to handle unexpected scenarios. If a user uploads an unfamiliar file format, for instance, the agent will generate code to extract and process the text without requiring a human to intervene.&lt;/p&gt;&lt;p&gt;Jwo demonstrated this capability with a daily workflow she runs: Every morning at 10 a.m., a Routine automatically summarizes her Google Calendar meetings, identifies external participants, finds their LinkedIn profiles, and sends the summary to her via Slack — all without her involvement.&lt;/p&gt;&lt;p&gt;&amp;quot;This was pretty simple, but you can imagine for a salesperson it might say, &amp;#x27;At the end of the day, wrap up a summary of all the calls I had, send me action items, post it to the account-specific Slack channel, and tag these folks so they can accomplish those workflows,&amp;#x27;&amp;quot; Jwo said. &amp;quot;That can run continuously each day, each week, or on demand.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From mortgage lenders to CPG brands: Real-world AI agent use cases across industries&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform is attracting customers across multiple industries. &lt;a href="https://www.newamericanfunding.com/"&gt;&lt;u&gt;New American Funding&lt;/u&gt;&lt;/a&gt;, a mortgage lender, uses Writer Agent to automate marketing workflows. Senior Content Marketing Manager Karen Rodriguez uploads Asana project tickets with creative briefs, and the AI executes tasks like updating email campaigns or transforming articles into social media carousels, video scripts, and captions.&lt;/p&gt;&lt;p&gt;Other use cases span financial services teams creating investment dashboards with &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt; data, consumer packaged goods companies brainstorming new product lines based on social media trends, and marketing teams generating partnership presentations with branded assets.&lt;/p&gt;&lt;p&gt;Writer has added customers including &lt;a href="https://www.tiktok.com/en/"&gt;&lt;u&gt;TikTok&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.cmcsa.com/"&gt;&lt;u&gt;Comcast&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.keurigdrpepper.com/"&gt;&lt;u&gt;Keurig Dr Pepper&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.caa.com/"&gt;&lt;u&gt;CAA&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.aptitudehealth.com/"&gt;&lt;u&gt;Aptitude Health&lt;/u&gt;&lt;/a&gt;, joining an existing base that includes &lt;a href="https://www.accenture.com/"&gt;&lt;u&gt;Accenture&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.qualcomm.com/"&gt;&lt;u&gt;Qualcomm&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.uber.com/"&gt;&lt;u&gt;Uber&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://investor.vanguard.com/corporate-portal"&gt;&lt;u&gt;Vanguard&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.marriott.com/default.mi"&gt;&lt;u&gt;Marriott&lt;/u&gt;&lt;/a&gt;. The company now serves more than 300 enterprises and has secured over $50 million in signed contracts, with projections to double that to $100 million this year.&lt;/p&gt;&lt;p&gt;The startup&amp;#x27;s net retention rate — a measure of how much existing customers expand their usage — stands at 160%, meaning customers on average increase their spending by 60% after initial contracts. Twenty customers who started with $200,000-$300,000 contracts now spend about $1 million annually, according to company data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&amp;#x27;Vibe working&amp;#x27;: Writer&amp;#x27;s vision for AI-powered productivity beyond coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer executives frame the platform as enabling what they call &amp;quot;vibe working&amp;quot; — a playful reference to the popular term &amp;quot;vibe coding,&amp;quot; which describes AI tools like Cursor that dramatically accelerate software development.&lt;/p&gt;&lt;p&gt;&amp;quot;We used to call it transformation when we took 12 steps and made them nine. That&amp;#x27;s optimizing the world as it is,&amp;quot; Habib said at Writer&amp;#x27;s AI Leaders Forum earlier this month, according to &lt;a href="https://www.forbes.com/sites/stevenwolfepereira/2025/11/08/what-writers-ai-leaders-forum-revealed-about-enterprise-ai/"&gt;&lt;u&gt;Forbes&lt;/u&gt;&lt;/a&gt;. &amp;quot;We can now create a new world. That is the greenfield mindset.&amp;quot;&lt;/p&gt;&lt;p&gt;Shetrit echoed this framing: &amp;quot;Vibe coding is the theme of 2025. Our view is that ‘vibe working’ is the theme of 2026. How do you bring the same productivity gains you&amp;#x27;ve seen with coding agents into the workspace in a way that non-technical users can maximize them?&amp;quot;&lt;/p&gt;&lt;p&gt;The platform is powered by &lt;a href="https://writer.com/engineering/long-context-palmyra-x5/"&gt;&lt;u&gt;Palmyra X5&lt;/u&gt;&lt;/a&gt;, Writer&amp;#x27;s proprietary large language model featuring a one-million-token context window — among the largest commercially available. Writer trained the model for approximately $700,000, a fraction of the estimated $100 million OpenAI spent on GPT-4, by using synthetic data and techniques that halt training when returns diminish.&lt;/p&gt;&lt;p&gt;The model can process one million tokens in about 22 seconds and costs 60 cents per million input tokens and $6 per million output tokens — significantly cheaper than comparable offerings, according to company specifications.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making AI Decisions Visible: Writer&amp;#x27;s Approach to Trust and Transparency&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A distinctive aspect of Writer&amp;#x27;s approach is transparency into the AI&amp;#x27;s decision-making process. The interface displays the agent&amp;#x27;s step-by-step reasoning, showing which data sources it accessed, what code it generated, and how it arrived at outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s a very clear exhibition of how the agent is thinking, what it&amp;#x27;s doing, what it&amp;#x27;s touching,&amp;quot; Shetrit said. &amp;quot;This is important for the end user to trust it, but also important for the IT person or security professional to see what&amp;#x27;s going on.&amp;quot;&lt;/p&gt;&lt;p&gt;This &amp;quot;supervision&amp;quot; model goes beyond simple observability of API calls to encompass what Shetrit described as &amp;quot;a superset of observability&amp;quot; — giving organizations the ability to not just monitor but control AI behavior through policies and permissions.&lt;/p&gt;&lt;p&gt;Session logs capture all agent activity when enabled by administrators, and users can submit feedback on every output to help improve system performance. The platform also emphasizes providing sources and citations for generated content, allowing users to verify information.&lt;/p&gt;&lt;p&gt;&amp;quot;With any sort of chat assistant, agentic or not, trust but verify is really important,&amp;quot; Jwo said. &amp;quot;That&amp;#x27;s part of the pillars of us building this and making it enterprise-grade.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Writer Agent Costs—and Why It&amp;#x27;s Included in the Base Platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer is including all the new capabilities—Playbooks, Routines, Connectors, and Personality customization—as part of its core platform without additional charges, according to Jwo.&lt;/p&gt;&lt;p&gt;&amp;quot;This is fully included as part of the Writer platform,&amp;quot; she said. &amp;quot;We&amp;#x27;re not charging additional for using Writer Agent.&amp;quot;&lt;/p&gt;&lt;p&gt;The &amp;quot;Personality&amp;quot; feature allows individual users, teams, or entire organizations to customize the AI&amp;#x27;s communication style, ensuring generated content matches brand voice and tone guidelines. This works alongside company-level controls that enforce terminology and style requirements.&lt;/p&gt;&lt;p&gt;For highly structured, repetitive tasks, Writer also offers a library of more than 100 pre-built agents and an AI Studio for building custom multi-agent systems aligned with specific business use cases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Race to Define Enterprise AI: Can Purpose-Built Platforms Beat Tech Giants?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch crystallizes a fundamental tension in how enterprises will adopt AI at scale. While consumer-facing AI tools emphasize individual productivity gains, companies need systems that work reliably across thousands of employees, integrate with existing software infrastructure, maintain regulatory compliance, and deliver measurable business impact.&lt;/p&gt;&lt;p&gt;Writer&amp;#x27;s wager is that these requirements demand purpose-built enterprise platforms rather than consumer tools adapted for business use. The company&amp;#x27;s &lt;a href="https://techcrunch.com/2024/11/12/generative-ai-startup-writer-raises-200m-at-a-1-9b-valuation/"&gt;&lt;u&gt;$1.9 billion valuation&lt;/u&gt;&lt;/a&gt; — achieved in a November 2024 funding round that raised $200 million — suggests investors see merit in this thesis. Backers include &lt;a href="https://www.premjiinvest.com/"&gt;&lt;u&gt;Premji Invest&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://radical.vc/"&gt;&lt;u&gt;Radical Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.iconiqcapital.com/growth"&gt;&lt;u&gt;ICONIQ Growth&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://salesforceventures.com/"&gt;&lt;u&gt;Salesforce Ventures&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.adobe.com/ventures.html"&gt;&lt;u&gt;Adobe Ventures&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yet the competitive landscape remains formidable. Microsoft and Google command enormous distribution advantages through their existing enterprise software relationships. OpenAI and Anthropic possess research capabilities that have produced breakthrough models. Whether Writer can maintain its differentiation as these giants expand their enterprise offerings will test the startup&amp;#x27;s core premise: that serving Fortune 500 companies from day one creates advantages that research labs turned enterprise vendors cannot easily replicate.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re entering an era where if you can describe a better way to work, you can build it,&amp;quot; Jwo said. &amp;quot;The new Writer Agent democratizes who gets to be a builder, empowering the operational experts and creative problem-solvers in every department to become the architects of their own transformation. That&amp;#x27;s how you unlock innovation that competitors can&amp;#x27;t replicate.&amp;quot;&lt;/p&gt;&lt;p&gt;The promise is alluring — AI capabilities powerful enough to transform how work gets done, accessible enough for any employee to use, and controlled enough for enterprises to deploy safely at scale. Whether Writer can deliver on that promise at the speed and scale required will determine if its vision of &amp;quot;vibe working&amp;quot; becomes the 2026 theme Shetrit predicts, or just another ambitious attempt to solve enterprise AI&amp;#x27;s execution problem.&lt;/p&gt;&lt;p&gt;But one thing is certain: In a market where 85% of AI initiatives fail to escape pilot purgatory, Writer is betting that the winners won&amp;#x27;t be the companies with the most powerful models—they&amp;#x27;ll be the ones that make those models actually work inside the enterprise.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/writers-ai-agents-can-actually-do-your-work-not-just-chat-about-it</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Microsoft remakes Windows for an era of autonomous AI agents (AI | VentureBeat)</title><link>https://venturebeat.com/ai/microsoft-remakes-windows-for-an-era-of-autonomous-ai-agents</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is fundamentally restructuring its Windows operating system to become what executives call the first &amp;quot;agentic OS,&amp;quot; embedding the infrastructure needed for autonomous AI agents to operate securely at enterprise scale — a watershed moment in the evolution of personal computing that positions the 40-year-old platform as the foundation for a new era of human-machine collaboration.&lt;/p&gt;&lt;p&gt;The company announced Tuesday at its &lt;a href="https://ignite.microsoft.com/en-US/home"&gt;&lt;u&gt;Ignite conference&lt;/u&gt;&lt;/a&gt; that it is introducing native agent infrastructure directly into &lt;a href="http://microsoft.com/en-us/windows/windows-11?r=1"&gt;&lt;u&gt;Windows 11&lt;/u&gt;&lt;/a&gt;, allowing AI agents — autonomous software programs that can perform complex, multi-step tasks on behalf of users — to discover tools, execute workflows, and interact with applications through standardized protocols while operating in secure, policy-controlled environments separate from user sessions.&lt;/p&gt;&lt;p&gt;The shift is Microsoft&amp;#x27;s most significant architectural evolution of Windows since the introduction of the modern security model, transforming the operating system from a platform where users manually orchestrate applications into one where they can &amp;quot;simply express your desired outcome, and agents handle the complexity,&amp;quot; according to Pavan Davuluri, President of Windows &amp;amp; Devices at Microsoft.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows 11 starts with this notion of secure by design, secure by default,&amp;quot; Davuluri said in an exclusive interview with VentureBeat. &amp;quot;And a lot of the work that we&amp;#x27;re doing today, when we think about the engagement we have with our customers, the expectations they have with us is making sure we are building upon the fact that Windows is the most secure platform for them and is the most resilient platform as well.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcements arrive as enterprises are &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"&gt;&lt;u&gt;experimenting with AI agents&lt;/u&gt;&lt;/a&gt; but struggling with fragmented tooling, security concerns, and lack of centralized management — challenges that Microsoft believes only operating system-level integration can solve. The stakes are enormous: with Windows running on an estimated 1.4 billion devices globally, Microsoft&amp;#x27;s architectural choices will likely shape how organizations deploy autonomous AI systems for years to come.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;New platform primitives create foundation for agent computing&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;At the core of Microsoft&amp;#x27;s vision are three new platform capabilities entering preview that fundamentally change how agents operate on Windows. &lt;a href="https://learn.microsoft.com/en-us/connectors/overview"&gt;&lt;u&gt;Agent Connectors&lt;/u&gt;&lt;/a&gt; provide native support for the &lt;a href="https://learn.microsoft.com/en-us/dynamics365/release-plan/2025wave2/service/dynamics365-customer-service/connect-ai-agents-using-model-context-protocol-server"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an open standard introduced by Anthropic that allows AI agents to connect with external tools and data sources. Microsoft has built what it calls an &amp;quot;on-device registry&amp;quot; — a secure, manageable repository where developers can register their applications&amp;#x27; capabilities as agent connectors, making them discoverable to any compatible agent on the system.&lt;/p&gt;&lt;p&gt;&amp;quot;These are platform capabilities that then become available to all of our customers,&amp;quot; Davuluri explained, describing how the Windows file system, for example, becomes an agent connector that any MCP-compatible agent can access with user consent. &amp;quot;We&amp;#x27;re able to do this in a fashion that can scale for one but it also allows others to participate in the Windows registry for MCP.&amp;quot;&lt;/p&gt;&lt;p&gt;The architecture introduces an &lt;a href="https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/"&gt;&lt;u&gt;MCP proxy layer&lt;/u&gt;&lt;/a&gt; that handles authentication, authorization, and auditing for all communication between agents and connectors. Microsoft is launching with two built-in agent connectors for File Explorer and System Settings, allowing agents to manage files or adjust system configurations like switching between light and dark mode — all with explicit user permission.&lt;/p&gt;&lt;p&gt;&lt;a href="https://support.microsoft.com/en-us/windows/experimental-agentic-features-a25ede8a-e4c2-4841-85a8-44839191dfb3"&gt;&lt;u&gt;Agent Workspace&lt;/u&gt;&lt;/a&gt;, entering private preview, represents perhaps the most significant security innovation. It creates what Microsoft describes as &amp;quot;a contained, policy-controlled, and auditable environment where agents can interact with software&amp;quot; — essentially a parallel desktop session where agents operate with their own distinct identity, completely separate from the user&amp;#x27;s primary session.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to be able to have clarity in the identity of the agent that is operating in the local operating system,&amp;quot; Davuluri said, addressing security concerns about agents accessing sensitive data. &amp;quot;We want that session to be a session that is secure, that is policy control, that is manageable, that has transparency and auditability.&amp;quot;&lt;/p&gt;&lt;p&gt;Each agent workspace runs with minimal privileges by default, accessing only explicitly granted resources. The system maintains detailed audit logs distinguishing agent actions from user actions — critical for enterprises that need to prove compliance and track all changes to systems and data.&lt;/p&gt;&lt;p&gt;&lt;a href="https://adoption.microsoft.com/en-us/ai-agents/agents-in-microsoft-365/"&gt;&lt;u&gt;Windows 365 for Agents&lt;/u&gt;&lt;/a&gt; extends this infrastructure to the cloud, turning Microsoft&amp;#x27;s Cloud PC offering into execution environments for agents. Instead of running on local devices, agents can operate in secure, policy-controlled virtual machines in Azure, enabling what Microsoft calls &amp;quot;computer-using agents&amp;quot; to interact with legacy applications and perform automation tasks at scale without consuming local compute resources.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taskbar becomes command center for monitoring AI agents at work&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The infrastructure enables significant user interface changes designed to make agents as commonplace as applications. Microsoft is introducing &amp;quot;Ask Copilot on the taskbar,&amp;quot; a unified entry point in preview that combines Microsoft 365 Copilot, agent invocation, and traditional search in a single interface.&lt;/p&gt;&lt;p&gt;Users will be able to invoke agents using &amp;quot;@&amp;quot; mentions directly from the taskbar, then monitor their progress through familiar UI patterns like hover cards, progress badges, and notifications — all while continuing other work. When an agent completes a task or needs input, it surfaces updates through the taskbar without disrupting the user&amp;#x27;s primary workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve evolved and created new UX in the taskbar to reflect the unique needs of agents performing background tasks on your behalf,&amp;quot; said Navjot Virk, Corporate Vice President of Windows Experiences, describing features like progress bars and status badges that indicate when agents are working, need approval, or have completed tasks.&lt;/p&gt;&lt;p&gt;The design philosophy, Virk emphasized, centers on user control. &amp;quot;These experiences are designed to be opt in. We want to give customers full control over when and how they engage with copilots and agents.&amp;quot;&lt;/p&gt;&lt;p&gt;For commercial &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot"&gt;&lt;u&gt;Microsoft 365 Copilot&lt;/u&gt;&lt;/a&gt; users, the integration goes deeper. Microsoft is embedding Copilot directly into File Explorer, allowing users to ask questions, generate summaries, or draft emails based on document contents without leaving the file management interface. On Copilot+ PCs — devices with neural processing units capable of 40 trillion operations per second — new capabilities include converting any on-screen table into an Excel spreadsheet through the Click to Do feature.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Microsoft bets on open standards against Apple and Google&amp;#x27;s proprietary approaches&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s embrace of the open &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol&lt;/u&gt;&lt;/a&gt;, created by Anthropic, marks a strategic bet on openness as enterprises evaluate competing AI platforms from Apple and Google that use proprietary frameworks.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is an open platform, and by virtue [of being] an open platform, we certainly have the ability to take existing technologies, evolve, harden, adapt those, but we also allow customers to bring their own capabilities to the platform as well,&amp;quot; Davuluri said when asked about competing with &lt;a href="https://www.apple.com/apple-intelligence/"&gt;&lt;u&gt;Apple Intelligence&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://www.android.com/enterprise/ai-at-work/"&gt;&lt;u&gt;Android AI for Enterprise&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company demonstrated this openness with Claude, Anthropic&amp;#x27;s AI assistant, accessing the Windows file system through agent connectors with user consent — one of numerous partnerships Microsoft has secured. Dynamics 365 is using the File Explorer connector to streamline expense reporting, reducing what was previously a 30-minute, dozen-step process to &amp;quot;one sentence with high accuracy,&amp;quot; according to Microsoft&amp;#x27;s blog post. Other early partners include &lt;a href="https://manus.im/"&gt;&lt;u&gt;Manus AI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://dash.dropbox.com/"&gt;&lt;u&gt;Dropbox Dash&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://roboflow.com/"&gt;&lt;u&gt;Roboflow&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.infosys.com/"&gt;&lt;u&gt;Infosys&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is the platform in which they build upon,&amp;quot; Davuluri said of enterprise customers. &amp;quot;And so our ability to take those existing bodies of work they have, and extend them is the, I think, the least friction way for them to go, learn, adopt, experiment and find ways to [scale].&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Security model enforces strict containment and mandatory user consent&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s security model for agents adheres to what it calls &amp;quot;&lt;a href="https://learn.microsoft.com/en-us/purview/deploymentmodels/depmod-securebydefault-intro"&gt;&lt;u&gt;secure by default&lt;/u&gt;&lt;/a&gt;&amp;quot; policies aligned with the company&amp;#x27;s broader &lt;a href="https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative"&gt;&lt;u&gt;Secure Future Initiative&lt;/u&gt;&lt;/a&gt;. All agent connectors registered in the on-device registry must meet strict requirements around packaging and identity, with applications properly packaged and signed by trusted sources. Developers must explicitly declare the minimum capabilities their agent connectors require, and agents and connectors run in isolated environments with dedicated agent user accounts, separate from human user accounts. Windows requires explicit user approval when agents first access sensitive resources like files or system settings.&lt;/p&gt;&lt;p&gt;&amp;quot;We give Windows the ability to go deliver on the security expectations, and then it is auditable at the end of the day,&amp;quot; Davuluri said. &amp;quot;You still want an auditability log that looks similar to perhaps what you use in the cloud. And so all three pieces are built into the design and architecture of Agent Workspace.&amp;quot;&lt;/p&gt;&lt;p&gt;For IT administrators, &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is introducing management policies through &lt;a href="https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/what-is-intune"&gt;&lt;u&gt;Intune&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/group-policy/group-policy-overview"&gt;&lt;u&gt;Group Policy&lt;/u&gt;&lt;/a&gt; that allow organizations to enable or disable agent features at device and account levels, set minimum security policy levels, and access event logs enumerating all agent connector invocations and errors. The company emphasized that agents operate with restricted privileges, with minimal permissions by default and access granted only to explicitly approved resources that users can revoke at any time. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Post-quantum cryptography and recovery tools address emerging and persistent threats&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond agent infrastructure, Microsoft announced significant security and resilience updates addressing both emerging and persistent enterprise challenges. &lt;a href="https://cloud.google.com/security/resources/post-quantum-cryptography?hl=en"&gt;&lt;u&gt;Post-Quantum Cryptography APIs&lt;/u&gt;&lt;/a&gt; are now generally available in Windows, allowing organizations to begin migrating to encryption algorithms designed to withstand future quantum computing attacks that could break today&amp;#x27;s cryptographic standards. Microsoft worked closely with the National Institute of Standards and Technology to implement these algorithms.&lt;/p&gt;&lt;p&gt;&amp;quot;We are introducing post quantum cryptography APIs in Windows,&amp;quot; Davuluri said. &amp;quot;For customers who want to be able to do cryptographic encryption in their workloads, they can start taking advantage of these APIs in Windows for the first time. That is a huge step forward for us when we think about the future of windows.&amp;quot;&lt;/p&gt;&lt;p&gt;Hardware-accelerated &lt;a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/"&gt;&lt;u&gt;BitLocker&lt;/u&gt;&lt;/a&gt; will arrive on new devices starting spring 2026, offloading disk encryption to dedicated silicon for faster performance while providing hardware-level key protection. Sysmon functionality is becoming generally available as part of Windows in early 2026, bringing advanced forensics and threat detection capabilities previously available only as a separate download directly into the operating system&amp;#x27;s event logging system.&lt;/p&gt;&lt;p&gt;The company also detailed progress on its Windows Resiliency Initiative, launched a year ago following the CrowdStrike incident that disrupted 8.5 million Windows devices globally. New recovery capabilities include Quick Machine Recovery with expanded networking support and Autopatch management, allowing IT to remotely fix devices stuck in Windows Recovery Environment. Point-in-time restore entering preview rolls back devices to earlier states to resolve update conflicts or configuration errors, while Cloud rebuild in preview allows IT to remotely rebuild malfunctioning devices by downloading fresh installation media and using Autopilot for zero-touch provisioning.&lt;/p&gt;&lt;p&gt;Microsoft is also raising security requirements for third-party drivers across the Windows ecosystem. Following updated requirements for antivirus drivers effective April 1, 2025, the company is expanding this approach to other driver classes including networking, cameras, USB, printers, and storage — requiring higher certification standards, adding compiler safeguards, and providing more Windows in-box drivers to reduce reliance on third-party kernel-mode code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Measured rollout reflects enterprise caution around autonomous software&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft is positioning these updates as essential infrastructure for what it calls &amp;quot;&lt;a href="https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born"&gt;&lt;u&gt;Frontier Firms&lt;/u&gt;&lt;/a&gt;&amp;quot; — organizations that &amp;quot;blend human ingenuity with intelligent systems to deliver real outcomes.&amp;quot; However, the company emphasized a cautious, opt-in approach that reflects enterprise concerns about autonomous software agents.&lt;/p&gt;&lt;p&gt;&amp;quot;The principles we&amp;#x27;re using in designing these new platform capabilities accounts for the reality that we have a very, very broad user base,&amp;quot; Davuluri said. &amp;quot;A lot of the features and capabilities we&amp;#x27;re building are opt in capabilities. And so it is our goal to be able to have users find value in the workflow and meet them.&amp;quot;&lt;/p&gt;&lt;p&gt;Virk emphasized the measured approach: &amp;quot;This is more about meeting customers where they are and then taking them on this journey when they are ready. So there&amp;#x27;s the optionality, but also having support for it. And really important thing is that they should feel comfortable. They should feel secure.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft&amp;#x27;s bet is that only operating system-level integration can provide the security, governance, and user experience required for mainstream AI agent adoption. Whether that vision materializes will depend on developer adoption, enterprise comfort with autonomous software, and Microsoft&amp;#x27;s ability to balance innovation with the stability that &lt;a href="https://gizmodo.com/windows-40-year-anniversary-evolving-into-bloated-ai-slop-copilot-2000686932"&gt;&lt;u&gt;40 years of Windows&lt;/u&gt;&lt;/a&gt; customers expect. After four decades of putting users in control of their computers, Windows is now asking them to share that control with machines.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is fundamentally restructuring its Windows operating system to become what executives call the first &amp;quot;agentic OS,&amp;quot; embedding the infrastructure needed for autonomous AI agents to operate securely at enterprise scale — a watershed moment in the evolution of personal computing that positions the 40-year-old platform as the foundation for a new era of human-machine collaboration.&lt;/p&gt;&lt;p&gt;The company announced Tuesday at its &lt;a href="https://ignite.microsoft.com/en-US/home"&gt;&lt;u&gt;Ignite conference&lt;/u&gt;&lt;/a&gt; that it is introducing native agent infrastructure directly into &lt;a href="http://microsoft.com/en-us/windows/windows-11?r=1"&gt;&lt;u&gt;Windows 11&lt;/u&gt;&lt;/a&gt;, allowing AI agents — autonomous software programs that can perform complex, multi-step tasks on behalf of users — to discover tools, execute workflows, and interact with applications through standardized protocols while operating in secure, policy-controlled environments separate from user sessions.&lt;/p&gt;&lt;p&gt;The shift is Microsoft&amp;#x27;s most significant architectural evolution of Windows since the introduction of the modern security model, transforming the operating system from a platform where users manually orchestrate applications into one where they can &amp;quot;simply express your desired outcome, and agents handle the complexity,&amp;quot; according to Pavan Davuluri, President of Windows &amp;amp; Devices at Microsoft.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows 11 starts with this notion of secure by design, secure by default,&amp;quot; Davuluri said in an exclusive interview with VentureBeat. &amp;quot;And a lot of the work that we&amp;#x27;re doing today, when we think about the engagement we have with our customers, the expectations they have with us is making sure we are building upon the fact that Windows is the most secure platform for them and is the most resilient platform as well.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcements arrive as enterprises are &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"&gt;&lt;u&gt;experimenting with AI agents&lt;/u&gt;&lt;/a&gt; but struggling with fragmented tooling, security concerns, and lack of centralized management — challenges that Microsoft believes only operating system-level integration can solve. The stakes are enormous: with Windows running on an estimated 1.4 billion devices globally, Microsoft&amp;#x27;s architectural choices will likely shape how organizations deploy autonomous AI systems for years to come.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;New platform primitives create foundation for agent computing&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;At the core of Microsoft&amp;#x27;s vision are three new platform capabilities entering preview that fundamentally change how agents operate on Windows. &lt;a href="https://learn.microsoft.com/en-us/connectors/overview"&gt;&lt;u&gt;Agent Connectors&lt;/u&gt;&lt;/a&gt; provide native support for the &lt;a href="https://learn.microsoft.com/en-us/dynamics365/release-plan/2025wave2/service/dynamics365-customer-service/connect-ai-agents-using-model-context-protocol-server"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an open standard introduced by Anthropic that allows AI agents to connect with external tools and data sources. Microsoft has built what it calls an &amp;quot;on-device registry&amp;quot; — a secure, manageable repository where developers can register their applications&amp;#x27; capabilities as agent connectors, making them discoverable to any compatible agent on the system.&lt;/p&gt;&lt;p&gt;&amp;quot;These are platform capabilities that then become available to all of our customers,&amp;quot; Davuluri explained, describing how the Windows file system, for example, becomes an agent connector that any MCP-compatible agent can access with user consent. &amp;quot;We&amp;#x27;re able to do this in a fashion that can scale for one but it also allows others to participate in the Windows registry for MCP.&amp;quot;&lt;/p&gt;&lt;p&gt;The architecture introduces an &lt;a href="https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/"&gt;&lt;u&gt;MCP proxy layer&lt;/u&gt;&lt;/a&gt; that handles authentication, authorization, and auditing for all communication between agents and connectors. Microsoft is launching with two built-in agent connectors for File Explorer and System Settings, allowing agents to manage files or adjust system configurations like switching between light and dark mode — all with explicit user permission.&lt;/p&gt;&lt;p&gt;&lt;a href="https://support.microsoft.com/en-us/windows/experimental-agentic-features-a25ede8a-e4c2-4841-85a8-44839191dfb3"&gt;&lt;u&gt;Agent Workspace&lt;/u&gt;&lt;/a&gt;, entering private preview, represents perhaps the most significant security innovation. It creates what Microsoft describes as &amp;quot;a contained, policy-controlled, and auditable environment where agents can interact with software&amp;quot; — essentially a parallel desktop session where agents operate with their own distinct identity, completely separate from the user&amp;#x27;s primary session.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to be able to have clarity in the identity of the agent that is operating in the local operating system,&amp;quot; Davuluri said, addressing security concerns about agents accessing sensitive data. &amp;quot;We want that session to be a session that is secure, that is policy control, that is manageable, that has transparency and auditability.&amp;quot;&lt;/p&gt;&lt;p&gt;Each agent workspace runs with minimal privileges by default, accessing only explicitly granted resources. The system maintains detailed audit logs distinguishing agent actions from user actions — critical for enterprises that need to prove compliance and track all changes to systems and data.&lt;/p&gt;&lt;p&gt;&lt;a href="https://adoption.microsoft.com/en-us/ai-agents/agents-in-microsoft-365/"&gt;&lt;u&gt;Windows 365 for Agents&lt;/u&gt;&lt;/a&gt; extends this infrastructure to the cloud, turning Microsoft&amp;#x27;s Cloud PC offering into execution environments for agents. Instead of running on local devices, agents can operate in secure, policy-controlled virtual machines in Azure, enabling what Microsoft calls &amp;quot;computer-using agents&amp;quot; to interact with legacy applications and perform automation tasks at scale without consuming local compute resources.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taskbar becomes command center for monitoring AI agents at work&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The infrastructure enables significant user interface changes designed to make agents as commonplace as applications. Microsoft is introducing &amp;quot;Ask Copilot on the taskbar,&amp;quot; a unified entry point in preview that combines Microsoft 365 Copilot, agent invocation, and traditional search in a single interface.&lt;/p&gt;&lt;p&gt;Users will be able to invoke agents using &amp;quot;@&amp;quot; mentions directly from the taskbar, then monitor their progress through familiar UI patterns like hover cards, progress badges, and notifications — all while continuing other work. When an agent completes a task or needs input, it surfaces updates through the taskbar without disrupting the user&amp;#x27;s primary workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve evolved and created new UX in the taskbar to reflect the unique needs of agents performing background tasks on your behalf,&amp;quot; said Navjot Virk, Corporate Vice President of Windows Experiences, describing features like progress bars and status badges that indicate when agents are working, need approval, or have completed tasks.&lt;/p&gt;&lt;p&gt;The design philosophy, Virk emphasized, centers on user control. &amp;quot;These experiences are designed to be opt in. We want to give customers full control over when and how they engage with copilots and agents.&amp;quot;&lt;/p&gt;&lt;p&gt;For commercial &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot"&gt;&lt;u&gt;Microsoft 365 Copilot&lt;/u&gt;&lt;/a&gt; users, the integration goes deeper. Microsoft is embedding Copilot directly into File Explorer, allowing users to ask questions, generate summaries, or draft emails based on document contents without leaving the file management interface. On Copilot+ PCs — devices with neural processing units capable of 40 trillion operations per second — new capabilities include converting any on-screen table into an Excel spreadsheet through the Click to Do feature.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Microsoft bets on open standards against Apple and Google&amp;#x27;s proprietary approaches&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s embrace of the open &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol&lt;/u&gt;&lt;/a&gt;, created by Anthropic, marks a strategic bet on openness as enterprises evaluate competing AI platforms from Apple and Google that use proprietary frameworks.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is an open platform, and by virtue [of being] an open platform, we certainly have the ability to take existing technologies, evolve, harden, adapt those, but we also allow customers to bring their own capabilities to the platform as well,&amp;quot; Davuluri said when asked about competing with &lt;a href="https://www.apple.com/apple-intelligence/"&gt;&lt;u&gt;Apple Intelligence&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://www.android.com/enterprise/ai-at-work/"&gt;&lt;u&gt;Android AI for Enterprise&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company demonstrated this openness with Claude, Anthropic&amp;#x27;s AI assistant, accessing the Windows file system through agent connectors with user consent — one of numerous partnerships Microsoft has secured. Dynamics 365 is using the File Explorer connector to streamline expense reporting, reducing what was previously a 30-minute, dozen-step process to &amp;quot;one sentence with high accuracy,&amp;quot; according to Microsoft&amp;#x27;s blog post. Other early partners include &lt;a href="https://manus.im/"&gt;&lt;u&gt;Manus AI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://dash.dropbox.com/"&gt;&lt;u&gt;Dropbox Dash&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://roboflow.com/"&gt;&lt;u&gt;Roboflow&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.infosys.com/"&gt;&lt;u&gt;Infosys&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is the platform in which they build upon,&amp;quot; Davuluri said of enterprise customers. &amp;quot;And so our ability to take those existing bodies of work they have, and extend them is the, I think, the least friction way for them to go, learn, adopt, experiment and find ways to [scale].&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Security model enforces strict containment and mandatory user consent&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s security model for agents adheres to what it calls &amp;quot;&lt;a href="https://learn.microsoft.com/en-us/purview/deploymentmodels/depmod-securebydefault-intro"&gt;&lt;u&gt;secure by default&lt;/u&gt;&lt;/a&gt;&amp;quot; policies aligned with the company&amp;#x27;s broader &lt;a href="https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative"&gt;&lt;u&gt;Secure Future Initiative&lt;/u&gt;&lt;/a&gt;. All agent connectors registered in the on-device registry must meet strict requirements around packaging and identity, with applications properly packaged and signed by trusted sources. Developers must explicitly declare the minimum capabilities their agent connectors require, and agents and connectors run in isolated environments with dedicated agent user accounts, separate from human user accounts. Windows requires explicit user approval when agents first access sensitive resources like files or system settings.&lt;/p&gt;&lt;p&gt;&amp;quot;We give Windows the ability to go deliver on the security expectations, and then it is auditable at the end of the day,&amp;quot; Davuluri said. &amp;quot;You still want an auditability log that looks similar to perhaps what you use in the cloud. And so all three pieces are built into the design and architecture of Agent Workspace.&amp;quot;&lt;/p&gt;&lt;p&gt;For IT administrators, &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is introducing management policies through &lt;a href="https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/what-is-intune"&gt;&lt;u&gt;Intune&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/group-policy/group-policy-overview"&gt;&lt;u&gt;Group Policy&lt;/u&gt;&lt;/a&gt; that allow organizations to enable or disable agent features at device and account levels, set minimum security policy levels, and access event logs enumerating all agent connector invocations and errors. The company emphasized that agents operate with restricted privileges, with minimal permissions by default and access granted only to explicitly approved resources that users can revoke at any time. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Post-quantum cryptography and recovery tools address emerging and persistent threats&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond agent infrastructure, Microsoft announced significant security and resilience updates addressing both emerging and persistent enterprise challenges. &lt;a href="https://cloud.google.com/security/resources/post-quantum-cryptography?hl=en"&gt;&lt;u&gt;Post-Quantum Cryptography APIs&lt;/u&gt;&lt;/a&gt; are now generally available in Windows, allowing organizations to begin migrating to encryption algorithms designed to withstand future quantum computing attacks that could break today&amp;#x27;s cryptographic standards. Microsoft worked closely with the National Institute of Standards and Technology to implement these algorithms.&lt;/p&gt;&lt;p&gt;&amp;quot;We are introducing post quantum cryptography APIs in Windows,&amp;quot; Davuluri said. &amp;quot;For customers who want to be able to do cryptographic encryption in their workloads, they can start taking advantage of these APIs in Windows for the first time. That is a huge step forward for us when we think about the future of windows.&amp;quot;&lt;/p&gt;&lt;p&gt;Hardware-accelerated &lt;a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/"&gt;&lt;u&gt;BitLocker&lt;/u&gt;&lt;/a&gt; will arrive on new devices starting spring 2026, offloading disk encryption to dedicated silicon for faster performance while providing hardware-level key protection. Sysmon functionality is becoming generally available as part of Windows in early 2026, bringing advanced forensics and threat detection capabilities previously available only as a separate download directly into the operating system&amp;#x27;s event logging system.&lt;/p&gt;&lt;p&gt;The company also detailed progress on its Windows Resiliency Initiative, launched a year ago following the CrowdStrike incident that disrupted 8.5 million Windows devices globally. New recovery capabilities include Quick Machine Recovery with expanded networking support and Autopatch management, allowing IT to remotely fix devices stuck in Windows Recovery Environment. Point-in-time restore entering preview rolls back devices to earlier states to resolve update conflicts or configuration errors, while Cloud rebuild in preview allows IT to remotely rebuild malfunctioning devices by downloading fresh installation media and using Autopilot for zero-touch provisioning.&lt;/p&gt;&lt;p&gt;Microsoft is also raising security requirements for third-party drivers across the Windows ecosystem. Following updated requirements for antivirus drivers effective April 1, 2025, the company is expanding this approach to other driver classes including networking, cameras, USB, printers, and storage — requiring higher certification standards, adding compiler safeguards, and providing more Windows in-box drivers to reduce reliance on third-party kernel-mode code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Measured rollout reflects enterprise caution around autonomous software&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft is positioning these updates as essential infrastructure for what it calls &amp;quot;&lt;a href="https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born"&gt;&lt;u&gt;Frontier Firms&lt;/u&gt;&lt;/a&gt;&amp;quot; — organizations that &amp;quot;blend human ingenuity with intelligent systems to deliver real outcomes.&amp;quot; However, the company emphasized a cautious, opt-in approach that reflects enterprise concerns about autonomous software agents.&lt;/p&gt;&lt;p&gt;&amp;quot;The principles we&amp;#x27;re using in designing these new platform capabilities accounts for the reality that we have a very, very broad user base,&amp;quot; Davuluri said. &amp;quot;A lot of the features and capabilities we&amp;#x27;re building are opt in capabilities. And so it is our goal to be able to have users find value in the workflow and meet them.&amp;quot;&lt;/p&gt;&lt;p&gt;Virk emphasized the measured approach: &amp;quot;This is more about meeting customers where they are and then taking them on this journey when they are ready. So there&amp;#x27;s the optionality, but also having support for it. And really important thing is that they should feel comfortable. They should feel secure.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft&amp;#x27;s bet is that only operating system-level integration can provide the security, governance, and user experience required for mainstream AI agent adoption. Whether that vision materializes will depend on developer adoption, enterprise comfort with autonomous software, and Microsoft&amp;#x27;s ability to balance innovation with the stability that &lt;a href="https://gizmodo.com/windows-40-year-anniversary-evolving-into-bloated-ai-slop-copilot-2000686932"&gt;&lt;u&gt;40 years of Windows&lt;/u&gt;&lt;/a&gt; customers expect. After four decades of putting users in control of their computers, Windows is now asking them to share that control with machines.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/microsoft-remakes-windows-for-an-era-of-autonomous-ai-agents</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Google launches Gemini 3 with new coding app and record benchmark scores (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/gemini.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google released Gemini 3, its latest and most advanced foundation model, which is now immediately available through the Gemini app and AI search interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coming just seven months after the Gemini 2.5 release, the new model is Google’s most capable LLM yet, and an immediate contender for the most capable AI tool on the market. The release also comes less than a week after OpenAI released GPT 5.1, and a mere two months after Anthropic released Sonnet 4.5 — a reminder of the blistering pace of frontier model development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A more research-intensive version of the model, called Gemini 3 Deepthink, will also be made available to Google AI Ultra subscribers in the coming weeks, once it passes further rounds of safety testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Gemini 3, we’re seeing this massive jump in reasoning,” said Tulsee Doshi, Google’s head of product for the Gemini model. “It’s responding with a level of depth and nuance that we haven’t seen before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of that reasoning power is already registering on independent benchmarks. With a score of 37.4, the model marked the highest score on record on the Humanity’s Last Exam benchmark, meant to capture general reasoning and expertise. The previous high score, held by GPT-5 Pro, was 31.64. Gemini 3 also topped the leaderboard on LMArena, a human-led benchmark that measures user satisfaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Google, the Gemini app currently has more than 650 million monthly active users, and 13 million software developers have used the model as part of their workflow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the base model, Google also released a Gemini-powered coding interface called Google Antigravity, allowing for multi-pane agentic coding similar to agentic IDEs like Warp or Cursor 2.0. Specifically, Antigravity combines a ChatGPT-style prompt window with a command-line interface and a browser window that can show the impact of the changes made by the coding agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The agent can work with your editor, across your terminal, across your browser to make sure that it helps you build that application in the best way possible,” said DeepMind CTO Koray Kavukcuoglu.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/gemini.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google released Gemini 3, its latest and most advanced foundation model, which is now immediately available through the Gemini app and AI search interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coming just seven months after the Gemini 2.5 release, the new model is Google’s most capable LLM yet, and an immediate contender for the most capable AI tool on the market. The release also comes less than a week after OpenAI released GPT 5.1, and a mere two months after Anthropic released Sonnet 4.5 — a reminder of the blistering pace of frontier model development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A more research-intensive version of the model, called Gemini 3 Deepthink, will also be made available to Google AI Ultra subscribers in the coming weeks, once it passes further rounds of safety testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Gemini 3, we’re seeing this massive jump in reasoning,” said Tulsee Doshi, Google’s head of product for the Gemini model. “It’s responding with a level of depth and nuance that we haven’t seen before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of that reasoning power is already registering on independent benchmarks. With a score of 37.4, the model marked the highest score on record on the Humanity’s Last Exam benchmark, meant to capture general reasoning and expertise. The previous high score, held by GPT-5 Pro, was 31.64. Gemini 3 also topped the leaderboard on LMArena, a human-led benchmark that measures user satisfaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Google, the Gemini app currently has more than 650 million monthly active users, and 13 million software developers have used the model as part of their workflow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the base model, Google also released a Gemini-powered coding interface called Google Antigravity, allowing for multi-pane agentic coding similar to agentic IDEs like Warp or Cursor 2.0. Specifically, Antigravity combines a ChatGPT-style prompt window with a command-line interface and a browser window that can show the impact of the changes made by the coding agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The agent can work with your editor, across your terminal, across your browser to make sure that it helps you build that application in the best way possible,” said DeepMind CTO Koray Kavukcuoglu.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Google’s new Gemini 3 “vibe-codes” responses and comes with its own agent (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1128065/googles-gemini-3/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Gemini-3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The previous model, Gemini 2.5, supports multimodal input. Users can feed it images, handwriting, or voice. But it usually requires explicit instructions about the format the user wants back, and it defaults to plain text regardless.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But Gemini 3 introduces what Google calls “generative interfaces,” which allow the model to make its own choices about what kind of output fits the prompt best, assembling visual layouts and dynamic views on its own instead of returning a block of text.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ask for travel recommendations and it may spin up a website-like interface inside the app, complete with modules, images, and follow-up prompts such as “How many days are you traveling?” or “What kinds of activities do you enjoy?” It also presents clickable options based on what you might want next.&lt;/p&gt; 
 &lt;p&gt;When asked to explain a concept, Gemini 3 may sketch a diagram or generate a simple animation on its own if it believes a visual is more effective.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“Visual layout generates an immersive, magazine-style view complete with photos and modules,” says Josh Woodward, VP of Google Labs, Gemini, and AI Studio. “These elements don’t just look good but invite your input to further tailor the results.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;With Gemini 3, Google is also introducing Gemini Agent, an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similar to other agents, it breaks tasks into discrete steps, displays its progress in real time, and pauses for approval from the user before continuing. Google describes the feature as a step toward “a true generalist agent.” It will be available on the web for Google AI Ultra subscribers in the US starting November 18.&lt;/p&gt;  &lt;p&gt;The overall approach can seem a lot like “vibe coding,” where users describe an end goal in plain language and let the model assemble the interface or code needed to get there.&lt;/p&gt;  &lt;p&gt;The update also ties Gemini more deeply into Google’s existing products. In Search, a limited group of Google AI Pro and Ultra subscribers can now switch to Gemini 3 Pro, the reasoning variation of the new model, to receive deeper, more thorough AI-generated summaries that rely on the model’s reasoning rather than the existing AI Mode.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;For shopping, Gemini will now pull from Google’s Shopping Graph—which the company says contains more than 50 billion product listings—to generate its own recommendation guides. Users just need to ask a shopping-related question or search a shopping-related phrase, and the model assembles an interactive, Wirecutter-style product recommendation piece, complete with prices and product details, without redirecting to an external site.&lt;/p&gt;  &lt;p&gt;For developers, Google is also pushing single-prompt software generation further. The company introduced Google Antigravity, a&amp;nbsp; development platform that acts as an all-in-one space where code, tools, and workflows can be created and managed from a single prompt.&lt;/p&gt;  &lt;p&gt;Derek Nee, CEO of Flowith, an agentic AI application, told &lt;em&gt;MIT Technology Revie&lt;/em&gt;w that Gemini 3 Pro addresses several gaps in earlier models. Improvements include stronger visual understanding, better code generation, and better performance on long tasks—features he sees as essential for developers of AI apps and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Given its speed and cost advantages, we’re integrating the new model into our product,” he says. “We’re optimistic about its potential, but we need deeper testing to understand how far it can go.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Gemini-3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The previous model, Gemini 2.5, supports multimodal input. Users can feed it images, handwriting, or voice. But it usually requires explicit instructions about the format the user wants back, and it defaults to plain text regardless.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But Gemini 3 introduces what Google calls “generative interfaces,” which allow the model to make its own choices about what kind of output fits the prompt best, assembling visual layouts and dynamic views on its own instead of returning a block of text.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ask for travel recommendations and it may spin up a website-like interface inside the app, complete with modules, images, and follow-up prompts such as “How many days are you traveling?” or “What kinds of activities do you enjoy?” It also presents clickable options based on what you might want next.&lt;/p&gt; 
 &lt;p&gt;When asked to explain a concept, Gemini 3 may sketch a diagram or generate a simple animation on its own if it believes a visual is more effective.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“Visual layout generates an immersive, magazine-style view complete with photos and modules,” says Josh Woodward, VP of Google Labs, Gemini, and AI Studio. “These elements don’t just look good but invite your input to further tailor the results.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;With Gemini 3, Google is also introducing Gemini Agent, an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similar to other agents, it breaks tasks into discrete steps, displays its progress in real time, and pauses for approval from the user before continuing. Google describes the feature as a step toward “a true generalist agent.” It will be available on the web for Google AI Ultra subscribers in the US starting November 18.&lt;/p&gt;  &lt;p&gt;The overall approach can seem a lot like “vibe coding,” where users describe an end goal in plain language and let the model assemble the interface or code needed to get there.&lt;/p&gt;  &lt;p&gt;The update also ties Gemini more deeply into Google’s existing products. In Search, a limited group of Google AI Pro and Ultra subscribers can now switch to Gemini 3 Pro, the reasoning variation of the new model, to receive deeper, more thorough AI-generated summaries that rely on the model’s reasoning rather than the existing AI Mode.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;For shopping, Gemini will now pull from Google’s Shopping Graph—which the company says contains more than 50 billion product listings—to generate its own recommendation guides. Users just need to ask a shopping-related question or search a shopping-related phrase, and the model assembles an interactive, Wirecutter-style product recommendation piece, complete with prices and product details, without redirecting to an external site.&lt;/p&gt;  &lt;p&gt;For developers, Google is also pushing single-prompt software generation further. The company introduced Google Antigravity, a&amp;nbsp; development platform that acts as an all-in-one space where code, tools, and workflows can be created and managed from a single prompt.&lt;/p&gt;  &lt;p&gt;Derek Nee, CEO of Flowith, an agentic AI application, told &lt;em&gt;MIT Technology Revie&lt;/em&gt;w that Gemini 3 Pro addresses several gaps in earlier models. Improvements include stronger visual understanding, better code generation, and better performance on long tasks—features he sees as essential for developers of AI apps and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Given its speed and cost advantages, we’re integrating the new model into our product,” he says. “We’re optimistic about its potential, but we need deeper testing to understand how far it can go.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1128065/googles-gemini-3/</guid><pubDate>Tue, 18 Nov 2025 16:00:07 +0000</pubDate></item><item><title>Delivering AI-Ready Enterprise Data With GPU-Accelerated AI Storage (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-data-platform-gpu-accelerated-storage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-data-platform-storage.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents have the potential to become indispensable tools for automating complex tasks. But bringing agents to production remains challenging.&lt;/p&gt;
&lt;p&gt;According to Gartner, “about 40% of AI prototypes make it into production, and participants reported data availability and quality as a top barrier to AI adoption.&lt;sup&gt;1&lt;/sup&gt;”&lt;/p&gt;
&lt;p&gt;Just like human workers, AI agents need secure, relevant, accurate and recent data to deliver business value — what the industry is now calling “AI-ready data.”&lt;/p&gt;
&lt;p&gt;Making enterprise data AI-ready presents unique challenges. Gartner estimates, “Unstructured data such as documents and multimedia files accounts for 70% to 90% of organizational data, and poses unique governance challenges due to its volume, variety and lack of coherent structure.&lt;sup&gt;2&lt;/sup&gt;” Unstructured data sources include email, PDFs, videos, audio clips and presentations.&lt;/p&gt;
&lt;p&gt;An emerging class of GPU-accelerated data and storage infrastructure — the AI data platform — transforms unstructured data into AI-ready data quickly and securely.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;What Is AI-Ready Data?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI-ready data can be consumed by AI training, fine-tuning and retrieval-augmented generation pipelines without additional preparation.&lt;/p&gt;
&lt;p&gt;Making unstructured data AI-ready involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting and curating data from diverse sources&lt;/li&gt;
&lt;li&gt;Applying metadata for data management and governance&lt;/li&gt;
&lt;li&gt;Dividing the source documents into semantically relevant chunks&lt;/li&gt;
&lt;li&gt;Embedding the chunks into vectors for efficient storage, search and retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enterprises cannot unlock the full value of their AI investments until their unstructured data is AI-ready.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why Making Data AI-Ready Is Difficult&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Making unstructured data AI-ready remains a substantial challenge for most enterprises due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data complexity&lt;/strong&gt;: A typical enterprise has hundreds of diverse data sources in dozens of formats and modalities — including video, audio, text and images. This data lives in different storage silos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data velocity&lt;/strong&gt;: The volume of business data is exploding. Predictions show global stored data will double over the next four years. And the rate of data change is increasing as enterprises adopt real-time streaming sensors such as camera feeds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data sprawl and data drift&lt;/strong&gt;: Frequent data copying and transformation introduces cost and security risks. Over time, the content or permissions of AI representations — such as text chunks and embeddings — diverge from source-of-truth documents. Plus, as the number of chatbots and agents proliferates, the security risk of data increases.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these factors force enterprise data scientists to spend the majority of their time locating, cleaning and organizing data — leaving less time for identifying valuable insights.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The AI Data Platform — a New Class of Enterprise Data and Storage Infrastructure&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI data platforms are an emerging class of GPU-accelerated data and storage infrastructure that makes enterprise data AI-ready.&lt;/p&gt;
&lt;p&gt;By embedding GPU acceleration directly into the data path, AI data platforms transform data for AI pipelines as a background operation invisible to the user.&lt;/p&gt;
&lt;p&gt;The data is prepared in place, minimizing unnecessary copies and associated security risks.&lt;/p&gt;
&lt;p&gt;By integrating data preparation as a core capability of storage infrastructure, AI data platforms ensure that the accuracy and security of the data is maintained. Any modifications to the sources of truth documents — including edits or permission changes — are instantly conveyed to their associated vector embeddings.&lt;/p&gt;
&lt;p&gt;Key benefits of AI data platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Faster time to value&lt;/strong&gt;: Enterprises don’t need to design, build and optimize AI data pipelines from the ground up. AI data platforms deliver an integrated, state-of-the-art AI data pipeline out of the box.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduced data drift&lt;/strong&gt;: By continuously ingesting, embedding and indexing enterprise data in near real time, AI data platforms reduce time to insight and minimize data drift.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved data security&lt;/strong&gt;: Because source-of-truth documents are stored together in AI data platforms, any changes to their contents or permissions are instantly propagated to the AI applications that use them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplified data governance&lt;/strong&gt;: Preparing data in place reduces the proliferation of shadow copies that undermine access control, traceability and compliance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved GPU utilization&lt;/strong&gt;: In an AI data platform, GPU capacity is sized for the amount, type and change velocity of the data under management. GPU capacity scales with the data, ensuring GPUs are not over- or under-provisioned for data preparation tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;The NVIDIA AI Data Platform&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI is changing every industry — and AI data platforms are the natural evolution of enterprise storage for the generative AI era, changing from passive containers to active engines delivering business value.&lt;/p&gt;
&lt;p&gt;By integrating GPU acceleration into the data path, AI data platforms enable enterprises to activate their AI agents with AI-ready data quickly and securely.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform reference design brings together NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA BlueField-3 DPUs and integrated AI data processing pipelines based on NVIDIA Blueprints.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform design has been adopted by leading AI infrastructure and storage providers including Cisco, Cloudian, DDN, Dell Technologies, Hitachi Vantara, HPE, IBM, NetApp, Pure Storage, VAST Data and WEKA — each extending the design with their own unique differentiation and innovation.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about the &lt;/i&gt;&lt;i&gt;NVIDIA AI Data Platform&lt;/i&gt;&lt;i&gt;. Plus, tune in to this&lt;/i&gt;&lt;i&gt; NVIDIA AI Podcast episode on AI data platforms:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/i&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;i&gt;Gartner, How to Design an Effective Data Quality Operating Model by Sue Waite and Melody Chien, 15 July 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;i&gt;Gartner, Governing Unstructured Data for AI Readiness: A Strategic Roadmap by Melody Chien, 14 August 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-data-platform-storage.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents have the potential to become indispensable tools for automating complex tasks. But bringing agents to production remains challenging.&lt;/p&gt;
&lt;p&gt;According to Gartner, “about 40% of AI prototypes make it into production, and participants reported data availability and quality as a top barrier to AI adoption.&lt;sup&gt;1&lt;/sup&gt;”&lt;/p&gt;
&lt;p&gt;Just like human workers, AI agents need secure, relevant, accurate and recent data to deliver business value — what the industry is now calling “AI-ready data.”&lt;/p&gt;
&lt;p&gt;Making enterprise data AI-ready presents unique challenges. Gartner estimates, “Unstructured data such as documents and multimedia files accounts for 70% to 90% of organizational data, and poses unique governance challenges due to its volume, variety and lack of coherent structure.&lt;sup&gt;2&lt;/sup&gt;” Unstructured data sources include email, PDFs, videos, audio clips and presentations.&lt;/p&gt;
&lt;p&gt;An emerging class of GPU-accelerated data and storage infrastructure — the AI data platform — transforms unstructured data into AI-ready data quickly and securely.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;What Is AI-Ready Data?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI-ready data can be consumed by AI training, fine-tuning and retrieval-augmented generation pipelines without additional preparation.&lt;/p&gt;
&lt;p&gt;Making unstructured data AI-ready involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting and curating data from diverse sources&lt;/li&gt;
&lt;li&gt;Applying metadata for data management and governance&lt;/li&gt;
&lt;li&gt;Dividing the source documents into semantically relevant chunks&lt;/li&gt;
&lt;li&gt;Embedding the chunks into vectors for efficient storage, search and retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enterprises cannot unlock the full value of their AI investments until their unstructured data is AI-ready.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why Making Data AI-Ready Is Difficult&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Making unstructured data AI-ready remains a substantial challenge for most enterprises due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data complexity&lt;/strong&gt;: A typical enterprise has hundreds of diverse data sources in dozens of formats and modalities — including video, audio, text and images. This data lives in different storage silos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data velocity&lt;/strong&gt;: The volume of business data is exploding. Predictions show global stored data will double over the next four years. And the rate of data change is increasing as enterprises adopt real-time streaming sensors such as camera feeds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data sprawl and data drift&lt;/strong&gt;: Frequent data copying and transformation introduces cost and security risks. Over time, the content or permissions of AI representations — such as text chunks and embeddings — diverge from source-of-truth documents. Plus, as the number of chatbots and agents proliferates, the security risk of data increases.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these factors force enterprise data scientists to spend the majority of their time locating, cleaning and organizing data — leaving less time for identifying valuable insights.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The AI Data Platform — a New Class of Enterprise Data and Storage Infrastructure&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI data platforms are an emerging class of GPU-accelerated data and storage infrastructure that makes enterprise data AI-ready.&lt;/p&gt;
&lt;p&gt;By embedding GPU acceleration directly into the data path, AI data platforms transform data for AI pipelines as a background operation invisible to the user.&lt;/p&gt;
&lt;p&gt;The data is prepared in place, minimizing unnecessary copies and associated security risks.&lt;/p&gt;
&lt;p&gt;By integrating data preparation as a core capability of storage infrastructure, AI data platforms ensure that the accuracy and security of the data is maintained. Any modifications to the sources of truth documents — including edits or permission changes — are instantly conveyed to their associated vector embeddings.&lt;/p&gt;
&lt;p&gt;Key benefits of AI data platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Faster time to value&lt;/strong&gt;: Enterprises don’t need to design, build and optimize AI data pipelines from the ground up. AI data platforms deliver an integrated, state-of-the-art AI data pipeline out of the box.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduced data drift&lt;/strong&gt;: By continuously ingesting, embedding and indexing enterprise data in near real time, AI data platforms reduce time to insight and minimize data drift.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved data security&lt;/strong&gt;: Because source-of-truth documents are stored together in AI data platforms, any changes to their contents or permissions are instantly propagated to the AI applications that use them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplified data governance&lt;/strong&gt;: Preparing data in place reduces the proliferation of shadow copies that undermine access control, traceability and compliance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved GPU utilization&lt;/strong&gt;: In an AI data platform, GPU capacity is sized for the amount, type and change velocity of the data under management. GPU capacity scales with the data, ensuring GPUs are not over- or under-provisioned for data preparation tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;The NVIDIA AI Data Platform&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI is changing every industry — and AI data platforms are the natural evolution of enterprise storage for the generative AI era, changing from passive containers to active engines delivering business value.&lt;/p&gt;
&lt;p&gt;By integrating GPU acceleration into the data path, AI data platforms enable enterprises to activate their AI agents with AI-ready data quickly and securely.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform reference design brings together NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA BlueField-3 DPUs and integrated AI data processing pipelines based on NVIDIA Blueprints.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform design has been adopted by leading AI infrastructure and storage providers including Cisco, Cloudian, DDN, Dell Technologies, Hitachi Vantara, HPE, IBM, NetApp, Pure Storage, VAST Data and WEKA — each extending the design with their own unique differentiation and innovation.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about the &lt;/i&gt;&lt;i&gt;NVIDIA AI Data Platform&lt;/i&gt;&lt;i&gt;. Plus, tune in to this&lt;/i&gt;&lt;i&gt; NVIDIA AI Podcast episode on AI data platforms:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/i&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;i&gt;Gartner, How to Design an Effective Data Quality Operating Model by Sue Waite and Melody Chien, 15 July 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;i&gt;Gartner, Governing Unstructured Data for AI Readiness: A Strategic Roadmap by Melody Chien, 14 August 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-data-platform-gpu-accelerated-storage/</guid><pubDate>Tue, 18 Nov 2025 16:00:34 +0000</pubDate></item><item><title>Realizing value with AI inference at scale and in production (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1128007/realizing-value-with-ai-inference-at-scale-and-in-production/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Training an AI model to predict equipment failures is an engineering achievement. But it's not until prediction meets action—the moment that model successfully flags a malfunctioning machine—that true business transformation occurs. One technical milestone lives in a proof-of-concept deck; the other meaningfully contributes to the bottom line.&lt;/p&gt;  &lt;p&gt;Craig Partridge, senior director worldwide of Digital Next Advisory at HPE, believes "the true value of AI lies in inference”. Inference is where AI earns its keep. It’s the operational layer that puts all that training to use in real-world workflows.&amp;nbsp;Partridge elaborates, "The phrase we use for this is 'trusted AI inferencing at scale and in production,'" he says. "That's where we think the biggest return on AI investments will come from."&lt;/p&gt;&lt;p&gt;Getting to that point is difficult. Christian Reichenbach, worldwide digital advisor at HPE, points to findings from the company's recent survey of 1,775 IT leaders: While nearly a quarter (22%) of organizations have now operationalized AI—up from 15% the previous year—the majority remain stuck in experimentation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Reaching the next stage requires a three-part approach: establishing trust as an operating principle, ensuring data-centric execution, and cultivating IT leadership capable of scaling AI successfully.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Trust as a prerequisite for scalable, high-stakes AI&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Trusted inference means users can actually rely on the answers they're getting from AI systems. This is important for applications like generating marketing copy and deploying customer service chatbots, but it's absolutely critical for higher-stakes scenarios—say, a robot assisting during surgeries or an autonomous vehicle navigating crowded streets.&lt;/p&gt; 
 &lt;p&gt;Whatever the use case, establishing trust will require doubling down on data quality; first and foremost, inferencing outcomes must be built on reliable foundations. This reality informs one of Partridge's go-to mantras: "Bad data in equals bad inferencing out."&lt;/p&gt;  &lt;p&gt;Reichenbach cites a real-world example of what happens when data quality falls short—the rise of unreliable AI-generated content, including hallucinations, that clogs workflows and forces employees to spend significant time fact-checking. "When things go wrong, trust goes down, productivity gains are not reached, and the outcome we're&amp;nbsp; looking for is not achieved," he says.&lt;/p&gt; 
 &lt;p&gt;On the other hand, when trust is properly engineered into inference systems, efficiency and productivity gains can increase. Take a network operations team tasked with troubleshooting configurations. With a trusted inferencing engine, that unit gains a reliable copilot that can deliver faster, more accurate, custom-tailored recommendations—"a 24/7 member of the team they didn't have before," says Partridge.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The shift to data-centric thinking and rise of the AI factory&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In the first AI wave, companies rushed to hire data scientists and many viewed sophisticated, trillion-parameter models as the primary goal. But today, as organizations move to turn early pilots into real, measurable outcomes, the focus has shifted toward data engineering and architecture.&lt;/p&gt;  &lt;p&gt;"Over the past five years, what's become more meaningful is breaking down data silos, accessing data streams, and quickly unlocking value," says Reichenbach. It’s an evolution happening alongside the rise of the AI factory—the always-on production line where data moves through pipelines and feedback loops to generate continuous intelligence.&lt;/p&gt;  &lt;p&gt;This shift reflects an evolution from model-centric to data-centric thinking, and with it comes a new set of strategic considerations. "It comes down to two things: How much of the intelligence--the model itself--is truly yours? And how much of the input--the data--is uniquely yours, from your customers, operations, or market?" says Reichenbach.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These two central questions inform everything from platform direction and operating models to engineering roles and trust and security considerations. To help clients map their answers—and translate them into actionable strategies—Partridge breaks down HPE's four-quadrant AI factory implication matrix (see figure):&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128011" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/HPE_AI-factory-implication-matrix_02@2x.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Source: HPE, 2025&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Run&lt;/strong&gt;: Accessing an external, pretrained model via an interface or API; organizations don’t own the model or the data. Implementation requires strong security and governance. It also requires establishing a center of excellence that makes and communicates decisions about AI usage.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;RAG (retrieval augmented generation)&lt;/strong&gt;: Using external, pre-trained models combined with a company’s proprietary data to create unique insights. Implementation focuses on connecting data streams to inferencing capabilities that provide rapid, integrated access to full-stack AI platforms.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Riches&lt;/strong&gt;: Training custom models on data that resides in the enterprise for unique differentiation opportunities and insights. Implementation requires scalable, energy-efficient environments, and often high-performance systems.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Regulate&lt;/strong&gt;: Leveraging custom models trained on external data, requiring the same scalable setup as Riches, but with added focus on legal and regulatory compliance for handling sensitive, non-owned data with extreme caution.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Importantly, these quadrants are not mutually exclusive. Partridge notes that most organizations—including HPE itself—operate across many of the quadrants. "We build our own models to help understand how networks operate," he says. "We then deploy that intelligence into our products, so that our end customer gets the chance to deliver in what we call the 'Run' quadrant. So for them, it's not their data; it's not their model. They're just adding that capability inside their organization."&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT's moment to scale—and lead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The second part of Partridge's catchphrase about inferencing—"at scale"— speaks to a primary tension in enterprise AI: what works for a handful of use cases often breaks when applied across an entire organization.&lt;/p&gt; 

 &lt;p&gt;"There's value in experimentation and kicking ideas around," he says. "But if you want to really see the benefits of AI, it needs to be something that everybody can engage in and that solves for many different use cases."&lt;/p&gt;  &lt;p&gt;In Partridge's view, the challenge of turning boutique pilots into organization-wide systems is uniquely suited to the IT function's core competencies—and it's a leadership opportunity the function can't afford to sit out. "IT takes things that are small-scale and implements the discipline required to run them at scale," he says. "So, IT organizations really need to lean into this debate."&lt;/p&gt;  &lt;p&gt;For IT teams content to linger on the sidelines, history offers a cautionary tale from the last major infrastructure shift: enterprise migration to the cloud. Many IT departments sat out decision-making during the early cloud adoption wave a decade ago, while business units independently deployed cloud services. This led to fragmented systems, redundant spending, and security gaps that took years to untangle.&lt;/p&gt;  &lt;p&gt;The same dynamic threatens to repeat with AI, as different teams experiment with tools and models outside IT's purview. This phenomenon—sometimes called shadow AI—describes environments where pilots proliferate without oversight or governance. Partridge believes that most organizations are already operating in the "Run" quadrant in some capacity, as employees will use AI tools whether or not they're officially authorized to.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Rather than shut down experimentation, it is now IT's mandate to bring structure to it. And enterprises must architect a data platform strategy that brings together enterprise data with guardrails, governance framework, and accessibility to feed AI. Also, it’s critical to keep standardizing infrastructure (such as private cloud AI platforms), protecting data integrity, and safeguarding brand trust, all while enabling the speed and flexibility that AI applications demand. These are the requirements for reaching the final milestone: AI that's truly in production.&lt;/p&gt;  &lt;p&gt;For teams on the path to that goal, Reichenbach distills what success requires. "It comes down to knowing where you play: When to Run external models smarter, when to apply RAG to make them more informed, where to invest to unlock Riches from your own data and models, and when to Regulate what you don't control," says Reichenbach. "The winners will be those who bring clarity to all quadrants and align technology ambition with governance and value creation."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Training an AI model to predict equipment failures is an engineering achievement. But it's not until prediction meets action—the moment that model successfully flags a malfunctioning machine—that true business transformation occurs. One technical milestone lives in a proof-of-concept deck; the other meaningfully contributes to the bottom line.&lt;/p&gt;  &lt;p&gt;Craig Partridge, senior director worldwide of Digital Next Advisory at HPE, believes "the true value of AI lies in inference”. Inference is where AI earns its keep. It’s the operational layer that puts all that training to use in real-world workflows.&amp;nbsp;Partridge elaborates, "The phrase we use for this is 'trusted AI inferencing at scale and in production,'" he says. "That's where we think the biggest return on AI investments will come from."&lt;/p&gt;&lt;p&gt;Getting to that point is difficult. Christian Reichenbach, worldwide digital advisor at HPE, points to findings from the company's recent survey of 1,775 IT leaders: While nearly a quarter (22%) of organizations have now operationalized AI—up from 15% the previous year—the majority remain stuck in experimentation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Reaching the next stage requires a three-part approach: establishing trust as an operating principle, ensuring data-centric execution, and cultivating IT leadership capable of scaling AI successfully.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Trust as a prerequisite for scalable, high-stakes AI&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Trusted inference means users can actually rely on the answers they're getting from AI systems. This is important for applications like generating marketing copy and deploying customer service chatbots, but it's absolutely critical for higher-stakes scenarios—say, a robot assisting during surgeries or an autonomous vehicle navigating crowded streets.&lt;/p&gt; 
 &lt;p&gt;Whatever the use case, establishing trust will require doubling down on data quality; first and foremost, inferencing outcomes must be built on reliable foundations. This reality informs one of Partridge's go-to mantras: "Bad data in equals bad inferencing out."&lt;/p&gt;  &lt;p&gt;Reichenbach cites a real-world example of what happens when data quality falls short—the rise of unreliable AI-generated content, including hallucinations, that clogs workflows and forces employees to spend significant time fact-checking. "When things go wrong, trust goes down, productivity gains are not reached, and the outcome we're&amp;nbsp; looking for is not achieved," he says.&lt;/p&gt; 
 &lt;p&gt;On the other hand, when trust is properly engineered into inference systems, efficiency and productivity gains can increase. Take a network operations team tasked with troubleshooting configurations. With a trusted inferencing engine, that unit gains a reliable copilot that can deliver faster, more accurate, custom-tailored recommendations—"a 24/7 member of the team they didn't have before," says Partridge.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The shift to data-centric thinking and rise of the AI factory&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In the first AI wave, companies rushed to hire data scientists and many viewed sophisticated, trillion-parameter models as the primary goal. But today, as organizations move to turn early pilots into real, measurable outcomes, the focus has shifted toward data engineering and architecture.&lt;/p&gt;  &lt;p&gt;"Over the past five years, what's become more meaningful is breaking down data silos, accessing data streams, and quickly unlocking value," says Reichenbach. It’s an evolution happening alongside the rise of the AI factory—the always-on production line where data moves through pipelines and feedback loops to generate continuous intelligence.&lt;/p&gt;  &lt;p&gt;This shift reflects an evolution from model-centric to data-centric thinking, and with it comes a new set of strategic considerations. "It comes down to two things: How much of the intelligence--the model itself--is truly yours? And how much of the input--the data--is uniquely yours, from your customers, operations, or market?" says Reichenbach.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These two central questions inform everything from platform direction and operating models to engineering roles and trust and security considerations. To help clients map their answers—and translate them into actionable strategies—Partridge breaks down HPE's four-quadrant AI factory implication matrix (see figure):&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128011" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/HPE_AI-factory-implication-matrix_02@2x.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Source: HPE, 2025&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Run&lt;/strong&gt;: Accessing an external, pretrained model via an interface or API; organizations don’t own the model or the data. Implementation requires strong security and governance. It also requires establishing a center of excellence that makes and communicates decisions about AI usage.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;RAG (retrieval augmented generation)&lt;/strong&gt;: Using external, pre-trained models combined with a company’s proprietary data to create unique insights. Implementation focuses on connecting data streams to inferencing capabilities that provide rapid, integrated access to full-stack AI platforms.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Riches&lt;/strong&gt;: Training custom models on data that resides in the enterprise for unique differentiation opportunities and insights. Implementation requires scalable, energy-efficient environments, and often high-performance systems.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Regulate&lt;/strong&gt;: Leveraging custom models trained on external data, requiring the same scalable setup as Riches, but with added focus on legal and regulatory compliance for handling sensitive, non-owned data with extreme caution.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Importantly, these quadrants are not mutually exclusive. Partridge notes that most organizations—including HPE itself—operate across many of the quadrants. "We build our own models to help understand how networks operate," he says. "We then deploy that intelligence into our products, so that our end customer gets the chance to deliver in what we call the 'Run' quadrant. So for them, it's not their data; it's not their model. They're just adding that capability inside their organization."&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT's moment to scale—and lead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The second part of Partridge's catchphrase about inferencing—"at scale"— speaks to a primary tension in enterprise AI: what works for a handful of use cases often breaks when applied across an entire organization.&lt;/p&gt; 

 &lt;p&gt;"There's value in experimentation and kicking ideas around," he says. "But if you want to really see the benefits of AI, it needs to be something that everybody can engage in and that solves for many different use cases."&lt;/p&gt;  &lt;p&gt;In Partridge's view, the challenge of turning boutique pilots into organization-wide systems is uniquely suited to the IT function's core competencies—and it's a leadership opportunity the function can't afford to sit out. "IT takes things that are small-scale and implements the discipline required to run them at scale," he says. "So, IT organizations really need to lean into this debate."&lt;/p&gt;  &lt;p&gt;For IT teams content to linger on the sidelines, history offers a cautionary tale from the last major infrastructure shift: enterprise migration to the cloud. Many IT departments sat out decision-making during the early cloud adoption wave a decade ago, while business units independently deployed cloud services. This led to fragmented systems, redundant spending, and security gaps that took years to untangle.&lt;/p&gt;  &lt;p&gt;The same dynamic threatens to repeat with AI, as different teams experiment with tools and models outside IT's purview. This phenomenon—sometimes called shadow AI—describes environments where pilots proliferate without oversight or governance. Partridge believes that most organizations are already operating in the "Run" quadrant in some capacity, as employees will use AI tools whether or not they're officially authorized to.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Rather than shut down experimentation, it is now IT's mandate to bring structure to it. And enterprises must architect a data platform strategy that brings together enterprise data with guardrails, governance framework, and accessibility to feed AI. Also, it’s critical to keep standardizing infrastructure (such as private cloud AI platforms), protecting data integrity, and safeguarding brand trust, all while enabling the speed and flexibility that AI applications demand. These are the requirements for reaching the final milestone: AI that's truly in production.&lt;/p&gt;  &lt;p&gt;For teams on the path to that goal, Reichenbach distills what success requires. "It comes down to knowing where you play: When to Run external models smarter, when to apply RAG to make them more informed, where to invest to unlock Riches from your own data and models, and when to Regulate what you don't control," says Reichenbach. "The winners will be those who bring clarity to all quadrants and align technology ambition with governance and value creation."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1128007/realizing-value-with-ai-inference-at-scale-and-in-production/</guid><pubDate>Tue, 18 Nov 2025 16:02:16 +0000</pubDate></item><item><title>Networking for AI: Building the foundation for real-time intelligence (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1127997/networking-for-ai-building-the-foundation-for-real-time-intelligence/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The Ryder Cup is an almost-century-old tournament pitting Europe against the United States in an elite showcase of golf skill and strategy. At the 2025 event, nearly a quarter of a million spectators gathered to watch three days of fierce competition on the fairways.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128002" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-Networking-image-16x9-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;From a technology and logistics perspective, pulling off an event of this scale is no easy feat. The Ryder Cup’s infrastructure must accommodate the tens of thousands of network users who flood the venue (this year, at Bethpage Black in Farmingdale, New York) every day.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;To manage this IT complexity, Ryder Cup engaged technology partner HPE to create a central hub for its operations. The solution centered around a platform where tournament staff could access data visualization supporting operational decision-making.&amp;nbsp;This dashboard, which leveraged a high-performance network and private-cloud environment, aggregated and distilled insights from diverse&amp;nbsp;real-time&amp;nbsp;data feeds.&lt;/p&gt;  &lt;p&gt;It was a glimpse into what AI-ready networking looks like at scale—a real-world stress test with implications for everything from event management to enterprise operations. While models and data readiness get the lion's share of boardroom attention and media hype, networking is a critical third leg of successful AI implementation, explains Jon Green, CTO of HPE Networking. “Disconnected AI doesn’t get you very much; you need a way to get data into it and out of it for both training and inference,” he says.&lt;/p&gt; 
 &lt;p&gt;As businesses move toward distributed, real-time AI applications, tomorrow’s networks will need to parse even more massive volumes of information at ever more lightning-fast speeds. What played out on the greens at Bethpage Black represents a lesson being learned across industries: Inference-ready networks are a make-or-break factor for turning AI’s promise into real-world performance.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Making a network AI inference-ready&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;More than half of organizations are still struggling to operationalize their data pipelines. In a recent HPE cross-industry survey of 1,775 &amp;nbsp;IT leaders, 45% said they could run real-time data pushes and pulls for innovation. It’s a noticeable change over last year’s numbers (just 7% reported having such capabilities in 2024), but there’s still work to be done to connect data collection with real-time decision-making.&lt;/p&gt; 
 &lt;p&gt;The network may hold the key to further narrowing that gap. Part of the solution will likely come down to infrastructure design. While traditional enterprise networks are engineered to handle the predictable flow of business applications—email, browsers, file sharing, etc.—they're not designed to field the dynamic, high-volume data movement required by AI workloads. Inferencing in particular depends on shuttling vast datasets between multiple GPUs with supercomputer-like precision.&lt;/p&gt;  &lt;p&gt;“There’s an ability to play fast and loose with a standard, off-the-shelf enterprise network,” says Green. “Few will notice if an email platform is half a second slower than it might’ve been. But with AI transaction processing, the entire job is gated by the last calculation taking place. So it becomes really noticeable if you’ve got any loss or congestion.”&lt;/p&gt;  &lt;p&gt;Networks built for AI, therefore, must operate with a different set of performance characteristics, including ultra-low latency, lossless throughput, specialized equipment, and adaptability at scale. One of these differences is AI’s distributed nature, which affects the seamless flow of data.&lt;/p&gt;  &lt;p&gt;The Ryder Cup was a vivid demonstration of this new class of networking in action. During the event, a Connected Intelligence Center was put in place to ingest data from ticket scans, weather reports, GPS-tracked golf carts, concession and merchandise sales, spectator and consumer queues, and network performance. Additionally, 67 AI-enabled cameras were positioned throughout the course. Inputs were analyzed through an operational intelligence dashboard and provided staff with an instantaneous view of activity across the grounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;"The tournament is really complex from a networking perspective, because you have many big open areas that aren't uniformly packed with people," explains Green. "People tend to follow the action. So in certain areas, it's really dense with lots of people and devices, while other areas are completely empty."&lt;/p&gt;  &lt;p&gt;To handle that variability, engineers built out a two-tiered architecture. Across the sprawling venue, more than 650 WiFi 6E access points, 170 network switches, and 25 user experience sensors worked together to maintain continuous connectivity and feed a private cloud AI cluster for live analytics. The front-end layer connected cameras, sensors, and access points to capture live video and movement data, while a back-end layer—located within a temporary on-site data center—linked GPUs and servers in a high-speed, low-latency configuration that effectively served as the system’s brain. Together, the setup enabled both rapid on-the-ground responses and data collection that could inform future operational planning. "AI models also were available to the team which could process video of the shots taken and help determine, from the footage, which ones were the most interesting,” says Green.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Physical AI and the return of on-prem intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;If time is of the essence for event management, it's even more critical in contexts where safety is on the line—for instance a self-driving car making a split-second decision to accelerate or brake.&lt;/p&gt;  &lt;p&gt;In planning for the rise of physical AI, where applications move off screens and onto factory floors and city streets, a growing number of enterprises are rethinking their architectures. Instead of sending the data to centralized clouds for inference, some are deploying edge-based AI clusters that process information closer to where it is generated. Data-intensive training may still occur in the cloud, but inferencing happens on-site.&lt;/p&gt; 

 &lt;p&gt;This hybrid approach is fueling a wave of operational repatriation, as workloads once relegated to the cloud return to on-premises infrastructure for enhanced speed, security, sovereignty, and cost reasons. "We’ve had an out-migration of IT into the cloud in recent years, but physical AI is one of the use cases that we believe will bring a lot of that back on-prem," predicts Green, giving the example of an AI-infused factory floor, where a round-trip of sensor data to the cloud would be too slow to safely control automated machinery. "By the time processing happens in the cloud, the machine has already moved," he explains.&lt;/p&gt;  &lt;p&gt;There's data to back up Green's projection: research&amp;nbsp;from Enterprise Research Group shows that 84% of respondents are reevaluating application deployment strategies due to the growth of AI. Market forecasts also reflect this shift. According to IDC, the AI market for infrastructure is expected to reach $758 billion by 2029.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI for networking and the future of self-driving infrastructure&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The relationship between networking and AI is circular: Modern networks make AI at scale possible, but AI is also helping make networks smarter and more capable.&lt;/p&gt;  &lt;p&gt;“Networks are some of the most data-rich systems in any organization,” says Green. “That makes them a perfect use case for AI. We can analyze millions of configuration states across thousands of customer environments and learn what actually improves performance or stability.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At HPE for example, which has one of the largest network telemetry repositories in the world, AI models analyze anonymized data collected from billions of connected devices to identify trends and refine behavior over time. The platform processes more than a trillion telemetry points each day, which means it can continuously learn from real-world conditions.&lt;/p&gt;  &lt;p&gt;The concept broadly known as AIOps (or AI-driven IT operations) is changing how enterprise networks are managed across industries. Today, AI surfaces insights as recommendations that administrators can choose to apply with a single click. Tomorrow, those same systems might automatically test and deploy low-risk changes themselves.&lt;/p&gt;  &lt;p&gt;That long-term vision, Green notes, is referred to as a “self-driving network”—one that handles the repetitive, error-prone tasks that have historically plagued IT teams. “AI isn’t coming for the network engineer’s job, but it will eliminate the tedious stuff that slows them down," he says. "You’ll be able to say, ‘Please go configure 130 switches to solve this issue,’ and the system will handle it. When a port gets stuck or someone plugs a connector in the wrong direction, AI can detect it—and in many cases, fix it automatically.”&lt;/p&gt;  &lt;p&gt;Digital initiatives now depend on how effectively information moves. Whether coordinating a live event or streamlining a supply chain, the performance of the network increasingly defines the performance of the business. Building that foundation today will separate those who pilot from those who scale AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The Ryder Cup is an almost-century-old tournament pitting Europe against the United States in an elite showcase of golf skill and strategy. At the 2025 event, nearly a quarter of a million spectators gathered to watch three days of fierce competition on the fairways.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128002" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-Networking-image-16x9-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;From a technology and logistics perspective, pulling off an event of this scale is no easy feat. The Ryder Cup’s infrastructure must accommodate the tens of thousands of network users who flood the venue (this year, at Bethpage Black in Farmingdale, New York) every day.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;To manage this IT complexity, Ryder Cup engaged technology partner HPE to create a central hub for its operations. The solution centered around a platform where tournament staff could access data visualization supporting operational decision-making.&amp;nbsp;This dashboard, which leveraged a high-performance network and private-cloud environment, aggregated and distilled insights from diverse&amp;nbsp;real-time&amp;nbsp;data feeds.&lt;/p&gt;  &lt;p&gt;It was a glimpse into what AI-ready networking looks like at scale—a real-world stress test with implications for everything from event management to enterprise operations. While models and data readiness get the lion's share of boardroom attention and media hype, networking is a critical third leg of successful AI implementation, explains Jon Green, CTO of HPE Networking. “Disconnected AI doesn’t get you very much; you need a way to get data into it and out of it for both training and inference,” he says.&lt;/p&gt; 
 &lt;p&gt;As businesses move toward distributed, real-time AI applications, tomorrow’s networks will need to parse even more massive volumes of information at ever more lightning-fast speeds. What played out on the greens at Bethpage Black represents a lesson being learned across industries: Inference-ready networks are a make-or-break factor for turning AI’s promise into real-world performance.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Making a network AI inference-ready&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;More than half of organizations are still struggling to operationalize their data pipelines. In a recent HPE cross-industry survey of 1,775 &amp;nbsp;IT leaders, 45% said they could run real-time data pushes and pulls for innovation. It’s a noticeable change over last year’s numbers (just 7% reported having such capabilities in 2024), but there’s still work to be done to connect data collection with real-time decision-making.&lt;/p&gt; 
 &lt;p&gt;The network may hold the key to further narrowing that gap. Part of the solution will likely come down to infrastructure design. While traditional enterprise networks are engineered to handle the predictable flow of business applications—email, browsers, file sharing, etc.—they're not designed to field the dynamic, high-volume data movement required by AI workloads. Inferencing in particular depends on shuttling vast datasets between multiple GPUs with supercomputer-like precision.&lt;/p&gt;  &lt;p&gt;“There’s an ability to play fast and loose with a standard, off-the-shelf enterprise network,” says Green. “Few will notice if an email platform is half a second slower than it might’ve been. But with AI transaction processing, the entire job is gated by the last calculation taking place. So it becomes really noticeable if you’ve got any loss or congestion.”&lt;/p&gt;  &lt;p&gt;Networks built for AI, therefore, must operate with a different set of performance characteristics, including ultra-low latency, lossless throughput, specialized equipment, and adaptability at scale. One of these differences is AI’s distributed nature, which affects the seamless flow of data.&lt;/p&gt;  &lt;p&gt;The Ryder Cup was a vivid demonstration of this new class of networking in action. During the event, a Connected Intelligence Center was put in place to ingest data from ticket scans, weather reports, GPS-tracked golf carts, concession and merchandise sales, spectator and consumer queues, and network performance. Additionally, 67 AI-enabled cameras were positioned throughout the course. Inputs were analyzed through an operational intelligence dashboard and provided staff with an instantaneous view of activity across the grounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;"The tournament is really complex from a networking perspective, because you have many big open areas that aren't uniformly packed with people," explains Green. "People tend to follow the action. So in certain areas, it's really dense with lots of people and devices, while other areas are completely empty."&lt;/p&gt;  &lt;p&gt;To handle that variability, engineers built out a two-tiered architecture. Across the sprawling venue, more than 650 WiFi 6E access points, 170 network switches, and 25 user experience sensors worked together to maintain continuous connectivity and feed a private cloud AI cluster for live analytics. The front-end layer connected cameras, sensors, and access points to capture live video and movement data, while a back-end layer—located within a temporary on-site data center—linked GPUs and servers in a high-speed, low-latency configuration that effectively served as the system’s brain. Together, the setup enabled both rapid on-the-ground responses and data collection that could inform future operational planning. "AI models also were available to the team which could process video of the shots taken and help determine, from the footage, which ones were the most interesting,” says Green.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Physical AI and the return of on-prem intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;If time is of the essence for event management, it's even more critical in contexts where safety is on the line—for instance a self-driving car making a split-second decision to accelerate or brake.&lt;/p&gt;  &lt;p&gt;In planning for the rise of physical AI, where applications move off screens and onto factory floors and city streets, a growing number of enterprises are rethinking their architectures. Instead of sending the data to centralized clouds for inference, some are deploying edge-based AI clusters that process information closer to where it is generated. Data-intensive training may still occur in the cloud, but inferencing happens on-site.&lt;/p&gt; 

 &lt;p&gt;This hybrid approach is fueling a wave of operational repatriation, as workloads once relegated to the cloud return to on-premises infrastructure for enhanced speed, security, sovereignty, and cost reasons. "We’ve had an out-migration of IT into the cloud in recent years, but physical AI is one of the use cases that we believe will bring a lot of that back on-prem," predicts Green, giving the example of an AI-infused factory floor, where a round-trip of sensor data to the cloud would be too slow to safely control automated machinery. "By the time processing happens in the cloud, the machine has already moved," he explains.&lt;/p&gt;  &lt;p&gt;There's data to back up Green's projection: research&amp;nbsp;from Enterprise Research Group shows that 84% of respondents are reevaluating application deployment strategies due to the growth of AI. Market forecasts also reflect this shift. According to IDC, the AI market for infrastructure is expected to reach $758 billion by 2029.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI for networking and the future of self-driving infrastructure&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The relationship between networking and AI is circular: Modern networks make AI at scale possible, but AI is also helping make networks smarter and more capable.&lt;/p&gt;  &lt;p&gt;“Networks are some of the most data-rich systems in any organization,” says Green. “That makes them a perfect use case for AI. We can analyze millions of configuration states across thousands of customer environments and learn what actually improves performance or stability.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At HPE for example, which has one of the largest network telemetry repositories in the world, AI models analyze anonymized data collected from billions of connected devices to identify trends and refine behavior over time. The platform processes more than a trillion telemetry points each day, which means it can continuously learn from real-world conditions.&lt;/p&gt;  &lt;p&gt;The concept broadly known as AIOps (or AI-driven IT operations) is changing how enterprise networks are managed across industries. Today, AI surfaces insights as recommendations that administrators can choose to apply with a single click. Tomorrow, those same systems might automatically test and deploy low-risk changes themselves.&lt;/p&gt;  &lt;p&gt;That long-term vision, Green notes, is referred to as a “self-driving network”—one that handles the repetitive, error-prone tasks that have historically plagued IT teams. “AI isn’t coming for the network engineer’s job, but it will eliminate the tedious stuff that slows them down," he says. "You’ll be able to say, ‘Please go configure 130 switches to solve this issue,’ and the system will handle it. When a port gets stuck or someone plugs a connector in the wrong direction, AI can detect it—and in many cases, fix it automatically.”&lt;/p&gt;  &lt;p&gt;Digital initiatives now depend on how effectively information moves. Whether coordinating a live event or streamlining a supply chain, the performance of the network increasingly defines the performance of the business. Building that foundation today will separate those who pilot from those who scale AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1127997/networking-for-ai-building-the-foundation-for-real-time-intelligence/</guid><pubDate>Tue, 18 Nov 2025 16:03:14 +0000</pubDate></item><item><title>Google unveils Gemini 3 AI model and AI-first IDE called Antigravity (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/11/google-unveils-gemini-3-ai-model-and-ai-first-ide-called-antigravity/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s flagship AI model is getting its second major upgrade this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini 3" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-640x361.png" width="640" /&gt;
                  &lt;img alt="Gemini 3" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Google has kicked its Gemini rollout into high gear over the past year, releasing the much-improved Gemini 2.5 family and cramming various flavors of the model into Search, Gmail, and just about everything else the company makes.&lt;/p&gt;
&lt;p&gt;Now, Google’s increasingly unavoidable AI is getting an upgrade. Gemini 3 Pro is available in a limited form today, featuring more immersive, visual outputs and fewer lies, Google says. The company also says Gemini 3 sets a new high-water mark for vibe coding, and Google is announcing a new AI-first integrated development environment (IDE) called Antigravity, which is also available today.&lt;/p&gt;
&lt;h2&gt;The first member of the Gemini 3 family&lt;/h2&gt;
&lt;p&gt;Google says the release of Gemini 3 is yet another step toward artificial general intelligence (AGI). The new version of Google’s flagship AI model has expanded simulated reasoning abilities and shows improved understanding of text, images, and video. So far, testers like it—Google’s latest LLM is once again atop the LMArena leaderboard with an ELO score of 1,501, besting Gemini 2.5 Pro by 50 points.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128002 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gemini 3 LMArena" class="fullwidth full" height="2160" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/gemini_3_lm_arena_leaderboard-1.png" width="3840" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Factuality has been a problem for all gen AI models, but Google says Gemini 3 is a big step in the right direction, and there are myriad benchmarks to tell the story. In the 1,000-question SimpleQA Verified test, Gemini 3 scored a record 72.1 percent. Yes, that means the state-of-the-art LLM still screws up almost 30 percent of general knowledge questions, but Google says this still shows substantial progress. On the much more difficult Humanity’s Last Exam, which tests PhD-level knowledge and reasoning, Gemini set another record, scoring 37.5 percent without tool use.&lt;/p&gt;
&lt;p&gt;Math and coding are also a focus of Gemini 3. The model set new records in MathArena Apex (23.4 percent) and WebDev Arena (1487 ELO). In the SWE-bench Verified, which tests a model’s ability to generate code, Gemini 3 hit an impressive 76.2 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2127999-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Scale-Illustrator-Demo.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So there are plenty of respectable but modest benchmark improvements, but Gemini 3 also won’t make you cringe as much. Google says it has tamped down on sycophancy, a common problem in all these overly polite LLMs. Outputs from Gemini 3 Pro are reportedly more concise, with less of what you want to hear and more of what you need to hear.&lt;/p&gt;
&lt;p&gt;You can also expect Gemini 3 Pro to produce noticeably richer outputs. Google claims Gemini’s expanded reasoning capabilities keep it on task more effectively, allowing it to take action on your behalf. For example, Gemini 3 can triage and take action on your emails, creating to-do lists, summaries, recommended replies, and handy buttons to trigger suggested actions. This differs from the current Gemini models, which would only create a text-based to-do list with similar prompts.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-Agent.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The model also has what Google calls a “generative interface,” which comes in the form of two experimental output modes called visual layout and dynamic view. The former is a magazine-style interface that includes lots of images in a scrollable UI. Dynamic view leverages Gemini’s coding abilities to create custom interfaces—for example, a web app that explores the life and work of Vincent Van Gogh.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-App-Dynamic-View.mp4?_=3" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There will also be a Deep Think mode for Gemini 3, but that’s not ready for prime time yet. Google says it’s being tested by a small group for later release, but you should expect big things. Deep Think mode manages 41 percent in Humanity’s Last Exam without tools. Believe it or not, that’s an impressive score.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Coding with vibes&lt;/h2&gt;
&lt;p&gt;Google has offered several ways of generating and modifying code with Gemini models, but the launch of Gemini 3 adds a new one: Google Antigravity. This is Google’s new agentic development platform—it’s essentially an IDE designed around agentic AI, and it’s available in preview today.&lt;/p&gt;
&lt;p&gt;With Antigravity, Google promises that you (the human) can get more work done by letting intelligent agents do the legwork. Google says you should think of Antigravity as a “mission control” for creating and monitoring multiple development agents. The AI in Antigravity can operate autonomously across the editor, terminal, and browser to create and modify projects, but everything they do is relayed to the user in the form of “Artifacts.” These sub-tasks are designed to be easily verifiable so you can keep on top of what the agent is doing. Gemini will be at the core of the Antigravity experience, but it’s not just Google’s bot. Antigravity also supports Claude Sonnet 4.5 and GPT-OSS agents.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="2160" id="video-2127999-4" preload="metadata" width="3840"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google-Antigravity-Demo.mp4?_=4" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Of course, developers can still plug into the Gemini API for coding tasks. With Gemini 3, Google is adding a client-side bash tool, which lets the AI generate shell commands in its workflow. The model can access file systems and automate operations, and a server-side bash tool will help generate code in multiple languages. This feature is starting in early access, though.&lt;/p&gt;
&lt;p&gt;AI Studio is designed to be a faster way to build something with Gemini 3. Google says Gemini 3 Pro’s strong instruction following makes it the best vibe coding model yet, allowing non-programmers to create more complex projects.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A big experiment&lt;/h2&gt;
&lt;p&gt;Google will eventually have a whole family of Gemini 3 models, but there’s just the one for now. Gemini 3 Pro is rolling out in the Gemini app, AI Studio, Vertex AI, and the API starting today as an experiment. If you want to tinker with the new model in Google’s Antigravity IDE, that’s also available for testing today on Windows, Mac, and Linux.&lt;/p&gt;
&lt;p&gt;Gemini 3 will also launch in the Google search experience on day one. You’ll have the option to enable Gemini 3 Pro in AI Mode, where Google says it will provide more useful information about a query. The generative interface capabilities from the Gemini app will be available here as well, allowing Gemini to create tools and simulations when appropriate to answer the user’s question. Google says these generative interfaces are strongly preferred in its user testing. This feature is available today, but only for AI Pro and Ultra subscribers.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-5" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-in-AI-Mode-Generative-UI-Home-Loan.mp4?_=5" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Because the Pro model is the only Gemini 3 variant available in the preview, AI Overviews isn’t getting an immediate upgrade. That will come, but for now, Overviews will only reach out to Gemini 3 Pro for especially difficult search queries—basically the kind of thing Google thinks you should have used AI Mode to do in the first place.&lt;/p&gt;
&lt;p&gt;There’s no official timeline for releasing more Gemini 3 models or graduating the Pro variant to general availability. However, given the wide rollout of the experimental release, it probably won’t be long.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s flagship AI model is getting its second major upgrade this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini 3" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-640x361.png" width="640" /&gt;
                  &lt;img alt="Gemini 3" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Google has kicked its Gemini rollout into high gear over the past year, releasing the much-improved Gemini 2.5 family and cramming various flavors of the model into Search, Gmail, and just about everything else the company makes.&lt;/p&gt;
&lt;p&gt;Now, Google’s increasingly unavoidable AI is getting an upgrade. Gemini 3 Pro is available in a limited form today, featuring more immersive, visual outputs and fewer lies, Google says. The company also says Gemini 3 sets a new high-water mark for vibe coding, and Google is announcing a new AI-first integrated development environment (IDE) called Antigravity, which is also available today.&lt;/p&gt;
&lt;h2&gt;The first member of the Gemini 3 family&lt;/h2&gt;
&lt;p&gt;Google says the release of Gemini 3 is yet another step toward artificial general intelligence (AGI). The new version of Google’s flagship AI model has expanded simulated reasoning abilities and shows improved understanding of text, images, and video. So far, testers like it—Google’s latest LLM is once again atop the LMArena leaderboard with an ELO score of 1,501, besting Gemini 2.5 Pro by 50 points.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128002 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gemini 3 LMArena" class="fullwidth full" height="2160" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/gemini_3_lm_arena_leaderboard-1.png" width="3840" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Factuality has been a problem for all gen AI models, but Google says Gemini 3 is a big step in the right direction, and there are myriad benchmarks to tell the story. In the 1,000-question SimpleQA Verified test, Gemini 3 scored a record 72.1 percent. Yes, that means the state-of-the-art LLM still screws up almost 30 percent of general knowledge questions, but Google says this still shows substantial progress. On the much more difficult Humanity’s Last Exam, which tests PhD-level knowledge and reasoning, Gemini set another record, scoring 37.5 percent without tool use.&lt;/p&gt;
&lt;p&gt;Math and coding are also a focus of Gemini 3. The model set new records in MathArena Apex (23.4 percent) and WebDev Arena (1487 ELO). In the SWE-bench Verified, which tests a model’s ability to generate code, Gemini 3 hit an impressive 76.2 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2127999-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Scale-Illustrator-Demo.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So there are plenty of respectable but modest benchmark improvements, but Gemini 3 also won’t make you cringe as much. Google says it has tamped down on sycophancy, a common problem in all these overly polite LLMs. Outputs from Gemini 3 Pro are reportedly more concise, with less of what you want to hear and more of what you need to hear.&lt;/p&gt;
&lt;p&gt;You can also expect Gemini 3 Pro to produce noticeably richer outputs. Google claims Gemini’s expanded reasoning capabilities keep it on task more effectively, allowing it to take action on your behalf. For example, Gemini 3 can triage and take action on your emails, creating to-do lists, summaries, recommended replies, and handy buttons to trigger suggested actions. This differs from the current Gemini models, which would only create a text-based to-do list with similar prompts.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-Agent.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The model also has what Google calls a “generative interface,” which comes in the form of two experimental output modes called visual layout and dynamic view. The former is a magazine-style interface that includes lots of images in a scrollable UI. Dynamic view leverages Gemini’s coding abilities to create custom interfaces—for example, a web app that explores the life and work of Vincent Van Gogh.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-App-Dynamic-View.mp4?_=3" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There will also be a Deep Think mode for Gemini 3, but that’s not ready for prime time yet. Google says it’s being tested by a small group for later release, but you should expect big things. Deep Think mode manages 41 percent in Humanity’s Last Exam without tools. Believe it or not, that’s an impressive score.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Coding with vibes&lt;/h2&gt;
&lt;p&gt;Google has offered several ways of generating and modifying code with Gemini models, but the launch of Gemini 3 adds a new one: Google Antigravity. This is Google’s new agentic development platform—it’s essentially an IDE designed around agentic AI, and it’s available in preview today.&lt;/p&gt;
&lt;p&gt;With Antigravity, Google promises that you (the human) can get more work done by letting intelligent agents do the legwork. Google says you should think of Antigravity as a “mission control” for creating and monitoring multiple development agents. The AI in Antigravity can operate autonomously across the editor, terminal, and browser to create and modify projects, but everything they do is relayed to the user in the form of “Artifacts.” These sub-tasks are designed to be easily verifiable so you can keep on top of what the agent is doing. Gemini will be at the core of the Antigravity experience, but it’s not just Google’s bot. Antigravity also supports Claude Sonnet 4.5 and GPT-OSS agents.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="2160" id="video-2127999-4" preload="metadata" width="3840"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google-Antigravity-Demo.mp4?_=4" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Of course, developers can still plug into the Gemini API for coding tasks. With Gemini 3, Google is adding a client-side bash tool, which lets the AI generate shell commands in its workflow. The model can access file systems and automate operations, and a server-side bash tool will help generate code in multiple languages. This feature is starting in early access, though.&lt;/p&gt;
&lt;p&gt;AI Studio is designed to be a faster way to build something with Gemini 3. Google says Gemini 3 Pro’s strong instruction following makes it the best vibe coding model yet, allowing non-programmers to create more complex projects.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A big experiment&lt;/h2&gt;
&lt;p&gt;Google will eventually have a whole family of Gemini 3 models, but there’s just the one for now. Gemini 3 Pro is rolling out in the Gemini app, AI Studio, Vertex AI, and the API starting today as an experiment. If you want to tinker with the new model in Google’s Antigravity IDE, that’s also available for testing today on Windows, Mac, and Linux.&lt;/p&gt;
&lt;p&gt;Gemini 3 will also launch in the Google search experience on day one. You’ll have the option to enable Gemini 3 Pro in AI Mode, where Google says it will provide more useful information about a query. The generative interface capabilities from the Gemini app will be available here as well, allowing Gemini to create tools and simulations when appropriate to answer the user’s question. Google says these generative interfaces are strongly preferred in its user testing. This feature is available today, but only for AI Pro and Ultra subscribers.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-5" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-in-AI-Mode-Generative-UI-Home-Loan.mp4?_=5" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Because the Pro model is the only Gemini 3 variant available in the preview, AI Overviews isn’t getting an immediate upgrade. That will come, but for now, Overviews will only reach out to Gemini 3 Pro for especially difficult search queries—basically the kind of thing Google thinks you should have used AI Mode to do in the first place.&lt;/p&gt;
&lt;p&gt;There’s no official timeline for releasing more Gemini 3 models or graduating the Pro variant to general availability. However, given the wide rollout of the experimental release, it probably won’t be long.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/11/google-unveils-gemini-3-ai-model-and-ai-first-ide-called-antigravity/</guid><pubDate>Tue, 18 Nov 2025 16:08:56 +0000</pubDate></item><item><title>Microsoft, NVIDIA, and Anthropic forge AI compute alliance (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-nvidia-and-anthropic-forge-ai-compute-alliance/</link><description>&lt;p&gt;Microsoft, Anthropic, and NVIDIA are setting a bar for cloud infrastructure investment and AI model availability with a new compute alliance. This agreement signals a divergence from single-model dependency toward a diversified, hardware-optimised ecosystem, altering the governance landscape for senior technology leaders.&lt;/p&gt;&lt;p&gt;Microsoft CEO Satya Nadella says the relationship is a reciprocal integration where the companies are “increasingly going to be customers of each other”. While Anthropic leverages Azure infrastructure, Microsoft will incorporate Anthropic models across its product stack.&lt;/p&gt;&lt;p&gt;Anthropic has committed to purchasing $30 billion of Azure compute capacity. This figure shows the immense computational requirements necessary to train and deploy the next generation of frontier models. The collaboration involves a specific hardware trajectory, beginning with NVIDIA’s Grace Blackwell systems and progressing to the Vera Rubin architecture.&lt;/p&gt;&lt;p&gt;NVIDIA CEO Jensen Huang expects the Grace Blackwell architecture with NVLink to deliver an “order of magnitude speed up,” a necessary leap for driving down token economics.&lt;/p&gt;&lt;p&gt;For those overseeing infrastructure strategy, Huang’s description of a “shift-left” engineering approach – where NVIDIA technology appears on Azure immediately upon release – suggests that enterprises running Claude on Azure will access performance characteristics distinct from standard instances. This deep integration may influence architectural decisions regarding latency-sensitive applications or high-throughput batch processing.&lt;/p&gt;&lt;p&gt;Financial planning must now account for what Huang identifies as three simultaneous scaling laws: pre-training, post-training, and inference-time scaling.&lt;/p&gt;&lt;p&gt;Traditionally, AI compute costs were weighted heavily toward training. However, Huang notes that with test-time scaling – where the model “thinks” longer to produce higher quality answers – inference costs are rising.&lt;/p&gt;&lt;p&gt;Consequently, AI operational expenditure (OpEx) will not be a flat rate per token but will correlate with the complexity of the reasoning required. Budget forecasting for agentic workflows must therefore become more dynamic.&lt;/p&gt;&lt;p&gt;Integration into existing enterprise workflows remains a primary hurdle for adoption. To address this, Microsoft has committed to continuing access for Claude across the Copilot family.&lt;/p&gt;&lt;p&gt;Operational emphasis falls heavily on agentic capabilities. Huang highlighted Anthropic’s Model Context Protocol (MCP) as a development that has “revolutionised the agentic AI landscape”. Software engineering leaders should note that NVIDIA engineers are already utilising Claude Code to refactor legacy codebases.&lt;/p&gt;&lt;p&gt;From a security perspective, this integration simplifies the perimeter. Security leaders vetting third-party API endpoints can now provision Claude capabilities within the existing Microsoft 365 compliance boundary. This streamlines data governance, as the interaction logs and data handling remain within the established Microsoft tenant agreements.&lt;/p&gt;&lt;p&gt;Vendor lock-in persists as a friction point for CDOs and risk officers. This AI compute partnership alleviates that concern by making Claude the only frontier model available across all three prominent global cloud services. Nadella emphasised that this multi-model approach builds upon, rather than replaces, Microsoft’s existing partnership with OpenAI, which remains a core component of their strategy.&lt;/p&gt;&lt;p&gt;For Anthropic, the alliance resolves the “enterprise go-to-market” challenge. Huang noted that building an enterprise sales motion takes decades. By piggybacking on Microsoft’s established channels, Anthropic bypasses this adoption curve.&lt;/p&gt;&lt;p&gt;This trilateral agreement alters the procurement landscape. Nadella urges the industry to move beyond a “zero-sum narrative,” suggesting a future of broad and durable capabilities.&lt;/p&gt;&lt;p&gt;Organisations should review their current model portfolios. The availability of Claude Sonnet 4.5 and Opus 4.1 on Azure warrants a comparative TCO analysis against existing deployments. Furthermore, the “gigawatt of capacity” commitment signals that capacity constraints for these specific models may be less severe than in previous hardware cycles.&lt;/p&gt;&lt;p&gt;Following this AI compute partnership, the focus for enterprises must now turn from access to optimisation; matching the right model version to the specific business process to maximise the return on this expanded infrastructure.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Microsoft, Anthropic, and NVIDIA are setting a bar for cloud infrastructure investment and AI model availability with a new compute alliance. This agreement signals a divergence from single-model dependency toward a diversified, hardware-optimised ecosystem, altering the governance landscape for senior technology leaders.&lt;/p&gt;&lt;p&gt;Microsoft CEO Satya Nadella says the relationship is a reciprocal integration where the companies are “increasingly going to be customers of each other”. While Anthropic leverages Azure infrastructure, Microsoft will incorporate Anthropic models across its product stack.&lt;/p&gt;&lt;p&gt;Anthropic has committed to purchasing $30 billion of Azure compute capacity. This figure shows the immense computational requirements necessary to train and deploy the next generation of frontier models. The collaboration involves a specific hardware trajectory, beginning with NVIDIA’s Grace Blackwell systems and progressing to the Vera Rubin architecture.&lt;/p&gt;&lt;p&gt;NVIDIA CEO Jensen Huang expects the Grace Blackwell architecture with NVLink to deliver an “order of magnitude speed up,” a necessary leap for driving down token economics.&lt;/p&gt;&lt;p&gt;For those overseeing infrastructure strategy, Huang’s description of a “shift-left” engineering approach – where NVIDIA technology appears on Azure immediately upon release – suggests that enterprises running Claude on Azure will access performance characteristics distinct from standard instances. This deep integration may influence architectural decisions regarding latency-sensitive applications or high-throughput batch processing.&lt;/p&gt;&lt;p&gt;Financial planning must now account for what Huang identifies as three simultaneous scaling laws: pre-training, post-training, and inference-time scaling.&lt;/p&gt;&lt;p&gt;Traditionally, AI compute costs were weighted heavily toward training. However, Huang notes that with test-time scaling – where the model “thinks” longer to produce higher quality answers – inference costs are rising.&lt;/p&gt;&lt;p&gt;Consequently, AI operational expenditure (OpEx) will not be a flat rate per token but will correlate with the complexity of the reasoning required. Budget forecasting for agentic workflows must therefore become more dynamic.&lt;/p&gt;&lt;p&gt;Integration into existing enterprise workflows remains a primary hurdle for adoption. To address this, Microsoft has committed to continuing access for Claude across the Copilot family.&lt;/p&gt;&lt;p&gt;Operational emphasis falls heavily on agentic capabilities. Huang highlighted Anthropic’s Model Context Protocol (MCP) as a development that has “revolutionised the agentic AI landscape”. Software engineering leaders should note that NVIDIA engineers are already utilising Claude Code to refactor legacy codebases.&lt;/p&gt;&lt;p&gt;From a security perspective, this integration simplifies the perimeter. Security leaders vetting third-party API endpoints can now provision Claude capabilities within the existing Microsoft 365 compliance boundary. This streamlines data governance, as the interaction logs and data handling remain within the established Microsoft tenant agreements.&lt;/p&gt;&lt;p&gt;Vendor lock-in persists as a friction point for CDOs and risk officers. This AI compute partnership alleviates that concern by making Claude the only frontier model available across all three prominent global cloud services. Nadella emphasised that this multi-model approach builds upon, rather than replaces, Microsoft’s existing partnership with OpenAI, which remains a core component of their strategy.&lt;/p&gt;&lt;p&gt;For Anthropic, the alliance resolves the “enterprise go-to-market” challenge. Huang noted that building an enterprise sales motion takes decades. By piggybacking on Microsoft’s established channels, Anthropic bypasses this adoption curve.&lt;/p&gt;&lt;p&gt;This trilateral agreement alters the procurement landscape. Nadella urges the industry to move beyond a “zero-sum narrative,” suggesting a future of broad and durable capabilities.&lt;/p&gt;&lt;p&gt;Organisations should review their current model portfolios. The availability of Claude Sonnet 4.5 and Opus 4.1 on Azure warrants a comparative TCO analysis against existing deployments. Furthermore, the “gigawatt of capacity” commitment signals that capacity constraints for these specific models may be less severe than in previous hardware cycles.&lt;/p&gt;&lt;p&gt;Following this AI compute partnership, the focus for enterprises must now turn from access to optimisation; matching the right model version to the specific business process to maximise the return on this expanded infrastructure.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-nvidia-and-anthropic-forge-ai-compute-alliance/</guid><pubDate>Tue, 18 Nov 2025 16:29:24 +0000</pubDate></item><item><title>Google CEO: If an AI bubble pops, no one is getting out clean (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/googles-sundar-pichai-warns-of-irrationality-in-trillion-dollar-ai-investment-boom/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sundar Pichai says no company is immune if AI bubble bursts, echoing dotcom fears.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google CEO Sundar Pichai.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Alphabet CEO Sundar Pichai warned of “irrationality” in the AI market, telling the BBC in an interview, “I think no company is going to be immune, including us.” His comments arrive as scrutiny over the state of the AI market has reached new heights, with Alphabet shares doubling in value over seven months to reach a $3.5 trillion market capitalization.&lt;/p&gt;
&lt;p&gt;Speaking exclusively to the BBC at Google’s California headquarters, Pichai acknowledged that while AI investment growth is at an “extraordinary moment,” the industry can “overshoot” in investment cycles, as we’re seeing now. He drew comparisons to the late 1990s Internet boom, which saw early Internet company valuations surge before collapsing in 2000, leading to bankruptcies and job losses.&lt;/p&gt;
&lt;p&gt;“We can look back at the Internet right now. There was clearly a lot of excess investment, but none of us would question whether the Internet was profound,” Pichai said. “I expect AI to be the same. So I think it’s both rational and there are elements of irrationality through a moment like this.”&lt;/p&gt;
&lt;p&gt;Over the past year, some analysts and tech industry critics have expressed increasing skepticism about a web of $1.4 trillion in deals surrounding Google competitor OpenAI in particular. The company has committed to spending $1.4 trillion on infrastructure over eight years, while it expects to generate around $13 billion in revenue this year. OpenAI CEO Sam Altman told reporters at a private dinner in August that investors are “overexcited” about AI models and that “someone” will lose a “phenomenal amount of money.”&lt;/p&gt;
&lt;p&gt;Reacting to the Pichai comments, prominent AI industry critic Ed Zitron told Ars Technica, “I think that this is the first moment where a magnificent 7 feels it’s necessary to be on the right side of history, leaning on the shaky talking point of ‘there was a lot of over investment in the Internet too’ because there really isn’t a defense for the&lt;span&gt;—&lt;/span&gt;to use his own terminology&lt;span&gt;—&lt;/span&gt;‘excess investment’ in AI.” He added, “I imagine others will follow.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Market concerns and Google’s position&lt;/h2&gt;
&lt;p&gt;Alphabet’s recent market performance has been driven by investor confidence in the company’s ability to compete with OpenAI’s ChatGPT, as well as its development of specialized chips for AI that can compete with Nvidia’s. Nvidia recently reached a world-first $5 trillion valuation due to making GPUs that can accelerate the matrix math at the heart of AI computations.&lt;/p&gt;
&lt;p&gt;Despite acknowledging that no company would be immune to a potential AI bubble burst, Pichai argued that Google’s unique position gives it an advantage. He told the BBC that the company owns what he called a “full stack” of technologies, from chips to YouTube data to models and frontier science research. This integrated approach, he suggested, would help the company weather any market turbulence better than competitors.&lt;/p&gt;
&lt;p&gt;Pichai also told the BBC that people should not “blindly trust” everything AI tools output. The company currently faces repeated accuracy concerns about some of its AI models. Pichai said that while AI tools are helpful “if you want to creatively write something,” people “have to learn to use these tools for what they’re good at and not blindly trust everything they say.”&lt;/p&gt;
&lt;p&gt;In the BBC interview, the Google boss also addressed the “immense” energy needs of AI, acknowledging that the intensive energy requirements of expanding AI ventures have caused slippage on Alphabet’s climate targets. However, Pichai insisted that the company still wants to achieve net zero by 2030 through investments in new energy technologies. “The rate at which we were hoping to make progress will be impacted,” Pichai said, warning that constraining an economy based on energy “will have consequences.”&lt;/p&gt;
&lt;p&gt;Even with the warnings about a potential AI bubble, Pichai did not miss his chance to promote the technology, albeit with a hint of danger regarding its widespread impact. Pichai described AI as “the most profound technology” humankind has worked on.&lt;/p&gt;
&lt;p&gt;“We will have to work through societal disruptions,” he said, adding that the technology would “create new opportunities” and “evolve and transition certain jobs.” He said people who adapt to AI tools “will do better” in their professions, whatever field they work in.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sundar Pichai says no company is immune if AI bubble bursts, echoing dotcom fears.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google CEO Sundar Pichai.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Alphabet CEO Sundar Pichai warned of “irrationality” in the AI market, telling the BBC in an interview, “I think no company is going to be immune, including us.” His comments arrive as scrutiny over the state of the AI market has reached new heights, with Alphabet shares doubling in value over seven months to reach a $3.5 trillion market capitalization.&lt;/p&gt;
&lt;p&gt;Speaking exclusively to the BBC at Google’s California headquarters, Pichai acknowledged that while AI investment growth is at an “extraordinary moment,” the industry can “overshoot” in investment cycles, as we’re seeing now. He drew comparisons to the late 1990s Internet boom, which saw early Internet company valuations surge before collapsing in 2000, leading to bankruptcies and job losses.&lt;/p&gt;
&lt;p&gt;“We can look back at the Internet right now. There was clearly a lot of excess investment, but none of us would question whether the Internet was profound,” Pichai said. “I expect AI to be the same. So I think it’s both rational and there are elements of irrationality through a moment like this.”&lt;/p&gt;
&lt;p&gt;Over the past year, some analysts and tech industry critics have expressed increasing skepticism about a web of $1.4 trillion in deals surrounding Google competitor OpenAI in particular. The company has committed to spending $1.4 trillion on infrastructure over eight years, while it expects to generate around $13 billion in revenue this year. OpenAI CEO Sam Altman told reporters at a private dinner in August that investors are “overexcited” about AI models and that “someone” will lose a “phenomenal amount of money.”&lt;/p&gt;
&lt;p&gt;Reacting to the Pichai comments, prominent AI industry critic Ed Zitron told Ars Technica, “I think that this is the first moment where a magnificent 7 feels it’s necessary to be on the right side of history, leaning on the shaky talking point of ‘there was a lot of over investment in the Internet too’ because there really isn’t a defense for the&lt;span&gt;—&lt;/span&gt;to use his own terminology&lt;span&gt;—&lt;/span&gt;‘excess investment’ in AI.” He added, “I imagine others will follow.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Market concerns and Google’s position&lt;/h2&gt;
&lt;p&gt;Alphabet’s recent market performance has been driven by investor confidence in the company’s ability to compete with OpenAI’s ChatGPT, as well as its development of specialized chips for AI that can compete with Nvidia’s. Nvidia recently reached a world-first $5 trillion valuation due to making GPUs that can accelerate the matrix math at the heart of AI computations.&lt;/p&gt;
&lt;p&gt;Despite acknowledging that no company would be immune to a potential AI bubble burst, Pichai argued that Google’s unique position gives it an advantage. He told the BBC that the company owns what he called a “full stack” of technologies, from chips to YouTube data to models and frontier science research. This integrated approach, he suggested, would help the company weather any market turbulence better than competitors.&lt;/p&gt;
&lt;p&gt;Pichai also told the BBC that people should not “blindly trust” everything AI tools output. The company currently faces repeated accuracy concerns about some of its AI models. Pichai said that while AI tools are helpful “if you want to creatively write something,” people “have to learn to use these tools for what they’re good at and not blindly trust everything they say.”&lt;/p&gt;
&lt;p&gt;In the BBC interview, the Google boss also addressed the “immense” energy needs of AI, acknowledging that the intensive energy requirements of expanding AI ventures have caused slippage on Alphabet’s climate targets. However, Pichai insisted that the company still wants to achieve net zero by 2030 through investments in new energy technologies. “The rate at which we were hoping to make progress will be impacted,” Pichai said, warning that constraining an economy based on energy “will have consequences.”&lt;/p&gt;
&lt;p&gt;Even with the warnings about a potential AI bubble, Pichai did not miss his chance to promote the technology, albeit with a hint of danger regarding its widespread impact. Pichai described AI as “the most profound technology” humankind has worked on.&lt;/p&gt;
&lt;p&gt;“We will have to work through societal disruptions,” he said, adding that the technology would “create new opportunities” and “evolve and transition certain jobs.” He said people who adapt to AI tools “will do better” in their professions, whatever field they work in.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/googles-sundar-pichai-warns-of-irrationality-in-trillion-dollar-ai-investment-boom/</guid><pubDate>Tue, 18 Nov 2025 16:32:58 +0000</pubDate></item><item><title>Poe’s AI app now supports group chats across AI models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/poes-ai-app-now-supports-group-chats-across-ai-models/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Poe, Quora’s app that brings together different AI models into one platform, is launching group chat functionality. The company announced on Monday that users worldwide will be able to start group chats with up to 200 other people, then collaborate across more than 200 AI models — including text, image, video, and audio generators — within a single conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes just days after OpenAI’s ChatGPT began piloting group chats in markets like Japan, New Zealand, South Korea, and Taiwan. The move could potentially transform the chatbot from a one-on-one AI interaction into a collaborative space where users can also engage with friends, family, or colleagues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Quora says the addition of group chats to Poe could enable new types of interactive experiences for AI users. For instance, the company suggests that families or friends could use the feature to plan a trip together using Gemini 2.5’s search functionality and o3 Deep Research. Teams could also work together to brainstorm images for mood boards using the various image models on Poe, or groups could play trivia games together using one of the quiz bots on the app.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The group chats will allow users to work together using any combination of AI models or creator-made bots, including models like Claude 4.5 Sonnet, ElevenLabs v3, ElevenLabs Music, Nano Banana, GPT-5.1, Kling 2.5 Turbo Pro, o3 Deep Research, Sora 2 Pro, and Veo 3.1, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poe users can start a group chat from the app’s home screen on the website at poe.com. As you chat, the chat history will sync in real time across your devices, so you could start chatting on desktop and then move to a mobile device without losing the thread.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3068805" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/poe-group-chat.avif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Quora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Quora developed the feature over the past six months and plans to continue to improve group chats in the weeks following its launch, based on user feedback.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think the space of potential group interactions mediated by AI and collaboration opportunities with AI is vast and currently under-explored,” the company shared in its announcement. “The product we are opening up today also allows anyone to create a custom bot on Poe and share it for others to use in their own groups, and we are excited to see the use cases that everyone discovers.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Poe, Quora’s app that brings together different AI models into one platform, is launching group chat functionality. The company announced on Monday that users worldwide will be able to start group chats with up to 200 other people, then collaborate across more than 200 AI models — including text, image, video, and audio generators — within a single conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes just days after OpenAI’s ChatGPT began piloting group chats in markets like Japan, New Zealand, South Korea, and Taiwan. The move could potentially transform the chatbot from a one-on-one AI interaction into a collaborative space where users can also engage with friends, family, or colleagues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Quora says the addition of group chats to Poe could enable new types of interactive experiences for AI users. For instance, the company suggests that families or friends could use the feature to plan a trip together using Gemini 2.5’s search functionality and o3 Deep Research. Teams could also work together to brainstorm images for mood boards using the various image models on Poe, or groups could play trivia games together using one of the quiz bots on the app.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The group chats will allow users to work together using any combination of AI models or creator-made bots, including models like Claude 4.5 Sonnet, ElevenLabs v3, ElevenLabs Music, Nano Banana, GPT-5.1, Kling 2.5 Turbo Pro, o3 Deep Research, Sora 2 Pro, and Veo 3.1, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poe users can start a group chat from the app’s home screen on the website at poe.com. As you chat, the chat history will sync in real time across your devices, so you could start chatting on desktop and then move to a mobile device without losing the thread.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3068805" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/poe-group-chat.avif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Quora&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Quora developed the feature over the past six months and plans to continue to improve group chats in the weeks following its launch, based on user feedback.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think the space of potential group interactions mediated by AI and collaboration opportunities with AI is vast and currently under-explored,” the company shared in its announcement. “The product we are opening up today also allows anyone to create a custom bot on Poe and share it for others to use in their own groups, and we are excited to see the use cases that everyone discovers.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/poes-ai-app-now-supports-group-chats-across-ai-models/</guid><pubDate>Tue, 18 Nov 2025 17:04:03 +0000</pubDate></item><item><title>[NEW] MIT Energy Initiative conference spotlights research priorities amidst a changing energy landscape (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-energy-initiative-conference-1118</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mitei-annual-conference.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We’re here to talk about really substantive changes, and we want you to be a participant in that,” said Desirée Plata, the School of Engineering Distinguished Professor of Climate and Energy in MIT’s Department of Civil and Environmental Engineering, at Energizing@MIT: the MIT Energy Initiative’s (MITEI) Annual Research Conference that was held on Sept. 9-10.&lt;/p&gt;&lt;p&gt;Plata’s words resonated with the 150-plus participants from academia, industry, and government meeting in Cambridge for the conference, whose theme was “tackling emerging energy challenges.” Meeting such challenges and ultimately altering the trajectory of global climate outcomes requires partnerships, speakers agreed.&lt;/p&gt;&lt;p&gt;“We have to be humble and open,” said Giacomo Silvestri, chair of Eniverse Ventures at Eni, in a shared keynote address. “We cannot develop innovation just focusing on ourselves and our competencies … so we need to partner with startups, venture funds, universities like MIT and other public and private institutions.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Added his Eni colleague, Annalisa Muccioli, head of research and technology, “The energy transition is a race we can win only by combining mature solutions ready to deploy, together with emerging technologies that still require acceleration and risk management.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Research targets&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a conference that showcased a suite of research priorities MITEI has identified as central to ensuring a low-carbon energy future, participants shared both promising discoveries and strategies for advancing proven technologies in the face of shifting political winds and policy uncertainties.&lt;/p&gt;&lt;p&gt;One panel focused on grid resiliency — a topic that has moved from the periphery to the center of energy discourse as climate-driven disruptions, cyber threats, and the integration of renewables challenge legacy systems. A dramatic case in point: the April 2025 outage in Spain and Portugal that left millions without power for eight to 15 hours.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“I want to emphasize that this failure was about more than the power system,” said MITEI research scientist Pablo Duenas-Martinez. While he pinpointed technical problems with reactive power and voltage control behind the system collapse, Duenas-Martinez also called out a lack of transmission capacity with Central Europe and out-of-date operating procedures, and recommended better preparation and communication among transmission systems and utility operators.&lt;/p&gt;&lt;p&gt;“You can’t plan for every single eventuality, which means we need to broaden the portfolio of extreme events we prepare for,” noted Jennifer Pearce, vice president at energy company Avangrid. “We are making the system smarter, stronger, and more resilient to better protect from a wide range of threats such as storms, flooding, and extreme heat events.” Pearce noted that Avangrid’s commitment to deliver safe, reliable power to its customers necessitates “meticulous emergency planning procedures.”&lt;/p&gt;&lt;p&gt;The resiliency of the electric grid under greatly increased demand is an important motivation behind MITEI’s September 2025 launch of the Data Center Power Forum, which was also announced during the annual research conference. The forum will include research projects, webinars, and other content focused on energy supply and storage, grid design and management, infrastructure, and public and economic policy related to data centers. The forum’s members include MITEI companies that also participate in MIT’s Center for Environmental and Energy Policy Research (CEEPR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Storage and transportation: Staggering challenges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meeting climate goals to decarbonize the world by 2050 requires building around 300 terawatt-hours of storage, according to Asegun Henry, a professor in the MIT Department of Mechanical Engineering. “It’s an unbelievably enormous problem people have to wrap their minds around,” he said. Henry has been developing a high-temperature thermal energy storage system he has nicknamed “sun in a box.” His system uses liquid metal and graphite to hold electricity as heat and then convert it back to electricity, enabling storage anywhere from five to 500 hours.&lt;/p&gt;&lt;p&gt;“At the end of the day, storage provides a service, and the type of technology that you need is a function of the service that you value the most,” said Nestor Sepulveda, commercial lead for advanced energy investments and partnerships at Google. “I don't think there is one winner-takes-all type of market here.”&lt;/p&gt;&lt;p&gt;Another panel explored sustainable fuels that could help decarbonize hard-to-electrify sectors like aviation, shipping, and long-haul trucking. Randall Field, MITEI’s director of research, noted that sustainably produced drop-in fuels — fuels that are largely compatible with existing engines — “could eliminate potentially trillions of dollars of cost for fleet replacement and for infrastructure build-out, while also helping us to accelerate the rate of decarbonization of the transportation sectors."&lt;/p&gt;&lt;p&gt;Erik G. Birkerts is the chief growth officer of LanzaJet, which produces a drop-in, high-energy-density aviation fuel derived from agricultural residue and other waste carbon sources. “The key to driving broad sustainable aviation fuel adoption is solving both the supply-side challenge through more production and the demand-side hurdle by reducing costs,” he said.&lt;/p&gt;&lt;p&gt;“We think a good policy framework [for sustainable fuels] would be something that is technology-neutral, does not exclude any pathways to produce, is based on life cycle accounting practices, and on market mechanisms,” said Veronica L. Robertson, energy products technology portfolio manager at ExxonMobil.&lt;/p&gt;&lt;p&gt;MITEI plans a major expansion of its research on sustainable fuels, announcing a two-year study, “The future of fuels: Pathways to sustainable transportation,” starting in early 2026. According to Field, the study will analyze and assess biofuels and e-fuels.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Solutions from labs big and small&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Global energy leaders offered glimpses of their research projects. A panel on carbon capture in power generation featured three takes on the topic: Devin Shaw, commercial director of decarbonization technologies at Shell, described post-combustion carbon capture in power plants using steam for heat recovery; Jan Marsh, a global program lead at Siemens Energy, discussed deploying novel materials to capture carbon dioxide directly from the air; and Jeffrey Goldmeer, senior director of technology strategy at GE Vernova, explained integrating carbon capture into gas-powered turbine systems.&lt;/p&gt;&lt;p&gt;During a panel on vehicle electrification, Brian Storey, vice president of energy and materials at the Toyota Research Institute, provided an overview of Toyota’s portfolio of projects for decarbonization, including solid-state batteries, flexible manufacturing lines, and grid-forming inverters to support EV charging infrastructure.&lt;/p&gt;&lt;p&gt;A session on MITEI seed fund projects revealed promising early-stage research inside MIT’s own labs. A new process for decarbonizing the production of ethylene was presented by Yogesh Surendranath, Donner Professor of Science in the MIT Department of Chemistry. Materials Science and Engineering assistant professor Aristide Gumyusenge also discussed the development of polymers essential for a new kind of sodium-ion battery.&lt;/p&gt;&lt;p&gt;Shepherding bold, new technologies like these from academic labs into the real world cannot succeed without ample support and deft management.&amp;nbsp;A panel on paths to commercialization featured the work of Iwnetim Abate, Chipman Career Development Professor and assistant professor in the MIT Department of Materials Science and Engineering, who has spun out a company, Addis Energy, based on a novel geothermal process for harvesting clean hydrogen and ammonia from subsurface, iron-rich rocks. Among his funders: ARPA-E and MIT’s own The Engine Ventures.&lt;/p&gt;&lt;p&gt;The panel also highlighted the MIT Proto Ventures Program, an initiative to seize early-stage MIT ideas and unleash them as world-changing startups. “A mere 4.2 percent of all the patents that are actually prosecuted in the world are ever commercialized, which seems like a shocking number,” said Andrew Inglis, an entrepreneur working with Proto Ventures to translate geothermal discoveries into businesses.&amp;nbsp;“Can’t we do this better? Let’s do this better!”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Geopolitical hazards&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the conference, participants often voiced concern about the impacts of competition between the United States and China. Kelly Sims Gallagher, dean of the Fletcher School at Tufts University and an expert on China’s energy landscape, delivered the sobering news in her keynote address: “U.S. competitiveness in low-carbon technologies has eroded in nearly every category,” she said. “The Chinese are winning the clean tech race.”&lt;/p&gt;&lt;p&gt;China enjoys a 51 percent share in global wind turbine manufacture and 75 percent in solar modules. It also controls low-carbon supply chains that much of the world depends on. “China is getting so dominant that nobody can carve out a comparative advantage in anything,” said Gallagher. “China is just so big, and the scale is so huge that the Chinese can truly conquer markets and make it very hard for potential competitors to find a way in.”&lt;/p&gt;&lt;p&gt;And for the United States, the problem is “the seesaw of energy policy,” she says. “It’s incredibly difficult for the private sector to plan and to operate, given the lack of predictability and policy here.”&lt;/p&gt;&lt;p&gt;Nevertheless, Gallagher believes the United States still has a chance of at least regaining competitiveness, by setting up a stable, bipartisan energy policy, rebuilding domestic manufacturing and supply chains; providing consistent fiscal incentives; attracting and retaining global talent; and fostering international collaboration.&lt;/p&gt;&lt;p&gt;The conference shone a light on one such collaboration: a China-U.S. joint venture to manufacture lithium iron phosphate batteries for commercial vehicles in the United States. The venture brings together Eve Energy, a Chinese battery technology and manufacturing company; Daimler, a global commercial vehicle manufacturer; PACCAR Inc., a U.S.-based truck manufacturer; and Accelera, the zero-emissions business of Cummins Inc. “Manufacturing batteries in the U.S. makes the supply chain more robust and reduces geopolitical risks,” said Mike Gerty, of PACCAR.&lt;/p&gt;&lt;p&gt;While she acknowledged the obstacles confronting her colleagues in the room, Plata nevertheless concluded her remarks as a panel moderator with some optimism: “I hope you all leave this conference and look back on it in the future, saying I was in the room when they actually solved some of the challenges standing between now and the future that we all wish to manifest.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mitei-annual-conference.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We’re here to talk about really substantive changes, and we want you to be a participant in that,” said Desirée Plata, the School of Engineering Distinguished Professor of Climate and Energy in MIT’s Department of Civil and Environmental Engineering, at Energizing@MIT: the MIT Energy Initiative’s (MITEI) Annual Research Conference that was held on Sept. 9-10.&lt;/p&gt;&lt;p&gt;Plata’s words resonated with the 150-plus participants from academia, industry, and government meeting in Cambridge for the conference, whose theme was “tackling emerging energy challenges.” Meeting such challenges and ultimately altering the trajectory of global climate outcomes requires partnerships, speakers agreed.&lt;/p&gt;&lt;p&gt;“We have to be humble and open,” said Giacomo Silvestri, chair of Eniverse Ventures at Eni, in a shared keynote address. “We cannot develop innovation just focusing on ourselves and our competencies … so we need to partner with startups, venture funds, universities like MIT and other public and private institutions.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Added his Eni colleague, Annalisa Muccioli, head of research and technology, “The energy transition is a race we can win only by combining mature solutions ready to deploy, together with emerging technologies that still require acceleration and risk management.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Research targets&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a conference that showcased a suite of research priorities MITEI has identified as central to ensuring a low-carbon energy future, participants shared both promising discoveries and strategies for advancing proven technologies in the face of shifting political winds and policy uncertainties.&lt;/p&gt;&lt;p&gt;One panel focused on grid resiliency — a topic that has moved from the periphery to the center of energy discourse as climate-driven disruptions, cyber threats, and the integration of renewables challenge legacy systems. A dramatic case in point: the April 2025 outage in Spain and Portugal that left millions without power for eight to 15 hours.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“I want to emphasize that this failure was about more than the power system,” said MITEI research scientist Pablo Duenas-Martinez. While he pinpointed technical problems with reactive power and voltage control behind the system collapse, Duenas-Martinez also called out a lack of transmission capacity with Central Europe and out-of-date operating procedures, and recommended better preparation and communication among transmission systems and utility operators.&lt;/p&gt;&lt;p&gt;“You can’t plan for every single eventuality, which means we need to broaden the portfolio of extreme events we prepare for,” noted Jennifer Pearce, vice president at energy company Avangrid. “We are making the system smarter, stronger, and more resilient to better protect from a wide range of threats such as storms, flooding, and extreme heat events.” Pearce noted that Avangrid’s commitment to deliver safe, reliable power to its customers necessitates “meticulous emergency planning procedures.”&lt;/p&gt;&lt;p&gt;The resiliency of the electric grid under greatly increased demand is an important motivation behind MITEI’s September 2025 launch of the Data Center Power Forum, which was also announced during the annual research conference. The forum will include research projects, webinars, and other content focused on energy supply and storage, grid design and management, infrastructure, and public and economic policy related to data centers. The forum’s members include MITEI companies that also participate in MIT’s Center for Environmental and Energy Policy Research (CEEPR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Storage and transportation: Staggering challenges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meeting climate goals to decarbonize the world by 2050 requires building around 300 terawatt-hours of storage, according to Asegun Henry, a professor in the MIT Department of Mechanical Engineering. “It’s an unbelievably enormous problem people have to wrap their minds around,” he said. Henry has been developing a high-temperature thermal energy storage system he has nicknamed “sun in a box.” His system uses liquid metal and graphite to hold electricity as heat and then convert it back to electricity, enabling storage anywhere from five to 500 hours.&lt;/p&gt;&lt;p&gt;“At the end of the day, storage provides a service, and the type of technology that you need is a function of the service that you value the most,” said Nestor Sepulveda, commercial lead for advanced energy investments and partnerships at Google. “I don't think there is one winner-takes-all type of market here.”&lt;/p&gt;&lt;p&gt;Another panel explored sustainable fuels that could help decarbonize hard-to-electrify sectors like aviation, shipping, and long-haul trucking. Randall Field, MITEI’s director of research, noted that sustainably produced drop-in fuels — fuels that are largely compatible with existing engines — “could eliminate potentially trillions of dollars of cost for fleet replacement and for infrastructure build-out, while also helping us to accelerate the rate of decarbonization of the transportation sectors."&lt;/p&gt;&lt;p&gt;Erik G. Birkerts is the chief growth officer of LanzaJet, which produces a drop-in, high-energy-density aviation fuel derived from agricultural residue and other waste carbon sources. “The key to driving broad sustainable aviation fuel adoption is solving both the supply-side challenge through more production and the demand-side hurdle by reducing costs,” he said.&lt;/p&gt;&lt;p&gt;“We think a good policy framework [for sustainable fuels] would be something that is technology-neutral, does not exclude any pathways to produce, is based on life cycle accounting practices, and on market mechanisms,” said Veronica L. Robertson, energy products technology portfolio manager at ExxonMobil.&lt;/p&gt;&lt;p&gt;MITEI plans a major expansion of its research on sustainable fuels, announcing a two-year study, “The future of fuels: Pathways to sustainable transportation,” starting in early 2026. According to Field, the study will analyze and assess biofuels and e-fuels.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Solutions from labs big and small&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Global energy leaders offered glimpses of their research projects. A panel on carbon capture in power generation featured three takes on the topic: Devin Shaw, commercial director of decarbonization technologies at Shell, described post-combustion carbon capture in power plants using steam for heat recovery; Jan Marsh, a global program lead at Siemens Energy, discussed deploying novel materials to capture carbon dioxide directly from the air; and Jeffrey Goldmeer, senior director of technology strategy at GE Vernova, explained integrating carbon capture into gas-powered turbine systems.&lt;/p&gt;&lt;p&gt;During a panel on vehicle electrification, Brian Storey, vice president of energy and materials at the Toyota Research Institute, provided an overview of Toyota’s portfolio of projects for decarbonization, including solid-state batteries, flexible manufacturing lines, and grid-forming inverters to support EV charging infrastructure.&lt;/p&gt;&lt;p&gt;A session on MITEI seed fund projects revealed promising early-stage research inside MIT’s own labs. A new process for decarbonizing the production of ethylene was presented by Yogesh Surendranath, Donner Professor of Science in the MIT Department of Chemistry. Materials Science and Engineering assistant professor Aristide Gumyusenge also discussed the development of polymers essential for a new kind of sodium-ion battery.&lt;/p&gt;&lt;p&gt;Shepherding bold, new technologies like these from academic labs into the real world cannot succeed without ample support and deft management.&amp;nbsp;A panel on paths to commercialization featured the work of Iwnetim Abate, Chipman Career Development Professor and assistant professor in the MIT Department of Materials Science and Engineering, who has spun out a company, Addis Energy, based on a novel geothermal process for harvesting clean hydrogen and ammonia from subsurface, iron-rich rocks. Among his funders: ARPA-E and MIT’s own The Engine Ventures.&lt;/p&gt;&lt;p&gt;The panel also highlighted the MIT Proto Ventures Program, an initiative to seize early-stage MIT ideas and unleash them as world-changing startups. “A mere 4.2 percent of all the patents that are actually prosecuted in the world are ever commercialized, which seems like a shocking number,” said Andrew Inglis, an entrepreneur working with Proto Ventures to translate geothermal discoveries into businesses.&amp;nbsp;“Can’t we do this better? Let’s do this better!”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Geopolitical hazards&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the conference, participants often voiced concern about the impacts of competition between the United States and China. Kelly Sims Gallagher, dean of the Fletcher School at Tufts University and an expert on China’s energy landscape, delivered the sobering news in her keynote address: “U.S. competitiveness in low-carbon technologies has eroded in nearly every category,” she said. “The Chinese are winning the clean tech race.”&lt;/p&gt;&lt;p&gt;China enjoys a 51 percent share in global wind turbine manufacture and 75 percent in solar modules. It also controls low-carbon supply chains that much of the world depends on. “China is getting so dominant that nobody can carve out a comparative advantage in anything,” said Gallagher. “China is just so big, and the scale is so huge that the Chinese can truly conquer markets and make it very hard for potential competitors to find a way in.”&lt;/p&gt;&lt;p&gt;And for the United States, the problem is “the seesaw of energy policy,” she says. “It’s incredibly difficult for the private sector to plan and to operate, given the lack of predictability and policy here.”&lt;/p&gt;&lt;p&gt;Nevertheless, Gallagher believes the United States still has a chance of at least regaining competitiveness, by setting up a stable, bipartisan energy policy, rebuilding domestic manufacturing and supply chains; providing consistent fiscal incentives; attracting and retaining global talent; and fostering international collaboration.&lt;/p&gt;&lt;p&gt;The conference shone a light on one such collaboration: a China-U.S. joint venture to manufacture lithium iron phosphate batteries for commercial vehicles in the United States. The venture brings together Eve Energy, a Chinese battery technology and manufacturing company; Daimler, a global commercial vehicle manufacturer; PACCAR Inc., a U.S.-based truck manufacturer; and Accelera, the zero-emissions business of Cummins Inc. “Manufacturing batteries in the U.S. makes the supply chain more robust and reduces geopolitical risks,” said Mike Gerty, of PACCAR.&lt;/p&gt;&lt;p&gt;While she acknowledged the obstacles confronting her colleagues in the room, Plata nevertheless concluded her remarks as a panel moderator with some optimism: “I hope you all leave this conference and look back on it in the future, saying I was in the room when they actually solved some of the challenges standing between now and the future that we all wish to manifest.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-energy-initiative-conference-1118</guid><pubDate>Tue, 18 Nov 2025 17:10:00 +0000</pubDate></item><item><title>[NEW] Microsoft tries to head off the “novel security risks” of Windows 11 AI agents (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/11/new-windows-11-ai-agents-can-work-in-the-background-but-create-new-security-risks/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Agents with read/write access to your files create big security, privacy issues.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-640x480.jpeg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Copilot key on the keyboard of a Windows PC. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has been adding AI features to Windows 11 for years, but things have recently entered a new phase, with both generative and so-called “agentic” AI features working their way deeper into the bedrock of the operating system. A new build of Windows 11 released to Windows Insider Program testers yesterday includes a new “experimental agentic features” toggle in the Settings to support a feature called Copilot Actions, and Microsoft has published a detailed support article detailing more about just how those “experimental agentic features” will work.&lt;/p&gt;
&lt;p&gt;If you’re not familiar, “agentic” is a buzzword that Microsoft has used repeatedly to describe its future ambitions for Windows 11—in plainer language, these agents are meant to accomplish assigned tasks in the background, allowing the user’s attention to be turned elsewhere. Microsoft says it wants agents to be capable of “everyday tasks like organizing files, scheduling meetings, or sending emails,” and that Copilot Actions should give you “an active digital collaborator that can carry out complex tasks for you to enhance efficiency and productivity.”&lt;/p&gt;
&lt;p&gt;But like other kinds of AI, these agents can be prone to error and confabulations and will often proceed as if they know what they’re doing even when they don’t. They also present, in Microsoft’s own words, “novel security risks,” mostly related to what can happen if an attacker is able to give instructions to one of these agents. As a result, Microsoft’s implementation walks a tightrope between giving these agents access to your files and cordoning them off from the rest of the system.&lt;/p&gt;
&lt;h2&gt;Possible risks and attempted fixes&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2128140 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="951" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AIComponents-11-17.png" width="1204" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      For now, these “experimental agentic features” are optional, only available in early test builds of Windows 11, and off by default.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For example, AI agents running on a PC will be given their own user accounts separate from your personal account, ensuring that they don’t have permission to change &lt;em&gt;everything&lt;/em&gt; on the system and giving them their own “desktop” to work with that won’t interfere with what you’re working with on your screen. Users need to approve requests for their data, and “all actions of an agent are observable and distinguishable from those taken by a user.” Microsoft also says agents need to be able to produce logs of their activities and “should provide a means to supervise their activities,” including showing users a list of actions they’ll take to accomplish a multi-step task.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But these safeguards and monitoring capabilities don’t change the fact that you’re exposing yourself to privacy and security risks by using AI agents. They’ll be able to request read and write access to most of the files in your user account—by default, anything in the Documents, Downloads, Desktop, Music, Pictures, and Videos folders. They’ll have access to any apps that have been installed for all users on the PC (apps that have only been installed in your user account won’t be accessible to the agent, and it will also be possible for users to install apps that only their agents can access.) And agents can potentially be vulnerable to hijacking that exposes your data to attackers—Microsoft specifically mentions “cross-prompt injection (XPIA), where malicious content embedded in UI elements or documents can override agent instructions, leading to unintended actions like data exfiltration or malware installation.”&lt;/p&gt;
&lt;p&gt;For now, these features can be switched off with the Settings toggle and are off by default. That concession to user preference—plus the lengthy support document outlining the risks and the precautions Microsoft has tried to build into the system—at least suggests that Microsoft has learned lessons from its botched rollout of the data-scraping Windows Recall feature last year.&lt;/p&gt;
&lt;p&gt;Hopefully these features remain fully off by default when they start rolling out to the general public. If not, they risk becoming one more of the many things you need to change or turn off in a modern Windows 11 installation if you want to keep the operating system’s various cloud and AI offerings out of your way.&lt;/p&gt;
&lt;p&gt;Alongside these upcoming AI agents, Microsoft is also attempting to make Copilot more “human-centered” and approachable, adding a Clippy-esque animated character named “Mico” and improving its ability to understand voice input as well as typical mouse-and-keyboard requests.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Agents with read/write access to your files create big security, privacy issues.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-640x480.jpeg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Copilot key on the keyboard of a Windows PC. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has been adding AI features to Windows 11 for years, but things have recently entered a new phase, with both generative and so-called “agentic” AI features working their way deeper into the bedrock of the operating system. A new build of Windows 11 released to Windows Insider Program testers yesterday includes a new “experimental agentic features” toggle in the Settings to support a feature called Copilot Actions, and Microsoft has published a detailed support article detailing more about just how those “experimental agentic features” will work.&lt;/p&gt;
&lt;p&gt;If you’re not familiar, “agentic” is a buzzword that Microsoft has used repeatedly to describe its future ambitions for Windows 11—in plainer language, these agents are meant to accomplish assigned tasks in the background, allowing the user’s attention to be turned elsewhere. Microsoft says it wants agents to be capable of “everyday tasks like organizing files, scheduling meetings, or sending emails,” and that Copilot Actions should give you “an active digital collaborator that can carry out complex tasks for you to enhance efficiency and productivity.”&lt;/p&gt;
&lt;p&gt;But like other kinds of AI, these agents can be prone to error and confabulations and will often proceed as if they know what they’re doing even when they don’t. They also present, in Microsoft’s own words, “novel security risks,” mostly related to what can happen if an attacker is able to give instructions to one of these agents. As a result, Microsoft’s implementation walks a tightrope between giving these agents access to your files and cordoning them off from the rest of the system.&lt;/p&gt;
&lt;h2&gt;Possible risks and attempted fixes&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2128140 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="951" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AIComponents-11-17.png" width="1204" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      For now, these “experimental agentic features” are optional, only available in early test builds of Windows 11, and off by default.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For example, AI agents running on a PC will be given their own user accounts separate from your personal account, ensuring that they don’t have permission to change &lt;em&gt;everything&lt;/em&gt; on the system and giving them their own “desktop” to work with that won’t interfere with what you’re working with on your screen. Users need to approve requests for their data, and “all actions of an agent are observable and distinguishable from those taken by a user.” Microsoft also says agents need to be able to produce logs of their activities and “should provide a means to supervise their activities,” including showing users a list of actions they’ll take to accomplish a multi-step task.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But these safeguards and monitoring capabilities don’t change the fact that you’re exposing yourself to privacy and security risks by using AI agents. They’ll be able to request read and write access to most of the files in your user account—by default, anything in the Documents, Downloads, Desktop, Music, Pictures, and Videos folders. They’ll have access to any apps that have been installed for all users on the PC (apps that have only been installed in your user account won’t be accessible to the agent, and it will also be possible for users to install apps that only their agents can access.) And agents can potentially be vulnerable to hijacking that exposes your data to attackers—Microsoft specifically mentions “cross-prompt injection (XPIA), where malicious content embedded in UI elements or documents can override agent instructions, leading to unintended actions like data exfiltration or malware installation.”&lt;/p&gt;
&lt;p&gt;For now, these features can be switched off with the Settings toggle and are off by default. That concession to user preference—plus the lengthy support document outlining the risks and the precautions Microsoft has tried to build into the system—at least suggests that Microsoft has learned lessons from its botched rollout of the data-scraping Windows Recall feature last year.&lt;/p&gt;
&lt;p&gt;Hopefully these features remain fully off by default when they start rolling out to the general public. If not, they risk becoming one more of the many things you need to change or turn off in a modern Windows 11 installation if you want to keep the operating system’s various cloud and AI offerings out of your way.&lt;/p&gt;
&lt;p&gt;Alongside these upcoming AI agents, Microsoft is also attempting to make Copilot more “human-centered” and approachable, adding a Clippy-esque animated character named “Mico” and improving its ability to understand voice input as well as typical mouse-and-keyboard requests.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/11/new-windows-11-ai-agents-can-work-in-the-background-but-create-new-security-risks/</guid><pubDate>Tue, 18 Nov 2025 19:28:14 +0000</pubDate></item><item><title>[NEW] AI data center provider Lambda raises whopping $1.5B after multibillion-dollar Microsoft deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/ai-data-center-provider-lambda-raises-whopping-1-5b-after-multibillion-dollar-microsoft-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159544073.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data center provider Lambda announced Tuesday it raised $1.5 billion in a round led by TWG Global, a relatively new $40 billion investment firm formed by billionaires Thomas Tull, the former owner of Legendary Entertainment, and Guggenheim Partners founder and CEO Mark Walter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TWG holds a variety of the billionaires’ assets, including Walter’s stakes in the Los Angeles Lakers and the new Cadillac F1 racing team. The firm also has a $15 billion fund to invest in AI anchored by Abu Dhabi’s Mubadala Capital. TWG previously invested in a partnership with Elon Musk’s xAI and Palantir to sell AI agents to enterprises.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now it’s backing Lambda, which operates a number of U.S. AI data centers.&amp;nbsp;Lambda is a CoreWeave competitor, although it also sells its “AI factories” to hyperscaler clouds. Earlier this month, Lambda announced a multibillion-dollar deal to supply Microsoft with AI infrastructure using tens of thousands of Nvidia GPUs. (Nvidia is an investor in Lambda as well.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Remember that Microsoft had a similar deal with CoreWeave and had bought about $1 billion worth of services from the company in 2024, its largest customer last year by a mile. Then OpenAI swooped in and signed a $12 billion deal with CoreWeave in March.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, deal watchers have been talking for months about Lambda looking to raise hundreds of millions of dollars at a valuation north of $4 billion. There was also talk of an IPO. Prior to this, Lambda raised a $480 million Series D in February, with an estimated valuation of $2.5 billion, according to PitchBook.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lambda’s $1.5 billion raise far outstrips those earlier whispers of what it was seeking. Whether its valuation also soared, we can’t confirm and Lambda declined to comment on that.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159544073.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data center provider Lambda announced Tuesday it raised $1.5 billion in a round led by TWG Global, a relatively new $40 billion investment firm formed by billionaires Thomas Tull, the former owner of Legendary Entertainment, and Guggenheim Partners founder and CEO Mark Walter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TWG holds a variety of the billionaires’ assets, including Walter’s stakes in the Los Angeles Lakers and the new Cadillac F1 racing team. The firm also has a $15 billion fund to invest in AI anchored by Abu Dhabi’s Mubadala Capital. TWG previously invested in a partnership with Elon Musk’s xAI and Palantir to sell AI agents to enterprises.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now it’s backing Lambda, which operates a number of U.S. AI data centers.&amp;nbsp;Lambda is a CoreWeave competitor, although it also sells its “AI factories” to hyperscaler clouds. Earlier this month, Lambda announced a multibillion-dollar deal to supply Microsoft with AI infrastructure using tens of thousands of Nvidia GPUs. (Nvidia is an investor in Lambda as well.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Remember that Microsoft had a similar deal with CoreWeave and had bought about $1 billion worth of services from the company in 2024, its largest customer last year by a mile. Then OpenAI swooped in and signed a $12 billion deal with CoreWeave in March.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, deal watchers have been talking for months about Lambda looking to raise hundreds of millions of dollars at a valuation north of $4 billion. There was also talk of an IPO. Prior to this, Lambda raised a $480 million Series D in February, with an estimated valuation of $2.5 billion, according to PitchBook.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lambda’s $1.5 billion raise far outstrips those earlier whispers of what it was seeking. Whether its valuation also soared, we can’t confirm and Lambda declined to comment on that.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/ai-data-center-provider-lambda-raises-whopping-1-5b-after-multibillion-dollar-microsoft-deal/</guid><pubDate>Tue, 18 Nov 2025 19:37:25 +0000</pubDate></item><item><title>[NEW] Powering AI Superfactories, NVIDIA and Microsoft Integrate Latest Technologies for Inference, Cybersecurity, Physical AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-microsoft-ai-superfactories/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/partner-blog-azure-promo-1260x680-2-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Timed with the Microsoft Ignite conference running this week, NVIDIA is expanding its collaboration with Microsoft, including through the adoption of next-generation NVIDIA Spectrum-X Ethernet switches for the new Microsoft Fairwater AI superfactory, powered by the NVIDIA Blackwell platform.&lt;/p&gt;
&lt;p&gt;The collaboration brings new integrations across Microsoft 365 Copilot, as well as the public preview of next-generation Azure NC Series VMs powered by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA Nemotron integrations to accelerate AI for Microsoft SQL Server 2025, capabilities for onboarding AI agents in Microsoft 365 and optimizations for high-performance inference, cybersecurity and physical AI.&lt;/p&gt;
&lt;p&gt;Microsoft’s AI Superfactory connects the landmark Fairwater data center in Wisconsin with a new, state-of-the-art facility in Atlanta, Georgia. This massive-scale infrastructure will integrate hundreds of thousands of NVIDIA Blackwell GPUs for large-scale training. In addition, Microsoft is deploying more than 100,000 Blackwell Ultra GPUs in NVIDIA GB300 NVL72 systems being deployed globally for inference.&lt;/p&gt;
&lt;p&gt;“Our collaboration with NVIDIA is built on driving innovation across the entire system and full stack, from silicon to services,” said Nidhi Chappell, corporate vice president of product management at Microsoft. “By coupling Microsoft Azure’s unmatched data center scale with NVIDIA’s accelerated computing, we are maximizing AI data center performance and efficiency, which is of paramount importance for our customers leading the new AI era.”&lt;/p&gt;
&lt;p&gt;The most demanding workloads for OpenAI, the Microsoft AI Superintelligence Team, Microsoft 365 Copilot and Microsoft Foundry services will be powered by this infrastructure. Customers like Black Forest Labs are also using NVIDIA GB200 NVL72 systems to train next-generation multimodal FLUX models that power visual intelligence.&lt;/p&gt;
&lt;p&gt;To connect this massive infrastructure, Microsoft is deploying next-generation NVIDIA Spectrum-X Ethernet switches in its Fairwater AI data center — the largest and most sophisticated AI factories ever built — delivering the performance, scale and efficiency required for OpenAI to run large-scale AI models and applications.&lt;/p&gt;
&lt;p&gt;New Azure NCv6 Series VMs with NVIDIA RTX PRO 6000 Blackwell GPUs are now in public preview on Azure, expanding the Blackwell platform to provide right-sized acceleration for multiple workloads including multimodal agentic AI, industrial digitalization with NVIDIA Omniverse libraries, scientific simulation and visual computing. This flexibility extends from the cloud to the edge with Azure Local, enabling powerful sovereign AI solutions while bringing low-latency, real-time AI to wherever data needs to reside.&lt;/p&gt;
&lt;p&gt;This allows enterprises to seamlessly develop, deploy and manage AI-powered digital twins and generative AI applications with NVIDIA RTX PRO 6000 Blackwell GPUs from the Azure cloud directly to their factory floors, on-premises data centers or secure edge locations.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Software Optimizations Deliver a Fungible AI Fleet&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA platform on Azure, spanning NVIDIA Blackwell and Hopper GPUs, accelerates the latest models from the Microsoft AI Superintelligence Team, including text (MAI-1-preview), real-time voice (MAI-Voice-1) and high-fidelity image generation (MAI-Image-1) — bringing new multimodal experiences across Bing Image Creator and Microsoft Copilot.&lt;/p&gt;
&lt;p&gt;Central to NVIDIA’s collaboration with Microsoft is building a fungible fleet — a flexible, continuously modernized infrastructure that can accelerate any workload with maximum efficiency. This is achieved through continuous, full-stack software optimizations that deliver compounding performance gains and maximize throughput across the entire AI lifecycle and across multiple NVIDIA architectures on Azure. The gains also extend to workloads beyond generative AI, including data processing, vector search, databases, digital twins, scientific computing and 3D design.&lt;/p&gt;
&lt;p&gt;This co-engineering saves significant costs for customers, making AI projects that were once theoretical now economically viable. For example, the continuous full-stack optimization work has directly contributed to an over 90% drop in the price of popular GPT models for end users on Azure in two years.&lt;/p&gt;
&lt;p&gt;Ongoing optimization work now extends to Microsoft Foundry, where the NVIDIA TensorRT-LLM library helps boost throughput, reduce latency and lower costs for a wide range of popular open models.&lt;/p&gt;
&lt;p&gt;NVIDIA and Microsoft have also partnered to optimize their fleet for AI workload performance through the NVIDIA DGX Cloud Benchmarking suite. Engineering teams from both companies worked closely together to identify bottlenecks and implement infrastructure tuning, driving performance gains. By achieving 95% of the performance possible using the NVIDIA reference architecture, Microsoft was named an Exemplar Cloud for H100 training.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;From Intelligent Data to AI Agents&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and Microsoft are integrating AI into the core of the enterprise, unlocking decades of proprietary data stored in one of the world’s most trusted databases.&lt;/p&gt;
&lt;p&gt;NVIDIA is accelerating AI in the new Microsoft SQL Server 2025 by integrating it with NVIDIA Nemotron open models and NVIDIA NIM microservices. This solution delivers GPU-optimized, secure and scalable retrieval-augmented generation directly where enterprise data lives, in the cloud or on premises.&lt;/p&gt;
&lt;p&gt;Plus, the collaboration extends to the new frontier of agentic AI in the workplace. The NVIDIA NeMo Agent Toolkit now connects with Microsoft Agent 365, enabling developers to build, deploy and onboard compliant, enterprise-ready AI agents directly into the Microsoft 365 app ecosystem, including Outlook, Teams, Word and SharePoint.&lt;/p&gt;
&lt;p&gt;To power these new enterprise agents, Microsoft Foundry now offers NVIDIA Nemotron models for digital AI and NVIDIA Cosmos models for physical AI as secure NIM microservices. Developers can use them to build enterprise-grade agentic AI for a vast range of applications that benefit from multimodal intelligence, multilingual reasoning, math, coding and physical AI capabilities.&lt;/p&gt;
&lt;p&gt;The collaboration is also tackling cyber threats for enterprises. Microsoft and NVIDIA are collaborating on research for new adversarial learning models, built on the NVIDIA Dynamo-Triton framework and the NVIDIA TensorRT suite of tools, that can help enterprises defend against real-time cybersecurity threats with a 160x performance speedup compared with CPU methods.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Physical AI and Industrial Digitalization&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and Microsoft are building the future of physical AI. With NVIDIA Omniverse libraries available on Microsoft Azure, NVIDIA is unlocking end-to-end reindustrialization in the cloud through its developer ecosystem. Developers are transforming industrial workflows, from computer-aided engineering with Synopsys to factory operations with Sight Machine and SymphonyAI.&lt;/p&gt;
&lt;p&gt;Robotics developers can tap into the NVIDIA Isaac Sim open-source robotics simulation framework to unlock critical workflows, from synthetic data generation to software-in-the-loop testing for all types of robot embodiments. Hexagon is building its AEON humanoid robot primarily using NVIDIA’s full robotics stack on Azure. Similarly, the robotics platform, Wandelbots NOVA, running on Azure integrates Isaac Sim and Isaac Lab to simplify and speed up simulation to real-world deployment.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA and Microsoft are using a standardized approach for digital engineering to enable seamless OpenUSD interoperability across 3D workflows, making simulation and digital content creation accessible in the cloud.&lt;/p&gt;
&lt;p&gt;This expanded collaboration comes on the heels of a partnership announced with Anthropic and Microsoft earlier today. NVIDIA and Anthropic will collaborate on design and engineering to optimize Anthropic models for performance, efficiency and total cost of ownership, as well as optimize future NVIDIA architectures for Anthropic workloads.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about NVIDIA and Microsoft’s collaboration and sessions at Microsoft Ignite.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/partner-blog-azure-promo-1260x680-2-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Timed with the Microsoft Ignite conference running this week, NVIDIA is expanding its collaboration with Microsoft, including through the adoption of next-generation NVIDIA Spectrum-X Ethernet switches for the new Microsoft Fairwater AI superfactory, powered by the NVIDIA Blackwell platform.&lt;/p&gt;
&lt;p&gt;The collaboration brings new integrations across Microsoft 365 Copilot, as well as the public preview of next-generation Azure NC Series VMs powered by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA Nemotron integrations to accelerate AI for Microsoft SQL Server 2025, capabilities for onboarding AI agents in Microsoft 365 and optimizations for high-performance inference, cybersecurity and physical AI.&lt;/p&gt;
&lt;p&gt;Microsoft’s AI Superfactory connects the landmark Fairwater data center in Wisconsin with a new, state-of-the-art facility in Atlanta, Georgia. This massive-scale infrastructure will integrate hundreds of thousands of NVIDIA Blackwell GPUs for large-scale training. In addition, Microsoft is deploying more than 100,000 Blackwell Ultra GPUs in NVIDIA GB300 NVL72 systems being deployed globally for inference.&lt;/p&gt;
&lt;p&gt;“Our collaboration with NVIDIA is built on driving innovation across the entire system and full stack, from silicon to services,” said Nidhi Chappell, corporate vice president of product management at Microsoft. “By coupling Microsoft Azure’s unmatched data center scale with NVIDIA’s accelerated computing, we are maximizing AI data center performance and efficiency, which is of paramount importance for our customers leading the new AI era.”&lt;/p&gt;
&lt;p&gt;The most demanding workloads for OpenAI, the Microsoft AI Superintelligence Team, Microsoft 365 Copilot and Microsoft Foundry services will be powered by this infrastructure. Customers like Black Forest Labs are also using NVIDIA GB200 NVL72 systems to train next-generation multimodal FLUX models that power visual intelligence.&lt;/p&gt;
&lt;p&gt;To connect this massive infrastructure, Microsoft is deploying next-generation NVIDIA Spectrum-X Ethernet switches in its Fairwater AI data center — the largest and most sophisticated AI factories ever built — delivering the performance, scale and efficiency required for OpenAI to run large-scale AI models and applications.&lt;/p&gt;
&lt;p&gt;New Azure NCv6 Series VMs with NVIDIA RTX PRO 6000 Blackwell GPUs are now in public preview on Azure, expanding the Blackwell platform to provide right-sized acceleration for multiple workloads including multimodal agentic AI, industrial digitalization with NVIDIA Omniverse libraries, scientific simulation and visual computing. This flexibility extends from the cloud to the edge with Azure Local, enabling powerful sovereign AI solutions while bringing low-latency, real-time AI to wherever data needs to reside.&lt;/p&gt;
&lt;p&gt;This allows enterprises to seamlessly develop, deploy and manage AI-powered digital twins and generative AI applications with NVIDIA RTX PRO 6000 Blackwell GPUs from the Azure cloud directly to their factory floors, on-premises data centers or secure edge locations.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Software Optimizations Deliver a Fungible AI Fleet&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA platform on Azure, spanning NVIDIA Blackwell and Hopper GPUs, accelerates the latest models from the Microsoft AI Superintelligence Team, including text (MAI-1-preview), real-time voice (MAI-Voice-1) and high-fidelity image generation (MAI-Image-1) — bringing new multimodal experiences across Bing Image Creator and Microsoft Copilot.&lt;/p&gt;
&lt;p&gt;Central to NVIDIA’s collaboration with Microsoft is building a fungible fleet — a flexible, continuously modernized infrastructure that can accelerate any workload with maximum efficiency. This is achieved through continuous, full-stack software optimizations that deliver compounding performance gains and maximize throughput across the entire AI lifecycle and across multiple NVIDIA architectures on Azure. The gains also extend to workloads beyond generative AI, including data processing, vector search, databases, digital twins, scientific computing and 3D design.&lt;/p&gt;
&lt;p&gt;This co-engineering saves significant costs for customers, making AI projects that were once theoretical now economically viable. For example, the continuous full-stack optimization work has directly contributed to an over 90% drop in the price of popular GPT models for end users on Azure in two years.&lt;/p&gt;
&lt;p&gt;Ongoing optimization work now extends to Microsoft Foundry, where the NVIDIA TensorRT-LLM library helps boost throughput, reduce latency and lower costs for a wide range of popular open models.&lt;/p&gt;
&lt;p&gt;NVIDIA and Microsoft have also partnered to optimize their fleet for AI workload performance through the NVIDIA DGX Cloud Benchmarking suite. Engineering teams from both companies worked closely together to identify bottlenecks and implement infrastructure tuning, driving performance gains. By achieving 95% of the performance possible using the NVIDIA reference architecture, Microsoft was named an Exemplar Cloud for H100 training.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;From Intelligent Data to AI Agents&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and Microsoft are integrating AI into the core of the enterprise, unlocking decades of proprietary data stored in one of the world’s most trusted databases.&lt;/p&gt;
&lt;p&gt;NVIDIA is accelerating AI in the new Microsoft SQL Server 2025 by integrating it with NVIDIA Nemotron open models and NVIDIA NIM microservices. This solution delivers GPU-optimized, secure and scalable retrieval-augmented generation directly where enterprise data lives, in the cloud or on premises.&lt;/p&gt;
&lt;p&gt;Plus, the collaboration extends to the new frontier of agentic AI in the workplace. The NVIDIA NeMo Agent Toolkit now connects with Microsoft Agent 365, enabling developers to build, deploy and onboard compliant, enterprise-ready AI agents directly into the Microsoft 365 app ecosystem, including Outlook, Teams, Word and SharePoint.&lt;/p&gt;
&lt;p&gt;To power these new enterprise agents, Microsoft Foundry now offers NVIDIA Nemotron models for digital AI and NVIDIA Cosmos models for physical AI as secure NIM microservices. Developers can use them to build enterprise-grade agentic AI for a vast range of applications that benefit from multimodal intelligence, multilingual reasoning, math, coding and physical AI capabilities.&lt;/p&gt;
&lt;p&gt;The collaboration is also tackling cyber threats for enterprises. Microsoft and NVIDIA are collaborating on research for new adversarial learning models, built on the NVIDIA Dynamo-Triton framework and the NVIDIA TensorRT suite of tools, that can help enterprises defend against real-time cybersecurity threats with a 160x performance speedup compared with CPU methods.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Physical AI and Industrial Digitalization&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and Microsoft are building the future of physical AI. With NVIDIA Omniverse libraries available on Microsoft Azure, NVIDIA is unlocking end-to-end reindustrialization in the cloud through its developer ecosystem. Developers are transforming industrial workflows, from computer-aided engineering with Synopsys to factory operations with Sight Machine and SymphonyAI.&lt;/p&gt;
&lt;p&gt;Robotics developers can tap into the NVIDIA Isaac Sim open-source robotics simulation framework to unlock critical workflows, from synthetic data generation to software-in-the-loop testing for all types of robot embodiments. Hexagon is building its AEON humanoid robot primarily using NVIDIA’s full robotics stack on Azure. Similarly, the robotics platform, Wandelbots NOVA, running on Azure integrates Isaac Sim and Isaac Lab to simplify and speed up simulation to real-world deployment.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA and Microsoft are using a standardized approach for digital engineering to enable seamless OpenUSD interoperability across 3D workflows, making simulation and digital content creation accessible in the cloud.&lt;/p&gt;
&lt;p&gt;This expanded collaboration comes on the heels of a partnership announced with Anthropic and Microsoft earlier today. NVIDIA and Anthropic will collaborate on design and engineering to optimize Anthropic models for performance, efficiency and total cost of ownership, as well as optimize future NVIDIA architectures for Anthropic workloads.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about NVIDIA and Microsoft’s collaboration and sessions at Microsoft Ignite.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-microsoft-ai-superfactories/</guid><pubDate>Tue, 18 Nov 2025 20:00:22 +0000</pubDate></item><item><title>[NEW] Musk's xAI launches Grok 4.1 with lower hallucination rate on the web and apps — no API access (for now) (AI | VentureBeat)</title><link>https://venturebeat.com/ai/musks-xai-launches-grok-4-1-with-lower-hallucination-rate-on-the-web-and</link><description>[unable to retrieve full-text content]&lt;p&gt;In what appeared to be a bid to soak up some of Google&amp;#x27;s limelight prior to the &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;launch of its new Gemini 3 flagship AI model &lt;/a&gt;— now recorded as the most powerful LLM in the world by multiple independent evaluators — Elon Musk&amp;#x27;s rival AI startup xAI last night unveiled its newest large language model, &lt;a href="https://x.ai/news/grok-4-1"&gt;Grok 4.1.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The model is now live for consumer use on Grok.com, social network X (formerly Twitter), and the company’s iOS and Android mobile apps, and it arrives with major architectural and usability enhancements, among them: faster reasoning, improved emotional intelligence, and significantly reduced hallucination rates. xAI also commendably published a white paper on its evaluations and including a small bit on training process &lt;a href="https://data.x.ai/2025-11-17-grok-4-1-model-card.pdf"&gt;here&lt;/a&gt;.  &lt;/p&gt;&lt;p&gt;Across public benchmarks, Grok 4.1 has vaulted to the top of the leaderboard, outperforming rival models from Anthropic, OpenAI, and Google — at least, Google&amp;#x27;s pre-Gemini 3 model (Gemini 2.5 Pro). It builds upon the success of xAI&amp;#x27;s Grok-4 Fast, which &lt;a href="https://venturebeat.com/ai/what-to-know-about-grok-4-fast-for-enterprise-use-cases"&gt;VentureBeat covered favorably&lt;/a&gt; shortly following its release back in September 2025.&lt;/p&gt;&lt;p&gt;However, enterprise developers looking to integrate the new and improved model Grok 4.1 into production environments will find one major constraint: it&amp;#x27;s not yet available through &lt;a href="https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models"&gt;xAI’s public API&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Despite its high benchmarks, Grok 4.1 remains confined to xAI’s consumer-facing interfaces, with no announced timeline for API exposure. At present, only older models—including Grok 4 Fast (reasoning and non-reasoning variants), Grok 4 0709, and legacy models such as Grok 3, Grok 3 Mini, and Grok 2 Vision—are available for programmatic use via the xAI developer API. These support up to 2 million tokens of context, with token pricing ranging from $0.20 to $3.00 per million depending on the configuration.&lt;/p&gt;&lt;p&gt;For now, this limits Grok 4.1’s utility in enterprise workflows that rely on backend integration, fine-tuned agentic pipelines, or scalable internal tooling. While the consumer rollout positions Grok 4.1 as the most capable LLM in xAI’s portfolio, production deployments in enterprise environments remain on hold.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Model Design and Deployment Strategy&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Grok 4.1 arrives in two configurations: a fast-response, low-latency mode for immediate replies, and a “thinking” mode that engages in multi-step reasoning before producing output. &lt;/p&gt;&lt;p&gt;Both versions are live for end users and are selectable via the model picker in xAI’s apps.&lt;/p&gt;&lt;p&gt;The two configurations differ not just in latency but also in how deeply the model processes prompts. Grok 4.1 Thinking leverages internal planning and deliberation mechanisms, while the standard version prioritizes speed. Despite the difference in architecture, both scored higher than any competing models in blind preference and benchmark testing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Leading the Field in Human and Expert Evaluation&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;On the &lt;a href="https://lmarena.ai/leaderboard/text"&gt;LMArena Text Arena leaderboard&lt;/a&gt;, Grok 4.1 Thinking briefly held the top position with a normalized Elo score of 1483 — then was dethroned a few hours later with &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google&amp;#x27;s release of Gemini 3 &lt;/a&gt;and its incredible 1501 Elo score. &lt;/p&gt;&lt;p&gt;The non-thinking version of Grok 4.1 also fares well on the index, however, at 1465. &lt;/p&gt;&lt;p&gt;These scores place Grok 4.1 above Google’s Gemini 2.5 Pro, Anthropic’s Claude 4.5 series, and OpenAI’s GPT-4.5 preview.&lt;/p&gt;&lt;p&gt;In creative writing, Grok 4.1 ranks second only to Polaris Alpha (an early GPT-5.1 variant), with the “thinking” model earning a score of 1721.9 on the Creative Writing v3 benchmark. This marks a roughly 600-point improvement over previous Grok iterations. &lt;/p&gt;&lt;p&gt;Similarly, in the Arena Expert leaderboard, which aggregates feedback from professional reviewers, Grok 4.1 Thinking again leads the field with a score of 1510.&lt;/p&gt;&lt;p&gt;The gains are especially notable given that Grok 4.1 was released only two months after Grok 4 Fast, highlighting the accelerated development pace at xAI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Core Improvements Over Previous Generations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Technically, Grok 4.1 represents a significant leap in real-world usability. Visual capabilities—previously limited in Grok 4—have been upgraded to enable robust image and video understanding, including chart analysis and OCR-level text extraction. Multimodal reliability was a pain point in prior versions and has now been addressed.&lt;/p&gt;&lt;p&gt;Token-level latency has been reduced by approximately 28 percent while preserving reasoning depth. &lt;/p&gt;&lt;p&gt;In long-context tasks, Grok 4.1 maintains coherent output up to 1 million tokens, improving on Grok 4’s tendency to degrade past the 300,000 token mark.&lt;/p&gt;&lt;p&gt;xAI has also improved the model&amp;#x27;s tool orchestration capabilities. Grok 4.1 can now plan and execute multiple external tools in parallel, reducing the number of interaction cycles required to complete multi-step queries. &lt;/p&gt;&lt;p&gt;According to internal test logs, some research tasks that previously required four steps can now be completed in one or two.&lt;/p&gt;&lt;p&gt;Other alignment improvements include better truth calibration—reducing the tendency to hedge or soften politically sensitive outputs—and more natural, human-like prosody in voice mode, with support for different speaking styles and accents.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety and Adversarial Robustness&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As part of its risk management framework, xAI evaluated Grok 4.1 for refusal behavior, hallucination resistance, sycophancy, and dual-use safety.&lt;/p&gt;&lt;p&gt;The hallucination rate in non-reasoning mode has dropped from 12.09 percent in Grok 4 Fast to just 4.22 percent — a roughly 65% improvement.&lt;/p&gt;&lt;p&gt;The model also scored 2.97 percent on FActScore, a factual QA benchmark, down from 9.89 percent in earlier versions.&lt;/p&gt;&lt;p&gt;In the domain of adversarial robustness, Grok 4.1 has been tested with prompt injection attacks, jailbreak prompts, and sensitive chemistry and biology queries. &lt;/p&gt;&lt;p&gt;Safety filters showed low false negative rates, especially for restricted chemical knowledge (0.00 percent) and restricted biological queries (0.03 percent). &lt;/p&gt;&lt;p&gt;The model’s ability to resist manipulation in persuasion benchmarks, such as MakeMeSay, also appears strong—it registered a 0 percent success rate as an attacker.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Limited Enterprise Access via API&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite these gains, Grok 4.1 remains unavailable to enterprise users through xAI’s API. According to the company’s &lt;a href="https://docs.x.ai/docs/models"&gt;public documentation&lt;/a&gt;, the latest available models for developers are Grok 4 Fast (both reasoning and non-reasoning variants), each supporting up to 2 million tokens of context at pricing tiers ranging from $0.20 to $0.50 per million tokens. These are backed by a 4M tokens-per-minute throughput limit and 480 requests per minute (RPM) rate cap.&lt;/p&gt;&lt;p&gt;By contrast, Grok 4.1 is accessible only through xAI’s consumer-facing properties—X, Grok.com, and the mobile apps. This means organizations cannot yet deploy Grok 4.1 via fine-tuned internal workflows, multi-agent chains, or real-time product integrations.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Industry Reception and Next Steps&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release has been met with strong public and industry feedback. Elon Musk, founder of xAI, posted a brief endorsement, calling it “a great model” and congratulating the team. AI benchmark platforms have praised the leap in usability and linguistic nuance.&lt;/p&gt;&lt;p&gt;For enterprise customers, however, the picture is more mixed. Grok 4.1’s performance represents a breakthrough for general-purpose and creative tasks, but until API access is enabled, it will remain a consumer-first product with limited enterprise applicability.&lt;/p&gt;&lt;p&gt;As competitive models from OpenAI, Google, and Anthropic continue to evolve, xAI’s next strategic move may hinge on when—and how—it opens Grok 4.1 to external developers.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In what appeared to be a bid to soak up some of Google&amp;#x27;s limelight prior to the &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;launch of its new Gemini 3 flagship AI model &lt;/a&gt;— now recorded as the most powerful LLM in the world by multiple independent evaluators — Elon Musk&amp;#x27;s rival AI startup xAI last night unveiled its newest large language model, &lt;a href="https://x.ai/news/grok-4-1"&gt;Grok 4.1.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The model is now live for consumer use on Grok.com, social network X (formerly Twitter), and the company’s iOS and Android mobile apps, and it arrives with major architectural and usability enhancements, among them: faster reasoning, improved emotional intelligence, and significantly reduced hallucination rates. xAI also commendably published a white paper on its evaluations and including a small bit on training process &lt;a href="https://data.x.ai/2025-11-17-grok-4-1-model-card.pdf"&gt;here&lt;/a&gt;.  &lt;/p&gt;&lt;p&gt;Across public benchmarks, Grok 4.1 has vaulted to the top of the leaderboard, outperforming rival models from Anthropic, OpenAI, and Google — at least, Google&amp;#x27;s pre-Gemini 3 model (Gemini 2.5 Pro). It builds upon the success of xAI&amp;#x27;s Grok-4 Fast, which &lt;a href="https://venturebeat.com/ai/what-to-know-about-grok-4-fast-for-enterprise-use-cases"&gt;VentureBeat covered favorably&lt;/a&gt; shortly following its release back in September 2025.&lt;/p&gt;&lt;p&gt;However, enterprise developers looking to integrate the new and improved model Grok 4.1 into production environments will find one major constraint: it&amp;#x27;s not yet available through &lt;a href="https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models"&gt;xAI’s public API&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Despite its high benchmarks, Grok 4.1 remains confined to xAI’s consumer-facing interfaces, with no announced timeline for API exposure. At present, only older models—including Grok 4 Fast (reasoning and non-reasoning variants), Grok 4 0709, and legacy models such as Grok 3, Grok 3 Mini, and Grok 2 Vision—are available for programmatic use via the xAI developer API. These support up to 2 million tokens of context, with token pricing ranging from $0.20 to $3.00 per million depending on the configuration.&lt;/p&gt;&lt;p&gt;For now, this limits Grok 4.1’s utility in enterprise workflows that rely on backend integration, fine-tuned agentic pipelines, or scalable internal tooling. While the consumer rollout positions Grok 4.1 as the most capable LLM in xAI’s portfolio, production deployments in enterprise environments remain on hold.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Model Design and Deployment Strategy&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Grok 4.1 arrives in two configurations: a fast-response, low-latency mode for immediate replies, and a “thinking” mode that engages in multi-step reasoning before producing output. &lt;/p&gt;&lt;p&gt;Both versions are live for end users and are selectable via the model picker in xAI’s apps.&lt;/p&gt;&lt;p&gt;The two configurations differ not just in latency but also in how deeply the model processes prompts. Grok 4.1 Thinking leverages internal planning and deliberation mechanisms, while the standard version prioritizes speed. Despite the difference in architecture, both scored higher than any competing models in blind preference and benchmark testing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Leading the Field in Human and Expert Evaluation&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;On the &lt;a href="https://lmarena.ai/leaderboard/text"&gt;LMArena Text Arena leaderboard&lt;/a&gt;, Grok 4.1 Thinking briefly held the top position with a normalized Elo score of 1483 — then was dethroned a few hours later with &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google&amp;#x27;s release of Gemini 3 &lt;/a&gt;and its incredible 1501 Elo score. &lt;/p&gt;&lt;p&gt;The non-thinking version of Grok 4.1 also fares well on the index, however, at 1465. &lt;/p&gt;&lt;p&gt;These scores place Grok 4.1 above Google’s Gemini 2.5 Pro, Anthropic’s Claude 4.5 series, and OpenAI’s GPT-4.5 preview.&lt;/p&gt;&lt;p&gt;In creative writing, Grok 4.1 ranks second only to Polaris Alpha (an early GPT-5.1 variant), with the “thinking” model earning a score of 1721.9 on the Creative Writing v3 benchmark. This marks a roughly 600-point improvement over previous Grok iterations. &lt;/p&gt;&lt;p&gt;Similarly, in the Arena Expert leaderboard, which aggregates feedback from professional reviewers, Grok 4.1 Thinking again leads the field with a score of 1510.&lt;/p&gt;&lt;p&gt;The gains are especially notable given that Grok 4.1 was released only two months after Grok 4 Fast, highlighting the accelerated development pace at xAI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Core Improvements Over Previous Generations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Technically, Grok 4.1 represents a significant leap in real-world usability. Visual capabilities—previously limited in Grok 4—have been upgraded to enable robust image and video understanding, including chart analysis and OCR-level text extraction. Multimodal reliability was a pain point in prior versions and has now been addressed.&lt;/p&gt;&lt;p&gt;Token-level latency has been reduced by approximately 28 percent while preserving reasoning depth. &lt;/p&gt;&lt;p&gt;In long-context tasks, Grok 4.1 maintains coherent output up to 1 million tokens, improving on Grok 4’s tendency to degrade past the 300,000 token mark.&lt;/p&gt;&lt;p&gt;xAI has also improved the model&amp;#x27;s tool orchestration capabilities. Grok 4.1 can now plan and execute multiple external tools in parallel, reducing the number of interaction cycles required to complete multi-step queries. &lt;/p&gt;&lt;p&gt;According to internal test logs, some research tasks that previously required four steps can now be completed in one or two.&lt;/p&gt;&lt;p&gt;Other alignment improvements include better truth calibration—reducing the tendency to hedge or soften politically sensitive outputs—and more natural, human-like prosody in voice mode, with support for different speaking styles and accents.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety and Adversarial Robustness&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As part of its risk management framework, xAI evaluated Grok 4.1 for refusal behavior, hallucination resistance, sycophancy, and dual-use safety.&lt;/p&gt;&lt;p&gt;The hallucination rate in non-reasoning mode has dropped from 12.09 percent in Grok 4 Fast to just 4.22 percent — a roughly 65% improvement.&lt;/p&gt;&lt;p&gt;The model also scored 2.97 percent on FActScore, a factual QA benchmark, down from 9.89 percent in earlier versions.&lt;/p&gt;&lt;p&gt;In the domain of adversarial robustness, Grok 4.1 has been tested with prompt injection attacks, jailbreak prompts, and sensitive chemistry and biology queries. &lt;/p&gt;&lt;p&gt;Safety filters showed low false negative rates, especially for restricted chemical knowledge (0.00 percent) and restricted biological queries (0.03 percent). &lt;/p&gt;&lt;p&gt;The model’s ability to resist manipulation in persuasion benchmarks, such as MakeMeSay, also appears strong—it registered a 0 percent success rate as an attacker.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Limited Enterprise Access via API&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite these gains, Grok 4.1 remains unavailable to enterprise users through xAI’s API. According to the company’s &lt;a href="https://docs.x.ai/docs/models"&gt;public documentation&lt;/a&gt;, the latest available models for developers are Grok 4 Fast (both reasoning and non-reasoning variants), each supporting up to 2 million tokens of context at pricing tiers ranging from $0.20 to $0.50 per million tokens. These are backed by a 4M tokens-per-minute throughput limit and 480 requests per minute (RPM) rate cap.&lt;/p&gt;&lt;p&gt;By contrast, Grok 4.1 is accessible only through xAI’s consumer-facing properties—X, Grok.com, and the mobile apps. This means organizations cannot yet deploy Grok 4.1 via fine-tuned internal workflows, multi-agent chains, or real-time product integrations.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Industry Reception and Next Steps&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release has been met with strong public and industry feedback. Elon Musk, founder of xAI, posted a brief endorsement, calling it “a great model” and congratulating the team. AI benchmark platforms have praised the leap in usability and linguistic nuance.&lt;/p&gt;&lt;p&gt;For enterprise customers, however, the picture is more mixed. Grok 4.1’s performance represents a breakthrough for general-purpose and creative tasks, but until API access is enabled, it will remain a consumer-first product with limited enterprise applicability.&lt;/p&gt;&lt;p&gt;As competitive models from OpenAI, Google, and Anthropic continue to evolve, xAI’s next strategic move may hinge on when—and how—it opens Grok 4.1 to external developers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/musks-xai-launches-grok-4-1-with-lower-hallucination-rate-on-the-web-and</guid><pubDate>Tue, 18 Nov 2025 20:03:00 +0000</pubDate></item><item><title>[NEW] Tech giants pour billions into Anthropic as circular AI investments roll on (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/tech-giants-pour-billions-into-anthropic-as-circular-ai-investments-roll-on/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        ChatGPT competitor secures billions from Microsoft and Nvidia in deal to use cloud services and chips.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/triple_people-640x356.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/triple_people-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still image of Dario Amodei of Anthropic (L), Satya Nadella of Microsoft (Center), and Jensen Huang of Nvidia (R) taken from an announcement video.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.youtube.com/watch?v=bl7vHnOgEg0&amp;amp;t=4s

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Microsoft and Nvidia announced plans to invest in Anthropic under a new partnership that includes a $30 billion commitment by the Claude maker to use Microsoft’s cloud services. Nvidia will commit up to $10 billion to Anthropic and Microsoft up to $5 billion, with both companies investing in Anthropic’s next funding round.&lt;/p&gt;
&lt;p&gt;The deal brings together two companies that have backed OpenAI and connects them more closely to one of the ChatGPT maker’s main competitors. Microsoft CEO Satya Nadella said in a video that OpenAI “remains a critical partner,” while adding that the companies will increasingly be customers of each other.&lt;/p&gt;
&lt;p&gt;“We will use Anthropic models, they will use our infrastructure, and we’ll go to market together,” Nadella said.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic, Microsoft, and NVIDIA announce partnerships. 

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The move follows OpenAI’s recent restructuring that gave the company greater distance from its non-profit origins. OpenAI has since announced a $38 billion deal to buy cloud services from Amazon.com as the company becomes less dependent on Microsoft. OpenAI CEO Sam Altman has said the company plans to spend $1.4 trillion to develop 30 gigawatts of computing resources.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;D.A. Davidson analyst Gil Luria told Reuters that the new Anthropic-Microsoft partnership aims to reduce the AI economy’s reliance on OpenAI. “Microsoft has decided not to rely on one frontier model company,” Luria said. “Nvidia was also somewhat dependent on OpenAI’s success and is now helping generating broader demand.”&lt;/p&gt;
&lt;p&gt;However, the partnership also places further scrutiny on the increasingly circular nature of AI industry investments. “Anthropic will pay Microsoft to pay Nvidia so Microsoft and Nvidia can pay Anthropic,” wrote CNBC tech correspondent Steve Kovach on Bluesky.&lt;/p&gt;
&lt;p&gt;Under the partnership, Anthropic will work with Nvidia on chips and models to improve performance and commit up to 1 gigawatt of compute using Nvidia’s Grace Blackwell and Vera Rubin hardware.&lt;/p&gt;
&lt;p&gt;Microsoft will give Azure AI Foundry customers access to the latest Claude models. With this deal, Claude becomes available through all three major cloud providers: Microsoft, Amazon, and Google. Amazon will remain Anthropic’s primary cloud provider and training partner.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        ChatGPT competitor secures billions from Microsoft and Nvidia in deal to use cloud services and chips.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/triple_people-640x356.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/triple_people-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still image of Dario Amodei of Anthropic (L), Satya Nadella of Microsoft (Center), and Jensen Huang of Nvidia (R) taken from an announcement video.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.youtube.com/watch?v=bl7vHnOgEg0&amp;amp;t=4s

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Microsoft and Nvidia announced plans to invest in Anthropic under a new partnership that includes a $30 billion commitment by the Claude maker to use Microsoft’s cloud services. Nvidia will commit up to $10 billion to Anthropic and Microsoft up to $5 billion, with both companies investing in Anthropic’s next funding round.&lt;/p&gt;
&lt;p&gt;The deal brings together two companies that have backed OpenAI and connects them more closely to one of the ChatGPT maker’s main competitors. Microsoft CEO Satya Nadella said in a video that OpenAI “remains a critical partner,” while adding that the companies will increasingly be customers of each other.&lt;/p&gt;
&lt;p&gt;“We will use Anthropic models, they will use our infrastructure, and we’ll go to market together,” Nadella said.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic, Microsoft, and NVIDIA announce partnerships. 

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The move follows OpenAI’s recent restructuring that gave the company greater distance from its non-profit origins. OpenAI has since announced a $38 billion deal to buy cloud services from Amazon.com as the company becomes less dependent on Microsoft. OpenAI CEO Sam Altman has said the company plans to spend $1.4 trillion to develop 30 gigawatts of computing resources.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;D.A. Davidson analyst Gil Luria told Reuters that the new Anthropic-Microsoft partnership aims to reduce the AI economy’s reliance on OpenAI. “Microsoft has decided not to rely on one frontier model company,” Luria said. “Nvidia was also somewhat dependent on OpenAI’s success and is now helping generating broader demand.”&lt;/p&gt;
&lt;p&gt;However, the partnership also places further scrutiny on the increasingly circular nature of AI industry investments. “Anthropic will pay Microsoft to pay Nvidia so Microsoft and Nvidia can pay Anthropic,” wrote CNBC tech correspondent Steve Kovach on Bluesky.&lt;/p&gt;
&lt;p&gt;Under the partnership, Anthropic will work with Nvidia on chips and models to improve performance and commit up to 1 gigawatt of compute using Nvidia’s Grace Blackwell and Vera Rubin hardware.&lt;/p&gt;
&lt;p&gt;Microsoft will give Azure AI Foundry customers access to the latest Claude models. With this deal, Claude becomes available through all three major cloud providers: Microsoft, Amazon, and Google. Amazon will remain Anthropic’s primary cloud provider and training partner.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/tech-giants-pour-billions-into-anthropic-as-circular-ai-investments-roll-on/</guid><pubDate>Tue, 18 Nov 2025 20:37:04 +0000</pubDate></item><item><title>[NEW] Hugging Face CEO says we’re in an ‘LLM bubble,’ not an AI bubble (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/hugging-face-ceo-says-were-in-an-llm-bubble-not-an-ai-bubble/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/clem-delangue.png?resize=1200,789" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hugging Face co-founder and CEO Clem Delangue says we’re not in an AI bubble, but an “LLM bubble” — and it may be poised to pop. At an Axios event on Tuesday, the entrepreneur behind the popular AI platform and community site agreed that bubble talk is today’s “trillion-dollar question,” but said he doesn’t believe AI’s future is at risk if the bubble bursts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, as Delangue sees it, it’s large language models (LLMs) — like those powering ChatGPT, Gemini, and other chatbots — that are receiving outsized attention, and that attention may not last.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re in an LLM bubble, and I think the LLM bubble might be bursting next year,” explained Delangue. “But ‘LLM’ is just a subset of AI when it comes to applying AI to biology, chemistry, image, audio, [and] video. I think we’re at the beginning of it, and we’ll see much more in the next few years,” he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One issue, he argued, is that LLMs aren’t the right solution for everything, and smaller, more specialized models will see increased adoption in the future. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think all the attention, all the focus, all the money, is concentrated into this idea that you can build one model through a bunch of compute and that is going to solve all problems for all companies and all people,” said Delangue. “I think the reality is that you’ll see in the next few months, next few years, kind of like a multiplicity of models that are more customized, specialized, that are going to solve different problems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As an example, he suggested the use case of a banking customer chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You don’t need it to tell you about the meaning of life, right? You can use a smaller, more specialized model that is going to be cheaper, that is going to be faster, that maybe you’re going to be able to run on your infrastructure as an enterprise, and I think that is the future of AI,” Delangue pointed out. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Hugging Face founder admitted that an LLM bubble bursting could impact his company to some extent, but noted that the AI industry is so big that it’s already diversified. That means even if a portion of the industry is overvalued, like LLMs, it’s not going to have a massive impact on the AI field itself or his business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, he noted, Hugging Face still has half of the $400 million it has raised in the bank. This cautious approach to spending represents a different strategy from what other AI companies are doing these days, especially in the LLM space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In AI standards, that’s called profitability because the other guys — it’s not hundreds of millions that they’re spending. It’s obviously billions of dollars,” he said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By comparison, Hugging Face is taking a more capital-efficient approach. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think a lot of people right now are rushing — or maybe even panicking — and taking a really short-term approach to things. I’ve been in AI for 15 years now, so I’ve seen some of the cycles,” Delangue added. “And so we’re learning from that and trying to build a long-term, sustainable, impactful company for the world.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/clem-delangue.png?resize=1200,789" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hugging Face co-founder and CEO Clem Delangue says we’re not in an AI bubble, but an “LLM bubble” — and it may be poised to pop. At an Axios event on Tuesday, the entrepreneur behind the popular AI platform and community site agreed that bubble talk is today’s “trillion-dollar question,” but said he doesn’t believe AI’s future is at risk if the bubble bursts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, as Delangue sees it, it’s large language models (LLMs) — like those powering ChatGPT, Gemini, and other chatbots — that are receiving outsized attention, and that attention may not last.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re in an LLM bubble, and I think the LLM bubble might be bursting next year,” explained Delangue. “But ‘LLM’ is just a subset of AI when it comes to applying AI to biology, chemistry, image, audio, [and] video. I think we’re at the beginning of it, and we’ll see much more in the next few years,” he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One issue, he argued, is that LLMs aren’t the right solution for everything, and smaller, more specialized models will see increased adoption in the future. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think all the attention, all the focus, all the money, is concentrated into this idea that you can build one model through a bunch of compute and that is going to solve all problems for all companies and all people,” said Delangue. “I think the reality is that you’ll see in the next few months, next few years, kind of like a multiplicity of models that are more customized, specialized, that are going to solve different problems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As an example, he suggested the use case of a banking customer chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You don’t need it to tell you about the meaning of life, right? You can use a smaller, more specialized model that is going to be cheaper, that is going to be faster, that maybe you’re going to be able to run on your infrastructure as an enterprise, and I think that is the future of AI,” Delangue pointed out. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Hugging Face founder admitted that an LLM bubble bursting could impact his company to some extent, but noted that the AI industry is so big that it’s already diversified. That means even if a portion of the industry is overvalued, like LLMs, it’s not going to have a massive impact on the AI field itself or his business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, he noted, Hugging Face still has half of the $400 million it has raised in the bank. This cautious approach to spending represents a different strategy from what other AI companies are doing these days, especially in the LLM space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In AI standards, that’s called profitability because the other guys — it’s not hundreds of millions that they’re spending. It’s obviously billions of dollars,” he said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By comparison, Hugging Face is taking a more capital-efficient approach. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think a lot of people right now are rushing — or maybe even panicking — and taking a really short-term approach to things. I’ve been in AI for 15 years now, so I’ve seen some of the cycles,” Delangue added. “And so we’re learning from that and trying to build a long-term, sustainable, impactful company for the world.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/hugging-face-ceo-says-were-in-an-llm-bubble-not-an-ai-bubble/</guid><pubDate>Tue, 18 Nov 2025 21:42:48 +0000</pubDate></item><item><title>[NEW] Gordon Bell Prize Finalists Push Open Science Boundaries With NVIDIA-Powered Supercomputers (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/gordon-bell-finalists-2025/</link><description>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.4 (Yoast SEO v26.4) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	Gordon Bell Prize Finalists Push Open Science Boundaries With NVIDIA-Powered Supercomputers | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Five finalists for the esteemed high-performance computing award have achieved breakthroughs in climate modeling, fluid simulation and more with the Alps, JUPITER and Perlmutter supercomputers.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Five finalists for the Gordon Bell Prize for outstanding achievements in high-performance computing (HPC) are using NVIDIA-powered supercomputers for their critical work in climate modeling, materials science, fluid simulation, geophysics and electronic design.&lt;/p&gt;&lt;p&gt;Announced today at SC25, the finalists’ projects are driving AI and HPC for science using physics simulation, high-precision math and other advanced supercomputing techniques, accelerating breakthroughs across weather forecasting, semiconductor design, space exploration and other fields. Their results are open and accessible on ArXiv.&lt;/p&gt;&lt;p&gt;The supercomputers powering their work include:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Alps — hosted at the Swiss National Supercomputing Centre (CSCS) and powered by more than 10,000 NVIDIA GH200 Grace Hopper Superchips.&amp;nbsp;&lt;/li&gt;
&lt;li&gt;Perlmutter — hosted at the National Energy Research Scientific Computing Center (NERSC) and powered by NVIDIA accelerated computing.&lt;/li&gt;
&lt;li&gt;JUPITER — Europe’s first exascale supercomputer, hosted at the Jülich Supercomputing Centre (JSC) and powered by the NVIDIA Grace Hopper platform and Quantum-X800 InfiniBand networking.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jupiter-featured_1280x720.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rendering of JUPITER supercomputer racks featuring the NVIDIA Grace Hopper platform. Video courtesy of Forschungszentrum Jülich / Sascha Kreklau.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“At CSCS, we don’t just support open science — we accelerate it,” said Thomas Schulthess, director of CSCS. “The extraordinary breakthroughs by this year’s five Gordon Bell finalists in climate modeling, materials science, fluid dynamics and digital twins stand as irrefutable proof: without the Alps supercomputer, these scientific discoveries simply would not exist. Pushing computational boundaries turns bold targets into reality, delivering scientific revolutions that will redefine our world.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="&amp;quot;Pushing computational boundaries turns bold targets into reality, delivering scientific revolutions that will redefine our world,&amp;quot; said Thomas Schulthess, director of CSCS." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/cscs-pull-quote-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Learn more about the five finalists’ projects below.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;ICON: Modeling Earth at Kilometer-Scale&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;A novel configuration for the ICON Earth system model — developed by researchers at the Max Planck Institute for Meteorology, German Climate Computing Centre (DKRZ), CSCS, JSC, ETH Zurich and NVIDIA — is poised to enable more accurate weather forecasts and a deeper understanding of how the planet works.&amp;nbsp;&lt;/p&gt;&lt;p&gt;By modeling the entire Earth’s systems at kilometer-scale resolution, ICON can capture the flow of energy, water and carbon through the atmosphere, oceans and land with exceptional detail and unprecedented temporal compression — allowing about 146 days to be simulated every 24 hours — which enables more efficient climate simulations projecting up to decades forward.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/11/icon-carbon-flux-simulation-video.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A simulation of carbon dioxide flux using the ICON model.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Integrating all essential components of the Earth system in the ICON model at an unprecedented resolution of 1 kilometer allows researchers to see full global Earth system information on local scales and learn more about the implications of future warming for both people and ecosystems,” said Daniel Klocke, computational infrastructure and model development group leader at Max Planck Institute for Meteorology.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;ORBIT-2: Exascale Vision Foundation Models for Weather and Climate Modeling&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Developed as part of a collaboration between Oak Ridge National Laboratory, NVIDIA and others — and running on the Alps supercomputer — ORBIT-2 is an AI foundation model for weather and climate downscaling that demonstrates unparalleled scalability and precision.&lt;/p&gt;&lt;p&gt;Tapping into exascale computing and algorithmic innovation, ORBIT-2 overcomes challenges faced by traditional climate models with spatial hyper-resolution downscaling, a technique that creates high-resolution data from lower-resolution sources. This enables teams to capture and predict far more localized phenomena like urban heat islands, extreme precipitation events and subtle shifts in monsoon patterns.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;“NVIDIA’s advanced supercomputing technologies enabled ORBIT-2 to achieve exceptional scalability, reliability and impact at the intersection of AI and high-performance computing on NVIDIA platforms,” said Prasanna Balaprakash, director of AI programs and section head for data and AI systems at Oak Ridge National Laboratory.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;QuaTrEx: Advancing Transistor Design Through Nanoscale Device Modeling&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;A team from ETH Zurich has advanced nanoscale electronic device modeling with QuaTrEx, a package of algorithms that can boost the design of next-generation transistors.&lt;/p&gt;&lt;p&gt;Running on the Alps supercomputer with NVIDIA GH200 Superchips, QuaTrEx can simulate devices with more than 45,000 atoms with FP64 performance and extreme parallel-computing efficiency. This enables faster, more accurate design of transistors, called NREFTs, that will be crucial for the semiconductor industry.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A simulation of the flow of electrons in a nanoribbon transistor. Video courtesy of ETH Zurich.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Access to Alps was instrumental in the development of QuaTrEx,” said Mathieu Luisier, full professor of computational nanoelectronics at ETH Zurich. “It allowed us to simulate devices that we could not imagine handling just a few months ago.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Simulating Spacecraft at Record-Breaking Scales With the MFC Flow Solver&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Designing spacecrafts, especially those with many small engines, requires detailed simulation, as engines packed closely together can cause their exhaust to interact and heat up a rocket’s base.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Running on the Alps supercomputer, MFC, an open-source solver developed by the Georgia Institute of Technology in collaboration with NVIDIA and others, enables fluid flow simulation 4x faster and with over 5x greater energy efficiency while maintaining the same accuracy as the previous world record. Based on full-scale runs on Alps, MFC is expected to run at 10x the scale of the previous world record on JUPITER. This paves the way for faster, more accurate design of critical components for space exploration.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/11/mfc-engine-simulation.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rocket engine simulation using computational fluid dynamics. Video courtesy of the Georgia Institute of Technology.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Our new information geometric regularization method, combined with the NVIDIA GH200 Superchip’s unified virtual memory and mixed-precision capabilities, has drastically improved the efficiency of simulating complex computational fluid flows, enabling us to simulate rocket engine plumes at unprecedented scales,” said Spencer Bryngelson, assistant professor in computational science and engineering at the Georgia Institute of Technology.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;A Digital Twin for Tsunami Early Warning&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The University of Texas at Austin, Lawrence Livermore National Laboratory and the University of California San Diego have created the world’s first digital twin that can issue real-time probabilistic tsunami forecasts based on a full-physics model.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Applied to the Cascadia subduction zone in the Pacific Northwest, the digital twin accomplished complex computations that would normally take 50 years on 512 GPUs in just 0.2 seconds on the Alps and Perlmutter supercomputers, representing a 10 billion-fold speedup.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;“For the first time, real-time sensor data can be rapidly combined with full-physics modeling and uncertainty quantification to give people a chance to act before disaster strikes,” said Omar Ghattas, professor of mechanical engineering at UT Austin. “This framework provides a basis for predictive, physics-based emergency-response systems across various hazards.”&lt;/p&gt;&lt;p&gt;For the tsunami digital twin, ICON and MFC projects, NVIDIA CUDA-X libraries played a key role in maximizing the performance and efficiency of the complex simulations. ICON also taps into NVIDIA CUDA Graphs, which allow work to be defined as graphs rather than single operations.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about the latest supercomputing advancements by joining &lt;/i&gt;&lt;i&gt;NVIDIA at SC25&lt;/i&gt;&lt;i&gt;, running through Thursday, Nov. 20.&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</description><content:encoded>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.4 (Yoast SEO v26.4) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	Gordon Bell Prize Finalists Push Open Science Boundaries With NVIDIA-Powered Supercomputers | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Five finalists for the esteemed high-performance computing award have achieved breakthroughs in climate modeling, fluid simulation and more with the Alps, JUPITER and Perlmutter supercomputers.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Five finalists for the Gordon Bell Prize for outstanding achievements in high-performance computing (HPC) are using NVIDIA-powered supercomputers for their critical work in climate modeling, materials science, fluid simulation, geophysics and electronic design.&lt;/p&gt;&lt;p&gt;Announced today at SC25, the finalists’ projects are driving AI and HPC for science using physics simulation, high-precision math and other advanced supercomputing techniques, accelerating breakthroughs across weather forecasting, semiconductor design, space exploration and other fields. Their results are open and accessible on ArXiv.&lt;/p&gt;&lt;p&gt;The supercomputers powering their work include:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Alps — hosted at the Swiss National Supercomputing Centre (CSCS) and powered by more than 10,000 NVIDIA GH200 Grace Hopper Superchips.&amp;nbsp;&lt;/li&gt;
&lt;li&gt;Perlmutter — hosted at the National Energy Research Scientific Computing Center (NERSC) and powered by NVIDIA accelerated computing.&lt;/li&gt;
&lt;li&gt;JUPITER — Europe’s first exascale supercomputer, hosted at the Jülich Supercomputing Centre (JSC) and powered by the NVIDIA Grace Hopper platform and Quantum-X800 InfiniBand networking.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jupiter-featured_1280x720.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rendering of JUPITER supercomputer racks featuring the NVIDIA Grace Hopper platform. Video courtesy of Forschungszentrum Jülich / Sascha Kreklau.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“At CSCS, we don’t just support open science — we accelerate it,” said Thomas Schulthess, director of CSCS. “The extraordinary breakthroughs by this year’s five Gordon Bell finalists in climate modeling, materials science, fluid dynamics and digital twins stand as irrefutable proof: without the Alps supercomputer, these scientific discoveries simply would not exist. Pushing computational boundaries turns bold targets into reality, delivering scientific revolutions that will redefine our world.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="&amp;quot;Pushing computational boundaries turns bold targets into reality, delivering scientific revolutions that will redefine our world,&amp;quot; said Thomas Schulthess, director of CSCS." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/cscs-pull-quote-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Learn more about the five finalists’ projects below.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;ICON: Modeling Earth at Kilometer-Scale&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;A novel configuration for the ICON Earth system model — developed by researchers at the Max Planck Institute for Meteorology, German Climate Computing Centre (DKRZ), CSCS, JSC, ETH Zurich and NVIDIA — is poised to enable more accurate weather forecasts and a deeper understanding of how the planet works.&amp;nbsp;&lt;/p&gt;&lt;p&gt;By modeling the entire Earth’s systems at kilometer-scale resolution, ICON can capture the flow of energy, water and carbon through the atmosphere, oceans and land with exceptional detail and unprecedented temporal compression — allowing about 146 days to be simulated every 24 hours — which enables more efficient climate simulations projecting up to decades forward.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/11/icon-carbon-flux-simulation-video.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A simulation of carbon dioxide flux using the ICON model.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Integrating all essential components of the Earth system in the ICON model at an unprecedented resolution of 1 kilometer allows researchers to see full global Earth system information on local scales and learn more about the implications of future warming for both people and ecosystems,” said Daniel Klocke, computational infrastructure and model development group leader at Max Planck Institute for Meteorology.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;ORBIT-2: Exascale Vision Foundation Models for Weather and Climate Modeling&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Developed as part of a collaboration between Oak Ridge National Laboratory, NVIDIA and others — and running on the Alps supercomputer — ORBIT-2 is an AI foundation model for weather and climate downscaling that demonstrates unparalleled scalability and precision.&lt;/p&gt;&lt;p&gt;Tapping into exascale computing and algorithmic innovation, ORBIT-2 overcomes challenges faced by traditional climate models with spatial hyper-resolution downscaling, a technique that creates high-resolution data from lower-resolution sources. This enables teams to capture and predict far more localized phenomena like urban heat islands, extreme precipitation events and subtle shifts in monsoon patterns.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;“NVIDIA’s advanced supercomputing technologies enabled ORBIT-2 to achieve exceptional scalability, reliability and impact at the intersection of AI and high-performance computing on NVIDIA platforms,” said Prasanna Balaprakash, director of AI programs and section head for data and AI systems at Oak Ridge National Laboratory.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;QuaTrEx: Advancing Transistor Design Through Nanoscale Device Modeling&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;A team from ETH Zurich has advanced nanoscale electronic device modeling with QuaTrEx, a package of algorithms that can boost the design of next-generation transistors.&lt;/p&gt;&lt;p&gt;Running on the Alps supercomputer with NVIDIA GH200 Superchips, QuaTrEx can simulate devices with more than 45,000 atoms with FP64 performance and extreme parallel-computing efficiency. This enables faster, more accurate design of transistors, called NREFTs, that will be crucial for the semiconductor industry.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A simulation of the flow of electrons in a nanoribbon transistor. Video courtesy of ETH Zurich.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Access to Alps was instrumental in the development of QuaTrEx,” said Mathieu Luisier, full professor of computational nanoelectronics at ETH Zurich. “It allowed us to simulate devices that we could not imagine handling just a few months ago.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Simulating Spacecraft at Record-Breaking Scales With the MFC Flow Solver&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Designing spacecrafts, especially those with many small engines, requires detailed simulation, as engines packed closely together can cause their exhaust to interact and heat up a rocket’s base.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Running on the Alps supercomputer, MFC, an open-source solver developed by the Georgia Institute of Technology in collaboration with NVIDIA and others, enables fluid flow simulation 4x faster and with over 5x greater energy efficiency while maintaining the same accuracy as the previous world record. Based on full-scale runs on Alps, MFC is expected to run at 10x the scale of the previous world record on JUPITER. This paves the way for faster, more accurate design of critical components for space exploration.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/11/mfc-engine-simulation.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rocket engine simulation using computational fluid dynamics. Video courtesy of the Georgia Institute of Technology.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Our new information geometric regularization method, combined with the NVIDIA GH200 Superchip’s unified virtual memory and mixed-precision capabilities, has drastically improved the efficiency of simulating complex computational fluid flows, enabling us to simulate rocket engine plumes at unprecedented scales,” said Spencer Bryngelson, assistant professor in computational science and engineering at the Georgia Institute of Technology.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;A Digital Twin for Tsunami Early Warning&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The University of Texas at Austin, Lawrence Livermore National Laboratory and the University of California San Diego have created the world’s first digital twin that can issue real-time probabilistic tsunami forecasts based on a full-physics model.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Applied to the Cascadia subduction zone in the Pacific Northwest, the digital twin accomplished complex computations that would normally take 50 years on 512 GPUs in just 0.2 seconds on the Alps and Perlmutter supercomputers, representing a 10 billion-fold speedup.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;“For the first time, real-time sensor data can be rapidly combined with full-physics modeling and uncertainty quantification to give people a chance to act before disaster strikes,” said Omar Ghattas, professor of mechanical engineering at UT Austin. “This framework provides a basis for predictive, physics-based emergency-response systems across various hazards.”&lt;/p&gt;&lt;p&gt;For the tsunami digital twin, ICON and MFC projects, NVIDIA CUDA-X libraries played a key role in maximizing the performance and efficiency of the complex simulations. ICON also taps into NVIDIA CUDA Graphs, which allow work to be defined as graphs rather than single operations.&lt;/p&gt;&lt;p&gt;[embedded content]&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about the latest supercomputing advancements by joining &lt;/i&gt;&lt;i&gt;NVIDIA at SC25&lt;/i&gt;&lt;i&gt;, running through Thursday, Nov. 20.&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/gordon-bell-finalists-2025/</guid><pubDate>Tue, 18 Nov 2025 22:45:47 +0000</pubDate></item></channel></rss>