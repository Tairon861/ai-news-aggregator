<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 09 Jul 2025 12:46:35 +0000</lastBuildDate><item><title>[NEW] Hugging Face just launched a $299 robot that could disrupt the entire robotics industry (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/hugging-face-just-launched-a-299-robot-that-could-disrupt-the-entire-robotics-industry/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Hugging Face, the $4.5 billion artificial intelligence platform that has become the GitHub of machine learning, announced Tuesday the launch of Reachy Mini, a $299 desktop robot designed to bring AI-powered robotics to millions of developers worldwide. The 11-inch humanoid companion represents the company’s boldest move yet to democratize robotics development and challenge the industry’s traditional closed-source, high-cost model.&lt;/p&gt;



&lt;p&gt;The announcement comes as Hugging Face crosses a significant milestone of 10 million AI builders using its platform, with CEO Clément Delangue revealing in an exclusive interview that “more and more of them are building in relation to robotics.” The compact robot, which can sit on any desk next to a laptop, addresses what Delangue calls a fundamental barrier in robotics development: accessibility.&lt;/p&gt;



&lt;p&gt;“One of the challenges with robotics is that you know you can’t just build on your laptop. You need to have some sort of robotics partner to help in your building, and most people won’t be able to buy $70,000 robots,” Delangue explained, referring to traditional industrial robotics systems and even newer humanoid robots like Tesla’s Optimus, which is expected to cost $20,000-$30,000.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-a-software-company-is-betting-big-on-physical-ai-robots"&gt;How a software company is betting big on physical AI robots&lt;/h2&gt;



&lt;p&gt;Reachy Mini emerges from Hugging Face’s April acquisition of French robotics startup Pollen Robotics, marking the company’s most significant hardware expansion since its founding. The robot represents the first consumer product to integrate natively with the Hugging Face Hub, allowing developers to access thousands of pre-built AI models and share robotics applications through the platform’s “Spaces” feature.&lt;/p&gt;



&lt;p&gt;The timing appears deliberate as the AI industry grapples with the next frontier: physical AI. While large language models have dominated the past two years, industry leaders increasingly believe that artificial intelligence will need physical embodiment to achieve human-level capabilities. Goldman Sachs projects the humanoid robotics market could reach $38 billion by 2035, while the World Economic Forum identifies robotics as a critical frontier technology for industrial operations.&lt;/p&gt;



&lt;p&gt;“We’re seeing more and more people moving to robotics, which is extremely exciting,” Delangue said. “The idea is to really become the desktop, open-source robot for AI builders.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-the-299-robot-that-could-democratize-ai-development"&gt;Inside the $299 robot that could democratize AI development&lt;/h2&gt;



&lt;p&gt;Reachy Mini packs sophisticated capabilities into its compact form factor. The robot features six degrees of freedom in its moving head, full body rotation, animated antennas, a wide-angle camera, multiple microphones, and a 5-watt speaker. The wireless version includes a Raspberry Pi 5 computer and battery, making it fully autonomous.&lt;/p&gt;



&lt;p&gt;The robot ships as a DIY kit and can be programmed in Python, with JavaScript and Scratch support planned. Pre-installed demonstration applications include face and hand tracking, smart companion features, and dancing moves. Developers can create and share new applications through Hugging Face’s Spaces platform, potentially creating what Delangue envisions as “thousands, tens of thousands, millions of apps.”&lt;/p&gt;



&lt;p&gt;This approach contrasts sharply with traditional robotics companies that typically release one product annually with limited customization options. “We want to have a model where we release tons of things,” Delangue explained. “Maybe we’ll release 100 prototypes a year. Out of this 100 prototypes, maybe we’ll assemble only 10 ourselves… and maybe fully assembled, fully packaged, fully integrated with all the software stack, maybe there’s going to be just a couple of them.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-open-source-hardware-might-be-the-future-of-robotics"&gt;Why open source hardware might be the future of robotics&lt;/h2&gt;



&lt;p&gt;The launch represents a fascinating test of whether open-source principles can translate successfully to hardware businesses. Hugging Face plans to release all hardware designs, software, and assembly instructions as open source, allowing anyone to build their own version. The company monetizes through convenience, selling pre-assembled units to developers who prefer to pay rather than build from scratch.&lt;/p&gt;



&lt;p&gt;“You try to share as much as possible to really empower the community,” Delangue explained. “There are people who, even if they have all the recipes open source to build their own Reachy Mini, would prefer to pay 300 bucks, 500 bucks, and get it already ready, or easy to assemble at home.”&lt;/p&gt;



&lt;p&gt;This freemium approach for hardware echoes successful software models but faces unique challenges. Manufacturing costs, supply chain complexity, and physical distribution create constraints that don’t exist in pure software businesses. However, Delangue argues this creates valuable feedback loops: “You learn from the open source community about what they want to build, how they want to build, and you can reintegrate it into what you sell.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-privacy-challenge-facing-ai-robots-in-your-home"&gt;The privacy challenge facing AI robots in your home&lt;/h2&gt;



&lt;p&gt;The move into robotics raises new questions about data privacy and security that don’t exist with purely digital AI systems. Robots equipped with cameras, microphones, and the ability to take physical actions in homes and workplaces create unprecedented privacy considerations.&lt;/p&gt;



&lt;p&gt;Delangue positions open source as the solution to these concerns. “One of my personal motivations to do open source robotics is that I think it’s going to fight concentration of power… the natural tendency of creating black box robots that users don’t really understand or really control,” he said. “The idea of ending up in a world where just a few companies are controlling millions of robots that are in people’s homes, being able to take action in real life, is quite scary.”&lt;/p&gt;



&lt;p&gt;The open-source approach allows users to inspect code, understand data flows, and potentially run AI models locally rather than relying on cloud services. For enterprise customers, Hugging Face’s existing enterprise platform could provide private deployment options for robotics applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-prototype-to-production-hugging-face-s-manufacturing-gamble"&gt;From prototype to production: Hugging Face’s manufacturing gamble&lt;/h2&gt;



&lt;p&gt;Hugging Face faces significant manufacturing and scaling challenges as it transitions from a software platform to a hardware company. The company plans to begin shipping Reachy Mini units as early as next month, starting with more DIY-oriented versions where customers complete final assembly.&lt;/p&gt;



&lt;p&gt;“The first versions, the first orders shipping will be a bit DIY, in the sense that we’ll split the weight of assembling with the user,” Delangue explained. “We’ll do some of the assembling ourselves, and then the user will be doing some of the assembling themselves too.”&lt;/p&gt;



&lt;p&gt;This approach aligns with the company’s goal of engaging the AI builder community in hands-on robotics development while managing manufacturing complexity. The strategy also reflects uncertainty about market demand for the new product category.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-taking-on-tesla-and-boston-dynamics-with-radical-transparency"&gt;Taking on Tesla and Boston Dynamics with radical transparency&lt;/h2&gt;



&lt;p&gt;Reachy Mini enters a rapidly evolving robotics landscape. Tesla’s Optimus program, Figure’s humanoid robots, and Boston Dynamics‘ commercial offerings represent the high-end of the market, while companies like Unitree have introduced more affordable humanoid robots at around $16,000.&lt;/p&gt;



&lt;p&gt;Hugging Face’s approach differs fundamentally from these competitors. Rather than creating a single, highly capable robot, the company is building an ecosystem of affordable, modular, open-source robotics components. Previous releases include the SO-101 robotic arm (starting at $100) and plans for the HopeJR humanoid robot (around $3,000).&lt;/p&gt;



&lt;p&gt;The strategy reflects broader trends in AI development, where open-source models from companies like Meta and smaller players have challenged closed-source leaders like OpenAI. In January, Chinese startup DeepSeek shocked the industry by releasing a powerful AI model developed at significantly lower cost than competing systems, demonstrating the potential for open-source approaches to disrupt established players.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-an-ecosystem-the-partnerships-powering-open-robotics"&gt;Building an ecosystem: The partnerships powering open robotics&lt;/h2&gt;



&lt;p&gt;Hugging Face’s robotics expansion benefits from strategic partnerships across the industry. The company collaborates with NVIDIA on robotics simulation and training through Isaac Lab, enabling developers to generate synthetic training data and test robot behaviors in virtual environments before deployment.&lt;/p&gt;



&lt;p&gt;The recent release of SmolVLA, a 450-million parameter vision-language-action model, demonstrates the technical foundation underlying Reachy Mini. The model is designed to be efficient enough to run on consumer hardware, including MacBooks, making sophisticated AI capabilities accessible to individual developers rather than requiring expensive cloud infrastructure.&lt;/p&gt;



&lt;p&gt;Physical Intelligence, a startup co-founded by UC Berkeley professor Sergey Levine, has made its Pi0 robot foundation model available through Hugging Face, creating opportunities for cross-pollination between different robotics approaches. “Making robotics more accessible increases the velocity with which technology advances,” Levine noted in previous statements about open-source robotics.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-a-299-robot-means-for-the-billion-dollar-ai-hardware-race"&gt;What a $299 robot means for the billion-dollar AI hardware race&lt;/h2&gt;



&lt;p&gt;The Reachy Mini launch signals Hugging Face’s ambition to become the dominant platform for AI development across all modalities, not just text and image generation. With robotics representing a potential $38 billion market by 2035, according to Goldman Sachs projections, early platform positioning could prove strategically valuable.&lt;/p&gt;



&lt;p&gt;Delangue envisions a future where hardware becomes an integral part of AI development workflows. “We see hardware as part of the AI builder building blocks,” he explained. “Always with our approach of being open, being community driven, integrating everything with as many community members, as many other organizations as possible.”&lt;/p&gt;



&lt;p&gt;The company’s financial position provides flexibility to experiment with hardware business models. As a profitable company with significant funding, Hugging Face can afford to prioritize market development over immediate revenue optimization. Delangue mentioned potential subscription models where Hugging Face platform access could include hardware components, similar to how some software companies bundle services.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-affordable-robots-could-transform-education-and-research"&gt;How affordable robots could transform education and research&lt;/h2&gt;



&lt;p&gt;Beyond commercial applications, Reachy Mini could significantly impact robotics education and research. At $299, the robot costs less than many smartphones while providing full programmability and AI integration. Universities, coding bootcamps, and individual learners could use the platform to explore robotics concepts without requiring expensive laboratory equipment.&lt;/p&gt;



&lt;p&gt;The open-source nature enables educational institutions to modify hardware and software to suit specific curricula. Students could progress from basic programming exercises to sophisticated AI applications using the same platform, potentially accelerating robotics education and workforce development.&lt;/p&gt;



&lt;p&gt;Delangue revealed that community feedback has already influenced product development. A colleague’s five-year-old daughter wanted to carry the robot around the house, leading to the development of the wireless version. “She started to want to take the Reachy Mini and bring it everywhere. That’s when the wires started to be a problem,” he explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-disruption-that-could-reshape-the-entire-robotics-industry"&gt;The disruption that could reshape the entire robotics industry&lt;/h2&gt;



&lt;p&gt;Hugging Face’s approach could fundamentally alter robotics industry dynamics. Traditional robotics companies invest heavily in proprietary technology, limiting innovation to internal teams. The open-source model could unlock distributed innovation across thousands of developers, potentially accelerating advancement while reducing costs.&lt;/p&gt;



&lt;p&gt;The strategy mirrors successful disruptions in other technology sectors. Linux challenged proprietary operating systems, Android democratized mobile development, and TensorFlow accelerated machine learning adoption. If successful, Hugging Face’s robotics platform could follow a similar trajectory.&lt;/p&gt;



&lt;p&gt;However, hardware presents unique challenges compared to software. Manufacturing quality control, supply chain management, and physical safety requirements create complexity that doesn’t exist in purely digital products. The company’s ability to manage these challenges while maintaining its open-source philosophy will determine the platform’s long-term success.&lt;/p&gt;



&lt;p&gt;Whether Reachy Mini succeeds or fails, its launch marks a pivotal moment in robotics development. For the first time, a major AI platform is betting that the future of robotics belongs not in corporate research labs, but in the hands of millions of individual developers armed with affordable, open-source tools. In an industry long dominated by secrecy and six-figure price tags, that might just be the most revolutionary idea of all.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Hugging Face, the $4.5 billion artificial intelligence platform that has become the GitHub of machine learning, announced Tuesday the launch of Reachy Mini, a $299 desktop robot designed to bring AI-powered robotics to millions of developers worldwide. The 11-inch humanoid companion represents the company’s boldest move yet to democratize robotics development and challenge the industry’s traditional closed-source, high-cost model.&lt;/p&gt;



&lt;p&gt;The announcement comes as Hugging Face crosses a significant milestone of 10 million AI builders using its platform, with CEO Clément Delangue revealing in an exclusive interview that “more and more of them are building in relation to robotics.” The compact robot, which can sit on any desk next to a laptop, addresses what Delangue calls a fundamental barrier in robotics development: accessibility.&lt;/p&gt;



&lt;p&gt;“One of the challenges with robotics is that you know you can’t just build on your laptop. You need to have some sort of robotics partner to help in your building, and most people won’t be able to buy $70,000 robots,” Delangue explained, referring to traditional industrial robotics systems and even newer humanoid robots like Tesla’s Optimus, which is expected to cost $20,000-$30,000.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-a-software-company-is-betting-big-on-physical-ai-robots"&gt;How a software company is betting big on physical AI robots&lt;/h2&gt;



&lt;p&gt;Reachy Mini emerges from Hugging Face’s April acquisition of French robotics startup Pollen Robotics, marking the company’s most significant hardware expansion since its founding. The robot represents the first consumer product to integrate natively with the Hugging Face Hub, allowing developers to access thousands of pre-built AI models and share robotics applications through the platform’s “Spaces” feature.&lt;/p&gt;



&lt;p&gt;The timing appears deliberate as the AI industry grapples with the next frontier: physical AI. While large language models have dominated the past two years, industry leaders increasingly believe that artificial intelligence will need physical embodiment to achieve human-level capabilities. Goldman Sachs projects the humanoid robotics market could reach $38 billion by 2035, while the World Economic Forum identifies robotics as a critical frontier technology for industrial operations.&lt;/p&gt;



&lt;p&gt;“We’re seeing more and more people moving to robotics, which is extremely exciting,” Delangue said. “The idea is to really become the desktop, open-source robot for AI builders.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-the-299-robot-that-could-democratize-ai-development"&gt;Inside the $299 robot that could democratize AI development&lt;/h2&gt;



&lt;p&gt;Reachy Mini packs sophisticated capabilities into its compact form factor. The robot features six degrees of freedom in its moving head, full body rotation, animated antennas, a wide-angle camera, multiple microphones, and a 5-watt speaker. The wireless version includes a Raspberry Pi 5 computer and battery, making it fully autonomous.&lt;/p&gt;



&lt;p&gt;The robot ships as a DIY kit and can be programmed in Python, with JavaScript and Scratch support planned. Pre-installed demonstration applications include face and hand tracking, smart companion features, and dancing moves. Developers can create and share new applications through Hugging Face’s Spaces platform, potentially creating what Delangue envisions as “thousands, tens of thousands, millions of apps.”&lt;/p&gt;



&lt;p&gt;This approach contrasts sharply with traditional robotics companies that typically release one product annually with limited customization options. “We want to have a model where we release tons of things,” Delangue explained. “Maybe we’ll release 100 prototypes a year. Out of this 100 prototypes, maybe we’ll assemble only 10 ourselves… and maybe fully assembled, fully packaged, fully integrated with all the software stack, maybe there’s going to be just a couple of them.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-open-source-hardware-might-be-the-future-of-robotics"&gt;Why open source hardware might be the future of robotics&lt;/h2&gt;



&lt;p&gt;The launch represents a fascinating test of whether open-source principles can translate successfully to hardware businesses. Hugging Face plans to release all hardware designs, software, and assembly instructions as open source, allowing anyone to build their own version. The company monetizes through convenience, selling pre-assembled units to developers who prefer to pay rather than build from scratch.&lt;/p&gt;



&lt;p&gt;“You try to share as much as possible to really empower the community,” Delangue explained. “There are people who, even if they have all the recipes open source to build their own Reachy Mini, would prefer to pay 300 bucks, 500 bucks, and get it already ready, or easy to assemble at home.”&lt;/p&gt;



&lt;p&gt;This freemium approach for hardware echoes successful software models but faces unique challenges. Manufacturing costs, supply chain complexity, and physical distribution create constraints that don’t exist in pure software businesses. However, Delangue argues this creates valuable feedback loops: “You learn from the open source community about what they want to build, how they want to build, and you can reintegrate it into what you sell.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-privacy-challenge-facing-ai-robots-in-your-home"&gt;The privacy challenge facing AI robots in your home&lt;/h2&gt;



&lt;p&gt;The move into robotics raises new questions about data privacy and security that don’t exist with purely digital AI systems. Robots equipped with cameras, microphones, and the ability to take physical actions in homes and workplaces create unprecedented privacy considerations.&lt;/p&gt;



&lt;p&gt;Delangue positions open source as the solution to these concerns. “One of my personal motivations to do open source robotics is that I think it’s going to fight concentration of power… the natural tendency of creating black box robots that users don’t really understand or really control,” he said. “The idea of ending up in a world where just a few companies are controlling millions of robots that are in people’s homes, being able to take action in real life, is quite scary.”&lt;/p&gt;



&lt;p&gt;The open-source approach allows users to inspect code, understand data flows, and potentially run AI models locally rather than relying on cloud services. For enterprise customers, Hugging Face’s existing enterprise platform could provide private deployment options for robotics applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-prototype-to-production-hugging-face-s-manufacturing-gamble"&gt;From prototype to production: Hugging Face’s manufacturing gamble&lt;/h2&gt;



&lt;p&gt;Hugging Face faces significant manufacturing and scaling challenges as it transitions from a software platform to a hardware company. The company plans to begin shipping Reachy Mini units as early as next month, starting with more DIY-oriented versions where customers complete final assembly.&lt;/p&gt;



&lt;p&gt;“The first versions, the first orders shipping will be a bit DIY, in the sense that we’ll split the weight of assembling with the user,” Delangue explained. “We’ll do some of the assembling ourselves, and then the user will be doing some of the assembling themselves too.”&lt;/p&gt;



&lt;p&gt;This approach aligns with the company’s goal of engaging the AI builder community in hands-on robotics development while managing manufacturing complexity. The strategy also reflects uncertainty about market demand for the new product category.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-taking-on-tesla-and-boston-dynamics-with-radical-transparency"&gt;Taking on Tesla and Boston Dynamics with radical transparency&lt;/h2&gt;



&lt;p&gt;Reachy Mini enters a rapidly evolving robotics landscape. Tesla’s Optimus program, Figure’s humanoid robots, and Boston Dynamics‘ commercial offerings represent the high-end of the market, while companies like Unitree have introduced more affordable humanoid robots at around $16,000.&lt;/p&gt;



&lt;p&gt;Hugging Face’s approach differs fundamentally from these competitors. Rather than creating a single, highly capable robot, the company is building an ecosystem of affordable, modular, open-source robotics components. Previous releases include the SO-101 robotic arm (starting at $100) and plans for the HopeJR humanoid robot (around $3,000).&lt;/p&gt;



&lt;p&gt;The strategy reflects broader trends in AI development, where open-source models from companies like Meta and smaller players have challenged closed-source leaders like OpenAI. In January, Chinese startup DeepSeek shocked the industry by releasing a powerful AI model developed at significantly lower cost than competing systems, demonstrating the potential for open-source approaches to disrupt established players.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-an-ecosystem-the-partnerships-powering-open-robotics"&gt;Building an ecosystem: The partnerships powering open robotics&lt;/h2&gt;



&lt;p&gt;Hugging Face’s robotics expansion benefits from strategic partnerships across the industry. The company collaborates with NVIDIA on robotics simulation and training through Isaac Lab, enabling developers to generate synthetic training data and test robot behaviors in virtual environments before deployment.&lt;/p&gt;



&lt;p&gt;The recent release of SmolVLA, a 450-million parameter vision-language-action model, demonstrates the technical foundation underlying Reachy Mini. The model is designed to be efficient enough to run on consumer hardware, including MacBooks, making sophisticated AI capabilities accessible to individual developers rather than requiring expensive cloud infrastructure.&lt;/p&gt;



&lt;p&gt;Physical Intelligence, a startup co-founded by UC Berkeley professor Sergey Levine, has made its Pi0 robot foundation model available through Hugging Face, creating opportunities for cross-pollination between different robotics approaches. “Making robotics more accessible increases the velocity with which technology advances,” Levine noted in previous statements about open-source robotics.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-a-299-robot-means-for-the-billion-dollar-ai-hardware-race"&gt;What a $299 robot means for the billion-dollar AI hardware race&lt;/h2&gt;



&lt;p&gt;The Reachy Mini launch signals Hugging Face’s ambition to become the dominant platform for AI development across all modalities, not just text and image generation. With robotics representing a potential $38 billion market by 2035, according to Goldman Sachs projections, early platform positioning could prove strategically valuable.&lt;/p&gt;



&lt;p&gt;Delangue envisions a future where hardware becomes an integral part of AI development workflows. “We see hardware as part of the AI builder building blocks,” he explained. “Always with our approach of being open, being community driven, integrating everything with as many community members, as many other organizations as possible.”&lt;/p&gt;



&lt;p&gt;The company’s financial position provides flexibility to experiment with hardware business models. As a profitable company with significant funding, Hugging Face can afford to prioritize market development over immediate revenue optimization. Delangue mentioned potential subscription models where Hugging Face platform access could include hardware components, similar to how some software companies bundle services.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-affordable-robots-could-transform-education-and-research"&gt;How affordable robots could transform education and research&lt;/h2&gt;



&lt;p&gt;Beyond commercial applications, Reachy Mini could significantly impact robotics education and research. At $299, the robot costs less than many smartphones while providing full programmability and AI integration. Universities, coding bootcamps, and individual learners could use the platform to explore robotics concepts without requiring expensive laboratory equipment.&lt;/p&gt;



&lt;p&gt;The open-source nature enables educational institutions to modify hardware and software to suit specific curricula. Students could progress from basic programming exercises to sophisticated AI applications using the same platform, potentially accelerating robotics education and workforce development.&lt;/p&gt;



&lt;p&gt;Delangue revealed that community feedback has already influenced product development. A colleague’s five-year-old daughter wanted to carry the robot around the house, leading to the development of the wireless version. “She started to want to take the Reachy Mini and bring it everywhere. That’s when the wires started to be a problem,” he explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-disruption-that-could-reshape-the-entire-robotics-industry"&gt;The disruption that could reshape the entire robotics industry&lt;/h2&gt;



&lt;p&gt;Hugging Face’s approach could fundamentally alter robotics industry dynamics. Traditional robotics companies invest heavily in proprietary technology, limiting innovation to internal teams. The open-source model could unlock distributed innovation across thousands of developers, potentially accelerating advancement while reducing costs.&lt;/p&gt;



&lt;p&gt;The strategy mirrors successful disruptions in other technology sectors. Linux challenged proprietary operating systems, Android democratized mobile development, and TensorFlow accelerated machine learning adoption. If successful, Hugging Face’s robotics platform could follow a similar trajectory.&lt;/p&gt;



&lt;p&gt;However, hardware presents unique challenges compared to software. Manufacturing quality control, supply chain management, and physical safety requirements create complexity that doesn’t exist in purely digital products. The company’s ability to manage these challenges while maintaining its open-source philosophy will determine the platform’s long-term success.&lt;/p&gt;



&lt;p&gt;Whether Reachy Mini succeeds or fails, its launch marks a pivotal moment in robotics development. For the first time, a major AI platform is betting that the future of robotics belongs not in corporate research labs, but in the hands of millions of individual developers armed with affordable, open-source tools. In an industry long dominated by secrecy and six-figure price tags, that might just be the most revolutionary idea of all.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/hugging-face-just-launched-a-299-robot-that-could-disrupt-the-entire-robotics-industry/</guid><pubDate>Wed, 09 Jul 2025 07:00:00 +0000</pubDate></item><item><title>[NEW] Hugging Face opens up orders for its Reachy Mini desktop robots (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/hugging-face-opens-up-orders-for-its-reachy-mini-desktop-robots/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/REACHY-MINI-3.jpg?resize=1200,798" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hugging Face is ready for developers to start tinkering and testing its latest robotics release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI development platform announced Wednesday that it’s now accepting orders for its Reachy Mini desktop robots. The company initially unveiled the prototypes of these devices back in May, alongside a larger humanoid robot named HopeJR.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hugging Face said it plans to release two versions of the Reachy Mini. The first, called the Reachy Mini Wireless, is wireless and costs $449 and runs on a Raspberry 5 mini computer. The second version is the Reachy Mini Lite, which needs to be connected to a computing source ,but is cheaper at $299.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The open source robots come in a kit for developers to build themselves. The Reachy Minis are about the size of a standard stuffed animal and come with two screens for eyes and two antennas. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once built, these robots are fully programmable in Python. These devices also come with a set of pre-installed demos and are integrated with the Hugging Face Hub, the company’s open source machine learning platform, which gives users access to more than 1.7 million AI models and more than 400,000 datasets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clém Delangue, the CEO of Hugging Face, told TechCrunch they decided to launch two versions of the Reachy Mini based on initial feedback on the company’s original prototype. An early tester found that their five-year-old daughter wanted to be able to take the desktop robot around the house with her. The company figured she wouldn’t be the only one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The goal in the future is to keep carefully getting a lot of feedback like that from users, from the community, that’s how we’ve always been building products at Hugging Face as an open source community platform,” Delangue said. “By the nature of it being open source, it means that people will be able to extend it, modify it, change everything they want.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The target audience for these devices is AI developers, Delangue said. The Reachy Minis allow users to code, build, and test AI applications on the desktop robot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anyone will be able to build their own specific features and apps for Reachy Mini that then they’ll be able to share with the community,” Delangue said. “So we hope that it’s really going to unleash the creativity of builders to build, you know, millions of different applications, millions of different features that they can share with the community, so that anyone can then, like, plug and play with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Reachy Mini Lite should start shipping next month, with the wireless version shipping later this year. Delangue said it was important for the company to start shipping shortly after orders, as opposed to doing a long pre-order process with an unclear timeline, because they want to get the robots in users’ hands as fast as possible.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Delangue added this release is really in line with what Hugging Face is targeting for its robotics program in general — open source hardware that gives users complete control.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I feel like it’s really important for the future of robotics to be open source, instead of being closed source, black box, [and] concentrated in the hands of a few companies,” Delangue said. “I think it’s quite a scary world to have like millions of robots in people’s home controlled by one company, with customers, users, not really being able to control them, understand them. I would much rather live in a place, or in a world, or in a country, where everyone can have some control over the robots.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/REACHY-MINI-3.jpg?resize=1200,798" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hugging Face is ready for developers to start tinkering and testing its latest robotics release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI development platform announced Wednesday that it’s now accepting orders for its Reachy Mini desktop robots. The company initially unveiled the prototypes of these devices back in May, alongside a larger humanoid robot named HopeJR.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hugging Face said it plans to release two versions of the Reachy Mini. The first, called the Reachy Mini Wireless, is wireless and costs $449 and runs on a Raspberry 5 mini computer. The second version is the Reachy Mini Lite, which needs to be connected to a computing source ,but is cheaper at $299.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The open source robots come in a kit for developers to build themselves. The Reachy Minis are about the size of a standard stuffed animal and come with two screens for eyes and two antennas. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once built, these robots are fully programmable in Python. These devices also come with a set of pre-installed demos and are integrated with the Hugging Face Hub, the company’s open source machine learning platform, which gives users access to more than 1.7 million AI models and more than 400,000 datasets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clém Delangue, the CEO of Hugging Face, told TechCrunch they decided to launch two versions of the Reachy Mini based on initial feedback on the company’s original prototype. An early tester found that their five-year-old daughter wanted to be able to take the desktop robot around the house with her. The company figured she wouldn’t be the only one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The goal in the future is to keep carefully getting a lot of feedback like that from users, from the community, that’s how we’ve always been building products at Hugging Face as an open source community platform,” Delangue said. “By the nature of it being open source, it means that people will be able to extend it, modify it, change everything they want.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The target audience for these devices is AI developers, Delangue said. The Reachy Minis allow users to code, build, and test AI applications on the desktop robot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anyone will be able to build their own specific features and apps for Reachy Mini that then they’ll be able to share with the community,” Delangue said. “So we hope that it’s really going to unleash the creativity of builders to build, you know, millions of different applications, millions of different features that they can share with the community, so that anyone can then, like, plug and play with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Reachy Mini Lite should start shipping next month, with the wireless version shipping later this year. Delangue said it was important for the company to start shipping shortly after orders, as opposed to doing a long pre-order process with an unclear timeline, because they want to get the robots in users’ hands as fast as possible.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Delangue added this release is really in line with what Hugging Face is targeting for its robotics program in general — open source hardware that gives users complete control.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I feel like it’s really important for the future of robotics to be open source, instead of being closed source, black box, [and] concentrated in the hands of a few companies,” Delangue said. “I think it’s quite a scary world to have like millions of robots in people’s home controlled by one company, with customers, users, not really being able to control them, understand them. I would much rather live in a place, or in a world, or in a country, where everyone can have some control over the robots.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/hugging-face-opens-up-orders-for-its-reachy-mini-desktop-robots/</guid><pubDate>Wed, 09 Jul 2025 07:00:00 +0000</pubDate></item><item><title>[NEW] Inside OpenAI’s empire: A conversation with Karen Hao (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/09/1119784/inside-openais-empire-a-conversation-with-karen-hao/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Hello, everyone, and welcome to this special edition of Roundtables. These are our subscriber-only events where you get to listen in to conversations between editors and reporters. Now, I’m delighted to say we’ve got an absolute cracker of an event today. I’m very happy to have our prodigal daughter, Karen Hao, a fabulous AI journalist, here with us to talk about her new book. Hello, Karen, how are you doing?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Good. Thank you so much for having me back, Niall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Lovely to have you. So I’m sure you all know Karen and that’s why you’re here. But to give you a quick, quick synopsis, Karen has a degree in mechanical engineering from MIT. She was &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior editor for AI and has won countless awards, been cited in Congress, written for the &lt;em&gt;Wall Street Journal&lt;/em&gt; and &lt;em&gt;The Atlantic,&lt;/em&gt; and set up a series at the Pulitzer Center to teach journalists how to cover AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But most important of all, she’s here to discuss her new book, which I’ve got a copy of here, &lt;em&gt;Empire of AI.&lt;/em&gt; The UK version is subtitled “Inside the reckless race for total domination,” and the US one, I believe, is “Dreams and nightmares in Sam Altman’s OpenAI.”&lt;/p&gt; 
 &lt;p&gt;It’s been an absolute sensation, a &lt;em&gt;New York Times&lt;/em&gt; chart topper. An incredible feat of reporting—like 300 interviews, including 90 with people inside OpenAI. And it’s a brilliant look at not just OpenAI’s rise, and the character of Sam Altman, which is very interesting in its own right, but also a really astute look at what kind of AI we’re building and who holds the keys.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Karen, the core of the book, the rise and rise of OpenAI, was one of your first big features at &lt;em&gt;MIT Technology Review&lt;/em&gt;&lt;em&gt;.&lt;/em&gt; It’s a brilliant story that lifted the lid for the first time on what was going on at OpenAI … and they really hated it, right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yes, and first of all, thank you to everyone for being here. It’s always great to be home. I do still consider &lt;em&gt;MIT Tech Review&lt;/em&gt; to be my journalistic home, and that story was—I only did it because Niall assigned it after I said, “Hey, it seems like OpenAI is kind of an interesting thing,” and he was like, you should profile them. And I had never written a profile about a company before, and I didn’t think that I would have it in me, and Niall believed that I would be able to do it. So it really didn’t happen other than because of you.&lt;/p&gt;  &lt;p&gt;I went into the piece with an open mind about—let me understand what OpenAI is. Let me take what they say at face value. They were founded as a nonprofit. They have this mission to ensure artificial general intelligence benefits all of humanity. What do they mean by that? How are they trying to achieve that ultimately? How are they striking this balance between mission-driven AI development and the need to raise money and capital?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;And through the course of embedding within the company for three days, and then interviewing dozens of people outside the company or around the company … I came to realize that there was a fundamental disconnect between what they were publicly espousing and accumulating a lot of goodwill from and how they were operating. And that is what I ended up focusing my profile on, and that is why they were not very pleased.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And how have you seen OpenAI change even since you did the profile? That sort of misalignment feels like it’s got messier and more confusing in the years since.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Absolutely. I mean, it’s kind of remarkable that OpenAI, you could argue that they are now one of the most capitalistic corporations in Silicon Valley. They just raised $40 billion, in the largest-ever private fundraising round in tech industry history. They’re valued at $300 billion. And yet they still say that they are first and foremost a nonprofit.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I think this really gets to the heart of how much OpenAI has tried to position and reposition itself throughout its decade-long history, to ultimately play into the narratives that they think are going to do best with the public and with policymakers, in spite of what they might actually be doing in terms of developing their technologies and commercializing them.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; You cite Sam Altman saying, you know, the race for AGI is what motivated a lot of this, and I’ll come back to that a bit before the end. But he talks about it as like the Manhattan Project for AI. You cite him quoting Oppenheimer (of course, you know, there’s no self-aggrandizing there): “Technology happens because it’s possible,” he says in the book.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And it feels to me like this is one of the themes of the book: the idea that technology doesn’t just happen because it comes along. It comes because of choices that people make. It’s not an inevitability that things are the way they are and that people are who they are. What they think is important—that influences the direction of travel. So what does this mean, in practice, if that’s the case?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;With OpenAI in particular, they made a very key decision early on in their history that led to all of the AI technologies that we see dominating the marketplace and dominating headlines today. And that was a decision to try and advance AI progress through scaling the existing techniques that were available to them. At the time when OpenAI started, at the end of 2015, and then, when they made that decision, in roughly around 2017, this was a very unpopular perspective within the broader AI research field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There were kind of two competing ideas about how to advance AI progress, or rather a spectrum of ideas, bookended by two extremes. One extreme being, we have all the techniques we need, and we should just aggressively scale. And the other one being that we don’t actually have the techniques we need. We need to continue innovating and doing fundamental AI research to get more breakthroughs. And largely the field assumed that this side of the spectrum [focusing on fundamental AI research] was the most likely approach for getting advancements, but OpenAI was anomalously committed to the other extreme—this idea that we can just take neural networks and pump ever more data, and train on ever larger supercomputers, larger than have ever been built in history.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The reason why they made that decision was because they were competing against Google, which had a dominant monopoly on AI talent. And OpenAI knew that they didn’t necessarily have the ability to beat Google simply by trying to get research breakthroughs. That’s a very hard path. When you’re doing fundamental research, you never really know when the breakthrough might appear. It’s not a very linear line of progress, but scaling is sort of linear. As long as you just pump more data and more compute, you can get gains. And so they thought, we can just do this faster than anyone else. And that’s the way that we’re going to leap ahead of Google. And it particularly aligned with Sam Altman’s skillset, as well, because he is a once-in-a-generation fundraising talent, and when you’re going for scale to advance AI models, the primary bottleneck is capital.&lt;/p&gt;  &lt;p&gt;And so it was kind of a great fit for what he had to offer, which is, he knows how to accumulate capital, and he knows how to accumulate it very quickly. So that is ultimately how you can see that technology is a product of human choices and human perspectives. And they’re the specific skills and strengths that that team had at the time for how they wanted to move forward.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And to be fair, I mean, it works, right? It was amazing, fabulous. You know the breakthroughs that happened, GPT-2 to GPT-3, just from scale and data and compute, kind of were mind-blowing really, as we look back on it now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, it is remarkable how much it did work, because there was a lot of skepticism about the idea that scale could lead to the kind of technical progress that we’ve seen. But one of my biggest critiques of this particular approach is that there’s also an extraordinary amount of costs that come with this particular pathway to getting more advancements. And there are many different pathways to advancing AI, so we could have actually gotten all of these benefits, and moving forward, we could continue to get more benefits from AI, without actually engaging in a hugely consumptive, hugely costly approach to its development.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, so in terms of consumptive, that’s something we’ve touched on here quite recently at MIT Technology Review, like the energy costs of AI. The data center costs are absolutely extraordinary, right? Like the data behind it is incredible. And it’s only gonna get worse in the next few years if we continue down this path, right?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah … so first of all, everyone should read the series that &lt;em&gt;Tech Review&lt;/em&gt; put out, if you haven’t already, on the energy question, because it really does break down everything from what is the energy consumption of the smallest unit of interacting with these models, all the way up until the highest level.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The number that I have seen a lot, and that I’ve been repeating, is there was a McKinsey report that was looking at if we continue to just look at the pace at which data centers and supercomputers are being built and scaled, in the next five years, we would have to add two to six times the amount of energy consumed by California onto the grid. And most of that will have to be serviced by fossil fuels, because these data centers and supercomputers have to run 24/7, so we cannot rely solely on renewable energy. We do not have enough nuclear power capacity to power these colossal pieces of infrastructure. And so we’re already accelerating the climate crisis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And we’re also accelerating a public-health crisis, the pumping of thousands of tons of air pollutants into the air from coal plants that are having their lives extended and methane gas turbines that are being built in service of powering these data centers. And in addition to that, there’s also an acceleration of the freshwater crisis, because these pieces of infrastructure have to be cooled with freshwater resources. It has to be fresh water, because if it’s any other type of water, it corrodes the equipment, it leads to bacterial growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;And Bloomberg recently had a story that showed that two-thirds of these data centers are actually going into water-scarce areas, into places where the communities already do not have enough fresh water at their disposal. So that is one dimension of many that I refer to when I say, the extraordinary costs of this particular pathway for AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; So in terms of costs and the extractive process of making AI, I wanted to give you the chance to talk about the other theme of the book, apart from just OpenAI’s explosion. It’s the colonial way of looking at the way AI is made: the empire. I’m saying this obviously because we’re here, but this is an idea that came out of reporting you started at &lt;em&gt;MIT Technology Review&lt;/em&gt; and then continued into the book. Tell us about how this framing helps us understand how AI is made now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, so this was a framing that I started thinking a lot about when I was working on the AI Colonialism series for &lt;em&gt;Tech Review.&lt;/em&gt; It was a series of stories that looked at the way that, pre-ChatGPT, the commercialization of AI and its deployment into the world was already leading to entrenchment of historical inequities into the present day.&lt;/p&gt;  &lt;p&gt;And one example was a story that was about how facial recognition companies were swarming into South Africa to try and harvest more data from South Africa during a time when they were getting criticized for the fact that their technologies did not accurately recognize black faces. And the deployment of those facial recognition technologies into South Africa, into the streets of Johannesburg, was leading to what South African scholars were calling a recreation of a digital apartheid—the controlling of black bodies, movement of black people.&lt;/p&gt; 
 &lt;p&gt;And this idea really haunted me for a really long time. Through my reporting in that series, there were so many examples that I kept hitting upon of this thesis, that the AI industry was perpetuating. It felt like it was becoming this neocolonial force. And then, when ChatGPT came out, it became clear that this was just accelerating.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When you accelerate the scale of these technologies, and you start training them on the entirety of the Internet, and you start using these supercomputers that are the size of dozens—if not hundreds—of football fields. Then you really start talking about an extraordinary global level of extraction and exploitation that is happening to produce these technologies. And then the historical power imbalances become even more obvious.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;And so there are four parallels that I draw in my book between what I have now termed empires of AI versus empires of old. The first one is that empires lay claim to resources that are not their own. So these companies are scraping all this data that is not their own, taking all the intellectual property that is not their own.&lt;/p&gt;  &lt;p&gt;The second is that empires exploit a lot of labor. So we see them moving to countries in the Global South or other economically vulnerable communities to contract workers to do some of the worst work in the development pipeline for producing these technologies—and also producing technologies that then inherently are labor-automating and engage in labor exploitation in and of themselves.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And the third feature is that the empires monopolize knowledge production. So, in the last 10 years, we’ve seen the AI industry monopolize more and more of the AI researchers in the world. So AI researchers are no longer contributing to open science, working in universities or independent institutions, and the effect on the research is what you would imagine would happen if most of the climate scientists in the world were being bankrolled by oil and gas companies. You would not be getting a clear picture, and we are not getting a clear picture, of the limitations of these technologies, or if there are better ways to develop these technologies.&lt;/p&gt;  &lt;p&gt;And the fourth and final feature is that empires always engage in this aggressive race rhetoric, where there are good empires and evil empires. And they, the good empire, have to be strong enough to beat back the evil empire, and that is why they should have unfettered license to consume all of these resources and exploit all of this labor. And if the evil empire gets the technology first, humanity goes to hell. But if the good empire gets the technology first, they’ll civilize the world, and humanity gets to go to heaven. So on many different levels, like the empire theme, I felt like it was the most comprehensive way to name exactly how these companies operate, and exactly what their impacts are on the world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, brilliant. I mean, you talk about the evil empire. What happens if the evil empire gets it first? And what I mentioned at the top is AGI. For me, it’s almost like the extra character in the book all the way through. It’s sort of looming over everything, like the ghost at the feast, sort of saying like, this is the thing that motivates everything at OpenAI. This is the thing we’ve got to get to before anyone else gets to it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There’s a bit in the book about how they’re talking internally at OpenAI, like, we’ve got to make sure that AGI is in US hands where it’s safe versus like anywhere else. And some of the international staff are openly like—that’s kind of a weird way to frame it, isn’t it? Why is the US version of AGI better than others?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So tell us a bit about how it drives what they do. And AGI isn’t an inevitable fact that’s just happening anyway, is it? It’s not even a thing yet.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;There’s not even consensus around whether or not it’s even possible or what it even is. There was recently a &lt;em&gt;New York Times&lt;/em&gt; story by Cade Metz that was citing a survey of long-standing AI researchers in the field, and 75% of them still think that we don’t have the techniques yet for reaching AGI, whatever that means. And the most classic definition or understanding of what AGI is, is being able to fully recreate human intelligence in software. But the problem is, we also don’t have scientific consensus around what human intelligence is. And so one of the aspects that I talk about a lot in the book is that, when there is a vacuum of shared meaning around this term, and what it would look like, when would we have arrived at it? What capabilities should we be evaluating these systems on to determine that we’ve gotten there? It can basically just be whatever OpenAI wants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So it’s kind of just this ever-present goalpost that keeps shifting, depending on where the company wants to go. You know, they have a full range, a variety of different definitions that they’ve used throughout the years. In fact, they even have a joke internally: If you ask 13 OpenAI researchers what AGI is, you’ll get 15 definitions. So they are kind of self-aware that this is not really a real term and it doesn’t really have that much meaning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it does serve this purpose of creating a kind of quasi-religious fervor around what they’re doing, where people think that they have to keep driving towards this horizon, and that one day when they get there, it’s going to have a civilizationally transformative impact. And therefore, what else should you be working on in your life, but this? And who else should be working on it, but you?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;And so it is their justification not just for continuing to push and scale and consume all these resources—because none of that consumption, none of that harm matters anymore if you end up hitting this destination. But they also use it as a way to develop their technologies in a very deeply anti-democratic way, where they say, we are the only people that have the expertise, that have the right to carefully control the development of this technology and usher it into the world. And we cannot let anyone else participate because it’s just too powerful of a technology.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;You talk about the factions, particularly the religious framing. AGI has been around as a concept for a while—it was very niche, very kind of nerdy fun, really, to talk about—to suddenly become extremely mainstream. And they have the boomers versus doomers dichotomy. Where are you on that spectrum?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;So the boomers are people who think that AGI is going to bring us to utopia, and the doomers think AGI is going to devastate all of humanity. And to me these are actually two sides of the same coin. They both believe that AGI is possible, and it’s imminent, and it’s going to change everything.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And I am not on this spectrum. I’m in a third space, which is the AI accountability space, which is rooted in the observation that these companies have accumulated an extraordinary amount of power, both economic and political power, to go back to the empire analogy.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the thing that we need to do in order to not return to an age of empire and erode a lot of democratic norms is to hold these companies accountable with all the tools at our disposal, and to recognize all the harms that they are already perpetuating through a misguided approach to AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;I’ve got a couple of questions from readers. I’m gonna try to pull them together a little bit because Abbas asks, what would post-imperial AI look like? And there was a question from Liam basically along the same lines. How do you make a more ethical version of AI that is not within this framework?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;We sort of already touched a little bit upon this idea. But there are so many different ways to develop AI. There are myriads of techniques throughout the history of AI development, which is decades long. There have been various shifts in the winds of which techniques ultimately rise and fall. And it isn’t based solely on the scientific or technical merit of any particular technique. Oftentimes certain techniques become more popular because of business reasons or because of the funder’s ideologies. And that’s sort of what we’re seeing today with the complete indexing of AI development on large-scale AI model development.&lt;/p&gt;  &lt;p&gt;And ultimately, these large-scale models … We talked about how it’s a remarkable technical leap, but in terms of social progress or economic progress, the benefits of these models have been kind of middling. And the way that I see us shifting to AI models that are going to be A) more beneficial and B) not so imperial is to refocus on task-specific AI systems that are tackling well-scoped challenges that inherently lend themselves to the strengths of AI systems that are inherently computational optimization problems.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;So I’m talking about things like using AI to integrate more renewable energy into the grid. This is something that we definitely need. We need to more quickly accelerate our electrification of the grid, and one of the challenges of using more renewable energy is the unpredictability of it. And this is a key strength of AI technologies, being able to have predictive capabilities and optimization capabilities where you can match the energy generation of different renewables with the energy demands of different people that are drawing from the grid.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Quite a few people have been asking, in the chat, different versions of the same question. If you were an early-career AI scientist, or if you were involved in AI, what can you do yourself to bring about a more ethical version of AI? Do you have any power left, or is it too late?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;No, I don’t think it’s too late at all. I mean, as I’ve been talking with a lot of people just in the lay public, one of the biggest challenges that they have is they don’t have any alternatives for AI. They want the benefits of AI, but they also do not want to participate in a supply chain that is really harmful. And so the first question is, always, is there an alternative? Which tools do I shift to? And unfortunately, there just aren’t that many alternatives right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And so the first thing that I would say to early-career AI researchers and entrepreneurs is to build those alternatives, because there are plenty of people that are actually really excited about the possibility of switching to more ethical alternatives. And one of the analogies I often use is that we kind of need to do with the AI industry what happened with the fashion industry. There was also a lot of environmental exploitation, labor exploitation in the fashion industry, and there was enough consumer demand that it created new markets for ethical and sustainably sourced fashion. And so we kind of need to see just more options occupying that space.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Do you feel optimistic about the future? Or where do you sit? You know, things aren’t great as you spell them out now. Where’s the hope for us?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; I am. I’m super optimistic. Part of the reason why I’m optimistic is because you know, a few years ago, when I started writing about AI at &lt;em&gt;Tech Review,&lt;/em&gt; I remember people would say, wow, that’s a really niche beat. Do you have enough to write about?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And now, I mean, everyone is talking about AI, and I think that’s the first step to actually getting to a better place with AI development. The amount of public awareness and attention and scrutiny that is now going into how we develop these technologies, how we use these technologies, is really, really important. Like, we need to be having this public debate and that in and of itself is a significant step change from what we had before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the next step, and part of the reason why I wrote this book, is we need to convert the awareness into action, and people should take an active role. Every single person should feel that they have an active role in shaping the future of AI development, if you think about all of the different ways that you interface with the AI development supply chain and deployment supply chain—like you give your data or withhold your data.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;There are probably data centers that are being built around you right now. If you’re a parent, there’s some kind of AI policy being crafted at [your kid’s] school. There’s some kind of AI policy being crafted at your workplace. These are all what I consider sites of democratic contestation, where you can use those opportunities to assert your voice about how you want AI to be developed and deployed. If you do not want these companies to use certain kinds of data, push back when they just take the data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I closed all of my personal social media accounts because I just did not like the fact that they were scraping my personal photos to train their generative AI models. I’ve seen parents and students and teachers start forming committees within schools to talk about what their AI policy should be and to draft it collectively as a community. Same with businesses. They’re doing the same thing. If we all kind of step up to play that active role, I am super optimistic that we’ll get to a better place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Mark, in the chat, mentions the Māori story from New Zealand towards the end of your book, and that’s an example of sort of community-led AI in action, isn’t it?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah. There was a community in New Zealand that really wanted to help revitalize the Māori language by building a speech recognition tool that could recognize Māori, and therefore be able to transcribe a rich repository of archival audio of their ancestors speaking Māori. And the first thing that they did when engaging in that project was they asked the community, do you want this AI tool?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Imagine that.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;I know! It’s such a radical concept, this idea of consent at every stage. But they first asked that; the community wholeheartedly said yes. They then engaged in a public education campaign to explain to people, okay, what does it take to develop an AI tool? Well, we are going to need data. We’re going to need audio transcription pairs to train this AI model. So then they ran a public contest in which they were able to get dozens, if not hundreds, of people in their community to donate data to this project. And then they made sure that when they developed the model, they actively explained to the community at every step how their data was being used, how it would be stored, how it would continue to be protected. And any other project that would use the data has to get permission and consent from the community first.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;And so it was a completely democratic process, for whether they wanted the tool, how to develop the tool, and how the tool should continue to be used, and how their data should continue to be used over time.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Great. I know we’ve gone a bit over time. I’ve got two more things I’m going to ask you, basically putting together lots of questions people have asked in the chat about your view on what role regulations should play. What are your thoughts on that?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah, I mean, in an ideal world where we actually had a functioning government, regulation should absolutely play a huge role. And it shouldn’t just be thinking about once an AI model is built, how to regulate that. But still thinking about the full supply chain of AI development, regulating the data and what’s allowed to be trained in these models, regulating the land use. And what pieces of land are allowed to build data centers? How much energy and water are the data centers allowed to consume? And also regulating the transparency. We don’t know what data is in these training data sets, and we don’t know the environmental costs of training these models. We don’t know how much water these data centers consume and that is all information that these companies actively withhold to prevent democratic processes from happening. So if there were one major intervention that regulators could have, it should be to dramatically increase the amount of transparency along the supply chain.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Okay, great. So just to bring it back around to OpenAI and Sam Altman to finish with. He famously sent an email around, didn’t he? After your original &lt;em&gt;Tech Review&lt;/em&gt; story, saying this is not great. We don’t like this. And he didn’t want to speak to you for your book, either, did he?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; No, he did not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;No. But imagine Sam Altman is in the chat here. He’s subscribed to &lt;em&gt;Technology Review&lt;/em&gt; and is watching this Roundtables because he wants to know what you’re saying about him. If you could talk to him directly, what would you like to ask him?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; What degree of harm do you need to see in order to realize that you should take a different path?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Nice, blunt, to the point. All right, Karen, thank you so much for your time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Thank you so much, everyone.&lt;/p&gt;  &lt;p&gt;MIT Technology Review Roundtables is a subscriber-only online event series where experts discuss the latest developments and what’s next in emerging technologies. Sign up to get notified about upcoming sessions.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Hello, everyone, and welcome to this special edition of Roundtables. These are our subscriber-only events where you get to listen in to conversations between editors and reporters. Now, I’m delighted to say we’ve got an absolute cracker of an event today. I’m very happy to have our prodigal daughter, Karen Hao, a fabulous AI journalist, here with us to talk about her new book. Hello, Karen, how are you doing?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Good. Thank you so much for having me back, Niall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Lovely to have you. So I’m sure you all know Karen and that’s why you’re here. But to give you a quick, quick synopsis, Karen has a degree in mechanical engineering from MIT. She was &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior editor for AI and has won countless awards, been cited in Congress, written for the &lt;em&gt;Wall Street Journal&lt;/em&gt; and &lt;em&gt;The Atlantic,&lt;/em&gt; and set up a series at the Pulitzer Center to teach journalists how to cover AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But most important of all, she’s here to discuss her new book, which I’ve got a copy of here, &lt;em&gt;Empire of AI.&lt;/em&gt; The UK version is subtitled “Inside the reckless race for total domination,” and the US one, I believe, is “Dreams and nightmares in Sam Altman’s OpenAI.”&lt;/p&gt; 
 &lt;p&gt;It’s been an absolute sensation, a &lt;em&gt;New York Times&lt;/em&gt; chart topper. An incredible feat of reporting—like 300 interviews, including 90 with people inside OpenAI. And it’s a brilliant look at not just OpenAI’s rise, and the character of Sam Altman, which is very interesting in its own right, but also a really astute look at what kind of AI we’re building and who holds the keys.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Karen, the core of the book, the rise and rise of OpenAI, was one of your first big features at &lt;em&gt;MIT Technology Review&lt;/em&gt;&lt;em&gt;.&lt;/em&gt; It’s a brilliant story that lifted the lid for the first time on what was going on at OpenAI … and they really hated it, right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yes, and first of all, thank you to everyone for being here. It’s always great to be home. I do still consider &lt;em&gt;MIT Tech Review&lt;/em&gt; to be my journalistic home, and that story was—I only did it because Niall assigned it after I said, “Hey, it seems like OpenAI is kind of an interesting thing,” and he was like, you should profile them. And I had never written a profile about a company before, and I didn’t think that I would have it in me, and Niall believed that I would be able to do it. So it really didn’t happen other than because of you.&lt;/p&gt;  &lt;p&gt;I went into the piece with an open mind about—let me understand what OpenAI is. Let me take what they say at face value. They were founded as a nonprofit. They have this mission to ensure artificial general intelligence benefits all of humanity. What do they mean by that? How are they trying to achieve that ultimately? How are they striking this balance between mission-driven AI development and the need to raise money and capital?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;And through the course of embedding within the company for three days, and then interviewing dozens of people outside the company or around the company … I came to realize that there was a fundamental disconnect between what they were publicly espousing and accumulating a lot of goodwill from and how they were operating. And that is what I ended up focusing my profile on, and that is why they were not very pleased.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And how have you seen OpenAI change even since you did the profile? That sort of misalignment feels like it’s got messier and more confusing in the years since.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Absolutely. I mean, it’s kind of remarkable that OpenAI, you could argue that they are now one of the most capitalistic corporations in Silicon Valley. They just raised $40 billion, in the largest-ever private fundraising round in tech industry history. They’re valued at $300 billion. And yet they still say that they are first and foremost a nonprofit.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I think this really gets to the heart of how much OpenAI has tried to position and reposition itself throughout its decade-long history, to ultimately play into the narratives that they think are going to do best with the public and with policymakers, in spite of what they might actually be doing in terms of developing their technologies and commercializing them.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; You cite Sam Altman saying, you know, the race for AGI is what motivated a lot of this, and I’ll come back to that a bit before the end. But he talks about it as like the Manhattan Project for AI. You cite him quoting Oppenheimer (of course, you know, there’s no self-aggrandizing there): “Technology happens because it’s possible,” he says in the book.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And it feels to me like this is one of the themes of the book: the idea that technology doesn’t just happen because it comes along. It comes because of choices that people make. It’s not an inevitability that things are the way they are and that people are who they are. What they think is important—that influences the direction of travel. So what does this mean, in practice, if that’s the case?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;With OpenAI in particular, they made a very key decision early on in their history that led to all of the AI technologies that we see dominating the marketplace and dominating headlines today. And that was a decision to try and advance AI progress through scaling the existing techniques that were available to them. At the time when OpenAI started, at the end of 2015, and then, when they made that decision, in roughly around 2017, this was a very unpopular perspective within the broader AI research field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There were kind of two competing ideas about how to advance AI progress, or rather a spectrum of ideas, bookended by two extremes. One extreme being, we have all the techniques we need, and we should just aggressively scale. And the other one being that we don’t actually have the techniques we need. We need to continue innovating and doing fundamental AI research to get more breakthroughs. And largely the field assumed that this side of the spectrum [focusing on fundamental AI research] was the most likely approach for getting advancements, but OpenAI was anomalously committed to the other extreme—this idea that we can just take neural networks and pump ever more data, and train on ever larger supercomputers, larger than have ever been built in history.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The reason why they made that decision was because they were competing against Google, which had a dominant monopoly on AI talent. And OpenAI knew that they didn’t necessarily have the ability to beat Google simply by trying to get research breakthroughs. That’s a very hard path. When you’re doing fundamental research, you never really know when the breakthrough might appear. It’s not a very linear line of progress, but scaling is sort of linear. As long as you just pump more data and more compute, you can get gains. And so they thought, we can just do this faster than anyone else. And that’s the way that we’re going to leap ahead of Google. And it particularly aligned with Sam Altman’s skillset, as well, because he is a once-in-a-generation fundraising talent, and when you’re going for scale to advance AI models, the primary bottleneck is capital.&lt;/p&gt;  &lt;p&gt;And so it was kind of a great fit for what he had to offer, which is, he knows how to accumulate capital, and he knows how to accumulate it very quickly. So that is ultimately how you can see that technology is a product of human choices and human perspectives. And they’re the specific skills and strengths that that team had at the time for how they wanted to move forward.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And to be fair, I mean, it works, right? It was amazing, fabulous. You know the breakthroughs that happened, GPT-2 to GPT-3, just from scale and data and compute, kind of were mind-blowing really, as we look back on it now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, it is remarkable how much it did work, because there was a lot of skepticism about the idea that scale could lead to the kind of technical progress that we’ve seen. But one of my biggest critiques of this particular approach is that there’s also an extraordinary amount of costs that come with this particular pathway to getting more advancements. And there are many different pathways to advancing AI, so we could have actually gotten all of these benefits, and moving forward, we could continue to get more benefits from AI, without actually engaging in a hugely consumptive, hugely costly approach to its development.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, so in terms of consumptive, that’s something we’ve touched on here quite recently at MIT Technology Review, like the energy costs of AI. The data center costs are absolutely extraordinary, right? Like the data behind it is incredible. And it’s only gonna get worse in the next few years if we continue down this path, right?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah … so first of all, everyone should read the series that &lt;em&gt;Tech Review&lt;/em&gt; put out, if you haven’t already, on the energy question, because it really does break down everything from what is the energy consumption of the smallest unit of interacting with these models, all the way up until the highest level.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The number that I have seen a lot, and that I’ve been repeating, is there was a McKinsey report that was looking at if we continue to just look at the pace at which data centers and supercomputers are being built and scaled, in the next five years, we would have to add two to six times the amount of energy consumed by California onto the grid. And most of that will have to be serviced by fossil fuels, because these data centers and supercomputers have to run 24/7, so we cannot rely solely on renewable energy. We do not have enough nuclear power capacity to power these colossal pieces of infrastructure. And so we’re already accelerating the climate crisis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And we’re also accelerating a public-health crisis, the pumping of thousands of tons of air pollutants into the air from coal plants that are having their lives extended and methane gas turbines that are being built in service of powering these data centers. And in addition to that, there’s also an acceleration of the freshwater crisis, because these pieces of infrastructure have to be cooled with freshwater resources. It has to be fresh water, because if it’s any other type of water, it corrodes the equipment, it leads to bacterial growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;And Bloomberg recently had a story that showed that two-thirds of these data centers are actually going into water-scarce areas, into places where the communities already do not have enough fresh water at their disposal. So that is one dimension of many that I refer to when I say, the extraordinary costs of this particular pathway for AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; So in terms of costs and the extractive process of making AI, I wanted to give you the chance to talk about the other theme of the book, apart from just OpenAI’s explosion. It’s the colonial way of looking at the way AI is made: the empire. I’m saying this obviously because we’re here, but this is an idea that came out of reporting you started at &lt;em&gt;MIT Technology Review&lt;/em&gt; and then continued into the book. Tell us about how this framing helps us understand how AI is made now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, so this was a framing that I started thinking a lot about when I was working on the AI Colonialism series for &lt;em&gt;Tech Review.&lt;/em&gt; It was a series of stories that looked at the way that, pre-ChatGPT, the commercialization of AI and its deployment into the world was already leading to entrenchment of historical inequities into the present day.&lt;/p&gt;  &lt;p&gt;And one example was a story that was about how facial recognition companies were swarming into South Africa to try and harvest more data from South Africa during a time when they were getting criticized for the fact that their technologies did not accurately recognize black faces. And the deployment of those facial recognition technologies into South Africa, into the streets of Johannesburg, was leading to what South African scholars were calling a recreation of a digital apartheid—the controlling of black bodies, movement of black people.&lt;/p&gt; 
 &lt;p&gt;And this idea really haunted me for a really long time. Through my reporting in that series, there were so many examples that I kept hitting upon of this thesis, that the AI industry was perpetuating. It felt like it was becoming this neocolonial force. And then, when ChatGPT came out, it became clear that this was just accelerating.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When you accelerate the scale of these technologies, and you start training them on the entirety of the Internet, and you start using these supercomputers that are the size of dozens—if not hundreds—of football fields. Then you really start talking about an extraordinary global level of extraction and exploitation that is happening to produce these technologies. And then the historical power imbalances become even more obvious.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;And so there are four parallels that I draw in my book between what I have now termed empires of AI versus empires of old. The first one is that empires lay claim to resources that are not their own. So these companies are scraping all this data that is not their own, taking all the intellectual property that is not their own.&lt;/p&gt;  &lt;p&gt;The second is that empires exploit a lot of labor. So we see them moving to countries in the Global South or other economically vulnerable communities to contract workers to do some of the worst work in the development pipeline for producing these technologies—and also producing technologies that then inherently are labor-automating and engage in labor exploitation in and of themselves.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And the third feature is that the empires monopolize knowledge production. So, in the last 10 years, we’ve seen the AI industry monopolize more and more of the AI researchers in the world. So AI researchers are no longer contributing to open science, working in universities or independent institutions, and the effect on the research is what you would imagine would happen if most of the climate scientists in the world were being bankrolled by oil and gas companies. You would not be getting a clear picture, and we are not getting a clear picture, of the limitations of these technologies, or if there are better ways to develop these technologies.&lt;/p&gt;  &lt;p&gt;And the fourth and final feature is that empires always engage in this aggressive race rhetoric, where there are good empires and evil empires. And they, the good empire, have to be strong enough to beat back the evil empire, and that is why they should have unfettered license to consume all of these resources and exploit all of this labor. And if the evil empire gets the technology first, humanity goes to hell. But if the good empire gets the technology first, they’ll civilize the world, and humanity gets to go to heaven. So on many different levels, like the empire theme, I felt like it was the most comprehensive way to name exactly how these companies operate, and exactly what their impacts are on the world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, brilliant. I mean, you talk about the evil empire. What happens if the evil empire gets it first? And what I mentioned at the top is AGI. For me, it’s almost like the extra character in the book all the way through. It’s sort of looming over everything, like the ghost at the feast, sort of saying like, this is the thing that motivates everything at OpenAI. This is the thing we’ve got to get to before anyone else gets to it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There’s a bit in the book about how they’re talking internally at OpenAI, like, we’ve got to make sure that AGI is in US hands where it’s safe versus like anywhere else. And some of the international staff are openly like—that’s kind of a weird way to frame it, isn’t it? Why is the US version of AGI better than others?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So tell us a bit about how it drives what they do. And AGI isn’t an inevitable fact that’s just happening anyway, is it? It’s not even a thing yet.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;There’s not even consensus around whether or not it’s even possible or what it even is. There was recently a &lt;em&gt;New York Times&lt;/em&gt; story by Cade Metz that was citing a survey of long-standing AI researchers in the field, and 75% of them still think that we don’t have the techniques yet for reaching AGI, whatever that means. And the most classic definition or understanding of what AGI is, is being able to fully recreate human intelligence in software. But the problem is, we also don’t have scientific consensus around what human intelligence is. And so one of the aspects that I talk about a lot in the book is that, when there is a vacuum of shared meaning around this term, and what it would look like, when would we have arrived at it? What capabilities should we be evaluating these systems on to determine that we’ve gotten there? It can basically just be whatever OpenAI wants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So it’s kind of just this ever-present goalpost that keeps shifting, depending on where the company wants to go. You know, they have a full range, a variety of different definitions that they’ve used throughout the years. In fact, they even have a joke internally: If you ask 13 OpenAI researchers what AGI is, you’ll get 15 definitions. So they are kind of self-aware that this is not really a real term and it doesn’t really have that much meaning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it does serve this purpose of creating a kind of quasi-religious fervor around what they’re doing, where people think that they have to keep driving towards this horizon, and that one day when they get there, it’s going to have a civilizationally transformative impact. And therefore, what else should you be working on in your life, but this? And who else should be working on it, but you?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;And so it is their justification not just for continuing to push and scale and consume all these resources—because none of that consumption, none of that harm matters anymore if you end up hitting this destination. But they also use it as a way to develop their technologies in a very deeply anti-democratic way, where they say, we are the only people that have the expertise, that have the right to carefully control the development of this technology and usher it into the world. And we cannot let anyone else participate because it’s just too powerful of a technology.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;You talk about the factions, particularly the religious framing. AGI has been around as a concept for a while—it was very niche, very kind of nerdy fun, really, to talk about—to suddenly become extremely mainstream. And they have the boomers versus doomers dichotomy. Where are you on that spectrum?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;So the boomers are people who think that AGI is going to bring us to utopia, and the doomers think AGI is going to devastate all of humanity. And to me these are actually two sides of the same coin. They both believe that AGI is possible, and it’s imminent, and it’s going to change everything.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And I am not on this spectrum. I’m in a third space, which is the AI accountability space, which is rooted in the observation that these companies have accumulated an extraordinary amount of power, both economic and political power, to go back to the empire analogy.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the thing that we need to do in order to not return to an age of empire and erode a lot of democratic norms is to hold these companies accountable with all the tools at our disposal, and to recognize all the harms that they are already perpetuating through a misguided approach to AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;I’ve got a couple of questions from readers. I’m gonna try to pull them together a little bit because Abbas asks, what would post-imperial AI look like? And there was a question from Liam basically along the same lines. How do you make a more ethical version of AI that is not within this framework?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;We sort of already touched a little bit upon this idea. But there are so many different ways to develop AI. There are myriads of techniques throughout the history of AI development, which is decades long. There have been various shifts in the winds of which techniques ultimately rise and fall. And it isn’t based solely on the scientific or technical merit of any particular technique. Oftentimes certain techniques become more popular because of business reasons or because of the funder’s ideologies. And that’s sort of what we’re seeing today with the complete indexing of AI development on large-scale AI model development.&lt;/p&gt;  &lt;p&gt;And ultimately, these large-scale models … We talked about how it’s a remarkable technical leap, but in terms of social progress or economic progress, the benefits of these models have been kind of middling. And the way that I see us shifting to AI models that are going to be A) more beneficial and B) not so imperial is to refocus on task-specific AI systems that are tackling well-scoped challenges that inherently lend themselves to the strengths of AI systems that are inherently computational optimization problems.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;So I’m talking about things like using AI to integrate more renewable energy into the grid. This is something that we definitely need. We need to more quickly accelerate our electrification of the grid, and one of the challenges of using more renewable energy is the unpredictability of it. And this is a key strength of AI technologies, being able to have predictive capabilities and optimization capabilities where you can match the energy generation of different renewables with the energy demands of different people that are drawing from the grid.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Quite a few people have been asking, in the chat, different versions of the same question. If you were an early-career AI scientist, or if you were involved in AI, what can you do yourself to bring about a more ethical version of AI? Do you have any power left, or is it too late?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;No, I don’t think it’s too late at all. I mean, as I’ve been talking with a lot of people just in the lay public, one of the biggest challenges that they have is they don’t have any alternatives for AI. They want the benefits of AI, but they also do not want to participate in a supply chain that is really harmful. And so the first question is, always, is there an alternative? Which tools do I shift to? And unfortunately, there just aren’t that many alternatives right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And so the first thing that I would say to early-career AI researchers and entrepreneurs is to build those alternatives, because there are plenty of people that are actually really excited about the possibility of switching to more ethical alternatives. And one of the analogies I often use is that we kind of need to do with the AI industry what happened with the fashion industry. There was also a lot of environmental exploitation, labor exploitation in the fashion industry, and there was enough consumer demand that it created new markets for ethical and sustainably sourced fashion. And so we kind of need to see just more options occupying that space.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Do you feel optimistic about the future? Or where do you sit? You know, things aren’t great as you spell them out now. Where’s the hope for us?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; I am. I’m super optimistic. Part of the reason why I’m optimistic is because you know, a few years ago, when I started writing about AI at &lt;em&gt;Tech Review,&lt;/em&gt; I remember people would say, wow, that’s a really niche beat. Do you have enough to write about?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And now, I mean, everyone is talking about AI, and I think that’s the first step to actually getting to a better place with AI development. The amount of public awareness and attention and scrutiny that is now going into how we develop these technologies, how we use these technologies, is really, really important. Like, we need to be having this public debate and that in and of itself is a significant step change from what we had before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the next step, and part of the reason why I wrote this book, is we need to convert the awareness into action, and people should take an active role. Every single person should feel that they have an active role in shaping the future of AI development, if you think about all of the different ways that you interface with the AI development supply chain and deployment supply chain—like you give your data or withhold your data.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;There are probably data centers that are being built around you right now. If you’re a parent, there’s some kind of AI policy being crafted at [your kid’s] school. There’s some kind of AI policy being crafted at your workplace. These are all what I consider sites of democratic contestation, where you can use those opportunities to assert your voice about how you want AI to be developed and deployed. If you do not want these companies to use certain kinds of data, push back when they just take the data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I closed all of my personal social media accounts because I just did not like the fact that they were scraping my personal photos to train their generative AI models. I’ve seen parents and students and teachers start forming committees within schools to talk about what their AI policy should be and to draft it collectively as a community. Same with businesses. They’re doing the same thing. If we all kind of step up to play that active role, I am super optimistic that we’ll get to a better place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Mark, in the chat, mentions the Māori story from New Zealand towards the end of your book, and that’s an example of sort of community-led AI in action, isn’t it?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah. There was a community in New Zealand that really wanted to help revitalize the Māori language by building a speech recognition tool that could recognize Māori, and therefore be able to transcribe a rich repository of archival audio of their ancestors speaking Māori. And the first thing that they did when engaging in that project was they asked the community, do you want this AI tool?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Imagine that.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;I know! It’s such a radical concept, this idea of consent at every stage. But they first asked that; the community wholeheartedly said yes. They then engaged in a public education campaign to explain to people, okay, what does it take to develop an AI tool? Well, we are going to need data. We’re going to need audio transcription pairs to train this AI model. So then they ran a public contest in which they were able to get dozens, if not hundreds, of people in their community to donate data to this project. And then they made sure that when they developed the model, they actively explained to the community at every step how their data was being used, how it would be stored, how it would continue to be protected. And any other project that would use the data has to get permission and consent from the community first.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;And so it was a completely democratic process, for whether they wanted the tool, how to develop the tool, and how the tool should continue to be used, and how their data should continue to be used over time.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Great. I know we’ve gone a bit over time. I’ve got two more things I’m going to ask you, basically putting together lots of questions people have asked in the chat about your view on what role regulations should play. What are your thoughts on that?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah, I mean, in an ideal world where we actually had a functioning government, regulation should absolutely play a huge role. And it shouldn’t just be thinking about once an AI model is built, how to regulate that. But still thinking about the full supply chain of AI development, regulating the data and what’s allowed to be trained in these models, regulating the land use. And what pieces of land are allowed to build data centers? How much energy and water are the data centers allowed to consume? And also regulating the transparency. We don’t know what data is in these training data sets, and we don’t know the environmental costs of training these models. We don’t know how much water these data centers consume and that is all information that these companies actively withhold to prevent democratic processes from happening. So if there were one major intervention that regulators could have, it should be to dramatically increase the amount of transparency along the supply chain.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Okay, great. So just to bring it back around to OpenAI and Sam Altman to finish with. He famously sent an email around, didn’t he? After your original &lt;em&gt;Tech Review&lt;/em&gt; story, saying this is not great. We don’t like this. And he didn’t want to speak to you for your book, either, did he?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; No, he did not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;No. But imagine Sam Altman is in the chat here. He’s subscribed to &lt;em&gt;Technology Review&lt;/em&gt; and is watching this Roundtables because he wants to know what you’re saying about him. If you could talk to him directly, what would you like to ask him?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; What degree of harm do you need to see in order to realize that you should take a different path?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Nice, blunt, to the point. All right, Karen, thank you so much for your time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Thank you so much, everyone.&lt;/p&gt;  &lt;p&gt;MIT Technology Review Roundtables is a subscriber-only online event series where experts discuss the latest developments and what’s next in emerging technologies. Sign up to get notified about upcoming sessions.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/09/1119784/inside-openais-empire-a-conversation-with-karen-hao/</guid><pubDate>Wed, 09 Jul 2025 09:10:29 +0000</pubDate></item><item><title>[NEW] The Download: a conversation with Karen Hao, and how did life begin? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/09/1119923/the-download-a-conversation-with-karen-hao-and-how-did-life-begin/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire: A conversation with Karen Hao&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In a wide-ranging Roundtables conversation for MIT Technology Review subscribers, journalist and author Karen Hao recently spoke about her new book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;She talked with executive editor Niall Firth about how she first covered the company in 2020 while on staff at MIT Technology Review. They discussed how the AI industry now functions like an empire and went on to examine what ethically-made AI looks like.&lt;/p&gt;&lt;p&gt;Read the transcript of the conversation, which has been lightly edited and condensed. And, if you’re already a subscriber, you can watch the on-demand recording of the event here.&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How did life begin?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;How life begins is one of the biggest and hardest questions in science. All we know is that something happened on Earth more than 3.5 billion years ago, and it may well have occurred on many other worlds in the universe as well. Could AI help us to unpick the mysteries around the origins of life and detect signs of it on other worlds?&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which&amp;nbsp;&lt;br /&gt;we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI’s Grok went on an anti-Semitic rant&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Days after Elon Musk said new updates would lessen its reliance on mainstream media. (WP $)&lt;br /&gt;+ &lt;em&gt;The chatbot started to call itself ‘MechaHitler.’ &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;What Grok’s neo-Nazi turn tells us about xAI. &lt;/em&gt;(The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 Musk loyalists are fighting to keep DOGE running&lt;/strong&gt;&lt;br /&gt;As officials seek to diminish the department’s role. (WSJ $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 An imposter used AI to successfully impersonate Marco Rubio&lt;/strong&gt;&lt;br /&gt;They were able to send voice and text messages to fellow politicians. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s not the first time Rubio has been targeted like this. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Terrorist groups are using AI to recruit and plan&lt;/strong&gt;&lt;br /&gt;Counter-terror agencies are struggling to keep up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How the crypto faithful won over the President&lt;/strong&gt;&lt;br /&gt;The industry’s successful Trump courtship sparked a lobbying bonanza. (NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 Wanted: 115,000 Nvidia chips for China’s data centers&lt;br /&gt;&lt;/strong&gt;But the US doesn’t seem to know how many restricted chips are already in the country. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 For startups, protecting companies from AI threats isn’t big business&lt;br /&gt;&lt;/strong&gt;Smaller firms are only making modest gains—for now. (The Information $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Inside Zimbabwe’s dangerous EV lithium mines&lt;br /&gt;&lt;/strong&gt;Many residents worry that China is exploiting them. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How one mine could unlock billions in EV subsidies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 ‘The Milk Guy’ is delivering raw dairy around NYC&lt;/strong&gt;&lt;br /&gt;Mmm, delicious listeria, salmonella, and E. coli. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;RFK Jr barred Democrats from being vaccine advisors. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Department of Health and Human Services is searching for two new vaccines against deadly viruses. &lt;/em&gt;(Undark)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Take a look at these beautiful star clusters&lt;/strong&gt;&lt;br /&gt;Courtesy of the Hubble Space Telescope and the James Webb Space Telescope. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;See the stunning first images from the Vera C. Rubin Observatory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“People are going to die.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Clement Nkubizi, the country director for the nonprofit Action Against Hunger in South Sudan, tells Wired that their food stock is running critically low in the wake of USAID cuts.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpM4iSKDKESfRE8dtWt9FeqQ1ufknplS0GI5omvwo4qZXBgRKP5R9CxuOQ2FVkZKaeX6fdg8CjPNndAeZzB2tva0bZrgO7ss4GKZTHhLvAWHBA9sHuqCT6cfWc7sL6754KrGhk?key=jwt8GONxQlylLoe59hwzNg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The world is moving closer to a new cold war fought with authoritarian tech&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Despite President Biden’s assurances that the US is not seeking a new cold war, one is brewing between the world’s autocracies and democracies—and technology is fueling it.&lt;/p&gt;&lt;p&gt;Authoritarian states are following China’s lead and are trending toward more digital rights abuses by increasing the mass digital surveillance of citizens, censorship, and controls on individual expression.&lt;/p&gt;&lt;p&gt;And while democracies also use massive amounts of surveillance technology, it’s the tech trade relationships between authoritarian countries that’s enabling the rise of digitally enabled social control. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire: A conversation with Karen Hao&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In a wide-ranging Roundtables conversation for MIT Technology Review subscribers, journalist and author Karen Hao recently spoke about her new book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;She talked with executive editor Niall Firth about how she first covered the company in 2020 while on staff at MIT Technology Review. They discussed how the AI industry now functions like an empire and went on to examine what ethically-made AI looks like.&lt;/p&gt;&lt;p&gt;Read the transcript of the conversation, which has been lightly edited and condensed. And, if you’re already a subscriber, you can watch the on-demand recording of the event here.&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How did life begin?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;How life begins is one of the biggest and hardest questions in science. All we know is that something happened on Earth more than 3.5 billion years ago, and it may well have occurred on many other worlds in the universe as well. Could AI help us to unpick the mysteries around the origins of life and detect signs of it on other worlds?&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which&amp;nbsp;&lt;br /&gt;we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI’s Grok went on an anti-Semitic rant&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Days after Elon Musk said new updates would lessen its reliance on mainstream media. (WP $)&lt;br /&gt;+ &lt;em&gt;The chatbot started to call itself ‘MechaHitler.’ &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;What Grok’s neo-Nazi turn tells us about xAI. &lt;/em&gt;(The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 Musk loyalists are fighting to keep DOGE running&lt;/strong&gt;&lt;br /&gt;As officials seek to diminish the department’s role. (WSJ $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 An imposter used AI to successfully impersonate Marco Rubio&lt;/strong&gt;&lt;br /&gt;They were able to send voice and text messages to fellow politicians. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s not the first time Rubio has been targeted like this. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Terrorist groups are using AI to recruit and plan&lt;/strong&gt;&lt;br /&gt;Counter-terror agencies are struggling to keep up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How the crypto faithful won over the President&lt;/strong&gt;&lt;br /&gt;The industry’s successful Trump courtship sparked a lobbying bonanza. (NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 Wanted: 115,000 Nvidia chips for China’s data centers&lt;br /&gt;&lt;/strong&gt;But the US doesn’t seem to know how many restricted chips are already in the country. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 For startups, protecting companies from AI threats isn’t big business&lt;br /&gt;&lt;/strong&gt;Smaller firms are only making modest gains—for now. (The Information $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Inside Zimbabwe’s dangerous EV lithium mines&lt;br /&gt;&lt;/strong&gt;Many residents worry that China is exploiting them. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How one mine could unlock billions in EV subsidies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 ‘The Milk Guy’ is delivering raw dairy around NYC&lt;/strong&gt;&lt;br /&gt;Mmm, delicious listeria, salmonella, and E. coli. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;RFK Jr barred Democrats from being vaccine advisors. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Department of Health and Human Services is searching for two new vaccines against deadly viruses. &lt;/em&gt;(Undark)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Take a look at these beautiful star clusters&lt;/strong&gt;&lt;br /&gt;Courtesy of the Hubble Space Telescope and the James Webb Space Telescope. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;See the stunning first images from the Vera C. Rubin Observatory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“People are going to die.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Clement Nkubizi, the country director for the nonprofit Action Against Hunger in South Sudan, tells Wired that their food stock is running critically low in the wake of USAID cuts.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpM4iSKDKESfRE8dtWt9FeqQ1ufknplS0GI5omvwo4qZXBgRKP5R9CxuOQ2FVkZKaeX6fdg8CjPNndAeZzB2tva0bZrgO7ss4GKZTHhLvAWHBA9sHuqCT6cfWc7sL6754KrGhk?key=jwt8GONxQlylLoe59hwzNg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The world is moving closer to a new cold war fought with authoritarian tech&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Despite President Biden’s assurances that the US is not seeking a new cold war, one is brewing between the world’s autocracies and democracies—and technology is fueling it.&lt;/p&gt;&lt;p&gt;Authoritarian states are following China’s lead and are trending toward more digital rights abuses by increasing the mass digital surveillance of citizens, censorship, and controls on individual expression.&lt;/p&gt;&lt;p&gt;And while democracies also use massive amounts of surveillance technology, it’s the tech trade relationships between authoritarian countries that’s enabling the rise of digitally enabled social control. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/09/1119923/the-download-a-conversation-with-karen-hao-and-how-did-life-begin/</guid><pubDate>Wed, 09 Jul 2025 12:10:00 +0000</pubDate></item></channel></rss>