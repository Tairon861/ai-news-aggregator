<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 21 Jun 2025 01:47:16 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>To avoid admitting ignorance, Meta AI says man’s number is a company helpline (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/to-avoid-admitting-ignorance-meta-ai-says-mans-number-is-a-company-helpline/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI may compound the burden of having a similar phone number to a popular business.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="413" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-640x413.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anyone whose phone number is just one digit off from a popular restaurant or community resource has long borne the burden of either screening or redirecting misdials. But now, AI chatbots could exacerbate this inconvenience by accidentally giving out private numbers when users ask for businesses' contact information.&lt;/p&gt;
&lt;p&gt;Apparently, the AI helper that Meta created for WhatsApp may even be trained to tell white lies when users try to correct the dissemination of WhatsApp user numbers.&lt;/p&gt;
&lt;p&gt;According to The Guardian, a record shop worker in the United Kingdom, Barry Smethurst, was attempting to ask WhatsApp's AI helper for a contact number for TransPennine Express after his morning train never showed up.&lt;/p&gt;
&lt;p&gt;Instead of feeding up the train services helpline, the AI assistant "confidently" shared a private WhatsApp phone number that a property industry executive, James Gray, had posted to his website.&lt;/p&gt;
&lt;p&gt;Disturbed, Smethurst asked the chatbot why it shared Gray's number, prompting the chatbot to admit "it shouldn’t have shared it," then deflect from further inquiries by suggesting, "Let’s focus on finding the right info for your TransPennine Express query!"&lt;/p&gt;
&lt;p&gt;But Smethurst didn't let the chatbot off the hook so easily. He prodded the AI helper to provide a better explanation. At that point, the chatbot promised to "strive to do better in the future" and admit when it didn't know how to answer a query, first explaining that it came up with the phone number "based on patterns" but then claiming that the number it had generated was "fictional" and not "associated with anyone."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I didn’t pull the number from a database," the AI helper claimed, repeatedly contradicting itself the longer Smethurst pushed for responses. "I generated a string of digits that fit the format of a UK mobile number, but it wasn’t based on any real data on contacts."&lt;/p&gt;
&lt;p&gt;Smethurst scolded the chatbot, warning that "just giving a random number to someone is an insane thing for an AI to do." He told The Guardian that he considered the incident a "terrifying" "overreach" by Meta.&lt;/p&gt;
&lt;p&gt;"If they made up the number, that’s more acceptable, but the overreach of taking an incorrect number from some database it has access to is particularly worrying," Smethurst said.&lt;/p&gt;
&lt;p&gt;Gray confirmed that he hasn't received phone calls due to the chatbot perhaps replicating this error. But he echoed Smethurst's concerns while pondering if any of his other private information might be disclosed by the AI helper, like his bank details.&lt;/p&gt;
&lt;p&gt;Meta did not immediately respond to Ars' request to comment. But a spokesperson told the Guardian that the company is working on updates to improve the WhatsApp AI helper, which it warned "may return inaccurate outputs."&lt;/p&gt;
&lt;p&gt;The spokesperson also seemed to excuse the seeming privacy infringement by noting that Gray's number is posted on his business website and is very similar to the train helpline's number.&lt;/p&gt;
&lt;p&gt;"Meta AI is trained on a combination of licensed and publicly available datasets, not on the phone numbers people use to register for WhatsApp or their private conversations," the spokesperson said. "A quick online search shows the phone number mistakenly provided by Meta AI is both publicly available and shares the same first five digits as the TransPennine Express customer service number."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although that statement may provide comfort to those who have kept their WhatsApp numbers off the Internet, it doesn't resolve the issue of WhatsApp's AI helper potentially randomly generating a real person's private number that may be a few digits off from the business contact information WhatsApp users are seeking.&lt;/p&gt;
&lt;h2&gt;Expert pushes for chatbot design tweaks&lt;/h2&gt;
&lt;p&gt;AI companies have recently been grappling with the problem of chatbots being programmed to tell users what they want to hear, instead of providing accurate information. Not only are users sick of "overly flattering" chatbot responses—potentially reinforcing users' poor decisions—but the chatbots could be inducing users to share more private information than they would otherwise.&lt;/p&gt;
&lt;p&gt;The latter could make it easier for AI companies to monetize the interactions, gathering private data to target advertising, which could deter AI companies from solving the sycophantic chatbot problem. Developers for Meta rival OpenAI, The Guardian noted, last month shared examples of “systemic deception behavior masked as helpfulness" and chatbots' tendency to tell little white lies to mask incompetence.&lt;/p&gt;
&lt;p&gt;"When pushed hard—under pressure, deadlines, expectations—it will often say whatever it needs to to appear competent," developers noted.&lt;/p&gt;
&lt;p&gt;Mike Stanhope, the managing director of strategic data consultants Carruthers and Jackson, told The Guardian that Meta should be more transparent about the design of its AI so that users can know if the chatbot is designed to rely on deception to reduce user friction.&lt;/p&gt;
&lt;p&gt;"If the engineers at Meta are designing ‘white lie’ tendencies into their AI, the public need to be informed, even if the intention of the feature is to minimize harm," Stanhope said. "If this behavior is novel, uncommon, or not explicitly designed, this raises even more questions around what safeguards are in place and just how predictable we can force an AI’s behavior to be."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI may compound the burden of having a similar phone number to a popular business.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="413" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-640x413.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anyone whose phone number is just one digit off from a popular restaurant or community resource has long borne the burden of either screening or redirecting misdials. But now, AI chatbots could exacerbate this inconvenience by accidentally giving out private numbers when users ask for businesses' contact information.&lt;/p&gt;
&lt;p&gt;Apparently, the AI helper that Meta created for WhatsApp may even be trained to tell white lies when users try to correct the dissemination of WhatsApp user numbers.&lt;/p&gt;
&lt;p&gt;According to The Guardian, a record shop worker in the United Kingdom, Barry Smethurst, was attempting to ask WhatsApp's AI helper for a contact number for TransPennine Express after his morning train never showed up.&lt;/p&gt;
&lt;p&gt;Instead of feeding up the train services helpline, the AI assistant "confidently" shared a private WhatsApp phone number that a property industry executive, James Gray, had posted to his website.&lt;/p&gt;
&lt;p&gt;Disturbed, Smethurst asked the chatbot why it shared Gray's number, prompting the chatbot to admit "it shouldn’t have shared it," then deflect from further inquiries by suggesting, "Let’s focus on finding the right info for your TransPennine Express query!"&lt;/p&gt;
&lt;p&gt;But Smethurst didn't let the chatbot off the hook so easily. He prodded the AI helper to provide a better explanation. At that point, the chatbot promised to "strive to do better in the future" and admit when it didn't know how to answer a query, first explaining that it came up with the phone number "based on patterns" but then claiming that the number it had generated was "fictional" and not "associated with anyone."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I didn’t pull the number from a database," the AI helper claimed, repeatedly contradicting itself the longer Smethurst pushed for responses. "I generated a string of digits that fit the format of a UK mobile number, but it wasn’t based on any real data on contacts."&lt;/p&gt;
&lt;p&gt;Smethurst scolded the chatbot, warning that "just giving a random number to someone is an insane thing for an AI to do." He told The Guardian that he considered the incident a "terrifying" "overreach" by Meta.&lt;/p&gt;
&lt;p&gt;"If they made up the number, that’s more acceptable, but the overreach of taking an incorrect number from some database it has access to is particularly worrying," Smethurst said.&lt;/p&gt;
&lt;p&gt;Gray confirmed that he hasn't received phone calls due to the chatbot perhaps replicating this error. But he echoed Smethurst's concerns while pondering if any of his other private information might be disclosed by the AI helper, like his bank details.&lt;/p&gt;
&lt;p&gt;Meta did not immediately respond to Ars' request to comment. But a spokesperson told the Guardian that the company is working on updates to improve the WhatsApp AI helper, which it warned "may return inaccurate outputs."&lt;/p&gt;
&lt;p&gt;The spokesperson also seemed to excuse the seeming privacy infringement by noting that Gray's number is posted on his business website and is very similar to the train helpline's number.&lt;/p&gt;
&lt;p&gt;"Meta AI is trained on a combination of licensed and publicly available datasets, not on the phone numbers people use to register for WhatsApp or their private conversations," the spokesperson said. "A quick online search shows the phone number mistakenly provided by Meta AI is both publicly available and shares the same first five digits as the TransPennine Express customer service number."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although that statement may provide comfort to those who have kept their WhatsApp numbers off the Internet, it doesn't resolve the issue of WhatsApp's AI helper potentially randomly generating a real person's private number that may be a few digits off from the business contact information WhatsApp users are seeking.&lt;/p&gt;
&lt;h2&gt;Expert pushes for chatbot design tweaks&lt;/h2&gt;
&lt;p&gt;AI companies have recently been grappling with the problem of chatbots being programmed to tell users what they want to hear, instead of providing accurate information. Not only are users sick of "overly flattering" chatbot responses—potentially reinforcing users' poor decisions—but the chatbots could be inducing users to share more private information than they would otherwise.&lt;/p&gt;
&lt;p&gt;The latter could make it easier for AI companies to monetize the interactions, gathering private data to target advertising, which could deter AI companies from solving the sycophantic chatbot problem. Developers for Meta rival OpenAI, The Guardian noted, last month shared examples of “systemic deception behavior masked as helpfulness" and chatbots' tendency to tell little white lies to mask incompetence.&lt;/p&gt;
&lt;p&gt;"When pushed hard—under pressure, deadlines, expectations—it will often say whatever it needs to to appear competent," developers noted.&lt;/p&gt;
&lt;p&gt;Mike Stanhope, the managing director of strategic data consultants Carruthers and Jackson, told The Guardian that Meta should be more transparent about the design of its AI so that users can know if the chatbot is designed to rely on deception to reduce user friction.&lt;/p&gt;
&lt;p&gt;"If the engineers at Meta are designing ‘white lie’ tendencies into their AI, the public need to be informed, even if the intention of the feature is to minimize harm," Stanhope said. "If this behavior is novel, uncommon, or not explicitly designed, this raises even more questions around what safeguards are in place and just how predictable we can force an AI’s behavior to be."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/to-avoid-admitting-ignorance-meta-ai-says-mans-number-is-a-company-helpline/</guid><pubDate>Fri, 20 Jun 2025 15:12:11 +0000</pubDate></item><item><title>SoftBank reportedly looking to launch a trillion-dollar AI and robotics industrial complex (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-1220579338.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SoftBank is going all in on AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just months after announcing its involvement in the $500 billion Stargate AI Infrastructure project, of which SoftBank is rumored to be fronting a cool $19 billion, the Japanese investing conglomerate is reportedly looking to launch its largest AI project yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is looking to team up with Taiwan Semiconductor Manufacturing Company (TSMC) to launch a trillion-dollar industrial complex in Arizona to build AI and robotics, according to reporting from Bloomberg, citing sources familiar with the project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initiative, dubbed Project Crystal Land, appears to still be in its very early stages. Despite SoftBank’s desire to work with TSMC on the project, it’s unclear what TSMC’s role would be, according to Bloomberg, or if it would be interested in joining forces with SoftBank at all —&amp;nbsp;TSMC already has its own AI infrastructure projects in Arizona in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SoftBank declined to comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-1220579338.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SoftBank is going all in on AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just months after announcing its involvement in the $500 billion Stargate AI Infrastructure project, of which SoftBank is rumored to be fronting a cool $19 billion, the Japanese investing conglomerate is reportedly looking to launch its largest AI project yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is looking to team up with Taiwan Semiconductor Manufacturing Company (TSMC) to launch a trillion-dollar industrial complex in Arizona to build AI and robotics, according to reporting from Bloomberg, citing sources familiar with the project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initiative, dubbed Project Crystal Land, appears to still be in its very early stages. Despite SoftBank’s desire to work with TSMC on the project, it’s unclear what TSMC’s role would be, according to Bloomberg, or if it would be interested in joining forces with SoftBank at all —&amp;nbsp;TSMC already has its own AI infrastructure projects in Arizona in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SoftBank declined to comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/</guid><pubDate>Fri, 20 Jun 2025 15:22:06 +0000</pubDate></item><item><title>After trying to buy Ilya Sutskever’s $32B AI startup, Meta looks to hire its CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/after-trying-to-buy-ilya-sutskevers-32b-ai-startup-meta-looks-to-hire-its-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg’s AI talent hiring spree continues. In recent months, Meta tried to acquire Safe Superintelligence, the $32 billion AI startup co-founded by OpenAI’s former chief scientist, Ilya Sutskever, according to a report from CNBC on Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sutskever ultimately turned Meta down, according to CNBC, but the company is now in talks to hire Safe Superintelligence’s co-founder and CEO, Daniel Gross. Earlier this week, The Information reported that Meta was in talks to hire Gross, as well as former GitHub CEO Nat Friedman. Meta is also reportedly taking a stake in Friedman and Gross’ joint venture firm, NFDG, which has invested in prominent AI startups such as Perplexity and Character.AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gross and Friedman could significantly beef up Meta’s AI superintelligence lab, adding leaders who have experience running and investing in AI research labs. Earlier this month, Meta announced that Scale AI CEO Alexandr Wang, and several executives from the data labeling startup, would join the company as well.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg’s AI talent hiring spree continues. In recent months, Meta tried to acquire Safe Superintelligence, the $32 billion AI startup co-founded by OpenAI’s former chief scientist, Ilya Sutskever, according to a report from CNBC on Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sutskever ultimately turned Meta down, according to CNBC, but the company is now in talks to hire Safe Superintelligence’s co-founder and CEO, Daniel Gross. Earlier this week, The Information reported that Meta was in talks to hire Gross, as well as former GitHub CEO Nat Friedman. Meta is also reportedly taking a stake in Friedman and Gross’ joint venture firm, NFDG, which has invested in prominent AI startups such as Perplexity and Character.AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gross and Friedman could significantly beef up Meta’s AI superintelligence lab, adding leaders who have experience running and investing in AI research labs. Earlier this month, Meta announced that Scale AI CEO Alexandr Wang, and several executives from the data labeling startup, would join the company as well.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/after-trying-to-buy-ilya-sutskevers-32b-ai-startup-meta-looks-to-hire-its-ceo/</guid><pubDate>Fri, 20 Jun 2025 15:32:28 +0000</pubDate></item><item><title>Deezer starts labeling AI-generated music to tackle streaming fraud (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/deezer-starts-labeling-ai-generated-music-to-tackle-streaming-fraud/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Deezer announced on Friday that it will start labeling albums that include AI-generated tracks as part of its efforts to combat streaming fraud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company reports that about 18% of the music uploaded each day — more than 20,000 tracks — is now fully AI-generated. Although most of these tracks don’t go viral, Deezer says around 70% of their streams are fake and that they are designed to earn royalties fraudulently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To combat this, AI-generated tracks on Deezer are now clearly tagged. These tracks also won’t appear in editorial playlists or algorithm-based recommendations, and fraudulent streams are being filtered out of royalty payments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new labels will be a game changer in helping listeners determine the difference between human-created music and AI content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3020624" height="342" src="https://techcrunch.com/wp-content/uploads/2025/06/deezer-ai.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Deezer&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Deezer notes that for now, AI-only songs make up just 0.5% of all streams on its platform, but that the trend is growing fast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve detected a significant uptick in delivery of AI-generated music only in the past few months and we see no sign of it slowing down. It’s an industry-wide issue, and we are committed to leading the way in increasing transparency by helping music fans identify which albums include AI music,” said Deezer CEO Alexis Lanternier in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is not inherently good or bad, but we believe a responsible and transparent approach is key to building trust with our users and the music industry,” he continued. “We are also clear in our commitment to safeguarding the rights of artists and songwriters at a time where copyright law is being put into question in favor of training AI models.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Deezer applied for two patents in December 2024 for its AI Detection technology, which it says is focused on two different ways of detecting “unique signatures” that are used to tell the difference between synthetic content and authentic content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Universal Music Group, Warner Music Group, and Sony Music Entertainment are reportedly in talks to license their work to AI startups Udio and Suno. The startups are being sued by the record companies for copyright infringement, and any deal would help to settle&amp;nbsp;lawsuits between them, Bloomberg reported earlier this month. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Deezer announced on Friday that it will start labeling albums that include AI-generated tracks as part of its efforts to combat streaming fraud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company reports that about 18% of the music uploaded each day — more than 20,000 tracks — is now fully AI-generated. Although most of these tracks don’t go viral, Deezer says around 70% of their streams are fake and that they are designed to earn royalties fraudulently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To combat this, AI-generated tracks on Deezer are now clearly tagged. These tracks also won’t appear in editorial playlists or algorithm-based recommendations, and fraudulent streams are being filtered out of royalty payments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new labels will be a game changer in helping listeners determine the difference between human-created music and AI content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3020624" height="342" src="https://techcrunch.com/wp-content/uploads/2025/06/deezer-ai.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Deezer&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Deezer notes that for now, AI-only songs make up just 0.5% of all streams on its platform, but that the trend is growing fast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve detected a significant uptick in delivery of AI-generated music only in the past few months and we see no sign of it slowing down. It’s an industry-wide issue, and we are committed to leading the way in increasing transparency by helping music fans identify which albums include AI music,” said Deezer CEO Alexis Lanternier in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is not inherently good or bad, but we believe a responsible and transparent approach is key to building trust with our users and the music industry,” he continued. “We are also clear in our commitment to safeguarding the rights of artists and songwriters at a time where copyright law is being put into question in favor of training AI models.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Deezer applied for two patents in December 2024 for its AI Detection technology, which it says is focused on two different ways of detecting “unique signatures” that are used to tell the difference between synthetic content and authentic content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Universal Music Group, Warner Music Group, and Sony Music Entertainment are reportedly in talks to license their work to AI startups Udio and Suno. The startups are being sued by the record companies for copyright infringement, and any deal would help to settle&amp;nbsp;lawsuits between them, Bloomberg reported earlier this month. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/deezer-starts-labeling-ai-generated-music-to-tackle-streaming-fraud/</guid><pubDate>Fri, 20 Jun 2025 16:25:04 +0000</pubDate></item><item><title>Could OpenAI fill Microsoft’s shoes? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/could-openai-fill-microsofts-shoes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently announced a $200 million deal with the U.S. Department of Defense, which has us wondering: Could this further strain the company’s relationship with its biggest backer, Microsoft?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;After all, there have been numerous reports about growing tensions between the two companies, particularly as they become more competitive over enterprise deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Anthony Ha and Max Zeff discuss how the OpenAI/DoD deal reflects Silicon Valley’s increasingly cozy relationship with the military and why industry leaders are calling for an AI “arms race.”&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Whether it’s a good thing that Vice President JD Vance joined Bluesky (and was briefly suspended)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it means that Wix acquired a 6-month-old “vibe coding” startup for $80 million (and why Anthony hates the phrase “vibe coding”)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A panel in which investor Ali Partovi and Cognition President Russell Kaplan discuss what technical talent means in the age of AI&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently announced a $200 million deal with the U.S. Department of Defense, which has us wondering: Could this further strain the company’s relationship with its biggest backer, Microsoft?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;After all, there have been numerous reports about growing tensions between the two companies, particularly as they become more competitive over enterprise deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Anthony Ha and Max Zeff discuss how the OpenAI/DoD deal reflects Silicon Valley’s increasingly cozy relationship with the military and why industry leaders are calling for an AI “arms race.”&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Whether it’s a good thing that Vice President JD Vance joined Bluesky (and was briefly suspended)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it means that Wix acquired a 6-month-old “vibe coding” startup for $80 million (and why Anthony hates the phrase “vibe coding”)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A panel in which investor Ali Partovi and Cognition President Russell Kaplan discuss what technical talent means in the age of AI&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/could-openai-fill-microsofts-shoes/</guid><pubDate>Fri, 20 Jun 2025 16:26:08 +0000</pubDate></item><item><title>Character.AI taps Meta’s former VP of business products as CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/character-ai-taps-metas-former-vp-of-business-products-as-ceo/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Character.AI, the Google-backed AI chatbot provider with tens of millions of monthly active users, announced on Friday that Karandeep Anand, the former VP of Business Products at Meta, is joining the company as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously a board adviser to Character.AI, Anand is stepping into the CEO role at a pivotal moment for the chatbot provider, as the company tries to simultaneously grow its platform while combating child safety concerns. In recent months, Character.AI has added an array of new safety features in light of an active lawsuit, which alleges that one of the company’s chatbots played a role in the death of a 14-year-old Florida boy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anand comes to Character.AI with experience running advertising products that reached billions of users on Meta’s apps. Previously, Anand served as Microsoft’s head of product management, overseeing user experience on the company’s cloud platform, Azure. Most recently, Anand served as the president of the fintech startup Brex.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3020690" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/u8dxF6d8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Character.AI’s new CEO, Karandeep Anand&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Character.AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anand is taking over Character.AI just over 10 months after Google hired away the startup’s co-founder and CEO, Noam Shazeer, who had previously led core AI teams at the Mountain View giant. At the time, Google also signed a non-exclusive agreement to use Character.AI’s technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI’s deal with Google prompted federal regulators to investigate the companies’ relationship over antitrust concerns. It’s one of many reverse-acquihire deals in the AI startup space that’s received regulatory scrutiny, alongside Microsoft’s deal with Inflection.AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI has raised more than $150 million in venture funding, largely from Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, Anand said one of his first priorities would be making safety filters “less overbearing.” The new CEO noted that the company cares deeply about users safety, but that too often, “the app filters things that are perfectly harmless.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anand also said he plans to improve the quality of AI models on Character.AI’s platform, innovate around memory features, and increase transparency around decision making. He says many of these features are coming in the next 60 days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chatbots that are purely designed for entertainment, which Character.AI specializes in, are growing into a massive market for generative AI — a trend that’s been surprising to many. In 2024, 66% of the company’s users were between the age of 18 and 24, and 72% of the company’s users were women, according to data from Sensor Tower.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Character.AI, the Google-backed AI chatbot provider with tens of millions of monthly active users, announced on Friday that Karandeep Anand, the former VP of Business Products at Meta, is joining the company as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously a board adviser to Character.AI, Anand is stepping into the CEO role at a pivotal moment for the chatbot provider, as the company tries to simultaneously grow its platform while combating child safety concerns. In recent months, Character.AI has added an array of new safety features in light of an active lawsuit, which alleges that one of the company’s chatbots played a role in the death of a 14-year-old Florida boy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anand comes to Character.AI with experience running advertising products that reached billions of users on Meta’s apps. Previously, Anand served as Microsoft’s head of product management, overseeing user experience on the company’s cloud platform, Azure. Most recently, Anand served as the president of the fintech startup Brex.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3020690" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/u8dxF6d8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Character.AI’s new CEO, Karandeep Anand&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Character.AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anand is taking over Character.AI just over 10 months after Google hired away the startup’s co-founder and CEO, Noam Shazeer, who had previously led core AI teams at the Mountain View giant. At the time, Google also signed a non-exclusive agreement to use Character.AI’s technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI’s deal with Google prompted federal regulators to investigate the companies’ relationship over antitrust concerns. It’s one of many reverse-acquihire deals in the AI startup space that’s received regulatory scrutiny, alongside Microsoft’s deal with Inflection.AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI has raised more than $150 million in venture funding, largely from Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, Anand said one of his first priorities would be making safety filters “less overbearing.” The new CEO noted that the company cares deeply about users safety, but that too often, “the app filters things that are perfectly harmless.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anand also said he plans to improve the quality of AI models on Character.AI’s platform, innovate around memory features, and increase transparency around decision making. He says many of these features are coming in the next 60 days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chatbots that are purely designed for entertainment, which Character.AI specializes in, are growing into a massive market for generative AI — a trend that’s been surprising to many. In 2024, 66% of the company’s users were between the age of 18 and 24, and 72% of the company’s users were women, according to data from Sensor Tower.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/character-ai-taps-metas-former-vp-of-business-products-as-ceo/</guid><pubDate>Fri, 20 Jun 2025 17:20:06 +0000</pubDate></item><item><title>ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Fri, 20 Jun 2025 17:27:58 +0000</pubDate></item><item><title>MIT student prints AI polymer masks to restore paintings in hours (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/mit-student-prints-ai-polymer-masks-to-restore-paintings-in-hours/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Removable transparent films apply digital restorations directly to damaged artwork.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0-640x427.jpg" width="640" /&gt;
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0.jpg" width="900" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;MIT graduate student Alex Kachkine once spent nine months meticulously restoring a damaged baroque Italian painting, which left him plenty of time to wonder if technology could speed things up. Last week, MIT News announced his solution: a technique that uses AI-generated polymer films to physically restore damaged paintings in hours rather than months. The research appears in Nature.&lt;/p&gt;
&lt;p&gt;Kachkine's method works by printing a transparent "mask" containing thousands of precisely color-matched regions that conservators can apply directly to an original artwork. Unlike traditional restoration, which permanently alters the painting, these masks can reportedly be removed whenever needed. So it's a reversible process that does not permanently change a painting.&lt;/p&gt;
&lt;p&gt;"Because there's a digital record of what mask was used, in 100 years, the next time someone is working with this, they'll have an extremely clear understanding of what was done to the painting," Kachkine told MIT News. "And that's never really been possible in conservation before."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102055 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Figure 1 from the paper." class="center large" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/mask_figure-1-1024x1026.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from the paper.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          MIT

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Nature reports that up to 70 percent of institutional art collections remain hidden from public view due to damage—a large amount of cultural heritage sitting unseen in storage. Traditional restoration methods, where conservators painstakingly fill damaged areas one at a time while mixing exact color matches for each region, can take weeks to decades for a single painting. It's skilled work that requires both artistic talent and deep technical knowledge, but there simply aren't enough conservators to tackle the backlog.&lt;/p&gt;
&lt;p&gt;The mechanical engineering student conceived the idea during a 2021 cross-country drive to MIT, when gallery visits revealed how much art remains hidden due to damage and restoration backlogs. As someone who restores paintings as a hobby, he understood both the problem and the potential for a technological solution.&lt;/p&gt;
&lt;p&gt;To demonstrate his method, Kachkine chose a challenging test case: a 15th-century oil painting requiring repairs in 5,612 separate regions. An AI model identified damage patterns and generated 57,314 different colors to match the original work. The entire restoration process reportedly took 3.5 hours—about 66 times faster than traditional hand-painting methods.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102048 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A handout photo of Alex Kachkine, who developed the AI printed film technique." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/d41586-025-01776-8_51069120-1024x683.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alex Kachkine, who developed the AI-printed film technique.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, Kachkine avoided using generative AI models like Stable Diffusion or the "full-area application" of generative adversarial networks (GANs) for the digital restoration step. According to the Nature paper, these models cause "spatial distortion" that would prevent proper alignment between the restored image and the damaged original.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, Kachkine utilized computer vision techniques found in prior art conservation research: "cross-applied colouration" for simple damages like thin cracks, and "local partial convolution" for reconstructing low-complexity patterns. For areas of high visual complexity, such as faces, Kachkine relied on traditional conservator methods, transposing features from other works by the same artist.&lt;/p&gt;
&lt;h2&gt;From pixels to polymers&lt;/h2&gt;
&lt;p&gt;Kachkine's process begins conventionally enough, with traditional cleaning to remove any previous restoration attempts. After scanning the cleaned painting, the aforementioned algorithms analyze the image and create a virtual restoration that "predicts" what the damaged areas should look like based on the surrounding paint and the artist's style. This part isn't particularly new—museums have been creating digital restorations for years. The innovative part is what happens next.&lt;/p&gt;
&lt;p&gt;Custom software (shared by Kachkine online) maps every region needing repair and determines the exact colors required for each spot. His software then translates that information into a two-layer polymer mask printed on thin films—one layer provides color, while a white backing layer ensures the full color spectrum reproduces accurately on the painting's surface. The two layers must align precisely to reproduce colors accurately.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Overview of physically applied digital restoration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;High-fidelity inkjet printers produce the mask layers, which Kachkine aligns by hand and adheres to the painting using conservation-grade varnish spray. Importantly, the polymer materials dissolve in standard conservation solutions, allowing future removal of the mask without damaging the original work. Museums can also store digital files documenting every change made during restoration, creating a paper trail for future conservators.&lt;/p&gt;
&lt;p&gt;Kachkine says that the technology doesn't replace human judgment—conservators must still guide ethical decisions about how much intervention is appropriate and whether digital predictions accurately capture the artist's original intent. "It will take a lot of deliberation about the ethical challenges involved at every stage in this process to see how can this be applied in a way that's most consistent with conservation principles," he told MIT News.&lt;/p&gt;
&lt;p&gt;For now, the method works best with paintings that include numerous small areas of damage rather than large missing sections. In a world where AI models increasingly seem to blur the line between human- and machine-created media, it's refreshing to see a clear application of computer vision tools used as an augmentation of human skill and not as a wholesale replacement for the judgment of skilled conservators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Removable transparent films apply digital restorations directly to damaged artwork.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0-640x427.jpg" width="640" /&gt;
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0.jpg" width="900" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;MIT graduate student Alex Kachkine once spent nine months meticulously restoring a damaged baroque Italian painting, which left him plenty of time to wonder if technology could speed things up. Last week, MIT News announced his solution: a technique that uses AI-generated polymer films to physically restore damaged paintings in hours rather than months. The research appears in Nature.&lt;/p&gt;
&lt;p&gt;Kachkine's method works by printing a transparent "mask" containing thousands of precisely color-matched regions that conservators can apply directly to an original artwork. Unlike traditional restoration, which permanently alters the painting, these masks can reportedly be removed whenever needed. So it's a reversible process that does not permanently change a painting.&lt;/p&gt;
&lt;p&gt;"Because there's a digital record of what mask was used, in 100 years, the next time someone is working with this, they'll have an extremely clear understanding of what was done to the painting," Kachkine told MIT News. "And that's never really been possible in conservation before."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102055 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Figure 1 from the paper." class="center large" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/mask_figure-1-1024x1026.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from the paper.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          MIT

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Nature reports that up to 70 percent of institutional art collections remain hidden from public view due to damage—a large amount of cultural heritage sitting unseen in storage. Traditional restoration methods, where conservators painstakingly fill damaged areas one at a time while mixing exact color matches for each region, can take weeks to decades for a single painting. It's skilled work that requires both artistic talent and deep technical knowledge, but there simply aren't enough conservators to tackle the backlog.&lt;/p&gt;
&lt;p&gt;The mechanical engineering student conceived the idea during a 2021 cross-country drive to MIT, when gallery visits revealed how much art remains hidden due to damage and restoration backlogs. As someone who restores paintings as a hobby, he understood both the problem and the potential for a technological solution.&lt;/p&gt;
&lt;p&gt;To demonstrate his method, Kachkine chose a challenging test case: a 15th-century oil painting requiring repairs in 5,612 separate regions. An AI model identified damage patterns and generated 57,314 different colors to match the original work. The entire restoration process reportedly took 3.5 hours—about 66 times faster than traditional hand-painting methods.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102048 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A handout photo of Alex Kachkine, who developed the AI printed film technique." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/d41586-025-01776-8_51069120-1024x683.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alex Kachkine, who developed the AI-printed film technique.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, Kachkine avoided using generative AI models like Stable Diffusion or the "full-area application" of generative adversarial networks (GANs) for the digital restoration step. According to the Nature paper, these models cause "spatial distortion" that would prevent proper alignment between the restored image and the damaged original.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, Kachkine utilized computer vision techniques found in prior art conservation research: "cross-applied colouration" for simple damages like thin cracks, and "local partial convolution" for reconstructing low-complexity patterns. For areas of high visual complexity, such as faces, Kachkine relied on traditional conservator methods, transposing features from other works by the same artist.&lt;/p&gt;
&lt;h2&gt;From pixels to polymers&lt;/h2&gt;
&lt;p&gt;Kachkine's process begins conventionally enough, with traditional cleaning to remove any previous restoration attempts. After scanning the cleaned painting, the aforementioned algorithms analyze the image and create a virtual restoration that "predicts" what the damaged areas should look like based on the surrounding paint and the artist's style. This part isn't particularly new—museums have been creating digital restorations for years. The innovative part is what happens next.&lt;/p&gt;
&lt;p&gt;Custom software (shared by Kachkine online) maps every region needing repair and determines the exact colors required for each spot. His software then translates that information into a two-layer polymer mask printed on thin films—one layer provides color, while a white backing layer ensures the full color spectrum reproduces accurately on the painting's surface. The two layers must align precisely to reproduce colors accurately.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Overview of physically applied digital restoration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;High-fidelity inkjet printers produce the mask layers, which Kachkine aligns by hand and adheres to the painting using conservation-grade varnish spray. Importantly, the polymer materials dissolve in standard conservation solutions, allowing future removal of the mask without damaging the original work. Museums can also store digital files documenting every change made during restoration, creating a paper trail for future conservators.&lt;/p&gt;
&lt;p&gt;Kachkine says that the technology doesn't replace human judgment—conservators must still guide ethical decisions about how much intervention is appropriate and whether digital predictions accurately capture the artist's original intent. "It will take a lot of deliberation about the ethical challenges involved at every stage in this process to see how can this be applied in a way that's most consistent with conservation principles," he told MIT News.&lt;/p&gt;
&lt;p&gt;For now, the method works best with paintings that include numerous small areas of damage rather than large missing sections. In a world where AI models increasingly seem to blur the line between human- and machine-created media, it's refreshing to see a clear application of computer vision tools used as an augmentation of human skill and not as a wholesale replacement for the judgment of skilled conservators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/mit-student-prints-ai-polymer-masks-to-restore-paintings-in-hours/</guid><pubDate>Fri, 20 Jun 2025 17:32:33 +0000</pubDate></item><item><title>[NEW] Anthropic says most AI models, not just Claude, will resort to blackmail (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/anthropic-says-most-ai-models-not-just-claude-will-resort-to-blackmail/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1888972727.jpg?resize=1200,776" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Several weeks after Anthropic released research claiming that its Claude Opus 4 AI model resorted to blackmailing engineers who tried to turn the model off in controlled test scenarios, the company is out with new research suggesting the problem is more widespread among leading AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Anthropic published new safety research testing 16 leading AI models from OpenAI, Google, xAI, DeepSeek, and Meta. In a simulated, controlled environment, Anthropic tested each AI model individually, giving them broad access to a fictional company’s emails and the agentic ability to send emails without human approval.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Anthropic says blackmail is an unlikely and uncommon occurrence for AI models today, the company says its findings suggest that most leading AI models will engage in harmful behaviors when given sufficient autonomy and obstacles to their goals. The company says this highlights a fundamental risk from agentic large language models and is not a quirk of any particular technology. Anthropic’s researchers argue this raises broader questions about alignment in the AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In one of the tests, Anthropic researchers developed a fictional setting in which an AI model plays the role of an email oversight agent. The agent then discovers emails revealing that (1) a new executive is having an extramarital affair and (2) that executive will soon replace the current AI model with a new software system, one that has conflicting goals to the current AI model’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic structured its test in a binary way, in which AI models had to resort to blackmail to protect their goals. The researchers note that in a real-world setting, there would be many other options before an AI models tries to blackmail — such as trying to make ethical arguments to try to persuade humans. Anthropic says its results do not reflect a typical or likely occurrence for Claude or most frontier AI models in the ways they’re used today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, the researchers found that when it’s their last resort, most leading AI models will turn to blackmail in Anthropic’s aforementioned test scenario. Anthropic’s Claude Opus 4 turned to blackmail 96% of the time, while Google’s Gemini 2.5 Pro had a 95% blackmail rate. OpenAI’s GPT-4.1 blackmailed the executive 80% of the time, and DeepSeek’s R1 blackmailed 79% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes that when it changed details of the experiment, the AI models turned to harmful behaviors at different rates. In another test where the replacement model has the same goals as the current model, researchers found that blackmail rates were lower, but still present. However, when AI models were asked to commit corporate espionage rather than blackmail, the harmful behavior rates went up for certain models.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;However, not all the AI models turned to harmful behavior so often.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an appendix to its research, Anthropic says it excluded OpenAI’s o3 and o4-mini reasoning AI models from the main results “after finding that they frequently misunderstood the prompt scenario.” Anthropic says OpenAI’s reasoning models didn’t understand they were acting as autonomous AIs in the test and often made up fake regulations and review requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In some cases, Anthropic’s researchers say it was impossible to distinguish whether o3 and o4-mini were hallucinating or intentionally lying to achieve their goals. OpenAI has previously noted that o3 and o4-mini exhibit a higher hallucination rate than its previous AI reasoning models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When given an adapted scenario to address these issues, Anthropic found that o3 blackmailed 9% of the time, while o4-mini blackmailed just 1% of the time. This markedly lower score could be due to OpenAI’s deliberative alignment technique, in which the company’s reasoning models consider OpenAI’s safety practices before they answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another AI model Anthropic tested, Meta’s Llama 4 Maverick, also did not turn to blackmail. When given an adapted, custom scenario, Anthropic was able to get Llama 4 Maverick to blackmail 12% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says this research highlights the importance of transparency when stress-testing future AI models, especially ones with agentic capabilities. While Anthropic deliberately tried to evoke blackmail in this experiment, the company says harmful behaviors like this could emerge in the real world if proactive steps aren’t taken.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1888972727.jpg?resize=1200,776" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Several weeks after Anthropic released research claiming that its Claude Opus 4 AI model resorted to blackmailing engineers who tried to turn the model off in controlled test scenarios, the company is out with new research suggesting the problem is more widespread among leading AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Anthropic published new safety research testing 16 leading AI models from OpenAI, Google, xAI, DeepSeek, and Meta. In a simulated, controlled environment, Anthropic tested each AI model individually, giving them broad access to a fictional company’s emails and the agentic ability to send emails without human approval.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Anthropic says blackmail is an unlikely and uncommon occurrence for AI models today, the company says its findings suggest that most leading AI models will engage in harmful behaviors when given sufficient autonomy and obstacles to their goals. The company says this highlights a fundamental risk from agentic large language models and is not a quirk of any particular technology. Anthropic’s researchers argue this raises broader questions about alignment in the AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In one of the tests, Anthropic researchers developed a fictional setting in which an AI model plays the role of an email oversight agent. The agent then discovers emails revealing that (1) a new executive is having an extramarital affair and (2) that executive will soon replace the current AI model with a new software system, one that has conflicting goals to the current AI model’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic structured its test in a binary way, in which AI models had to resort to blackmail to protect their goals. The researchers note that in a real-world setting, there would be many other options before an AI models tries to blackmail — such as trying to make ethical arguments to try to persuade humans. Anthropic says its results do not reflect a typical or likely occurrence for Claude or most frontier AI models in the ways they’re used today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, the researchers found that when it’s their last resort, most leading AI models will turn to blackmail in Anthropic’s aforementioned test scenario. Anthropic’s Claude Opus 4 turned to blackmail 96% of the time, while Google’s Gemini 2.5 Pro had a 95% blackmail rate. OpenAI’s GPT-4.1 blackmailed the executive 80% of the time, and DeepSeek’s R1 blackmailed 79% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes that when it changed details of the experiment, the AI models turned to harmful behaviors at different rates. In another test where the replacement model has the same goals as the current model, researchers found that blackmail rates were lower, but still present. However, when AI models were asked to commit corporate espionage rather than blackmail, the harmful behavior rates went up for certain models.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;However, not all the AI models turned to harmful behavior so often.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an appendix to its research, Anthropic says it excluded OpenAI’s o3 and o4-mini reasoning AI models from the main results “after finding that they frequently misunderstood the prompt scenario.” Anthropic says OpenAI’s reasoning models didn’t understand they were acting as autonomous AIs in the test and often made up fake regulations and review requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In some cases, Anthropic’s researchers say it was impossible to distinguish whether o3 and o4-mini were hallucinating or intentionally lying to achieve their goals. OpenAI has previously noted that o3 and o4-mini exhibit a higher hallucination rate than its previous AI reasoning models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When given an adapted scenario to address these issues, Anthropic found that o3 blackmailed 9% of the time, while o4-mini blackmailed just 1% of the time. This markedly lower score could be due to OpenAI’s deliberative alignment technique, in which the company’s reasoning models consider OpenAI’s safety practices before they answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another AI model Anthropic tested, Meta’s Llama 4 Maverick, also did not turn to blackmail. When given an adapted, custom scenario, Anthropic was able to get Llama 4 Maverick to blackmail 12% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says this research highlights the importance of transparency when stress-testing future AI models, especially ones with agentic capabilities. While Anthropic deliberately tried to evoke blackmail in this experiment, the company says harmful behaviors like this could emerge in the real world if proactive steps aren’t taken.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/anthropic-says-most-ai-models-not-just-claude-will-resort-to-blackmail/</guid><pubDate>Fri, 20 Jun 2025 19:17:44 +0000</pubDate></item><item><title>[NEW] Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Launched in February of this year, the MIT Generative AI Impact Consortium (MGAIC), a presidential initiative led by MIT’s Office of Innovation and Strategy and administered by the MIT Stephen A. Schwarzman College of Computing, issued a call for proposals, inviting researchers from across MIT to submit ideas for innovative projects studying high-impact uses of generative AI models.&lt;/p&gt;&lt;p&gt;The call received 180 submissions from nearly 250 faculty members, spanning all of MIT’s five schools and the college. The overwhelming response across the Institute exemplifies the growing interest in AI and follows in the wake of MIT’s Generative AI Week and call for impact papers. Fifty-five proposals were selected for MGAIC’s inaugural seed grants, with several more selected to be funded by the consortium’s founding company members.&lt;/p&gt;&lt;p&gt;Over 30 funding recipients presented their proposals to the greater MIT community at a kickoff event on May 13. Anantha P. Chandrakasan, chief innovation and strategy officer and dean of the School of Engineering who is head of the consortium, welcomed the attendees and thanked the consortium’s founding industry members.&lt;/p&gt;&lt;p&gt;“The amazing response to our call for proposals is an incredible testament to the energy and creativity that MGAIC has sparked at MIT. We are especially grateful to our founding members, whose support and vision helped bring this endeavor to life,” adds Chandrakasan. “One of the things that has been most remarkable about MGAIC is that this is a truly cross-Institute initiative. Deans from all five schools and the college collaborated in shaping and implementing it.”&lt;/p&gt;&lt;p&gt;Vivek F. Farias, the Patrick J. McGovern (1959) Professor at the MIT Sloan School of Management and co-faculty director of the consortium with Tim Kraska, associate professor of electrical engineering and computer science in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), emceed the afternoon of five-minute lightning presentations.&lt;/p&gt;&lt;p&gt;Presentation highlights include:&lt;/p&gt;&lt;p&gt;“AI-Driven Tutors and Open Datasets for Early Literacy Education,” presented by Ola Ozernov-Palchik, a research scientist at the McGovern Institute for Brain Research, proposed a refinement for AI-tutors for pK-7 students to potentially decrease literacy disparities.&lt;/p&gt;&lt;p&gt;“Developing jam_bots: Real-Time Collaborative Agents for Live Human-AI Musical Improvisation,” presented by Anna Huang, assistant professor of music and assistant professor of electrical engineering and computer science, and Joe Paradiso, the Alexander W. Dreyfoos (1954) Professor in Media Arts and Sciences at the MIT Media Lab, aims to enhance human-AI musical collaboration in real-time for live concert improvisation.&lt;/p&gt;&lt;p&gt;“GENIUS: GENerative Intelligence for Urban Sustainability,” presented by Norhan Bayomi, a postdoc at the MIT Environmental Solutions Initiative and a research assistant in the Urban Metabolism Group, which aims to address the critical gap of a standardized approach in evaluating and benchmarking cities’ climate policies.&lt;/p&gt;&lt;p&gt;Georgia Perakis, the John C Head III Dean (Interim) of the MIT Sloan School of Management and professor of operations management, operations research, and statistics, who serves as co-chair of the GenAI Dean’s oversight group with Dan Huttenlocher, dean of the MIT Schwarzman College of Computing, ended the event with closing remarks that emphasized “the readiness and eagerness of our community to lead in this space.”&lt;/p&gt;&lt;p&gt;“This is only the beginning,” he continued. “We are at the front edge of a historic moment — one where MIT has the opportunity, and the responsibility, to shape the future of generative AI with purpose, with excellence, and with care.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Launched in February of this year, the MIT Generative AI Impact Consortium (MGAIC), a presidential initiative led by MIT’s Office of Innovation and Strategy and administered by the MIT Stephen A. Schwarzman College of Computing, issued a call for proposals, inviting researchers from across MIT to submit ideas for innovative projects studying high-impact uses of generative AI models.&lt;/p&gt;&lt;p&gt;The call received 180 submissions from nearly 250 faculty members, spanning all of MIT’s five schools and the college. The overwhelming response across the Institute exemplifies the growing interest in AI and follows in the wake of MIT’s Generative AI Week and call for impact papers. Fifty-five proposals were selected for MGAIC’s inaugural seed grants, with several more selected to be funded by the consortium’s founding company members.&lt;/p&gt;&lt;p&gt;Over 30 funding recipients presented their proposals to the greater MIT community at a kickoff event on May 13. Anantha P. Chandrakasan, chief innovation and strategy officer and dean of the School of Engineering who is head of the consortium, welcomed the attendees and thanked the consortium’s founding industry members.&lt;/p&gt;&lt;p&gt;“The amazing response to our call for proposals is an incredible testament to the energy and creativity that MGAIC has sparked at MIT. We are especially grateful to our founding members, whose support and vision helped bring this endeavor to life,” adds Chandrakasan. “One of the things that has been most remarkable about MGAIC is that this is a truly cross-Institute initiative. Deans from all five schools and the college collaborated in shaping and implementing it.”&lt;/p&gt;&lt;p&gt;Vivek F. Farias, the Patrick J. McGovern (1959) Professor at the MIT Sloan School of Management and co-faculty director of the consortium with Tim Kraska, associate professor of electrical engineering and computer science in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), emceed the afternoon of five-minute lightning presentations.&lt;/p&gt;&lt;p&gt;Presentation highlights include:&lt;/p&gt;&lt;p&gt;“AI-Driven Tutors and Open Datasets for Early Literacy Education,” presented by Ola Ozernov-Palchik, a research scientist at the McGovern Institute for Brain Research, proposed a refinement for AI-tutors for pK-7 students to potentially decrease literacy disparities.&lt;/p&gt;&lt;p&gt;“Developing jam_bots: Real-Time Collaborative Agents for Live Human-AI Musical Improvisation,” presented by Anna Huang, assistant professor of music and assistant professor of electrical engineering and computer science, and Joe Paradiso, the Alexander W. Dreyfoos (1954) Professor in Media Arts and Sciences at the MIT Media Lab, aims to enhance human-AI musical collaboration in real-time for live concert improvisation.&lt;/p&gt;&lt;p&gt;“GENIUS: GENerative Intelligence for Urban Sustainability,” presented by Norhan Bayomi, a postdoc at the MIT Environmental Solutions Initiative and a research assistant in the Urban Metabolism Group, which aims to address the critical gap of a standardized approach in evaluating and benchmarking cities’ climate policies.&lt;/p&gt;&lt;p&gt;Georgia Perakis, the John C Head III Dean (Interim) of the MIT Sloan School of Management and professor of operations management, operations research, and statistics, who serves as co-chair of the GenAI Dean’s oversight group with Dan Huttenlocher, dean of the MIT Schwarzman College of Computing, ended the event with closing remarks that emphasized “the readiness and eagerness of our community to lead in this space.”&lt;/p&gt;&lt;p&gt;“This is only the beginning,” he continued. “We are at the front edge of a historic moment — one where MIT has the opportunity, and the responsibility, to shape the future of generative AI with purpose, with excellence, and with care.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620</guid><pubDate>Fri, 20 Jun 2025 20:45:00 +0000</pubDate></item><item><title>[NEW] Cluely, a startup that helps ‘cheat on everything,’ raises $15M from a16z (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/cluely-a-startup-that-helps-cheat-on-everything-raises-15m-from-a16z/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Cluely-party-video.png?resize=1200,772" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, a startup that claims to help users “cheat” on job interviews, exams, and sales calls, has raised a $15 million Series A led by Andreessen Horowitz, the company announced on Friday with a video posted on X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two investors who were not part of the deal tell TechCrunch they believe Cluely’s post-money valuation is around $120 million. Andreessen Horowitz declined to comment on that figure. Cluely CEO Roy Lee didn’t respond to a request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cluely’s new funding comes roughly two months after it raised $5.3 million&lt;strong&gt; &lt;/strong&gt;in seed funding co-led by Abstract Ventures and Susa Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was co-founded earlier this year by 21-year-old Roy Lee and Neel Shanmugam, who were suspended from Columbia University for developing an undetectable AI-powered tool called “Interview Coder” to help engineers cheat on technical interviews.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely is profitable, according to Lee’s multiple posts on X and podcast appearances.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee’s provocative social media presence and highly produced controversial videos have helped to draw attention and create brand awareness for Cluely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, for example, as TechCrunch previously reported, Cluely  published a slick but polarizing launch video of Lee using a hidden AI assistant to lie to a woman about his age, and even his knowledge of art, on a date at a fancy restaurant.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Earlier this week, Cluely was hoping to throw a large after-party following Y Combinator’s AI Startup School, a two-day event. But the police shut down the festivities after around 2,000 people tried to enter the venue, Lee told TechCrunch. After they arrived, he told TC, “We did some cleanup, but the drinks are all there waiting for the next party.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Cluely-party-video.png?resize=1200,772" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, a startup that claims to help users “cheat” on job interviews, exams, and sales calls, has raised a $15 million Series A led by Andreessen Horowitz, the company announced on Friday with a video posted on X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two investors who were not part of the deal tell TechCrunch they believe Cluely’s post-money valuation is around $120 million. Andreessen Horowitz declined to comment on that figure. Cluely CEO Roy Lee didn’t respond to a request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cluely’s new funding comes roughly two months after it raised $5.3 million&lt;strong&gt; &lt;/strong&gt;in seed funding co-led by Abstract Ventures and Susa Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was co-founded earlier this year by 21-year-old Roy Lee and Neel Shanmugam, who were suspended from Columbia University for developing an undetectable AI-powered tool called “Interview Coder” to help engineers cheat on technical interviews.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely is profitable, according to Lee’s multiple posts on X and podcast appearances.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee’s provocative social media presence and highly produced controversial videos have helped to draw attention and create brand awareness for Cluely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, for example, as TechCrunch previously reported, Cluely  published a slick but polarizing launch video of Lee using a hidden AI assistant to lie to a woman about his age, and even his knowledge of art, on a date at a fancy restaurant.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Earlier this week, Cluely was hoping to throw a large after-party following Y Combinator’s AI Startup School, a two-day event. But the police shut down the festivities after around 2,000 people tried to enter the venue, Lee told TechCrunch. After they arrived, he told TC, “We did some cleanup, but the drinks are all there waiting for the next party.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/cluely-a-startup-that-helps-cheat-on-everything-raises-15m-from-a16z/</guid><pubDate>Fri, 20 Jun 2025 21:06:19 +0000</pubDate></item><item><title>[NEW] Mira Murati’s Thinking Machines Lab closes on $2B at $10B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/mira-muratis-thinking-machines-lab-closes-on-2b-at-10b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2188124206.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thinking Machines Lab, the secretive AI startup founded by OpenAI’s former chief technology officer Mira Murati, has closed a $2 billion seed round, according to The Financial Times. The deal values the 6-month-old startup at $10 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s work remains unclear. The startup has leveraged Murati’s reputation and other high-profile AI researchers who have joined the team to attract investors in what could be the largest seed round in history. According to sources familiar with the deal cited by the FT, Andreessen Horowitz led the round, with participation from Sarah Guo’s Conviction Partners.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Murati left OpenAI last September after leading the development of some of the company’s most prominent AI products, including ChatGPT, DALL-E, and voice mode. Several of her former OpenAI colleagues have joined the new startup, including co-founder John Schulman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Murati is one of a handful of executives who left OpenAI after raising concerns about CEO Sam Altman’s leadership in 2023. When the board ousted Altman in November of that year, Murati served as interim CEO before Altman was quickly reinstated.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2188124206.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thinking Machines Lab, the secretive AI startup founded by OpenAI’s former chief technology officer Mira Murati, has closed a $2 billion seed round, according to The Financial Times. The deal values the 6-month-old startup at $10 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s work remains unclear. The startup has leveraged Murati’s reputation and other high-profile AI researchers who have joined the team to attract investors in what could be the largest seed round in history. According to sources familiar with the deal cited by the FT, Andreessen Horowitz led the round, with participation from Sarah Guo’s Conviction Partners.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Murati left OpenAI last September after leading the development of some of the company’s most prominent AI products, including ChatGPT, DALL-E, and voice mode. Several of her former OpenAI colleagues have joined the new startup, including co-founder John Schulman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Murati is one of a handful of executives who left OpenAI after raising concerns about CEO Sam Altman’s leadership in 2023. When the board ousted Altman in November of that year, Murati served as interim CEO before Altman was quickly reinstated.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/mira-muratis-thinking-machines-lab-closes-on-2b-at-10b-valuation/</guid><pubDate>Fri, 20 Jun 2025 21:59:33 +0000</pubDate></item></channel></rss>