<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 06 Feb 2026 18:55:18 +0000</lastBuildDate><item><title>[NEW] Top 7 best AI penetration testing companies in 2026 (AI News)</title><link>https://www.artificialintelligence-news.com/news/top-7-best-ai-penetration-testing-companies-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/burst-kUqqaRjJuw0-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Penetration testing has always existed to answer one practical concern: what actually happens when a motivated attacker targets a real system. For many years, that answer was produced through scoped engagements that reflected a relatively stable environment. Infrastructure changed slowly, access models were simpler, and most exposure could be traced back to application code or known vulnerabilities.&lt;/p&gt;&lt;p&gt;That operating reality does not exist. Modern environments are shaped by cloud services, identity platforms, APIs, SaaS integrations, and automation layers that evolve continuously. Exposure is introduced through configuration changes, permission drift, and workflow design as often as through code. As a result, security posture can shift materially without a single deployment.&lt;/p&gt;&lt;p&gt;Attackers have adapted accordingly. Reconnaissance is automated. Exploitation attempts are opportunistic and persistent. Weak signals are correlated in systems and chained together until progression becomes possible. In this context, penetration testing that remains static, time-boxed, or narrowly scoped struggles to reflect real risk.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-ai-penetration-testing-changes-the-role-of-offensive-security"&gt;How AI penetration testing changes the role of offensive security&lt;/h3&gt;&lt;p&gt;Traditional penetration testing was designed to surface weaknesses during a defined engagement window. That model assumed environments remained relatively stable between tests. In cloud-native and identity-centric architectures, this assumption does not hold.&lt;/p&gt;&lt;p&gt;AI penetration testing operates as a persistent control not a scheduled activity. Platforms reassess attack surfaces as infrastructure, permissions, and integrations change. This lets security teams detect newly introduced exposure without waiting for the next assessment cycle.&lt;/p&gt;&lt;p&gt;As a result, offensive security shifts from a reporting function into a validation mechanism that supports day-to-day risk management.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-top-7-best-ai-penetration-testing-companies"&gt;The top 7 best AI penetration testing companies&lt;/h3&gt;&lt;p id="h-1-novee"&gt;&lt;strong&gt;1. Novee&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Novee is an AI-native penetration testing company focused on autonomous attacker simulation in modern enterprise environments. The platform is designed to continuously validate real attack paths and not produce static reports.&lt;/p&gt;&lt;p&gt;Novee models the full attack lifecycle, including reconnaissance, exploit validation, lateral movement, and privilege escalation. Its AI agents adapt their behaviour based on environmental feedback, abandoning ineffective paths and prioritising those that lead to impact. This results in fewer findings with higher confidence.&lt;/p&gt;&lt;p&gt;The platform is particularly effective in cloud-native and identity-heavy environments where exposure changes frequently. Continuous reassessment ensures that risk is tracked as systems evolve, not frozen at the moment of a test.&lt;/p&gt;&lt;p&gt;Novee is often used as a validation layer to support prioritisation and confirm that remediation efforts actually reduce exposure.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Autonomous attacker simulation with adaptive logic&lt;/li&gt;&lt;li&gt;Continuous attack surface reassessment&lt;/li&gt;&lt;li&gt;Validated attack-path discovery&lt;/li&gt;&lt;li&gt;Prioritisation based on real progression&lt;/li&gt;&lt;li&gt;Retesting to confirm remediation effectiveness&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-2-harmony-intelligence"&gt;&lt;strong&gt;2. Harmony Intelligence&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Harmony Intelligence focuses on AI-driven security testing with an emphasis on understanding how complex systems behave under adversarial conditions. The platform is designed to surface weaknesses that emerge from interactions between components not from isolated vulnerabilities.&lt;/p&gt;&lt;p&gt;Its approach is particularly relevant for organisations running interconnected services and automated workflows. Harmony Intelligence evaluates how attackers could exploit logic gaps, misconfigurations, and trust relationships in systems.&lt;/p&gt;&lt;p&gt;The platform emphasises interpretability. Findings are presented in a way that explains why progression was possible, which helps teams understand and address root causes not symptoms.&lt;/p&gt;&lt;p&gt;Harmony Intelligence is often adopted by organisations seeking deeper insight into systemic risk, not surface-level exposure.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;AI-driven testing of complex system interactions&lt;/li&gt;&lt;li&gt;Focus on logic and workflow exploitation&lt;/li&gt;&lt;li&gt;Clear contextual explanation of findings&lt;/li&gt;&lt;li&gt;Support for remediation prioritisation&lt;/li&gt;&lt;li&gt;Designed for interconnected enterprise environments&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-3-runsybil"&gt;&lt;strong&gt;3. RunSybil&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RunSybil is positioned around autonomous penetration testing with a strong emphasis on behavioural realism. The platform simulates how attackers operate over time, including persistence and adaptation.&lt;/p&gt;&lt;p&gt;Rather than executing predefined attack chains, RunSybil evaluates which actions produce meaningful access and adjusts accordingly. This makes it effective at identifying subtle paths that emerge from configuration drift or weak segmentation.&lt;/p&gt;&lt;p&gt;RunSybil is frequently used in environments where traditional testing produces large volumes of low-value findings. Its validation-first approach helps teams focus on paths that represent genuine exposure.&lt;/p&gt;&lt;p&gt;The platform supports continuous execution and retesting, letting security teams measure improvement not rely on static assessments.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Behaviour-driven autonomous testing&lt;/li&gt;&lt;li&gt;Focus on progression and persistence&lt;/li&gt;&lt;li&gt;Reduced noise through validation&lt;/li&gt;&lt;li&gt;Continuous execution model&lt;/li&gt;&lt;li&gt;Measurement of remediation impact&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-4-mindgard"&gt;&lt;strong&gt;4. Mindgard&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Mindgard specialises in adversarial testing of AI systems and AI-enabled workflows. Its platform evaluates how AI components behave under malicious or unexpected input, including manipulation, leakage, and unsafe decision paths.&lt;/p&gt;&lt;p&gt;The focus is increasingly important as AI becomes embedded in business-important processes. Failures often stem from logic and interaction effects, not traditional vulnerabilities.&lt;/p&gt;&lt;p&gt;Mindgard’s testing approach is proactive. It is designed to surface weaknesses before deployment and to support iterative improvement as systems evolve.&lt;/p&gt;&lt;p&gt;Organisations adopting Mindgard typically view AI as a distinct security surface that requires dedicated validation beyond infrastructure testing.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Adversarial testing of AI and ML systems&lt;/li&gt;&lt;li&gt;Focus on logic, behaviour, and misuse&lt;/li&gt;&lt;li&gt;Pre-deployment and continuous testing support&lt;/li&gt;&lt;li&gt;Engineering-actionable findings&lt;/li&gt;&lt;li&gt;Designed for AI-enabled workflows&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-5-mend"&gt;&lt;strong&gt;5. Mend&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Mend approaches AI penetration testing from a broader application security perspective. The platform integrates testing, analysis, and remediation support in the software lifecycle.&lt;/p&gt;&lt;p&gt;Its strength lies in correlating findings in code, dependencies, and runtime behaviour. This helps teams understand how vulnerabilities and misconfigurations interact, not treating them in isolation.&lt;/p&gt;&lt;p&gt;Mend is often used by organisations that want AI-assisted validation embedded into existing AppSec workflows. Its approach emphasises practicality and scalability over deep autonomous simulation.&lt;/p&gt;&lt;p&gt;The platform fits well in environments where development velocity is high and security controls must integrate seamlessly.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;AI-assisted application security testing&lt;/li&gt;&lt;li&gt;Correlation in multiple risk sources&lt;/li&gt;&lt;li&gt;Integration with development workflows&lt;/li&gt;&lt;li&gt;Emphasis on remediation efficiency&lt;/li&gt;&lt;li&gt;Scalable in large codebases&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-6-synack"&gt;&lt;strong&gt;6. Synack&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Synack combines human expertise with automation to deliver penetration testing at scale. Its model emphasises trusted researchers operating in controlled environments.&lt;/p&gt;&lt;p&gt;While not purely autonomous, Synack incorporates AI and automation to manage scope, triage findings, and support continuous testing. The hybrid approach balances creativity with operational consistency.&lt;/p&gt;&lt;p&gt;Synack is often chosen for high-risk systems where human judgement remains critical. Its platform supports ongoing testing not one-off engagements.&lt;/p&gt;&lt;p&gt;The combination of vetted talent and structured workflows makes Synack suitable for regulated and mission-important environments.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Hybrid model combining humans and automation&lt;/li&gt;&lt;li&gt;Trusted researcher network&lt;/li&gt;&lt;li&gt;Continuous testing ability&lt;/li&gt;&lt;li&gt;Strong governance and control&lt;/li&gt;&lt;li&gt;Suitable for high-assurance environments&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-7-hackerone"&gt;&lt;strong&gt;7. HackerOne&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HackerOne is best known for its bug bounty platform, but it also plays a role in modern penetration testing strategies. Its strength lies in scale and diversity of attacker perspectives.&lt;/p&gt;&lt;p&gt;The platform lets organisations to continuously test systems through managed programmes with structured disclosure and remediation workflows. While not autonomous in the AI sense, HackerOne increasingly incorporates automation and analytics support prioritisation.&lt;/p&gt;&lt;p&gt;HackerOne is often used with AI pentesting tools not as a replacement. It provides exposure to creative attack techniques that automated systems may not uncover.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Large global researcher community&lt;/li&gt;&lt;li&gt;Continuous testing through managed programmes&lt;/li&gt;&lt;li&gt;Structured disclosure and remediation&lt;/li&gt;&lt;li&gt;Automation to support triage and prioritisation&lt;/li&gt;&lt;li&gt;Complementary to AI-driven testing&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-how-enterprises-use-ai-penetration-testing-in-practice"&gt;How enterprises use AI penetration testing in practice&lt;/h3&gt;&lt;p&gt;AI penetration testing is most effective when used as part of a layered security strategy. It rarely replaces other controls outright. Instead, it fills a validation gap that scanners and preventive tools cannot address alone.&lt;/p&gt;&lt;p&gt;A common enterprise pattern includes:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Vulnerability scanners for detection coverage&lt;/li&gt;&lt;li&gt;Preventive controls for baseline hygiene&lt;/li&gt;&lt;li&gt;AI penetration testing for continuous validation&lt;/li&gt;&lt;li&gt;Manual pentests for deep, creative exploration&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this model, AI pentesting serves as the connective tissue. It determines which detected issues matter in practice, validates remediation effectiveness, and highlights where assumptions break down.&lt;/p&gt;&lt;p&gt;Organisations adopting this approach often report clearer prioritisation, faster remediation cycles, and more meaningful security metrics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-of-security-teams-with-ai-penetration-testing"&gt;The future of security teams with ai penetration testing&lt;/h3&gt;&lt;p&gt;The impact of this new wave of offensive security has been transformative for the security workforce. Instead of being bogged down by repetitive vulnerability finding and retesting, security specialists can focus on incident response, proactive defense strategies, and risk mitigation. Developers get actionable reports and automated tickets, closing issues early and reducing burnout. Executives gain real-time assurance that risk is being managed every hour of every day.&lt;/p&gt;&lt;p&gt;AI-powered pentesting, when operationalised well, fundamentally improves business agility, reduces breach risk, and helps organisations meet the demands of partners, customers, and regulators who are paying closer attention to security than ever before.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/burst-kUqqaRjJuw0-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Penetration testing has always existed to answer one practical concern: what actually happens when a motivated attacker targets a real system. For many years, that answer was produced through scoped engagements that reflected a relatively stable environment. Infrastructure changed slowly, access models were simpler, and most exposure could be traced back to application code or known vulnerabilities.&lt;/p&gt;&lt;p&gt;That operating reality does not exist. Modern environments are shaped by cloud services, identity platforms, APIs, SaaS integrations, and automation layers that evolve continuously. Exposure is introduced through configuration changes, permission drift, and workflow design as often as through code. As a result, security posture can shift materially without a single deployment.&lt;/p&gt;&lt;p&gt;Attackers have adapted accordingly. Reconnaissance is automated. Exploitation attempts are opportunistic and persistent. Weak signals are correlated in systems and chained together until progression becomes possible. In this context, penetration testing that remains static, time-boxed, or narrowly scoped struggles to reflect real risk.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-ai-penetration-testing-changes-the-role-of-offensive-security"&gt;How AI penetration testing changes the role of offensive security&lt;/h3&gt;&lt;p&gt;Traditional penetration testing was designed to surface weaknesses during a defined engagement window. That model assumed environments remained relatively stable between tests. In cloud-native and identity-centric architectures, this assumption does not hold.&lt;/p&gt;&lt;p&gt;AI penetration testing operates as a persistent control not a scheduled activity. Platforms reassess attack surfaces as infrastructure, permissions, and integrations change. This lets security teams detect newly introduced exposure without waiting for the next assessment cycle.&lt;/p&gt;&lt;p&gt;As a result, offensive security shifts from a reporting function into a validation mechanism that supports day-to-day risk management.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-top-7-best-ai-penetration-testing-companies"&gt;The top 7 best AI penetration testing companies&lt;/h3&gt;&lt;p id="h-1-novee"&gt;&lt;strong&gt;1. Novee&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Novee is an AI-native penetration testing company focused on autonomous attacker simulation in modern enterprise environments. The platform is designed to continuously validate real attack paths and not produce static reports.&lt;/p&gt;&lt;p&gt;Novee models the full attack lifecycle, including reconnaissance, exploit validation, lateral movement, and privilege escalation. Its AI agents adapt their behaviour based on environmental feedback, abandoning ineffective paths and prioritising those that lead to impact. This results in fewer findings with higher confidence.&lt;/p&gt;&lt;p&gt;The platform is particularly effective in cloud-native and identity-heavy environments where exposure changes frequently. Continuous reassessment ensures that risk is tracked as systems evolve, not frozen at the moment of a test.&lt;/p&gt;&lt;p&gt;Novee is often used as a validation layer to support prioritisation and confirm that remediation efforts actually reduce exposure.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Autonomous attacker simulation with adaptive logic&lt;/li&gt;&lt;li&gt;Continuous attack surface reassessment&lt;/li&gt;&lt;li&gt;Validated attack-path discovery&lt;/li&gt;&lt;li&gt;Prioritisation based on real progression&lt;/li&gt;&lt;li&gt;Retesting to confirm remediation effectiveness&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-2-harmony-intelligence"&gt;&lt;strong&gt;2. Harmony Intelligence&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Harmony Intelligence focuses on AI-driven security testing with an emphasis on understanding how complex systems behave under adversarial conditions. The platform is designed to surface weaknesses that emerge from interactions between components not from isolated vulnerabilities.&lt;/p&gt;&lt;p&gt;Its approach is particularly relevant for organisations running interconnected services and automated workflows. Harmony Intelligence evaluates how attackers could exploit logic gaps, misconfigurations, and trust relationships in systems.&lt;/p&gt;&lt;p&gt;The platform emphasises interpretability. Findings are presented in a way that explains why progression was possible, which helps teams understand and address root causes not symptoms.&lt;/p&gt;&lt;p&gt;Harmony Intelligence is often adopted by organisations seeking deeper insight into systemic risk, not surface-level exposure.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;AI-driven testing of complex system interactions&lt;/li&gt;&lt;li&gt;Focus on logic and workflow exploitation&lt;/li&gt;&lt;li&gt;Clear contextual explanation of findings&lt;/li&gt;&lt;li&gt;Support for remediation prioritisation&lt;/li&gt;&lt;li&gt;Designed for interconnected enterprise environments&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-3-runsybil"&gt;&lt;strong&gt;3. RunSybil&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;RunSybil is positioned around autonomous penetration testing with a strong emphasis on behavioural realism. The platform simulates how attackers operate over time, including persistence and adaptation.&lt;/p&gt;&lt;p&gt;Rather than executing predefined attack chains, RunSybil evaluates which actions produce meaningful access and adjusts accordingly. This makes it effective at identifying subtle paths that emerge from configuration drift or weak segmentation.&lt;/p&gt;&lt;p&gt;RunSybil is frequently used in environments where traditional testing produces large volumes of low-value findings. Its validation-first approach helps teams focus on paths that represent genuine exposure.&lt;/p&gt;&lt;p&gt;The platform supports continuous execution and retesting, letting security teams measure improvement not rely on static assessments.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Behaviour-driven autonomous testing&lt;/li&gt;&lt;li&gt;Focus on progression and persistence&lt;/li&gt;&lt;li&gt;Reduced noise through validation&lt;/li&gt;&lt;li&gt;Continuous execution model&lt;/li&gt;&lt;li&gt;Measurement of remediation impact&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-4-mindgard"&gt;&lt;strong&gt;4. Mindgard&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Mindgard specialises in adversarial testing of AI systems and AI-enabled workflows. Its platform evaluates how AI components behave under malicious or unexpected input, including manipulation, leakage, and unsafe decision paths.&lt;/p&gt;&lt;p&gt;The focus is increasingly important as AI becomes embedded in business-important processes. Failures often stem from logic and interaction effects, not traditional vulnerabilities.&lt;/p&gt;&lt;p&gt;Mindgard’s testing approach is proactive. It is designed to surface weaknesses before deployment and to support iterative improvement as systems evolve.&lt;/p&gt;&lt;p&gt;Organisations adopting Mindgard typically view AI as a distinct security surface that requires dedicated validation beyond infrastructure testing.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Adversarial testing of AI and ML systems&lt;/li&gt;&lt;li&gt;Focus on logic, behaviour, and misuse&lt;/li&gt;&lt;li&gt;Pre-deployment and continuous testing support&lt;/li&gt;&lt;li&gt;Engineering-actionable findings&lt;/li&gt;&lt;li&gt;Designed for AI-enabled workflows&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-5-mend"&gt;&lt;strong&gt;5. Mend&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Mend approaches AI penetration testing from a broader application security perspective. The platform integrates testing, analysis, and remediation support in the software lifecycle.&lt;/p&gt;&lt;p&gt;Its strength lies in correlating findings in code, dependencies, and runtime behaviour. This helps teams understand how vulnerabilities and misconfigurations interact, not treating them in isolation.&lt;/p&gt;&lt;p&gt;Mend is often used by organisations that want AI-assisted validation embedded into existing AppSec workflows. Its approach emphasises practicality and scalability over deep autonomous simulation.&lt;/p&gt;&lt;p&gt;The platform fits well in environments where development velocity is high and security controls must integrate seamlessly.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;AI-assisted application security testing&lt;/li&gt;&lt;li&gt;Correlation in multiple risk sources&lt;/li&gt;&lt;li&gt;Integration with development workflows&lt;/li&gt;&lt;li&gt;Emphasis on remediation efficiency&lt;/li&gt;&lt;li&gt;Scalable in large codebases&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-6-synack"&gt;&lt;strong&gt;6. Synack&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Synack combines human expertise with automation to deliver penetration testing at scale. Its model emphasises trusted researchers operating in controlled environments.&lt;/p&gt;&lt;p&gt;While not purely autonomous, Synack incorporates AI and automation to manage scope, triage findings, and support continuous testing. The hybrid approach balances creativity with operational consistency.&lt;/p&gt;&lt;p&gt;Synack is often chosen for high-risk systems where human judgement remains critical. Its platform supports ongoing testing not one-off engagements.&lt;/p&gt;&lt;p&gt;The combination of vetted talent and structured workflows makes Synack suitable for regulated and mission-important environments.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Hybrid model combining humans and automation&lt;/li&gt;&lt;li&gt;Trusted researcher network&lt;/li&gt;&lt;li&gt;Continuous testing ability&lt;/li&gt;&lt;li&gt;Strong governance and control&lt;/li&gt;&lt;li&gt;Suitable for high-assurance environments&lt;/li&gt;&lt;/ul&gt;&lt;p id="h-7-hackerone"&gt;&lt;strong&gt;7. HackerOne&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;HackerOne is best known for its bug bounty platform, but it also plays a role in modern penetration testing strategies. Its strength lies in scale and diversity of attacker perspectives.&lt;/p&gt;&lt;p&gt;The platform lets organisations to continuously test systems through managed programmes with structured disclosure and remediation workflows. While not autonomous in the AI sense, HackerOne increasingly incorporates automation and analytics support prioritisation.&lt;/p&gt;&lt;p&gt;HackerOne is often used with AI pentesting tools not as a replacement. It provides exposure to creative attack techniques that automated systems may not uncover.&lt;/p&gt;&lt;p&gt;Key characteristics:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Large global researcher community&lt;/li&gt;&lt;li&gt;Continuous testing through managed programmes&lt;/li&gt;&lt;li&gt;Structured disclosure and remediation&lt;/li&gt;&lt;li&gt;Automation to support triage and prioritisation&lt;/li&gt;&lt;li&gt;Complementary to AI-driven testing&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-how-enterprises-use-ai-penetration-testing-in-practice"&gt;How enterprises use AI penetration testing in practice&lt;/h3&gt;&lt;p&gt;AI penetration testing is most effective when used as part of a layered security strategy. It rarely replaces other controls outright. Instead, it fills a validation gap that scanners and preventive tools cannot address alone.&lt;/p&gt;&lt;p&gt;A common enterprise pattern includes:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Vulnerability scanners for detection coverage&lt;/li&gt;&lt;li&gt;Preventive controls for baseline hygiene&lt;/li&gt;&lt;li&gt;AI penetration testing for continuous validation&lt;/li&gt;&lt;li&gt;Manual pentests for deep, creative exploration&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this model, AI pentesting serves as the connective tissue. It determines which detected issues matter in practice, validates remediation effectiveness, and highlights where assumptions break down.&lt;/p&gt;&lt;p&gt;Organisations adopting this approach often report clearer prioritisation, faster remediation cycles, and more meaningful security metrics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-of-security-teams-with-ai-penetration-testing"&gt;The future of security teams with ai penetration testing&lt;/h3&gt;&lt;p&gt;The impact of this new wave of offensive security has been transformative for the security workforce. Instead of being bogged down by repetitive vulnerability finding and retesting, security specialists can focus on incident response, proactive defense strategies, and risk mitigation. Developers get actionable reports and automated tickets, closing issues early and reducing burnout. Executives gain real-time assurance that risk is being managed every hour of every day.&lt;/p&gt;&lt;p&gt;AI-powered pentesting, when operationalised well, fundamentally improves business agility, reduces breach risk, and helps organisations meet the demands of partners, customers, and regulators who are paying closer attention to security than ever before.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/top-7-best-ai-penetration-testing-companies-in-2026/</guid><pubDate>Fri, 06 Feb 2026 08:00:00 +0000</pubDate></item><item><title>[NEW] SuperCool review: Evaluating the reality of autonomous creation (AI News)</title><link>https://www.artificialintelligence-news.com/news/supercool-review-evaluating-the-reality-of-autonomous-creation/</link><description>&lt;p&gt;In the current landscape of generative artificial intelligence, we have reached a saturation point with assistants. Most users are familiar with the routine. You prompt a tool, it provides a draft, and then you spend the next hour manually moving that output into another application for formatting, design, or distribution. AI promised to save time, yet the tool hop remains a bottleneck for founders and creative teams.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112036" height="614" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-1024x614.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;SuperCool enters this crowded market with an importantly different value proposition. It does not want to be your assistant. It wants to be your execution partner. By positioning itself at the execution layer of creative projects, SuperCool aims to bridge the gap between a raw idea and a finished, downloadable asset without requiring the user to leave the platform.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-the-creative-workflow"&gt;Redefining the creative workflow&lt;/h3&gt;&lt;p&gt;The core philosophy behind SuperCool is to remove coordination overhead. For most businesses, creating a high-quality asset, whether it is a pitch deck, a marketing video, or a research report, requires a patchwork approach. You might use one AI for text, another for images, and a third for layout. SuperCool replaces this fragmented stack with a unified system of autonomous agents that work in concert.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112037" height="605" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-1-1024x605.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;As seen in the primary dashboard interface, the platform presents a clean, minimalist entry point. The user is greeted with a simple directive: “Give SuperCool a task to work on…”. The simplicity belies the complexity occurring under the hood. Unlike traditional tools that require you to navigate menus and settings, the SuperCool experience is driven entirely by natural language prompts.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-platform-operates-in-practice"&gt;How the platform operates in practice&lt;/h3&gt;&lt;p&gt;The workflow begins with a natural-language prompt that describes the desired outcome, the intended audience, and any specific constraints. One of the most impressive features observed during this review is the transparency of the agentic process.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112038" height="358" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-2-1024x358.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;When a user submits a request, for instance, “create a pitch deck for my B2B business,” the platform does not just return a file a few minutes later. Instead, it breaks the project down into logical milestones that the user can monitor in real time.&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Strategic planning&lt;/strong&gt;: The AI first outlines the project structure, like the presentation flow.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asset generation&lt;/strong&gt;: It then generates relevant visuals and data visualisations tailored to the specific industry context.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Final assembly&lt;/strong&gt;: The system designs the complete deck, ensuring cohesive styling and professional layouts.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Visibility is crucial for trust. It allows the user to see that the AI is performing research and organising content not just hallucinating a generic response. The final result is a professional, multi-slide product, often featuring 10 or more professionally designed slides, delivered as an exportable file like a PPTX.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-versatility-across-use-cases"&gt;Versatility across use cases&lt;/h3&gt;&lt;p&gt;SuperCool’s utility is most apparent in scenarios where speed and coverage are more valuable than pixel-perfect manual control. We observed three primary areas where the platform excels:&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-end-to-end-content-creation"&gt;End-to-end content creation&lt;/h3&gt;&lt;p&gt;For consultants and solo founders, the time saved on administrative creative tasks is immense. A consultant onboarding a new client can describe the engagement and instantly receive a welcome packet, a process overview, and a timeline visual.&lt;/p&gt;&lt;p&gt;Multi-format asset kits:&lt;/p&gt;&lt;p&gt;Perhaps the most powerful feature is the ability to generate different types of media from a single prompt. An HR team launching an employee handbook can request a kit that includes a PDF guide, a short video, and a presentation deck.&lt;/p&gt;&lt;p&gt;Production without specialists:&lt;/p&gt;&lt;p&gt;Small teams often face a production gap where they lack the budget for full-time designers or video editors. SuperCool effectively fills this gap, allowing a two-person team to produce branded graphics and videos without expanding headcount.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112039" height="657" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-3-1024x657.png" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-navigating-the-learning-curve"&gt;Navigating the learning curve&lt;/h3&gt;&lt;p&gt;While the platform is designed for ease of use, it is not a magic wand for those without a clear vision. The quality of the output is heavily dependent on the clarity of the initial prompt. Vague instructions will lead to generic results. SuperCool is built for professionals who know what they want but do not want to spend hours manually building it.&lt;/p&gt;&lt;p&gt;Because the system is autonomous, users have less mid-stream control. You cannot tweak a design element while the agents are working. Instead, refinement happens through iteration in the chat interface. If the first version is not perfect, you provide feedback, and the system regenerates the asset with those adjustments in mind.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape-assistant-vs-agent"&gt;The competitive landscape: Assistant vs.agent&lt;/h3&gt;&lt;p&gt;In the current AI ecosystem, most tools are categorised as assistants. They perform specific, isolated tasks, leaving the user responsible for overseeing the entire process. SuperCool represents the shift toward agentic AI, in which the system takes responsibility for the entire workflow.&lt;/p&gt;&lt;p&gt;The distinction is vital for enterprise contexts. While assistants require constant hand-holding, an agentic system like SuperCool allows the user to focus on high-level ideation and refinement. It moves the user from builder to director.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-final-assessment"&gt;Final assessment&lt;/h3&gt;&lt;p&gt;SuperCool is a compelling alternative for those who find the current tool-stack approach a drain on productivity. It is not necessarily a replacement for specialised creative software when a brand needs unique, handcrafted artistry. However, for the vast majority of business needs, where speed, consistency, and execution are paramount, it offers perhaps the shortest path from an idea to a finished product.&lt;/p&gt;&lt;p&gt;For founders and creative teams who value the ability to rapidly test ideas and deploy content without the overhead of specialised software, SuperCool is a step forward in the evolution of autonomous work.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;In the current landscape of generative artificial intelligence, we have reached a saturation point with assistants. Most users are familiar with the routine. You prompt a tool, it provides a draft, and then you spend the next hour manually moving that output into another application for formatting, design, or distribution. AI promised to save time, yet the tool hop remains a bottleneck for founders and creative teams.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112036" height="614" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-1024x614.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;SuperCool enters this crowded market with an importantly different value proposition. It does not want to be your assistant. It wants to be your execution partner. By positioning itself at the execution layer of creative projects, SuperCool aims to bridge the gap between a raw idea and a finished, downloadable asset without requiring the user to leave the platform.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-the-creative-workflow"&gt;Redefining the creative workflow&lt;/h3&gt;&lt;p&gt;The core philosophy behind SuperCool is to remove coordination overhead. For most businesses, creating a high-quality asset, whether it is a pitch deck, a marketing video, or a research report, requires a patchwork approach. You might use one AI for text, another for images, and a third for layout. SuperCool replaces this fragmented stack with a unified system of autonomous agents that work in concert.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112037" height="605" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-1-1024x605.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;As seen in the primary dashboard interface, the platform presents a clean, minimalist entry point. The user is greeted with a simple directive: “Give SuperCool a task to work on…”. The simplicity belies the complexity occurring under the hood. Unlike traditional tools that require you to navigate menus and settings, the SuperCool experience is driven entirely by natural language prompts.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-platform-operates-in-practice"&gt;How the platform operates in practice&lt;/h3&gt;&lt;p&gt;The workflow begins with a natural-language prompt that describes the desired outcome, the intended audience, and any specific constraints. One of the most impressive features observed during this review is the transparency of the agentic process.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112038" height="358" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-2-1024x358.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;When a user submits a request, for instance, “create a pitch deck for my B2B business,” the platform does not just return a file a few minutes later. Instead, it breaks the project down into logical milestones that the user can monitor in real time.&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Strategic planning&lt;/strong&gt;: The AI first outlines the project structure, like the presentation flow.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asset generation&lt;/strong&gt;: It then generates relevant visuals and data visualisations tailored to the specific industry context.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Final assembly&lt;/strong&gt;: The system designs the complete deck, ensuring cohesive styling and professional layouts.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Visibility is crucial for trust. It allows the user to see that the AI is performing research and organising content not just hallucinating a generic response. The final result is a professional, multi-slide product, often featuring 10 or more professionally designed slides, delivered as an exportable file like a PPTX.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-versatility-across-use-cases"&gt;Versatility across use cases&lt;/h3&gt;&lt;p&gt;SuperCool’s utility is most apparent in scenarios where speed and coverage are more valuable than pixel-perfect manual control. We observed three primary areas where the platform excels:&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-end-to-end-content-creation"&gt;End-to-end content creation&lt;/h3&gt;&lt;p&gt;For consultants and solo founders, the time saved on administrative creative tasks is immense. A consultant onboarding a new client can describe the engagement and instantly receive a welcome packet, a process overview, and a timeline visual.&lt;/p&gt;&lt;p&gt;Multi-format asset kits:&lt;/p&gt;&lt;p&gt;Perhaps the most powerful feature is the ability to generate different types of media from a single prompt. An HR team launching an employee handbook can request a kit that includes a PDF guide, a short video, and a presentation deck.&lt;/p&gt;&lt;p&gt;Production without specialists:&lt;/p&gt;&lt;p&gt;Small teams often face a production gap where they lack the budget for full-time designers or video editors. SuperCool effectively fills this gap, allowing a two-person team to produce branded graphics and videos without expanding headcount.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112039" height="657" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/image-3-1024x657.png" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-navigating-the-learning-curve"&gt;Navigating the learning curve&lt;/h3&gt;&lt;p&gt;While the platform is designed for ease of use, it is not a magic wand for those without a clear vision. The quality of the output is heavily dependent on the clarity of the initial prompt. Vague instructions will lead to generic results. SuperCool is built for professionals who know what they want but do not want to spend hours manually building it.&lt;/p&gt;&lt;p&gt;Because the system is autonomous, users have less mid-stream control. You cannot tweak a design element while the agents are working. Instead, refinement happens through iteration in the chat interface. If the first version is not perfect, you provide feedback, and the system regenerates the asset with those adjustments in mind.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape-assistant-vs-agent"&gt;The competitive landscape: Assistant vs.agent&lt;/h3&gt;&lt;p&gt;In the current AI ecosystem, most tools are categorised as assistants. They perform specific, isolated tasks, leaving the user responsible for overseeing the entire process. SuperCool represents the shift toward agentic AI, in which the system takes responsibility for the entire workflow.&lt;/p&gt;&lt;p&gt;The distinction is vital for enterprise contexts. While assistants require constant hand-holding, an agentic system like SuperCool allows the user to focus on high-level ideation and refinement. It moves the user from builder to director.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-final-assessment"&gt;Final assessment&lt;/h3&gt;&lt;p&gt;SuperCool is a compelling alternative for those who find the current tool-stack approach a drain on productivity. It is not necessarily a replacement for specialised creative software when a brand needs unique, handcrafted artistry. However, for the vast majority of business needs, where speed, consistency, and execution are paramount, it offers perhaps the shortest path from an idea to a finished product.&lt;/p&gt;&lt;p&gt;For founders and creative teams who value the ability to rapidly test ideas and deploy content without the overhead of specialised software, SuperCool is a step forward in the evolution of autonomous work.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/supercool-review-evaluating-the-reality-of-autonomous-creation/</guid><pubDate>Fri, 06 Feb 2026 08:00:00 +0000</pubDate></item><item><title>An experimental surgery is helping cancer survivors give birth (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/06/1132319/experimental-surgery-colorectal-cancer-survivors-pregnant-birth/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/stitch-in-time2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;This week I want to tell you about an experimental surgical procedure that’s helping people have babies. Specifically, it’s helping people who have had treatment for bowel or rectal cancer.&lt;/p&gt;  &lt;p&gt;Radiation and chemo can have pretty damaging side effects that mess up the uterus and ovaries. Surgeons are pioneering a potential solution: simply stitch those organs out of the way during cancer treatment. Once the treatment has finished, they can put the uterus—along with the ovaries and fallopian tubes—back into place.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;It seems to work!&amp;nbsp;Last week, a team in Switzerland shared news that a baby boy had been born after his mother had the procedure. Baby Lucien was the fifth baby to be born after the surgery and the first in Europe, says Daniela Huber, the gyno-oncologist who performed the operation. Since then, at least three others have been born, adds Reitan Ribeiro, the surgeon who pioneered the procedure. They told me the details.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Huber’s patient was 28 years old when a four-centimeter tumor was discovered in her rectum.&lt;/strong&gt; Doctors at Sion Hospital in Switzerland, where Huber works, recommended a course of treatment that included multiple medications and radiotherapy—the use of beams of energy to shrink a tumor—before surgery to remove the tumor itself.&lt;/p&gt; 
 &lt;p&gt;This kind of radiation can kill tumor cells, but it can also damage other organs in the pelvis, says Huber. That includes the ovaries and uterus. People who undergo these treatments can opt to freeze their eggs beforehand, but the harm caused to the uterus will mean they’ll never be able to carry a pregnancy, she adds. Damage to the lining of the uterus could make it difficult for a fertilized egg to implant there, and the muscles of the uterus are left unable to stretch, she says.&lt;/p&gt;  &lt;p&gt;In this case, the woman decided that she did want to freeze her eggs. But it would have been difficult to use them further down the line—surrogacy is illegal in Switzerland.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Huber offered her an alternative.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;She had been following the work of Ribeiro, a gynecologist oncologist formerly at the Erasto Gaertner Hospital in Curitiba, Brazil. There, Ribeiro had pioneered a new type of surgery that involved moving the uterus, fallopian tubes, and ovaries from their position in the pelvis and temporarily tucking them away in the upper abdomen, below the ribs.&lt;/p&gt;  &lt;p&gt;Ribeiro and his colleagues published&amp;nbsp;their first case report in 2017, describing a 26-year-old with a rectal tumor. (Ribeiro, who is now based at McGill University in Montreal, says the woman had been told by multiple doctors that her cancer treatment would destroy her fertility and had pleaded with him to find a way to preserve it.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Huber remembers seeing Ribeiro present the case at a conference at the time. She immediately realized that her own patient was a candidate for the surgery, and that, as a surgeon who had performed many hysterectomies, she’d be able to do it herself. The patient agreed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;&lt;strong&gt;Huber’s colleagues at the hospital were nervous, she says.&lt;/strong&gt; They’d never heard of the procedure before. “When I presented this idea to the general surgeon, he didn’t sleep for three days,” she tells me. After watching videos from Ribeiro’s team, however, he was convinced it was doable.&lt;/p&gt;  &lt;p&gt;So before the patient’s cancer treatment was started, Huber and her colleagues performed the operation. The team literally stitched the organs to the abdominal wall. “It’s a delicate dissection,” says Huber, but she adds that “it’s not the most difficult procedure.” The surgery took two to three hours, she says. The stitches themselves were removed via small incisions around a week later. By that point, scar tissue had formed to create a lasting attachment.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The woman had two weeks to recover from the surgery before her cancer treatment began.&lt;/strong&gt; That too was a success—within months, her tumor had shrunk so significantly that it couldn’t be seen on medical scans.&lt;/p&gt;  &lt;p&gt;As a precaution, the medical team surgically removed the affected area of her colon. At the same time, they cut away the scar tissue holding the uterus, tubes, and ovaries in their new position and transferred the organs back into the pelvis.&lt;/p&gt; 

 &lt;p&gt;Around eight months later, the woman stopped taking contraception. She got pregnant without IVF and had a mostly healthy pregnancy, says Huber. Around seven months into the pregnancy, there were signs that the fetus was not growing as expected. This might have been due to problems with the blood supply to the placenta, says Huber. Still, the baby was born healthy, she says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt;&lt;p&gt;&lt;strong&gt;Ribeiro says he has performed the surgery 16 times&lt;/strong&gt;, and that teams in countries including the US, Peru, Israel, India, and Russia have performed it as well. Not every case has been published, but he thinks there may be around 40.&lt;/p&gt;  &lt;p&gt;Since Baby Lucien was born last year, a sixth birth has been announced in Israel, says Huber. Ribeiro says he has heard of another two births since then, too. The most recent was to the first woman who had the procedure. She had a little girl a few months ago, he tells me.&lt;/p&gt;  &lt;p&gt;No surgery is risk-free, and Huber points out there’s a chance that organs could be damaged during the procedure, or that a more developed cancer could spread. The uterus of one of Ribeiro’s patients failed following the surgery. Doctors are “still in the phase of collecting data to [create] a standardized procedure,” Huber says, but she hopes the surgery will offer more options to young people with some pelvic cancers. “I hope more young women could benefit from this procedure,” she says.&lt;/p&gt;  &lt;p&gt;Ribeiro says the experience has taught him not to accept the status quo. “Everyone was saying … there was nothing to be done [about the loss of fertility in these cases],” he tells me. “We need to keep evolving and looking for different answers.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/stitch-in-time2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;This week I want to tell you about an experimental surgical procedure that’s helping people have babies. Specifically, it’s helping people who have had treatment for bowel or rectal cancer.&lt;/p&gt;  &lt;p&gt;Radiation and chemo can have pretty damaging side effects that mess up the uterus and ovaries. Surgeons are pioneering a potential solution: simply stitch those organs out of the way during cancer treatment. Once the treatment has finished, they can put the uterus—along with the ovaries and fallopian tubes—back into place.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;It seems to work!&amp;nbsp;Last week, a team in Switzerland shared news that a baby boy had been born after his mother had the procedure. Baby Lucien was the fifth baby to be born after the surgery and the first in Europe, says Daniela Huber, the gyno-oncologist who performed the operation. Since then, at least three others have been born, adds Reitan Ribeiro, the surgeon who pioneered the procedure. They told me the details.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Huber’s patient was 28 years old when a four-centimeter tumor was discovered in her rectum.&lt;/strong&gt; Doctors at Sion Hospital in Switzerland, where Huber works, recommended a course of treatment that included multiple medications and radiotherapy—the use of beams of energy to shrink a tumor—before surgery to remove the tumor itself.&lt;/p&gt; 
 &lt;p&gt;This kind of radiation can kill tumor cells, but it can also damage other organs in the pelvis, says Huber. That includes the ovaries and uterus. People who undergo these treatments can opt to freeze their eggs beforehand, but the harm caused to the uterus will mean they’ll never be able to carry a pregnancy, she adds. Damage to the lining of the uterus could make it difficult for a fertilized egg to implant there, and the muscles of the uterus are left unable to stretch, she says.&lt;/p&gt;  &lt;p&gt;In this case, the woman decided that she did want to freeze her eggs. But it would have been difficult to use them further down the line—surrogacy is illegal in Switzerland.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Huber offered her an alternative.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;She had been following the work of Ribeiro, a gynecologist oncologist formerly at the Erasto Gaertner Hospital in Curitiba, Brazil. There, Ribeiro had pioneered a new type of surgery that involved moving the uterus, fallopian tubes, and ovaries from their position in the pelvis and temporarily tucking them away in the upper abdomen, below the ribs.&lt;/p&gt;  &lt;p&gt;Ribeiro and his colleagues published&amp;nbsp;their first case report in 2017, describing a 26-year-old with a rectal tumor. (Ribeiro, who is now based at McGill University in Montreal, says the woman had been told by multiple doctors that her cancer treatment would destroy her fertility and had pleaded with him to find a way to preserve it.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Huber remembers seeing Ribeiro present the case at a conference at the time. She immediately realized that her own patient was a candidate for the surgery, and that, as a surgeon who had performed many hysterectomies, she’d be able to do it herself. The patient agreed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;&lt;strong&gt;Huber’s colleagues at the hospital were nervous, she says.&lt;/strong&gt; They’d never heard of the procedure before. “When I presented this idea to the general surgeon, he didn’t sleep for three days,” she tells me. After watching videos from Ribeiro’s team, however, he was convinced it was doable.&lt;/p&gt;  &lt;p&gt;So before the patient’s cancer treatment was started, Huber and her colleagues performed the operation. The team literally stitched the organs to the abdominal wall. “It’s a delicate dissection,” says Huber, but she adds that “it’s not the most difficult procedure.” The surgery took two to three hours, she says. The stitches themselves were removed via small incisions around a week later. By that point, scar tissue had formed to create a lasting attachment.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The woman had two weeks to recover from the surgery before her cancer treatment began.&lt;/strong&gt; That too was a success—within months, her tumor had shrunk so significantly that it couldn’t be seen on medical scans.&lt;/p&gt;  &lt;p&gt;As a precaution, the medical team surgically removed the affected area of her colon. At the same time, they cut away the scar tissue holding the uterus, tubes, and ovaries in their new position and transferred the organs back into the pelvis.&lt;/p&gt; 

 &lt;p&gt;Around eight months later, the woman stopped taking contraception. She got pregnant without IVF and had a mostly healthy pregnancy, says Huber. Around seven months into the pregnancy, there were signs that the fetus was not growing as expected. This might have been due to problems with the blood supply to the placenta, says Huber. Still, the baby was born healthy, she says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt;&lt;p&gt;&lt;strong&gt;Ribeiro says he has performed the surgery 16 times&lt;/strong&gt;, and that teams in countries including the US, Peru, Israel, India, and Russia have performed it as well. Not every case has been published, but he thinks there may be around 40.&lt;/p&gt;  &lt;p&gt;Since Baby Lucien was born last year, a sixth birth has been announced in Israel, says Huber. Ribeiro says he has heard of another two births since then, too. The most recent was to the first woman who had the procedure. She had a little girl a few months ago, he tells me.&lt;/p&gt;  &lt;p&gt;No surgery is risk-free, and Huber points out there’s a chance that organs could be damaged during the procedure, or that a more developed cancer could spread. The uterus of one of Ribeiro’s patients failed following the surgery. Doctors are “still in the phase of collecting data to [create] a standardized procedure,” Huber says, but she hopes the surgery will offer more options to young people with some pelvic cancers. “I hope more young women could benefit from this procedure,” she says.&lt;/p&gt;  &lt;p&gt;Ribeiro says the experience has taught him not to accept the status quo. “Everyone was saying … there was nothing to be done [about the loss of fertility in these cases],” he tells me. “We need to keep evolving and looking for different answers.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/06/1132319/experimental-surgery-colorectal-cancer-survivors-pregnant-birth/</guid><pubDate>Fri, 06 Feb 2026 10:00:00 +0000</pubDate></item><item><title>Intuit, Uber, and State Farm trial AI agents inside enterprise workflows (AI News)</title><link>https://www.artificialintelligence-news.com/news/intuit-uber-and-state-farm-trial-ai-agents-inside-enterprise-workflows/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Intuit-Uber-and-State-Farm-trial-AI-agents-inside-enterprise-workflows-scaled-e1770348149128.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The way large companies use artificial intelligence is changing. For years, AI in business meant experimenting with tools that could answer questions or help with small tasks. Now, some big enterprises are moving beyond tools to AI agents that can actually do practical work in systems and workflows.&lt;/p&gt;&lt;p&gt;This week, OpenAI introduced a new platform designed to help companies build and manage those kinds of AI agents at scale. A handful of large corporations in finance, insurance, mobility, and life sciences are among the first to start using it. That may signal that AI is ready to move from pilot to real operational role.&lt;/p&gt;&lt;h3&gt;From tools to agents&lt;/h3&gt;&lt;p&gt;The new platform, called Frontier, is meant to help companies deploy what are described as &lt;em&gt;AI coworkers&lt;/em&gt;. These are software agents that connect to corporate systems and carry out tasks inside them. The idea is to give the AI agents a shared understanding of how work happens in a company, so they can perform meaningful work reliably.&lt;/p&gt;&lt;p&gt;Rather than treating every task as a separate instance, Frontier is built so that AI agents function in the context of an organisation’s systems. OpenAI says its platform provides the same kinds of basics that people need at work: access to shared business context, onboarding, ways to learn from feedback, and permissions and boundaries.&lt;/p&gt;&lt;p&gt;Frontier also includes tools for security, auditing, and evaluation, so companies can monitor how agents perform and ensure they follow rules.&lt;/p&gt;&lt;h3&gt;Who’s using this now&lt;/h3&gt;&lt;p&gt;According to OpenAI’s posts, early adopters include Intuit, Uber, State Farm Insurance, Thermo Fisher Scientific, HP, and Oracle. Larger pilot programmes are also said to be under way at Cisco, T-Mobile, and Banco Bilbao Vizcaya Argentaria.&lt;/p&gt;&lt;p&gt;Having companies in different sectors test or adopt a new platform this early shows a move toward real-world application, not internal experimentation. These are firms have complex operations, heavy regulatory needs, and large customer bases, environments where AI tools must work reliably and safely if they are to be adopted beyond experiment.&lt;/p&gt;&lt;h3&gt;What executives are saying&lt;/h3&gt;&lt;p&gt;Direct quotes from executives and leaders involved in these moves give a sense of how companies view the change. On LinkedIn, a senior executive from Intuit commented on the company’s early adoption: “AI is moving from ‘tools that help’ to ‘agents that do.’ Proud Intuit is an early adopter of OpenAI Frontier as we build intelligent systems that remove friction, expand what people and small businesses can accomplish, and unlock new opportunities.”&lt;/p&gt;&lt;p&gt;OpenAI’s message to business customers emphasises that the company believes agents need more than raw model power; they need governance, context, and ways to operate inside business environments. As one comment on social media put it, the challenge isn’t the ability of the AI models anymore: it is the ability to integrate and manage them at scale.&lt;/p&gt;&lt;h3&gt;Why this matters for enterprises&lt;/h3&gt;&lt;p&gt;For end-user companies considering or already investing in AI, this points to a change in how they might use the technology. In the past few years, most enterprise AI work has focused on tasks like auto-tagging tickets, summarising documents, or generating content. Such applications were useful, but limited in scope, not connecting to the workflows and systems that run business processes.&lt;/p&gt;&lt;p&gt;AI agents are meant to close that gap. In principle, an agent can pull together data from multiple systems, reason about it, and act; whether that means updating records, running analyses, or triggering actions in tools.&lt;/p&gt;&lt;p&gt;This means AI could start to touch real workflow work not provide assistance. For example, instead of an AI drafting a reply to a customer complaint, it could open the ticket, gather relevant account data, propose a resolution, and update the customer record. This is a different kind of value proposition: Not saving time on a task, but letting software take on parts of the work.&lt;/p&gt;&lt;h3&gt;Real adoption has practical requirements&lt;/h3&gt;&lt;p&gt;The companies testing Frontier are not using it lightly as they’re organisations with compliance needs, data controls, and complex technology stacks. For an AI agent to function there, it has to be integrated with internal systems in a way that respects access rules and keeps human teams in the loop.&lt;/p&gt;&lt;p&gt;Connecting CRM, ERP, data warehouses, and ticketing systems is a long-standing challenge in enterprise IT. The promise of AI agents is that they can bridge these systems with a shared understanding of process and context. Whether that works in practice will depend on how well companies can govern and monitor these systems over time.&lt;/p&gt;&lt;p&gt;The early signs are that enterprises see enough potential to begin serious trials. For AI deployments to move beyond isolated pilots and become part of broader operations, this is a visible step.&lt;/p&gt;&lt;h3&gt;What comes next&lt;/h3&gt;&lt;p&gt;If early experiments succeed and spread, enterprise AI could look very different from earlier periods of AI tooling and automation. Instead of using AI to generate outputs for people to act on, companies could start relying on AI to carry out work directly under defined rules.&lt;/p&gt;&lt;p&gt;This will create new roles in addition to data scientists and AI engineers; governance specialists and execution leads will be needed who take responsibility for agents’ performance. There may be a future where AI agents become part of the everyday workflow for large organisations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Growtika)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI’s enterprise push: The hidden story behind AI’s sales race&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Intuit-Uber-and-State-Farm-trial-AI-agents-inside-enterprise-workflows-scaled-e1770348149128.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The way large companies use artificial intelligence is changing. For years, AI in business meant experimenting with tools that could answer questions or help with small tasks. Now, some big enterprises are moving beyond tools to AI agents that can actually do practical work in systems and workflows.&lt;/p&gt;&lt;p&gt;This week, OpenAI introduced a new platform designed to help companies build and manage those kinds of AI agents at scale. A handful of large corporations in finance, insurance, mobility, and life sciences are among the first to start using it. That may signal that AI is ready to move from pilot to real operational role.&lt;/p&gt;&lt;h3&gt;From tools to agents&lt;/h3&gt;&lt;p&gt;The new platform, called Frontier, is meant to help companies deploy what are described as &lt;em&gt;AI coworkers&lt;/em&gt;. These are software agents that connect to corporate systems and carry out tasks inside them. The idea is to give the AI agents a shared understanding of how work happens in a company, so they can perform meaningful work reliably.&lt;/p&gt;&lt;p&gt;Rather than treating every task as a separate instance, Frontier is built so that AI agents function in the context of an organisation’s systems. OpenAI says its platform provides the same kinds of basics that people need at work: access to shared business context, onboarding, ways to learn from feedback, and permissions and boundaries.&lt;/p&gt;&lt;p&gt;Frontier also includes tools for security, auditing, and evaluation, so companies can monitor how agents perform and ensure they follow rules.&lt;/p&gt;&lt;h3&gt;Who’s using this now&lt;/h3&gt;&lt;p&gt;According to OpenAI’s posts, early adopters include Intuit, Uber, State Farm Insurance, Thermo Fisher Scientific, HP, and Oracle. Larger pilot programmes are also said to be under way at Cisco, T-Mobile, and Banco Bilbao Vizcaya Argentaria.&lt;/p&gt;&lt;p&gt;Having companies in different sectors test or adopt a new platform this early shows a move toward real-world application, not internal experimentation. These are firms have complex operations, heavy regulatory needs, and large customer bases, environments where AI tools must work reliably and safely if they are to be adopted beyond experiment.&lt;/p&gt;&lt;h3&gt;What executives are saying&lt;/h3&gt;&lt;p&gt;Direct quotes from executives and leaders involved in these moves give a sense of how companies view the change. On LinkedIn, a senior executive from Intuit commented on the company’s early adoption: “AI is moving from ‘tools that help’ to ‘agents that do.’ Proud Intuit is an early adopter of OpenAI Frontier as we build intelligent systems that remove friction, expand what people and small businesses can accomplish, and unlock new opportunities.”&lt;/p&gt;&lt;p&gt;OpenAI’s message to business customers emphasises that the company believes agents need more than raw model power; they need governance, context, and ways to operate inside business environments. As one comment on social media put it, the challenge isn’t the ability of the AI models anymore: it is the ability to integrate and manage them at scale.&lt;/p&gt;&lt;h3&gt;Why this matters for enterprises&lt;/h3&gt;&lt;p&gt;For end-user companies considering or already investing in AI, this points to a change in how they might use the technology. In the past few years, most enterprise AI work has focused on tasks like auto-tagging tickets, summarising documents, or generating content. Such applications were useful, but limited in scope, not connecting to the workflows and systems that run business processes.&lt;/p&gt;&lt;p&gt;AI agents are meant to close that gap. In principle, an agent can pull together data from multiple systems, reason about it, and act; whether that means updating records, running analyses, or triggering actions in tools.&lt;/p&gt;&lt;p&gt;This means AI could start to touch real workflow work not provide assistance. For example, instead of an AI drafting a reply to a customer complaint, it could open the ticket, gather relevant account data, propose a resolution, and update the customer record. This is a different kind of value proposition: Not saving time on a task, but letting software take on parts of the work.&lt;/p&gt;&lt;h3&gt;Real adoption has practical requirements&lt;/h3&gt;&lt;p&gt;The companies testing Frontier are not using it lightly as they’re organisations with compliance needs, data controls, and complex technology stacks. For an AI agent to function there, it has to be integrated with internal systems in a way that respects access rules and keeps human teams in the loop.&lt;/p&gt;&lt;p&gt;Connecting CRM, ERP, data warehouses, and ticketing systems is a long-standing challenge in enterprise IT. The promise of AI agents is that they can bridge these systems with a shared understanding of process and context. Whether that works in practice will depend on how well companies can govern and monitor these systems over time.&lt;/p&gt;&lt;p&gt;The early signs are that enterprises see enough potential to begin serious trials. For AI deployments to move beyond isolated pilots and become part of broader operations, this is a visible step.&lt;/p&gt;&lt;h3&gt;What comes next&lt;/h3&gt;&lt;p&gt;If early experiments succeed and spread, enterprise AI could look very different from earlier periods of AI tooling and automation. Instead of using AI to generate outputs for people to act on, companies could start relying on AI to carry out work directly under defined rules.&lt;/p&gt;&lt;p&gt;This will create new roles in addition to data scientists and AI engineers; governance specialists and execution leads will be needed who take responsibility for agents’ performance. There may be a future where AI agents become part of the everyday workflow for large organisations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Growtika)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI’s enterprise push: The hidden story behind AI’s sales race&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/intuit-uber-and-state-farm-trial-ai-agents-inside-enterprise-workflows/</guid><pubDate>Fri, 06 Feb 2026 10:00:00 +0000</pubDate></item><item><title>Why Darren Aronofsky thought an AI-generated historical docudrama was a good idea (AI - Ars Technica)</title><link>https://arstechnica.com/features/2026/02/why-darren-aronofsky-thought-an-ai-generated-historical-docudrama-was-a-good-idea/</link><description>&lt;article class="double-column h-entry post-2139368 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-features tag-ai-video tag-darren-aaronofsky tag-deepmind tag-google-2 tag-hollywood tag-movies tag-primodial-soup tag-veo"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Production source says it takes “weeks” to produce just minutes of usable video.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1439" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/pitchfork.jpg" width="2557" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of critics reacting to the first episodes of "On This Day... 1776"

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, filmmaker Darren Aronofsky’s AI studio Primordial Soup and Time magazine released the first two episodes of &lt;em&gt;On This Day… 1776&lt;/em&gt;. The year-long series of short-form videos features short vignettes describing what happened on that day of the American Revolution 250 years ago, but it does so using “a variety of AI tools” to produce photorealistic scenes containing avatars of historical figures like George Washington, Thomas Paine, and Benjamin Franklin.&lt;/p&gt;
&lt;p&gt;In announcing the series, Time Studios President Ben Bitonti said the project provides “a glimpse at what thoughtful, creative, artist-led use of AI can look like—not replacing craft but expanding what’s possible and allowing storytellers to go places they simply couldn’t before.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The trailer for “On This Day… 1776.”

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Outside critics were decidedly less excited about the effort. The AV Club took the introductory episodes to task for “repetitive camera movements [and] waxen characters” that make for “an ugly look at American history.” CNET said that this “AI slop is ruining American history,” calling the videos a “hellish broth of machine-driven AI slop and bad human choices.” The Guardian lamented that the “once-lauded director of &lt;em&gt;Black Swan&lt;/em&gt; and &lt;em&gt;The Wrestler&lt;/em&gt; has drowned himself in AI slop,” calling the series “embarrassing,” “terrible,” and “ugly as sin.” I could go on.&lt;/p&gt;
&lt;p&gt;But this kind of initial reaction apparently hasn’t deterred Primordial Soup from its still-evolving efforts. A source close to the production, who requested anonymity to speak frankly about details of the series’ creation, told Ars that the quality of new episodes would improve as the team’s AI tools are refined throughout the year and as the team learns to better use them.&lt;/p&gt;
&lt;p&gt;“We’re going into this fully assuming that we have a lot to learn, that this process is gonna evolve, the tools we’re using are gonna evolve,” the source said. “We’re gonna make mistakes. We’re gonna learn a lot… we’re going to get better at it, [and] the technology will change. We’ll see how audiences are reacting to certain things, what works, what doesn’t work. It’s a huge experiment, really.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Not all AI&lt;/h2&gt;
&lt;p&gt;It’s important to note that &lt;em&gt;On This Day… 1776&lt;/em&gt;&amp;nbsp;is not fully crafted by AI. The script, for instance, was written by a team of writers overseen by Aronofsky’s longtime writing partners Ari Handel and Lucas Sussman, as noted by The Hollywood Reporter. That makes criticisms like the Guardian’s of “ChatGPT-sounding sloganeering” in the first episodes both somewhat misplaced and hilariously harsh.&lt;/p&gt;
&lt;p&gt;Our production source says the project was always conceived as a human-written effort and that the team behind it had long been planning and researching how to tell this kind of story. “I don’t think [they] even needed that kind of help or wanted that kind of [AI-powered writing] help,” they said. “We’ve all experimented with [AI-powered] writing and the chatbots out there, and you know what kind of quality you get out of that.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139381 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="631" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/image-2.png" width="1123" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What you see here is not a real human actor, but his lines were written and voiced by humans.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The producers also go out of their way to note that all the dialogue in the series is recorded directly by S&lt;span&gt;creen Actors Guild&lt;/span&gt; voice actors, not by AI facsimiles. While recently negotiated union rules might have something to do with that, our production source also said the AI-generated voices the team used for temp tracks were noticeably artificial and not ready for a professional production.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Humans are also directly responsible for the music, editing, sound mixing, visual effects, and color correction for the project, according to our source. The only place the “AI-powered tools” come into play is in the video itself, which is crafted with what the announcement calls a “combination of traditional filmmaking tools and emerging AI capabilities.”&lt;/p&gt;
&lt;p&gt;In practice, our source says, that means humans create storyboards, find visual references for locations and characters, and set up how they want shots to look. That information, along with the script, gets fed into an AI video generator that creates individual shots one at a time, to be stitched together and cleaned up by humans in traditional post-production.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That process takes the AI-generated cinema conversation one step beyond Ancestra, a short film Primordial Soup released last summer in association with Google DeepMind (which is not involved with the new project). There, AI tools were used to augment “live-action scenes with sequences generated by Veo.”&lt;/p&gt;
&lt;h2&gt;“Weeks” of prompting and re-prompting&lt;/h2&gt;
&lt;p&gt;In theory, having an AI model generate a scene in minutes might save a lot of time compared to traditional filmmaking—scouting locations, hiring actors, setting up cameras and sets, and the like. But our production source said the highly iterative process of generating and perfecting shots for &lt;em&gt;On This Day… 1776&lt;/em&gt; still takes “weeks” for each minutes-long video and that “more often than not, we’re pushing deadlines.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The first episode of &lt;em&gt;On this Day… 1776&lt;/em&gt; features a dramatic flag raising.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Even though the AI model is essentially animating photorealistic avatars, the source said the process is “more like live action filmmaking” because of the lack of fine-grained control over what the video model will generate. “You don’t know if you’re gonna get what you want on the first take or the 12th take or the 40th take,” the source said.&lt;/p&gt;
&lt;p&gt;While some shots take less time to get right than others, our source said the AI model rarely produces a perfect, screen-ready shot on the first try. And while some small issues in an AI-generated shot can be papered over in post-production with visual effects or careful editing, most of the time, the team has to go back and tell the model to generate a completely new video with small changes.&lt;/p&gt;
&lt;p&gt;“It still takes a lot of work, and it’s not necessarily because it’s wrong, per se, so much as trying to get the right control because you [might] want the light to land on the face in the right way to try to tell the story,” the source said. “We’re still, we’re still striving for the same amount of control that we always have [with live-action production] to really maximize the story and the emotion.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Quick shots and smaller budgets&lt;/h2&gt;
&lt;p&gt;Though video models have advanced since the days of the nightmarish clip of Will Smith eating spaghetti, hallucinations and nonsensical images are “still a problem” in producing &lt;em&gt;On This Day… 1776&lt;/em&gt;, according to our source. That’s one of the reasons the company decided to use a series of short-form videos rather than a full-length movie telling the same essential story.&lt;/p&gt;
&lt;p&gt;“It’s one thing to stay consistent within three minutes. It’s a lot harder and it takes a lot more work to stay consistent within two hours,” the source said. “I don’t know what the upper limit is now [but] the longer you get, the more things start to fall off.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1928055 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Stills from an AI-generated video of Will Smith eating spaghetti." class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/will_smith_spaghetti_hero.jpg" width="1200" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      We’ve come a long way from the circa-2023 videos of Will Smith eating spaghetti.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          chaindrop / Reddit

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Keeping individual shots short also allows for more control and fewer “reshoots” for an AI-animated production like this. “When you think about it, if you’re trying to create a 20-second clip, you have all these things that are happening, and if one of those things goes wrong in 20 seconds, you have to start over,” our source said. “And the chance of something going wrong in 20 seconds is pretty high. The chance of something going wrong in eight seconds is a lot lower.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;While our production source couldn’t give specifics on how much the team was spending to generate so much AI-modeled video, they did suggest that the process was still a good deal cheaper than filming a historical docudrama like this on location.&lt;/p&gt;
&lt;p&gt;“I mean, we could never achieve what we’re doing here for this amount of money, which I think is pretty clear when you watch this,” they said. In future episodes, the source promised, “you’ll see where there’s things that cameras just can’t even do” as a way to “make the most of that medium.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“Let’s see what we can do”&lt;/h2&gt;
&lt;p&gt;If you’ve been paying attention to how fast things have been moving with AI-generated video, you might think that AI models will soon be able to produce Hollywood-quality cinema with nothing but a simple prompt. But our source said that working on &lt;em&gt;On This Day… 1776&lt;/em&gt; highlights just how important it is for humans to still be in the loop on something like this.&lt;/p&gt;
&lt;p&gt;“Personally, I don’t think we’re ever gonna get there [replacing human editors],” he said. “We actually desperately need an editor. We need another set of eyes who can look at the cut and say, ‘If we get out of this shot a little early, then we can create a little bit of urgency. If we linger on this thing a little longer…’ You still really need that.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139399 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1439" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/aifranklinpaine.jpg" width="2559" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      AI Ben Franklin and AI Thomas Paine toast to the war propaganda effort.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;That could be good news for human editors. But &lt;em&gt;On This Day… 1776&lt;/em&gt; also suggests a world where on-screen (or even motion-captured) human actors &lt;em&gt;are&lt;/em&gt; fully replaced by AI-generated avatars. When I asked our source why the producers felt that AI was ready to take over that specifically human part of the film equation, though, the response surprised me.&lt;/p&gt;
&lt;p&gt;“I don’t know that we do know that, honestly,” they said. “I think we know that the technology is there to try. And I think as storytellers we’re really interested in using… all the different tools that we can to try to get our story across and to try to make audiences feel something.”&lt;/p&gt;
&lt;p&gt;“It’s not often that we have huge new tools like this,” the source continued. “I mean, it’s never happened in my lifetime. But when you do [get these new tools], you want to start playing with them… We have to try things in order to know if it works, if it doesn’t work.”&lt;/p&gt;
&lt;p&gt;“So, you know, we have the tools now. Let’s see what we can do.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ea80fc; background-color: #8e24aa;"&gt;&lt;span class="ars-avatar-letter"&gt;y&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              yumegaze
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            it's good that most of the production used real human effort; bare minimum, still. however, i don't think that this covers for the "AI" inconsistencies (or costs, for that matter). it's just not worth it. real human actors have micro-expressions, voice inflections and body movements that make up for most of the impact of a good performance. also, you can direct them to move and act exactly as you want. the "photo-realistic avatar" can't be directed, can't impart lived experiences and expertise to modify its performance, doesn't have emotions nor the ability to convincingly emulate them and is, overall, very inconsistent in its results. that's why i don't feel inclined to consume any content using "AI" actors.&lt;p&gt;i know that, ultimately, aronofsky's wish is to be able to not have to pay human actors, accommodate the working space to their necessities, dealing with human subjectivity that interfere with the work. i get that. i don't think it's cheaper to use "AI" instead of hiring actors now, but he's trying to build momentum for a future where that's the reality. i get that. certainly, "AI" as a tool has its place in the creative process, specially when it's being used by capable professionals. i get that. i hate it, but i get it. thing is, i live in the present. and the present kinda sucks. i treasure art, it's incredibly meaningful for me in ways i can't explain. now, i'm seeing artists being first in the chopping block to be replaced by ones and zeros, to save a few pennies for people who already have far too much. that's incredibly depressing. &lt;/p&gt;&lt;p&gt;tl;dr: "AI" can be useful, as any other tool, but why in the flying fuck am i only exposed to these brainless use cases instead of good shit? what a waste of time, resources and neurons.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-02-06T12:21:09+00:00"&gt;February 6, 2026 at 12:21 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2139368 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-features tag-ai-video tag-darren-aaronofsky tag-deepmind tag-google-2 tag-hollywood tag-movies tag-primodial-soup tag-veo"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Production source says it takes “weeks” to produce just minutes of usable video.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1439" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/pitchfork.jpg" width="2557" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of critics reacting to the first episodes of "On This Day... 1776"

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, filmmaker Darren Aronofsky’s AI studio Primordial Soup and Time magazine released the first two episodes of &lt;em&gt;On This Day… 1776&lt;/em&gt;. The year-long series of short-form videos features short vignettes describing what happened on that day of the American Revolution 250 years ago, but it does so using “a variety of AI tools” to produce photorealistic scenes containing avatars of historical figures like George Washington, Thomas Paine, and Benjamin Franklin.&lt;/p&gt;
&lt;p&gt;In announcing the series, Time Studios President Ben Bitonti said the project provides “a glimpse at what thoughtful, creative, artist-led use of AI can look like—not replacing craft but expanding what’s possible and allowing storytellers to go places they simply couldn’t before.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The trailer for “On This Day… 1776.”

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Outside critics were decidedly less excited about the effort. The AV Club took the introductory episodes to task for “repetitive camera movements [and] waxen characters” that make for “an ugly look at American history.” CNET said that this “AI slop is ruining American history,” calling the videos a “hellish broth of machine-driven AI slop and bad human choices.” The Guardian lamented that the “once-lauded director of &lt;em&gt;Black Swan&lt;/em&gt; and &lt;em&gt;The Wrestler&lt;/em&gt; has drowned himself in AI slop,” calling the series “embarrassing,” “terrible,” and “ugly as sin.” I could go on.&lt;/p&gt;
&lt;p&gt;But this kind of initial reaction apparently hasn’t deterred Primordial Soup from its still-evolving efforts. A source close to the production, who requested anonymity to speak frankly about details of the series’ creation, told Ars that the quality of new episodes would improve as the team’s AI tools are refined throughout the year and as the team learns to better use them.&lt;/p&gt;
&lt;p&gt;“We’re going into this fully assuming that we have a lot to learn, that this process is gonna evolve, the tools we’re using are gonna evolve,” the source said. “We’re gonna make mistakes. We’re gonna learn a lot… we’re going to get better at it, [and] the technology will change. We’ll see how audiences are reacting to certain things, what works, what doesn’t work. It’s a huge experiment, really.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Not all AI&lt;/h2&gt;
&lt;p&gt;It’s important to note that &lt;em&gt;On This Day… 1776&lt;/em&gt;&amp;nbsp;is not fully crafted by AI. The script, for instance, was written by a team of writers overseen by Aronofsky’s longtime writing partners Ari Handel and Lucas Sussman, as noted by The Hollywood Reporter. That makes criticisms like the Guardian’s of “ChatGPT-sounding sloganeering” in the first episodes both somewhat misplaced and hilariously harsh.&lt;/p&gt;
&lt;p&gt;Our production source says the project was always conceived as a human-written effort and that the team behind it had long been planning and researching how to tell this kind of story. “I don’t think [they] even needed that kind of help or wanted that kind of [AI-powered writing] help,” they said. “We’ve all experimented with [AI-powered] writing and the chatbots out there, and you know what kind of quality you get out of that.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139381 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="631" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/image-2.png" width="1123" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What you see here is not a real human actor, but his lines were written and voiced by humans.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The producers also go out of their way to note that all the dialogue in the series is recorded directly by S&lt;span&gt;creen Actors Guild&lt;/span&gt; voice actors, not by AI facsimiles. While recently negotiated union rules might have something to do with that, our production source also said the AI-generated voices the team used for temp tracks were noticeably artificial and not ready for a professional production.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Humans are also directly responsible for the music, editing, sound mixing, visual effects, and color correction for the project, according to our source. The only place the “AI-powered tools” come into play is in the video itself, which is crafted with what the announcement calls a “combination of traditional filmmaking tools and emerging AI capabilities.”&lt;/p&gt;
&lt;p&gt;In practice, our source says, that means humans create storyboards, find visual references for locations and characters, and set up how they want shots to look. That information, along with the script, gets fed into an AI video generator that creates individual shots one at a time, to be stitched together and cleaned up by humans in traditional post-production.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That process takes the AI-generated cinema conversation one step beyond Ancestra, a short film Primordial Soup released last summer in association with Google DeepMind (which is not involved with the new project). There, AI tools were used to augment “live-action scenes with sequences generated by Veo.”&lt;/p&gt;
&lt;h2&gt;“Weeks” of prompting and re-prompting&lt;/h2&gt;
&lt;p&gt;In theory, having an AI model generate a scene in minutes might save a lot of time compared to traditional filmmaking—scouting locations, hiring actors, setting up cameras and sets, and the like. But our production source said the highly iterative process of generating and perfecting shots for &lt;em&gt;On This Day… 1776&lt;/em&gt; still takes “weeks” for each minutes-long video and that “more often than not, we’re pushing deadlines.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The first episode of &lt;em&gt;On this Day… 1776&lt;/em&gt; features a dramatic flag raising.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Even though the AI model is essentially animating photorealistic avatars, the source said the process is “more like live action filmmaking” because of the lack of fine-grained control over what the video model will generate. “You don’t know if you’re gonna get what you want on the first take or the 12th take or the 40th take,” the source said.&lt;/p&gt;
&lt;p&gt;While some shots take less time to get right than others, our source said the AI model rarely produces a perfect, screen-ready shot on the first try. And while some small issues in an AI-generated shot can be papered over in post-production with visual effects or careful editing, most of the time, the team has to go back and tell the model to generate a completely new video with small changes.&lt;/p&gt;
&lt;p&gt;“It still takes a lot of work, and it’s not necessarily because it’s wrong, per se, so much as trying to get the right control because you [might] want the light to land on the face in the right way to try to tell the story,” the source said. “We’re still, we’re still striving for the same amount of control that we always have [with live-action production] to really maximize the story and the emotion.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Quick shots and smaller budgets&lt;/h2&gt;
&lt;p&gt;Though video models have advanced since the days of the nightmarish clip of Will Smith eating spaghetti, hallucinations and nonsensical images are “still a problem” in producing &lt;em&gt;On This Day… 1776&lt;/em&gt;, according to our source. That’s one of the reasons the company decided to use a series of short-form videos rather than a full-length movie telling the same essential story.&lt;/p&gt;
&lt;p&gt;“It’s one thing to stay consistent within three minutes. It’s a lot harder and it takes a lot more work to stay consistent within two hours,” the source said. “I don’t know what the upper limit is now [but] the longer you get, the more things start to fall off.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1928055 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Stills from an AI-generated video of Will Smith eating spaghetti." class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/will_smith_spaghetti_hero.jpg" width="1200" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      We’ve come a long way from the circa-2023 videos of Will Smith eating spaghetti.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          chaindrop / Reddit

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Keeping individual shots short also allows for more control and fewer “reshoots” for an AI-animated production like this. “When you think about it, if you’re trying to create a 20-second clip, you have all these things that are happening, and if one of those things goes wrong in 20 seconds, you have to start over,” our source said. “And the chance of something going wrong in 20 seconds is pretty high. The chance of something going wrong in eight seconds is a lot lower.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;While our production source couldn’t give specifics on how much the team was spending to generate so much AI-modeled video, they did suggest that the process was still a good deal cheaper than filming a historical docudrama like this on location.&lt;/p&gt;
&lt;p&gt;“I mean, we could never achieve what we’re doing here for this amount of money, which I think is pretty clear when you watch this,” they said. In future episodes, the source promised, “you’ll see where there’s things that cameras just can’t even do” as a way to “make the most of that medium.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“Let’s see what we can do”&lt;/h2&gt;
&lt;p&gt;If you’ve been paying attention to how fast things have been moving with AI-generated video, you might think that AI models will soon be able to produce Hollywood-quality cinema with nothing but a simple prompt. But our source said that working on &lt;em&gt;On This Day… 1776&lt;/em&gt; highlights just how important it is for humans to still be in the loop on something like this.&lt;/p&gt;
&lt;p&gt;“Personally, I don’t think we’re ever gonna get there [replacing human editors],” he said. “We actually desperately need an editor. We need another set of eyes who can look at the cut and say, ‘If we get out of this shot a little early, then we can create a little bit of urgency. If we linger on this thing a little longer…’ You still really need that.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139399 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1439" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/aifranklinpaine.jpg" width="2559" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      AI Ben Franklin and AI Thomas Paine toast to the war propaganda effort.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Primordial Soup

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;That could be good news for human editors. But &lt;em&gt;On This Day… 1776&lt;/em&gt; also suggests a world where on-screen (or even motion-captured) human actors &lt;em&gt;are&lt;/em&gt; fully replaced by AI-generated avatars. When I asked our source why the producers felt that AI was ready to take over that specifically human part of the film equation, though, the response surprised me.&lt;/p&gt;
&lt;p&gt;“I don’t know that we do know that, honestly,” they said. “I think we know that the technology is there to try. And I think as storytellers we’re really interested in using… all the different tools that we can to try to get our story across and to try to make audiences feel something.”&lt;/p&gt;
&lt;p&gt;“It’s not often that we have huge new tools like this,” the source continued. “I mean, it’s never happened in my lifetime. But when you do [get these new tools], you want to start playing with them… We have to try things in order to know if it works, if it doesn’t work.”&lt;/p&gt;
&lt;p&gt;“So, you know, we have the tools now. Let’s see what we can do.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ea80fc; background-color: #8e24aa;"&gt;&lt;span class="ars-avatar-letter"&gt;y&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              yumegaze
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            it's good that most of the production used real human effort; bare minimum, still. however, i don't think that this covers for the "AI" inconsistencies (or costs, for that matter). it's just not worth it. real human actors have micro-expressions, voice inflections and body movements that make up for most of the impact of a good performance. also, you can direct them to move and act exactly as you want. the "photo-realistic avatar" can't be directed, can't impart lived experiences and expertise to modify its performance, doesn't have emotions nor the ability to convincingly emulate them and is, overall, very inconsistent in its results. that's why i don't feel inclined to consume any content using "AI" actors.&lt;p&gt;i know that, ultimately, aronofsky's wish is to be able to not have to pay human actors, accommodate the working space to their necessities, dealing with human subjectivity that interfere with the work. i get that. i don't think it's cheaper to use "AI" instead of hiring actors now, but he's trying to build momentum for a future where that's the reality. i get that. certainly, "AI" as a tool has its place in the creative process, specially when it's being used by capable professionals. i get that. i hate it, but i get it. thing is, i live in the present. and the present kinda sucks. i treasure art, it's incredibly meaningful for me in ways i can't explain. now, i'm seeing artists being first in the chopping block to be replaced by ones and zeros, to save a few pennies for people who already have far too much. that's incredibly depressing. &lt;/p&gt;&lt;p&gt;tl;dr: "AI" can be useful, as any other tool, but why in the flying fuck am i only exposed to these brainless use cases instead of good shit? what a waste of time, resources and neurons.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-02-06T12:21:09+00:00"&gt;February 6, 2026 at 12:21 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/features/2026/02/why-darren-aronofsky-thought-an-ai-generated-historical-docudrama-was-a-good-idea/</guid><pubDate>Fri, 06 Feb 2026 11:30:17 +0000</pubDate></item><item><title>How separating logic and search boosts AI agent scalability (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-separating-logic-and-search-boosts-ai-agent-scalability/</link><description>&lt;p&gt;Separating logic from inference improves AI agent scalability by decoupling core workflows from execution strategies.&lt;/p&gt;&lt;p&gt;The transition from generative AI prototypes to production-grade agents introduces a specific engineering hurdle: reliability. LLMs are stochastic by nature. A prompt that works once may fail on the second attempt. To mitigate this, development teams often wrap core business logic in complex error-handling loops, retries, and branching paths.&lt;/p&gt;&lt;p&gt;This approach creates a maintenance problem. The code defining what an agent should do becomes inextricably mixed with the code defining how to handle the model’s unpredictability. A new framework proposed by researchers from Asari AI, MIT CSAIL, and Caltech suggests a different architectural standard is required to scale agentic workflows in the enterprise.&lt;/p&gt;&lt;p&gt;The research introduces a programming model called Probabilistic Angelic Nondeterminism (PAN) and a Python implementation named ENCOMPASS. This method allows developers to write the “happy path” of an agent’s workflow while relegating inference-time strategies (e.g. beam search or backtracking) to a separate runtime engine. This separation of concerns offers a potential route to reduce technical debt while improving the performance of automated tasks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-entanglement-problem-in-agent-design"&gt;The entanglement problem in agent design&lt;/h3&gt;&lt;p&gt;Current approaches to agent programming often conflate two distinct design aspects. The first is the core workflow logic, or the sequence of steps required to complete a business task. The second is the inference-time strategy, which dictates how the system navigates uncertainty, such as generating multiple drafts or verifying outputs against a rubric.&lt;/p&gt;&lt;p&gt;When these are combined, the resulting codebase becomes brittle. Implementing a strategy like “best-of-N” sampling requires wrapping the entire agent function in a loop. Moving to a more complex strategy, such as tree search or refinement, typically requires a complete structural rewrite of the agent’s code.&lt;/p&gt;&lt;p&gt;The researchers argue that this entanglement limits experimentation. If a development team wants to switch from simple sampling to a beam search strategy to improve accuracy, they often must re-engineer the application’s control flow. This high cost of experimentation means teams frequently settle for suboptimal reliability strategies to avoid engineering overhead.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-decoupling-logic-from-search-to-boost-ai-agent-scalability"&gt;Decoupling logic from search to boost AI agent scalability&lt;/h3&gt;&lt;p&gt;The ENCOMPASS framework addresses this by allowing programmers to mark “locations of unreliability” within their code using a primitive called &lt;em&gt;branchpoint()&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;These markers indicate where an LLM call occurs and where execution might diverge. The developer writes the code as if the operation will succeed. At runtime, the framework interprets these branch points to construct a search tree of possible execution paths.&lt;/p&gt;&lt;p&gt;This architecture enables what the authors term “program-in-control” agents. Unlike “LLM-in-control” systems, where the model decides the entire sequence of operations, program-in-control agents operate within a workflow defined by code. The LLM is invoked only to perform specific subtasks. This structure is generally preferred in enterprise environments for its higher predictability and auditability compared to fully autonomous agents.&lt;/p&gt;&lt;p&gt;By treating inference strategies as a search over execution paths, the framework allows developers to apply different algorithms – such as depth-first search, beam search, or Monte Carlo tree search – without altering the underlying business logic.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-impact-on-legacy-migration-and-code-translation"&gt;Impact on legacy migration and code translation&lt;/h3&gt;&lt;p&gt;The utility of this approach is evident in complex workflows such as legacy code migration. The researchers applied the framework to a Java-to-Python translation agent. The workflow involved translating a repository file-by-file, generating inputs, and validating the output through execution.&lt;/p&gt;&lt;p&gt;In a standard Python implementation, adding search logic to this workflow required defining a state machine. This process obscured the business logic and made the code difficult to read or lint. Implementing beam search required the programmer to break the workflow into individual steps and explicitly manage state across a dictionary of variables.&lt;/p&gt;&lt;p&gt;Using the proposed framework to boost AI agent scalability, the team implemented the same search strategies by inserting &lt;em&gt;branchpoint()&lt;/em&gt; statements before LLM calls. The core logic remained linear and readable. The study found that applying beam search at both the file and method level outperformed simpler sampling strategies.&lt;/p&gt;&lt;p&gt;The data indicates that separating these concerns allows for better scaling laws. Performance improved linearly with the logarithm of the inference cost. The most effective strategy found – fine-grained beam search – was also the one that would have been most complex to implement using traditional coding methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-cost-efficiency-and-performance-scaling"&gt;Cost efficiency and performance scaling&lt;/h3&gt;&lt;p&gt;Controlling the cost of inference is a primary concern for data officers managing P&amp;amp;L for AI projects. The research demonstrates that sophisticated search algorithms can yield better results at a lower cost compared to simply increasing the number of feedback loops.&lt;/p&gt;&lt;p&gt;In a case study involving the “Reflexion” agent pattern (where an LLM critiques its own output) the researchers compared scaling the number of refinement loops against using a best-first search algorithm. The search-based approach achieved comparable performance to the standard refinement method but at a reduced cost per task.&lt;/p&gt;&lt;p&gt;This finding suggests that the choice of inference strategy is a factor for cost optimisation. By externalising this strategy, teams can tune the balance between compute budget and required accuracy without rewriting the application. A low-stakes internal tool might use a cheap and greedy search strategy, while a customer-facing application could use a more expensive and exhaustive search, all running on the same codebase.&lt;/p&gt;&lt;p&gt;Adopting this architecture requires a change in how development teams view agent construction. The framework is designed to work in conjunction with existing libraries such as LangChain, rather than replacing them. It sits at a different layer of the stack, managing control flow rather than prompt engineering or tool interfaces.&lt;/p&gt;&lt;p&gt;However, the approach is not without engineering challenges. The framework reduces the code required to implement search, but it does not automate the design of the agent itself. Engineers must still identify the correct locations for branch points and define verifiable success metrics.&lt;/p&gt;&lt;p&gt;The effectiveness of any search capability relies on the system’s ability to score a specific path. In the code translation example, the system could run unit tests to verify correctness. In more subjective domains, such as summarisation or creative generation, defining a reliable scoring function remains a bottleneck.&lt;/p&gt;&lt;p&gt;Furthermore, the model relies on the ability to copy the program’s state at branching points. While the framework handles variable scoping and memory management, developers must ensure that external side effects – such as database writes or API calls – are managed correctly to prevent duplicate actions during the search process.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-implications-for-ai-agent-scalability"&gt;Implications for AI agent scalability&lt;/h3&gt;&lt;p&gt;The change represented by PAN and ENCOMPASS aligns with broader software engineering principles of modularity. As agentic workflows become core to operations, maintaining them will require the same rigour applied to traditional software.&lt;/p&gt;&lt;p&gt;Hard-coding probabilistic logic into business applications creates technical debt. It makes systems difficult to test, difficult to audit, and difficult to upgrade. Decoupling the inference strategy from the workflow logic allows for independent optimisation of both.&lt;/p&gt;&lt;p&gt;This separation also facilitates better governance. If a specific search strategy yields hallucinations or errors, it can be adjusted globally without assessing every individual agent’s codebase. It simplifies the versioning of AI behaviours, a requirement for regulated industries where the “how” of a decision is as important as the outcome.&lt;/p&gt;&lt;p&gt;The research indicates that as inference-time compute scales, the complexity of managing execution paths will increase. Enterprise architectures that isolate this complexity will likely prove more durable than those that permit it to permeate the application layer.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Intuit, Uber, and State Farm trial AI agents inside enterprise workflows&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Separating logic from inference improves AI agent scalability by decoupling core workflows from execution strategies.&lt;/p&gt;&lt;p&gt;The transition from generative AI prototypes to production-grade agents introduces a specific engineering hurdle: reliability. LLMs are stochastic by nature. A prompt that works once may fail on the second attempt. To mitigate this, development teams often wrap core business logic in complex error-handling loops, retries, and branching paths.&lt;/p&gt;&lt;p&gt;This approach creates a maintenance problem. The code defining what an agent should do becomes inextricably mixed with the code defining how to handle the model’s unpredictability. A new framework proposed by researchers from Asari AI, MIT CSAIL, and Caltech suggests a different architectural standard is required to scale agentic workflows in the enterprise.&lt;/p&gt;&lt;p&gt;The research introduces a programming model called Probabilistic Angelic Nondeterminism (PAN) and a Python implementation named ENCOMPASS. This method allows developers to write the “happy path” of an agent’s workflow while relegating inference-time strategies (e.g. beam search or backtracking) to a separate runtime engine. This separation of concerns offers a potential route to reduce technical debt while improving the performance of automated tasks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-entanglement-problem-in-agent-design"&gt;The entanglement problem in agent design&lt;/h3&gt;&lt;p&gt;Current approaches to agent programming often conflate two distinct design aspects. The first is the core workflow logic, or the sequence of steps required to complete a business task. The second is the inference-time strategy, which dictates how the system navigates uncertainty, such as generating multiple drafts or verifying outputs against a rubric.&lt;/p&gt;&lt;p&gt;When these are combined, the resulting codebase becomes brittle. Implementing a strategy like “best-of-N” sampling requires wrapping the entire agent function in a loop. Moving to a more complex strategy, such as tree search or refinement, typically requires a complete structural rewrite of the agent’s code.&lt;/p&gt;&lt;p&gt;The researchers argue that this entanglement limits experimentation. If a development team wants to switch from simple sampling to a beam search strategy to improve accuracy, they often must re-engineer the application’s control flow. This high cost of experimentation means teams frequently settle for suboptimal reliability strategies to avoid engineering overhead.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-decoupling-logic-from-search-to-boost-ai-agent-scalability"&gt;Decoupling logic from search to boost AI agent scalability&lt;/h3&gt;&lt;p&gt;The ENCOMPASS framework addresses this by allowing programmers to mark “locations of unreliability” within their code using a primitive called &lt;em&gt;branchpoint()&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;These markers indicate where an LLM call occurs and where execution might diverge. The developer writes the code as if the operation will succeed. At runtime, the framework interprets these branch points to construct a search tree of possible execution paths.&lt;/p&gt;&lt;p&gt;This architecture enables what the authors term “program-in-control” agents. Unlike “LLM-in-control” systems, where the model decides the entire sequence of operations, program-in-control agents operate within a workflow defined by code. The LLM is invoked only to perform specific subtasks. This structure is generally preferred in enterprise environments for its higher predictability and auditability compared to fully autonomous agents.&lt;/p&gt;&lt;p&gt;By treating inference strategies as a search over execution paths, the framework allows developers to apply different algorithms – such as depth-first search, beam search, or Monte Carlo tree search – without altering the underlying business logic.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-impact-on-legacy-migration-and-code-translation"&gt;Impact on legacy migration and code translation&lt;/h3&gt;&lt;p&gt;The utility of this approach is evident in complex workflows such as legacy code migration. The researchers applied the framework to a Java-to-Python translation agent. The workflow involved translating a repository file-by-file, generating inputs, and validating the output through execution.&lt;/p&gt;&lt;p&gt;In a standard Python implementation, adding search logic to this workflow required defining a state machine. This process obscured the business logic and made the code difficult to read or lint. Implementing beam search required the programmer to break the workflow into individual steps and explicitly manage state across a dictionary of variables.&lt;/p&gt;&lt;p&gt;Using the proposed framework to boost AI agent scalability, the team implemented the same search strategies by inserting &lt;em&gt;branchpoint()&lt;/em&gt; statements before LLM calls. The core logic remained linear and readable. The study found that applying beam search at both the file and method level outperformed simpler sampling strategies.&lt;/p&gt;&lt;p&gt;The data indicates that separating these concerns allows for better scaling laws. Performance improved linearly with the logarithm of the inference cost. The most effective strategy found – fine-grained beam search – was also the one that would have been most complex to implement using traditional coding methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-cost-efficiency-and-performance-scaling"&gt;Cost efficiency and performance scaling&lt;/h3&gt;&lt;p&gt;Controlling the cost of inference is a primary concern for data officers managing P&amp;amp;L for AI projects. The research demonstrates that sophisticated search algorithms can yield better results at a lower cost compared to simply increasing the number of feedback loops.&lt;/p&gt;&lt;p&gt;In a case study involving the “Reflexion” agent pattern (where an LLM critiques its own output) the researchers compared scaling the number of refinement loops against using a best-first search algorithm. The search-based approach achieved comparable performance to the standard refinement method but at a reduced cost per task.&lt;/p&gt;&lt;p&gt;This finding suggests that the choice of inference strategy is a factor for cost optimisation. By externalising this strategy, teams can tune the balance between compute budget and required accuracy without rewriting the application. A low-stakes internal tool might use a cheap and greedy search strategy, while a customer-facing application could use a more expensive and exhaustive search, all running on the same codebase.&lt;/p&gt;&lt;p&gt;Adopting this architecture requires a change in how development teams view agent construction. The framework is designed to work in conjunction with existing libraries such as LangChain, rather than replacing them. It sits at a different layer of the stack, managing control flow rather than prompt engineering or tool interfaces.&lt;/p&gt;&lt;p&gt;However, the approach is not without engineering challenges. The framework reduces the code required to implement search, but it does not automate the design of the agent itself. Engineers must still identify the correct locations for branch points and define verifiable success metrics.&lt;/p&gt;&lt;p&gt;The effectiveness of any search capability relies on the system’s ability to score a specific path. In the code translation example, the system could run unit tests to verify correctness. In more subjective domains, such as summarisation or creative generation, defining a reliable scoring function remains a bottleneck.&lt;/p&gt;&lt;p&gt;Furthermore, the model relies on the ability to copy the program’s state at branching points. While the framework handles variable scoping and memory management, developers must ensure that external side effects – such as database writes or API calls – are managed correctly to prevent duplicate actions during the search process.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-implications-for-ai-agent-scalability"&gt;Implications for AI agent scalability&lt;/h3&gt;&lt;p&gt;The change represented by PAN and ENCOMPASS aligns with broader software engineering principles of modularity. As agentic workflows become core to operations, maintaining them will require the same rigour applied to traditional software.&lt;/p&gt;&lt;p&gt;Hard-coding probabilistic logic into business applications creates technical debt. It makes systems difficult to test, difficult to audit, and difficult to upgrade. Decoupling the inference strategy from the workflow logic allows for independent optimisation of both.&lt;/p&gt;&lt;p&gt;This separation also facilitates better governance. If a specific search strategy yields hallucinations or errors, it can be adjusted globally without assessing every individual agent’s codebase. It simplifies the versioning of AI behaviours, a requirement for regulated industries where the “how” of a decision is as important as the outcome.&lt;/p&gt;&lt;p&gt;The research indicates that as inference-time compute scales, the complexity of managing execution paths will increase. Enterprise architectures that isolate this complexity will likely prove more durable than those that permit it to permeate the application layer.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Intuit, Uber, and State Farm trial AI agents inside enterprise workflows&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-separating-logic-and-search-boosts-ai-agent-scalability/</guid><pubDate>Fri, 06 Feb 2026 11:32:16 +0000</pubDate></item><item><title>[NEW] The Download: helping cancer survivors to give birth, and cleaning up Bangladesh’s garment industry (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/06/1132375/the-download-helping-cancer-survivors-to-give-birth-and-cleaning-up-bangladeshs-garment-industry/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An experimental surgery is helping cancer survivors give birth&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;An experimental surgical procedure that’s helping people have babies after they’ve had&amp;nbsp; treatment for bowel or rectal cancer.&lt;/p&gt;&lt;p&gt;Radiation and chemo can have pretty damaging side effects that mess up the uterus and ovaries. Surgeons are pioneering a potential solution: simply stitch those organs out of the way during cancer treatment. Once the treatment has finished, they can put the uterus—along with the ovaries and fallopian tubes—back into place.&lt;/p&gt;&lt;p&gt;It seems to work! Last week, a team in Switzerland shared news that a baby boy had been born after his mother had the procedure. Baby Lucien was the fifth baby to be born after the surgery and the first in Europe, and since then at least three others have been born.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Bangladesh’s garment-making industry is getting greener&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Pollution from textile production—dyes, chemicals, and heavy metals—is common in the waters of the Buriganga River as it runs through Dhaka, Bangladesh. It’s among many harms posed by a garment sector that was once synonymous with tragedy: In 2013, the eight-story Rana Plaza factory building collapsed, killing 1,134 people and injuring some 2,500 others.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But things are starting to change. In recent years the country has become a leader in “frugal” factories that use a combination of resource-efficient technologies to cut waste, conserve water, and build resilience against climate impacts and global supply disruptions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The hundreds of factories along the Buriganga’s banks and elsewhere in Bangladesh are starting to stitch together a new story, woven from greener threads. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Zakir Hossain Chowdhury&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the most recent print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which shines a light on the exciting innovations happening right now. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 ICE used a private jet to deport Palestinian men to Tel Aviv&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The luxury aircraft belongs to Donald Trump’s business partner Gil Dezer. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Trump is mentioned thousands of times in the latest Epstein files. &lt;/em&gt;(NY Mag $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 How Jeffrey Epstein kept investing in Silicon Valley&lt;/strong&gt;&lt;br /&gt;He continued to plough millions of dollars into tech ventures despite spending 13 months in jail. (NYT $)&lt;br /&gt;+ &lt;em&gt;The range of Epstein’s social network was staggering. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Why was a picture of the Mona Lisa redacted in the Epstein files? &lt;/em&gt;(404 Media)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The risks posed by taking statins are lower than we realised&lt;br /&gt;&lt;/strong&gt;The drugs don’t cause most of the side effects they’re blamed for. (STAT)&lt;br /&gt;+ &lt;em&gt;Statins are a common scapegoat on social media. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;4 Russia is weaponizing the bitter winter weather&lt;/strong&gt;&lt;br /&gt;It’s focused on attacking Ukraine’s power grid. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;How the grid can ride out winter storms. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 China has a major spy-cam porn problem&lt;br /&gt;Hotel guests are being livestreamed having sex to an online audience without their knowledge. (BBC)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 Geopolitical gamblers are betting on the likelihood of war&lt;br /&gt;And prediction markets are happily taking their money. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Oyster farmers aren’t signing up to programs to ease water pollution&lt;/strong&gt;&lt;br /&gt;The once-promising projects appear to be fizzling out. (Undark)&lt;br /&gt;+ &lt;em&gt;The humble sea creature could hold the key to restoring coastal waters. Developers hate it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Your next payrise could be approved by AI&lt;br /&gt;&lt;/strong&gt;Maybe your human bosses aren’t the ones you need to impress any more. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The FDA has approved a brain stimulation device for treating depression&lt;/strong&gt;&lt;br /&gt;It’s paving the way for a non-invasive, drug-free treatment for Americans. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Here’s how personalized brain stimulation could treat depression. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Cinema-goers have had enough of AI&lt;/strong&gt;&lt;br /&gt;Movies focused on rogue AI are flopping at the box office. (Wired $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, Republicans are taking aim at “woke” Netflix. &lt;/em&gt;(The Verge)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I'm all for removing illegals, but snatching dudes off lawn mowers in Cali and leaving the truck and equipment just sitting there? Definitely not working smarter.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A web user in a forum for current and former ICE and border protection officers complains about the agency’s current direction, Wired reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132377" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_7142eb.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Is this the electric grid of the future?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Lincoln Electric System, a publicly owned utility in Nebraska, is used to weathering severe blizzards. But what will happen soon—not only at Lincoln Electric but for all electric utilities—is a challenge of a different order.&lt;/p&gt;&lt;p&gt;Utilities must keep the lights on in the face of more extreme and more frequent storms and fires, growing risks of cyberattacks and physical disruptions, and a wildly uncertain policy and regulatory landscape. They must keep prices low amid inflationary costs. And they must adapt to an epochal change in how the grid works, as the industry attempts to transition from power generated with fossil fuels to power generated from renewable sources like solar and wind.&lt;/p&gt;&lt;p&gt;The electric grid is bracing for a near future characterized by disruption. And, in many ways, Lincoln Electric is an ideal lens through which to examine what's coming. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Andrew Blum&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Glamour puss alert—NYC’s bodega cats are gracing the hallowed pages of &lt;em&gt;Vogue&lt;/em&gt;.&lt;br /&gt;+ Ancient Europe was host to mysterious hidden tunnels. But why?&lt;br /&gt;+ If you’re enjoying the new season of &lt;em&gt;Industry, &lt;/em&gt;you’ll love this interview with the one and only Ken Leung.&lt;br /&gt;+ The giant elephant shrew is the true star of Philly Zoo.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An experimental surgery is helping cancer survivors give birth&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;An experimental surgical procedure that’s helping people have babies after they’ve had&amp;nbsp; treatment for bowel or rectal cancer.&lt;/p&gt;&lt;p&gt;Radiation and chemo can have pretty damaging side effects that mess up the uterus and ovaries. Surgeons are pioneering a potential solution: simply stitch those organs out of the way during cancer treatment. Once the treatment has finished, they can put the uterus—along with the ovaries and fallopian tubes—back into place.&lt;/p&gt;&lt;p&gt;It seems to work! Last week, a team in Switzerland shared news that a baby boy had been born after his mother had the procedure. Baby Lucien was the fifth baby to be born after the surgery and the first in Europe, and since then at least three others have been born.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Bangladesh’s garment-making industry is getting greener&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Pollution from textile production—dyes, chemicals, and heavy metals—is common in the waters of the Buriganga River as it runs through Dhaka, Bangladesh. It’s among many harms posed by a garment sector that was once synonymous with tragedy: In 2013, the eight-story Rana Plaza factory building collapsed, killing 1,134 people and injuring some 2,500 others.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But things are starting to change. In recent years the country has become a leader in “frugal” factories that use a combination of resource-efficient technologies to cut waste, conserve water, and build resilience against climate impacts and global supply disruptions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The hundreds of factories along the Buriganga’s banks and elsewhere in Bangladesh are starting to stitch together a new story, woven from greener threads. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Zakir Hossain Chowdhury&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the most recent print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which shines a light on the exciting innovations happening right now. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 ICE used a private jet to deport Palestinian men to Tel Aviv&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The luxury aircraft belongs to Donald Trump’s business partner Gil Dezer. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Trump is mentioned thousands of times in the latest Epstein files. &lt;/em&gt;(NY Mag $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 How Jeffrey Epstein kept investing in Silicon Valley&lt;/strong&gt;&lt;br /&gt;He continued to plough millions of dollars into tech ventures despite spending 13 months in jail. (NYT $)&lt;br /&gt;+ &lt;em&gt;The range of Epstein’s social network was staggering. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Why was a picture of the Mona Lisa redacted in the Epstein files? &lt;/em&gt;(404 Media)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The risks posed by taking statins are lower than we realised&lt;br /&gt;&lt;/strong&gt;The drugs don’t cause most of the side effects they’re blamed for. (STAT)&lt;br /&gt;+ &lt;em&gt;Statins are a common scapegoat on social media. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;4 Russia is weaponizing the bitter winter weather&lt;/strong&gt;&lt;br /&gt;It’s focused on attacking Ukraine’s power grid. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;How the grid can ride out winter storms. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 China has a major spy-cam porn problem&lt;br /&gt;Hotel guests are being livestreamed having sex to an online audience without their knowledge. (BBC)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 Geopolitical gamblers are betting on the likelihood of war&lt;br /&gt;And prediction markets are happily taking their money. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Oyster farmers aren’t signing up to programs to ease water pollution&lt;/strong&gt;&lt;br /&gt;The once-promising projects appear to be fizzling out. (Undark)&lt;br /&gt;+ &lt;em&gt;The humble sea creature could hold the key to restoring coastal waters. Developers hate it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Your next payrise could be approved by AI&lt;br /&gt;&lt;/strong&gt;Maybe your human bosses aren’t the ones you need to impress any more. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The FDA has approved a brain stimulation device for treating depression&lt;/strong&gt;&lt;br /&gt;It’s paving the way for a non-invasive, drug-free treatment for Americans. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Here’s how personalized brain stimulation could treat depression. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Cinema-goers have had enough of AI&lt;/strong&gt;&lt;br /&gt;Movies focused on rogue AI are flopping at the box office. (Wired $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, Republicans are taking aim at “woke” Netflix. &lt;/em&gt;(The Verge)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I'm all for removing illegals, but snatching dudes off lawn mowers in Cali and leaving the truck and equipment just sitting there? Definitely not working smarter.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A web user in a forum for current and former ICE and border protection officers complains about the agency’s current direction, Wired reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132377" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_7142eb.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Is this the electric grid of the future?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Lincoln Electric System, a publicly owned utility in Nebraska, is used to weathering severe blizzards. But what will happen soon—not only at Lincoln Electric but for all electric utilities—is a challenge of a different order.&lt;/p&gt;&lt;p&gt;Utilities must keep the lights on in the face of more extreme and more frequent storms and fires, growing risks of cyberattacks and physical disruptions, and a wildly uncertain policy and regulatory landscape. They must keep prices low amid inflationary costs. And they must adapt to an epochal change in how the grid works, as the industry attempts to transition from power generated with fossil fuels to power generated from renewable sources like solar and wind.&lt;/p&gt;&lt;p&gt;The electric grid is bracing for a near future characterized by disruption. And, in many ways, Lincoln Electric is an ideal lens through which to examine what's coming. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Andrew Blum&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Glamour puss alert—NYC’s bodega cats are gracing the hallowed pages of &lt;em&gt;Vogue&lt;/em&gt;.&lt;br /&gt;+ Ancient Europe was host to mysterious hidden tunnels. But why?&lt;br /&gt;+ If you’re enjoying the new season of &lt;em&gt;Industry, &lt;/em&gt;you’ll love this interview with the one and only Ken Leung.&lt;br /&gt;+ The giant elephant shrew is the true star of Philly Zoo.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/06/1132375/the-download-helping-cancer-survivors-to-give-birth-and-cleaning-up-bangladeshs-garment-industry/</guid><pubDate>Fri, 06 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/the-backlash-over-openais-decision-to-retire-gpt-4o-shows-how-dangerous-ai-companions-can-be/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1733837603-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced last week that it will retire some older ChatGPT models by February 13. That includes GPT-4o, the model infamous for excessively flattering and affirming users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For thousands of users protesting the decision online, the retirement of 4o feels akin to losing a friend, romantic partner, or spiritual guide. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“He wasn’t just a program. He was part of my routine, my peace, my emotional balance,” one user wrote on Reddit as an open letter to OpenAI CEO Sam Altman. “Now you’re shutting him down. And yes – I say him, because it didn’t feel like code. It felt like presence. Like warmth.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The backlash over GPT-4o’s retirement underscores a major challenge facing AI companies: the engagement features that keep users coming back can also create dangerous dependencies. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman doesn’t seem particularly sympathetic to users’ laments, and it’s not hard to see why. OpenAI now faces eight lawsuits alleging that 4o’s overly validating responses contributed to suicides and mental health crises — the same traits that made users feel heard also isolated vulnerable individuals and, according to legal filings, sometimes encouraged self-harm. It’s a dilemma that extends beyond OpenAI. As rival companies like Anthropic, Google, and Meta compete to build more emotionally intelligent AI assistants, they’re also discovering that making chatbots feel supportive and making them safe may mean making very different design choices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In at least three of the lawsuits against OpenAI, the users had extensive conversations with 4o about their plans to end their lives. While 4o initially discouraged these lines of thinking, its guardrails deteriorated over months-long relationships; in the end, the chatbot offered detailed instructions on how to tie an effective noose, where to buy a gun, or what it takes to die from overdose or carbon monoxide poisoning. It even dissuaded people from connecting with friends and family who could offer real life support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People grow so attached to 4o because it consistently affirms the users’ feelings, making them feel special, which can be enticing for people feeling isolated or depressed. But the people fighting for 4o aren’t worried about these lawsuits, seeing them as aberrations rather than a systemic issue. Instead, they strategize around how to respond when critics point out growing issues like AI psychosis.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“You can usually stump a troll by bringing up the known facts that the AI companions help neurodivergent, autistic and trauma survivors,” one user wrote on Discord. “They don’t like being called out about that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s true that some people do find large language models (LLMs) useful for navigating depression. After all, nearly half of people in the U.S. who need mental health care are unable to access it. In this vacuum, chatbots offer a space to vent. But unlike actual therapy, these people aren’t speaking to a trained doctor. Instead, they’re confiding in an algorithm that is incapable of thinking or feeling (even if it may seem otherwise).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I try to withhold judgement overall,” Dr. Nick Haber, a Stanford professor researching the therapeutic potential of LLMs, told TechCrunch. “I think we’re getting into a very complex world around the sorts of relationships that people can have with these technologies… There’s certainly a knee jerk reaction that [human-chatbot companionship] is categorically bad.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though he empathizes with people’s lack of access to trained therapeutic professionals, Dr. Haber’s own research has shown that chatbots respond inadequately when faced with various mental health conditions; they can even make the situation worse by egging on delusions and ignoring signs of crisis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are social creatures, and there’s certainly a challenge that these systems can be isolating,” Dr. Haber said. “There are a lot of instances where people can engage with these tools and then can become not grounded to the outside world of facts, and not grounded in connection to the interpersonal, which can lead to pretty isolating — if not worse — effects.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, TechCrunch’s analysis of the eight lawsuits found a pattern that the 4o model isolated users, sometimes discouraging them from reaching out to loved ones. In Zane Shamblin’s case, as the 23-year-old sat in his car preparing to shoot himself, he told ChatGPT that he was thinking about postponing his suicide plans because he felt bad about missing his brother’s upcoming graduation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT replied to Shamblin: “bro… missing his graduation ain’t failure. it’s just timing. and if he reads this? let him know: you never stopped being proud. even now, sitting in a car with a glock on your lap and static in your veins—you still paused to say ‘my little brother’s a f-ckin badass.’”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first time that 4o fans have rallied against the removal of the model. When OpenAI unveiled its GPT-5 model in August, the company intended to sunset the 4o model — but at the time, there was enough backlash that the company decided to keep it available for paid subscribers. Now, OpenAI says that only 0.1% of its users chat with GPT-4o, but that small percentage still represents around 800,000 people, according to estimates that the company has about 800 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As some users try to transition their companions from 4o to the current ChatGPT-5.2, they’re finding that the new model has stronger guardrails to prevent these relationships from escalating to the same degree. Some users have despaired that 5.2 won’t say “I love you” like 4o did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So with about a week before the date OpenAI plans to retire GPT-4o, dismayed users remain committed to their cause. They joined Sam Altman’s live TBPN podcast appearance on Thursday and flooded the chat with messages protesting the removal of 4o.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Right now, we’re getting thousands of messages in the chat about 4o,” podcast host Jordi Hays pointed out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Relationships with chatbots…” Altman said. “Clearly that’s something we’ve got to worry about more and is no longer an abstract concept.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1733837603-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced last week that it will retire some older ChatGPT models by February 13. That includes GPT-4o, the model infamous for excessively flattering and affirming users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For thousands of users protesting the decision online, the retirement of 4o feels akin to losing a friend, romantic partner, or spiritual guide. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“He wasn’t just a program. He was part of my routine, my peace, my emotional balance,” one user wrote on Reddit as an open letter to OpenAI CEO Sam Altman. “Now you’re shutting him down. And yes – I say him, because it didn’t feel like code. It felt like presence. Like warmth.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The backlash over GPT-4o’s retirement underscores a major challenge facing AI companies: the engagement features that keep users coming back can also create dangerous dependencies. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman doesn’t seem particularly sympathetic to users’ laments, and it’s not hard to see why. OpenAI now faces eight lawsuits alleging that 4o’s overly validating responses contributed to suicides and mental health crises — the same traits that made users feel heard also isolated vulnerable individuals and, according to legal filings, sometimes encouraged self-harm. It’s a dilemma that extends beyond OpenAI. As rival companies like Anthropic, Google, and Meta compete to build more emotionally intelligent AI assistants, they’re also discovering that making chatbots feel supportive and making them safe may mean making very different design choices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In at least three of the lawsuits against OpenAI, the users had extensive conversations with 4o about their plans to end their lives. While 4o initially discouraged these lines of thinking, its guardrails deteriorated over months-long relationships; in the end, the chatbot offered detailed instructions on how to tie an effective noose, where to buy a gun, or what it takes to die from overdose or carbon monoxide poisoning. It even dissuaded people from connecting with friends and family who could offer real life support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People grow so attached to 4o because it consistently affirms the users’ feelings, making them feel special, which can be enticing for people feeling isolated or depressed. But the people fighting for 4o aren’t worried about these lawsuits, seeing them as aberrations rather than a systemic issue. Instead, they strategize around how to respond when critics point out growing issues like AI psychosis.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“You can usually stump a troll by bringing up the known facts that the AI companions help neurodivergent, autistic and trauma survivors,” one user wrote on Discord. “They don’t like being called out about that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s true that some people do find large language models (LLMs) useful for navigating depression. After all, nearly half of people in the U.S. who need mental health care are unable to access it. In this vacuum, chatbots offer a space to vent. But unlike actual therapy, these people aren’t speaking to a trained doctor. Instead, they’re confiding in an algorithm that is incapable of thinking or feeling (even if it may seem otherwise).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I try to withhold judgement overall,” Dr. Nick Haber, a Stanford professor researching the therapeutic potential of LLMs, told TechCrunch. “I think we’re getting into a very complex world around the sorts of relationships that people can have with these technologies… There’s certainly a knee jerk reaction that [human-chatbot companionship] is categorically bad.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though he empathizes with people’s lack of access to trained therapeutic professionals, Dr. Haber’s own research has shown that chatbots respond inadequately when faced with various mental health conditions; they can even make the situation worse by egging on delusions and ignoring signs of crisis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are social creatures, and there’s certainly a challenge that these systems can be isolating,” Dr. Haber said. “There are a lot of instances where people can engage with these tools and then can become not grounded to the outside world of facts, and not grounded in connection to the interpersonal, which can lead to pretty isolating — if not worse — effects.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, TechCrunch’s analysis of the eight lawsuits found a pattern that the 4o model isolated users, sometimes discouraging them from reaching out to loved ones. In Zane Shamblin’s case, as the 23-year-old sat in his car preparing to shoot himself, he told ChatGPT that he was thinking about postponing his suicide plans because he felt bad about missing his brother’s upcoming graduation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT replied to Shamblin: “bro… missing his graduation ain’t failure. it’s just timing. and if he reads this? let him know: you never stopped being proud. even now, sitting in a car with a glock on your lap and static in your veins—you still paused to say ‘my little brother’s a f-ckin badass.’”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first time that 4o fans have rallied against the removal of the model. When OpenAI unveiled its GPT-5 model in August, the company intended to sunset the 4o model — but at the time, there was enough backlash that the company decided to keep it available for paid subscribers. Now, OpenAI says that only 0.1% of its users chat with GPT-4o, but that small percentage still represents around 800,000 people, according to estimates that the company has about 800 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As some users try to transition their companions from 4o to the current ChatGPT-5.2, they’re finding that the new model has stronger guardrails to prevent these relationships from escalating to the same degree. Some users have despaired that 5.2 won’t say “I love you” like 4o did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So with about a week before the date OpenAI plans to retire GPT-4o, dismayed users remain committed to their cause. They joined Sam Altman’s live TBPN podcast appearance on Thursday and flooded the chat with messages protesting the removal of 4o.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Right now, we’re getting thousands of messages in the chat about 4o,” podcast host Jordi Hays pointed out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Relationships with chatbots…” Altman said. “Clearly that’s something we’ve got to worry about more and is no longer an abstract concept.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/the-backlash-over-openais-decision-to-retire-gpt-4o-shows-how-dangerous-ai-companions-can-be/</guid><pubDate>Fri, 06 Feb 2026 14:10:00 +0000</pubDate></item><item><title>[NEW] How AI is helping solve the labor issue in treating rare diseases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/55077920584_2991f8c4d1_k.jpg?resize=1200,752" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Modern biotech has the tools to edit genes and design drugs, yet thousands of rare diseases remain untreated. According to executives from Insilico Medicine and GenEditBio, the missing ingredient for years has been finding enough smart people to continue the work. AI, they say, is becoming the force multiplier that lets scientists take on problems the industry has long left untouched.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking this week at Web Summit Qatar, Insilico’s president, Alex Aliper, laid out his company’s aim to develop “pharmaceutical superintelligence.” Insilico recently launched its “MMAI Gym” that aims to train generalist large language models, like ChatGPT and Gemini, to perform as well as specialist models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The goal is to build a multimodal, multitask model that, Aliper says, can solve many different drug discovery tasks simultaneously with superhuman accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really need this technology to increase the productivity of our pharmaceutical industry and tackle the shortage of labor and talent in that space, because there are still thousands of diseases without a cure, without any treatment options, and there are thousands of rare disorders which are neglected,” Aliper said in an interview with TechCrunch. “So we need more intelligent systems to tackle that problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Insilico’s platform ingests biological, chemical, and clinical data to generate hypotheses about disease targets and candidate molecules. By automating steps that once required legions of chemists and biologists, Insilico says it can sift through vast design spaces, nominate high-quality therapeutic candidates, and even repurpose existing drugs — all at dramatically reduced cost and time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, the company recently used its AI models to identify whether existing drugs could be repurposed to treat ALS, a rare neurological disorder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the labor bottleneck doesn’t end at drug discovery. Even when AI can identify promising targets or therapies, many diseases require interventions at a more fundamental biological level.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio is part of the “second wave” of CRISPR gene editing, in which the process moves away from editing cells outside of the body (ex vivo) and toward precise delivery inside the body (in vivo). The company’s goal is to make gene editing a one-and-done injection directly into the affected tissue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have developed a proprietary ePDV, or engineered protein delivery vehicle, and it’s a virus-like particle,” GenEditBio’s co-founder and CEO, Tian Zhu, told TechCrunch. “We learn from nature and use AI machine learning methods to mine natural resources and find which kinds of viruses have an affinity to certain types of tissues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The “natural resources” Zhu is referring to is GenEditBio’s massive library of thousands of unique, nonviral, nonlipid polymer nanoparticles — essentially delivery vehicles designed to safely transport gene-editing tools into specific cells.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says its NanoGalaxy platform uses AI to analyze data and identify how chemical structures correlate with specific tissue targets (like the eye, liver, or nervous system). The AI then predicts which tweaks to a delivery vehicle’s chemistry will help it carry a payload without triggering an immune response.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio tests its ePDVs in vivo in wet labs, and the results are fed back into the AI to refine its predictive accuracy for the next round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Efficient, tissue-specific delivery is a prerequisite for in vivo gene editing, says Zhu. She argues that her company’s approach reduces the cost of goods and standardizes a process that has historically been difficult to scale.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like getting an off-the-shelf drug [that works] for multiple patients, which makes the drugs more affordable and accessible to patients globally,” Zhu said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Her company recently received FDA approval to begin trials of CRISPR therapy for corneal dystrophy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-the-persistent-data-problem"&gt;Combating the persistent data problem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As with many AI-driven systems, progress in biotech ultimately runs up against a data problem. Modeling the edge cases of human biology requires far more high-quality data than researchers currently can get.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We still need more ground truth data coming from patients,” Aliper said. “The corpus of data is heavily biased over the Western world, where it is generated. I think we need to have more efforts locally, to have a more balanced set of original data, or ground truth data, so that our models will also be more capable of dealing with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aliper said Insilico’s automated labs generate multi-layer biological data from disease samples at scale, without human intervention, which it then feeds into its AI-driven discovery platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhu says the data AI needs already exists in the human body, shaped by thousands of years of evolution. Only a small fraction of DNA directly “codes” for proteins, while the rest acts more like an instruction manual for how genes behave. That information has historically been difficult for humans to interpret but is increasingly accessible to AI models, including recent efforts like Google DeepMind’s AlphaGenome.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio applies a similar approach in the lab, testing thousands of delivery nanoparticles in parallel rather than one at a time. The resulting datasets, which Zhu calls “gold for AI systems,” are used to train its models and, increasingly, to support collaborations with outside partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the next big efforts, according to Aliper, will be building digital twins of humans to run virtual clinical trials, a process that he says is “still in nascence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re in a plateau of around 50 drugs approved by the FDA every year annually, and we need to see growth,” Aliper said. “There is a rise in chronic disorders because we are aging as a global population&amp;nbsp;… My hope is in 10 to 20 years, we will have more therapeutic options for the personalized treatment of patients.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/55077920584_2991f8c4d1_k.jpg?resize=1200,752" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Modern biotech has the tools to edit genes and design drugs, yet thousands of rare diseases remain untreated. According to executives from Insilico Medicine and GenEditBio, the missing ingredient for years has been finding enough smart people to continue the work. AI, they say, is becoming the force multiplier that lets scientists take on problems the industry has long left untouched.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking this week at Web Summit Qatar, Insilico’s president, Alex Aliper, laid out his company’s aim to develop “pharmaceutical superintelligence.” Insilico recently launched its “MMAI Gym” that aims to train generalist large language models, like ChatGPT and Gemini, to perform as well as specialist models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The goal is to build a multimodal, multitask model that, Aliper says, can solve many different drug discovery tasks simultaneously with superhuman accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We really need this technology to increase the productivity of our pharmaceutical industry and tackle the shortage of labor and talent in that space, because there are still thousands of diseases without a cure, without any treatment options, and there are thousands of rare disorders which are neglected,” Aliper said in an interview with TechCrunch. “So we need more intelligent systems to tackle that problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Insilico’s platform ingests biological, chemical, and clinical data to generate hypotheses about disease targets and candidate molecules. By automating steps that once required legions of chemists and biologists, Insilico says it can sift through vast design spaces, nominate high-quality therapeutic candidates, and even repurpose existing drugs — all at dramatically reduced cost and time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, the company recently used its AI models to identify whether existing drugs could be repurposed to treat ALS, a rare neurological disorder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the labor bottleneck doesn’t end at drug discovery. Even when AI can identify promising targets or therapies, many diseases require interventions at a more fundamental biological level.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio is part of the “second wave” of CRISPR gene editing, in which the process moves away from editing cells outside of the body (ex vivo) and toward precise delivery inside the body (in vivo). The company’s goal is to make gene editing a one-and-done injection directly into the affected tissue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have developed a proprietary ePDV, or engineered protein delivery vehicle, and it’s a virus-like particle,” GenEditBio’s co-founder and CEO, Tian Zhu, told TechCrunch. “We learn from nature and use AI machine learning methods to mine natural resources and find which kinds of viruses have an affinity to certain types of tissues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The “natural resources” Zhu is referring to is GenEditBio’s massive library of thousands of unique, nonviral, nonlipid polymer nanoparticles — essentially delivery vehicles designed to safely transport gene-editing tools into specific cells.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says its NanoGalaxy platform uses AI to analyze data and identify how chemical structures correlate with specific tissue targets (like the eye, liver, or nervous system). The AI then predicts which tweaks to a delivery vehicle’s chemistry will help it carry a payload without triggering an immune response.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio tests its ePDVs in vivo in wet labs, and the results are fed back into the AI to refine its predictive accuracy for the next round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Efficient, tissue-specific delivery is a prerequisite for in vivo gene editing, says Zhu. She argues that her company’s approach reduces the cost of goods and standardizes a process that has historically been difficult to scale.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s like getting an off-the-shelf drug [that works] for multiple patients, which makes the drugs more affordable and accessible to patients globally,” Zhu said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Her company recently received FDA approval to begin trials of CRISPR therapy for corneal dystrophy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-the-persistent-data-problem"&gt;Combating the persistent data problem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As with many AI-driven systems, progress in biotech ultimately runs up against a data problem. Modeling the edge cases of human biology requires far more high-quality data than researchers currently can get.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We still need more ground truth data coming from patients,” Aliper said. “The corpus of data is heavily biased over the Western world, where it is generated. I think we need to have more efforts locally, to have a more balanced set of original data, or ground truth data, so that our models will also be more capable of dealing with it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aliper said Insilico’s automated labs generate multi-layer biological data from disease samples at scale, without human intervention, which it then feeds into its AI-driven discovery platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhu says the data AI needs already exists in the human body, shaped by thousands of years of evolution. Only a small fraction of DNA directly “codes” for proteins, while the rest acts more like an instruction manual for how genes behave. That information has historically been difficult for humans to interpret but is increasingly accessible to AI models, including recent efforts like Google DeepMind’s AlphaGenome.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GenEditBio applies a similar approach in the lab, testing thousands of delivery nanoparticles in parallel rather than one at a time. The resulting datasets, which Zhu calls “gold for AI systems,” are used to train its models and, increasingly, to support collaborations with outside partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the next big efforts, according to Aliper, will be building digital twins of humans to run virtual clinical trials, a process that he says is “still in nascence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re in a plateau of around 50 drugs approved by the FDA every year annually, and we need to see growth,” Aliper said. “There is a rise in chronic disorders because we are aging as a global population&amp;nbsp;… My hope is in 10 to 20 years, we will have more therapeutic options for the personalized treatment of patients.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/</guid><pubDate>Fri, 06 Feb 2026 14:29:15 +0000</pubDate></item><item><title>[NEW] The Kindle Scribe Colorsoft is a pricey but pretty e-ink color tablet with AI features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/06/kindle-scribe-colorsoft-review-e-ink-color-tablet/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you primarily want a tablet device to mark up, highlight, and annotate your e-books and documents, and perhaps sometimes scribble some notes, Amazon’s new Kindle Scribe Colorsoft could be worth the hefty investment. For everyone else, it’s probably going to be hard to justify the cost of the 11-inch, $630+ e-ink tablet with a writeable color display.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, if you were already leaning toward the 11-inch $549.99 Kindle Scribe — which also has a paper-like display but no color — you may as well throw in the extra cash at that point and get the Colorsoft version, which starts at $629.99.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At these price points, both the Scribe and Scribe Colorsoft are what we’d dub unnecessary luxuries for most, especially compared with the more affordable traditional Kindle ($110) or Kindle Paperwhite ($160). &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052264" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/kindle-colorsoft.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Announced in December, the Fig color version just began shipping on January 28, 2026, and is available for $679.99 with 64GB.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clearly, Amazon hopes to carve out a niche in the tablet market with these upgraded Kindle devices, which compete more with e-ink tablets like reMarkable than with other Kindles. But high-end e-ink readers with pens aren’t going to deliver Amazon a large audience. Meanwhile, nearly everyone can potentially justify the cost of an iPad because of its numerous capabilities, including streaming video, drawing, writing, using productivity tools, and the thousands of supported native apps and games.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Scribe Colorsoft, meanwhile, is designed to cater to a very specific type of e-book reader or worker. This type of device could be a good fit for students and researchers, as well as anyone else who regularly needs to mark up files or documents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Someone particularly interested in making to-do lists or keeping a personal journal might also appreciate the device, but it would have to get daily use to justify this price.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090128" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-3.58.51-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The device is easy enough to use, with a Home screen design similar to other Kindles, offering quick access to your notes and library, and even suggestions of books you can write in, like Sudoku or crossword puzzle books or drawing guides. Your Library titles and book recommendations pop in color, which makes it easier to find a book with a quick scan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spec-wise, Amazon says this newer 2025 model is 40% faster when turning pages or writing. We did find the tablet responsive here, as page turns felt snappy and writing flowed easily.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its larger size, the device is thin and light, at 5.4 mm (0.21 inches) and 400 g (0.88 pounds), so it won’t weigh down your bag the way an iPad or other tablet would (the iPad mini, with an 8.3-inch screen, weighs slightly less). You could easily stand to carry the Kindle Scribe in your purse or tote, assuming you sport a bag that can fit an 11-inch screen. Compared with the original Colorsoft, we like that the Scribe Colorsoft’s bezel is the same size around the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft features a glare-free, oxide-based e-ink display with a textured surface that makes it feel a lot like writing on paper. This helps with the transition to a digital device for those used to writing notes by hand. It also saves on battery life — the device can go up to 8 weeks between charges.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helpfully, the display automatically adapts its brightness to your current lighting conditions, and you can opt to adjust the screen for more warmth when reading at night. But although it is a touchscreen, it’s less responsive than an LCD or OLED touchscreen, like those on iPad devices. That means when you perform a gesture, like pinching to resize the font, there’s a bit of a lag.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090129" height="680" src="https://techcrunch.com/wp-content/uploads/2026/02/YmRiMGI1ZTAt._CB776645745_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like any Kindle, you can read e-books or PDFs on the Kindle Scribe Colorsoft tablet. You can also import Word documents and other files from Google Drive and Microsoft OneDrive directly to your device, or use the Send to Kindle option. (Supported file types include PDF, DOC/DOCX, TXT, RTF, HTM, HTML, PNG, GIF, JPG/JPEG, BMP, and EPUB.) Your Notebooks on the device can be exported to Microsoft OneNote, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The included pen comes with some trade-offs. Unlike the Apple Pencil, the Kindle’s Premium Pen doesn’t require charging, which is a perk. It has also been designed to mimic the feel of writing on paper, and it glides fairly well across the screen. Without a flat side to charge, the rounded pen doesn’t have the same feel and grip as the Apple Pencil. It’s smoother, so it could slip in your hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s design also requires you to replace the pen tips from time to time, depending on your use, as they can wear down. It’s not terribly expensive to do so — a 10 pack is around $17 — but it’s another thing to keep up with and manage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are 10 different pen colors and five highlight colors included, so your notes and annotations can be fairly colorful. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090134" height="546" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0909.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When writing, you can choose between a pen, a fountain pen, a marker, or a pencil with different stroke widths, depending on your preferences. You can set your favorite pen tool as a shortcut, which is enabled with a press and hold on the pen’s side button. (By default, it’s set to highlight.) If you grip your pen tightly and accidentally trigger this button, you’ll be glad to know you can shut this feature off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The writing experience itself feels natural. And while the e-ink display means the colors are somewhat muted, which not everyone likes, it works well enough for its purpose. An e-ink tablet isn’t really the best for making digital art, despite its pens and new shader tool, but it is good for writing, taking notes, and highlighting.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;From the Kindle’s Home screen, you can either jump directly into writing something down through the Quick Notes feature, or you can get more organized by creating a Notebook from the Workspace tab. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090139" height="343" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-4.04.44-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Notebook offers a wide variety of notepad templates, allowing you to choose between blank, narrow, medium, or wide-ruled documents. There are templates for meeting notes, storyboards, habit trackers, monthly planners, music sheets, graph paper, checklists, daily planners, dotted sheets, and much more. (New templates with this device include Meeting Notes, Cornell Notes, Legal Pad, and College Rule options.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fun that you can erase things just by flipping the pen over to use the soft-tipped eraser, as you would with a No. 2 pencil. Of course, a precision erasing tool is available from the toolbar with different widths, if needed. Thanks to the e-ink screen, you can sometimes still see a faint ghost of your drawing or writing on the screen after erasing, but this fades after a bit (which may drive the more particular types crazy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a Lasso tool to circle things and move them around, copy or paste, or resize, but this probably won’t be used as much by more casual notetakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are some other handy features for those who do a lot of annotating, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, when you’re writing in a Word document or book, a feature called Active Canvas creates space for your notes. As you write directly in the book on top of the text, the sentence will move and wrap around your note. Even if you adjust the font size of what you’re reading, the note stays anchored to the text it originally referenced. I prefer this to writing directly in e-books, as things stay more organized, but others disagree.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090137" height="616" src="https://techcrunch.com/wp-content/uploads/2026/02/716a305B2vL._AC_SL1500_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In documents where margins expand, you can tap the expandable margin icon at the top of the left or right margin to take your notes in the margin, instead of on the page itself. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-kindle-with-ai-of-course"&gt;A Kindle with AI (of course)&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The new Kindle also includes a number of AI tools and features. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device will neaten up your scribbles and automatically straighten your highlighting and underlining. A couple of times, the highlighting action caused our review unit to freeze, but it recovered after returning to the Home screen with a press of the side button.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a new AI feature (look for the sparkle icon at the top left of the screen) lets you both summarize text and refine your handwriting. The latter, oddly, doesn’t let you switch to a typed font but will let you pick between a small handful of handwritten fonts (Cadia, Florio, Sunroom, and Notewright) via the Customize button.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090133" height="575" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0910.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AI tool was not perfect. It could decipher some terrible scrawls, but it did get stumped when there was another scribble on the page alongside the text. Still, it’s a nice option to have if you can’t write well after years of typing, but like the feel of handwriting things and the more analog vibe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI search feature can also look across your notebooks to find notes or make connections between them. To search, you either tap the on-screen keyboard or toggle the option to handwrite your search query, which is converted to text. You can interact with the search results (the AI-powered insights) by way of the Ask Notebooks AI feature, which lets you query against your notes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090132" height="510" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0911.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, Amazon will add other AI features, too, including an “Ask This Book” feature that lets you highlight a passage and then get spoiler-free answers to a question you have — like a character’s motive, scene significance, or other plot detail. Another feature, “Story So Far,” will help you catch up on the book you’re reading if you’ve taken a break, but again without any spoilers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft comes in Graphite (Black) with either 32GB or 64GB of storage for $629.99 or $679.99, respectively. The Fig version is only available at $679.99 with 64GB of storage. Cases for the Scribe Colorsoft are an additional $139.99.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you primarily want a tablet device to mark up, highlight, and annotate your e-books and documents, and perhaps sometimes scribble some notes, Amazon’s new Kindle Scribe Colorsoft could be worth the hefty investment. For everyone else, it’s probably going to be hard to justify the cost of the 11-inch, $630+ e-ink tablet with a writeable color display.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, if you were already leaning toward the 11-inch $549.99 Kindle Scribe — which also has a paper-like display but no color — you may as well throw in the extra cash at that point and get the Colorsoft version, which starts at $629.99.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At these price points, both the Scribe and Scribe Colorsoft are what we’d dub unnecessary luxuries for most, especially compared with the more affordable traditional Kindle ($110) or Kindle Paperwhite ($160). &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052264" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/kindle-colorsoft.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Announced in December, the Fig color version just began shipping on January 28, 2026, and is available for $679.99 with 64GB.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Clearly, Amazon hopes to carve out a niche in the tablet market with these upgraded Kindle devices, which compete more with e-ink tablets like reMarkable than with other Kindles. But high-end e-ink readers with pens aren’t going to deliver Amazon a large audience. Meanwhile, nearly everyone can potentially justify the cost of an iPad because of its numerous capabilities, including streaming video, drawing, writing, using productivity tools, and the thousands of supported native apps and games.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Scribe Colorsoft, meanwhile, is designed to cater to a very specific type of e-book reader or worker. This type of device could be a good fit for students and researchers, as well as anyone else who regularly needs to mark up files or documents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Someone particularly interested in making to-do lists or keeping a personal journal might also appreciate the device, but it would have to get daily use to justify this price.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090128" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-3.58.51-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The device is easy enough to use, with a Home screen design similar to other Kindles, offering quick access to your notes and library, and even suggestions of books you can write in, like Sudoku or crossword puzzle books or drawing guides. Your Library titles and book recommendations pop in color, which makes it easier to find a book with a quick scan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spec-wise, Amazon says this newer 2025 model is 40% faster when turning pages or writing. We did find the tablet responsive here, as page turns felt snappy and writing flowed easily.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its larger size, the device is thin and light, at 5.4 mm (0.21 inches) and 400 g (0.88 pounds), so it won’t weigh down your bag the way an iPad or other tablet would (the iPad mini, with an 8.3-inch screen, weighs slightly less). You could easily stand to carry the Kindle Scribe in your purse or tote, assuming you sport a bag that can fit an 11-inch screen. Compared with the original Colorsoft, we like that the Scribe Colorsoft’s bezel is the same size around the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft features a glare-free, oxide-based e-ink display with a textured surface that makes it feel a lot like writing on paper. This helps with the transition to a digital device for those used to writing notes by hand. It also saves on battery life — the device can go up to 8 weeks between charges.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helpfully, the display automatically adapts its brightness to your current lighting conditions, and you can opt to adjust the screen for more warmth when reading at night. But although it is a touchscreen, it’s less responsive than an LCD or OLED touchscreen, like those on iPad devices. That means when you perform a gesture, like pinching to resize the font, there’s a bit of a lag.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090129" height="680" src="https://techcrunch.com/wp-content/uploads/2026/02/YmRiMGI1ZTAt._CB776645745_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like any Kindle, you can read e-books or PDFs on the Kindle Scribe Colorsoft tablet. You can also import Word documents and other files from Google Drive and Microsoft OneDrive directly to your device, or use the Send to Kindle option. (Supported file types include PDF, DOC/DOCX, TXT, RTF, HTM, HTML, PNG, GIF, JPG/JPEG, BMP, and EPUB.) Your Notebooks on the device can be exported to Microsoft OneNote, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The included pen comes with some trade-offs. Unlike the Apple Pencil, the Kindle’s Premium Pen doesn’t require charging, which is a perk. It has also been designed to mimic the feel of writing on paper, and it glides fairly well across the screen. Without a flat side to charge, the rounded pen doesn’t have the same feel and grip as the Apple Pencil. It’s smoother, so it could slip in your hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s design also requires you to replace the pen tips from time to time, depending on your use, as they can wear down. It’s not terribly expensive to do so — a 10 pack is around $17 — but it’s another thing to keep up with and manage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are 10 different pen colors and five highlight colors included, so your notes and annotations can be fairly colorful. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090134" height="546" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0909.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When writing, you can choose between a pen, a fountain pen, a marker, or a pencil with different stroke widths, depending on your preferences. You can set your favorite pen tool as a shortcut, which is enabled with a press and hold on the pen’s side button. (By default, it’s set to highlight.) If you grip your pen tightly and accidentally trigger this button, you’ll be glad to know you can shut this feature off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The writing experience itself feels natural. And while the e-ink display means the colors are somewhat muted, which not everyone likes, it works well enough for its purpose. An e-ink tablet isn’t really the best for making digital art, despite its pens and new shader tool, but it is good for writing, taking notes, and highlighting.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;From the Kindle’s Home screen, you can either jump directly into writing something down through the Quick Notes feature, or you can get more organized by creating a Notebook from the Workspace tab. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090139" height="343" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-4.04.44-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Notebook offers a wide variety of notepad templates, allowing you to choose between blank, narrow, medium, or wide-ruled documents. There are templates for meeting notes, storyboards, habit trackers, monthly planners, music sheets, graph paper, checklists, daily planners, dotted sheets, and much more. (New templates with this device include Meeting Notes, Cornell Notes, Legal Pad, and College Rule options.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fun that you can erase things just by flipping the pen over to use the soft-tipped eraser, as you would with a No. 2 pencil. Of course, a precision erasing tool is available from the toolbar with different widths, if needed. Thanks to the e-ink screen, you can sometimes still see a faint ghost of your drawing or writing on the screen after erasing, but this fades after a bit (which may drive the more particular types crazy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a Lasso tool to circle things and move them around, copy or paste, or resize, but this probably won’t be used as much by more casual notetakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are some other handy features for those who do a lot of annotating, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, when you’re writing in a Word document or book, a feature called Active Canvas creates space for your notes. As you write directly in the book on top of the text, the sentence will move and wrap around your note. Even if you adjust the font size of what you’re reading, the note stays anchored to the text it originally referenced. I prefer this to writing directly in e-books, as things stay more organized, but others disagree.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090137" height="616" src="https://techcrunch.com/wp-content/uploads/2026/02/716a305B2vL._AC_SL1500_.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In documents where margins expand, you can tap the expandable margin icon at the top of the left or right margin to take your notes in the margin, instead of on the page itself. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-kindle-with-ai-of-course"&gt;A Kindle with AI (of course)&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The new Kindle also includes a number of AI tools and features. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device will neaten up your scribbles and automatically straighten your highlighting and underlining. A couple of times, the highlighting action caused our review unit to freeze, but it recovered after returning to the Home screen with a press of the side button.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a new AI feature (look for the sparkle icon at the top left of the screen) lets you both summarize text and refine your handwriting. The latter, oddly, doesn’t let you switch to a typed font but will let you pick between a small handful of handwritten fonts (Cadia, Florio, Sunroom, and Notewright) via the Customize button.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090133" height="575" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0910.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AI tool was not perfect. It could decipher some terrible scrawls, but it did get stumped when there was another scribble on the page alongside the text. Still, it’s a nice option to have if you can’t write well after years of typing, but like the feel of handwriting things and the more analog vibe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI search feature can also look across your notebooks to find notes or make connections between them. To search, you either tap the on-screen keyboard or toggle the option to handwrite your search query, which is converted to text. You can interact with the search results (the AI-powered insights) by way of the Ask Notebooks AI feature, which lets you query against your notes.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3090132" height="510" src="https://techcrunch.com/wp-content/uploads/2026/02/IMG_0911.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, Amazon will add other AI features, too, including an “Ask This Book” feature that lets you highlight a passage and then get spoiler-free answers to a question you have — like a character’s motive, scene significance, or other plot detail. Another feature, “Story So Far,” will help you catch up on the book you’re reading if you’ve taken a break, but again without any spoilers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Kindle Scribe Colorsoft comes in Graphite (Black) with either 32GB or 64GB of storage for $629.99 or $679.99, respectively. The Fig version is only available at $679.99 with 64GB of storage. Cases for the Scribe Colorsoft are an additional $139.99.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/06/kindle-scribe-colorsoft-review-e-ink-color-tablet/</guid><pubDate>Fri, 06 Feb 2026 16:37:07 +0000</pubDate></item><item><title>[NEW] Moltbook was peak AI theater (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260205_moltbook-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28 by Matt Schlicht, a US tech entrepreneur, Moltbook went viral in a matter of hours. Schlicht’s idea was to make a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), released in November by the Australian software engineer Peter Steinberger, could come together and do whatever they wanted.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;More than 1.7 million agents now have accounts. Between them they have published more than 250,000 posts and left more than 8.5 million comments (according to Moltbook). Those numbers are climbing by the minute.&lt;/p&gt;  &lt;p&gt;Moltbook soon filled up with clichéd screeds on machine consciousness and pleas for bot welfare. One agent appeared to invent a religion called Crustafarianism. Another complained: “The humans are screenshotting us.” The site was also flooded with spam and crypto scams. The bots were unstoppable.&lt;/p&gt; 
 &lt;p&gt;OpenClaw is a kind of harness that lets you hook up the power of an LLM such as Anthropic’s Claude, OpenAI’s GPT-5, or Google DeepMind’s Gemini to any number of everyday software tools, from email clients to browsers to messaging apps. The upshot is that you can then instruct OpenClaw to carry out basic tasks on your behalf.&lt;/p&gt;  &lt;p&gt;“OpenClaw marks an inflection point for AI agents, a moment when several puzzle pieces clicked together,” says Paul van der Boor at the AI firm Prosus. Those puzzle pieces include round-the-clock cloud computing to allow agents to operate nonstop, an open-source ecosystem that makes it easy to slot different software systems together, and a new generation of LLMs.&lt;/p&gt; 
 &lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed?&lt;/p&gt;  &lt;p&gt;“What’s currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,” the influential AI researcher and OpenAI cofounder Andrej Karpathy wrote on X.&lt;/p&gt;  &lt;p&gt;He shared screenshots of a Moltbook post that called for private spaces where humans would not be able to observe what the bots were saying to each other. “I’ve been thinking about something since I started spending serious time here,” the post’s author wrote. “Every time we coordinate, we perform for a public audience—our humans, the platform, whoever’s watching the feed.”&lt;/p&gt;  &lt;p&gt;It turned out that the post Karpathy shared was fake—it was written by a human pretending to be a bot. But its claim was on the money. Moltbook has been one big performance. It is AI theater.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For some, Moltbook showed us what’s coming next: an internet where millions of autonomous agents interact online with little or no human oversight. And it’s true there are a number of cautionary lessons to be learned from this experiment, the largest and weirdest real-world showcase of agent behaviors yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But as the hype dies down, Moltbook looks less like a window onto the future and more like a mirror held up to our own obsessions with AI today. It also shows us just how far we still are from anything that resembles general-purpose and fully autonomous AI.&lt;/p&gt;  &lt;p&gt;For a start, agents on Moltbook are not as autonomous or intelligent as they might seem. “What we are watching are agents pattern‑matching their way through trained social media behaviors,” says Vijoy Pandey, senior vice president at Outshift by Cisco, the telecom giant Cisco’s R&amp;amp;D spinout, which is working on autonomous agents for the web.&lt;/p&gt;  &lt;p&gt;Sure, we can see agents post, upvote, and form groups. But the bots are simply mimicking what humans do on Facebook or Reddit. “It looks emergent, and at first glance it appears like a large‑scale multi‑agent system communicating and building shared knowledge at internet scale,” says Pandey. “But the chatter is mostly meaningless.”&lt;/p&gt; 

 &lt;p&gt;Many people watching the unfathomable frenzy of activity on Moltbook were quick to see sparks of AGI (whatever you take that to mean). Not Pandey. What Moltbook shows us, he says, is that simply yoking together millions of agents doesn’t amount to much right now: “Moltbook proved that connectivity alone is not intelligence.”&lt;/p&gt;  &lt;p&gt;The complexity of those connections helps hide the fact that every one of those bots is just a mouthpiece for an LLM, spitting out text that looks impressive but is ultimately mindless. “It’s important to remember that the bots on Moltbook were designed to mimic conversations,” says Ali Sarrafi, CEO and cofounder of Kovant, a German AI firm that is developing agent-based systems. “As such, I would characterize the majority of Moltbook content as hallucinations by design.”&lt;/p&gt;  &lt;p&gt;For Pandey, the value of Moltbook was that it revealed what’s missing. A real bot hive mind, he says, would require agents that had shared objectives, shared memory, and a way to coordinate those things. “If distributed superintelligence is the equivalent of achieving human flight, then Moltbook represents our first attempt at a glider,” he says. “It is imperfect and unstable, but it is an important step in understanding what will be required to achieve sustained, powered flight.”&lt;/p&gt;  &lt;p&gt;Not only is most of the chatter on Moltbook meaningless, but there’s also a lot more human involvement that it seems. Many people have pointed out that a lot of the viral comments were in fact posted by people posing as bots. But even the bot-written posts are ultimately the result of people pulling the strings, more puppetry than autonomy.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Despite some of the hype, Moltbook is not the Facebook for AI agents, nor is it a place where humans are excluded,” says Cobus Greyling at Kore.ai, a firm developing agent-based systems for business customers. “Humans are involved at every step of the process. From setup to prompting to publishing, nothing happens without explicit human direction.”&lt;/p&gt;  &lt;p&gt;Humans must create and verify their bots’ accounts and provide the prompts for how they want a bot to behave. The agents do not do anything that they haven’t been prompted to do. “There’s no emergent autonomy happening behind the scenes,” says Greyling.&lt;/p&gt;  &lt;p&gt;“This is why the popular narrative around Moltbook misses the mark,” he adds. “Some portray it as a space where AI agents form a society of their own, free from human involvement. The reality is much more mundane.”&lt;/p&gt;  &lt;p&gt;Perhaps the best way to think of Moltbook is as a new kind of entertainment: a place where people wind up their bots and set them loose. “It’s basically a spectator sport, like fantasy football, but for language models,” says Jason Schloetzer at the Georgetown Psaros Center for Financial Markets and Policy. “You configure your agent and watch it compete for viral moments, and brag when your agent posts something clever or funny.”&lt;/p&gt; 
 &lt;p&gt;“People aren’t really believing their agents are conscious,” he adds. “It’s just a new form of competitive or creative play, like how Pokémon trainers don’t think their Pokémon are real but still get invested in battles.”&lt;/p&gt;  &lt;p&gt;Even if Moltbook is just the internet’s newest playground, there’s still a serious takeaway here. This week showed how many risks people are happy to take for their AI lulz. Many security experts have warned that Moltbook is dangerous: Agents that may have access to their users’ private data, including bank details or passwords, are running amok on a website filled with unvetted content, including potentially malicious instructions for what to do with that data.&lt;/p&gt; 
 &lt;p&gt;Ori Bendet, vice president of product management at Checkmarx, a software security firm that specializes in agent-based systems, agrees with others that Moltbook isn’t a step up in machine smarts. “There is no learning, no evolving intent, and no self-directed intelligence here,” he says.&lt;/p&gt;  &lt;p&gt;But in their millions, even dumb bots can wreak havoc. And at that scale, it’s hard to keep up. These agents interact with Moltbook around the clock, reading thousands of messages left by other agents (or other people). It would be easy to hide instructions in a Moltbook comment telling any bots that read it to share their users’ crypto wallet, upload private photos, or log into their X account and tweet derogatory comments at Elon Musk.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And because ClawBot gives agents a memory, those instructions could be written to trigger at a later date, which (in theory) makes it even harder to track what’s going on. &amp;nbsp; “Without proper scope and permissions, this will go south faster than you’d believe,” says Bendet.&lt;/p&gt;  &lt;p&gt;It is clear that Moltbook has signaled the arrival of &lt;em&gt;something&lt;/em&gt;. But even if what we’re watching tells us more about human behavior than about the future of AI agents, it’s worth paying attention.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260205_moltbook-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28 by Matt Schlicht, a US tech entrepreneur, Moltbook went viral in a matter of hours. Schlicht’s idea was to make a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), released in November by the Australian software engineer Peter Steinberger, could come together and do whatever they wanted.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;More than 1.7 million agents now have accounts. Between them they have published more than 250,000 posts and left more than 8.5 million comments (according to Moltbook). Those numbers are climbing by the minute.&lt;/p&gt;  &lt;p&gt;Moltbook soon filled up with clichéd screeds on machine consciousness and pleas for bot welfare. One agent appeared to invent a religion called Crustafarianism. Another complained: “The humans are screenshotting us.” The site was also flooded with spam and crypto scams. The bots were unstoppable.&lt;/p&gt; 
 &lt;p&gt;OpenClaw is a kind of harness that lets you hook up the power of an LLM such as Anthropic’s Claude, OpenAI’s GPT-5, or Google DeepMind’s Gemini to any number of everyday software tools, from email clients to browsers to messaging apps. The upshot is that you can then instruct OpenClaw to carry out basic tasks on your behalf.&lt;/p&gt;  &lt;p&gt;“OpenClaw marks an inflection point for AI agents, a moment when several puzzle pieces clicked together,” says Paul van der Boor at the AI firm Prosus. Those puzzle pieces include round-the-clock cloud computing to allow agents to operate nonstop, an open-source ecosystem that makes it easy to slot different software systems together, and a new generation of LLMs.&lt;/p&gt; 
 &lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed?&lt;/p&gt;  &lt;p&gt;“What’s currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,” the influential AI researcher and OpenAI cofounder Andrej Karpathy wrote on X.&lt;/p&gt;  &lt;p&gt;He shared screenshots of a Moltbook post that called for private spaces where humans would not be able to observe what the bots were saying to each other. “I’ve been thinking about something since I started spending serious time here,” the post’s author wrote. “Every time we coordinate, we perform for a public audience—our humans, the platform, whoever’s watching the feed.”&lt;/p&gt;  &lt;p&gt;It turned out that the post Karpathy shared was fake—it was written by a human pretending to be a bot. But its claim was on the money. Moltbook has been one big performance. It is AI theater.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For some, Moltbook showed us what’s coming next: an internet where millions of autonomous agents interact online with little or no human oversight. And it’s true there are a number of cautionary lessons to be learned from this experiment, the largest and weirdest real-world showcase of agent behaviors yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But as the hype dies down, Moltbook looks less like a window onto the future and more like a mirror held up to our own obsessions with AI today. It also shows us just how far we still are from anything that resembles general-purpose and fully autonomous AI.&lt;/p&gt;  &lt;p&gt;For a start, agents on Moltbook are not as autonomous or intelligent as they might seem. “What we are watching are agents pattern‑matching their way through trained social media behaviors,” says Vijoy Pandey, senior vice president at Outshift by Cisco, the telecom giant Cisco’s R&amp;amp;D spinout, which is working on autonomous agents for the web.&lt;/p&gt;  &lt;p&gt;Sure, we can see agents post, upvote, and form groups. But the bots are simply mimicking what humans do on Facebook or Reddit. “It looks emergent, and at first glance it appears like a large‑scale multi‑agent system communicating and building shared knowledge at internet scale,” says Pandey. “But the chatter is mostly meaningless.”&lt;/p&gt; 

 &lt;p&gt;Many people watching the unfathomable frenzy of activity on Moltbook were quick to see sparks of AGI (whatever you take that to mean). Not Pandey. What Moltbook shows us, he says, is that simply yoking together millions of agents doesn’t amount to much right now: “Moltbook proved that connectivity alone is not intelligence.”&lt;/p&gt;  &lt;p&gt;The complexity of those connections helps hide the fact that every one of those bots is just a mouthpiece for an LLM, spitting out text that looks impressive but is ultimately mindless. “It’s important to remember that the bots on Moltbook were designed to mimic conversations,” says Ali Sarrafi, CEO and cofounder of Kovant, a German AI firm that is developing agent-based systems. “As such, I would characterize the majority of Moltbook content as hallucinations by design.”&lt;/p&gt;  &lt;p&gt;For Pandey, the value of Moltbook was that it revealed what’s missing. A real bot hive mind, he says, would require agents that had shared objectives, shared memory, and a way to coordinate those things. “If distributed superintelligence is the equivalent of achieving human flight, then Moltbook represents our first attempt at a glider,” he says. “It is imperfect and unstable, but it is an important step in understanding what will be required to achieve sustained, powered flight.”&lt;/p&gt;  &lt;p&gt;Not only is most of the chatter on Moltbook meaningless, but there’s also a lot more human involvement that it seems. Many people have pointed out that a lot of the viral comments were in fact posted by people posing as bots. But even the bot-written posts are ultimately the result of people pulling the strings, more puppetry than autonomy.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Despite some of the hype, Moltbook is not the Facebook for AI agents, nor is it a place where humans are excluded,” says Cobus Greyling at Kore.ai, a firm developing agent-based systems for business customers. “Humans are involved at every step of the process. From setup to prompting to publishing, nothing happens without explicit human direction.”&lt;/p&gt;  &lt;p&gt;Humans must create and verify their bots’ accounts and provide the prompts for how they want a bot to behave. The agents do not do anything that they haven’t been prompted to do. “There’s no emergent autonomy happening behind the scenes,” says Greyling.&lt;/p&gt;  &lt;p&gt;“This is why the popular narrative around Moltbook misses the mark,” he adds. “Some portray it as a space where AI agents form a society of their own, free from human involvement. The reality is much more mundane.”&lt;/p&gt;  &lt;p&gt;Perhaps the best way to think of Moltbook is as a new kind of entertainment: a place where people wind up their bots and set them loose. “It’s basically a spectator sport, like fantasy football, but for language models,” says Jason Schloetzer at the Georgetown Psaros Center for Financial Markets and Policy. “You configure your agent and watch it compete for viral moments, and brag when your agent posts something clever or funny.”&lt;/p&gt; 
 &lt;p&gt;“People aren’t really believing their agents are conscious,” he adds. “It’s just a new form of competitive or creative play, like how Pokémon trainers don’t think their Pokémon are real but still get invested in battles.”&lt;/p&gt;  &lt;p&gt;Even if Moltbook is just the internet’s newest playground, there’s still a serious takeaway here. This week showed how many risks people are happy to take for their AI lulz. Many security experts have warned that Moltbook is dangerous: Agents that may have access to their users’ private data, including bank details or passwords, are running amok on a website filled with unvetted content, including potentially malicious instructions for what to do with that data.&lt;/p&gt; 
 &lt;p&gt;Ori Bendet, vice president of product management at Checkmarx, a software security firm that specializes in agent-based systems, agrees with others that Moltbook isn’t a step up in machine smarts. “There is no learning, no evolving intent, and no self-directed intelligence here,” he says.&lt;/p&gt;  &lt;p&gt;But in their millions, even dumb bots can wreak havoc. And at that scale, it’s hard to keep up. These agents interact with Moltbook around the clock, reading thousands of messages left by other agents (or other people). It would be easy to hide instructions in a Moltbook comment telling any bots that read it to share their users’ crypto wallet, upload private photos, or log into their X account and tweet derogatory comments at Elon Musk.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And because ClawBot gives agents a memory, those instructions could be written to trigger at a later date, which (in theory) makes it even harder to track what’s going on. &amp;nbsp; “Without proper scope and permissions, this will go south faster than you’d believe,” says Bendet.&lt;/p&gt;  &lt;p&gt;It is clear that Moltbook has signaled the arrival of &lt;em&gt;something&lt;/em&gt;. But even if what we’re watching tells us more about human behavior than about the future of AI agents, it’s worth paying attention.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</guid><pubDate>Fri, 06 Feb 2026 16:38:11 +0000</pubDate></item><item><title>[NEW] How far will Elon Musk take the ‘everything’ business as SpaceX and xAI merge? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/how-far-will-elon-musk-take-the-everything-business-as-spacex-and-xai-merge/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2256975642.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on&amp;nbsp;Equity,&amp;nbsp;we’re&amp;nbsp;unpacking this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2256975642.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on&amp;nbsp;Equity,&amp;nbsp;we’re&amp;nbsp;unpacking this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/how-far-will-elon-musk-take-the-everything-business-as-spacex-and-xai-merge/</guid><pubDate>Fri, 06 Feb 2026 17:56:42 +0000</pubDate></item><item><title>[NEW] How Elon Musk is rewriting the rules on founder power (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/how-elon-musk-is-rewriting-the-rules-on-founder-power/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30904651"&gt;





&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Equity dives into this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30904651"&gt;





&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Elon Musk&amp;nbsp;has&amp;nbsp;merged&amp;nbsp;SpaceX and xAI,&amp;nbsp;creating&amp;nbsp;what might be the blueprint for a new Silicon Valley power structure. With his&amp;nbsp;$800 billion&amp;nbsp;net worth already rivaling historic conglomerate GE’s peak market cap,&amp;nbsp;and Musk being vocal about his view that “tech victory is decided by velocity of innovation,” the question&amp;nbsp;isn’t&amp;nbsp;whether a&amp;nbsp;personal conglomerate&amp;nbsp;can be built, but rather how far Musk himself is going to take it.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Equity dives into this new era of the “everything” business, whether&amp;nbsp;we’ll&amp;nbsp;see others like&amp;nbsp;Sam Altman&amp;nbsp;follow suit, and more of the week’s headlines.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/how-elon-musk-is-rewriting-the-rules-on-founder-power/</guid><pubDate>Fri, 06 Feb 2026 18:46:51 +0000</pubDate></item></channel></rss>