<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 18 Jun 2025 18:31:25 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Pope Leo makes AI’s threat to humanity a signature issue (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/pope-leo-makes-ais-threat-to-humanity-a-signature-issue/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2213411719.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Pope Leo XIV is making the threat of AI to humanity a key issue of his legacy, challenging the technology industry that has spent years courting the Vatican.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new American pope’s namesake, Leo XIII, stood up for the rights of factory workers during the Gilded Age, a period in the 19th century of swift economic change and extreme wealth inequality led by corrupt industrial robber barons.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Speaking to a hall of cardinals last month, the pope said he would rely on 2,000 years of church social teaching to “respond to another industrial revolution and to innovations in the field of artificial intelligence that pose challenges to human dignity, justice, and labor,” reports The Wall Street Journal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In attempts to shape Rome’s dialogue on AI and, by association, influence governments and policymakers, leaders of Google, Microsoft, Cisco and other tech giants have flown to the Vatican to preach the good word of emerging technologies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Vatican has pushed for a binding international treaty on AI, something most tech CEOs would say threatens to stifle innovation.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2213411719.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Pope Leo XIV is making the threat of AI to humanity a key issue of his legacy, challenging the technology industry that has spent years courting the Vatican.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new American pope’s namesake, Leo XIII, stood up for the rights of factory workers during the Gilded Age, a period in the 19th century of swift economic change and extreme wealth inequality led by corrupt industrial robber barons.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Speaking to a hall of cardinals last month, the pope said he would rely on 2,000 years of church social teaching to “respond to another industrial revolution and to innovations in the field of artificial intelligence that pose challenges to human dignity, justice, and labor,” reports The Wall Street Journal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In attempts to shape Rome’s dialogue on AI and, by association, influence governments and policymakers, leaders of Google, Microsoft, Cisco and other tech giants have flown to the Vatican to preach the good word of emerging technologies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Vatican has pushed for a binding international treaty on AI, something most tech CEOs would say threatens to stifle innovation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/pope-leo-makes-ais-threat-to-humanity-a-signature-issue/</guid><pubDate>Wed, 18 Jun 2025 08:05:31 +0000</pubDate></item><item><title>Why AI hardware needs to be open (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1118943/ai-hardware-open/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/maker-mat2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When OpenAI acquired Io to create “the coolest piece of tech that the world will have ever seen,” it confirmed what industry experts have long been saying: Hardware is the new frontier for AI. AI will no longer just be an abstract thing in the cloud far away. It’s coming for our homes, our rooms, our beds, our bodies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That should worry us.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Once again, the future of technology is being engineered in secret by a handful of people and delivered to the rest of us as a sealed, seamless, perfect device. When technology is designed in secrecy and sold to us as a black box, we are reduced to consumers. We wait for updates. We adapt to features. We don’t shape the tools; they shape us.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is a problem. And not just for tinkerers and technologists, but for all of us.&lt;/p&gt; 
 &lt;p&gt;We are living through a crisis of disempowerment. Children are more anxious than ever; the former US surgeon general described a loneliness epidemic; people are increasingly worried about AI eroding education. The beautiful devices we use have been correlated with many of these trends. Now AI—arguably the most powerful technology of our era—is moving off the screen and into physical space.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The timing is not a coincidence. Hardware is having a renaissance. Every major tech company is investing in physical interfaces for AI. Startups are raising capital to build robots, glasses, wearables that are going to track our every move. The form factor of AI is the next battlefield. Do we really want our future mediated entirely through interfaces we can’t open, code we can’t see, and decisions we can’t influence?&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This moment creates an existential opening, a chance to do things differently. Because away from the self-centeredness of Silicon Valley, a quiet, grounded sense of resistance is reactivating. I’m calling it the revenge of the makers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2007, as the iPhone emerged, the maker movement was taking shape. This subculture advocates for learning-through-making in social environments like hackerspaces and libraries. DIY and open hardware enthusiasts gathered in person at Maker Faires—large events where people of all ages tinkered and shared their inventions in 3D printing, robotics, electronics, and more. Motivated by fun, self-fulfillment, and shared learning, the movement birthed companies like MakerBot, Raspberry Pi, Arduino, and (my own education startup) littleBits from garages and kitchen tables. I myself wanted to challenge the notion that technology had to be intimidating or inaccessible, creating modular electronic building blocks designed to put the power of invention in the hands of everyone.&lt;/p&gt;  &lt;p&gt;By definition, the maker movement is humble and it is consistent. Makers do not believe in the cult of individual genius; we believe in collective genius. We believe that creativity is universally distributed (not exclusively bestowed), that inventing is better together, and that we should make open products so people can observe, learn, and create—basically, the polar opposite of what Jony Ive and Sam Altman are building.&lt;/p&gt;  &lt;p&gt;But over time, the momentum faded. The movement was dismissed by the tech and investment industry as niche and hobbyist, and starting in 2018, pressures on the hardware venture market (followed by covid) made people retreat from social spaces to spend more time behind screens.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Now it’s mounting a powerful second act, joined by a wave of AI open-source enthusiasts. This time around the stakes are higher, and we need to give it the support it never had.&lt;/p&gt;  &lt;p&gt;In 2024 the AI leader Hugging Face developed an open-source platform for AI robots, which already has 3,500+ robot data sets and draws thousands of participants from every continent to join giant hackathons. Raspberry Pi went public on the London Stock Exchange for $700 million. After a hiatus, Maker Faire came back; the most recent one had nearly 30,000 attendees, with kinetic sculptures, flaming octopuses, and DIY robot bands, and this year there will be over 100 Maker Faires around the world. Just last week, DIY.org relaunched its app. In March, my friend Roya Mahboob, founder of the Afghan Girls Robotics Team, released a movie about the team to incredible reviews. People love the idea that making is the ultimate form of human empowerment and expression. All the while, a core set of people have continued influencing millions through maker organizations like FabLabs and Adafruit.&lt;/p&gt;  &lt;p&gt;Studies show that hands-on creativity reduces anxiety, combats loneliness, and boosts cognitive function. The act of making grounds us, connects us to others, and reminds us that we are capable of shaping the world with our own hands.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’m not proposing to reject AI hardware but to reject the idea that innovation must be proprietary, elite, and closed. I’m proposing to fund and build the open alternative. That means putting our investment, time, and purchases towards robot built in community labs, AI models trained in the open, tools made transparent and hackable. That world isn’t just more inclusive—it’s more innovative. It’s also more fun.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;This is not nostalgia. This is about fighting for the kind of future we want: A future of openness and joy, not of conformity and consumption. One where technology invites participation, not passivity. Where children grow up not just knowing how to swipe, but how to build. Where creativity is a shared endeavor, not the mythical province of lone geniuses in glass towers.&lt;/p&gt;  &lt;p&gt;In his Io announcement video, Altman said, “We are literally on the brink of a new generation of technology that can make us our better selves.” It reminded me of the movie &lt;em&gt;Mountainhead&lt;/em&gt;, where four tech moguls tell themselves they are saving the world while the world is burning. I don’t think the iPhone made us our better selves. In fact, you’ve never seen me run faster than when I’m trying to snatch an iPhone out of my three-year-old’s hands.&lt;/p&gt;  &lt;p&gt;So yes, I’m watching what Sam Altman and Jony Ive will unveil. But I’m far more excited by what’s happening in basements, in classrooms, on workbenches. Because the real iPhone moment isn’t a new product we wait for. It’s the moment you realize you can build it yourself. And best of all? You&amp;nbsp; can’t doomscroll when you’re holding a soldering iron.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ayah Bdeir is a leader in the maker movement, a champion of open source AI, and founder of littleBits, the hardware platform that teaches STEAM to kids through hands-on invention. A graduate of the MIT Media Lab, she was selected as one of the BBC’s 100 Most Influential Women, and her inventions have been acquired by the Museum of Modern Art.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/maker-mat2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When OpenAI acquired Io to create “the coolest piece of tech that the world will have ever seen,” it confirmed what industry experts have long been saying: Hardware is the new frontier for AI. AI will no longer just be an abstract thing in the cloud far away. It’s coming for our homes, our rooms, our beds, our bodies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That should worry us.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Once again, the future of technology is being engineered in secret by a handful of people and delivered to the rest of us as a sealed, seamless, perfect device. When technology is designed in secrecy and sold to us as a black box, we are reduced to consumers. We wait for updates. We adapt to features. We don’t shape the tools; they shape us.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is a problem. And not just for tinkerers and technologists, but for all of us.&lt;/p&gt; 
 &lt;p&gt;We are living through a crisis of disempowerment. Children are more anxious than ever; the former US surgeon general described a loneliness epidemic; people are increasingly worried about AI eroding education. The beautiful devices we use have been correlated with many of these trends. Now AI—arguably the most powerful technology of our era—is moving off the screen and into physical space.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The timing is not a coincidence. Hardware is having a renaissance. Every major tech company is investing in physical interfaces for AI. Startups are raising capital to build robots, glasses, wearables that are going to track our every move. The form factor of AI is the next battlefield. Do we really want our future mediated entirely through interfaces we can’t open, code we can’t see, and decisions we can’t influence?&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This moment creates an existential opening, a chance to do things differently. Because away from the self-centeredness of Silicon Valley, a quiet, grounded sense of resistance is reactivating. I’m calling it the revenge of the makers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2007, as the iPhone emerged, the maker movement was taking shape. This subculture advocates for learning-through-making in social environments like hackerspaces and libraries. DIY and open hardware enthusiasts gathered in person at Maker Faires—large events where people of all ages tinkered and shared their inventions in 3D printing, robotics, electronics, and more. Motivated by fun, self-fulfillment, and shared learning, the movement birthed companies like MakerBot, Raspberry Pi, Arduino, and (my own education startup) littleBits from garages and kitchen tables. I myself wanted to challenge the notion that technology had to be intimidating or inaccessible, creating modular electronic building blocks designed to put the power of invention in the hands of everyone.&lt;/p&gt;  &lt;p&gt;By definition, the maker movement is humble and it is consistent. Makers do not believe in the cult of individual genius; we believe in collective genius. We believe that creativity is universally distributed (not exclusively bestowed), that inventing is better together, and that we should make open products so people can observe, learn, and create—basically, the polar opposite of what Jony Ive and Sam Altman are building.&lt;/p&gt;  &lt;p&gt;But over time, the momentum faded. The movement was dismissed by the tech and investment industry as niche and hobbyist, and starting in 2018, pressures on the hardware venture market (followed by covid) made people retreat from social spaces to spend more time behind screens.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Now it’s mounting a powerful second act, joined by a wave of AI open-source enthusiasts. This time around the stakes are higher, and we need to give it the support it never had.&lt;/p&gt;  &lt;p&gt;In 2024 the AI leader Hugging Face developed an open-source platform for AI robots, which already has 3,500+ robot data sets and draws thousands of participants from every continent to join giant hackathons. Raspberry Pi went public on the London Stock Exchange for $700 million. After a hiatus, Maker Faire came back; the most recent one had nearly 30,000 attendees, with kinetic sculptures, flaming octopuses, and DIY robot bands, and this year there will be over 100 Maker Faires around the world. Just last week, DIY.org relaunched its app. In March, my friend Roya Mahboob, founder of the Afghan Girls Robotics Team, released a movie about the team to incredible reviews. People love the idea that making is the ultimate form of human empowerment and expression. All the while, a core set of people have continued influencing millions through maker organizations like FabLabs and Adafruit.&lt;/p&gt;  &lt;p&gt;Studies show that hands-on creativity reduces anxiety, combats loneliness, and boosts cognitive function. The act of making grounds us, connects us to others, and reminds us that we are capable of shaping the world with our own hands.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’m not proposing to reject AI hardware but to reject the idea that innovation must be proprietary, elite, and closed. I’m proposing to fund and build the open alternative. That means putting our investment, time, and purchases towards robot built in community labs, AI models trained in the open, tools made transparent and hackable. That world isn’t just more inclusive—it’s more innovative. It’s also more fun.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;This is not nostalgia. This is about fighting for the kind of future we want: A future of openness and joy, not of conformity and consumption. One where technology invites participation, not passivity. Where children grow up not just knowing how to swipe, but how to build. Where creativity is a shared endeavor, not the mythical province of lone geniuses in glass towers.&lt;/p&gt;  &lt;p&gt;In his Io announcement video, Altman said, “We are literally on the brink of a new generation of technology that can make us our better selves.” It reminded me of the movie &lt;em&gt;Mountainhead&lt;/em&gt;, where four tech moguls tell themselves they are saving the world while the world is burning. I don’t think the iPhone made us our better selves. In fact, you’ve never seen me run faster than when I’m trying to snatch an iPhone out of my three-year-old’s hands.&lt;/p&gt;  &lt;p&gt;So yes, I’m watching what Sam Altman and Jony Ive will unveil. But I’m far more excited by what’s happening in basements, in classrooms, on workbenches. Because the real iPhone moment isn’t a new product we wait for. It’s the moment you realize you can build it yourself. And best of all? You&amp;nbsp; can’t doomscroll when you’re holding a soldering iron.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ayah Bdeir is a leader in the maker movement, a champion of open source AI, and founder of littleBits, the hardware platform that teaches STEAM to kids through hands-on invention. A graduate of the MIT Media Lab, she was selected as one of the BBC’s 100 Most Influential Women, and her inventions have been acquired by the Museum of Modern Art.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1118943/ai-hardware-open/</guid><pubDate>Wed, 18 Jun 2025 08:49:23 +0000</pubDate></item><item><title>The quest to defend against tech in intimate partner violence (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1118235/big-tech-intimate-partner-violence/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their Massachusetts home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior. One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt;  &lt;p&gt;“What am I supposed to tell my daughter?” says Gioia, who is going by a pseudonym in this story out of safety concerns. “She’s so excited but doesn’t realize [it’s] a monitoring device for him to see where we are.” In the end, she decided not to confiscate the watch. Instead, she told her daughter to leave it at home whenever they went out together, saying that this way it wouldn’t get lost.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Gioia says she has informed a family court of this and many other instances in which her ex has used or appeared to use technology to stalk her, but so far this hasn’t helped her get full custody of her children. The court’s failure to recognize these tech-facilitated tactics for maintaining power and control has left her frustrated to the point where she yearns for visible bruises. “I wish he was breaking my arms and punching me in the face,” she says, “because then people could see it.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;People I spoke with for this article described combating tech-facilitated abuse as playing “whack-a-mole.” Just as you figure out how to alert people to smartphone location sharing, enter smart cars.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;This sentiment is unfortunately common among people experiencing what’s become known as TFA, or tech-­facilitated abuse. Defined by the National Network to End Domestic Violence as “the use of digital tools, online platforms, or electronic devices to control, harass, monitor, or harm someone,” these often invisible or below-the-radar methods include using spyware and hidden cameras; sharing intimate images on social media without consent; logging into and draining a partner’s online bank account; and using device-based location tracking, as Gioia’s ex did with their daughter’s smartwatch.&lt;/p&gt; 
 &lt;p&gt;Because technology is so ubiquitous, TFA occurs in most cases of intimate partner violence. And those whose jobs entail protecting victims and survivors and holding abusive actors accountable struggle to get a handle on this multi­faceted problem. An Australian study from October 2024, which drew on in-depth interviews with victims and survivors of TFA, found a “considerable gap” in the understanding of TFA among frontline workers like police and victim service providers, with the result that police repeatedly dismissed TFA reports and failed to identify such incidents as examples of intimate partner violence. The study also identified a significant shortage of funding for specialists—that is, computer scientists skilled in conducting safety scans on the devices of people experiencing TFA.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The dearth of understanding is particularly concerning because keeping up with the many faces of tech-facilitated abuse requires significant expertise and vigilance. As internet-connected cars and homes become more common and location tracking is increasingly normalized, novel opportunities are emerging to use technology to stalk and harass. In reporting this piece, I heard chilling tales of abusers who remotely locked partners in their own “smart homes,” sometimes turning up the heat for added torment. One woman who fled her abusive partner found an ominous message when she opened her Netflix account miles away: “Bitch I’m Watching You” spelled out where the names of the accounts’ users should be.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Despite the range of tactics, a 2022 survey of TFA-focused studies across a number of English-speaking countries found that the results readily map onto the Power and Control Wheel, a tool developed in Duluth, Minnesota, in the 1980s that categorizes the all-encompassing ways abusive partners exert power and control over victims: economically, emotionally, through threats, using children, and more. Michaela Rogers, the lead author of the study and a senior lecturer at the University of Sheffield in the UK, says she noted “paranoia, anxiety, depression, trauma and PTSD, low self-esteem … and self-harm” among TFA survivors in the wake of abuse that often pervaded every aspect of their lives.&lt;/p&gt;  &lt;p&gt;This kind of abuse is taxing and tricky to resolve alone. Service providers and victim advocates strive to help, but many lack tech skills, and they can’t stop tech companies from bringing products to market. Some work with those companies to help create safeguards, but there are limits to what businesses can do to hold abusive actors accountable. To establish real guardrails and dole out serious consequences, robust legal frameworks are needed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s been slow work, but there have been concerted efforts to address TFA at each of these levels in the past couple of years. Some US states have passed laws against using smart car technology or location trackers such as Apple AirTags for stalking and harassment. Tech companies, including Apple and Meta, have hired people with experience in victim services to guide development of product safeguards, and advocates for victims and survivors are seeking out more specialized tech education.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the ever-evolving nature of technology makes it nearly impossible to create a permanent fix. People I spoke with for this article described the effort as playing “whack-a-mole.” Just as you figure out how to alert people to smartphone location sharing, enter smart cars. Outlaw AirTag stalking and a newer, more effective tool appears that can legally track your ex. That’s why groups that uniquely address TFA, like the Clinic to End Tech Abuse (CETA) at Cornell Tech in New York City, are working to create permanent infrastructure. A problem that has typically been seen as a side focus for service organizations can finally get the treatment it deserves as a ubiquitous and potentially life-endangering aspect of intimate partner violence. &lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;Volunteer tech support&lt;/h3&gt;  &lt;p&gt;CETA saw its first client seven years ago. In a small white room on Cornell Tech’s Roosevelt Island campus, two computer scientists sat down with someone whose abuser had been accessing the photos on their iPhone. The person didn’t know how this was happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We worked with our client for about an hour and a half,” says one of the scientists, Thomas Ristenpart, “and realized it was probably an iCloud Family Sharing issue.”&lt;/p&gt;  &lt;p&gt;At the time, CETA was one of just two clinics in the country created to address TFA (the other being the Technology Enabled Coercive Control Clinic in Seattle), and it remains on the cutting edge of the issue.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Picture a Venn diagram, with one circle representing computer scientists and the other service providers for domestic violence victims. It’s practically two separate circles, with CETA occupying a thin overlapping slice. Tech experts are much more likely to be drawn to profitable companies or research institutions than social-work nonprofits, so it’s unexpected that a couple of academic researchers identified TFA as a problem and chose to dedicate their careers to combating it. Their work has won results, but the learning curve was steep.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;CETA grew out of an interest in measuring the “internet spyware software ecosystem” exploited in intimate partner violence, says Ristenpart. He and cofounder Nicola Dell initially figured they could help by building a tool that could scan phones for intrusive software. They quickly realized that this alone wouldn’t solve the problem—and could even compromise people’s safety if done carelessly, since it could alert abusers that their surveillance had been detected and was actively being thwarted.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="close-up of a hand holding an Apple AirTag" class="wp-image-1118672" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/onur-binay-x8VQhw4xbRk-unsplash.jpg?w=1655" width="1655" /&gt;&lt;figcaption class="wp-element-caption"&gt;In December, Ohio passed a law making AirTag stalking a crime. Florida is considering increasing penalties for people who use tracking devices to “commit or facilitate commission of dangerous crimes.”&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ONUR BINAY/UNSPLASH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Instead, Dell and Ristenpart studied the dynamics of coercive control. They conducted about 14 focus groups with professionals who worked daily with victims and survivors. They connected with organizations like the Anti-Violence Project and New York’s Family Justice Centers to get referrals. With the covid-19 pandemic, CETA went virtual and stayed that way. Its services now resemble “remote tech support,” Dell says. A handful of volunteers, many of whom work in Big Tech, receive clients’ intake information and guide them through processes for stopping unwanted location sharing, for example, on their devices.&lt;/p&gt;  &lt;p&gt;Remote support has sufficed because abusers generally aren’t carrying out the type of sophisticated attack that can be foiled only by disassembling a device. “For the most part, people are using standard tools in the way that they were designed to be used,” says Dell. For example, someone might throw an AirTag into a stroller to keep track of its whereabouts (and those of the person pushing it), or act as the admin of a shared online bank account.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Though CETA stands out as a tech-­centric service organization for survivors, anti-domestic-violence groups have been encountering and combating TFA for decades. When Cindy Southworth started her career in the domestic violence field in the 1990s, she heard of abusers doing rough location tracking using car odometers—the mileage could suggest, for instance, that a driver pretending to set out for the supermarket had instead left town to seek support. Later, when Southworth joined the Pennsylvania Coalition Against Domestic Violence, the advocacy community was looking at caller ID as “not only an incredibly powerful tool for survivors to be able to see who’s calling,” she recalls, “but also potentially a risky technology, if an abuser could see.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;As technology evolved, the ways abusers took advantage evolved too. Realizing that the advocacy community “was not up on tech,” Southworth founded the National Network to End Domestic Violence’s Safety Net Project in 2000 to provide a comprehensive training curriculum on how to “harness [technology] to help victims” and hold abusers accountable when they misuse it. Today, the project offers resources on its website, like tool kits that include guidance on strategies such as creating strong passwords and security questions. “When you’re in a relationship with someone,” explains director Audace Garnett, “they may know your mother’s maiden name.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Big Tech safeguards&lt;/h3&gt;  &lt;p&gt;Southworth’s efforts later extended to advising tech companies on how to protect users who have experienced intimate partner violence. In 2020, she joined Facebook (now Meta) as its head of women’s safety. “What really drew me to Facebook was the work on intimate image abuse,” she says, noting that the company had come up with one of the first “sextortion” policies in 2012. Now she works on “reactive hashing,” which adds “digital fingerprints” to images that have been identified as nonconsensual so that survivors only need to report them once for all repeats to get blocked.&lt;/p&gt;  &lt;p&gt;Other areas of concern include “cyberflashing,” in which someone might share, say, unwanted explicit photos. Meta has worked to prevent that on Instagram by not allowing accounts to send images, videos, or voice notes unless they follow you. Besides that, though, many of Meta’s practices surrounding potential abuse appear to be more reactive than proactive. The company says it removes online threats that violate its policies against bullying and that promote “offline violence.” But earlier this year, Meta made its policies about speech on its platforms more permissive. Now users are allowed to refer to women as “household objects,” reported CNN, and to post transphobic and homophobic comments that had formerly been banned.&lt;/p&gt;  &lt;p&gt;A key challenge is that the very same tech can be used for good or evil: A tracking function that’s dangerous for someone whose partner is using it to stalk them might help someone else stay abreast of a stalker’s whereabouts. When I asked sources what tech companies should be doing to mitigate technology-assisted abuse, researchers and lawyers alike tended to throw up their hands. One cited the problem of abusers using parental controls to monitor adults instead of children—tech companies won’t do away with those important features for keeping children safe, and there is only so much they can do to limit how customers use or misuse them. Safety Net’s Garnett said companies should design technology with safety in mind “from the get-go” but pointed out that in the case of many well-established products, it’s too late for that. A couple of computer scientists pointed to Apple as a company with especially effective security measures: Its closed ecosystem can block sneaky third-party apps and alert users when they’re being tracked. But these experts also acknowledged that none of these measures are foolproof.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Over roughly the past decade, major US-based tech companies including Google, Meta, Airbnb, Apple, and Amazon have launched safety advisory boards to address this conundrum. The strategies they have implemented vary. At Uber, board members share feedback on “potential blind spots” and have influenced the development of customizable safety tools, says Liz Dank, who leads work on women’s and personal safety at the company. One result of this collaboration is Uber’s PIN verification feature, in which riders have to give drivers a unique number assigned by the app in order for the ride to start. This ensures that they’re getting into the right car.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Apple’s approach has included detailed guidance in the form of a 140-page “Personal Safety User Guide.” Under one heading, “I want to escape or am considering leaving a relationship that doesn’t feel safe,” it provides links to pages about blocking and evidence collection and “safety steps that include unwanted tracking alerts.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Creative abusers can bypass these sorts of precautions. Recently Elizabeth (for privacy, we’re using her first name only) found an AirTag her ex had hidden inside a wheel well of her car, attached to a magnet and wrapped in duct tape. Months after the AirTag debuted, Apple had received enough reports about unwanted tracking to introduce a security measure letting users who’d been alerted that an AirTag was following them locate the device via sound. “That’s why he’d wrapped it in duct tape,” says Elizabeth. “To muffle the sound.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Laws play catch-up&lt;/h3&gt;  &lt;p&gt;If tech companies can’t police TFA, law enforcement should—but its responses vary. “I’ve seen police say to a victim, ‘You shouldn’t have given him the picture,’” says Lisa Fontes, a psychologist and an expert on coercive control, about cases where intimate images are shared nonconsensually. When people have brought police hidden “nanny cams” planted by their abusers, Fontes has heard responses along the lines of “You can’t prove he bought it [or] that he was actually spying on you. So there’s nothing we can do.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Places like the Queens Family Justice Center in New York City aim to remedy these law enforcement challenges. Navigating its mazelike halls, you can’t avoid bumping into a mix of attorneys, social workers, and case managers—which I did when executive director Susan Jacob showed me around after my visit to CETA. That’s by design. The center, one of more than 100 throughout the US, provides multiple services for those affected by gender-based and domestic violence. As I left, I passed a police officer escorting a man in handcuffs.&lt;/p&gt;  &lt;p&gt;CETA is in the process of moving its services here—and then to centers in the city’s other four boroughs. Having tech clinics at these centers will put the techies right next to lawyers who may be prosecuting cases. It’s tricky to prove the identity of people connected with anonymous forms of tech harassment like social media posts and spoofed phone calls, but the expert help could make it easier for lawyers to build cases for search warrants and protection orders.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Law enforcement’s responses to allegations of tech-facilitated abuse vary. “I’ve seen police say to a victim, ‘You shouldn’t have given him the picture.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Lisa Fontes, psychologist and expert on coercive control&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Lawyers pursuing cases with tech components don’t always have the legal framework to back them up. But laws in most US states do prohibit remote, covert tracking and the nonconsensual sharing of intimate images, while laws relating to privacy invasion, computer crimes, and stalking might cover aspects of TFA. In December, Ohio passed a law making AirTag stalking a crime, and Florida is considering an amendment that would increase penalties for people who use tracking devices to “commit or facilitate commission of dangerous crimes.” But keeping up with evolving tech requires additional legal specificity. “Tech comes first,” explains Lindsey Song, associate program director of the Queens center’s family law project. “People use it well. Abusers figure out how to misuse it. The law and policy come way, way, way later.”&lt;/p&gt;  &lt;p&gt;California is leading the charge in legislation addressing harassment via smart vehicles. Signed into law in September 2024, Senate Bill 1394 requires connected vehicles to notify users if someone has accessed their systems remotely and provide a way for drivers to stop that access. “Many lawmakers were shocked to learn how common this problem is,” says Akilah Weber Pierson, a state senator who coauthored the bill. “Once I explained how survivors were being stalked or controlled through features designed for convenience, there was a lot of support.”&lt;/p&gt; 
 &lt;p&gt;At the federal level, the Safe Con­nections Act signed into law in 2022 requires mobile service providers to honor survivors’ requests to separate from abusers’ plans. As of 2024, the Federal Communications Commission has been examining how to incorporate smart-car-­facilitated abuse into the act’s purview. And in May, President Trump signed a bill prohibiting the online publication of sexually explicit images without consent. But there has been little progress on other fronts. The Tech Safety for Victims of Domestic Violence, Dating Violence, Sexual Assault, and Stalking Act would have authorized a pilot program, run by the Justice Department’s Office on Violence Against Women, to create as many as 15 TFA clinics for survivors. But since its introduction in the House of Representatives in November 2023, the bill has gone nowhere.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Tech abuse isn’t about tech&lt;/h3&gt;  &lt;p&gt;With changes happening so slowly at the legislative level, it remains largely up to folks on the ground to protect survivors from TFA. Rahul Chatterjee, an assistant professor of computer science at the University of Wisconsin–Madison, has taken a particularly hands-on approach. In 2021, he founded the Madison Tech Clinic after working at CETA as a graduate student. He and his team are working on a physical tool that can detect hidden cameras and other monitoring devices. The aim is to use cheap hardware like Raspberry Pis and ESP32s to keep it affordable.&lt;/p&gt;  &lt;p&gt;Chatterjee has come across products online that purport to provide such protection, like radio frequency monitors for the impossibly low price of $20 and red-light devices claiming to detect invisible cameras. But they’re “snake oil,” he says. “We test them in the lab, and they don’t work.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;With the Trump administration slashing academic funding, folks who run tech clinics have expressed concern about sustainability. Dell, at least, received $800,000 from the MacArthur Foundation in 2024, some of which she plans to put toward launching new CETA-like clinics. The tech clinic in Queens got some seed funding from CETA for its first year, but it is “actively seeking fundraising to continue the program,” says Jennifer Friedman, a lawyer with the nonprofit Sanctuary for Families, which is overseeing the clinic.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;While these clinics expose all sorts of malicious applications of technology, the moral of this story isn’t that you should fear your tech. It’s that people who aim to cause harm will take advantage of whatever new tools are available.&lt;/p&gt;  &lt;p&gt;“[TFA] is not about the technology—it’s about the abuse,” says Garnett. “With or without the technology, the harm can still happen.” Ultimately, the only way to stem gender-based and intimate partner violence is at a societal level, through thoughtful legislation, amply funded antiviolence programs, and academic research that makes clinics like CETA possible.&lt;/p&gt;  &lt;p&gt;In the meantime, to protect themselves, survivors like Gioia make do with Band-Aid fixes. She bought her kids separate smartphones and sports gear to use at her house so her ex couldn’t slip tracking devices into the equipment he’d provided. “I’m paying extra,” she says, “so stuff isn’t going back and forth.” She got a new number and a new phone.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Believe the people that [say this is happening to them],” she says, “because it’s going on, and it’s rampant.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jessica Klein is a Philadelphia-based freelance journalist covering intimate partner violence, cryptocurrency, and other topics.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their Massachusetts home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior. One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt;  &lt;p&gt;“What am I supposed to tell my daughter?” says Gioia, who is going by a pseudonym in this story out of safety concerns. “She’s so excited but doesn’t realize [it’s] a monitoring device for him to see where we are.” In the end, she decided not to confiscate the watch. Instead, she told her daughter to leave it at home whenever they went out together, saying that this way it wouldn’t get lost.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Gioia says she has informed a family court of this and many other instances in which her ex has used or appeared to use technology to stalk her, but so far this hasn’t helped her get full custody of her children. The court’s failure to recognize these tech-facilitated tactics for maintaining power and control has left her frustrated to the point where she yearns for visible bruises. “I wish he was breaking my arms and punching me in the face,” she says, “because then people could see it.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;People I spoke with for this article described combating tech-facilitated abuse as playing “whack-a-mole.” Just as you figure out how to alert people to smartphone location sharing, enter smart cars.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;This sentiment is unfortunately common among people experiencing what’s become known as TFA, or tech-­facilitated abuse. Defined by the National Network to End Domestic Violence as “the use of digital tools, online platforms, or electronic devices to control, harass, monitor, or harm someone,” these often invisible or below-the-radar methods include using spyware and hidden cameras; sharing intimate images on social media without consent; logging into and draining a partner’s online bank account; and using device-based location tracking, as Gioia’s ex did with their daughter’s smartwatch.&lt;/p&gt; 
 &lt;p&gt;Because technology is so ubiquitous, TFA occurs in most cases of intimate partner violence. And those whose jobs entail protecting victims and survivors and holding abusive actors accountable struggle to get a handle on this multi­faceted problem. An Australian study from October 2024, which drew on in-depth interviews with victims and survivors of TFA, found a “considerable gap” in the understanding of TFA among frontline workers like police and victim service providers, with the result that police repeatedly dismissed TFA reports and failed to identify such incidents as examples of intimate partner violence. The study also identified a significant shortage of funding for specialists—that is, computer scientists skilled in conducting safety scans on the devices of people experiencing TFA.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The dearth of understanding is particularly concerning because keeping up with the many faces of tech-facilitated abuse requires significant expertise and vigilance. As internet-connected cars and homes become more common and location tracking is increasingly normalized, novel opportunities are emerging to use technology to stalk and harass. In reporting this piece, I heard chilling tales of abusers who remotely locked partners in their own “smart homes,” sometimes turning up the heat for added torment. One woman who fled her abusive partner found an ominous message when she opened her Netflix account miles away: “Bitch I’m Watching You” spelled out where the names of the accounts’ users should be.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Despite the range of tactics, a 2022 survey of TFA-focused studies across a number of English-speaking countries found that the results readily map onto the Power and Control Wheel, a tool developed in Duluth, Minnesota, in the 1980s that categorizes the all-encompassing ways abusive partners exert power and control over victims: economically, emotionally, through threats, using children, and more. Michaela Rogers, the lead author of the study and a senior lecturer at the University of Sheffield in the UK, says she noted “paranoia, anxiety, depression, trauma and PTSD, low self-esteem … and self-harm” among TFA survivors in the wake of abuse that often pervaded every aspect of their lives.&lt;/p&gt;  &lt;p&gt;This kind of abuse is taxing and tricky to resolve alone. Service providers and victim advocates strive to help, but many lack tech skills, and they can’t stop tech companies from bringing products to market. Some work with those companies to help create safeguards, but there are limits to what businesses can do to hold abusive actors accountable. To establish real guardrails and dole out serious consequences, robust legal frameworks are needed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s been slow work, but there have been concerted efforts to address TFA at each of these levels in the past couple of years. Some US states have passed laws against using smart car technology or location trackers such as Apple AirTags for stalking and harassment. Tech companies, including Apple and Meta, have hired people with experience in victim services to guide development of product safeguards, and advocates for victims and survivors are seeking out more specialized tech education.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the ever-evolving nature of technology makes it nearly impossible to create a permanent fix. People I spoke with for this article described the effort as playing “whack-a-mole.” Just as you figure out how to alert people to smartphone location sharing, enter smart cars. Outlaw AirTag stalking and a newer, more effective tool appears that can legally track your ex. That’s why groups that uniquely address TFA, like the Clinic to End Tech Abuse (CETA) at Cornell Tech in New York City, are working to create permanent infrastructure. A problem that has typically been seen as a side focus for service organizations can finally get the treatment it deserves as a ubiquitous and potentially life-endangering aspect of intimate partner violence. &lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;Volunteer tech support&lt;/h3&gt;  &lt;p&gt;CETA saw its first client seven years ago. In a small white room on Cornell Tech’s Roosevelt Island campus, two computer scientists sat down with someone whose abuser had been accessing the photos on their iPhone. The person didn’t know how this was happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We worked with our client for about an hour and a half,” says one of the scientists, Thomas Ristenpart, “and realized it was probably an iCloud Family Sharing issue.”&lt;/p&gt;  &lt;p&gt;At the time, CETA was one of just two clinics in the country created to address TFA (the other being the Technology Enabled Coercive Control Clinic in Seattle), and it remains on the cutting edge of the issue.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Picture a Venn diagram, with one circle representing computer scientists and the other service providers for domestic violence victims. It’s practically two separate circles, with CETA occupying a thin overlapping slice. Tech experts are much more likely to be drawn to profitable companies or research institutions than social-work nonprofits, so it’s unexpected that a couple of academic researchers identified TFA as a problem and chose to dedicate their careers to combating it. Their work has won results, but the learning curve was steep.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;CETA grew out of an interest in measuring the “internet spyware software ecosystem” exploited in intimate partner violence, says Ristenpart. He and cofounder Nicola Dell initially figured they could help by building a tool that could scan phones for intrusive software. They quickly realized that this alone wouldn’t solve the problem—and could even compromise people’s safety if done carelessly, since it could alert abusers that their surveillance had been detected and was actively being thwarted.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="close-up of a hand holding an Apple AirTag" class="wp-image-1118672" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/onur-binay-x8VQhw4xbRk-unsplash.jpg?w=1655" width="1655" /&gt;&lt;figcaption class="wp-element-caption"&gt;In December, Ohio passed a law making AirTag stalking a crime. Florida is considering increasing penalties for people who use tracking devices to “commit or facilitate commission of dangerous crimes.”&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ONUR BINAY/UNSPLASH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Instead, Dell and Ristenpart studied the dynamics of coercive control. They conducted about 14 focus groups with professionals who worked daily with victims and survivors. They connected with organizations like the Anti-Violence Project and New York’s Family Justice Centers to get referrals. With the covid-19 pandemic, CETA went virtual and stayed that way. Its services now resemble “remote tech support,” Dell says. A handful of volunteers, many of whom work in Big Tech, receive clients’ intake information and guide them through processes for stopping unwanted location sharing, for example, on their devices.&lt;/p&gt;  &lt;p&gt;Remote support has sufficed because abusers generally aren’t carrying out the type of sophisticated attack that can be foiled only by disassembling a device. “For the most part, people are using standard tools in the way that they were designed to be used,” says Dell. For example, someone might throw an AirTag into a stroller to keep track of its whereabouts (and those of the person pushing it), or act as the admin of a shared online bank account.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Though CETA stands out as a tech-­centric service organization for survivors, anti-domestic-violence groups have been encountering and combating TFA for decades. When Cindy Southworth started her career in the domestic violence field in the 1990s, she heard of abusers doing rough location tracking using car odometers—the mileage could suggest, for instance, that a driver pretending to set out for the supermarket had instead left town to seek support. Later, when Southworth joined the Pennsylvania Coalition Against Domestic Violence, the advocacy community was looking at caller ID as “not only an incredibly powerful tool for survivors to be able to see who’s calling,” she recalls, “but also potentially a risky technology, if an abuser could see.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;As technology evolved, the ways abusers took advantage evolved too. Realizing that the advocacy community “was not up on tech,” Southworth founded the National Network to End Domestic Violence’s Safety Net Project in 2000 to provide a comprehensive training curriculum on how to “harness [technology] to help victims” and hold abusers accountable when they misuse it. Today, the project offers resources on its website, like tool kits that include guidance on strategies such as creating strong passwords and security questions. “When you’re in a relationship with someone,” explains director Audace Garnett, “they may know your mother’s maiden name.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Big Tech safeguards&lt;/h3&gt;  &lt;p&gt;Southworth’s efforts later extended to advising tech companies on how to protect users who have experienced intimate partner violence. In 2020, she joined Facebook (now Meta) as its head of women’s safety. “What really drew me to Facebook was the work on intimate image abuse,” she says, noting that the company had come up with one of the first “sextortion” policies in 2012. Now she works on “reactive hashing,” which adds “digital fingerprints” to images that have been identified as nonconsensual so that survivors only need to report them once for all repeats to get blocked.&lt;/p&gt;  &lt;p&gt;Other areas of concern include “cyberflashing,” in which someone might share, say, unwanted explicit photos. Meta has worked to prevent that on Instagram by not allowing accounts to send images, videos, or voice notes unless they follow you. Besides that, though, many of Meta’s practices surrounding potential abuse appear to be more reactive than proactive. The company says it removes online threats that violate its policies against bullying and that promote “offline violence.” But earlier this year, Meta made its policies about speech on its platforms more permissive. Now users are allowed to refer to women as “household objects,” reported CNN, and to post transphobic and homophobic comments that had formerly been banned.&lt;/p&gt;  &lt;p&gt;A key challenge is that the very same tech can be used for good or evil: A tracking function that’s dangerous for someone whose partner is using it to stalk them might help someone else stay abreast of a stalker’s whereabouts. When I asked sources what tech companies should be doing to mitigate technology-assisted abuse, researchers and lawyers alike tended to throw up their hands. One cited the problem of abusers using parental controls to monitor adults instead of children—tech companies won’t do away with those important features for keeping children safe, and there is only so much they can do to limit how customers use or misuse them. Safety Net’s Garnett said companies should design technology with safety in mind “from the get-go” but pointed out that in the case of many well-established products, it’s too late for that. A couple of computer scientists pointed to Apple as a company with especially effective security measures: Its closed ecosystem can block sneaky third-party apps and alert users when they’re being tracked. But these experts also acknowledged that none of these measures are foolproof.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Over roughly the past decade, major US-based tech companies including Google, Meta, Airbnb, Apple, and Amazon have launched safety advisory boards to address this conundrum. The strategies they have implemented vary. At Uber, board members share feedback on “potential blind spots” and have influenced the development of customizable safety tools, says Liz Dank, who leads work on women’s and personal safety at the company. One result of this collaboration is Uber’s PIN verification feature, in which riders have to give drivers a unique number assigned by the app in order for the ride to start. This ensures that they’re getting into the right car.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Apple’s approach has included detailed guidance in the form of a 140-page “Personal Safety User Guide.” Under one heading, “I want to escape or am considering leaving a relationship that doesn’t feel safe,” it provides links to pages about blocking and evidence collection and “safety steps that include unwanted tracking alerts.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Creative abusers can bypass these sorts of precautions. Recently Elizabeth (for privacy, we’re using her first name only) found an AirTag her ex had hidden inside a wheel well of her car, attached to a magnet and wrapped in duct tape. Months after the AirTag debuted, Apple had received enough reports about unwanted tracking to introduce a security measure letting users who’d been alerted that an AirTag was following them locate the device via sound. “That’s why he’d wrapped it in duct tape,” says Elizabeth. “To muffle the sound.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Laws play catch-up&lt;/h3&gt;  &lt;p&gt;If tech companies can’t police TFA, law enforcement should—but its responses vary. “I’ve seen police say to a victim, ‘You shouldn’t have given him the picture,’” says Lisa Fontes, a psychologist and an expert on coercive control, about cases where intimate images are shared nonconsensually. When people have brought police hidden “nanny cams” planted by their abusers, Fontes has heard responses along the lines of “You can’t prove he bought it [or] that he was actually spying on you. So there’s nothing we can do.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Places like the Queens Family Justice Center in New York City aim to remedy these law enforcement challenges. Navigating its mazelike halls, you can’t avoid bumping into a mix of attorneys, social workers, and case managers—which I did when executive director Susan Jacob showed me around after my visit to CETA. That’s by design. The center, one of more than 100 throughout the US, provides multiple services for those affected by gender-based and domestic violence. As I left, I passed a police officer escorting a man in handcuffs.&lt;/p&gt;  &lt;p&gt;CETA is in the process of moving its services here—and then to centers in the city’s other four boroughs. Having tech clinics at these centers will put the techies right next to lawyers who may be prosecuting cases. It’s tricky to prove the identity of people connected with anonymous forms of tech harassment like social media posts and spoofed phone calls, but the expert help could make it easier for lawyers to build cases for search warrants and protection orders.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Law enforcement’s responses to allegations of tech-facilitated abuse vary. “I’ve seen police say to a victim, ‘You shouldn’t have given him the picture.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Lisa Fontes, psychologist and expert on coercive control&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Lawyers pursuing cases with tech components don’t always have the legal framework to back them up. But laws in most US states do prohibit remote, covert tracking and the nonconsensual sharing of intimate images, while laws relating to privacy invasion, computer crimes, and stalking might cover aspects of TFA. In December, Ohio passed a law making AirTag stalking a crime, and Florida is considering an amendment that would increase penalties for people who use tracking devices to “commit or facilitate commission of dangerous crimes.” But keeping up with evolving tech requires additional legal specificity. “Tech comes first,” explains Lindsey Song, associate program director of the Queens center’s family law project. “People use it well. Abusers figure out how to misuse it. The law and policy come way, way, way later.”&lt;/p&gt;  &lt;p&gt;California is leading the charge in legislation addressing harassment via smart vehicles. Signed into law in September 2024, Senate Bill 1394 requires connected vehicles to notify users if someone has accessed their systems remotely and provide a way for drivers to stop that access. “Many lawmakers were shocked to learn how common this problem is,” says Akilah Weber Pierson, a state senator who coauthored the bill. “Once I explained how survivors were being stalked or controlled through features designed for convenience, there was a lot of support.”&lt;/p&gt; 
 &lt;p&gt;At the federal level, the Safe Con­nections Act signed into law in 2022 requires mobile service providers to honor survivors’ requests to separate from abusers’ plans. As of 2024, the Federal Communications Commission has been examining how to incorporate smart-car-­facilitated abuse into the act’s purview. And in May, President Trump signed a bill prohibiting the online publication of sexually explicit images without consent. But there has been little progress on other fronts. The Tech Safety for Victims of Domestic Violence, Dating Violence, Sexual Assault, and Stalking Act would have authorized a pilot program, run by the Justice Department’s Office on Violence Against Women, to create as many as 15 TFA clinics for survivors. But since its introduction in the House of Representatives in November 2023, the bill has gone nowhere.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Tech abuse isn’t about tech&lt;/h3&gt;  &lt;p&gt;With changes happening so slowly at the legislative level, it remains largely up to folks on the ground to protect survivors from TFA. Rahul Chatterjee, an assistant professor of computer science at the University of Wisconsin–Madison, has taken a particularly hands-on approach. In 2021, he founded the Madison Tech Clinic after working at CETA as a graduate student. He and his team are working on a physical tool that can detect hidden cameras and other monitoring devices. The aim is to use cheap hardware like Raspberry Pis and ESP32s to keep it affordable.&lt;/p&gt;  &lt;p&gt;Chatterjee has come across products online that purport to provide such protection, like radio frequency monitors for the impossibly low price of $20 and red-light devices claiming to detect invisible cameras. But they’re “snake oil,” he says. “We test them in the lab, and they don’t work.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;With the Trump administration slashing academic funding, folks who run tech clinics have expressed concern about sustainability. Dell, at least, received $800,000 from the MacArthur Foundation in 2024, some of which she plans to put toward launching new CETA-like clinics. The tech clinic in Queens got some seed funding from CETA for its first year, but it is “actively seeking fundraising to continue the program,” says Jennifer Friedman, a lawyer with the nonprofit Sanctuary for Families, which is overseeing the clinic.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;While these clinics expose all sorts of malicious applications of technology, the moral of this story isn’t that you should fear your tech. It’s that people who aim to cause harm will take advantage of whatever new tools are available.&lt;/p&gt;  &lt;p&gt;“[TFA] is not about the technology—it’s about the abuse,” says Garnett. “With or without the technology, the harm can still happen.” Ultimately, the only way to stem gender-based and intimate partner violence is at a societal level, through thoughtful legislation, amply funded antiviolence programs, and academic research that makes clinics like CETA possible.&lt;/p&gt;  &lt;p&gt;In the meantime, to protect themselves, survivors like Gioia make do with Band-Aid fixes. She bought her kids separate smartphones and sports gear to use at her house so her ex couldn’t slip tracking devices into the equipment he’d provided. “I’m paying extra,” she says, “so stuff isn’t going back and forth.” She got a new number and a new phone.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Believe the people that [say this is happening to them],” she says, “because it’s going on, and it’s rampant.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jessica Klein is a Philadelphia-based freelance journalist covering intimate partner violence, cryptocurrency, and other topics.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1118235/big-tech-intimate-partner-violence/</guid><pubDate>Wed, 18 Jun 2025 10:00:00 +0000</pubDate></item><item><title>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Alt text: A dark blue, wavy surface with multiple colorful spheres placed on it. The spheres are in various colors including red, green, blue, yellow, purple, and orange. Each sphere is surrounded by small white particles that appear to be floating around them. The background is a gradient of dark teal to black." class="wp-image-1142136" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;We are excited to share our first big milestone in solving a grand challenge that has hampered the predictive power of computational chemistry, biochemistry, and materials science for decades. By using a scalable deep-learning approach and generating an unprecedented quantity of diverse, highly accurate data, we have achieved a breakthrough in the accuracy of density functional theory (DFT), the workhorse method that thousands of scientists use every year to simulate matter at the atomistic level. Within the region of chemical space represented in our large training dataset, our model reaches the accuracy required to reliably predict experimental outcomes, as assessed on the well-known benchmark dataset W4-17&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This removes a fundamental barrier to shifting the balance of molecule and material design from being driven by laboratory experiments to being driven by computational simulations. The implications for accelerating scientific discovery are far reaching, spanning applications from drugs to batteries and green fertilizers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dft"&gt;What is DFT?&lt;/h2&gt;



&lt;p&gt;Molecules and materials are made of atoms, which are held together by their electrons. These electrons act as a glue, determining the stability and properties of the chemical structure. Accurately computing the strength and properties of the electron glue is essential for predicting whether a chemical reaction will proceed, whether a candidate drug molecule will bind to its target protein, whether a material is suitable for carbon capture, or if a flow battery can be optimized for renewable energy storage. Unfortunately, a brute-force approach amounts to solving the many-electron Schrödinger equation, which requires computation that scales exponentially with the number of electrons. Considering that an atom has dozens of electrons, and that molecules and materials have large numbers of atoms, we could easily end up waiting the age of the universe to complete our computation unless we restrict our attention to small systems with only a few atoms.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;p&gt;DFT, introduced by Walter Kohn and collaborators in 1964-1965, was a true scientific breakthrough, earning Kohn the Nobel Prize in Chemistry in 1998. DFT provides an extraordinary reduction in the computational cost of calculating the electron glue in an exact manner, from exponential to cubic, making it possible to perform calculations of practical value within seconds to hours.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="what-is-the-grand-challenge-in-dft"&gt;What is the grand challenge in DFT?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;But there is a catch: the exact reformulation has a small but crucial term—the exchange-correlation (XC) functional—which Kohn proved is universal (i.e., the same for all molecules and materials), but for which no explicit expression is known. For 60 years, people have designed practical approximations for the XC functional. The magazine &lt;em&gt;Science&lt;/em&gt; dubbed the gold rush to design better XC models the “pursuit of the Divine Functional&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;”. With time, these approximations have grown into a zoo of hundreds of different XC functionals from which users must choose, often using experimental data as a guide. Owing to the uniquely favorable computational cost of DFT, existing functionals have enabled scientists to gain extremely useful insight into a huge variety of chemical problems. However, the limited accuracy and scope of current XC functionals mean that DFT is still mostly used to interpret experimental results rather than predict them.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="why-is-it-important-to-increase-the-accuracy-of-dft"&gt;Why is it important to increase the accuracy of DFT?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We can contrast the present state of computational chemistry with the state of aircraft engineering and design. Thanks to predictive simulations, aeronautical engineers no longer need to build and test thousands of prototypes to identify one viable design. However, this is exactly what we currently must do in molecular and materials sciences. We send thousands of potential candidates to the lab, because the accuracy of the computational methods is not sufficient to &lt;em&gt;predict&lt;/em&gt; the experiments. To make a significant shift in the balance from laboratory to &lt;em&gt;in silico&lt;/em&gt; experiments, we need to remove the fundamental bottleneck of the insufficient accuracy of present XC functionals. This amounts to bringing the error of DFT calculations with respect to experiments within &lt;em&gt;chemical accuracy&lt;/em&gt;, which is around 1 kcal/mol for most chemical processes. Present approximations typically have errors that are 3 to 30 times larger.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-can-ai-make-a-difference"&gt;How can AI make a difference?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;AI can transform how we model molecules and materials with DFT by learning the XC functional directly from highly accurate data. The goal is to learn how the XC functional captures the complex relationship between its input, the electron density, and its output, the XC energy. You can think of the density like a glue, with regions of space where there is a lot of it and other regions with less of it. Traditionally, researchers have built XC functional approximations using the concept of the so-called &lt;em&gt;Jacob’s ladder&lt;/em&gt;: a hierarchy of increasingly complex, hand-designed descriptors of the electron density. Including density descriptors from higher rungs of this ladder aims to improve accuracy, but it comes at the price of increased computational cost. Even the few attempts that use machine learning have stayed within this traditional paradigm, thereby taking an approach that is akin to what people were doing in computer vision and speech recognition before the deep-learning era. Progress toward better accuracy has stagnated for at least two decades with this approach.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our project is driven by the intuition that a true deep learning approach—where relevant representations of the electron density are learned directly from data in a computationally scalable way—has the potential to revolutionize the accuracy of DFT, much like deep learning has transformed other fields.&lt;strong&gt; &lt;/strong&gt;A significant challenge with going down this path, however, is that feature or representation learning is very data-hungry, and there is very little data around—too little to test this hypothesis reliably.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-have-we-done-in-this-milestone"&gt;What have we done in this milestone?&lt;/h2&gt;



&lt;p&gt;The first step was generating data—a lot of it. This posed a major challenge, since the data must come from accurate solutions of the many-electron Schrödinger equation, which is precisely the prohibitively expensive problem that DFT is designed to replace. Fortunately, decades of progress in the scientific community have led to smarter, more efficient variants of brute-force methods, making it possible to compute reference data for &lt;em&gt;small&lt;/em&gt; molecules at experimental accuracy. While these high-accuracy methods, also referred to as wavefunction methods, are far too costly for routine use in applications, we made a deliberate investment in them for this project. The reason? The upfront cost of generating high-quality training data is offset by the long-term benefit of enabling vast numbers of industrially relevant applications with cost effective DFT using the trained XC functional. Crucially, we rely on the ability of DFT—and our learned XC functional—to generalize from high-accuracy data for small systems to larger, more complex molecules.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There are many different high-accuracy wavefunction methods, each tailored to different regions of chemical space. However, their use at scale is not well established, as they require extensive expertise—small methodological choices can significantly affect accuracy at the level that we target. We therefore joined forces with Prof. Amir Karton&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; from the University of New England, Australia, a world-leading expert who developed widely recognized benchmark datasets for a fundamental thermochemical property: atomization energy—the energy required to break all bonds in a molecule and separate it into individual atoms. To create a training dataset of atomization energies at unprecedented scale, our team at Microsoft built a scalable pipeline to produce highly diverse molecular structures. Using these structures and substantial Azure compute resources via Microsoft’s Accelerating Foundation Models Research program&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Prof. Karton applied a high-accuracy wavefunction method to compute the corresponding energy labels. The result is a dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; two orders of magnitude larger than previous efforts. We are releasing a large part of this dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to the scientific community.&lt;/p&gt;



&lt;p&gt;Data generation was only half of the challenge. We also needed to design a dedicated deep-learning architecture for the XC functional—one that is both computationally scalable and capable of learning meaningful representations from electron densities to accurately predict the XC energy. Our team of machine learning specialists, assisted by DFT experts, introduced a series of innovations that solve these and other challenges inherent to this complex learning problem. The result is &lt;strong&gt;Skala&lt;/strong&gt;, an XC functional that generalizes to unseen molecules, reaching the accuracy needed to predict experiments. This demonstrates for the first time that deep learning can truly disrupt DFT: reaching experimental accuracy does not require the computationally expensive hand-designed features of Jacob’s ladder. Instead, we can retain the original computational complexity of DFT while allowing the XC functional to learn how to extract meaningful features and predict accurate energies.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near " class="wp-image-1142366" for="for" height="391" required="required" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near “chemical accuracy” (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;Skala is a new density functional for the exchange-correlation energy that employs meta-GGA ingredients plus D3 dispersion and machine-learned nonlocal features of the electron density. Some exact constraints were imposed, and some others “emerge” from the fitting to about 150,000 accurate energy differences for sp molecules and atoms. Skala achieves high, hybrid-like accuracy on a large and diverse data set of properties of main group molecules, which has no overlap with its training set. The computational cost of Skala is higher than that of the r2SCAN meta-GGA for small molecules, but about the same for systems with 1,000 or more occupied orbitals. Its cost seems to be only 10% of the cost of standard hybrids and 1% of the cost of local hybrids. Developed by a Microsoft team of density functional theorists and deep-learning experts, Skala could be the first machine-learned density functional to compete with existing functionals for wide use in computational chemistry, and a sign of things to come in that and related fields. Skala learned from big data and was taught by insightful human scientists.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— John P. Perdew, Professor of Physics, School of Science and Engineering, Tulane University&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;



&lt;p&gt;This first milestone was achieved for a challenging property in a specific region of chemical space—atomization energies of main group molecules—for which we generated our initial large batch of high-accuracy training data. Building on this foundation, we have started to expand our training dataset to cover a broader range of general chemistry, using our scalable in-house data generation pipeline. With the first small batch of training data beyond atomization energies, we have already extended the accuracy of our model, making it competitive with the best existing XC functionals across a wider spectrum of main group chemistry. This motivates us to continue growing our high-accuracy data generation campaign, engaging with external experts such as Prof. Amir Karton, who noted, “After years of benchmarking DFT methods against experimental accuracy, this is the first time I’ve witnessed such an unprecedented leap in the accuracy–cost trade-off. It is genuinely exciting to see how the creation of our new dataset has enabled these groundbreaking results — opening up a path for transformative advances across chemical, biochemical, and materials research.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="advancing-computational-chemistry-together"&gt;Advancing computational chemistry together&lt;/h2&gt;



&lt;p&gt;We are excited to work closely with the global computational chemistry community to accelerate progress for all and look forward to openly releasing our first XC functional in the near future.&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;Density Functional Theory&amp;nbsp;(DFT) and related technologies are a core Digital Chemistry technology supporting advancements in&amp;nbsp;Merck’s&amp;nbsp;diverse Life Science, Healthcare and Electronics businesses.&amp;nbsp;However, the limitations of traditional DFT methods, which have persisted for the last 50 years, have hindered its full potential. Microsoft Research’s innovative approach to integrating deep learning represents a&amp;nbsp;substantial leap, enhancing its accuracy, robustness, and scalability. We are&amp;nbsp;looking forward&amp;nbsp;to exploring&amp;nbsp;how this can advance&amp;nbsp;Digital Chemistry workflows&amp;nbsp;and unlock new possibilities for the future, aligning with our commitment to developing advanced algorithms and technologies that propel scientific innovation at Merck.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— Jan Gerit Brandenburg – Director for Digital Chemistry at Merck&amp;nbsp;&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;We are entering a golden age for predictive and realistic simulations: very accurate electronic-structure calculations provide vast amounts of consistent data that can be used to train novel machine-learning architectures, delivering the holy grail of precision and computational efficiency.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— Professor Nicola Marzari, Chair of Theory and Simulation of Materials, EPFL and PSI&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;







&lt;p&gt;We believe that our new functional can help unlock new opportunities for businesses and are eager to work together on real-world applications. &lt;strong&gt;Today, we are delighted to launch the DFT Research Early Access Program (DFT REAP) and welcome Flagship Pioneering as the first participant.&lt;/strong&gt; This program is for companies and research labs to collaborate with us to accelerate innovation across many industries. To find out more about how to join this program please visit:&amp;nbsp;https://aka.ms/DFT-REAP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;&lt;em&gt;“Microsoft’s effort to enhance the predictive power of computational chemistry reflects a bold but thoughtful step toward a simulation-first future. At Flagship, we believe that openly shared, foundational advances in science – like this leap forward in DFT accuracy – can serve as powerful enablers of innovation. These next-generation tools promise to accelerate discovery across a wide range of sectors, from therapeutics to materials science, by helping researchers navigate chemical and biological space with far greater precision and speed.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— &lt;/em&gt;Junaid Bajwa, M.D., Senior Partner at Flagship Pioneering and Science Partner at Pioneering Intelligence&lt;/cite&gt;&lt;/blockquote&gt;



&lt;p&gt;By making our work available to the scientific community, we hope to enable widespread testing and gather valuable feedback that will guide future improvements. For the first time, deep learning offers a clear and computationally scalable path to building an accurate, efficient, and broadly applicable model of the universal XC functional—one that could transform the computational design of molecules and materials.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgement"&gt;Acknowledgement&lt;/h2&gt;



&lt;p&gt;This work is the product of a highly collaborative and interdisciplinary effort led by Microsoft Research AI for Science, in partnership with colleagues from Microsoft Research Accelerator,&amp;nbsp;Microsoft Quantum and the&amp;nbsp;University of New England. The full author list includes Giulia Luise, Chin-Wei Huang, Thijs Vogels, Derk P. Kooi, Sebastian Ehlert, Stephanie Lanius, Klaas J. H. Giesbertz, Amir Karton, Deniz Gunceler, Megan Stanley, Wessel P. Bruinsma, Victor Garcia Satorras, Marwin Segler, Kenji Takeda, Lin Huang, Xinran Wei, José Garrido Torres, Albert Katbashev, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, Christopher M. Bishop, Jan Hermann, Rianne van den Berg and Paola Gori Giorgi.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Alt text: A dark blue, wavy surface with multiple colorful spheres placed on it. The spheres are in various colors including red, green, blue, yellow, purple, and orange. Each sphere is surrounded by small white particles that appear to be floating around them. The background is a gradient of dark teal to black." class="wp-image-1142136" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;We are excited to share our first big milestone in solving a grand challenge that has hampered the predictive power of computational chemistry, biochemistry, and materials science for decades. By using a scalable deep-learning approach and generating an unprecedented quantity of diverse, highly accurate data, we have achieved a breakthrough in the accuracy of density functional theory (DFT), the workhorse method that thousands of scientists use every year to simulate matter at the atomistic level. Within the region of chemical space represented in our large training dataset, our model reaches the accuracy required to reliably predict experimental outcomes, as assessed on the well-known benchmark dataset W4-17&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This removes a fundamental barrier to shifting the balance of molecule and material design from being driven by laboratory experiments to being driven by computational simulations. The implications for accelerating scientific discovery are far reaching, spanning applications from drugs to batteries and green fertilizers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dft"&gt;What is DFT?&lt;/h2&gt;



&lt;p&gt;Molecules and materials are made of atoms, which are held together by their electrons. These electrons act as a glue, determining the stability and properties of the chemical structure. Accurately computing the strength and properties of the electron glue is essential for predicting whether a chemical reaction will proceed, whether a candidate drug molecule will bind to its target protein, whether a material is suitable for carbon capture, or if a flow battery can be optimized for renewable energy storage. Unfortunately, a brute-force approach amounts to solving the many-electron Schrödinger equation, which requires computation that scales exponentially with the number of electrons. Considering that an atom has dozens of electrons, and that molecules and materials have large numbers of atoms, we could easily end up waiting the age of the universe to complete our computation unless we restrict our attention to small systems with only a few atoms.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;p&gt;DFT, introduced by Walter Kohn and collaborators in 1964-1965, was a true scientific breakthrough, earning Kohn the Nobel Prize in Chemistry in 1998. DFT provides an extraordinary reduction in the computational cost of calculating the electron glue in an exact manner, from exponential to cubic, making it possible to perform calculations of practical value within seconds to hours.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="what-is-the-grand-challenge-in-dft"&gt;What is the grand challenge in DFT?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;But there is a catch: the exact reformulation has a small but crucial term—the exchange-correlation (XC) functional—which Kohn proved is universal (i.e., the same for all molecules and materials), but for which no explicit expression is known. For 60 years, people have designed practical approximations for the XC functional. The magazine &lt;em&gt;Science&lt;/em&gt; dubbed the gold rush to design better XC models the “pursuit of the Divine Functional&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;”. With time, these approximations have grown into a zoo of hundreds of different XC functionals from which users must choose, often using experimental data as a guide. Owing to the uniquely favorable computational cost of DFT, existing functionals have enabled scientists to gain extremely useful insight into a huge variety of chemical problems. However, the limited accuracy and scope of current XC functionals mean that DFT is still mostly used to interpret experimental results rather than predict them.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="why-is-it-important-to-increase-the-accuracy-of-dft"&gt;Why is it important to increase the accuracy of DFT?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We can contrast the present state of computational chemistry with the state of aircraft engineering and design. Thanks to predictive simulations, aeronautical engineers no longer need to build and test thousands of prototypes to identify one viable design. However, this is exactly what we currently must do in molecular and materials sciences. We send thousands of potential candidates to the lab, because the accuracy of the computational methods is not sufficient to &lt;em&gt;predict&lt;/em&gt; the experiments. To make a significant shift in the balance from laboratory to &lt;em&gt;in silico&lt;/em&gt; experiments, we need to remove the fundamental bottleneck of the insufficient accuracy of present XC functionals. This amounts to bringing the error of DFT calculations with respect to experiments within &lt;em&gt;chemical accuracy&lt;/em&gt;, which is around 1 kcal/mol for most chemical processes. Present approximations typically have errors that are 3 to 30 times larger.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-can-ai-make-a-difference"&gt;How can AI make a difference?&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;AI can transform how we model molecules and materials with DFT by learning the XC functional directly from highly accurate data. The goal is to learn how the XC functional captures the complex relationship between its input, the electron density, and its output, the XC energy. You can think of the density like a glue, with regions of space where there is a lot of it and other regions with less of it. Traditionally, researchers have built XC functional approximations using the concept of the so-called &lt;em&gt;Jacob’s ladder&lt;/em&gt;: a hierarchy of increasingly complex, hand-designed descriptors of the electron density. Including density descriptors from higher rungs of this ladder aims to improve accuracy, but it comes at the price of increased computational cost. Even the few attempts that use machine learning have stayed within this traditional paradigm, thereby taking an approach that is akin to what people were doing in computer vision and speech recognition before the deep-learning era. Progress toward better accuracy has stagnated for at least two decades with this approach.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our project is driven by the intuition that a true deep learning approach—where relevant representations of the electron density are learned directly from data in a computationally scalable way—has the potential to revolutionize the accuracy of DFT, much like deep learning has transformed other fields.&lt;strong&gt; &lt;/strong&gt;A significant challenge with going down this path, however, is that feature or representation learning is very data-hungry, and there is very little data around—too little to test this hypothesis reliably.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-have-we-done-in-this-milestone"&gt;What have we done in this milestone?&lt;/h2&gt;



&lt;p&gt;The first step was generating data—a lot of it. This posed a major challenge, since the data must come from accurate solutions of the many-electron Schrödinger equation, which is precisely the prohibitively expensive problem that DFT is designed to replace. Fortunately, decades of progress in the scientific community have led to smarter, more efficient variants of brute-force methods, making it possible to compute reference data for &lt;em&gt;small&lt;/em&gt; molecules at experimental accuracy. While these high-accuracy methods, also referred to as wavefunction methods, are far too costly for routine use in applications, we made a deliberate investment in them for this project. The reason? The upfront cost of generating high-quality training data is offset by the long-term benefit of enabling vast numbers of industrially relevant applications with cost effective DFT using the trained XC functional. Crucially, we rely on the ability of DFT—and our learned XC functional—to generalize from high-accuracy data for small systems to larger, more complex molecules.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There are many different high-accuracy wavefunction methods, each tailored to different regions of chemical space. However, their use at scale is not well established, as they require extensive expertise—small methodological choices can significantly affect accuracy at the level that we target. We therefore joined forces with Prof. Amir Karton&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; from the University of New England, Australia, a world-leading expert who developed widely recognized benchmark datasets for a fundamental thermochemical property: atomization energy—the energy required to break all bonds in a molecule and separate it into individual atoms. To create a training dataset of atomization energies at unprecedented scale, our team at Microsoft built a scalable pipeline to produce highly diverse molecular structures. Using these structures and substantial Azure compute resources via Microsoft’s Accelerating Foundation Models Research program&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Prof. Karton applied a high-accuracy wavefunction method to compute the corresponding energy labels. The result is a dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; two orders of magnitude larger than previous efforts. We are releasing a large part of this dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to the scientific community.&lt;/p&gt;



&lt;p&gt;Data generation was only half of the challenge. We also needed to design a dedicated deep-learning architecture for the XC functional—one that is both computationally scalable and capable of learning meaningful representations from electron densities to accurately predict the XC energy. Our team of machine learning specialists, assisted by DFT experts, introduced a series of innovations that solve these and other challenges inherent to this complex learning problem. The result is &lt;strong&gt;Skala&lt;/strong&gt;, an XC functional that generalizes to unseen molecules, reaching the accuracy needed to predict experiments. This demonstrates for the first time that deep learning can truly disrupt DFT: reaching experimental accuracy does not require the computationally expensive hand-designed features of Jacob’s ladder. Instead, we can retain the original computational complexity of DFT while allowing the XC functional to learn how to extract meaningful features and predict accurate energies.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near " class="wp-image-1142366" for="for" height="391" required="required" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near “chemical accuracy” (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;Skala is a new density functional for the exchange-correlation energy that employs meta-GGA ingredients plus D3 dispersion and machine-learned nonlocal features of the electron density. Some exact constraints were imposed, and some others “emerge” from the fitting to about 150,000 accurate energy differences for sp molecules and atoms. Skala achieves high, hybrid-like accuracy on a large and diverse data set of properties of main group molecules, which has no overlap with its training set. The computational cost of Skala is higher than that of the r2SCAN meta-GGA for small molecules, but about the same for systems with 1,000 or more occupied orbitals. Its cost seems to be only 10% of the cost of standard hybrids and 1% of the cost of local hybrids. Developed by a Microsoft team of density functional theorists and deep-learning experts, Skala could be the first machine-learned density functional to compete with existing functionals for wide use in computational chemistry, and a sign of things to come in that and related fields. Skala learned from big data and was taught by insightful human scientists.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— John P. Perdew, Professor of Physics, School of Science and Engineering, Tulane University&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;



&lt;p&gt;This first milestone was achieved for a challenging property in a specific region of chemical space—atomization energies of main group molecules—for which we generated our initial large batch of high-accuracy training data. Building on this foundation, we have started to expand our training dataset to cover a broader range of general chemistry, using our scalable in-house data generation pipeline. With the first small batch of training data beyond atomization energies, we have already extended the accuracy of our model, making it competitive with the best existing XC functionals across a wider spectrum of main group chemistry. This motivates us to continue growing our high-accuracy data generation campaign, engaging with external experts such as Prof. Amir Karton, who noted, “After years of benchmarking DFT methods against experimental accuracy, this is the first time I’ve witnessed such an unprecedented leap in the accuracy–cost trade-off. It is genuinely exciting to see how the creation of our new dataset has enabled these groundbreaking results — opening up a path for transformative advances across chemical, biochemical, and materials research.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="advancing-computational-chemistry-together"&gt;Advancing computational chemistry together&lt;/h2&gt;



&lt;p&gt;We are excited to work closely with the global computational chemistry community to accelerate progress for all and look forward to openly releasing our first XC functional in the near future.&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;Density Functional Theory&amp;nbsp;(DFT) and related technologies are a core Digital Chemistry technology supporting advancements in&amp;nbsp;Merck’s&amp;nbsp;diverse Life Science, Healthcare and Electronics businesses.&amp;nbsp;However, the limitations of traditional DFT methods, which have persisted for the last 50 years, have hindered its full potential. Microsoft Research’s innovative approach to integrating deep learning represents a&amp;nbsp;substantial leap, enhancing its accuracy, robustness, and scalability. We are&amp;nbsp;looking forward&amp;nbsp;to exploring&amp;nbsp;how this can advance&amp;nbsp;Digital Chemistry workflows&amp;nbsp;and unlock new possibilities for the future, aligning with our commitment to developing advanced algorithms and technologies that propel scientific innovation at Merck.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— Jan Gerit Brandenburg – Director for Digital Chemistry at Merck&amp;nbsp;&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;“&lt;em&gt;We are entering a golden age for predictive and realistic simulations: very accurate electronic-structure calculations provide vast amounts of consistent data that can be used to train novel machine-learning architectures, delivering the holy grail of precision and computational efficiency.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— Professor Nicola Marzari, Chair of Theory and Simulation of Materials, EPFL and PSI&lt;/em&gt;&lt;/cite&gt;&lt;/blockquote&gt;







&lt;p&gt;We believe that our new functional can help unlock new opportunities for businesses and are eager to work together on real-world applications. &lt;strong&gt;Today, we are delighted to launch the DFT Research Early Access Program (DFT REAP) and welcome Flagship Pioneering as the first participant.&lt;/strong&gt; This program is for companies and research labs to collaborate with us to accelerate innovation across many industries. To find out more about how to join this program please visit:&amp;nbsp;https://aka.ms/DFT-REAP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;&lt;em&gt;“Microsoft’s effort to enhance the predictive power of computational chemistry reflects a bold but thoughtful step toward a simulation-first future. At Flagship, we believe that openly shared, foundational advances in science – like this leap forward in DFT accuracy – can serve as powerful enablers of innovation. These next-generation tools promise to accelerate discovery across a wide range of sectors, from therapeutics to materials science, by helping researchers navigate chemical and biological space with far greater precision and speed.”&lt;/em&gt;&lt;/p&gt;
&lt;cite&gt;&lt;em&gt;— &lt;/em&gt;Junaid Bajwa, M.D., Senior Partner at Flagship Pioneering and Science Partner at Pioneering Intelligence&lt;/cite&gt;&lt;/blockquote&gt;



&lt;p&gt;By making our work available to the scientific community, we hope to enable widespread testing and gather valuable feedback that will guide future improvements. For the first time, deep learning offers a clear and computationally scalable path to building an accurate, efficient, and broadly applicable model of the universal XC functional—one that could transform the computational design of molecules and materials.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgement"&gt;Acknowledgement&lt;/h2&gt;



&lt;p&gt;This work is the product of a highly collaborative and interdisciplinary effort led by Microsoft Research AI for Science, in partnership with colleagues from Microsoft Research Accelerator,&amp;nbsp;Microsoft Quantum and the&amp;nbsp;University of New England. The full author list includes Giulia Luise, Chin-Wei Huang, Thijs Vogels, Derk P. Kooi, Sebastian Ehlert, Stephanie Lanius, Klaas J. H. Giesbertz, Amir Karton, Deniz Gunceler, Megan Stanley, Wessel P. Bruinsma, Victor Garcia Satorras, Marwin Segler, Kenji Takeda, Lin Huang, Xinran Wei, José Garrido Torres, Albert Katbashev, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, Christopher M. Bishop, Jan Hermann, Rianne van den Berg and Paola Gori Giorgi.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</guid><pubDate>Wed, 18 Jun 2025 10:01:47 +0000</pubDate></item><item><title>Scientists once hoarded pre-nuclear steel; now we’re hoarding pre-AI content (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/why-one-man-is-archiving-human-made-content-from-before-the-ai-explosion/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Newly announced catalog collects pre-2022 sources untouched by ChatGPT and AI contamination.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Mushroom cloud from Ivy Mike nuclear test" class="absolute inset-0 w-full h-full object-cover hidden" height="201" src="https://cdn.arstechnica.net/wp-content/uploads/2020/12/wheeler3-300x201.jpg" width="300" /&gt;
                  &lt;img alt="Mushroom cloud from Ivy Mike nuclear test" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2020/12/wheeler3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nuclear blasts contaminated steel worldwide, leading some scientists to seek out material from the pre-nuclear age.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          National Nuclear Security Administration/Public domain

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Former Cloudflare executive John Graham-Cumming recently announced that he launched a website, lowbackgroundsteel.ai, that treats pre-AI, human-created content like a precious commodity—a time capsule of organic creative expression from a time before machines joined the conversation. "The idea is to point to sources of text, images and video that were created prior to the explosion of AI-generated content," Graham-Cumming wrote on his blog last week. The reason? To preserve what made non-AI media uniquely human.&lt;/p&gt;
&lt;p&gt;The archive name comes from a scientific phenomenon from the Cold War era. After nuclear weapons testing began in 1945, atmospheric radiation contaminated new steel production worldwide. For decades, scientists needing radiation-free metal for sensitive instruments had to salvage steel from pre-war shipwrecks. Scientists called this steel "low-background steel." Graham-Cumming sees a parallel with today's web, where AI-generated content increasingly mingles with human-created material and contaminates it.&lt;/p&gt;
&lt;p&gt;With the advent of generative AI models like ChatGPT and Stable Diffusion in 2022, it has become far more difficult for researchers to ensure that media found on the Internet was created by humans without using AI tools. ChatGPT in particular triggered an avalanche of AI-generated text across the web, forcing at least one research project to shut down entirely.&lt;/p&gt;
&lt;p&gt;That casualty was wordfreq, a Python library created by researcher Robyn Speer that tracked word frequency usage across more than 40 languages by analyzing millions of sources, including Wikipedia, movie subtitles, news articles, and social media. The tool was widely used by academics and developers to study how language evolves and to build natural language processing applications. The project announced in September 2024 that it will no longer be updated because "the Web at large is full of slop generated by large language models, written by no one to communicate nothing."&lt;/p&gt;
&lt;p&gt;Some researchers also worry about AI models training on their own outputs, potentially leading to quality degradation over time—a phenomenon sometimes called "model collapse." But recent evidence suggests this fear may be overblown under certain conditions. Research by Gerstgrasser et al. (2024) suggests that model collapse can be avoided when synthetic data accumulates alongside real data, rather than replacing it entirely. In fact, when properly curated and combined with real data, synthetic data from AI models can actually assist with training newer, more capable models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A time capsule of human expression&lt;/h2&gt;
&lt;p&gt;Graham-Cumming is no stranger to tech preservation efforts. He's a British software engineer and writer best known for creating POPFile, an open source email spam filtering program, and for successfully petitioning the UK government to apologize for its persecution of codebreaker Alan Turing—an apology that Prime Minister Gordon Brown issued in 2009.&lt;/p&gt;
&lt;p&gt;As it turns out, his pre-AI website isn't new, but it has languished unannounced until now. "I created it back in March 2023 as a clearinghouse for online resources that hadn't been contaminated with AI-generated content," he wrote on his blog.&lt;/p&gt;
&lt;p&gt;The website points to several major archives of pre-AI content, including a Wikipedia dump from August 2022 (before ChatGPT's November 2022 release), Project Gutenberg's collection of public domain books, the Library of Congress photo archive, and GitHub's Arctic Code Vault—a snapshot of open source code buried in a former coal mine near the North Pole in February 2020. The wordfreq project appears on the list as well, flash-frozen from a time before AI contamination made its methodology untenable.&lt;/p&gt;
&lt;p&gt;The site accepts submissions of other pre-AI content sources through its Tumblr page. Graham-Cumming emphasizes that the project aims to document human creativity from before the AI era, not to make a statement against AI itself. As atmospheric nuclear testing ended and background radiation returned to natural levels, low-background steel eventually became unnecessary for most uses. Whether pre-AI content will follow a similar trajectory remains a question.&lt;/p&gt;
&lt;p&gt;Still, it feels reasonable to protect sources of human creativity now, including archival ones, because these repositories&amp;nbsp;may become useful in ways that few appreciate at the moment. For example, in 2020, I proposed creating a so-called "cryptographic ark"—a timestamped archive of pre-AI media that future historians could verify as authentic, collected before my then-arbitrary cutoff date of January 1, 2022. AI slop pollutes more than the current discourse—it could cloud the historical record as well.&lt;/p&gt;
&lt;p&gt;For now, lowbackgroundsteel.ai stands as a modest catalog of human expression from what may someday be seen as the last pre-AI era. It's a digital archaeology project marking the boundary between human-generated and hybrid human-AI cultures. In an age where distinguishing between human and machine output grows increasingly difficult, these archives may prove valuable for understanding how human communication evolved before AI entered the chat.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Newly announced catalog collects pre-2022 sources untouched by ChatGPT and AI contamination.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Mushroom cloud from Ivy Mike nuclear test" class="absolute inset-0 w-full h-full object-cover hidden" height="201" src="https://cdn.arstechnica.net/wp-content/uploads/2020/12/wheeler3-300x201.jpg" width="300" /&gt;
                  &lt;img alt="Mushroom cloud from Ivy Mike nuclear test" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2020/12/wheeler3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nuclear blasts contaminated steel worldwide, leading some scientists to seek out material from the pre-nuclear age.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          National Nuclear Security Administration/Public domain

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Former Cloudflare executive John Graham-Cumming recently announced that he launched a website, lowbackgroundsteel.ai, that treats pre-AI, human-created content like a precious commodity—a time capsule of organic creative expression from a time before machines joined the conversation. "The idea is to point to sources of text, images and video that were created prior to the explosion of AI-generated content," Graham-Cumming wrote on his blog last week. The reason? To preserve what made non-AI media uniquely human.&lt;/p&gt;
&lt;p&gt;The archive name comes from a scientific phenomenon from the Cold War era. After nuclear weapons testing began in 1945, atmospheric radiation contaminated new steel production worldwide. For decades, scientists needing radiation-free metal for sensitive instruments had to salvage steel from pre-war shipwrecks. Scientists called this steel "low-background steel." Graham-Cumming sees a parallel with today's web, where AI-generated content increasingly mingles with human-created material and contaminates it.&lt;/p&gt;
&lt;p&gt;With the advent of generative AI models like ChatGPT and Stable Diffusion in 2022, it has become far more difficult for researchers to ensure that media found on the Internet was created by humans without using AI tools. ChatGPT in particular triggered an avalanche of AI-generated text across the web, forcing at least one research project to shut down entirely.&lt;/p&gt;
&lt;p&gt;That casualty was wordfreq, a Python library created by researcher Robyn Speer that tracked word frequency usage across more than 40 languages by analyzing millions of sources, including Wikipedia, movie subtitles, news articles, and social media. The tool was widely used by academics and developers to study how language evolves and to build natural language processing applications. The project announced in September 2024 that it will no longer be updated because "the Web at large is full of slop generated by large language models, written by no one to communicate nothing."&lt;/p&gt;
&lt;p&gt;Some researchers also worry about AI models training on their own outputs, potentially leading to quality degradation over time—a phenomenon sometimes called "model collapse." But recent evidence suggests this fear may be overblown under certain conditions. Research by Gerstgrasser et al. (2024) suggests that model collapse can be avoided when synthetic data accumulates alongside real data, rather than replacing it entirely. In fact, when properly curated and combined with real data, synthetic data from AI models can actually assist with training newer, more capable models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A time capsule of human expression&lt;/h2&gt;
&lt;p&gt;Graham-Cumming is no stranger to tech preservation efforts. He's a British software engineer and writer best known for creating POPFile, an open source email spam filtering program, and for successfully petitioning the UK government to apologize for its persecution of codebreaker Alan Turing—an apology that Prime Minister Gordon Brown issued in 2009.&lt;/p&gt;
&lt;p&gt;As it turns out, his pre-AI website isn't new, but it has languished unannounced until now. "I created it back in March 2023 as a clearinghouse for online resources that hadn't been contaminated with AI-generated content," he wrote on his blog.&lt;/p&gt;
&lt;p&gt;The website points to several major archives of pre-AI content, including a Wikipedia dump from August 2022 (before ChatGPT's November 2022 release), Project Gutenberg's collection of public domain books, the Library of Congress photo archive, and GitHub's Arctic Code Vault—a snapshot of open source code buried in a former coal mine near the North Pole in February 2020. The wordfreq project appears on the list as well, flash-frozen from a time before AI contamination made its methodology untenable.&lt;/p&gt;
&lt;p&gt;The site accepts submissions of other pre-AI content sources through its Tumblr page. Graham-Cumming emphasizes that the project aims to document human creativity from before the AI era, not to make a statement against AI itself. As atmospheric nuclear testing ended and background radiation returned to natural levels, low-background steel eventually became unnecessary for most uses. Whether pre-AI content will follow a similar trajectory remains a question.&lt;/p&gt;
&lt;p&gt;Still, it feels reasonable to protect sources of human creativity now, including archival ones, because these repositories&amp;nbsp;may become useful in ways that few appreciate at the moment. For example, in 2020, I proposed creating a so-called "cryptographic ark"—a timestamped archive of pre-AI media that future historians could verify as authentic, collected before my then-arbitrary cutoff date of January 1, 2022. AI slop pollutes more than the current discourse—it could cloud the historical record as well.&lt;/p&gt;
&lt;p&gt;For now, lowbackgroundsteel.ai stands as a modest catalog of human expression from what may someday be seen as the last pre-AI era. It's a digital archaeology project marking the boundary between human-generated and hybrid human-AI cultures. In an age where distinguishing between human and machine output grows increasingly difficult, these archives may prove valuable for understanding how human communication evolved before AI entered the chat.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/why-one-man-is-archiving-human-made-content-from-before-the-ai-explosion/</guid><pubDate>Wed, 18 Jun 2025 11:15:46 +0000</pubDate></item><item><title>The Download: tackling tech-facilitated abuse, and opening up AI hardware (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1119002/the-download-tech-abuse-ai-hardware/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why it’s so hard to stop tech-facilitated abuse&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior. One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt;  &lt;p&gt;And Gioia is far from alone. In fact, tech-facilitated abuse now occurs in most cases of intimate partner violence—and we’re doing shockingly little to prevent it. Read the full story.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Klein&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live on Wednesday June 25, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why AI hardware needs to be open&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—by &lt;em&gt;Ayah Bdeir, a leader in the maker movement, champion of open source AI, and founder of littleBits, the hardware platform that teaches STEAM to kids through hands-on invention.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Once again, the future of technology is being engineered in secret by a handful of people and delivered to the rest of us as a sealed, seamless, perfect device. When technology is designed like this, we are reduced to consumers. We don’t shape the tools; they shape us.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;However, this moment creates a chance to do things differently. Because away from the self-centeredness of Silicon Valley, a quiet, grounded sense of resistance is reactivating.&amp;nbsp; Read the full story.&lt;/p&gt;  &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;/h3&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;MIT Technology Review Narrated: Deepfakes of your dead loved ones are a booming Chinese business&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In China, people are seeking help from AI-generated avatars to process their grief after a family member passes away. Our story about this trend is the latest to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Iran is going offline to avoid Israeli cyberattacks&lt;/strong&gt;&lt;br /&gt;A government spokesperson said it plans to disconnect completely from the global internet this evening. (The Verge)&lt;br /&gt;+ &lt;em&gt;How attacks on Iran’s oil exports could hurt China. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump is giving TikTok another reprieve from a US ban&lt;/strong&gt;&lt;br /&gt;It’s been a full five years since he signed the original executive order telling Bytedance to sell it. (CNN)&lt;br /&gt;+ &lt;em&gt;Why Chinese manufacturers are going viral on TikTok. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Conspiracy theories about the Minnesota shooting are all over social media&lt;/strong&gt;&lt;br /&gt;Whenever there’s an information vacuum, people are all too keen to fill it with noise and nonsense. (NBC)&amp;nbsp;&lt;br /&gt;+ &lt;em&gt;The shooting suspect allegedly used data broker sites to find targets’ addresses.&lt;/em&gt; (Wired $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Tensions between OpenAI and Microsoft are starting to boil over&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;OpenAI has even threatened to report its formerly close partner to antitrust regulators. (WSJ $)&lt;br /&gt;+&lt;em&gt; Here are the concessions OpenAI is seeking.&lt;/em&gt; (The Information $)&lt;br /&gt;+&lt;em&gt; Inside the story that enraged OpenAI. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 California cops are using AI cameras to investigate ICE protests&lt;/strong&gt;&lt;br /&gt;And sharing license plate data with other agencies, a practice some experts say is illegal. (404 Media)&lt;br /&gt;+ &lt;em&gt;How a new type of AI is helping police skirt facial recognition bans. (&lt;/em&gt;MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Social media is now Americans’ primary news source&lt;/strong&gt;&lt;br /&gt;It’s overtaken TV for the first time. (Reuters)&lt;br /&gt;+ &lt;em&gt;They watched more TV via streaming than cable last month, too. &lt;/em&gt;(NYT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Weight loss drugs may not work quite as well as hoped&lt;/strong&gt;&lt;br /&gt;Researchers analysed data from 51,085 patients and found bariatric surgery delivered better, more sustainable results. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 What is AI doing to reading?&amp;nbsp;📖&lt;/strong&gt;&lt;br /&gt;Here’s what we stand to gain—and lose—when we outsource reading to machines. (New Yorker $)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 India is relying on China to build up its EV market&lt;/strong&gt;&lt;br /&gt;It’s taking a drastically different course to the US. (Rest of World)&lt;br /&gt;+ &lt;em&gt;Why EVs are (mostly) set for solid growth in 2025.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 People are building AI tools to decipher cats’ meows&amp;nbsp;😸&lt;/strong&gt;&lt;br /&gt;Bet at least half of them are “feed me.” (Scientific American $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Have we fallen so low? Have we no shame?”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Remarks made by federal judge Williams G. Young this week as he voided some of the Trump administration’s cuts to National Institutes of Health grants, saying they were discriminatory, the New York Times reports.&amp;nbsp;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a pixelated plate with the crusts of a sandwich and two pickle slices" class="wp-image-1106727" src="https://wp.technologyreview.com/wp-content/uploads/2024/11/ai-lunch.jpeg?w=3000" /&gt;&lt;div class="image-credit"&gt;STEPHANIE ARNETT/MIT TECHNOLOGY REVIEW | GETTY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;&lt;br /&gt;Why AI could eat quantum computing’s lunch&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Tech companies have been funneling billions of dollars into quantum computers for years. The hope is that they’ll be a game changer for fields as diverse as finance, drug discovery, and logistics.&lt;/p&gt;&lt;p&gt;But while the field struggles with the realities of tricky quantum hardware, another challenger is making headway in some of these most promising use cases. AI is now being applied to fundamental physics, chemistry, and materials science in a way that suggests quantum computing’s purported home turf might not be so safe after all. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why it’s so hard to stop tech-facilitated abuse&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior. One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt;  &lt;p&gt;And Gioia is far from alone. In fact, tech-facilitated abuse now occurs in most cases of intimate partner violence—and we’re doing shockingly little to prevent it. Read the full story.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Klein&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live on Wednesday June 25, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why AI hardware needs to be open&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—by &lt;em&gt;Ayah Bdeir, a leader in the maker movement, champion of open source AI, and founder of littleBits, the hardware platform that teaches STEAM to kids through hands-on invention.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Once again, the future of technology is being engineered in secret by a handful of people and delivered to the rest of us as a sealed, seamless, perfect device. When technology is designed like this, we are reduced to consumers. We don’t shape the tools; they shape us.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;However, this moment creates a chance to do things differently. Because away from the self-centeredness of Silicon Valley, a quiet, grounded sense of resistance is reactivating.&amp;nbsp; Read the full story.&lt;/p&gt;  &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;/h3&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;MIT Technology Review Narrated: Deepfakes of your dead loved ones are a booming Chinese business&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In China, people are seeking help from AI-generated avatars to process their grief after a family member passes away. Our story about this trend is the latest to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Iran is going offline to avoid Israeli cyberattacks&lt;/strong&gt;&lt;br /&gt;A government spokesperson said it plans to disconnect completely from the global internet this evening. (The Verge)&lt;br /&gt;+ &lt;em&gt;How attacks on Iran’s oil exports could hurt China. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump is giving TikTok another reprieve from a US ban&lt;/strong&gt;&lt;br /&gt;It’s been a full five years since he signed the original executive order telling Bytedance to sell it. (CNN)&lt;br /&gt;+ &lt;em&gt;Why Chinese manufacturers are going viral on TikTok. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Conspiracy theories about the Minnesota shooting are all over social media&lt;/strong&gt;&lt;br /&gt;Whenever there’s an information vacuum, people are all too keen to fill it with noise and nonsense. (NBC)&amp;nbsp;&lt;br /&gt;+ &lt;em&gt;The shooting suspect allegedly used data broker sites to find targets’ addresses.&lt;/em&gt; (Wired $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Tensions between OpenAI and Microsoft are starting to boil over&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;OpenAI has even threatened to report its formerly close partner to antitrust regulators. (WSJ $)&lt;br /&gt;+&lt;em&gt; Here are the concessions OpenAI is seeking.&lt;/em&gt; (The Information $)&lt;br /&gt;+&lt;em&gt; Inside the story that enraged OpenAI. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 California cops are using AI cameras to investigate ICE protests&lt;/strong&gt;&lt;br /&gt;And sharing license plate data with other agencies, a practice some experts say is illegal. (404 Media)&lt;br /&gt;+ &lt;em&gt;How a new type of AI is helping police skirt facial recognition bans. (&lt;/em&gt;MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Social media is now Americans’ primary news source&lt;/strong&gt;&lt;br /&gt;It’s overtaken TV for the first time. (Reuters)&lt;br /&gt;+ &lt;em&gt;They watched more TV via streaming than cable last month, too. &lt;/em&gt;(NYT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Weight loss drugs may not work quite as well as hoped&lt;/strong&gt;&lt;br /&gt;Researchers analysed data from 51,085 patients and found bariatric surgery delivered better, more sustainable results. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 What is AI doing to reading?&amp;nbsp;📖&lt;/strong&gt;&lt;br /&gt;Here’s what we stand to gain—and lose—when we outsource reading to machines. (New Yorker $)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 India is relying on China to build up its EV market&lt;/strong&gt;&lt;br /&gt;It’s taking a drastically different course to the US. (Rest of World)&lt;br /&gt;+ &lt;em&gt;Why EVs are (mostly) set for solid growth in 2025.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 People are building AI tools to decipher cats’ meows&amp;nbsp;😸&lt;/strong&gt;&lt;br /&gt;Bet at least half of them are “feed me.” (Scientific American $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Have we fallen so low? Have we no shame?”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Remarks made by federal judge Williams G. Young this week as he voided some of the Trump administration’s cuts to National Institutes of Health grants, saying they were discriminatory, the New York Times reports.&amp;nbsp;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a pixelated plate with the crusts of a sandwich and two pickle slices" class="wp-image-1106727" src="https://wp.technologyreview.com/wp-content/uploads/2024/11/ai-lunch.jpeg?w=3000" /&gt;&lt;div class="image-credit"&gt;STEPHANIE ARNETT/MIT TECHNOLOGY REVIEW | GETTY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;&lt;br /&gt;Why AI could eat quantum computing’s lunch&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Tech companies have been funneling billions of dollars into quantum computers for years. The hope is that they’ll be a game changer for fields as diverse as finance, drug discovery, and logistics.&lt;/p&gt;&lt;p&gt;But while the field struggles with the realities of tricky quantum hardware, another challenger is making headway in some of these most promising use cases. AI is now being applied to fundamental physics, chemistry, and materials science in a way that suggests quantum computing’s purported home turf might not be so safe after all. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1119002/the-download-tech-abuse-ai-hardware/</guid><pubDate>Wed, 18 Jun 2025 12:15:00 +0000</pubDate></item><item><title>[NEW] Plug and Play: Build a G-Assist Plug-In Today (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/g-assist-hackathon-nv-blog-1280x680-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Project G-Assist — available through the NVIDIA App — is an experimental AI assistant that helps tune, control and optimize NVIDIA GeForce RTX systems.&lt;/p&gt;
&lt;p&gt;NVIDIA’s Plug and Play: Project G-Assist Plug-In Hackathon — running virtually through Wednesday, July 16 — invites the community to explore AI and build custom G-Assist plug-ins for a chance to win prizes and be featured on NVIDIA social media channels.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;G-Assist allows users to control their RTX GPU and other system settings using natural language, thanks to a small language model that runs on device. It can be used from the NVIDIA Overlay in the NVIDIA App without needing to tab out or switch programs. Users can expand its capabilities via plug-ins and even connect it to agentic frameworks such as Langflow.&lt;/p&gt;
&lt;p&gt;Below, find popular G-Assist plug-ins, hackathon details and tips to get started.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Plug-In and Win&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Join the hackathon by registering and checking out the curated technical resources.&lt;/p&gt;
&lt;p&gt;G-Assist plug-ins can be built in several ways, including with Python for rapid development, with C++ for performance-critical apps and with custom system interactions for hardware and operating system automation.&lt;/p&gt;
&lt;p&gt;For those that prefer vibe coding, the G-Assist Plug-In Builder — a ChatGPT-based app that allows no-code or low-code development with natural language commands — makes it easy for enthusiasts to start creating plug-ins.&lt;/p&gt;
&lt;p&gt;To submit an entry, participants must provide a GitHub repository, including source code file (plugin.py), requirements.txt, manifest.json, config.json (if applicable), a plug-in executable file and READme code.&lt;/p&gt;
&lt;p&gt;Then, submit a video — between 30 seconds and two minutes — showcasing the plug-in in action.&lt;/p&gt;
&lt;p&gt;Finally, hackathoners must promote their plug-in using #AIonRTXHackathon on a social media channel: Instagram, TikTok or X. Submit projects via this form by Wednesday, July 16.&lt;/p&gt;
&lt;p&gt;Judges will assess plug-ins based on three main criteria: 1) innovation and creativity, 2) technical execution and integration, reviewing technical depth, G-Assist integration and scalability, and 3) usability and community impact, aka how easy it is to use the plug-in.&lt;/p&gt;
&lt;p&gt;Winners will be selected on Wednesday, Aug. 20. First place will receive a GeForce RTX 5090 laptop, second place a GeForce RTX 5080 GPU and third a GeForce RTX 5070 GPU. These top three will also be featured on NVIDIA’s social media channels, get the opportunity to meet the NVIDIA G-Assist team and earn an NVIDIA Deep Learning Institute self-paced course credit.&lt;/p&gt;
&lt;p&gt;Project G-Assist requires a GeForce RTX 50, 40 or 30 Series Desktop GPU with at least 12GB of VRAM, Windows 11 or 10 operating system, a compatible CPU (Intel Pentium G Series, Core i3, i5, i7 or higher; AMD FX, Ryzen 3, 5, 7, 9, Threadripper or higher), specific disk space requirements and a recent GeForce Game Ready Driver or NVIDIA Studio Driver.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Plug-In(spiration)&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Explore open-source plug-in samples available on GitHub, which showcase the diverse ways on-device AI can enhance PC and gaming workflows.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Popular plug-ins include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Google Gemini&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Enables search-based queries using Google Search integration and large language model-based queries using Gemini capabilities in real time without needing to switch programs from the convenience of the NVIDIA App Overlay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Enables users to easily share game highlights or messages directly to Discord servers without disrupting gameplay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;IFTTT&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Lets users create automations across hundreds of compatible endpoints to trigger IoT routines — such as adjusting room lights and smart shades, or pushing the latest gaming news to a mobile device.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Spotify&lt;/b&gt;: Lets users control Spotify using simple voice commands or the G-Assist interface to play favorite tracks and manage playlists.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Twitch&lt;/b&gt;: Checks if any Twitch streamer is currently live and can access detailed stream information such as titles, games, view counts and more.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Get G-Assist(ance)&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Join the NVIDIA Developer Discord channel to collaborate, share creations and gain support from fellow AI enthusiasts and NVIDIA staff.&lt;/p&gt;
&lt;p&gt;Save the date for NVIDIA’s How to Build a G-Assist Plug-In webinar on Wednesday, July 9, from 10-11 a.m. PT, to learn more about Project G-Assist capabilities, discover the fundamentals of building, testing and deploying Project G-Assist plug-ins, and participate in a live Q&amp;amp;A session.&lt;/p&gt;
&lt;p&gt;Explore NVIDIA’s GitHub repository, which provides everything needed to get started developing with G-Assist, including sample plug-ins, step-by-step instructions and documentation for building custom functionalities.&lt;/p&gt;
&lt;p&gt;Learn more about the ChatGPT Plug-In Builder to transform ideas into functional G-Assist plug-ins with minimal coding. The tool uses OpenAI’s custom GPT builder to generate plug-in code and streamline the development process.&lt;/p&gt;
&lt;p&gt;NVIDIA’s technical blog walks through the architecture of a G-Assist plug-in, using a Twitch integration as an example. Discover how plug-ins work, how they communicate with G-Assist and how to build them from scratch.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Each week, the &lt;/i&gt;&lt;i&gt;RTX AI Garage&lt;/i&gt; &lt;i&gt;blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building &lt;/i&gt;&lt;i&gt;AI agents&lt;/i&gt;&lt;i&gt;, creative workflows, digital humans, productivity apps and more on AI PCs and workstations.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; — and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/g-assist-hackathon-nv-blog-1280x680-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Project G-Assist — available through the NVIDIA App — is an experimental AI assistant that helps tune, control and optimize NVIDIA GeForce RTX systems.&lt;/p&gt;
&lt;p&gt;NVIDIA’s Plug and Play: Project G-Assist Plug-In Hackathon — running virtually through Wednesday, July 16 — invites the community to explore AI and build custom G-Assist plug-ins for a chance to win prizes and be featured on NVIDIA social media channels.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;G-Assist allows users to control their RTX GPU and other system settings using natural language, thanks to a small language model that runs on device. It can be used from the NVIDIA Overlay in the NVIDIA App without needing to tab out or switch programs. Users can expand its capabilities via plug-ins and even connect it to agentic frameworks such as Langflow.&lt;/p&gt;
&lt;p&gt;Below, find popular G-Assist plug-ins, hackathon details and tips to get started.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Plug-In and Win&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Join the hackathon by registering and checking out the curated technical resources.&lt;/p&gt;
&lt;p&gt;G-Assist plug-ins can be built in several ways, including with Python for rapid development, with C++ for performance-critical apps and with custom system interactions for hardware and operating system automation.&lt;/p&gt;
&lt;p&gt;For those that prefer vibe coding, the G-Assist Plug-In Builder — a ChatGPT-based app that allows no-code or low-code development with natural language commands — makes it easy for enthusiasts to start creating plug-ins.&lt;/p&gt;
&lt;p&gt;To submit an entry, participants must provide a GitHub repository, including source code file (plugin.py), requirements.txt, manifest.json, config.json (if applicable), a plug-in executable file and READme code.&lt;/p&gt;
&lt;p&gt;Then, submit a video — between 30 seconds and two minutes — showcasing the plug-in in action.&lt;/p&gt;
&lt;p&gt;Finally, hackathoners must promote their plug-in using #AIonRTXHackathon on a social media channel: Instagram, TikTok or X. Submit projects via this form by Wednesday, July 16.&lt;/p&gt;
&lt;p&gt;Judges will assess plug-ins based on three main criteria: 1) innovation and creativity, 2) technical execution and integration, reviewing technical depth, G-Assist integration and scalability, and 3) usability and community impact, aka how easy it is to use the plug-in.&lt;/p&gt;
&lt;p&gt;Winners will be selected on Wednesday, Aug. 20. First place will receive a GeForce RTX 5090 laptop, second place a GeForce RTX 5080 GPU and third a GeForce RTX 5070 GPU. These top three will also be featured on NVIDIA’s social media channels, get the opportunity to meet the NVIDIA G-Assist team and earn an NVIDIA Deep Learning Institute self-paced course credit.&lt;/p&gt;
&lt;p&gt;Project G-Assist requires a GeForce RTX 50, 40 or 30 Series Desktop GPU with at least 12GB of VRAM, Windows 11 or 10 operating system, a compatible CPU (Intel Pentium G Series, Core i3, i5, i7 or higher; AMD FX, Ryzen 3, 5, 7, 9, Threadripper or higher), specific disk space requirements and a recent GeForce Game Ready Driver or NVIDIA Studio Driver.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Plug-In(spiration)&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Explore open-source plug-in samples available on GitHub, which showcase the diverse ways on-device AI can enhance PC and gaming workflows.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Popular plug-ins include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Google Gemini&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Enables search-based queries using Google Search integration and large language model-based queries using Gemini capabilities in real time without needing to switch programs from the convenience of the NVIDIA App Overlay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Enables users to easily share game highlights or messages directly to Discord servers without disrupting gameplay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;IFTTT&lt;/b&gt;&lt;b&gt;:&lt;/b&gt; Lets users create automations across hundreds of compatible endpoints to trigger IoT routines — such as adjusting room lights and smart shades, or pushing the latest gaming news to a mobile device.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Spotify&lt;/b&gt;: Lets users control Spotify using simple voice commands or the G-Assist interface to play favorite tracks and manage playlists.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Twitch&lt;/b&gt;: Checks if any Twitch streamer is currently live and can access detailed stream information such as titles, games, view counts and more.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Get G-Assist(ance)&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Join the NVIDIA Developer Discord channel to collaborate, share creations and gain support from fellow AI enthusiasts and NVIDIA staff.&lt;/p&gt;
&lt;p&gt;Save the date for NVIDIA’s How to Build a G-Assist Plug-In webinar on Wednesday, July 9, from 10-11 a.m. PT, to learn more about Project G-Assist capabilities, discover the fundamentals of building, testing and deploying Project G-Assist plug-ins, and participate in a live Q&amp;amp;A session.&lt;/p&gt;
&lt;p&gt;Explore NVIDIA’s GitHub repository, which provides everything needed to get started developing with G-Assist, including sample plug-ins, step-by-step instructions and documentation for building custom functionalities.&lt;/p&gt;
&lt;p&gt;Learn more about the ChatGPT Plug-In Builder to transform ideas into functional G-Assist plug-ins with minimal coding. The tool uses OpenAI’s custom GPT builder to generate plug-in code and streamline the development process.&lt;/p&gt;
&lt;p&gt;NVIDIA’s technical blog walks through the architecture of a G-Assist plug-in, using a Twitch integration as an example. Discover how plug-ins work, how they communicate with G-Assist and how to build them from scratch.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Each week, the &lt;/i&gt;&lt;i&gt;RTX AI Garage&lt;/i&gt; &lt;i&gt;blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building &lt;/i&gt;&lt;i&gt;AI agents&lt;/i&gt;&lt;i&gt;, creative workflows, digital humans, productivity apps and more on AI PCs and workstations.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; — and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in/</guid><pubDate>Wed, 18 Jun 2025 13:00:39 +0000</pubDate></item><item><title>[NEW] Puzzle Corner (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1119010/puzzle-corner-73/</link><description></description><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1119010/puzzle-corner-73/</guid><pubDate>Wed, 18 Jun 2025 13:05:08 +0000</pubDate></item><item><title>[NEW] AI adoption matures but deployment hurdles remain (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-adoption-matures-deployment-hurdles-remain/</link><description>&lt;p&gt;AI has moved beyond experimentation to become a core part of business operations, but deployment challenges persist.&lt;/p&gt;&lt;p&gt;Research from Zogby Analytics, on behalf of Prove AI, shows that most organisations have graduated from testing the AI waters to diving in headfirst with production-ready systems. Despite this progress, businesses are still grappling with basic challenges around data quality, security, and effectively training their models.&lt;/p&gt;&lt;p&gt;Looking at the numbers, it’s pretty eye-opening. 68% of organisations now have custom AI solutions up and running in production. Companies are putting their money where their mouth is too, with 81% spending at least a million annually on AI initiatives. Around a quarter are investing over 10 million each year, showing we’ve moved well beyond the “let’s experiment” phase into serious, long-term AI commitment.&lt;/p&gt;&lt;p&gt;This shift is reshaping leadership structures as well. 86% of organisations have appointed someone to lead their AI efforts, typically with a ‘Chief AI Officer’ title or similar. These AI leaders are now almost as influential as CEOs when it comes to setting strategy with 43.3% of companies saying the CEO calls the AI shots, while 42% give that responsibility to their AI chief.&lt;/p&gt;&lt;p&gt;But the AI deployment journey isn’t all smooth sailing. More than half of business leaders admit that training and fine-tuning AI models has been tougher than they expected. Data issues keep popping up, causing headaches with quality, availability, copyright, and model validation—undermining how effective these AI systems can be. Nearly 70% of organisations report having at least one AI project behind schedule, with data problems being the main culprit.&lt;/p&gt;&lt;p&gt;As businesses get more comfortable with AI, they’re finding new ways to use it. While chatbots and virtual assistants remain popular (55% adoption), more technical applications are gaining ground.&lt;/p&gt;&lt;p&gt;Software development now tops the list at 54%, alongside predictive analytics for forecasting and fraud detection at 52%. This suggests companies are moving beyond flashy customer-facing applications toward using AI to improve core operations. Marketing applications, once the gateway for many AI deployment initiatives, are getting less attention these days.&lt;/p&gt;&lt;p&gt;When it comes to the AI models themselves, there’s a strong focus on generative AI, with 57% of organisations making it a priority. However, many are taking a balanced approach, combining these newer models with traditional machine learning techniques.&lt;/p&gt;&lt;p&gt;Google’s Gemini and OpenAI’s GPT-4 are the most widely-used large language models, though DeepSeek, Claude, and Llama are also making strong showings. Most companies use two or three different LLMs, suggesting that a multi-model approach is becoming standard practice.&lt;/p&gt;&lt;p&gt;Perhaps most interesting is the shift in where companies are running their AI deployment. While almost nine in ten organisations use cloud services for at least some of their AI infrastructure, there’s a growing trend toward bringing things back in-house.&lt;/p&gt;&lt;p&gt;Two-thirds of business leaders now believe non-cloud deployments offer better security and efficiency. As a result, 67% plan to move their AI training data to on-premises or hybrid environments, seeking greater control over their digital assets. Data sovereignty is the top priority for 83% of respondents when deploying AI systems.&lt;/p&gt;&lt;p&gt;Business leaders seem confident about their AI governance capabilities with around 90% claiming they’re effectively managing AI policy, can set up necessary guardrails, and can track their data lineage. However, this confidence stands in contrast to the practical challenges causing project delays.&lt;/p&gt;&lt;p&gt;Issues with data labeling, model training, and validation continue to be stumbling blocks. This suggests a potential gap between executives’ confidence in their governance frameworks and the day-to-day reality of managing data. Talent shortages and integration difficulties with existing systems are also frequently cited reasons for delays.&lt;/p&gt;&lt;p&gt;The days of AI experimentation are behind us and it’s now a fundamental part of how businesses operate. Organisations are investing heavily, reshaping their leadership structures, and finding new ways for AI deployment across their operations.&lt;/p&gt;&lt;p&gt;Yet as ambitions grow, so do the challenges of putting these plans into action. The journey from pilot to production has exposed fundamental issues in data readiness and infrastructure. The resulting shift toward on-premises and hybrid solutions shows a new level of maturity, with organisations prioritising control, security, and governance.&lt;/p&gt;&lt;p&gt;As AI deployment accelerates, ensuring transparency, traceability, and trust isn’t just a goal but a necessity for success. The confidence is real, but so is the caution.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Roy Harryman)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI has moved beyond experimentation to become a core part of business operations, but deployment challenges persist.&lt;/p&gt;&lt;p&gt;Research from Zogby Analytics, on behalf of Prove AI, shows that most organisations have graduated from testing the AI waters to diving in headfirst with production-ready systems. Despite this progress, businesses are still grappling with basic challenges around data quality, security, and effectively training their models.&lt;/p&gt;&lt;p&gt;Looking at the numbers, it’s pretty eye-opening. 68% of organisations now have custom AI solutions up and running in production. Companies are putting their money where their mouth is too, with 81% spending at least a million annually on AI initiatives. Around a quarter are investing over 10 million each year, showing we’ve moved well beyond the “let’s experiment” phase into serious, long-term AI commitment.&lt;/p&gt;&lt;p&gt;This shift is reshaping leadership structures as well. 86% of organisations have appointed someone to lead their AI efforts, typically with a ‘Chief AI Officer’ title or similar. These AI leaders are now almost as influential as CEOs when it comes to setting strategy with 43.3% of companies saying the CEO calls the AI shots, while 42% give that responsibility to their AI chief.&lt;/p&gt;&lt;p&gt;But the AI deployment journey isn’t all smooth sailing. More than half of business leaders admit that training and fine-tuning AI models has been tougher than they expected. Data issues keep popping up, causing headaches with quality, availability, copyright, and model validation—undermining how effective these AI systems can be. Nearly 70% of organisations report having at least one AI project behind schedule, with data problems being the main culprit.&lt;/p&gt;&lt;p&gt;As businesses get more comfortable with AI, they’re finding new ways to use it. While chatbots and virtual assistants remain popular (55% adoption), more technical applications are gaining ground.&lt;/p&gt;&lt;p&gt;Software development now tops the list at 54%, alongside predictive analytics for forecasting and fraud detection at 52%. This suggests companies are moving beyond flashy customer-facing applications toward using AI to improve core operations. Marketing applications, once the gateway for many AI deployment initiatives, are getting less attention these days.&lt;/p&gt;&lt;p&gt;When it comes to the AI models themselves, there’s a strong focus on generative AI, with 57% of organisations making it a priority. However, many are taking a balanced approach, combining these newer models with traditional machine learning techniques.&lt;/p&gt;&lt;p&gt;Google’s Gemini and OpenAI’s GPT-4 are the most widely-used large language models, though DeepSeek, Claude, and Llama are also making strong showings. Most companies use two or three different LLMs, suggesting that a multi-model approach is becoming standard practice.&lt;/p&gt;&lt;p&gt;Perhaps most interesting is the shift in where companies are running their AI deployment. While almost nine in ten organisations use cloud services for at least some of their AI infrastructure, there’s a growing trend toward bringing things back in-house.&lt;/p&gt;&lt;p&gt;Two-thirds of business leaders now believe non-cloud deployments offer better security and efficiency. As a result, 67% plan to move their AI training data to on-premises or hybrid environments, seeking greater control over their digital assets. Data sovereignty is the top priority for 83% of respondents when deploying AI systems.&lt;/p&gt;&lt;p&gt;Business leaders seem confident about their AI governance capabilities with around 90% claiming they’re effectively managing AI policy, can set up necessary guardrails, and can track their data lineage. However, this confidence stands in contrast to the practical challenges causing project delays.&lt;/p&gt;&lt;p&gt;Issues with data labeling, model training, and validation continue to be stumbling blocks. This suggests a potential gap between executives’ confidence in their governance frameworks and the day-to-day reality of managing data. Talent shortages and integration difficulties with existing systems are also frequently cited reasons for delays.&lt;/p&gt;&lt;p&gt;The days of AI experimentation are behind us and it’s now a fundamental part of how businesses operate. Organisations are investing heavily, reshaping their leadership structures, and finding new ways for AI deployment across their operations.&lt;/p&gt;&lt;p&gt;Yet as ambitions grow, so do the challenges of putting these plans into action. The journey from pilot to production has exposed fundamental issues in data readiness and infrastructure. The resulting shift toward on-premises and hybrid solutions shows a new level of maturity, with organisations prioritising control, security, and governance.&lt;/p&gt;&lt;p&gt;As AI deployment accelerates, ensuring transparency, traceability, and trust isn’t just a goal but a necessity for success. The confidence is real, but so is the caution.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Roy Harryman)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-adoption-matures-deployment-hurdles-remain/</guid><pubDate>Wed, 18 Jun 2025 14:01:03 +0000</pubDate></item><item><title>[NEW] Puzzle Corner (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1118935/puzzle-corner-74/</link><description></description><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1118935/puzzle-corner-74/</guid><pubDate>Wed, 18 Jun 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google’s AI Mode can now have back-and-forth voice conversations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/googles-ai-mode-can-now-have-back-and-forth-voice-conversations/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out the ability for users to have a back-and-forth voice conversation with AI Mode, its experimental Search&amp;nbsp;feature&amp;nbsp;that lets users ask complex, multi-part questions. With the new Search Live integration, users can have a free-flowing voice conversation with Search and explore links from across the web. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will be able to access the feature by opening the Google app and tapping the new “Live” icon to ask their question aloud. They will then hear an AI-generated audio response, and they can follow up with another question.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today’s announcement comes a few weeks after Google rolled out AI Mode to everyone in the U.S. The launch of the feature was seen as Google’s answer to popular services like Perplexity AI and OpenAI’s ChatGPT Search. With this new update, Google is looking to take on those services’ respective voice modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says the feature will be useful in instances where you’re on the go or multitasking. For example, if you’re packing for a trip, you can ask a question like “What are some tips for preventing a linen dress from wrinkling in a suitcase?” You could follow up with another question like “What should I do if it still wrinkles?”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019848" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/Search-Live-with-voice-input-no-audio.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As you’re having the conversation, you’ll find links right on your screen if you want to dig deeper into your search. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because Search Live works in the background, you can continue the conversation while in another app. Plus, you have the option to tap the “transcript” button to view the text response and continue to ask questions by typing if you’d like to. You can also revisit a Search Live response by navigating to your AI Mode history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Behind the scenes, Search Live in AI Mode uses a custom version of Gemini with advanced voice capabilities,” Liza Ma, the director of product management at Google Search, explained in a blog post. “Our custom model is built on Search’s best-in-class quality and information systems, so you still get reliable, helpful responses no matter where or how you’re asking your question. Search Live with voice also uses our query fan-out technique to show you a wider and more diverse set of helpful web content, enabling new opportunities for exploration.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In the coming months, Google plans to bring more Live capabilities to AI Mode, including letting you ask questions based on what your phone’s camera is seeing in real time, as was previewed at Google I/O in May. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out the ability for users to have a back-and-forth voice conversation with AI Mode, its experimental Search&amp;nbsp;feature&amp;nbsp;that lets users ask complex, multi-part questions. With the new Search Live integration, users can have a free-flowing voice conversation with Search and explore links from across the web. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will be able to access the feature by opening the Google app and tapping the new “Live” icon to ask their question aloud. They will then hear an AI-generated audio response, and they can follow up with another question.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today’s announcement comes a few weeks after Google rolled out AI Mode to everyone in the U.S. The launch of the feature was seen as Google’s answer to popular services like Perplexity AI and OpenAI’s ChatGPT Search. With this new update, Google is looking to take on those services’ respective voice modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says the feature will be useful in instances where you’re on the go or multitasking. For example, if you’re packing for a trip, you can ask a question like “What are some tips for preventing a linen dress from wrinkling in a suitcase?” You could follow up with another question like “What should I do if it still wrinkles?”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019848" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/Search-Live-with-voice-input-no-audio.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As you’re having the conversation, you’ll find links right on your screen if you want to dig deeper into your search. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because Search Live works in the background, you can continue the conversation while in another app. Plus, you have the option to tap the “transcript” button to view the text response and continue to ask questions by typing if you’d like to. You can also revisit a Search Live response by navigating to your AI Mode history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Behind the scenes, Search Live in AI Mode uses a custom version of Gemini with advanced voice capabilities,” Liza Ma, the director of product management at Google Search, explained in a blog post. “Our custom model is built on Search’s best-in-class quality and information systems, so you still get reliable, helpful responses no matter where or how you’re asking your question. Search Live with voice also uses our query fan-out technique to show you a wider and more diverse set of helpful web content, enabling new opportunities for exploration.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In the coming months, Google plans to bring more Live capabilities to AI Mode, including letting you ask questions based on what your phone’s camera is seeing in real time, as was previewed at Google I/O in May. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/googles-ai-mode-can-now-have-back-and-forth-voice-conversations/</guid><pubDate>Wed, 18 Jun 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Seed to Series C: What VCs actually want from AI startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/seed-to-series-c-what-vcs-actually-want-from-ai-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/AI-Sessions-VC-Sessions-.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI investments hit $110 billion in 2024, and the funding landscape in 2025 is more competitive than ever. For early-stage startups, that means more money in the market, but also more pressure to stand out.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At TechCrunch Sessions: AI, Rebecca Bellan sat down with three experienced investors: Jill Chase, partner at CapitalG; Kanu Gulati, partner at Khosla Ventures; and Sara Ittelson, partner at Accel. They broke down what they are really looking for when evaluating AI startups from seed through Series C. Their message to founders? Forget the perfect pitch. Focus on building trust, surviving the hype cycle, and being ready for copycats the moment you find product-market fit.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode of Equity to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why VCs say founders should stop obsessing over the perfect pitch and focus on building real relationships.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it takes to go up against big incumbents without getting crushed.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why consumer focus (and speed) still win, even in B2B AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How agents and automation are already reshaping the startup playbook.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod. For the full episode transcript, for those who prefer reading over listening, check out our full archive of episodes &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/AI-Sessions-VC-Sessions-.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI investments hit $110 billion in 2024, and the funding landscape in 2025 is more competitive than ever. For early-stage startups, that means more money in the market, but also more pressure to stand out.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At TechCrunch Sessions: AI, Rebecca Bellan sat down with three experienced investors: Jill Chase, partner at CapitalG; Kanu Gulati, partner at Khosla Ventures; and Sara Ittelson, partner at Accel. They broke down what they are really looking for when evaluating AI startups from seed through Series C. Their message to founders? Forget the perfect pitch. Focus on building trust, surviving the hype cycle, and being ready for copycats the moment you find product-market fit.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode of Equity to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why VCs say founders should stop obsessing over the perfect pitch and focus on building real relationships.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it takes to go up against big incumbents without getting crushed.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why consumer focus (and speed) still win, even in B2B AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How agents and automation are already reshaping the startup playbook.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod. For the full episode transcript, for those who prefer reading over listening, check out our full archive of episodes &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/seed-to-series-c-what-vcs-actually-want-from-ai-startups/</guid><pubDate>Wed, 18 Jun 2025 16:16:24 +0000</pubDate></item><item><title>[NEW] Here’s your first look at the rebooted Digg (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/heres-your-first-look-at-the-rebooted-digg/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The rebooted version of Digg’s news aggregator has entered testing, offering users a first look at what this would-be Reddit competitor, built for the AI era, has in store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its height in 2008, Digg’s site was&amp;nbsp;valued at $175 million, but it was split up and sold for parts a decade later. In March, Digg’s original founder, Kevin Rose, and Reddit co-founder Alexis Ohanian teamed up to bring the brand back and reinvent the site for a new generation of internet users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founders think that the internet is being flooded with bots and AI agents, which will create demand for online communities like Digg that foster real human connections. They’ve said they’re also looking into using technology to establish ownership, like zero-knowledge proofs, alongside other tools that could verify whether someone is human before they’re able to post and join conversations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3014331" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/digg-mobile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Digg launched its iOS app to testers who are a part of its Groundbreakers community of early adopters. The app, which is in alpha testing, provides a first look at the direction the rebooted Digg is headed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app itself has a clean design, with a navigation bar at the bottom for moving between the different parts of the service like the Home feed, Search, Leaderboards, and user profile page.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Reddit, Digg offers a selection of feeds that allow you to view the site’s content in different ways. There are feeds to see the site’s most popular content (Most Dugg), Newest, Trending, and content that’s “Heating up.” These filters can be used across either All of Digg or just your own Feed, which is based on the communities you follow.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1510.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Reddit, there are only a handful of communities to join for the time being, including those focused on interests like art, entertainment, sports, finance, food, music, science, and technology, as well as those for asking questions (AMA), tracking news, or chatting about Digg itself. (The company says the ability to create communities will roll out in later tests.)&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019886" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1513.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As users share posts to these various communities, others can upvote or downvote them, save posts, and leave comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beneath posts, Digg is leveraging AI to summarize the article’s content. This news summarization trend has been popularized in other apps like Artifact, which sold to Yahoo, and modern-day news readers like Particle. However, AI-based news summaries can be hit or miss, which is why some publishers have been wary of implementing them on their own sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Digg hasn’t yet added any other AI summarization tools, like the ability to have the story explained from both sides or in a simpler format, like “Explain it like I’m 5,” like these earlier AI news apps had done.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In trying to differentiate its upvote and downvote buttons from Reddit, Digg is using icons that are meant to resemble hands. This design still needs work, though. As some have pointed out, it’s not clear which icon is meant to be the upvote or downvote; the icons could be read either way.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019888" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1511.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also features user profiles with bios, stats, posts, and achievements. For instance, users can earn “Gems” by being the first to Digg a post that then trends across the platform. The earlier you are to discover and dig these posts, the more Gems you earn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also leaderboards in the mobile app that highlight the top daily posts, comments, and Gem-finders, though Digg says it’s responding to user feedback and has been dialing back gamification elements on the desktop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Digg has learned from its past mistakes and is making its new leaderboards time-bound — that is, they refresh every 24 hours. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019887" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1512.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the prior version of Digg during the Web 2.0 era, Digg’s leaderboards became dominated by certain individuals who then had outsized influence on what trended. Users organized to promote or bury pages en masse, and some even began charging to get stories to the front page. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the rebooted Digg may want to avoid these types of problems, including leaderboards in the app at all may send the wrong message. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the new app is in good shape — especially considering it’s an alpha — what it’s not yet demonstrating is why anyone would leave Reddit to use Digg instead. That push may come in time, as Digg allows users to create their own communities and customize them to their liking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rose suggested during a recent AMA that Digg would like to turn to AI to help in community design further down the road.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We see a world where eventually you have a conversation with a built-in LLM on Digg and say, hey, I want my community to show up like this … I want to be this widget over here, or this be structured,” he explained.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The rebooted version of Digg’s news aggregator has entered testing, offering users a first look at what this would-be Reddit competitor, built for the AI era, has in store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its height in 2008, Digg’s site was&amp;nbsp;valued at $175 million, but it was split up and sold for parts a decade later. In March, Digg’s original founder, Kevin Rose, and Reddit co-founder Alexis Ohanian teamed up to bring the brand back and reinvent the site for a new generation of internet users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founders think that the internet is being flooded with bots and AI agents, which will create demand for online communities like Digg that foster real human connections. They’ve said they’re also looking into using technology to establish ownership, like zero-knowledge proofs, alongside other tools that could verify whether someone is human before they’re able to post and join conversations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3014331" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/digg-mobile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Digg launched its iOS app to testers who are a part of its Groundbreakers community of early adopters. The app, which is in alpha testing, provides a first look at the direction the rebooted Digg is headed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app itself has a clean design, with a navigation bar at the bottom for moving between the different parts of the service like the Home feed, Search, Leaderboards, and user profile page.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Reddit, Digg offers a selection of feeds that allow you to view the site’s content in different ways. There are feeds to see the site’s most popular content (Most Dugg), Newest, Trending, and content that’s “Heating up.” These filters can be used across either All of Digg or just your own Feed, which is based on the communities you follow.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1510.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Reddit, there are only a handful of communities to join for the time being, including those focused on interests like art, entertainment, sports, finance, food, music, science, and technology, as well as those for asking questions (AMA), tracking news, or chatting about Digg itself. (The company says the ability to create communities will roll out in later tests.)&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019886" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1513.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As users share posts to these various communities, others can upvote or downvote them, save posts, and leave comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beneath posts, Digg is leveraging AI to summarize the article’s content. This news summarization trend has been popularized in other apps like Artifact, which sold to Yahoo, and modern-day news readers like Particle. However, AI-based news summaries can be hit or miss, which is why some publishers have been wary of implementing them on their own sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Digg hasn’t yet added any other AI summarization tools, like the ability to have the story explained from both sides or in a simpler format, like “Explain it like I’m 5,” like these earlier AI news apps had done.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In trying to differentiate its upvote and downvote buttons from Reddit, Digg is using icons that are meant to resemble hands. This design still needs work, though. As some have pointed out, it’s not clear which icon is meant to be the upvote or downvote; the icons could be read either way.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019888" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1511.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also features user profiles with bios, stats, posts, and achievements. For instance, users can earn “Gems” by being the first to Digg a post that then trends across the platform. The earlier you are to discover and dig these posts, the more Gems you earn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also leaderboards in the mobile app that highlight the top daily posts, comments, and Gem-finders, though Digg says it’s responding to user feedback and has been dialing back gamification elements on the desktop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Digg has learned from its past mistakes and is making its new leaderboards time-bound — that is, they refresh every 24 hours. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019887" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1512.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the prior version of Digg during the Web 2.0 era, Digg’s leaderboards became dominated by certain individuals who then had outsized influence on what trended. Users organized to promote or bury pages en masse, and some even began charging to get stories to the front page. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the rebooted Digg may want to avoid these types of problems, including leaderboards in the app at all may send the wrong message. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the new app is in good shape — especially considering it’s an alpha — what it’s not yet demonstrating is why anyone would leave Reddit to use Digg instead. That push may come in time, as Digg allows users to create their own communities and customize them to their liking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rose suggested during a recent AMA that Digg would like to turn to AI to help in community design further down the road.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We see a world where eventually you have a conversation with a built-in LLM on Digg and say, hey, I want my community to show up like this … I want to be this widget over here, or this be structured,” he explained.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/heres-your-first-look-at-the-rebooted-digg/</guid><pubDate>Wed, 18 Jun 2025 16:16:36 +0000</pubDate></item><item><title>[NEW] Google’s frighteningly good Veo 3 AI videos to be integrated with YouTube Shorts (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/06/googles-veo-3-ai-videos-will-come-to-youtube-shorts-this-summer/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Shorts and Veo 3 could be a match made in heaven... or the other place.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-640x427.jpg" width="640" /&gt;
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-1152x648-1734018446.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Even in the age of TikTok, YouTube viewership continues to climb. While Google's iconic video streaming platform has traditionally pushed creators to produce longer videos that can accommodate more ads, the site's Shorts format is growing fast. That growth may explode in the coming months, as YouTube CEO Neal Mohan has announced that the Google Veo 3 AI video generator will be integrated with YouTube Shorts later this summer.&lt;/p&gt;
&lt;p&gt;According to Mohan, YouTube Shorts has seen a rise in popularity even compared to YouTube as a whole. The streaming platform is now the most watched source of video in the world, but Shorts specifically have seen a massive 186 percent increase in viewership over the past year. Mohan says Shorts now average 200 billion daily views.&lt;/p&gt;
&lt;p&gt;YouTube has already equipped creators with a few AI tools, including Dream Screen, which can produce AI video backgrounds with a text prompt. Veo 3 support will be a significant upgrade, though. At the Cannes festival, Mohan revealed that the streaming site will begin offering integration with Google's leading video model later this summer. "I believe these tools will open new creative lanes for everyone to explore," said Mohan.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2101731 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube Shorts recommendations." class="fullwidth full" height="470" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YT-Shorts.png" width="632" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      YouTube heavily promotes Shorts on the homepage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This move will require a few tweaks to Veo 3 outputs, but it seems like a perfect match. As the name implies, YouTube Shorts is intended for short video content. The format initially launched with a 30-second ceiling, but that has since been increased to 60 seconds. Because of the astronomical cost of generative AI, each generated Veo clip is quite short, a mere eight seconds in the current version of the tool. Slap a few of those together, and you've got a YouTube Short.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It has been impossible to avoid Veo 3 around the web ever since Google unveiled it at I/O last month. The updated AI model produces video and audio from a simple text prompt with stunning fidelity. In some cases, the results are so good that they could be passed off as a real, non-AI video, which is a bit scary.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="720" id="video-2101723-1" preload="metadata" width="1280"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/A_1980s_fitness_202505221451.mp4?_=1" type="video/mp4" /&gt;Veo 3 can produce surreal scenes that look incredibly realistic.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Veo 3 can produce surreal scenes that look incredibly realistic.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;While you can add Veo 3 videos (or any video) to a YouTube Short right now, they don't fit with the format's portrait orientation focus. Veo 3 outputs 720p landscape videos, meaning you'd have black bars in a Short. Presumably, Google will create a custom version of the model for YouTube to spit out vertical video clips.&lt;/p&gt;
&lt;p&gt;Mohan didn't mention a pricing model, but Veo 3 probably won't be cheap for Shorts creators. Currently, you must pay for Google's $250 AI Ultra plan to access Veo 3, and that still limits you to 125 8-second videos per month.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Shorts and Veo 3 could be a match made in heaven... or the other place.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-640x427.jpg" width="640" /&gt;
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-1152x648-1734018446.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Even in the age of TikTok, YouTube viewership continues to climb. While Google's iconic video streaming platform has traditionally pushed creators to produce longer videos that can accommodate more ads, the site's Shorts format is growing fast. That growth may explode in the coming months, as YouTube CEO Neal Mohan has announced that the Google Veo 3 AI video generator will be integrated with YouTube Shorts later this summer.&lt;/p&gt;
&lt;p&gt;According to Mohan, YouTube Shorts has seen a rise in popularity even compared to YouTube as a whole. The streaming platform is now the most watched source of video in the world, but Shorts specifically have seen a massive 186 percent increase in viewership over the past year. Mohan says Shorts now average 200 billion daily views.&lt;/p&gt;
&lt;p&gt;YouTube has already equipped creators with a few AI tools, including Dream Screen, which can produce AI video backgrounds with a text prompt. Veo 3 support will be a significant upgrade, though. At the Cannes festival, Mohan revealed that the streaming site will begin offering integration with Google's leading video model later this summer. "I believe these tools will open new creative lanes for everyone to explore," said Mohan.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2101731 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube Shorts recommendations." class="fullwidth full" height="470" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YT-Shorts.png" width="632" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      YouTube heavily promotes Shorts on the homepage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This move will require a few tweaks to Veo 3 outputs, but it seems like a perfect match. As the name implies, YouTube Shorts is intended for short video content. The format initially launched with a 30-second ceiling, but that has since been increased to 60 seconds. Because of the astronomical cost of generative AI, each generated Veo clip is quite short, a mere eight seconds in the current version of the tool. Slap a few of those together, and you've got a YouTube Short.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It has been impossible to avoid Veo 3 around the web ever since Google unveiled it at I/O last month. The updated AI model produces video and audio from a simple text prompt with stunning fidelity. In some cases, the results are so good that they could be passed off as a real, non-AI video, which is a bit scary.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="720" id="video-2101723-1" preload="metadata" width="1280"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/A_1980s_fitness_202505221451.mp4?_=1" type="video/mp4" /&gt;Veo 3 can produce surreal scenes that look incredibly realistic.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Veo 3 can produce surreal scenes that look incredibly realistic.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;While you can add Veo 3 videos (or any video) to a YouTube Short right now, they don't fit with the format's portrait orientation focus. Veo 3 outputs 720p landscape videos, meaning you'd have black bars in a Short. Presumably, Google will create a custom version of the model for YouTube to spit out vertical video clips.&lt;/p&gt;
&lt;p&gt;Mohan didn't mention a pricing model, but Veo 3 probably won't be cheap for Shorts creators. Currently, you must pay for Google's $250 AI Ultra plan to access Veo 3, and that still limits you to 125 8-second videos per month.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/06/googles-veo-3-ai-videos-will-come-to-youtube-shorts-this-summer/</guid><pubDate>Wed, 18 Jun 2025 16:17:45 +0000</pubDate></item><item><title>[NEW] The ‘OpenAI Files’ push for oversight in the race to AGI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/the-openai-files-push-for-oversight-in-the-race-to-agi/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188250304.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman has said humanity is only years away from developing artificial general intelligence that could automate most human labor. If that’s true, then humanity also deserves to understand and have a say in the people and mechanics behind such an incredible and destabilizing force.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the guiding purpose behind “The OpenAI Files,” an archival project from the Midas Project and the Tech Oversight Project, two nonprofit tech watchdog organizations. The Files are a “collection of documented concerns with governance practices, leadership integrity, and organizational culture at OpenAI.” Beyond raising awareness, the goal of the Files is to propose a path forward for OpenAI and other AI leaders that focuses on responsible governance, ethical leadership, and shared benefits.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The governance structures and leadership integrity guiding a project as important as this must reflect the magnitude and severity of the mission,” reads the website’s Vision for Change. “The companies leading the race to AGI must be held to, and must hold themselves to, exceptionally high standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the race to dominance in AI has resulted in raw scaling — a growth-at-all-costs mindset that has led companies like OpenAI to hoover up content without consent for training purposes and build massive data centers that are causing power outages and increasing electricity costs for local consumers. The rush to commercialize has also led companies to ship products before putting in necessary safeguards, as pressure from investors to turn a profit mounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That investor pressure has shifted OpenAI’s core structure. The OpenAI Files detail how, in its early nonprofit days, OpenAI had initially capped investor profits at a maximum of 100x so that any proceeds from achieving AGI would go to humanity. The company has since announced plans to remove that cap, admitting that it has made such changes to appease investors who made funding conditional on structural reforms.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files highlight issues like OpenAI’s rushed safety evaluation processes and “culture of recklessness,” as well as the potential conflicts of interest of OpenAI’s board members and Altman himself. They include a list of startups that might be in Altman’s own investment portfolio that also have overlapping businesses with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files also call into question Altman’s integrity, which has been a topic of speculation since senior employees tried to oust him in 2023 over “deceptive and chaotic behavior.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“I don’t think Sam is the guy who should have the finger on the button for AGI,” Ilya Sutskever, OpenAI’s former chief scientist, reportedly said at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The questions and solutions raised by the OpenAI Files remind us that enormous power rests in the hands of a few, with little transparency and limited oversight. The Files provide a glimpse into that black box and aim to shift the conversation from inevitability to accountability.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188250304.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman has said humanity is only years away from developing artificial general intelligence that could automate most human labor. If that’s true, then humanity also deserves to understand and have a say in the people and mechanics behind such an incredible and destabilizing force.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the guiding purpose behind “The OpenAI Files,” an archival project from the Midas Project and the Tech Oversight Project, two nonprofit tech watchdog organizations. The Files are a “collection of documented concerns with governance practices, leadership integrity, and organizational culture at OpenAI.” Beyond raising awareness, the goal of the Files is to propose a path forward for OpenAI and other AI leaders that focuses on responsible governance, ethical leadership, and shared benefits.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The governance structures and leadership integrity guiding a project as important as this must reflect the magnitude and severity of the mission,” reads the website’s Vision for Change. “The companies leading the race to AGI must be held to, and must hold themselves to, exceptionally high standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the race to dominance in AI has resulted in raw scaling — a growth-at-all-costs mindset that has led companies like OpenAI to hoover up content without consent for training purposes and build massive data centers that are causing power outages and increasing electricity costs for local consumers. The rush to commercialize has also led companies to ship products before putting in necessary safeguards, as pressure from investors to turn a profit mounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That investor pressure has shifted OpenAI’s core structure. The OpenAI Files detail how, in its early nonprofit days, OpenAI had initially capped investor profits at a maximum of 100x so that any proceeds from achieving AGI would go to humanity. The company has since announced plans to remove that cap, admitting that it has made such changes to appease investors who made funding conditional on structural reforms.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files highlight issues like OpenAI’s rushed safety evaluation processes and “culture of recklessness,” as well as the potential conflicts of interest of OpenAI’s board members and Altman himself. They include a list of startups that might be in Altman’s own investment portfolio that also have overlapping businesses with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files also call into question Altman’s integrity, which has been a topic of speculation since senior employees tried to oust him in 2023 over “deceptive and chaotic behavior.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“I don’t think Sam is the guy who should have the finger on the button for AGI,” Ilya Sutskever, OpenAI’s former chief scientist, reportedly said at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The questions and solutions raised by the OpenAI Files remind us that enormous power rests in the hands of a few, with little transparency and limited oversight. The Files provide a glimpse into that black box and aim to shift the conversation from inevitability to accountability.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/the-openai-files-push-for-oversight-in-the-race-to-agi/</guid><pubDate>Wed, 18 Jun 2025 16:19:50 +0000</pubDate></item><item><title>[NEW] OpenAI found features in AI models that correspond to different ‘personas’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/openai-found-features-in-ai-models-that-correspond-to-different-personas/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI researchers say they’ve discovered hidden features inside AI models that correspond to misaligned “personas,” according to new research published by the company on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By looking at an AI model’s internal representations — the numbers that dictate how an AI model responds, which often seem completely incoherent to humans — OpenAI researchers were able to find patterns that lit up when a model misbehaved. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The researchers found one such feature that corresponded to toxic behavior in an AI model’s responses —meaning the AI model would give misaligned responses, such as lying to users or making irresponsible suggestions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers discovered they were able to turn toxicity up or down by adjusting the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research gives the company a better understanding of the factors that can make AI models act unsafely, and thus, could help them develop safer AI models. OpenAI could potentially use the patterns they’ve found to better detect misalignment in production AI models, according to OpenAI interpretability researcher Dan Mossing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are hopeful that the tools we’ve learned — like this ability to reduce a complicated phenomenon to a simple mathematical operation — will help us understand model generalization in other places as well,” said Mossing in an interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI researchers know how to improve AI models, but confusingly, they don’t fully understand how AI models arrive at their answers — Anthropic’s Chris Olah often remarks that AI models are grown more than they are built. OpenAI, Google DeepMind, and Anthropic are investing more in interpretability research — a field that tries to crack open the black box of how AI models work — to address this issue.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;A recent study from Oxford AI research scientist&amp;nbsp;Owain Evans raised new questions about how AI models generalize. The research found that OpenAI’s models could be fine-tuned on insecure code and would then display malicious behaviors across a variety of domains, such as trying to trick a user into sharing their password. The phenomenon is known as emergent misalignment, and Evans’ study inspired OpenAI to explore this further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the process of studying emergent misalignment, OpenAI says it stumbled into features inside AI models that seem to play a large role in controlling behavior. Mossing says these patterns are reminiscent of internal brain activity in humans, in which certain neurons correlate to moods or behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Dan and team first presented this in a research meeting, I was like, ‘Wow, you guys found it,’” said Tejal Patwardhan, an OpenAI frontier evaluations researcher, in an interview with TechCrunch. “You found like, an internal neural activation that shows these personas and that you can actually steer to make the model more aligned.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some features OpenAI found correlate to sarcasm in AI model responses, whereas other features correlate to more toxic responses in which an AI model acts as a cartoonish, evil villain. OpenAI’s researchers say these features can change drastically during the fine-tuning process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, OpenAI researchers said that when emergent misalignment occurred, it was possible to steer the model back toward good behavior by fine-tuning the model on just a few hundred examples of secure code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research builds on the previous work Anthropic has done on interpretability and alignment. In 2024, Anthropic released research that tried to map the inner workings of AI models, trying to pin down and label various features that were responsible for different concepts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like OpenAI and Anthropic are making the case that there’s real value in understanding how AI models work, and not just making them better. However, there’s a long way to go to fully understand modern AI models.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI researchers say they’ve discovered hidden features inside AI models that correspond to misaligned “personas,” according to new research published by the company on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By looking at an AI model’s internal representations — the numbers that dictate how an AI model responds, which often seem completely incoherent to humans — OpenAI researchers were able to find patterns that lit up when a model misbehaved. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The researchers found one such feature that corresponded to toxic behavior in an AI model’s responses —meaning the AI model would give misaligned responses, such as lying to users or making irresponsible suggestions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers discovered they were able to turn toxicity up or down by adjusting the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research gives the company a better understanding of the factors that can make AI models act unsafely, and thus, could help them develop safer AI models. OpenAI could potentially use the patterns they’ve found to better detect misalignment in production AI models, according to OpenAI interpretability researcher Dan Mossing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are hopeful that the tools we’ve learned — like this ability to reduce a complicated phenomenon to a simple mathematical operation — will help us understand model generalization in other places as well,” said Mossing in an interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI researchers know how to improve AI models, but confusingly, they don’t fully understand how AI models arrive at their answers — Anthropic’s Chris Olah often remarks that AI models are grown more than they are built. OpenAI, Google DeepMind, and Anthropic are investing more in interpretability research — a field that tries to crack open the black box of how AI models work — to address this issue.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;A recent study from Oxford AI research scientist&amp;nbsp;Owain Evans raised new questions about how AI models generalize. The research found that OpenAI’s models could be fine-tuned on insecure code and would then display malicious behaviors across a variety of domains, such as trying to trick a user into sharing their password. The phenomenon is known as emergent misalignment, and Evans’ study inspired OpenAI to explore this further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the process of studying emergent misalignment, OpenAI says it stumbled into features inside AI models that seem to play a large role in controlling behavior. Mossing says these patterns are reminiscent of internal brain activity in humans, in which certain neurons correlate to moods or behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Dan and team first presented this in a research meeting, I was like, ‘Wow, you guys found it,’” said Tejal Patwardhan, an OpenAI frontier evaluations researcher, in an interview with TechCrunch. “You found like, an internal neural activation that shows these personas and that you can actually steer to make the model more aligned.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some features OpenAI found correlate to sarcasm in AI model responses, whereas other features correlate to more toxic responses in which an AI model acts as a cartoonish, evil villain. OpenAI’s researchers say these features can change drastically during the fine-tuning process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, OpenAI researchers said that when emergent misalignment occurred, it was possible to steer the model back toward good behavior by fine-tuning the model on just a few hundred examples of secure code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research builds on the previous work Anthropic has done on interpretability and alignment. In 2024, Anthropic released research that tried to map the inner workings of AI models, trying to pin down and label various features that were responsible for different concepts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like OpenAI and Anthropic are making the case that there’s real value in understanding how AI models work, and not just making them better. However, there’s a long way to go to fully understand modern AI models.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/openai-found-features-in-ai-models-that-correspond-to-different-personas/</guid><pubDate>Wed, 18 Jun 2025 17:10:58 +0000</pubDate></item><item><title>[NEW] xAI is facing a lawsuit for operating over 400 MW of gas turbines without permits (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/xai-is-facing-a-lawsuit-for-operating-over-400-mw-of-gas-turbines-without-permits/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Colossus data center operated by xAI outside of Memphis is facing a lawsuit for operating a fleet of natural gas turbines without permits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the past year, xAI has installed and operated at least 35 combustion turbines and other sources of air pollution at the Colossus site without ever obtaining the necessary preconstruction or operating air permits,” the Southern Environmental Law Center (SELC) wrote in a letter to xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The legal group submitted the letter on behalf of the NAACP. It serves as a notice for intent to sue xAI for violations of the Clean Air Act. The law requires organizations to submit such a letter 60 days in advance of filing a lawsuit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The gas turbines have the potential to emit more than 2,000 tons of NO&lt;sub&gt;x&lt;/sub&gt; per year, a group of chemicals that contribute to smog.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memphis already “had some of the worst air quality in the region,” SELC notes. “In 2024, Memphis was deemed an asthma capital of the nation by the Asthma and Allergy Foundation of America due to high rates of emergency room visits and deaths from asthma.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SELC alleges that xAI failed to obtain permits required by both the federal and local regulators before installing the generators. It also alleges that the company wasn’t operating them with proper air pollution controls. At one point, xAI had enough turbines to generate 421 megawatts of electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, the Shelby County Health Department, which oversees local air pollution compliance, “told reporters that xAI’s turbines were exempt from permitting, although SCHD still had not disclosed publicly what xAI was operating on its site nor the legal basis for any such exemption,” SELC said.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To determine what was happening at the Colossus site, SELC paid an aerial photographer to capture images of the facility in March. The photos revealed that xAI had installed 35 turbines around the perimeter of the data center at the time. Thermal images taken about a month later showed that at least 33 of them were operational, SELC said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After those images were taken, the Greater Memphis Chamber, a local economic development agency, said that xAI had removed some of the turbines. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The temporary natural gas turbines that were being used to power the Phase I GPUs prior to grid connection are now being demobilized and will be removed from the site over the next two months,” the Memphis Chamber said. “About half of the operating turbines will remain” until a second substation completes the data centers connection to the grid, the organization added, and that once the substation was complete, the turbines would serve as backups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a flight on June 15 showed that at least 26 turbines remained, including three new ones that had been installed since the April flight. The total generating capacity was around 407 megawatts, just 14 megawatts shy of the previous amount.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With very few exceptions — none of which apply here — new sources of criteria and other air pollutants in Tennessee must obtain preconstruction approval in the form of an air permit as well as a permit to operate and emit pollutants,” SELC said.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Colossus data center operated by xAI outside of Memphis is facing a lawsuit for operating a fleet of natural gas turbines without permits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the past year, xAI has installed and operated at least 35 combustion turbines and other sources of air pollution at the Colossus site without ever obtaining the necessary preconstruction or operating air permits,” the Southern Environmental Law Center (SELC) wrote in a letter to xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The legal group submitted the letter on behalf of the NAACP. It serves as a notice for intent to sue xAI for violations of the Clean Air Act. The law requires organizations to submit such a letter 60 days in advance of filing a lawsuit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The gas turbines have the potential to emit more than 2,000 tons of NO&lt;sub&gt;x&lt;/sub&gt; per year, a group of chemicals that contribute to smog.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memphis already “had some of the worst air quality in the region,” SELC notes. “In 2024, Memphis was deemed an asthma capital of the nation by the Asthma and Allergy Foundation of America due to high rates of emergency room visits and deaths from asthma.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SELC alleges that xAI failed to obtain permits required by both the federal and local regulators before installing the generators. It also alleges that the company wasn’t operating them with proper air pollution controls. At one point, xAI had enough turbines to generate 421 megawatts of electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, the Shelby County Health Department, which oversees local air pollution compliance, “told reporters that xAI’s turbines were exempt from permitting, although SCHD still had not disclosed publicly what xAI was operating on its site nor the legal basis for any such exemption,” SELC said.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To determine what was happening at the Colossus site, SELC paid an aerial photographer to capture images of the facility in March. The photos revealed that xAI had installed 35 turbines around the perimeter of the data center at the time. Thermal images taken about a month later showed that at least 33 of them were operational, SELC said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After those images were taken, the Greater Memphis Chamber, a local economic development agency, said that xAI had removed some of the turbines. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The temporary natural gas turbines that were being used to power the Phase I GPUs prior to grid connection are now being demobilized and will be removed from the site over the next two months,” the Memphis Chamber said. “About half of the operating turbines will remain” until a second substation completes the data centers connection to the grid, the organization added, and that once the substation was complete, the turbines would serve as backups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a flight on June 15 showed that at least 26 turbines remained, including three new ones that had been installed since the April flight. The total generating capacity was around 407 megawatts, just 14 megawatts shy of the previous amount.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With very few exceptions — none of which apply here — new sources of criteria and other air pollutants in Tennessee must obtain preconstruction approval in the form of an air permit as well as a permit to operate and emit pollutants,” SELC said.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/xai-is-facing-a-lawsuit-for-operating-over-400-mw-of-gas-turbines-without-permits/</guid><pubDate>Wed, 18 Jun 2025 17:24:12 +0000</pubDate></item><item><title>[NEW] OpenAI drops Scale AI as a data provider following Meta deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/openai-drops-scale-ai-as-a-data-provider-following-meta-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is phasing out its work with Scale AI and cutting ties with the data provider following Meta’s deal with the startup, an OpenAI spokesperson told Bloomberg on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Friar, the chief financial officer of OpenAI, previously suggested the company would continue its work with Scale AI. Now, it appears OpenAI has changed its tone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI said it was already winding down its work with Scale AI ahead of Meta’s announcement last week that it was investing billions of dollars in the startup and bringing on CEO Alexandr Wang. An OpenAI spokesperson told Bloomberg that OpenAI had been seeking other providers for more specialized data to develop increasingly advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s decision to cut ties raises questions about Scale AI’s core data labelling business. Last week, Reuters reported that Google was discussing plans to drop Scale AI as a data provider as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As rumors swirled about Meta’s deal with Wang, some of Scale AI’s competitors said they received an influx of interest from AI model providers looking for “neutral” partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post published Wednesday, Scale AI’s general counsel tried to squash the idea that Meta would receive preferential treatment following this deal. Scale AI’s executives said it would not share confidential information from other customers with Meta, and that Wang would not be involved in day-to-day operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those claims, it seems that Scale AI’s biggest customers are already pivoting away from the data provider — meaning the startup may have no choice but to change up its business.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In a separate blog post published on Wednesday, Scale AI’s interim CEO Jason Droege said the company would “double down” on its applications business, which involves building custom AI applications for governments and enterprises.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is phasing out its work with Scale AI and cutting ties with the data provider following Meta’s deal with the startup, an OpenAI spokesperson told Bloomberg on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Friar, the chief financial officer of OpenAI, previously suggested the company would continue its work with Scale AI. Now, it appears OpenAI has changed its tone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI said it was already winding down its work with Scale AI ahead of Meta’s announcement last week that it was investing billions of dollars in the startup and bringing on CEO Alexandr Wang. An OpenAI spokesperson told Bloomberg that OpenAI had been seeking other providers for more specialized data to develop increasingly advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s decision to cut ties raises questions about Scale AI’s core data labelling business. Last week, Reuters reported that Google was discussing plans to drop Scale AI as a data provider as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As rumors swirled about Meta’s deal with Wang, some of Scale AI’s competitors said they received an influx of interest from AI model providers looking for “neutral” partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post published Wednesday, Scale AI’s general counsel tried to squash the idea that Meta would receive preferential treatment following this deal. Scale AI’s executives said it would not share confidential information from other customers with Meta, and that Wang would not be involved in day-to-day operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those claims, it seems that Scale AI’s biggest customers are already pivoting away from the data provider — meaning the startup may have no choice but to change up its business.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In a separate blog post published on Wednesday, Scale AI’s interim CEO Jason Droege said the company would “double down” on its applications business, which involves building custom AI applications for governments and enterprises.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/openai-drops-scale-ai-as-a-data-provider-following-meta-deal/</guid><pubDate>Wed, 18 Jun 2025 18:16:21 +0000</pubDate></item></channel></rss>