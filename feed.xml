<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 24 Jun 2025 06:33:32 +0000</lastBuildDate><item><title>Ted Cruz can’t get all Republicans to back his fight against state AI laws (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/ted-cruz-cant-get-all-republicans-to-back-his-fight-against-state-ai-laws/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cruz plan moves ahead but was reportedly watered down amid Republican opposition.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Sen. Ted Cruz holds up a hand and speaks while presiding over a Senate subcommittee hearing." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ted-cruz-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Sen. Ted Cruz holds up a hand and speaks while presiding over a Senate subcommittee hearing." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ted-cruz-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sen. Ted Cruz (R-Texas) presides over a subcommittee hearing on June 3, 2025 in Washington, DC. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Chip Somodevilla

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A Republican proposal to penalize states that regulate artificial intelligence can move forward without requiring approval from 60 senators, the Senate parliamentarian decided on Saturday. But the moratorium on state AI laws did not have unanimous Republican support and has reportedly been watered down in an effort to push it toward passage.&lt;/p&gt;
&lt;p&gt;In early June, Sen. Ted Cruz (R-Texas) proposed enforcing a 10-year moratorium on AI regulation by making states ineligible for broadband funding if they try to impose any limits on development of artificial intelligence. While the House previously approved a version of the so-called "One Big Beautiful Bill" with an outright 10-year ban on state AI regulation, Cruz took a different approach because of the Senate rule that limits inclusion of "extraneous matter" in budget reconciliation legislation.&lt;/p&gt;
&lt;p&gt;Under the Senate's Byrd rule, a senator can object to a potentially extraneous budget provision. A motion to waive the Byrd rule requires a vote of 60 percent of the Senate.&lt;/p&gt;
&lt;p&gt;As originally drafted, Cruz's backdoor ban on state AI laws would have made it impossible for states to receive money from the $42 billion Broadband Equity, Access, and Deployment (BEAD) program if they try to regulate AI. He tied the provision into the budget bill by proposing an extra $500 million for the broadband-deployment grant program and expanding its purpose to also subsidize construction and deployment of infrastructure for artificial intelligence systems.&lt;/p&gt;
&lt;p&gt;Punchbowl News reported today that Cruz made changes in order to gain more Republican support and comply with Senate procedural rules. Cruz was quoted as saying that under his current version, states that regulate AI would only be shut out of the $500 million AI fund.&lt;/p&gt;
&lt;p&gt;This would seem to protect states' access to the $42 billion broadband deployment fund that will offer subsidies to ISPs that expand access to Internet service. Losing that funding would be a major blow to states that have spent the last couple of years developing plans to connect more of their residents to modern broadband. The latest Senate bill text was not available today. We contacted Cruz's office and will update this article if we get a response.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A spokesperson for Sen. Maria Cantwell (D-Wash.) told Ars today that Cruz's latest version could still prevent states from getting broadband funding. The text has "a backdoor to apply new AI requirements to the entire $42.45 billion program, not just the new $500 million," Cantwell's representative said.&lt;/p&gt;
&lt;h2&gt;Plan has opponents from both parties&lt;/h2&gt;
&lt;p&gt;Senate Parliamentarian Elizabeth MacDonough ruled that several parts of the Republican budget bill are subject to the Byrd rule and its 60-vote requirement, but Cruz's AI proposal wasn't one of them. A press release from Senate Budget Committee Ranking Member Jeff Merkley (D-Ore.) noted that "the parliamentarian's advice is based on whether a provision is appropriate for reconciliation and conforms to the limitations of the Byrd rule; it is not a judgement on the relative merits of a particular policy."&lt;/p&gt;
&lt;p&gt;Surviving the parliamentarian review doesn't guarantee passage. A Bloomberg article said the parliamentarian's decision is "a win for tech companies pushing to stall and override dozens of AI safety laws across the country," but that the "provision will likely still be challenged on the Senate floor, where stripping the provision would need just a simple majority. Some Republicans in both the House and Senate have pushed back on the AI provision."&lt;/p&gt;
&lt;p&gt;Republicans have a 53–47 edge in the Senate. Cantwell and Sen. Marsha Blackburn (R-Tenn.) teamed up for a press conference last week in which they spoke out against the proposed moratorium on state regulation.&lt;/p&gt;
&lt;p&gt;Cantwell said that 24 states last year started "regulating AI in some way, and they have adopted these laws that fill a gap while we are waiting for federal action. Now Congress is threatening these laws, which will leave hundreds of millions of Americans vulnerable to AI harm by abolishing those state law protections."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Blackburn said she agreed with Cantwell that the AI regulation proposal "is not the type of thing that we put into reconciliation bills." Blackburn added that lawmakers "are working to move forward with legislation at the federal level, but we do not need a moratorium that would prohibit our states from stepping up and protecting citizens in their state."&lt;/p&gt;
&lt;p&gt;Sens. Ron Johnson (R-Wis.) and Josh Hawley (R-Mo.) have also criticized the idea of stopping states from regulating AI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Cruz accused states of “strangling AI”&lt;/h2&gt;
&lt;p&gt;Cruz argued that his proposal stops states "from strangling AI deployment with EU-style regulation." Under his first proposal, no BEAD funds were to be given to any state or territory that enforces "any law or regulation... limiting, restricting, or otherwise regulating artificial intelligence models, artificial intelligence systems, or automated decision systems entered into interstate commerce."&lt;/p&gt;
&lt;p&gt;The Cantwell/Blackburn press conference also included Washington Attorney General Nick Brown, a Democrat; and Tennessee Attorney General Jonathan Skrmetti, a Republican. Brown said that "Washington has a law that prohibits deep fakes being used against political candidates by mimicking their appearance and their speech," another "that prohibits sharing fabricated sexual images without consent and provides for penalties for those who possess and distribute such images," and a third "that prohibits the knowing distribution of forged digital likenesses that can be used to harm or defraud people."&lt;/p&gt;
&lt;p&gt;"All of those laws, in my reading, would be invalid if this was to pass through Congress, and each of those laws are prohibiting and protecting people here in our state," Brown said.&lt;/p&gt;
&lt;p&gt;Skrmetti said that if the Senate proposal becomes law "there would be arguments out there for the big tech companies that the moratorium does, in fact, preclude any enforcement of any consumer protection laws if there's an AI component to the product that we're looking at."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Other Republican plans fail Byrd rule test&lt;/h2&gt;
&lt;p&gt;Senate Democrats said they are pleased that the parliamentarian ruled that several other parts of the bill are subject to the Byrd rule. "We continue to see Republicans' blatant disregard for the rules of reconciliation when drafting this bill... Democrats plan to challenge every part of this bill that hurts working families and violates this process," Merkley said.&lt;/p&gt;
&lt;p&gt;Merkley's press release said the provisions that are subject to a 60-vote threshold include one that "limits certain grant funding for 'sanctuary cities,' and where the Attorney General disagrees with states' and localities' immigration enforcement," and another that "gives state and local officials the authority to arrest any noncitizen suspected of being in the US unlawfully."&lt;/p&gt;
&lt;p&gt;The Byrd rule also applies to a section that "limits the ability of federal courts to issue preliminary injunctions or temporary restraining orders against the federal government by requiring litigants to post a potentially enormous bond," and another that "limits when the federal government can enter into or enforce settlement agreements that provide for payments to third parties to fully compensate victims, remedy harm, and punish and deter future violations," Merkley's office said.&lt;/p&gt;
&lt;p&gt;The office of Senate Democratic Leader Chuck Schumer (D-N.Y.) said yesterday that the provision requiring litigants to post bonds has been struck from the legislation. "This Senate Republican provision, which was even worse than the similar House-passed version, required a plaintiff seeking an emergency court order, preliminary injunction, or a temporary restraining order against the Trump Administration or the federal government to pay a costly bond up front—essentially making the justice system pay-to-play," Schumer's office said.&lt;/p&gt;
&lt;p&gt;Schumer said that "if enacted, this would have been one of the most brazen power grabs we've seen in American history—an attempt to let a future President Trump ignore court orders with impunity, putting him above the law."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cruz plan moves ahead but was reportedly watered down amid Republican opposition.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Sen. Ted Cruz holds up a hand and speaks while presiding over a Senate subcommittee hearing." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ted-cruz-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Sen. Ted Cruz holds up a hand and speaks while presiding over a Senate subcommittee hearing." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ted-cruz-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sen. Ted Cruz (R-Texas) presides over a subcommittee hearing on June 3, 2025 in Washington, DC. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Chip Somodevilla

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A Republican proposal to penalize states that regulate artificial intelligence can move forward without requiring approval from 60 senators, the Senate parliamentarian decided on Saturday. But the moratorium on state AI laws did not have unanimous Republican support and has reportedly been watered down in an effort to push it toward passage.&lt;/p&gt;
&lt;p&gt;In early June, Sen. Ted Cruz (R-Texas) proposed enforcing a 10-year moratorium on AI regulation by making states ineligible for broadband funding if they try to impose any limits on development of artificial intelligence. While the House previously approved a version of the so-called "One Big Beautiful Bill" with an outright 10-year ban on state AI regulation, Cruz took a different approach because of the Senate rule that limits inclusion of "extraneous matter" in budget reconciliation legislation.&lt;/p&gt;
&lt;p&gt;Under the Senate's Byrd rule, a senator can object to a potentially extraneous budget provision. A motion to waive the Byrd rule requires a vote of 60 percent of the Senate.&lt;/p&gt;
&lt;p&gt;As originally drafted, Cruz's backdoor ban on state AI laws would have made it impossible for states to receive money from the $42 billion Broadband Equity, Access, and Deployment (BEAD) program if they try to regulate AI. He tied the provision into the budget bill by proposing an extra $500 million for the broadband-deployment grant program and expanding its purpose to also subsidize construction and deployment of infrastructure for artificial intelligence systems.&lt;/p&gt;
&lt;p&gt;Punchbowl News reported today that Cruz made changes in order to gain more Republican support and comply with Senate procedural rules. Cruz was quoted as saying that under his current version, states that regulate AI would only be shut out of the $500 million AI fund.&lt;/p&gt;
&lt;p&gt;This would seem to protect states' access to the $42 billion broadband deployment fund that will offer subsidies to ISPs that expand access to Internet service. Losing that funding would be a major blow to states that have spent the last couple of years developing plans to connect more of their residents to modern broadband. The latest Senate bill text was not available today. We contacted Cruz's office and will update this article if we get a response.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A spokesperson for Sen. Maria Cantwell (D-Wash.) told Ars today that Cruz's latest version could still prevent states from getting broadband funding. The text has "a backdoor to apply new AI requirements to the entire $42.45 billion program, not just the new $500 million," Cantwell's representative said.&lt;/p&gt;
&lt;h2&gt;Plan has opponents from both parties&lt;/h2&gt;
&lt;p&gt;Senate Parliamentarian Elizabeth MacDonough ruled that several parts of the Republican budget bill are subject to the Byrd rule and its 60-vote requirement, but Cruz's AI proposal wasn't one of them. A press release from Senate Budget Committee Ranking Member Jeff Merkley (D-Ore.) noted that "the parliamentarian's advice is based on whether a provision is appropriate for reconciliation and conforms to the limitations of the Byrd rule; it is not a judgement on the relative merits of a particular policy."&lt;/p&gt;
&lt;p&gt;Surviving the parliamentarian review doesn't guarantee passage. A Bloomberg article said the parliamentarian's decision is "a win for tech companies pushing to stall and override dozens of AI safety laws across the country," but that the "provision will likely still be challenged on the Senate floor, where stripping the provision would need just a simple majority. Some Republicans in both the House and Senate have pushed back on the AI provision."&lt;/p&gt;
&lt;p&gt;Republicans have a 53–47 edge in the Senate. Cantwell and Sen. Marsha Blackburn (R-Tenn.) teamed up for a press conference last week in which they spoke out against the proposed moratorium on state regulation.&lt;/p&gt;
&lt;p&gt;Cantwell said that 24 states last year started "regulating AI in some way, and they have adopted these laws that fill a gap while we are waiting for federal action. Now Congress is threatening these laws, which will leave hundreds of millions of Americans vulnerable to AI harm by abolishing those state law protections."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Blackburn said she agreed with Cantwell that the AI regulation proposal "is not the type of thing that we put into reconciliation bills." Blackburn added that lawmakers "are working to move forward with legislation at the federal level, but we do not need a moratorium that would prohibit our states from stepping up and protecting citizens in their state."&lt;/p&gt;
&lt;p&gt;Sens. Ron Johnson (R-Wis.) and Josh Hawley (R-Mo.) have also criticized the idea of stopping states from regulating AI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Cruz accused states of “strangling AI”&lt;/h2&gt;
&lt;p&gt;Cruz argued that his proposal stops states "from strangling AI deployment with EU-style regulation." Under his first proposal, no BEAD funds were to be given to any state or territory that enforces "any law or regulation... limiting, restricting, or otherwise regulating artificial intelligence models, artificial intelligence systems, or automated decision systems entered into interstate commerce."&lt;/p&gt;
&lt;p&gt;The Cantwell/Blackburn press conference also included Washington Attorney General Nick Brown, a Democrat; and Tennessee Attorney General Jonathan Skrmetti, a Republican. Brown said that "Washington has a law that prohibits deep fakes being used against political candidates by mimicking their appearance and their speech," another "that prohibits sharing fabricated sexual images without consent and provides for penalties for those who possess and distribute such images," and a third "that prohibits the knowing distribution of forged digital likenesses that can be used to harm or defraud people."&lt;/p&gt;
&lt;p&gt;"All of those laws, in my reading, would be invalid if this was to pass through Congress, and each of those laws are prohibiting and protecting people here in our state," Brown said.&lt;/p&gt;
&lt;p&gt;Skrmetti said that if the Senate proposal becomes law "there would be arguments out there for the big tech companies that the moratorium does, in fact, preclude any enforcement of any consumer protection laws if there's an AI component to the product that we're looking at."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Other Republican plans fail Byrd rule test&lt;/h2&gt;
&lt;p&gt;Senate Democrats said they are pleased that the parliamentarian ruled that several other parts of the bill are subject to the Byrd rule. "We continue to see Republicans' blatant disregard for the rules of reconciliation when drafting this bill... Democrats plan to challenge every part of this bill that hurts working families and violates this process," Merkley said.&lt;/p&gt;
&lt;p&gt;Merkley's press release said the provisions that are subject to a 60-vote threshold include one that "limits certain grant funding for 'sanctuary cities,' and where the Attorney General disagrees with states' and localities' immigration enforcement," and another that "gives state and local officials the authority to arrest any noncitizen suspected of being in the US unlawfully."&lt;/p&gt;
&lt;p&gt;The Byrd rule also applies to a section that "limits the ability of federal courts to issue preliminary injunctions or temporary restraining orders against the federal government by requiring litigants to post a potentially enormous bond," and another that "limits when the federal government can enter into or enforce settlement agreements that provide for payments to third parties to fully compensate victims, remedy harm, and punish and deter future violations," Merkley's office said.&lt;/p&gt;
&lt;p&gt;The office of Senate Democratic Leader Chuck Schumer (D-N.Y.) said yesterday that the provision requiring litigants to post bonds has been struck from the legislation. "This Senate Republican provision, which was even worse than the similar House-passed version, required a plaintiff seeking an emergency court order, preliminary injunction, or a temporary restraining order against the Trump Administration or the federal government to pay a costly bond up front—essentially making the justice system pay-to-play," Schumer's office said.&lt;/p&gt;
&lt;p&gt;Schumer said that "if enacted, this would have been one of the most brazen power grabs we've seen in American history—an attempt to let a future President Trump ignore court orders with impunity, putting him above the law."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/ted-cruz-cant-get-all-republicans-to-back-his-fight-against-state-ai-laws/</guid><pubDate>Mon, 23 Jun 2025 20:02:12 +0000</pubDate></item><item><title>Unlocking rich genetic insights through multimodal AI with M-REGLE (The latest research from Google)</title><link>https://research.google/blog/unlocking-rich-genetic-insights-through-multimodal-ai-with-m-regle/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Everything from medical specialists with cutting-edge technology to simple smartwatches are generating data on an unprecedented scale. The aggregation of electronic health records, medical imaging, diagnostic tests, genomic data, and even real-time measurements from smartwatches creates a wealth of data for researchers and clinicians to analyze. These diverse data streams often carry unique and overlapping signals, even within the same organ system.&lt;/p&gt;&lt;p&gt;In the cardiovascular system, for example, an electrocardiogram (ECG) measures the heart's electrical activity, while a photoplethysmogram (PPG) — common in smartwatches — tracks blood volume changes. The co-analysis of these modalities can simultaneously assess both the heart’s electrical system and its pumping efficiency, thus providing a more complete picture of heart health. Integrating these physiological signatures with genetic information from large nation-level biobanks could enable the identification of the genetic underpinnings of disease.&lt;/p&gt;&lt;p&gt;Our earlier work, REGLE, was successful for genetic discovery using health data, but it was designed for a single data type (i.e., the unimodal setting). Alternatively, analyzing each modality separately and then trying to piece together the findings later (what we refer to as U-REGLE or Unimodal REGLE) also might not be the most efficient way. U-REGLE could miss subtle shared information between different modalities. Instead, we hypothesized that &lt;i&gt;jointly&lt;/i&gt; modeling these complementary data streams would boost the important biological signals, reduce noise, and lead to more powerful genetic discoveries.&lt;/p&gt;&lt;p&gt;Here we present our recent paper, “Utilizing multimodal AI to improve genetic analyses of cardiovascular traits”, which we published in the &lt;i&gt;American Journal of Human Genetics&lt;/i&gt;. We developed a multimodal version of REGLE, called M-REGLE, that allows the analysis of multiple types of clinical data together at once. M-REGLE produces lower reconstruction error, identifies more genetic associations, and outperforms risk scores in predicting cardiac disease compared to its predecessor, U-REGLE.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Everything from medical specialists with cutting-edge technology to simple smartwatches are generating data on an unprecedented scale. The aggregation of electronic health records, medical imaging, diagnostic tests, genomic data, and even real-time measurements from smartwatches creates a wealth of data for researchers and clinicians to analyze. These diverse data streams often carry unique and overlapping signals, even within the same organ system.&lt;/p&gt;&lt;p&gt;In the cardiovascular system, for example, an electrocardiogram (ECG) measures the heart's electrical activity, while a photoplethysmogram (PPG) — common in smartwatches — tracks blood volume changes. The co-analysis of these modalities can simultaneously assess both the heart’s electrical system and its pumping efficiency, thus providing a more complete picture of heart health. Integrating these physiological signatures with genetic information from large nation-level biobanks could enable the identification of the genetic underpinnings of disease.&lt;/p&gt;&lt;p&gt;Our earlier work, REGLE, was successful for genetic discovery using health data, but it was designed for a single data type (i.e., the unimodal setting). Alternatively, analyzing each modality separately and then trying to piece together the findings later (what we refer to as U-REGLE or Unimodal REGLE) also might not be the most efficient way. U-REGLE could miss subtle shared information between different modalities. Instead, we hypothesized that &lt;i&gt;jointly&lt;/i&gt; modeling these complementary data streams would boost the important biological signals, reduce noise, and lead to more powerful genetic discoveries.&lt;/p&gt;&lt;p&gt;Here we present our recent paper, “Utilizing multimodal AI to improve genetic analyses of cardiovascular traits”, which we published in the &lt;i&gt;American Journal of Human Genetics&lt;/i&gt;. We developed a multimodal version of REGLE, called M-REGLE, that allows the analysis of multiple types of clinical data together at once. M-REGLE produces lower reconstruction error, identifies more genetic associations, and outperforms risk scores in predicting cardiac disease compared to its predecessor, U-REGLE.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/unlocking-rich-genetic-insights-through-multimodal-ai-with-m-regle/</guid><pubDate>Mon, 23 Jun 2025 20:30:00 +0000</pubDate></item><item><title>Databricks, Perplexity co-founder pledges $100M on new fund for AI researchers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/23/databricks-perplexity-co-founder-pledges-100m-on-new-fund-for-ai-researchers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1211462615.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Andy Konwinski, computer scientist and co-founder of Databricks and Perplexity, announced Monday that his company, Laude, is forming a new AI research institute backed with $100 million of his own money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Laude Institute functions less as an AI research lab and more like a fund looking to make investments structured similar to grants. In addition to Konwinski, the institute’s board includes UC Berkeley professor Dave Patterson (known for a string of award-winning research), Jeff Dean (known as Google’s chief scientist), and Joelle Pineau (Meta’s vice president of AI Research).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Konwinski announced the institute’s first and “flagship” grant of $3 million annually for five years, which will anchor the new AI Systems Lab at UC Berkeley. This is a new lab led by one of Berkeley’s most celebrated researchers, Ion Stoica, current director of the Sky Computing Lab. Stoica is also a co-founder of startup Anyscale (an AI and Python platform) and AI big data company Databricks, both built from tech developed in Berkeley’s lab system.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI Systems Lab is set to open in 2027 and in addition to Stoica will include a number of other well-known researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In his blog post announcing the institute, Konwinski described its mission as ”built by and for computer science researchers&amp;nbsp;… We exist to catalyze work that doesn’t just push the field forward but guides it towards more beneficial outcomes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s not necessarily a direct dig at OpenAI, which started out as an AI research facility and is now, arguably, consumed by its enormous commercial side. But other researchers have fallen prey to the lure of money as well.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, popular AI researcher Epoch faced controversy when it revealed that OpenAI supported the creation of one of its AI benchmarks that was then used&amp;nbsp;to unveil its new o3 model. Epoch’s founder also launched a startup with the controversial mission to replace all human workers everywhere with AI agents.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Like other AI research organizations with commercial ambitions, Konwinski has structured his institute across boundaries: as a nonprofit with a public benefit corporation operating arm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’s dividing his research investments into two buckets that he calls “Slingshots and Moonshots.” Slingshots are for early-stage research that can benefit from grants and hands-on help. Moonshots are, as the name implies, for “long-horizon labs tackling species-level challenges like AI for scientific discovery, civic discourse, healthcare, and workforce re-skilling.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His lab has, for instance, collaborated with “terminal-bench,” a Stanford-led benchmark for how well AI agents handle tasks, used by Anthropic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One thing to note, Konwinski’s endeavors under the name “Laude” aren’t solely a grant-writing research institute. He also co-founded a for-profit venture fund launched in 2024. The fund’s co-founder is former NEA VC Pete Sonsini, and a Laude spokesperson tells us it has more than 50 leading researchers as LPs in the fund. As TechCrunch previously reported, Laude led a $12 million investment in AI agent infrastructure startup Arcade. It has quietly backed other startups, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Laude spokesperson tells us that while Konwinski has pledged $100 million, he’s also looking for, and open to, investment from other successful technologists. As to how Konwinski amassed a fortune big enough to guarantee $100 million for this new endeavor: Databricks closed a $15.3 billion funding round in January that valued the company at $62 billion. Perplexity last month secured a $14 billion valuation, too.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Does the world really need yet more AI “good for humanity” research or another AI company with a murky nonprofit/commercial structure? No, and yes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI research has become increasingly muddled. For instance, AI benchmarks designed to prove that a particular vendor’s model works best have become plentiful these days. (Even Salesforce has its own LLM benchmark for CRMs.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An alliance that includes the likes of Konwinski, Dean, and Stoica supporting truly independent research that could one day turn into independent and human-helpful commerce could be an attractive alternative.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Note: This story was updated to reflect more details shared about the Laude VC fund.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1211462615.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Andy Konwinski, computer scientist and co-founder of Databricks and Perplexity, announced Monday that his company, Laude, is forming a new AI research institute backed with $100 million of his own money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Laude Institute functions less as an AI research lab and more like a fund looking to make investments structured similar to grants. In addition to Konwinski, the institute’s board includes UC Berkeley professor Dave Patterson (known for a string of award-winning research), Jeff Dean (known as Google’s chief scientist), and Joelle Pineau (Meta’s vice president of AI Research).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Konwinski announced the institute’s first and “flagship” grant of $3 million annually for five years, which will anchor the new AI Systems Lab at UC Berkeley. This is a new lab led by one of Berkeley’s most celebrated researchers, Ion Stoica, current director of the Sky Computing Lab. Stoica is also a co-founder of startup Anyscale (an AI and Python platform) and AI big data company Databricks, both built from tech developed in Berkeley’s lab system.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI Systems Lab is set to open in 2027 and in addition to Stoica will include a number of other well-known researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In his blog post announcing the institute, Konwinski described its mission as ”built by and for computer science researchers&amp;nbsp;… We exist to catalyze work that doesn’t just push the field forward but guides it towards more beneficial outcomes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s not necessarily a direct dig at OpenAI, which started out as an AI research facility and is now, arguably, consumed by its enormous commercial side. But other researchers have fallen prey to the lure of money as well.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, popular AI researcher Epoch faced controversy when it revealed that OpenAI supported the creation of one of its AI benchmarks that was then used&amp;nbsp;to unveil its new o3 model. Epoch’s founder also launched a startup with the controversial mission to replace all human workers everywhere with AI agents.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Like other AI research organizations with commercial ambitions, Konwinski has structured his institute across boundaries: as a nonprofit with a public benefit corporation operating arm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’s dividing his research investments into two buckets that he calls “Slingshots and Moonshots.” Slingshots are for early-stage research that can benefit from grants and hands-on help. Moonshots are, as the name implies, for “long-horizon labs tackling species-level challenges like AI for scientific discovery, civic discourse, healthcare, and workforce re-skilling.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His lab has, for instance, collaborated with “terminal-bench,” a Stanford-led benchmark for how well AI agents handle tasks, used by Anthropic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One thing to note, Konwinski’s endeavors under the name “Laude” aren’t solely a grant-writing research institute. He also co-founded a for-profit venture fund launched in 2024. The fund’s co-founder is former NEA VC Pete Sonsini, and a Laude spokesperson tells us it has more than 50 leading researchers as LPs in the fund. As TechCrunch previously reported, Laude led a $12 million investment in AI agent infrastructure startup Arcade. It has quietly backed other startups, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Laude spokesperson tells us that while Konwinski has pledged $100 million, he’s also looking for, and open to, investment from other successful technologists. As to how Konwinski amassed a fortune big enough to guarantee $100 million for this new endeavor: Databricks closed a $15.3 billion funding round in January that valued the company at $62 billion. Perplexity last month secured a $14 billion valuation, too.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Does the world really need yet more AI “good for humanity” research or another AI company with a murky nonprofit/commercial structure? No, and yes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI research has become increasingly muddled. For instance, AI benchmarks designed to prove that a particular vendor’s model works best have become plentiful these days. (Even Salesforce has its own LLM benchmark for CRMs.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An alliance that includes the likes of Konwinski, Dean, and Stoica supporting truly independent research that could one day turn into independent and human-helpful commerce could be an attractive alternative.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Note: This story was updated to reflect more details shared about the Laude VC fund.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/23/databricks-perplexity-co-founder-pledges-100m-on-new-fund-for-ai-researchers/</guid><pubDate>Mon, 23 Jun 2025 20:30:03 +0000</pubDate></item><item><title>Salesforce launches Agentforce 3 with AI agent observability and MCP support (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/salesforce-launches-agentforce-3-with-ai-agent-observability-and-mcp-support/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Salesforce rolled out sweeping enhancements to its AI agent platform Monday, addressing the biggest hurdles enterprises face when deploying digital workers at scale: Knowing what those agents are actually doing and ensuring they can work securely across corporate systems.&lt;/p&gt;



&lt;p&gt;The company’s Agentforce 3 release introduces a comprehensive “Command Center” that gives executives real-time visibility into AI agent performance, plus native support for emerging interoperability standards that allow agents to connect with hundreds of external business tools without the need for custom coding.&lt;/p&gt;



&lt;p&gt;The timing reflects surging enterprise demand for AI agents. According to Salesforce data, AI agent usage has jumped 233% in six months, with more than 8,000 customers signing up to deploy the technology. Early adopters are seeing measurable returns: Engine reduced customer case handling time by 15%, while 1-800Accountant achieved 70% autonomous resolution of administrative chat requests during peak tax season.&lt;/p&gt;



&lt;p&gt;“We have hundreds of live implementations, if not thousands, and they’re running at scale,” Jayesh Govindarajan, EVP of Salesforce AI, said in an exclusive interview with VentureBeat. The company has moved decisively beyond experimental deployments, he noted: “AI agents are no longer experimental. They have really moved deeply into the fabric of the enterprise.”&lt;/p&gt;



&lt;p&gt;Adam Evans, EVP and GM of Salesforce AI, said in a live event on Monday announcing the platform upgrade: “Over the past several months we’ve listened deeply to our customers and continued our rapid pace of technology innovation. The result is Agentforce 3, a major leap forward for our platform that brings greater intelligence, higher performance and more trust and accountability to every Agentforce deployment.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-global-food-giant-pepsico-is-leading-the-enterprise-ai-agent-revolution"&gt;How global food giant PepsiCo is leading the enterprise AI agent revolution&lt;/h2&gt;



&lt;p&gt;Among the companies embracing this technology is PepsiCo, which is deploying Agentforce as part of a broader AI-driven transformation of its global operations. In an exclusive interview with VentureBeat, Athina Kanioura, PepsiCo’s chief strategy and transformation officer, described the deployment as crucial to the company’s evolution in an increasingly complex marketplace.&lt;/p&gt;



&lt;p&gt;“As a longtime partner of Salesforce, we recognized an opportunity to holistically integrate the way we utilize their platforms across our business — especially as the customer landscape evolves, trade becomes more complex and the need to better integrate our data increases,” Kanioura told VentureBeat.&lt;/p&gt;



&lt;p&gt;The food and beverage giant, whose products are consumed over a billion times daily worldwide, sees AI agents as essential for meeting customers “where they are — and in the ways they want to engage with us,” while driving backend efficiency by integrating systems and simplifying processes.&lt;/p&gt;



&lt;p&gt;PepsiCo’s seven-year relationship with Salesforce has positioned the company to move quickly on AI agents. “We were excited about how Agentforce could enhance the day-to-day experience for our field sellers – streamlining workflows and surfacing smarter insights in real time,” Kanioura explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-missing-piece-why-enterprise-ai-needs-real-time-monitoring-and-control"&gt;The missing piece: Why enterprise AI needs real-time monitoring and control&lt;/h2&gt;



&lt;p&gt;The Command Center represents Salesforce’s response to a critical gap in the enterprise AI market. While companies have rushed to deploy AI agents for customer service, sales and operational tasks, many lack visibility into how those digital workers are performing or impacting business outcomes.&lt;/p&gt;



&lt;p&gt;Govindarajan described the challenge facing enterprises that have moved beyond pilot programs: “It’s one thing to build an AI agent demo, but when you actually build an agentic system and put it in front of your users, there’s a different standard.” Companies need tools to understand when AI agents are struggling and when to bring humans into the workflow, he explained.&lt;/p&gt;



&lt;p&gt;“Teams can’t see what agents are doing — or evolve them fast enough,” the company acknowledged in its announcement. The new observability platform provides detailed analytics on agent interactions, health monitoring with real-time alerts and AI-powered recommendations for optimization.&lt;/p&gt;



&lt;p&gt;The system addresses what Govindarajan calls “day two problems” – the operational challenges that emerge after initial deployment. “You can have multiple agents for multiple personas, and you need to be able to observe how that’s actually impacting the task that needs to get done at scale,” he said. This includes managing the handoffs between digital agents and human workers when complex decisions or approvals are required.&lt;/p&gt;



&lt;p&gt;The system captures all agent activity in Salesforce’s Data Cloud using the OpenTelemetry standard, enabling integration with existing monitoring tools like Datadog and other enterprise systems. This addresses enterprises’ need to incorporate AI agent oversight into their existing operational workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-standards-and-secure-integration-how-ai-agents-connect-across-enterprise-systems"&gt;Open standards and secure integration: How AI agents connect across enterprise systems&lt;/h2&gt;



&lt;p&gt;Perhaps more significant is Salesforce’s embrace of the Model Context Protocol (MCP), an emerging open standard for AI agent interoperability. The platform will include native MCP support, allowing Agentforce agents to connect with any MCP-compliant server without custom development work.&lt;/p&gt;



&lt;p&gt;“There’s generic interoperability, and then there’s what we call enterprise-grade interoperability,” Gary Lerhaupt, VP of product architecture at Salesforce, explained in an exclusive interview with VentureBeat. “If it’s not enterprise grade, it’s like sparkling untrusted interop.” The key difference, he said, lies in governance and control mechanisms that enterprise customers require.&lt;/p&gt;



&lt;p&gt;This capability, working alongside an expanded AgentExchange marketplace, gives enterprises access to pre-built integrations with over 30 partners including Amazon Web Services, Box, Google Cloud, IBM, PayPal and Stripe. Lerhaupt said the company is launching with “north of 20, maybe 25 plus” vetted MCP servers, with partners like PayPal offering invoicing capabilities and Box providing document access through their MCP implementations.&lt;/p&gt;



&lt;p&gt;“In a world full of AI tools, Agentforce stood out not just for its first-of-a-kind technology but how seamlessly it fit into our technology ecosystem, the way we work and our AI strategy, standards and framework,” Kanioura said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-boost-faster-ai-models-and-enhanced-security-for-regulated-industries"&gt;Performance boost: Faster AI models and enhanced security for regulated industries&lt;/h2&gt;



&lt;p&gt;Underlying the new features is what Salesforce calls an enhanced “Atlas” architecture designed for enterprise-grade performance and security. The platform now offers 50% lower latency compared to January 2025, as well as response streaming for real-time user experiences and automatic failover between AI model providers to ensure continuous operation.&lt;/p&gt;



&lt;p&gt;For regulated industries, Salesforce’s approach to hosting AI models directly within its infrastructure addresses critical security concerns. “With Anthropic, the entire stack will be running within Salesforce infrastructure,” Govindarajan explained. “The calls are not going out to OpenAI, and traffic will be running within the Salesforce VPC. For regulated industries, that’s what we’ve been working on.”&lt;/p&gt;



&lt;p&gt;Critically for regulated industries, Salesforce now hosts Anthropic’s Claude models directly within its infrastructure via Amazon Bedrock, keeping sensitive data within the Salesforce security perimeter. The company plans to add Google’s Gemini models later this year, giving enterprises more options for AI model governance.&lt;/p&gt;



&lt;p&gt;The platform also expands global availability to Canada, the UK, India, Japan and Brazil, with support for six additional languages including French, German, Spanish, Italian, Japanese and Portuguese.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-zero-to-ai-agent-how-pre-built-industry-actions-speed-enterprise-deployment"&gt;From zero to AI agent: How pre-built industry actions speed enterprise deployment&lt;/h2&gt;



&lt;p&gt;Recognizing that enterprises need faster returns on AI investments, Salesforce has built more than 200 pre-configured industry actions — with more than 100 added this summer alone. These range from patient scheduling in healthcare to advertising proposal generation in media, designed to help companies deploy functional AI agents quickly rather than building from scratch.&lt;/p&gt;



&lt;p&gt;The results demonstrate the platform’s maturity. Beyond 1-800Accountant’s 70% deflection rate during tax season, Govindarajan cited other production deployments: “OpenTable sees 73% of all restaurant web queries handled by agents,” and Grupo Falabella, a Colombian customer service operation using WhatsApp, achieved a 71% reduction in phone call traffic in just three weeks.&lt;/p&gt;



&lt;p&gt;The company also introduced more flexible pricing, including unlimited usage licenses for employee-facing agents and per-action pricing that scales with actual AI work performed rather than simple conversation volume.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-new-digital-workforce-what-enterprise-ai-adoption-means-for-business-operations"&gt;The new digital workforce: What enterprise AI adoption means for business operations&lt;/h2&gt;



&lt;p&gt;As enterprises increasingly view AI agents as digital employees rather than simple automation tools, the stakes for getting deployment right have never been higher. Companies that successfully scale AI agents stand to gain significant competitive advantages, while those that struggle with governance and oversight risk operational disruptions.&lt;/p&gt;



&lt;p&gt;Govindarajan sees fundamental changes in how work gets organized: “New roles are emerging for people who manage a fleet of agents,” he said. “A CIO might ask, ‘I have seven agents running in my enterprise, what’s broadly happening?’ But someone running a specific marketing agent has a different lens on the same problem.”&lt;/p&gt;



&lt;p&gt;Looking ahead, Lerhaupt positioned the current moment as transformational: “You had the personal computer, then the Internet and now it’s multi-agent,” he said. He described the evolution from single-agent deployments as “the multi-agent revolution and the ability to plug agents together to do exceedingly complex new types of work.”&lt;/p&gt;



&lt;p&gt;For PepsiCo, the transformation goes beyond efficiency gains. “AI and technology are reshaping enterprise operations in ways that were once unimaginable,” Kanioura said. “The work we’re doing with Agentforce is one element of PepsiCo’s broader transformation as a connected company, paving the way for a more resilient and adaptive future of work.”&lt;/p&gt;



&lt;p&gt;The competitive landscape is intensifying as major technology companies race to establish AI agent platforms. When asked about competition from Microsoft, Google and Amazon, Govindarajan emphasized Salesforce’s integration advantages: “We are able to track the entire cycle of work within the enterprise ecosystem,” he said. “We can define flows and interactions in the enterprise, and we’ve been open and extensible in bringing in your data, your actions and orchestrating them effectively.”&lt;/p&gt;



&lt;p&gt;The Agentforce 3 platform is generally available now, with several features including hosted Anthropic models and the full Command Center rolling out through August. But perhaps the most telling sign of the technology’s enterprise readiness isn’t in the feature list — it’s in the confidence of companies like PepsiCo to bet their digital transformation on AI agents they can finally see, measure and control.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Salesforce rolled out sweeping enhancements to its AI agent platform Monday, addressing the biggest hurdles enterprises face when deploying digital workers at scale: Knowing what those agents are actually doing and ensuring they can work securely across corporate systems.&lt;/p&gt;



&lt;p&gt;The company’s Agentforce 3 release introduces a comprehensive “Command Center” that gives executives real-time visibility into AI agent performance, plus native support for emerging interoperability standards that allow agents to connect with hundreds of external business tools without the need for custom coding.&lt;/p&gt;



&lt;p&gt;The timing reflects surging enterprise demand for AI agents. According to Salesforce data, AI agent usage has jumped 233% in six months, with more than 8,000 customers signing up to deploy the technology. Early adopters are seeing measurable returns: Engine reduced customer case handling time by 15%, while 1-800Accountant achieved 70% autonomous resolution of administrative chat requests during peak tax season.&lt;/p&gt;



&lt;p&gt;“We have hundreds of live implementations, if not thousands, and they’re running at scale,” Jayesh Govindarajan, EVP of Salesforce AI, said in an exclusive interview with VentureBeat. The company has moved decisively beyond experimental deployments, he noted: “AI agents are no longer experimental. They have really moved deeply into the fabric of the enterprise.”&lt;/p&gt;



&lt;p&gt;Adam Evans, EVP and GM of Salesforce AI, said in a live event on Monday announcing the platform upgrade: “Over the past several months we’ve listened deeply to our customers and continued our rapid pace of technology innovation. The result is Agentforce 3, a major leap forward for our platform that brings greater intelligence, higher performance and more trust and accountability to every Agentforce deployment.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-global-food-giant-pepsico-is-leading-the-enterprise-ai-agent-revolution"&gt;How global food giant PepsiCo is leading the enterprise AI agent revolution&lt;/h2&gt;



&lt;p&gt;Among the companies embracing this technology is PepsiCo, which is deploying Agentforce as part of a broader AI-driven transformation of its global operations. In an exclusive interview with VentureBeat, Athina Kanioura, PepsiCo’s chief strategy and transformation officer, described the deployment as crucial to the company’s evolution in an increasingly complex marketplace.&lt;/p&gt;



&lt;p&gt;“As a longtime partner of Salesforce, we recognized an opportunity to holistically integrate the way we utilize their platforms across our business — especially as the customer landscape evolves, trade becomes more complex and the need to better integrate our data increases,” Kanioura told VentureBeat.&lt;/p&gt;



&lt;p&gt;The food and beverage giant, whose products are consumed over a billion times daily worldwide, sees AI agents as essential for meeting customers “where they are — and in the ways they want to engage with us,” while driving backend efficiency by integrating systems and simplifying processes.&lt;/p&gt;



&lt;p&gt;PepsiCo’s seven-year relationship with Salesforce has positioned the company to move quickly on AI agents. “We were excited about how Agentforce could enhance the day-to-day experience for our field sellers – streamlining workflows and surfacing smarter insights in real time,” Kanioura explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-missing-piece-why-enterprise-ai-needs-real-time-monitoring-and-control"&gt;The missing piece: Why enterprise AI needs real-time monitoring and control&lt;/h2&gt;



&lt;p&gt;The Command Center represents Salesforce’s response to a critical gap in the enterprise AI market. While companies have rushed to deploy AI agents for customer service, sales and operational tasks, many lack visibility into how those digital workers are performing or impacting business outcomes.&lt;/p&gt;



&lt;p&gt;Govindarajan described the challenge facing enterprises that have moved beyond pilot programs: “It’s one thing to build an AI agent demo, but when you actually build an agentic system and put it in front of your users, there’s a different standard.” Companies need tools to understand when AI agents are struggling and when to bring humans into the workflow, he explained.&lt;/p&gt;



&lt;p&gt;“Teams can’t see what agents are doing — or evolve them fast enough,” the company acknowledged in its announcement. The new observability platform provides detailed analytics on agent interactions, health monitoring with real-time alerts and AI-powered recommendations for optimization.&lt;/p&gt;



&lt;p&gt;The system addresses what Govindarajan calls “day two problems” – the operational challenges that emerge after initial deployment. “You can have multiple agents for multiple personas, and you need to be able to observe how that’s actually impacting the task that needs to get done at scale,” he said. This includes managing the handoffs between digital agents and human workers when complex decisions or approvals are required.&lt;/p&gt;



&lt;p&gt;The system captures all agent activity in Salesforce’s Data Cloud using the OpenTelemetry standard, enabling integration with existing monitoring tools like Datadog and other enterprise systems. This addresses enterprises’ need to incorporate AI agent oversight into their existing operational workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-standards-and-secure-integration-how-ai-agents-connect-across-enterprise-systems"&gt;Open standards and secure integration: How AI agents connect across enterprise systems&lt;/h2&gt;



&lt;p&gt;Perhaps more significant is Salesforce’s embrace of the Model Context Protocol (MCP), an emerging open standard for AI agent interoperability. The platform will include native MCP support, allowing Agentforce agents to connect with any MCP-compliant server without custom development work.&lt;/p&gt;



&lt;p&gt;“There’s generic interoperability, and then there’s what we call enterprise-grade interoperability,” Gary Lerhaupt, VP of product architecture at Salesforce, explained in an exclusive interview with VentureBeat. “If it’s not enterprise grade, it’s like sparkling untrusted interop.” The key difference, he said, lies in governance and control mechanisms that enterprise customers require.&lt;/p&gt;



&lt;p&gt;This capability, working alongside an expanded AgentExchange marketplace, gives enterprises access to pre-built integrations with over 30 partners including Amazon Web Services, Box, Google Cloud, IBM, PayPal and Stripe. Lerhaupt said the company is launching with “north of 20, maybe 25 plus” vetted MCP servers, with partners like PayPal offering invoicing capabilities and Box providing document access through their MCP implementations.&lt;/p&gt;



&lt;p&gt;“In a world full of AI tools, Agentforce stood out not just for its first-of-a-kind technology but how seamlessly it fit into our technology ecosystem, the way we work and our AI strategy, standards and framework,” Kanioura said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-boost-faster-ai-models-and-enhanced-security-for-regulated-industries"&gt;Performance boost: Faster AI models and enhanced security for regulated industries&lt;/h2&gt;



&lt;p&gt;Underlying the new features is what Salesforce calls an enhanced “Atlas” architecture designed for enterprise-grade performance and security. The platform now offers 50% lower latency compared to January 2025, as well as response streaming for real-time user experiences and automatic failover between AI model providers to ensure continuous operation.&lt;/p&gt;



&lt;p&gt;For regulated industries, Salesforce’s approach to hosting AI models directly within its infrastructure addresses critical security concerns. “With Anthropic, the entire stack will be running within Salesforce infrastructure,” Govindarajan explained. “The calls are not going out to OpenAI, and traffic will be running within the Salesforce VPC. For regulated industries, that’s what we’ve been working on.”&lt;/p&gt;



&lt;p&gt;Critically for regulated industries, Salesforce now hosts Anthropic’s Claude models directly within its infrastructure via Amazon Bedrock, keeping sensitive data within the Salesforce security perimeter. The company plans to add Google’s Gemini models later this year, giving enterprises more options for AI model governance.&lt;/p&gt;



&lt;p&gt;The platform also expands global availability to Canada, the UK, India, Japan and Brazil, with support for six additional languages including French, German, Spanish, Italian, Japanese and Portuguese.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-zero-to-ai-agent-how-pre-built-industry-actions-speed-enterprise-deployment"&gt;From zero to AI agent: How pre-built industry actions speed enterprise deployment&lt;/h2&gt;



&lt;p&gt;Recognizing that enterprises need faster returns on AI investments, Salesforce has built more than 200 pre-configured industry actions — with more than 100 added this summer alone. These range from patient scheduling in healthcare to advertising proposal generation in media, designed to help companies deploy functional AI agents quickly rather than building from scratch.&lt;/p&gt;



&lt;p&gt;The results demonstrate the platform’s maturity. Beyond 1-800Accountant’s 70% deflection rate during tax season, Govindarajan cited other production deployments: “OpenTable sees 73% of all restaurant web queries handled by agents,” and Grupo Falabella, a Colombian customer service operation using WhatsApp, achieved a 71% reduction in phone call traffic in just three weeks.&lt;/p&gt;



&lt;p&gt;The company also introduced more flexible pricing, including unlimited usage licenses for employee-facing agents and per-action pricing that scales with actual AI work performed rather than simple conversation volume.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-new-digital-workforce-what-enterprise-ai-adoption-means-for-business-operations"&gt;The new digital workforce: What enterprise AI adoption means for business operations&lt;/h2&gt;



&lt;p&gt;As enterprises increasingly view AI agents as digital employees rather than simple automation tools, the stakes for getting deployment right have never been higher. Companies that successfully scale AI agents stand to gain significant competitive advantages, while those that struggle with governance and oversight risk operational disruptions.&lt;/p&gt;



&lt;p&gt;Govindarajan sees fundamental changes in how work gets organized: “New roles are emerging for people who manage a fleet of agents,” he said. “A CIO might ask, ‘I have seven agents running in my enterprise, what’s broadly happening?’ But someone running a specific marketing agent has a different lens on the same problem.”&lt;/p&gt;



&lt;p&gt;Looking ahead, Lerhaupt positioned the current moment as transformational: “You had the personal computer, then the Internet and now it’s multi-agent,” he said. He described the evolution from single-agent deployments as “the multi-agent revolution and the ability to plug agents together to do exceedingly complex new types of work.”&lt;/p&gt;



&lt;p&gt;For PepsiCo, the transformation goes beyond efficiency gains. “AI and technology are reshaping enterprise operations in ways that were once unimaginable,” Kanioura said. “The work we’re doing with Agentforce is one element of PepsiCo’s broader transformation as a connected company, paving the way for a more resilient and adaptive future of work.”&lt;/p&gt;



&lt;p&gt;The competitive landscape is intensifying as major technology companies race to establish AI agent platforms. When asked about competition from Microsoft, Google and Amazon, Govindarajan emphasized Salesforce’s integration advantages: “We are able to track the entire cycle of work within the enterprise ecosystem,” he said. “We can define flows and interactions in the enterprise, and we’ve been open and extensible in bringing in your data, your actions and orchestrating them effectively.”&lt;/p&gt;



&lt;p&gt;The Agentforce 3 platform is generally available now, with several features including hosted Anthropic models and the full Command Center rolling out through August. But perhaps the most telling sign of the technology’s enterprise readiness isn’t in the feature list — it’s in the confidence of companies like PepsiCo to bet their digital transformation on AI agents they can finally see, measure and control.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/salesforce-launches-agentforce-3-with-ai-agent-observability-and-mcp-support/</guid><pubDate>Mon, 23 Jun 2025 21:03:09 +0000</pubDate></item><item><title>Beyond static AI: MIT’s new framework lets models teach themselves (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers at MIT have developed a framework called Self-Adapting Language Models (SEAL) that enables large language models (LLMs) to continuously learn and adapt by updating their own internal parameters. SEAL teaches an LLM to generate its own training data and update instructions, allowing it to permanently absorb new knowledge and learn new tasks.&lt;/p&gt;



&lt;p&gt;This framework could be useful for enterprise applications, particularly for AI agents that operate in dynamic environments, where they must constantly process new information and adapt their behavior.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-challenge-of-adapting-llms"&gt;The challenge of adapting LLMs&lt;/h2&gt;



&lt;p&gt;While large language models have shown remarkable abilities, adapting them to specific tasks, integrating new information, or mastering novel reasoning skills remains a significant hurdle.&lt;/p&gt;



&lt;p&gt;Currently, when faced with a new task, LLMs typically learn from data “as-is” through methods like finetuning or in-context learning. However, the provided data is not always in an optimal format for the model to learn efficiently. Existing approaches don’t allow the model to develop its own strategies for best transforming and learning from new information.&lt;/p&gt;



&lt;p&gt;“Many enterprise use cases demand more than just factual recall—they require deeper, persistent adaptation,” Jyo Pari, PhD student at MIT and co-author of the paper, told VentureBeat. “For example, a coding assistant might need to internalize a company’s specific software framework, or a customer-facing model might need to learn a user’s unique behavior or preferences over time.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In such cases, temporary retrieval falls short, and the knowledge needs to be “baked into” the model’s weights so that it influences all future responses.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-creating-self-adapting-language-models"&gt;Creating self-adapting language models&lt;/h2&gt;



&lt;p&gt;“As a step towards scalable and efficient adaptation of language models, we propose equipping LLMs with the ability to generate their own training data and finetuning directives for using such data,” the MIT researchers state in their paper.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Overview of SEAL framework (source: arXiv)" class="wp-image-3012752" height="214" src="https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Overview of SEAL framework Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The researchers’ solution is SEAL, short for Self-Adapting Language Models. It uses a reinforcement learning (RL) algorithm to train an LLM to generate “self-edits”—natural-language instructions that specify how the model should update its own weights. These self-edits can restructure new information, create synthetic training examples, or even define the technical parameters for the learning process itself.&lt;/p&gt;



&lt;p&gt;Intuitively, SEAL teaches a model how to create its own personalized study guide. Instead of just reading a new document (the raw data), the model learns to rewrite and reformat that information into a style it can more easily absorb and internalize. This process brings together several key areas of AI research, including synthetic data generation, reinforcement learning and test-time training (TTT).&lt;/p&gt;



&lt;p&gt;The framework operates on a two-loop system. In an “inner loop,” the model uses a self-edit to perform a small, temporary update to its weights. In an “outer loop,” the system evaluates whether that update improved the model’s performance on a target task. If it did, the model receives a positive reward, reinforcing its ability to generate that kind of effective self-edit in the future. Over time, the LLM becomes an expert at teaching itself.&lt;/p&gt;



&lt;p&gt;In their study, the researchers used a single model for the entire SEAL framework. However, they also note that this process can be decoupled into a “teacher-student” model. A specialized teacher model could be trained to generate effective self-edits for a separate student model, which would then be updated. This approach could allow for more specialized and efficient adaptation pipelines in enterprise settings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-seal-in-action"&gt;SEAL in action&lt;/h2&gt;



&lt;p&gt;The researchers tested SEAL in two key domains: knowledge incorporation (the ability to permanently integrate new facts) and few-shot learning (the ability to generalize from a handful of examples).&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="SEAL in knowledge incorporation (source: arXiv)" class="wp-image-3012753" height="152" src="https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL in knowledge incorporation Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For knowledge incorporation, the goal was to see if the model could answer questions about a text passage without having access to the passage during questioning. Finetuning Llama-3.2-1B on the raw text provided only a marginal improvement over the base model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, when the SEAL model created “self-edits” by generating several “implications” from a passage and was trained on this synthetic data, its accuracy jumped to 47%. Notably, this outperformed results from using synthetic data generated by the much larger GPT-4.1, suggesting the model learned to create superior training material for itself.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="SEAL in few-shot learning (source: arXiv)" class="wp-image-3012754" height="218" src="https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL in few-shot learning Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For few-shot learning, the researchers tested SEAL on examples from the Abstract Reasoning Corpus (ARC), where the model must solve visual puzzles. In the self-edit phase, the model had to generate the entire adaptation strategy, including which data augmentations and tools to use and what learning rate to apply.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SEAL achieved a 72.5% success rate, a dramatic improvement over the 20% rate achieved without RL training and the 0% rate of standard in-context learning.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="SEAL (red line) continues to improve across RL cycles (source: arXiv)" class="wp-image-3012755" height="510" src="https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png" width="508" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL (red line) continues to improve across RL cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;h2 class="wp-block-heading" id="h-implications-for-the-enterprise"&gt;Implications for the enterprise&lt;/h2&gt;



&lt;p&gt;Some experts project that the supply of high-quality, human-generated training data could be exhausted in the coming years. Progress may soon depend on “a model’s capacity to generate its own high-utility training signal,” as the researchers put it. They add, “A natural next step is to meta-train a dedicated SEAL synthetic-data generator model that produces fresh pretraining corpora, allowing future models to scale and achieve greater data efficiency without relying on additional human text.”&lt;/p&gt;



&lt;p&gt;For example, the researchers propose that an LLM could ingest complex documents like academic papers or financial reports and autonomously generate thousands of explanations and implications to deepen its understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This iterative loop of self-expression and self-refinement could allow models to keep improving on rare or underrepresented topics even in the absence of additional external supervision,” the researchers explain.&lt;/p&gt;



&lt;p&gt;This capability is especially promising for building AI agents. Agentic systems must incrementally acquire and retain knowledge as they interact with their environment. SEAL provides a mechanism for this. After an interaction, an agent could synthesize a self-edit to trigger a weight update, allowing it to internalize the lessons learned. This enables the agent to evolve over time, improve its performance based on experience, and reduce its reliance on static programming or repeated human guidance.&lt;/p&gt;



&lt;p&gt;“SEAL demonstrates that large language models need not remain static after pretraining,” the researchers write. “By learning to generate their own synthetic self-edit data and to apply it through lightweight weight updates, they can autonomously incorporate new knowledge and adapt to novel tasks.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-limitations-of-seal"&gt;Limitations of SEAL&lt;/h2&gt;



&lt;p&gt;That said, SEAL is not a universal solution. For example, it can suffer from “catastrophic forgetting,” where constant retraining cycles can result in the model learning its earlier knowledge.&lt;/p&gt;



&lt;p&gt;“In our current implementation, we encourage a hybrid approach,” Pari said. “Enterprises should be selective about what knowledge is important enough to integrate permanently.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Factual and evolving data can remain in external memory through RAG, while long-lasting, behavior-shaping knowledge is better suited for weight-level updates via SEAL.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This kind of hybrid memory strategy ensures the right information is persistent without overwhelming the model or introducing unnecessary forgetting,” he said.&lt;/p&gt;



&lt;p&gt;It is also worth noting that SEAL takes a non-trivial amount of time to tune the self-edit examples and train the model. This makes continuous, real-time editing infeasible in most production settings.&lt;/p&gt;



&lt;p&gt;“We envision a more practical deployment model where the system collects data over a period—say, a few hours or a day—and then performs targeted self-edits during scheduled update intervals,” Pari said. “This approach allows enterprises to control the cost of adaptation while still benefiting from SEAL’s ability to internalize new knowledge.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers at MIT have developed a framework called Self-Adapting Language Models (SEAL) that enables large language models (LLMs) to continuously learn and adapt by updating their own internal parameters. SEAL teaches an LLM to generate its own training data and update instructions, allowing it to permanently absorb new knowledge and learn new tasks.&lt;/p&gt;



&lt;p&gt;This framework could be useful for enterprise applications, particularly for AI agents that operate in dynamic environments, where they must constantly process new information and adapt their behavior.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-challenge-of-adapting-llms"&gt;The challenge of adapting LLMs&lt;/h2&gt;



&lt;p&gt;While large language models have shown remarkable abilities, adapting them to specific tasks, integrating new information, or mastering novel reasoning skills remains a significant hurdle.&lt;/p&gt;



&lt;p&gt;Currently, when faced with a new task, LLMs typically learn from data “as-is” through methods like finetuning or in-context learning. However, the provided data is not always in an optimal format for the model to learn efficiently. Existing approaches don’t allow the model to develop its own strategies for best transforming and learning from new information.&lt;/p&gt;



&lt;p&gt;“Many enterprise use cases demand more than just factual recall—they require deeper, persistent adaptation,” Jyo Pari, PhD student at MIT and co-author of the paper, told VentureBeat. “For example, a coding assistant might need to internalize a company’s specific software framework, or a customer-facing model might need to learn a user’s unique behavior or preferences over time.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In such cases, temporary retrieval falls short, and the knowledge needs to be “baked into” the model’s weights so that it influences all future responses.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-creating-self-adapting-language-models"&gt;Creating self-adapting language models&lt;/h2&gt;



&lt;p&gt;“As a step towards scalable and efficient adaptation of language models, we propose equipping LLMs with the ability to generate their own training data and finetuning directives for using such data,” the MIT researchers state in their paper.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Overview of SEAL framework (source: arXiv)" class="wp-image-3012752" height="214" src="https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Overview of SEAL framework Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The researchers’ solution is SEAL, short for Self-Adapting Language Models. It uses a reinforcement learning (RL) algorithm to train an LLM to generate “self-edits”—natural-language instructions that specify how the model should update its own weights. These self-edits can restructure new information, create synthetic training examples, or even define the technical parameters for the learning process itself.&lt;/p&gt;



&lt;p&gt;Intuitively, SEAL teaches a model how to create its own personalized study guide. Instead of just reading a new document (the raw data), the model learns to rewrite and reformat that information into a style it can more easily absorb and internalize. This process brings together several key areas of AI research, including synthetic data generation, reinforcement learning and test-time training (TTT).&lt;/p&gt;



&lt;p&gt;The framework operates on a two-loop system. In an “inner loop,” the model uses a self-edit to perform a small, temporary update to its weights. In an “outer loop,” the system evaluates whether that update improved the model’s performance on a target task. If it did, the model receives a positive reward, reinforcing its ability to generate that kind of effective self-edit in the future. Over time, the LLM becomes an expert at teaching itself.&lt;/p&gt;



&lt;p&gt;In their study, the researchers used a single model for the entire SEAL framework. However, they also note that this process can be decoupled into a “teacher-student” model. A specialized teacher model could be trained to generate effective self-edits for a separate student model, which would then be updated. This approach could allow for more specialized and efficient adaptation pipelines in enterprise settings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-seal-in-action"&gt;SEAL in action&lt;/h2&gt;



&lt;p&gt;The researchers tested SEAL in two key domains: knowledge incorporation (the ability to permanently integrate new facts) and few-shot learning (the ability to generalize from a handful of examples).&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="SEAL in knowledge incorporation (source: arXiv)" class="wp-image-3012753" height="152" src="https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL in knowledge incorporation Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For knowledge incorporation, the goal was to see if the model could answer questions about a text passage without having access to the passage during questioning. Finetuning Llama-3.2-1B on the raw text provided only a marginal improvement over the base model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, when the SEAL model created “self-edits” by generating several “implications” from a passage and was trained on this synthetic data, its accuracy jumped to 47%. Notably, this outperformed results from using synthetic data generated by the much larger GPT-4.1, suggesting the model learned to create superior training material for itself.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="SEAL in few-shot learning (source: arXiv)" class="wp-image-3012754" height="218" src="https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL in few-shot learning Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For few-shot learning, the researchers tested SEAL on examples from the Abstract Reasoning Corpus (ARC), where the model must solve visual puzzles. In the self-edit phase, the model had to generate the entire adaptation strategy, including which data augmentations and tools to use and what learning rate to apply.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SEAL achieved a 72.5% success rate, a dramatic improvement over the 20% rate achieved without RL training and the 0% rate of standard in-context learning.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="SEAL (red line) continues to improve across RL cycles (source: arXiv)" class="wp-image-3012755" height="510" src="https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png" width="508" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;SEAL (red line) continues to improve across RL cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;h2 class="wp-block-heading" id="h-implications-for-the-enterprise"&gt;Implications for the enterprise&lt;/h2&gt;



&lt;p&gt;Some experts project that the supply of high-quality, human-generated training data could be exhausted in the coming years. Progress may soon depend on “a model’s capacity to generate its own high-utility training signal,” as the researchers put it. They add, “A natural next step is to meta-train a dedicated SEAL synthetic-data generator model that produces fresh pretraining corpora, allowing future models to scale and achieve greater data efficiency without relying on additional human text.”&lt;/p&gt;



&lt;p&gt;For example, the researchers propose that an LLM could ingest complex documents like academic papers or financial reports and autonomously generate thousands of explanations and implications to deepen its understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This iterative loop of self-expression and self-refinement could allow models to keep improving on rare or underrepresented topics even in the absence of additional external supervision,” the researchers explain.&lt;/p&gt;



&lt;p&gt;This capability is especially promising for building AI agents. Agentic systems must incrementally acquire and retain knowledge as they interact with their environment. SEAL provides a mechanism for this. After an interaction, an agent could synthesize a self-edit to trigger a weight update, allowing it to internalize the lessons learned. This enables the agent to evolve over time, improve its performance based on experience, and reduce its reliance on static programming or repeated human guidance.&lt;/p&gt;



&lt;p&gt;“SEAL demonstrates that large language models need not remain static after pretraining,” the researchers write. “By learning to generate their own synthetic self-edit data and to apply it through lightweight weight updates, they can autonomously incorporate new knowledge and adapt to novel tasks.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-limitations-of-seal"&gt;Limitations of SEAL&lt;/h2&gt;



&lt;p&gt;That said, SEAL is not a universal solution. For example, it can suffer from “catastrophic forgetting,” where constant retraining cycles can result in the model learning its earlier knowledge.&lt;/p&gt;



&lt;p&gt;“In our current implementation, we encourage a hybrid approach,” Pari said. “Enterprises should be selective about what knowledge is important enough to integrate permanently.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Factual and evolving data can remain in external memory through RAG, while long-lasting, behavior-shaping knowledge is better suited for weight-level updates via SEAL.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This kind of hybrid memory strategy ensures the right information is persistent without overwhelming the model or introducing unnecessary forgetting,” he said.&lt;/p&gt;



&lt;p&gt;It is also worth noting that SEAL takes a non-trivial amount of time to tune the self-edit examples and train the model. This makes continuous, real-time editing infeasible in most production settings.&lt;/p&gt;



&lt;p&gt;“We envision a more practical deployment model where the system collects data over a period—say, a few hours or a day—and then performs targeted self-edits during scheduled update intervals,” Pari said. “This approach allows enterprises to control the cost of adaptation while still benefiting from SEAL’s ability to internalize new knowledge.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves/</guid><pubDate>Mon, 23 Jun 2025 21:58:44 +0000</pubDate></item><item><title>Court filings reveal OpenAI and io’s early work on an AI device (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/23/court-filings-reveal-openai-and-ios-early-work-on-an-ai-device/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal filings submitted earlier this month from lawyers representing OpenAI and Jony Ive’s io reveal new details about the companies’ efforts to build a mass-market AI hardware device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filings are part of a trademark dispute lawsuit filed this month by iyO, a Google-backed hardware startup developing custom-molded earpieces that connect to other devices. Over the weekend, OpenAI pulled promotional materials related to its $6.5 billion acquisition of Jony Ive’s io startup in order to comply with a court order involved in the suit. OpenAI says it’s fighting iyO’s allegations of trademark infringement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For the last year, OpenAI executives and former Apple leaders now working at io have vigorously researched in-ear hardware devices, according to filings submitted in iyO’s lawsuit. In a June 12 filing, lawyers representing OpenAI and io said the companies purchased at least 30 headphone sets from various companies to explore what’s on the market today. In recent months, OpenAI and io executives also met with iyO’s leadership and demoed their in-ear technology, according to emails revealed in the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, OpenAI’s first device in collaboration with io may not be a pair of headphones at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tang Tan, a longtime Apple executive who co-founded io and serves as the startup’s chief hardware officer, claims in a declaration to the court that the prototype OpenAI CEO Sam Altman mentioned in io’s launch video “is not an in-ear device, nor a wearable device.” Tan notes that the design of said prototype in not yet finalized and that the product is at least a year away from being advertised or offered for sale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The form factor of OpenAI and io’s first hardware device has largely remained a mystery. Altman merely stated in io’s launch video that the startup was working to create a “family” of AI devices with various capabilities, and Ive said io’s first prototype “completely captured” his imagination.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman had previously told OpenAI’s employees at a meeting that the company’s prototype, when finished, would be able to fit in a pocket or sit on a desk, according to the Wall Street Journal. The OpenAI CEO reportedly said the device would be fully aware of a user’s surroundings and that it would be a “third device” for consumers to use alongside their smartphone and laptop.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Our intent with this collaboration was, and is, to create products that go beyond traditional products and interfaces,” said Altman in a declaration to the court submitted on June 12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lawyers representing OpenAI also said in a filing that the company has explored a wide range of devices, including ones that were “desktop-based and mobile, wireless and wired, wearable and portable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While smart glasses have emerged as the front-runner for AI-enabled devices, with companies like Meta and Google racing to develop the first broadly adopted pair, several companies are also exploring AI-enabled headphones. Apple is reportedly working on a pair of AirPods with cameras, which would help power AI features by gathering information about the surrounding environment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In recent months, OpenAI and io executives have done considerable research into in-ear products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On May 1, OpenAI’s VP of Product, Peter Welinder, and Tan met with iyO’s CEO, Jason Rugolo, to learn more about iyO’s in-ear product, according to an emailed invitation revealed in the case. The meeting took place at io’s office in Jackson Square, the San Francisco neighborhood where Ive has bought several buildings to work on LoveFrom and io.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the meeting, Welinder and Tan tested out iyO’s custom-fit earpiece but were disappointed when the product failed repeatedly during demonstrations, according to follow-up emails revealed in the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tan claims in his declaration that he met with Rugolo as a courtesy to his mentor, longtime Apple executive Steve Zadesky, who recommended he take the meeting. Tan also claims he took several precautions to avoid learning too much about iyO’s IP, such as suggesting that his lawyers review materials before he does.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it seemed that OpenAI and io employees thought they could learn something from one of iyO’s partners. To customize its in-ear headsets, iyO sent a specialist from an ear-scanning company, The Ear Project, to someone’s home or office to get a detailed map of someone’s ear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In one email revealed in the case, Marwan Rammah, a former Apple engineer who’s now working at io, told Tan that purchasing a large database of three-dimensional scans from The Ear Project could give the company a “helpful starting point on ergonomics.” It’s unclear if any such deal took place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rugolo tried repeatedly to forge a deeper relationship between iyO, io, and OpenAI — but largely failed, according to the emails. He pitched OpenAI on launching iyO’s device as an early “developer kit” for its final AI device. He pitched OpenAI on investing in iyO and, at one point, even offered to sell his entire company for $200 million, the filings say. However, Tan said in his declaration that he declined these offers.&lt;/p&gt;&lt;p&gt;Evans Hankey, former Apple executive turned io co-founder and chief product officer, said in a declaration to the court that io is not working on a “custom-molded earpiece product.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker seems to be more than a year out from selling its first hardware device, which may not be an in-ear product whatsoever. Given what the company said in this lawsuit, it appears it is also exploring other form factors.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal filings submitted earlier this month from lawyers representing OpenAI and Jony Ive’s io reveal new details about the companies’ efforts to build a mass-market AI hardware device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filings are part of a trademark dispute lawsuit filed this month by iyO, a Google-backed hardware startup developing custom-molded earpieces that connect to other devices. Over the weekend, OpenAI pulled promotional materials related to its $6.5 billion acquisition of Jony Ive’s io startup in order to comply with a court order involved in the suit. OpenAI says it’s fighting iyO’s allegations of trademark infringement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For the last year, OpenAI executives and former Apple leaders now working at io have vigorously researched in-ear hardware devices, according to filings submitted in iyO’s lawsuit. In a June 12 filing, lawyers representing OpenAI and io said the companies purchased at least 30 headphone sets from various companies to explore what’s on the market today. In recent months, OpenAI and io executives also met with iyO’s leadership and demoed their in-ear technology, according to emails revealed in the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, OpenAI’s first device in collaboration with io may not be a pair of headphones at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tang Tan, a longtime Apple executive who co-founded io and serves as the startup’s chief hardware officer, claims in a declaration to the court that the prototype OpenAI CEO Sam Altman mentioned in io’s launch video “is not an in-ear device, nor a wearable device.” Tan notes that the design of said prototype in not yet finalized and that the product is at least a year away from being advertised or offered for sale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The form factor of OpenAI and io’s first hardware device has largely remained a mystery. Altman merely stated in io’s launch video that the startup was working to create a “family” of AI devices with various capabilities, and Ive said io’s first prototype “completely captured” his imagination.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman had previously told OpenAI’s employees at a meeting that the company’s prototype, when finished, would be able to fit in a pocket or sit on a desk, according to the Wall Street Journal. The OpenAI CEO reportedly said the device would be fully aware of a user’s surroundings and that it would be a “third device” for consumers to use alongside their smartphone and laptop.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Our intent with this collaboration was, and is, to create products that go beyond traditional products and interfaces,” said Altman in a declaration to the court submitted on June 12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lawyers representing OpenAI also said in a filing that the company has explored a wide range of devices, including ones that were “desktop-based and mobile, wireless and wired, wearable and portable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While smart glasses have emerged as the front-runner for AI-enabled devices, with companies like Meta and Google racing to develop the first broadly adopted pair, several companies are also exploring AI-enabled headphones. Apple is reportedly working on a pair of AirPods with cameras, which would help power AI features by gathering information about the surrounding environment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In recent months, OpenAI and io executives have done considerable research into in-ear products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On May 1, OpenAI’s VP of Product, Peter Welinder, and Tan met with iyO’s CEO, Jason Rugolo, to learn more about iyO’s in-ear product, according to an emailed invitation revealed in the case. The meeting took place at io’s office in Jackson Square, the San Francisco neighborhood where Ive has bought several buildings to work on LoveFrom and io.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the meeting, Welinder and Tan tested out iyO’s custom-fit earpiece but were disappointed when the product failed repeatedly during demonstrations, according to follow-up emails revealed in the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tan claims in his declaration that he met with Rugolo as a courtesy to his mentor, longtime Apple executive Steve Zadesky, who recommended he take the meeting. Tan also claims he took several precautions to avoid learning too much about iyO’s IP, such as suggesting that his lawyers review materials before he does.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it seemed that OpenAI and io employees thought they could learn something from one of iyO’s partners. To customize its in-ear headsets, iyO sent a specialist from an ear-scanning company, The Ear Project, to someone’s home or office to get a detailed map of someone’s ear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In one email revealed in the case, Marwan Rammah, a former Apple engineer who’s now working at io, told Tan that purchasing a large database of three-dimensional scans from The Ear Project could give the company a “helpful starting point on ergonomics.” It’s unclear if any such deal took place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rugolo tried repeatedly to forge a deeper relationship between iyO, io, and OpenAI — but largely failed, according to the emails. He pitched OpenAI on launching iyO’s device as an early “developer kit” for its final AI device. He pitched OpenAI on investing in iyO and, at one point, even offered to sell his entire company for $200 million, the filings say. However, Tan said in his declaration that he declined these offers.&lt;/p&gt;&lt;p&gt;Evans Hankey, former Apple executive turned io co-founder and chief product officer, said in a declaration to the court that io is not working on a “custom-molded earpiece product.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker seems to be more than a year out from selling its first hardware device, which may not be an in-ear product whatsoever. Given what the company said in this lawsuit, it appears it is also exploring other form factors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/23/court-filings-reveal-openai-and-ios-early-work-on-an-ai-device/</guid><pubDate>Mon, 23 Jun 2025 23:44:38 +0000</pubDate></item><item><title>[NEW] Google introduces AI mode to users in India (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/23/google-introduces-ai-mode-to-users-in-india/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2206888090.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google introduced its AI mode, a Q&amp;amp;A-style search tool, to users in India today. The company said that this tool is still in the experimental stage and users will need to opt in to it through Search Labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once a user has opted in, they can ask queries in English. Google didn’t specify whether it plans to support local languages or when that might be available.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can search for answers to complex, multi-part queries such as “My kids are 4 and 7 and have lots of energy. Suggest creative ways to get them active and moving indoors, especially on hot days, without needing a lot of space or expensive toys.” Additionally, users can ask follow-up questions to refine results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google started testing AI mode with premium subscribers in the U.S. earlier this year. The company then started broadly rolling out the feature to all U.S. users after its Google IO event. Over time, the company has added a shopping feature, introduced voice and image search support, and also introduced ads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that voice and image search features are supported for users in India, given that voice is a popular mode for search. It added that the AI mode is powered by a custom version of Gemini 2.5. The company also noted that early testers of the AI mode are asking 2-3x longer queries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 870 million internet users, India is one of the biggest markets for Google. It also acts as a testing ground for the company to observe how multilingual users use its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google still has a lion’s share in the search market, people have started using chat-based AI tools like ChatGPT and Perplexity more in their daily lives. With AI mode, Google wants users who prefer that kind of interface to use its own product. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Apart from AI mode, Google has been pushing products such as AI overviews, which summarize query results for you, in search. The company said in April that more than 1.5 billion people are using AI overviews across the globe. Earlier this month, the Wall Street Journal reported that Google’s AI features are hurting publishers, which have seen traffic drop-offs from organic search.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2206888090.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google introduced its AI mode, a Q&amp;amp;A-style search tool, to users in India today. The company said that this tool is still in the experimental stage and users will need to opt in to it through Search Labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once a user has opted in, they can ask queries in English. Google didn’t specify whether it plans to support local languages or when that might be available.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can search for answers to complex, multi-part queries such as “My kids are 4 and 7 and have lots of energy. Suggest creative ways to get them active and moving indoors, especially on hot days, without needing a lot of space or expensive toys.” Additionally, users can ask follow-up questions to refine results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google started testing AI mode with premium subscribers in the U.S. earlier this year. The company then started broadly rolling out the feature to all U.S. users after its Google IO event. Over time, the company has added a shopping feature, introduced voice and image search support, and also introduced ads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that voice and image search features are supported for users in India, given that voice is a popular mode for search. It added that the AI mode is powered by a custom version of Gemini 2.5. The company also noted that early testers of the AI mode are asking 2-3x longer queries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 870 million internet users, India is one of the biggest markets for Google. It also acts as a testing ground for the company to observe how multilingual users use its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google still has a lion’s share in the search market, people have started using chat-based AI tools like ChatGPT and Perplexity more in their daily lives. With AI mode, Google wants users who prefer that kind of interface to use its own product. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Apart from AI mode, Google has been pushing products such as AI overviews, which summarize query results for you, in search. The company said in April that more than 1.5 billion people are using AI overviews across the globe. Earlier this month, the Wall Street Journal reported that Google’s AI features are hurting publishers, which have seen traffic drop-offs from organic search.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/23/google-introduces-ai-mode-to-users-in-india/</guid><pubDate>Tue, 24 Jun 2025 05:40:04 +0000</pubDate></item></channel></rss>