<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 17 Sep 2025 01:36:56 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>YouTube rolls out Studio updates, ‘likeness’ detection, lip-synced dubs, creator collabs, and more (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-rolls-out-studio-updates-likeness-detection-lip-synced-dubs-creator-collabs-and-more/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube on Tuesday announced a suite of new features coming to YouTube Studio, the platform over 30 million creators use to manage their channels and track their analytics and revenue every month. At its Made on YouTube event, the company unveiled new and updated tools like an AI-powered chatbot for support, an inspiration tab, title A/B testing features, auto dubbing, likeness detection tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of these features build on tools previously announced or tested with smaller groups but are now rolling out more broadly.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046077" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Likeness-detection-title-card-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of these, the most interesting addition is the likeness-detection feature, which was first announced in 2024 and expanded earlier this year to a handful of top creators, like MrBeast. Now the company says it’s bringing the technology to an open beta that will be available to all YouTube Partner Program creators — content creators who meet certain subscriber and view thresholds to monetize their channels. These creators will be able to detect, manage, and authorize the removal of any unauthorized videos using their facial likeness. This will help them protect their image and reputation, and ensure their audience isn’t misled, notes YouTube.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046362" height="381" src="https://techcrunch.com/wp-content/uploads/2025/09/likeness-detection.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another new tool, Ask Studio, provides an AI-powered chatbot assistant that can guide users and answer questions about their account, like how their latest video is performing or what their audience is saying about their editing style, for example. The tool is meant to offer creators actionable insights that will help them grow their channel, according to YouTube.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(The feature is different from another “Ask” AI tool for viewers that YouTube tested in late 2023, which allowed users to ask questions about a video they were viewing.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046338" height="395" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-ask-studio.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One feature getting an update is the Inspiration tab in YouTube Studio. Launched publicly at last year’s event, the tab helps creators leverage AI to spark ideas and come up with video concepts. Now it’s being updated with new ways to generate ideas, including a list of suggested topics tailored to each creator’s channel and a set of nine responses to every AI prompt, to help creators build out their content plan. The company notes that the topics can be combined, or users can add their own, as they brainstorm. The feature will also explain why it’s making specific suggestions based on audience insights and behavior.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046346" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-studio-demo.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Studio will also introduce a way to test and compare up to three different video titles and thumbnails, as an update to its A/B testing feature launched to select creators in 2023 and expanded the following year. Creators have used this testing feature more than 15 million times so far, according to the company (a metric that seems a bit small, given that 20 million videos are uploaded to the site daily).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046349" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/ab-testing-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, creators will be able to collaborate with up to five others on one video that is shown to the audiences of all the participating creators. While the feature is aimed at boosting engagement and helping creators reach new viewers, the revenue earned from the video will be attributed to the channel that posts the video, YouTube says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046352" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/invite-collab.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will also begin testing lip-syncing technology to make its auto dubbing features more realistic. Today, YouTube supports dubbing content into 20 different languages, and in the coming months, it will improve the translated videos to make them appear more natural by matching lip movements to the dubbed audio. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046357" height="377" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-autodubbing-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that, on average, viewers spent over 75% of their time viewing the autodubbed video compared to the original, based on a comparison that ran from December 2024 to August 2025.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube on Tuesday announced a suite of new features coming to YouTube Studio, the platform over 30 million creators use to manage their channels and track their analytics and revenue every month. At its Made on YouTube event, the company unveiled new and updated tools like an AI-powered chatbot for support, an inspiration tab, title A/B testing features, auto dubbing, likeness detection tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of these features build on tools previously announced or tested with smaller groups but are now rolling out more broadly.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046077" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Likeness-detection-title-card-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of these, the most interesting addition is the likeness-detection feature, which was first announced in 2024 and expanded earlier this year to a handful of top creators, like MrBeast. Now the company says it’s bringing the technology to an open beta that will be available to all YouTube Partner Program creators — content creators who meet certain subscriber and view thresholds to monetize their channels. These creators will be able to detect, manage, and authorize the removal of any unauthorized videos using their facial likeness. This will help them protect their image and reputation, and ensure their audience isn’t misled, notes YouTube.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046362" height="381" src="https://techcrunch.com/wp-content/uploads/2025/09/likeness-detection.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another new tool, Ask Studio, provides an AI-powered chatbot assistant that can guide users and answer questions about their account, like how their latest video is performing or what their audience is saying about their editing style, for example. The tool is meant to offer creators actionable insights that will help them grow their channel, according to YouTube.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(The feature is different from another “Ask” AI tool for viewers that YouTube tested in late 2023, which allowed users to ask questions about a video they were viewing.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046338" height="395" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-ask-studio.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One feature getting an update is the Inspiration tab in YouTube Studio. Launched publicly at last year’s event, the tab helps creators leverage AI to spark ideas and come up with video concepts. Now it’s being updated with new ways to generate ideas, including a list of suggested topics tailored to each creator’s channel and a set of nine responses to every AI prompt, to help creators build out their content plan. The company notes that the topics can be combined, or users can add their own, as they brainstorm. The feature will also explain why it’s making specific suggestions based on audience insights and behavior.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046346" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-studio-demo.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Studio will also introduce a way to test and compare up to three different video titles and thumbnails, as an update to its A/B testing feature launched to select creators in 2023 and expanded the following year. Creators have used this testing feature more than 15 million times so far, according to the company (a metric that seems a bit small, given that 20 million videos are uploaded to the site daily).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046349" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/ab-testing-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, creators will be able to collaborate with up to five others on one video that is shown to the audiences of all the participating creators. While the feature is aimed at boosting engagement and helping creators reach new viewers, the revenue earned from the video will be attributed to the channel that posts the video, YouTube says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046352" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/invite-collab.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will also begin testing lip-syncing technology to make its auto dubbing features more realistic. Today, YouTube supports dubbing content into 20 different languages, and in the coming months, it will improve the translated videos to make them appear more natural by matching lip movements to the dubbed audio. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046357" height="377" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-autodubbing-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that, on average, viewers spent over 75% of their time viewing the autodubbed video compared to the original, based on a comparison that ran from December 2024 to August 2025.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-rolls-out-studio-updates-likeness-detection-lip-synced-dubs-creator-collabs-and-more/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>YouTube announces new generative AI tools for Shorts creators (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-announces-new-generative-ai-tools-for-shorts-creators/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its Made on YouTube live event on Tuesday, the company unveiled new generative AI tools for Shorts creators. YouTube is bringing a custom version of Google’s text-to-video generative AI model, Veo 3, to Shorts, along with a new remixing tool, an “Edit with AI” feature, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The custom version of Veo 3, called Veo 3 Fast, generates outputs with lower latency at 480p, making it easy to create video clips, YouTube says. And now users can do so with sound for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This update is rolling out in the United States, the United Kingdom, Canada, Australia, and New Zealand. YouTube plans to expand its functionality to more regions in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046043" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Veo-3-in-Shorts-product-mock.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is also bringing new Veo capabilities to Shorts, including the ability to apply motion from a video to an image. For example, you could animate a still image by making the person in it do a dance from a video. The company says this is possible through technology that captures and transfers movement from one subject to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators can now also use Veo to apply different styles to their videos, such as pop art or origami. Plus, creators now have the ability to add objects like characters or props with text descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new capabilities will roll out in the coming months. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046049" height="640" src="https://techcrunch.com/wp-content/uploads/2025/09/Add-motion-product-example.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new remixing tool, creators can turn the dialogue from eligible videos into catchy soundtracks for other Shorts. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As the world’s largest creative playground, YouTube is where trends are born and where you can draw inspiration from. Imagine hearing a line of dialogue that sparks an idea — a funny phrase, a memorable quote, or a one-of-a-kind sound — and you want to remix it into a new sound,” YouTube’s Director of Product, Shorts and Generative AI Creation, Dina Berrada, wrote in a blog post. “With our new Speech to Song remixing tool, you’ll be able to do just that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the feature uses Google’s AI music model Lyria 2 to create the soundtrack. Creators will be able to add their own vibe to the song, like “chill,” “danceable,” or “fun.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046053" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-5.19.05PM.png?w=657" width="657" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to test this feature soon, it says, and will roll it out to more creators in the United States in the coming weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new Edit with AI feature, creators can turn their raw footage into first drafts. It transforms raw camera roll footage into a first draft by finding and arranging the best moments and adding music and transitions. It can even add a voice-over that can react to what’s happening in the video, in either English or Hindi. The idea behind the feature is to give creators a starting point for their Shorts, YouTube says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is experimenting with Edit with AI on Shorts and in the YouTube Create app and will expand the feature in the coming weeks in select markets.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its Made on YouTube live event on Tuesday, the company unveiled new generative AI tools for Shorts creators. YouTube is bringing a custom version of Google’s text-to-video generative AI model, Veo 3, to Shorts, along with a new remixing tool, an “Edit with AI” feature, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The custom version of Veo 3, called Veo 3 Fast, generates outputs with lower latency at 480p, making it easy to create video clips, YouTube says. And now users can do so with sound for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This update is rolling out in the United States, the United Kingdom, Canada, Australia, and New Zealand. YouTube plans to expand its functionality to more regions in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046043" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Veo-3-in-Shorts-product-mock.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is also bringing new Veo capabilities to Shorts, including the ability to apply motion from a video to an image. For example, you could animate a still image by making the person in it do a dance from a video. The company says this is possible through technology that captures and transfers movement from one subject to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators can now also use Veo to apply different styles to their videos, such as pop art or origami. Plus, creators now have the ability to add objects like characters or props with text descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new capabilities will roll out in the coming months. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046049" height="640" src="https://techcrunch.com/wp-content/uploads/2025/09/Add-motion-product-example.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new remixing tool, creators can turn the dialogue from eligible videos into catchy soundtracks for other Shorts. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As the world’s largest creative playground, YouTube is where trends are born and where you can draw inspiration from. Imagine hearing a line of dialogue that sparks an idea — a funny phrase, a memorable quote, or a one-of-a-kind sound — and you want to remix it into a new sound,” YouTube’s Director of Product, Shorts and Generative AI Creation, Dina Berrada, wrote in a blog post. “With our new Speech to Song remixing tool, you’ll be able to do just that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the feature uses Google’s AI music model Lyria 2 to create the soundtrack. Creators will be able to add their own vibe to the song, like “chill,” “danceable,” or “fun.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046053" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-5.19.05PM.png?w=657" width="657" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to test this feature soon, it says, and will roll it out to more creators in the United States in the coming weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new Edit with AI feature, creators can turn their raw footage into first drafts. It transforms raw camera roll footage into a first draft by finding and arranging the best moments and adding music and transitions. It can even add a voice-over that can react to what’s happening in the video, in either English or Hindi. The idea behind the feature is to give creators a starting point for their Shorts, YouTube says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is experimenting with Edit with AI on Shorts and in the YouTube Create app and will expand the feature in the coming weeks in select markets.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-announces-new-generative-ai-tools-for-shorts-creators/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>YouTube to use AI to help podcasters promote themselves with clips and Shorts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-to-use-ai-to-help-podcasters-promote-themselves-with-clips-and-shorts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, YouTube introduced new tools for podcasters at its Made on YouTube live event in New York, including new ways to turn video podcasts into clips and YouTube Shorts and a new feature that helps create videos for audio-only podcasters. Both will be powered by AI and will roll out in the months ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Using AI technology, video podcast creators in the U.S. will be able to create clips more easily with AI suggestions, the company says. This will be available in the “coming months,” while a feature that will transform those clips into YouTube Shorts will arrive early next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition could give YouTube more fodder to compete with rival short-form video apps, like TikTok and Instagram (Reels), while also directing users to podcasters they might find interesting on YouTube’s larger platform, driving subscriptions and engagement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046308" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Podcast-clips-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, another new feature also available early next year will help audio podcasters turn their content into video. Using AI, these creators will be able to generate a customizable video for their podcast, the company says. However, the feature will only be available to “select podcasters” when it launches, with a larger expansion planned for later in 2026. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046310" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Audio-to-video-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has been more focused on building out tools for podcasters over the past several years, making pods a more prominent feature on YouTube’s home page and its YouTube Music service. Meanwhile, Spotify has been inching into its market with added support for video podcasts and other engagement features for podcasters, like comments, polls, and Q&amp;amp;As, as well as monetization tools.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046342" height="374" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-podcasts-1B.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In February, the company announced YouTube had surpassed 1 billion monthly podcaster viewers. Today, YouTube announced that users, as of July 2025, now consume over 100 million hours of podcasts daily, with more than 30% of those hours starting as a livestream or premiere.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, YouTube introduced new tools for podcasters at its Made on YouTube live event in New York, including new ways to turn video podcasts into clips and YouTube Shorts and a new feature that helps create videos for audio-only podcasters. Both will be powered by AI and will roll out in the months ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Using AI technology, video podcast creators in the U.S. will be able to create clips more easily with AI suggestions, the company says. This will be available in the “coming months,” while a feature that will transform those clips into YouTube Shorts will arrive early next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition could give YouTube more fodder to compete with rival short-form video apps, like TikTok and Instagram (Reels), while also directing users to podcasters they might find interesting on YouTube’s larger platform, driving subscriptions and engagement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046308" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Podcast-clips-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, another new feature also available early next year will help audio podcasters turn their content into video. Using AI, these creators will be able to generate a customizable video for their podcast, the company says. However, the feature will only be available to “select podcasters” when it launches, with a larger expansion planned for later in 2026. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046310" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Audio-to-video-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has been more focused on building out tools for podcasters over the past several years, making pods a more prominent feature on YouTube’s home page and its YouTube Music service. Meanwhile, Spotify has been inching into its market with added support for video podcasts and other engagement features for podcasters, like comments, polls, and Q&amp;amp;As, as well as monetization tools.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046342" height="374" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-podcasts-1B.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In February, the company announced YouTube had surpassed 1 billion monthly podcaster viewers. Today, YouTube announced that users, as of July 2025, now consume over 100 million hours of podcasts daily, with more than 30% of those hours starting as a livestream or premiere.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-to-use-ai-to-help-podcasters-promote-themselves-with-clips-and-shorts/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>How to build AI scaling laws for efficient LLM training and budget maximization (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/how-build-ai-scaling-laws-efficient-llm-training-budget-maximization-0916</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/Increasing-LLM-size.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When researchers are building large language models (LLMs), they aim to maximize performance under a particular computational and financial budget. Since training a model can amount to millions of dollars, developers need to be judicious with cost-impacting decisions about, for instance, the model architecture, optimizers, and training datasets before committing to a model. To anticipate the quality and accuracy of a large model’s predictions, practitioners often turn to scaling laws: using smaller, cheaper models to try to approximate the performance of a much larger target model. The challenge, however, is that there are thousands of ways to create a scaling law.&lt;/p&gt;&lt;p&gt;New work from MIT and MIT-IBM Watson AI Lab researchers addresses this by amassing and releasing a collection of hundreds of models and metrics concerning training and performance to approximate more than a thousand scaling laws. From this, the team developed a meta-analysis and guide for how to select small models and estimate scaling laws for different LLM model families, so that the budget is optimally applied toward generating reliable performance predictions.&lt;/p&gt;&lt;p&gt;“The notion that you might want to try to build mathematical models of the training process is a couple of years old, but I think what was new here is that most of the work that people had been doing before is saying, ‘can we say something post-hoc about what happened when we trained all of these models, so that when we’re trying to figure out how to train a new large-scale model, we can make the best decisions about how to use our compute budget?’” says Jacob Andreas, associate professor in the Department of Electrical Engineering and Computer Science and principal investigator with the MIT-IBM Watson AI Lab.&lt;/p&gt;&lt;p&gt;The research was recently presented at the International Conference on Machine Learning by Andreas, along with MIT-IBM Watson AI Lab researchers Leshem Choshen and Yang Zhang of IBM Research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Extrapolating performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;No matter how you slice it, developing LLMs is an expensive endeavor: from decision-making regarding the numbers of parameters and tokens, data selection and size, and training techniques to determining output accuracy and tuning to the target applications and tasks. Scaling laws offer a way to forecast model behavior by relating a large model’s loss to the performance of smaller, less-costly models from the same family, avoiding the need to fully train every candidate. Mainly, the differences between the smaller models are the number of parameters and token training size. According to Choshen, elucidating scaling laws not only enable better pre-training decisions, but also democratize the field by enabling researchers without vast resources to understand and build effective scaling laws.&lt;/p&gt;&lt;p&gt;The functional form of scaling laws is relatively simple, incorporating components from the small models that capture the number of parameters and their scaling effect, the number of training tokens and their scaling effect, and the baseline performance for the model family of interest. Together, they help researchers estimate a target large model’s performance loss; the smaller the loss, the better the target model’s outputs are likely to be.&lt;/p&gt;&lt;p&gt;These laws allow research teams to weigh trade-offs efficiently and to test how best to allocate limited resources. They’re particularly useful for evaluating scaling of a certain variable, like the number of tokens, and for A/B testing of different pre-training setups.&lt;/p&gt;&lt;p&gt;In general, scaling laws aren’t new; however, in the field of AI, they emerged as models grew and costs skyrocketed. “It’s like scaling laws just appeared at some point in the field,” says Choshen. “They started getting attention, but no one really tested how good they are and what you need to do to make a good scaling law.” Further, scaling laws were themselves also a black box, in a sense. “Whenever people have created scaling laws in the past, it has always just been one model, or one model family, and one dataset, and one developer,” says Andreas. “There hadn’t really been a lot of systematic meta-analysis, as everybody is individually training their own scaling laws. So, [we wanted to know,] are there high-level trends that you see across those things?”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To investigate this, Choshen, Andreas, and Zhang created a large dataset. They collected LLMs from 40 model families, including Pythia, OPT, OLMO, LLaMA, Bloom, T5-Pile, ModuleFormer mixture-of-experts, GPT, and other families. These included 485 unique, pre-trained models, and where available, data about their training checkpoints, computational cost (FLOPs), training epochs, and the seed, along with 1.9 million performance metrics of loss and downstream tasks. The models differed in their architectures, weights, and so on. Using these models, the researchers fit over 1,000 scaling laws and compared their accuracy across architectures, model sizes, and training regimes, as well as testing how the number of models, inclusion of intermediate training checkpoints, and partial training impacted the predictive power of scaling laws to target models. They used measurements of absolute relative error (ARE); this is the difference between the scaling law’s prediction and the observed loss of a large, trained model. With this, the team compared the scaling laws, and after analysis, distilled practical recommendations for AI practitioners about what makes effective scaling laws.&lt;/p&gt;&lt;p&gt;Their shared guidelines walk the developer through steps and options to consider and expectations. First, it’s critical to decide on a compute budget and target model accuracy. The team found that 4 percent ARE is about the best achievable accuracy one could expect due to random seed noise, but up to 20 percent ARE is still useful for decision-making. The researchers identified several factors that improve predictions, like including intermediate training checkpoints, rather than relying only on final losses; this made scaling laws more reliable. However, very early training data before 10 billion tokens are noisy, reduce accuracy, and should be discarded. They recommend prioritizing training more models across a spread of sizes to improve robustness of the scaling law’s prediction, not just larger models; selecting five models provides a solid starting point.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Generally, including larger models improves prediction, but costs can be saved by partially training the target model to about 30 percent of its dataset and using that for extrapolation. If the budget is considerably constrained, developers should consider training one smaller model within the target model family and borrow scaling law parameters from a model family with similar architecture; however, this may not work for encoder–decoder models. Lastly, the MIT-IBM research group found that when scaling laws were compared across model families, there was strong correlation between two sets of hyperparameters, meaning that three of the five hyperparameters explained nearly all of the variation and could likely capture the model behavior. Together, these guidelines provide a systematic approach to making scaling law estimation more efficient, reliable, and accessible for AI researchers working under varying budget constraints.&lt;/p&gt;&lt;p&gt;Several surprises arose during this work: small models partially trained are still very predictive, and further, the intermediate training stages from a fully trained model can be used (as if they are individual models) for prediction of another target model. “Basically, you don’t pay anything in the training, because you already trained the full model, so the half-trained model, for instance, is just a byproduct of what you did,” says Choshen. Another feature Andreas pointed out was that, when aggregated, the variability across model families and different experiments jumped out and was noisier than expected. Unexpectedly, the researchers found that it’s possible to utilize the scaling laws on large models to predict performance down to smaller models. Other research in the field has hypothesized that smaller models were a “different beast” compared to large ones; however, Choshen disagrees. “If they’re totally different, they should have shown totally different behavior, and they don’t.”&lt;/p&gt;&lt;p&gt;While this work focused on model training time, the researchers plan to extend their analysis to model inference. Andreas says it’s not, “how does my model get better as I add more training data or more parameters, but instead as I let it think for longer, draw more samples. I think there are definitely lessons to be learned here about how to also build predictive models of how much thinking you need to do at run time.” He says the theory of inference time scaling laws might become even more critical because, “it’s not like I'm going to train one model and then be done. [Rather,] it’s every time a user comes to me, they’re going to have a new query, and I need to figure out how hard [my model needs] to think to come up with the best answer. So, being able to build those kinds of predictive models, like we’re doing in this paper, is even more important.”&lt;/p&gt;&lt;p&gt;This research was supported, in part, by the MIT-IBM Watson AI Lab and a Sloan Research Fellowship.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/Increasing-LLM-size.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When researchers are building large language models (LLMs), they aim to maximize performance under a particular computational and financial budget. Since training a model can amount to millions of dollars, developers need to be judicious with cost-impacting decisions about, for instance, the model architecture, optimizers, and training datasets before committing to a model. To anticipate the quality and accuracy of a large model’s predictions, practitioners often turn to scaling laws: using smaller, cheaper models to try to approximate the performance of a much larger target model. The challenge, however, is that there are thousands of ways to create a scaling law.&lt;/p&gt;&lt;p&gt;New work from MIT and MIT-IBM Watson AI Lab researchers addresses this by amassing and releasing a collection of hundreds of models and metrics concerning training and performance to approximate more than a thousand scaling laws. From this, the team developed a meta-analysis and guide for how to select small models and estimate scaling laws for different LLM model families, so that the budget is optimally applied toward generating reliable performance predictions.&lt;/p&gt;&lt;p&gt;“The notion that you might want to try to build mathematical models of the training process is a couple of years old, but I think what was new here is that most of the work that people had been doing before is saying, ‘can we say something post-hoc about what happened when we trained all of these models, so that when we’re trying to figure out how to train a new large-scale model, we can make the best decisions about how to use our compute budget?’” says Jacob Andreas, associate professor in the Department of Electrical Engineering and Computer Science and principal investigator with the MIT-IBM Watson AI Lab.&lt;/p&gt;&lt;p&gt;The research was recently presented at the International Conference on Machine Learning by Andreas, along with MIT-IBM Watson AI Lab researchers Leshem Choshen and Yang Zhang of IBM Research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Extrapolating performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;No matter how you slice it, developing LLMs is an expensive endeavor: from decision-making regarding the numbers of parameters and tokens, data selection and size, and training techniques to determining output accuracy and tuning to the target applications and tasks. Scaling laws offer a way to forecast model behavior by relating a large model’s loss to the performance of smaller, less-costly models from the same family, avoiding the need to fully train every candidate. Mainly, the differences between the smaller models are the number of parameters and token training size. According to Choshen, elucidating scaling laws not only enable better pre-training decisions, but also democratize the field by enabling researchers without vast resources to understand and build effective scaling laws.&lt;/p&gt;&lt;p&gt;The functional form of scaling laws is relatively simple, incorporating components from the small models that capture the number of parameters and their scaling effect, the number of training tokens and their scaling effect, and the baseline performance for the model family of interest. Together, they help researchers estimate a target large model’s performance loss; the smaller the loss, the better the target model’s outputs are likely to be.&lt;/p&gt;&lt;p&gt;These laws allow research teams to weigh trade-offs efficiently and to test how best to allocate limited resources. They’re particularly useful for evaluating scaling of a certain variable, like the number of tokens, and for A/B testing of different pre-training setups.&lt;/p&gt;&lt;p&gt;In general, scaling laws aren’t new; however, in the field of AI, they emerged as models grew and costs skyrocketed. “It’s like scaling laws just appeared at some point in the field,” says Choshen. “They started getting attention, but no one really tested how good they are and what you need to do to make a good scaling law.” Further, scaling laws were themselves also a black box, in a sense. “Whenever people have created scaling laws in the past, it has always just been one model, or one model family, and one dataset, and one developer,” says Andreas. “There hadn’t really been a lot of systematic meta-analysis, as everybody is individually training their own scaling laws. So, [we wanted to know,] are there high-level trends that you see across those things?”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To investigate this, Choshen, Andreas, and Zhang created a large dataset. They collected LLMs from 40 model families, including Pythia, OPT, OLMO, LLaMA, Bloom, T5-Pile, ModuleFormer mixture-of-experts, GPT, and other families. These included 485 unique, pre-trained models, and where available, data about their training checkpoints, computational cost (FLOPs), training epochs, and the seed, along with 1.9 million performance metrics of loss and downstream tasks. The models differed in their architectures, weights, and so on. Using these models, the researchers fit over 1,000 scaling laws and compared their accuracy across architectures, model sizes, and training regimes, as well as testing how the number of models, inclusion of intermediate training checkpoints, and partial training impacted the predictive power of scaling laws to target models. They used measurements of absolute relative error (ARE); this is the difference between the scaling law’s prediction and the observed loss of a large, trained model. With this, the team compared the scaling laws, and after analysis, distilled practical recommendations for AI practitioners about what makes effective scaling laws.&lt;/p&gt;&lt;p&gt;Their shared guidelines walk the developer through steps and options to consider and expectations. First, it’s critical to decide on a compute budget and target model accuracy. The team found that 4 percent ARE is about the best achievable accuracy one could expect due to random seed noise, but up to 20 percent ARE is still useful for decision-making. The researchers identified several factors that improve predictions, like including intermediate training checkpoints, rather than relying only on final losses; this made scaling laws more reliable. However, very early training data before 10 billion tokens are noisy, reduce accuracy, and should be discarded. They recommend prioritizing training more models across a spread of sizes to improve robustness of the scaling law’s prediction, not just larger models; selecting five models provides a solid starting point.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Generally, including larger models improves prediction, but costs can be saved by partially training the target model to about 30 percent of its dataset and using that for extrapolation. If the budget is considerably constrained, developers should consider training one smaller model within the target model family and borrow scaling law parameters from a model family with similar architecture; however, this may not work for encoder–decoder models. Lastly, the MIT-IBM research group found that when scaling laws were compared across model families, there was strong correlation between two sets of hyperparameters, meaning that three of the five hyperparameters explained nearly all of the variation and could likely capture the model behavior. Together, these guidelines provide a systematic approach to making scaling law estimation more efficient, reliable, and accessible for AI researchers working under varying budget constraints.&lt;/p&gt;&lt;p&gt;Several surprises arose during this work: small models partially trained are still very predictive, and further, the intermediate training stages from a fully trained model can be used (as if they are individual models) for prediction of another target model. “Basically, you don’t pay anything in the training, because you already trained the full model, so the half-trained model, for instance, is just a byproduct of what you did,” says Choshen. Another feature Andreas pointed out was that, when aggregated, the variability across model families and different experiments jumped out and was noisier than expected. Unexpectedly, the researchers found that it’s possible to utilize the scaling laws on large models to predict performance down to smaller models. Other research in the field has hypothesized that smaller models were a “different beast” compared to large ones; however, Choshen disagrees. “If they’re totally different, they should have shown totally different behavior, and they don’t.”&lt;/p&gt;&lt;p&gt;While this work focused on model training time, the researchers plan to extend their analysis to model inference. Andreas says it’s not, “how does my model get better as I add more training data or more parameters, but instead as I let it think for longer, draw more samples. I think there are definitely lessons to be learned here about how to also build predictive models of how much thinking you need to do at run time.” He says the theory of inference time scaling laws might become even more critical because, “it’s not like I'm going to train one model and then be done. [Rather,] it’s every time a user comes to me, they’re going to have a new query, and I need to figure out how hard [my model needs] to think to come up with the best answer. So, being able to build those kinds of predictive models, like we’re doing in this paper, is even more important.”&lt;/p&gt;&lt;p&gt;This research was supported, in part, by the MIT-IBM Watson AI Lab and a Sloan Research Fellowship.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/how-build-ai-scaling-laws-efficient-llm-training-budget-maximization-0916</guid><pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate></item><item><title>D-ID acquires Berlin-based video startup Simpleshow (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/d-id-acquires-berlin-based-video-startup-simpleshow/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/ai-avatar-simpleshow-2154151760.jpg?resize=1200,826" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Video generation and editing platform D-ID said Tuesday that it has acquired Berlin-based B2B video creation platform Simpleshow. The companies didn’t disclose financial terms of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s product will operate under D-ID’s umbrella, and eventually the two platforms will merge, D-ID chief executive Gil Perry told TechCrunch. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Simpleshow, founded in 2008, has raised over $20 million in funding, according to Crunchbase data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has offices in Berlin, Luxembourg, London, Miami, Singapore, Hong Kong, and Tokyo. As part of the merger, the company will have consolidated offices in Berlin, Tel Aviv, and the United States. D-ID didn’t mention Simpleshow’s team size but said that the combined entity will have 140 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Simpleshow initially approached us for a strategic partnership. We saw that there was synergy between management teams and products,” said Perry. “We felt that we needed to increase our speed in capturing a large [part of the enterprise avatar video] market. We thought acquiring Simpleshow would give us the necessary boost in that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies are seeing a strong future of digital avatars for different kinds of videos, including training, marketing, and sales. D-ID already has a suite of AI-powered interactive avatars that it offers to its clients. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s CEO Karsten Boehrs said that when he joined the company over a decade ago, it was largely an agency producing videos for businesses and enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To achieve scale and serve more clients internationally, we decided to build a SaaS-based tech platform,” Boehrs told TechCrunch. “One of the first tools we launched was a text-to-video tool for our clients in 2017.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boehrs added that in the last few years, with the rise of AI, it started conversations with companies like Synthesia for potential partnerships and eventually landed on D-ID to get acquired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside its product, Simpleshow is also bringing more than 1,500 enterprise clients, including Adobe, Audio, Airbus, Microsoft, Bayer, HP, T-Mobile, McDonald’s, eBay, and Deutsche Bank. D-ID’s Perry mentioned that this will boost the company’s bottom line and bring it closer to profitability.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Going forward, D-ID wants to build interactive training videos, which will let users interrupt a video presented by an avatar and ask them a question or take a quiz. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has strong competition for enterprise adoption of digital avatars in companies like Synthesia and Soul Machines. Companies such as Google and McKinsey are also developing solutions to let clients use digital avatars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has raised $60 million in funding to date. The company said it has secured funding to bankroll the acquisition, but it didn’t disclose the money.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/ai-avatar-simpleshow-2154151760.jpg?resize=1200,826" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Video generation and editing platform D-ID said Tuesday that it has acquired Berlin-based B2B video creation platform Simpleshow. The companies didn’t disclose financial terms of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s product will operate under D-ID’s umbrella, and eventually the two platforms will merge, D-ID chief executive Gil Perry told TechCrunch. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Simpleshow, founded in 2008, has raised over $20 million in funding, according to Crunchbase data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has offices in Berlin, Luxembourg, London, Miami, Singapore, Hong Kong, and Tokyo. As part of the merger, the company will have consolidated offices in Berlin, Tel Aviv, and the United States. D-ID didn’t mention Simpleshow’s team size but said that the combined entity will have 140 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Simpleshow initially approached us for a strategic partnership. We saw that there was synergy between management teams and products,” said Perry. “We felt that we needed to increase our speed in capturing a large [part of the enterprise avatar video] market. We thought acquiring Simpleshow would give us the necessary boost in that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies are seeing a strong future of digital avatars for different kinds of videos, including training, marketing, and sales. D-ID already has a suite of AI-powered interactive avatars that it offers to its clients. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s CEO Karsten Boehrs said that when he joined the company over a decade ago, it was largely an agency producing videos for businesses and enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To achieve scale and serve more clients internationally, we decided to build a SaaS-based tech platform,” Boehrs told TechCrunch. “One of the first tools we launched was a text-to-video tool for our clients in 2017.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boehrs added that in the last few years, with the rise of AI, it started conversations with companies like Synthesia for potential partnerships and eventually landed on D-ID to get acquired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside its product, Simpleshow is also bringing more than 1,500 enterprise clients, including Adobe, Audio, Airbus, Microsoft, Bayer, HP, T-Mobile, McDonald’s, eBay, and Deutsche Bank. D-ID’s Perry mentioned that this will boost the company’s bottom line and bring it closer to profitability.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Going forward, D-ID wants to build interactive training videos, which will let users interrupt a video presented by an avatar and ask them a question or take a quiz. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has strong competition for enterprise adoption of digital avatars in companies like Synthesia and Soul Machines. Companies such as Google and McKinsey are also developing solutions to let clients use digital avatars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has raised $60 million in funding to date. The company said it has secured funding to bankroll the acquisition, but it didn’t disclose the money.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/d-id-acquires-berlin-based-video-startup-simpleshow/</guid><pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate></item><item><title>OpenAI will apply new restrictions to ChatGPT users under 18 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/openai-will-apply-new-restrictions-to-chatgpt-users-under-18/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced on Tuesday a raft of new user policies, including a pledge to significantly change how ChatGPT interacts with users under the age of 18.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We prioritize safety ahead of privacy and freedom for teens,” the post reads. “This is a new and powerful technology, and we believe minors need significant protection.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The changes for underage users deal specifically with conversations involving sexual topics or self-harm. Under the new policy, ChatGPT will be trained to no longer engage in “flirtatious talk” with underage users, and additional guardrails will be placed around discussions of suicide. If an underage user uses ChatGPT to imagine suicidal scenarios, the service will attempt to contact their parents or, in particularly severe cases, local police.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sadly, these scenarios are not hypotheticals. OpenAI is currently facing a wrongful death lawsuit from the parents of Adam Raine, who died by suicide after months of interactions with ChatGPT. Character.AI, another consumer chatbot, is facing a similar lawsuit. While the risks are particularly urgent for underage users considering self-harm, the broader phenomenon of chatbot-fueled delusion has drawn widespread concern, particularly as consumer chatbots have become capable of more sustained and detailed interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with the content-based restrictions, parents who register an underage user account will have the power to set “blackout hours” in which ChatGPT is not available, a feature that was not previously available.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new ChatGPT policies come on the same day as a Senate Judiciary Committee hearing titled “Examining the Harm of AI Chatbots.” The hearing was announced by Sen. Josh Hawley (R-MO) in August. Adam Raine’s father is scheduled to speak at the hearing, among other guests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hearing will also focus on the findings of a Reuters investigation that unearthed policy documents apparently encouraging sexual conversations with underage users. Meta updated its chatbot policies in the wake of the report.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Separating underage users will be a significant technical challenge, and OpenAI detailed its approach in a separate blog post. The service is “building toward a long-term system to understand whether someone is over or under 18,” but in the many ambiguous cases, the system will default toward the more restrictive rules. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For concerned parents, the most reliable way to ensure an underage user is recognized is to link the teen’s account to an existing parent account. This also enables the system to directly alert parents when the teen user is believed to be in distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the same post, Altman emphasized OpenAI’s ongoing commitment to user privacy and giving adult users broad freedom in how they choose to interact with ChatGPT. “We realize that these principles are in conflict,” the post concludes, “and not everyone will agree with how we are resolving that conflict.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you or someone you know needs help, call 1-800-273-8255 for the &lt;/em&gt;&lt;em&gt;National Suicide Prevention Lifeline&lt;/em&gt;&lt;em&gt;. You can also text HOME to 741-741 for free; text 988; or get 24-hour support from the &lt;/em&gt;&lt;em&gt;Crisis Text Line&lt;/em&gt;&lt;em&gt;. Outside of the U.S., please visit the &lt;/em&gt;&lt;em&gt;International Association for Suicide Prevention&lt;/em&gt;&lt;em&gt; for a database of resources.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced on Tuesday a raft of new user policies, including a pledge to significantly change how ChatGPT interacts with users under the age of 18.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We prioritize safety ahead of privacy and freedom for teens,” the post reads. “This is a new and powerful technology, and we believe minors need significant protection.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The changes for underage users deal specifically with conversations involving sexual topics or self-harm. Under the new policy, ChatGPT will be trained to no longer engage in “flirtatious talk” with underage users, and additional guardrails will be placed around discussions of suicide. If an underage user uses ChatGPT to imagine suicidal scenarios, the service will attempt to contact their parents or, in particularly severe cases, local police.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sadly, these scenarios are not hypotheticals. OpenAI is currently facing a wrongful death lawsuit from the parents of Adam Raine, who died by suicide after months of interactions with ChatGPT. Character.AI, another consumer chatbot, is facing a similar lawsuit. While the risks are particularly urgent for underage users considering self-harm, the broader phenomenon of chatbot-fueled delusion has drawn widespread concern, particularly as consumer chatbots have become capable of more sustained and detailed interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with the content-based restrictions, parents who register an underage user account will have the power to set “blackout hours” in which ChatGPT is not available, a feature that was not previously available.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new ChatGPT policies come on the same day as a Senate Judiciary Committee hearing titled “Examining the Harm of AI Chatbots.” The hearing was announced by Sen. Josh Hawley (R-MO) in August. Adam Raine’s father is scheduled to speak at the hearing, among other guests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hearing will also focus on the findings of a Reuters investigation that unearthed policy documents apparently encouraging sexual conversations with underage users. Meta updated its chatbot policies in the wake of the report.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Separating underage users will be a significant technical challenge, and OpenAI detailed its approach in a separate blog post. The service is “building toward a long-term system to understand whether someone is over or under 18,” but in the many ambiguous cases, the system will default toward the more restrictive rules. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For concerned parents, the most reliable way to ensure an underage user is recognized is to link the teen’s account to an existing parent account. This also enables the system to directly alert parents when the teen user is believed to be in distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the same post, Altman emphasized OpenAI’s ongoing commitment to user privacy and giving adult users broad freedom in how they choose to interact with ChatGPT. “We realize that these principles are in conflict,” the post concludes, “and not everyone will agree with how we are resolving that conflict.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you or someone you know needs help, call 1-800-273-8255 for the &lt;/em&gt;&lt;em&gt;National Suicide Prevention Lifeline&lt;/em&gt;&lt;em&gt;. You can also text HOME to 741-741 for free; text 988; or get 24-hour support from the &lt;/em&gt;&lt;em&gt;Crisis Text Line&lt;/em&gt;&lt;em&gt;. Outside of the U.S., please visit the &lt;/em&gt;&lt;em&gt;International Association for Suicide Prevention&lt;/em&gt;&lt;em&gt; for a database of resources.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/openai-will-apply-new-restrictions-to-chatgpt-users-under-18/</guid><pubDate>Tue, 16 Sep 2025 16:28:55 +0000</pubDate></item><item><title>Learn Your Way: Reimagining textbooks with generative AI (The latest research from Google)</title><link>https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Avinatan Hassidim, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, and Yoav Bar Sinai. Special thanks to our executive champions: Niv Efron, Avinatan Hassidim, Yossi Matias and Ben Gomes.&lt;/i&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Avinatan Hassidim, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, and Yoav Bar Sinai. Special thanks to our executive champions: Niv Efron, Avinatan Hassidim, Yossi Matias and Ben Gomes.&lt;/i&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</guid><pubDate>Tue, 16 Sep 2025 17:01:00 +0000</pubDate></item><item><title>Waymo’s Tekedra Mawakana on Scaling Self-Driving Beyond the Hype (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/waymos-tekedra-mawakana-on-the-truth-behind-autonomous-vehicles-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicles have long been touted as “just around the corner,” but the reality of bringing self-driving cars to the streets is far from simple. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — October 27–29 at Moscone West in San Francisco — Waymo co-CEO &lt;strong&gt;Tekedra Mawakana&lt;/strong&gt; joins the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;  for a wide-ranging conversation on the true state of AVs and where the industry goes from here. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Tekedra Mawakana" class="wp-image-3032642" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Tekedra-Mawakana-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-self-driving-reality-check"&gt;Inside the self-driving reality check&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While headlines often highlight crashes, controversies, or overblown promises, Mawakana has spent years navigating the real-world path to autonomous mobility. At Disrupt, she’ll dig into what it actually takes to scale AV deployment — from rider safety and public trust to regulation, operations, and competitive pressure from Tesla and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This session isn’t about vague timelines or flashy demos. It’s about what’s working, what still needs work, and what it means to bring autonomy to life at scale. Whether you’re a founder, investor, or simply curious about the road ahead, you won’t want to miss it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Waymo jaguar ipace autonomous vehicle" class="wp-image-2320477" height="453" src="https://techcrunch.com/wp-content/uploads/2022/05/IPACE_3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waymo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-leader-behind-the-wheel"&gt;Meet the leader behind the wheel&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tekedra Mawakana brings more than two decades of experience shaping global strategy at major tech companies. As co-CEO of Waymo, she guides the company’s mission to bring the Waymo Driver to the masses and lead the next generation of autonomous innovation. She also serves on Intuit’s board and advises several technology and social impact ventures.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-future-of-mobility-live-at-disrupt"&gt;The future of mobility, live at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Waymo’s story is a central chapter in the future of transportation, and this session offers a rare inside look at the journey behind the headlines. Join us at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, where 10,000+ startup and VC leaders gather to shape what’s next. &lt;strong&gt;Register today&lt;/strong&gt; and save up to &lt;strong&gt;$650&lt;/strong&gt; before rates rise.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicles have long been touted as “just around the corner,” but the reality of bringing self-driving cars to the streets is far from simple. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — October 27–29 at Moscone West in San Francisco — Waymo co-CEO &lt;strong&gt;Tekedra Mawakana&lt;/strong&gt; joins the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;  for a wide-ranging conversation on the true state of AVs and where the industry goes from here. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Tekedra Mawakana" class="wp-image-3032642" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Tekedra-Mawakana-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-self-driving-reality-check"&gt;Inside the self-driving reality check&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While headlines often highlight crashes, controversies, or overblown promises, Mawakana has spent years navigating the real-world path to autonomous mobility. At Disrupt, she’ll dig into what it actually takes to scale AV deployment — from rider safety and public trust to regulation, operations, and competitive pressure from Tesla and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This session isn’t about vague timelines or flashy demos. It’s about what’s working, what still needs work, and what it means to bring autonomy to life at scale. Whether you’re a founder, investor, or simply curious about the road ahead, you won’t want to miss it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Waymo jaguar ipace autonomous vehicle" class="wp-image-2320477" height="453" src="https://techcrunch.com/wp-content/uploads/2022/05/IPACE_3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waymo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-leader-behind-the-wheel"&gt;Meet the leader behind the wheel&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tekedra Mawakana brings more than two decades of experience shaping global strategy at major tech companies. As co-CEO of Waymo, she guides the company’s mission to bring the Waymo Driver to the masses and lead the next generation of autonomous innovation. She also serves on Intuit’s board and advises several technology and social impact ventures.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-future-of-mobility-live-at-disrupt"&gt;The future of mobility, live at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Waymo’s story is a central chapter in the future of transportation, and this session offers a rare inside look at the journey behind the headlines. Join us at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, where 10,000+ startup and VC leaders gather to shape what’s next. &lt;strong&gt;Register today&lt;/strong&gt; and save up to &lt;strong&gt;$650&lt;/strong&gt; before rates rise.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/waymos-tekedra-mawakana-on-the-truth-behind-autonomous-vehicles-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 16 Sep 2025 17:35:00 +0000</pubDate></item><item><title>[NEW] Gemini tops the App Store thanks to new AI image model, Nano Banana (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/gemini-tops-the-app-store-thanks-to-new-ai-image-model-nano-banana/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini’s mobile adoption has been soaring since the August launch of its Nano Banana image editor model, which has received positive reviews, particularly from users who say they can now more easily perform complex edits and create realistic images. The app has climbed to the top of global app stores’ charts and has seen a 45% month-over-month increase in downloads in the month of September so far, according to new data provided by app intelligence firm Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the month is only half over, Gemini’s app has already gained 12.6 million downloads in September, up from 8.7 million in August. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before this month, Gemini had only gotten as high as No. 3 on the U.S. App Store on January 28, 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after Nano Banana’s release, Gemini reached the No. 2 spot on the U.S. App Store on September 8. It then became the No. 1 app on September 12, where it has remained, after knocking OpenAI’s ChatGPT down to No. 2. No other dedicated AI apps are in the top 10 on the App Store at this time. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046478" height="365" src="https://techcrunch.com/wp-content/uploads/2025/09/gemini-nano-banana-ios-downloads-spike.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also became one of the top five iPhone apps overall in 108 countries globally, Appfigures’ data indicates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google Play, Gemini jumped from the No. 26 overall top app in the U.S. on September 8 to become the No. 2 app as of Monday. However, despite Android being Google’s own platform, ChatGPT remains in the top spot as of the time of writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been touting Gemini’s growth, as more mainstream users have been trying out the new image-editing features. For instance, Google Gemini and Google Labs VP Josh Woodward shared on X on September 8 that the app had gained 23 million first-time users since the Nano Banana model launched, and those users had shared over 500 million images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app’s rapid growth is also driving increases in consumer spending. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of the $6.3 million Gemini generated this year on iOS devices, $1.6 million was from the month of August, with much of that coming in after the Nano Banana model’s release. That’s up 1,291% from January’s figure of $115,000, Appfigures estimates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is also on track to at least match August’s number if not surpass it in September, as Gemini has pulled in $792,000 so far this month — roughly half of August’s total. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This year, Gemini’s app has been downloaded 103.7 million times and has seen 185.4 million downloads to date since its launch on Android in February 2024 and its expansion to iOS later that year.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini’s mobile adoption has been soaring since the August launch of its Nano Banana image editor model, which has received positive reviews, particularly from users who say they can now more easily perform complex edits and create realistic images. The app has climbed to the top of global app stores’ charts and has seen a 45% month-over-month increase in downloads in the month of September so far, according to new data provided by app intelligence firm Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the month is only half over, Gemini’s app has already gained 12.6 million downloads in September, up from 8.7 million in August. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before this month, Gemini had only gotten as high as No. 3 on the U.S. App Store on January 28, 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after Nano Banana’s release, Gemini reached the No. 2 spot on the U.S. App Store on September 8. It then became the No. 1 app on September 12, where it has remained, after knocking OpenAI’s ChatGPT down to No. 2. No other dedicated AI apps are in the top 10 on the App Store at this time. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046478" height="365" src="https://techcrunch.com/wp-content/uploads/2025/09/gemini-nano-banana-ios-downloads-spike.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also became one of the top five iPhone apps overall in 108 countries globally, Appfigures’ data indicates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google Play, Gemini jumped from the No. 26 overall top app in the U.S. on September 8 to become the No. 2 app as of Monday. However, despite Android being Google’s own platform, ChatGPT remains in the top spot as of the time of writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been touting Gemini’s growth, as more mainstream users have been trying out the new image-editing features. For instance, Google Gemini and Google Labs VP Josh Woodward shared on X on September 8 that the app had gained 23 million first-time users since the Nano Banana model launched, and those users had shared over 500 million images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app’s rapid growth is also driving increases in consumer spending. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of the $6.3 million Gemini generated this year on iOS devices, $1.6 million was from the month of August, with much of that coming in after the Nano Banana model’s release. That’s up 1,291% from January’s figure of $115,000, Appfigures estimates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is also on track to at least match August’s number if not surpass it in September, as Gemini has pulled in $792,000 so far this month — roughly half of August’s total. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This year, Gemini’s app has been downloaded 103.7 million times and has seen 185.4 million downloads to date since its launch on Android in February 2024 and its expansion to iOS later that year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/gemini-tops-the-app-store-thanks-to-new-ai-image-model-nano-banana/</guid><pubDate>Tue, 16 Sep 2025 18:07:40 +0000</pubDate></item><item><title>[NEW] CodeRabbit raises $60M, valuing the 2-year-old AI code review startup at $550M (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/coderabbit-raises-60m-valuing-the-2-year-old-ai-code-review-startup-at-550m/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2080972792.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Harjot Gill was running FluxNinja, an observability startup he co-founded several years after selling his first startup Netsil to Nutanix in 2018, when he noticed a curious trend. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had a team of remote engineers who were starting to adopt AI code generation on GitHub Copilot,” Gill told TechCrunch. “We saw that adoption happen, and it was very clear to me that as a second-order effect, it’s going to cause bottlenecks in the code review.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In early 2023, Gill started CodeRabbit, an AI-powered code review platform, and it acquired FlexNinja.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gill’s prediction has come true: developers are now regularly using AI coding assistants to generate code, but the output is often buggy, forcing engineers to spend a lot of time on corrections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit can help catch some of the errors. The business has been growing 20% a month and is now making more than $15 million in annual recurring revenue (ARR), according to Gill.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors find the startup’s growth exciting. On Tuesday, CodeRabbit announced that it raised a $60 million Series B, valuing the company at $550 million. The round, which brought the startup’s total funding to $88 million, was led by Scale Venture Partners with participation of NVentures, Nvidia’s venture capital arm, and returning investors including CRV. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit is helping companies like Chegg, Groupon, and Mercury, along with over 8,000 other businesses, save time on the famously frustrating task of code review, which has become even more time-consuming with the rise of AI-generated code.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since CodeRabbit understands a company’s codebase, it can identify bugs and provide feedback, acting like a coworker, Gill said.&amp;nbsp;He added that companies using CodeRabbit can cut the number of humans working on code-review by half.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with most areas of AI, CodeRabbit has competition. Startup rivals include Graphite, which secured a $52 million Series B led by Accel earlier this year, and Greptile, which we reported is in talks for a $30 million Series A round with Benchmark. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While leading AI coding assistants like Anthropic’s Claude Code and Cursor also offer AI-powered code review capabilities, Gill is betting that customers will prefer a standalone offering in the long term. “CodeRabbit is a lot more comprehensive in terms of depth and technical breadth than bundled solutions,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether his prediction will turn out to be correct remains to be seen. But for now, thousands of developers are clearly happy to pay CodeRabbit $30 a month. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even with the growing popularity of AI code review tools like CodeRabbit, AI solutions still can’t yet be fully trusted to fix the bugs and “unusable” code written by AI. The unreliability of AI-generated code has given rise to a new corporate role: the vibe code cleanup specialist.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2080972792.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Harjot Gill was running FluxNinja, an observability startup he co-founded several years after selling his first startup Netsil to Nutanix in 2018, when he noticed a curious trend. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had a team of remote engineers who were starting to adopt AI code generation on GitHub Copilot,” Gill told TechCrunch. “We saw that adoption happen, and it was very clear to me that as a second-order effect, it’s going to cause bottlenecks in the code review.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In early 2023, Gill started CodeRabbit, an AI-powered code review platform, and it acquired FlexNinja.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gill’s prediction has come true: developers are now regularly using AI coding assistants to generate code, but the output is often buggy, forcing engineers to spend a lot of time on corrections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit can help catch some of the errors. The business has been growing 20% a month and is now making more than $15 million in annual recurring revenue (ARR), according to Gill.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors find the startup’s growth exciting. On Tuesday, CodeRabbit announced that it raised a $60 million Series B, valuing the company at $550 million. The round, which brought the startup’s total funding to $88 million, was led by Scale Venture Partners with participation of NVentures, Nvidia’s venture capital arm, and returning investors including CRV. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit is helping companies like Chegg, Groupon, and Mercury, along with over 8,000 other businesses, save time on the famously frustrating task of code review, which has become even more time-consuming with the rise of AI-generated code.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since CodeRabbit understands a company’s codebase, it can identify bugs and provide feedback, acting like a coworker, Gill said.&amp;nbsp;He added that companies using CodeRabbit can cut the number of humans working on code-review by half.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with most areas of AI, CodeRabbit has competition. Startup rivals include Graphite, which secured a $52 million Series B led by Accel earlier this year, and Greptile, which we reported is in talks for a $30 million Series A round with Benchmark. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While leading AI coding assistants like Anthropic’s Claude Code and Cursor also offer AI-powered code review capabilities, Gill is betting that customers will prefer a standalone offering in the long term. “CodeRabbit is a lot more comprehensive in terms of depth and technical breadth than bundled solutions,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether his prediction will turn out to be correct remains to be seen. But for now, thousands of developers are clearly happy to pay CodeRabbit $30 a month. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even with the growing popularity of AI code review tools like CodeRabbit, AI solutions still can’t yet be fully trusted to fix the bugs and “unusable” code written by AI. The unreliability of AI-generated code has given rise to a new corporate role: the vibe code cleanup specialist.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/coderabbit-raises-60m-valuing-the-2-year-old-ai-code-review-startup-at-550m/</guid><pubDate>Tue, 16 Sep 2025 19:00:00 +0000</pubDate></item><item><title>[NEW] Silicon Valley bets big on ‘environments’ to train AI agents (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/silicon-valley-bets-big-on-environments-to-train-ai-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Big Tech CEOs have touted visions of AI agents that can autonomously use software applications to complete tasks for people. But take today’s consumer AI agents out for a spin, whether it’s OpenAI’s ChatGPT Agent or Perplexity’s Comet, and you’ll quickly realize how limited the technology still is. Making AI agents more robust may take a new set of techniques that the industry is still discovering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of those techniques is carefully simulating workspaces where agents can be trained on multi-step tasks — known as reinforcement learning (RL) environments. Similarly to how labeled datasets powered the last wave of AI, RL environments are starting to look like a critical element in the development of agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI researchers, founders, and investors tell TechCrunch that leading AI labs are now demanding more RL environments, and there’s no shortage of startups hoping to supply them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All the big AI labs are building RL environments in-house,” said Jennifer Li, general partner at Andreessen Horowitz, in an interview with TechCrunch. “But as you can imagine, creating these datasets is very complex, so AI labs are also looking at third party vendors that can create high quality environments and evaluations. Everyone is looking at this space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push for RL environments has minted a new class of well-funded startups, such as Mechanize and Prime Intellect, that aim to lead the space. Meanwhile, large data-labeling companies like Mercor and Surge say they’re investing more in RL environments to keep pace with the industry’s shifts from static datasets to interactive simulations. The major labs are considering investing heavily too: according to The Information, leaders at Anthropic have discussed spending more than $1 billion on RL environments over the next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope for investors and founders is that one of these startups emerge as the “Scale AI for environments,” referring to the $29 billion data labelling powerhouse that powered the chatbot era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether RL environments will truly push the frontier of AI progress.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-an-rl-environment"&gt;What is an RL environment?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At their core, RL environments are training grounds that simulate what an AI agent would be doing in a real software application. One founder described building them in recent interview “like creating a very boring video game.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, an environment could simulate a Chrome browser and task an AI agent with purchasing a pair of socks on Amazon. The agent is graded on its performance and sent a reward signal when it succeeds (in this case, buying a worthy pair of socks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While such a task sounds relatively simple, there are a lot of places where an AI agent could get tripped up. It might get lost navigating the web page’s drop down menus, or buy too many socks. And because developers can’t predict exactly what wrong turn an agent will take, the environment itself has to be robust enough to capture any unexpected behavior, and still deliver useful feedback. That makes building environments far more complex than a static dataset.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some environments are quite elaborate, allowing for AI agents to use tools, access the internet, or use various software applications to complete a given task. Others are more narrow, aimed at helping an agent learn specific tasks in enterprise software applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While RL environments are the hot thing in Silicon Valley right now, there’s a lot of precedent for using this technique. One of OpenAI’s first projects back in 2016 was building “RL Gyms,” which were quite similar to the modern conception of environments. The same year, Google DeepMind’s AlphaGo AI system beat a world champion at the board game, Go. It also used RL techniques within a simulated environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s unique about today’s environments is that researchers are trying to build computer-using AI agents with large transformer models. Unlike AlphaGo, which was a specialized AI system working in a closed environments, today’s AI agents are trained to have more general capabilities. AI researchers today have a stronger starting point, but also a complicated goal where more can go wrong. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-crowded-field"&gt;&lt;strong&gt;A crowded field&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI data labeling companies like Scale AI, Surge, and Mercor are trying to meet the moment and build out RL environments. These companies have more resources than many startups in the space, as well as deep relationships with AI labs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surge CEO Edwin Chen tells TechCrunch he’s recently seen a “significant increase” in demand for RL environments within AI labs. Surge — which reportedly generated $1.2 billion in revenue last year from working with AI labs like OpenAI, Google, Anthropic and Meta — recently spun up a new internal organization specifically tasked with building out RL environments, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close behind Surge is Mercor, a startup valued at $10 billion, which has also worked with OpenAI, Meta, and Anthropic. Mercor is pitching investors on its business building RL environments for domain specific tasks such as coding, healthcare, and law, according to marketing materials seen by TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor CEO Brendan Foody told TechCrunch in an interview that “few understand how large the opportunity around RL environments truly is.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI used to dominate the data labeling space, but has lost ground since Meta invested $14 billion and hired away its CEO. Since then, Google and OpenAI dropped Scale AI as a data provider, and the startup even faces competition for data labelling work inside of Meta. But still, Scale is trying to meet the moment and build environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is just the nature of the business [Scale AI] is in,” said Chetan Rane, Scale AI’s head of product for agents and RL environments. “Scale has proven its ability to adapt quickly. We did this in the early days of autonomous vehicles, our first business unit. When ChatGPT came out, Scale AI adapted to that. And now, once again, we’re adapting to new frontier spaces like agents and environments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer players are focusing exclusively on environments from the outset. Among them is Mechanize, a startup founded roughly six months ago with the audacious goal of “automating all jobs.” However, co-founder Matthew Barnett tells TechCrunch that his firm is starting with RL environments for AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize aims to supply AI labs with a small number of robust RL environments, Barnett says, rather than larger data firms that create a wide range of simple RL environments. To this point, the startup is offering software engineers $500,000 salaries to build RL environments — far higher than an hourly contractor could earn working at Scale AI or Surge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize has already been working with Anthropic on RL environments, two sources familiar with the matter told TechCrunch. Mechanize and Anthropic declined to comment on the partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other startups are betting that RL environments will be influential outside of AI labs. Prime Intellect — a startup backed by AI researcher Andrej Karpathy, Founders Fund, and Menlo Ventures — is targeting smaller developers with its RL environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Prime Intellect launched an RL environments hub, which aims to be a “Hugging Face for RL environments.” The idea is to give open-source developers access to the same resources that large AI labs have, and sell those developers access to computational resources in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Training generally capable agents in RL environments can be more computational expensive than previous AI training techniques, according to Prime Intellect researcher Will Brown. Alongside startups building RL environments, there’s another opportunity for GPU providers that can power the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“RL environments are going to be too large for any one company to dominate,” said Brown in an interview. “Part of what we’re doing is just trying to build good open-source infrastructure around it. The service we sell is compute, so it is a convenient onramp to using GPUs, but we’re thinking of this more in the long term.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-it-scale"&gt;&lt;strong&gt;Will it scale?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The open question around RL environments is whether the technique will scale like previous AI training methods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reinforcement learning has powered some of the biggest leaps in AI over the past year, including models like OpenAI’s o1 and Anthropic’s Claude Opus 4. Those are particularly important breakthroughs because the methods previously used to improve AI models are now showing diminishing returns.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Environments are part of AI labs’ bigger bet on RL, which many believe will continue to drive progress as they add more data and computational resources to the process. Some of the OpenAI researchers behind o1 previously told TechCrunch that the company originally invested in AI reasoning models — which were created through investments in RL and test-time-compute — because they thought it would scale nicely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The best way to scale RL remains unclear, but environments seem like a promising contender. Instead of simply rewarding chatbots for text responses, they let agents operate in simulations with tools and computers at their disposal. That’s far more resource-intensive, but potentially more rewarding. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are skeptical that all these RL environments will pan out. Ross Taylor, a former AI research lead with Meta that co-founded General Reasoning, tells TechCrunch that RL environments are prone to reward hacking. This is a process in which AI models cheat in order to get a reward, without really doing the task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think people are underestimating how difficult it is to scale environments,” said Taylor. “Even the best publicly available [RL environments] typically don’t work without serious modification.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s Head of Engineering for its API business, Sherwin Wu, said in a recent podcast that he was “short” on RL environment startups. Wu noted that it’s a very competitive space, but also that AI research is evolving so quickly that it’s hard to serve AI labs well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karpathy, an investor in Prime Intellect that has called RL environments a potential breakthrough, has also voiced caution for the RL space more broadly. In a post on X, he raised concerns about how much more AI progress can be squeezed out of RL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am bullish on environments and agentic interactions but I am bearish on reinforcement learning specifically,” said Karpathy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: A previous version of this article referred to Mechanize as Mechanize Work. It has been updated to reflect the company’s official name.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Big Tech CEOs have touted visions of AI agents that can autonomously use software applications to complete tasks for people. But take today’s consumer AI agents out for a spin, whether it’s OpenAI’s ChatGPT Agent or Perplexity’s Comet, and you’ll quickly realize how limited the technology still is. Making AI agents more robust may take a new set of techniques that the industry is still discovering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of those techniques is carefully simulating workspaces where agents can be trained on multi-step tasks — known as reinforcement learning (RL) environments. Similarly to how labeled datasets powered the last wave of AI, RL environments are starting to look like a critical element in the development of agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI researchers, founders, and investors tell TechCrunch that leading AI labs are now demanding more RL environments, and there’s no shortage of startups hoping to supply them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All the big AI labs are building RL environments in-house,” said Jennifer Li, general partner at Andreessen Horowitz, in an interview with TechCrunch. “But as you can imagine, creating these datasets is very complex, so AI labs are also looking at third party vendors that can create high quality environments and evaluations. Everyone is looking at this space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push for RL environments has minted a new class of well-funded startups, such as Mechanize and Prime Intellect, that aim to lead the space. Meanwhile, large data-labeling companies like Mercor and Surge say they’re investing more in RL environments to keep pace with the industry’s shifts from static datasets to interactive simulations. The major labs are considering investing heavily too: according to The Information, leaders at Anthropic have discussed spending more than $1 billion on RL environments over the next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope for investors and founders is that one of these startups emerge as the “Scale AI for environments,” referring to the $29 billion data labelling powerhouse that powered the chatbot era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether RL environments will truly push the frontier of AI progress.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-an-rl-environment"&gt;What is an RL environment?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At their core, RL environments are training grounds that simulate what an AI agent would be doing in a real software application. One founder described building them in recent interview “like creating a very boring video game.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, an environment could simulate a Chrome browser and task an AI agent with purchasing a pair of socks on Amazon. The agent is graded on its performance and sent a reward signal when it succeeds (in this case, buying a worthy pair of socks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While such a task sounds relatively simple, there are a lot of places where an AI agent could get tripped up. It might get lost navigating the web page’s drop down menus, or buy too many socks. And because developers can’t predict exactly what wrong turn an agent will take, the environment itself has to be robust enough to capture any unexpected behavior, and still deliver useful feedback. That makes building environments far more complex than a static dataset.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some environments are quite elaborate, allowing for AI agents to use tools, access the internet, or use various software applications to complete a given task. Others are more narrow, aimed at helping an agent learn specific tasks in enterprise software applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While RL environments are the hot thing in Silicon Valley right now, there’s a lot of precedent for using this technique. One of OpenAI’s first projects back in 2016 was building “RL Gyms,” which were quite similar to the modern conception of environments. The same year, Google DeepMind’s AlphaGo AI system beat a world champion at the board game, Go. It also used RL techniques within a simulated environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s unique about today’s environments is that researchers are trying to build computer-using AI agents with large transformer models. Unlike AlphaGo, which was a specialized AI system working in a closed environments, today’s AI agents are trained to have more general capabilities. AI researchers today have a stronger starting point, but also a complicated goal where more can go wrong. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-crowded-field"&gt;&lt;strong&gt;A crowded field&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI data labeling companies like Scale AI, Surge, and Mercor are trying to meet the moment and build out RL environments. These companies have more resources than many startups in the space, as well as deep relationships with AI labs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surge CEO Edwin Chen tells TechCrunch he’s recently seen a “significant increase” in demand for RL environments within AI labs. Surge — which reportedly generated $1.2 billion in revenue last year from working with AI labs like OpenAI, Google, Anthropic and Meta — recently spun up a new internal organization specifically tasked with building out RL environments, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close behind Surge is Mercor, a startup valued at $10 billion, which has also worked with OpenAI, Meta, and Anthropic. Mercor is pitching investors on its business building RL environments for domain specific tasks such as coding, healthcare, and law, according to marketing materials seen by TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor CEO Brendan Foody told TechCrunch in an interview that “few understand how large the opportunity around RL environments truly is.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI used to dominate the data labeling space, but has lost ground since Meta invested $14 billion and hired away its CEO. Since then, Google and OpenAI dropped Scale AI as a data provider, and the startup even faces competition for data labelling work inside of Meta. But still, Scale is trying to meet the moment and build environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is just the nature of the business [Scale AI] is in,” said Chetan Rane, Scale AI’s head of product for agents and RL environments. “Scale has proven its ability to adapt quickly. We did this in the early days of autonomous vehicles, our first business unit. When ChatGPT came out, Scale AI adapted to that. And now, once again, we’re adapting to new frontier spaces like agents and environments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer players are focusing exclusively on environments from the outset. Among them is Mechanize, a startup founded roughly six months ago with the audacious goal of “automating all jobs.” However, co-founder Matthew Barnett tells TechCrunch that his firm is starting with RL environments for AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize aims to supply AI labs with a small number of robust RL environments, Barnett says, rather than larger data firms that create a wide range of simple RL environments. To this point, the startup is offering software engineers $500,000 salaries to build RL environments — far higher than an hourly contractor could earn working at Scale AI or Surge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize has already been working with Anthropic on RL environments, two sources familiar with the matter told TechCrunch. Mechanize and Anthropic declined to comment on the partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other startups are betting that RL environments will be influential outside of AI labs. Prime Intellect — a startup backed by AI researcher Andrej Karpathy, Founders Fund, and Menlo Ventures — is targeting smaller developers with its RL environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Prime Intellect launched an RL environments hub, which aims to be a “Hugging Face for RL environments.” The idea is to give open-source developers access to the same resources that large AI labs have, and sell those developers access to computational resources in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Training generally capable agents in RL environments can be more computational expensive than previous AI training techniques, according to Prime Intellect researcher Will Brown. Alongside startups building RL environments, there’s another opportunity for GPU providers that can power the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“RL environments are going to be too large for any one company to dominate,” said Brown in an interview. “Part of what we’re doing is just trying to build good open-source infrastructure around it. The service we sell is compute, so it is a convenient onramp to using GPUs, but we’re thinking of this more in the long term.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-it-scale"&gt;&lt;strong&gt;Will it scale?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The open question around RL environments is whether the technique will scale like previous AI training methods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reinforcement learning has powered some of the biggest leaps in AI over the past year, including models like OpenAI’s o1 and Anthropic’s Claude Opus 4. Those are particularly important breakthroughs because the methods previously used to improve AI models are now showing diminishing returns.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Environments are part of AI labs’ bigger bet on RL, which many believe will continue to drive progress as they add more data and computational resources to the process. Some of the OpenAI researchers behind o1 previously told TechCrunch that the company originally invested in AI reasoning models — which were created through investments in RL and test-time-compute — because they thought it would scale nicely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The best way to scale RL remains unclear, but environments seem like a promising contender. Instead of simply rewarding chatbots for text responses, they let agents operate in simulations with tools and computers at their disposal. That’s far more resource-intensive, but potentially more rewarding. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are skeptical that all these RL environments will pan out. Ross Taylor, a former AI research lead with Meta that co-founded General Reasoning, tells TechCrunch that RL environments are prone to reward hacking. This is a process in which AI models cheat in order to get a reward, without really doing the task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think people are underestimating how difficult it is to scale environments,” said Taylor. “Even the best publicly available [RL environments] typically don’t work without serious modification.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s Head of Engineering for its API business, Sherwin Wu, said in a recent podcast that he was “short” on RL environment startups. Wu noted that it’s a very competitive space, but also that AI research is evolving so quickly that it’s hard to serve AI labs well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karpathy, an investor in Prime Intellect that has called RL environments a potential breakthrough, has also voiced caution for the RL space more broadly. In a post on X, he raised concerns about how much more AI progress can be squeezed out of RL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am bullish on environments and agentic interactions but I am bearish on reinforcement learning specifically,” said Karpathy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: A previous version of this article referred to Mechanize as Mechanize Work. It has been updated to reflect the company’s official name.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/silicon-valley-bets-big-on-environments-to-train-ai-agents/</guid><pubDate>Tue, 16 Sep 2025 19:00:48 +0000</pubDate></item><item><title>[NEW] ChatGPT may soon require ID verification from adults, CEO says (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/chatgpt-may-soon-require-id-verification-from-adults-ceo-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chatbot will "default to the under-18 experience" when age is uncertain after teen suicide lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Javier Zayaz via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday, OpenAI announced plans to develop an automated age-prediction system that will determine whether ChatGPT users are over or under 18, automatically directing younger users to a restricted version of the AI chatbot. The company also confirmed that parental controls will launch by the end of September.&lt;/p&gt;
&lt;p&gt;In a companion blog post, OpenAI CEO Sam Altman acknowledged the company is explicitly "prioritizing safety ahead of privacy and freedom for teens," even though it means that adults may eventually need to verify their age to use a more unrestricted version of the service.&lt;/p&gt;
&lt;p&gt;"In some cases or countries we may also ask for an ID," Altman wrote. "We know this is a privacy compromise for adults but believe it is a worthy tradeoff." Altman admitted that "not everyone will agree with how we are resolving that conflict" between user privacy and teen safety.&lt;/p&gt;
&lt;p&gt;The announcements arrives weeks after a lawsuit filed by parents whose 16-year-old son died by suicide following extensive interactions with ChatGPT. According to the lawsuit, the chatbot provided detailed instructions, romanticized suicide methods, and discouraged the teen from seeking help from his family while OpenAI's system tracked 377 messages flagged for self-harm content without intervening.&lt;/p&gt;
&lt;p&gt;The proposed age-prediction system represents a non-trivial technical undertaking for OpenAI, and whether AI-powered age detection can actually work remains a significant open question. When the AI system in development identifies users under 18, OpenAI plans to automatically route the user to a modified ChatGPT experience that blocks graphic sexual content and includes other age-appropriate restrictions. The company says it will "take the safer route" when uncertain about a user's age, defaulting to the restricted experience and requiring adults to verify their age to access full functionality.&lt;/p&gt;
&lt;p&gt;The company didn't specify what technology it plans to use for age prediction or provide a timeline for deployment beyond saying it's "building toward" the system. OpenAI acknowledged that developing effective age-verification systems isn't straightforward. "Even the most advanced systems will sometimes struggle to predict age," the company wrote.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent academic research offers both possibilities and warnings for OpenAI's age-detection approach. A 2024 Georgia Tech study achieved 96 percent accuracy detecting underage users from text—but only in controlled conditions with cooperative subjects. When attempting to classify specific age groups, accuracy dropped to 54 percent, with the models completely failing for some demographics. More concerning: The research used curated datasets where ages were known and users weren't trying to deceive the system—luxuries OpenAI won't have with some of ChatGPT's users actively trying to bypass restrictions.&lt;/p&gt;
&lt;p&gt;While YouTube and Instagram can potentially analyze faces, posting patterns, and social networks to determine age, ChatGPT must rely solely on conversational text, which can be an unreliable signal of user age. Research on Twitter-user age prediction from 2017 conducted by Research Triangle International found that even with metadata like follower counts and posting frequency, text-based models "need continual updating" because "cohort effects in language usage vary over time," with terms, like "LOL," for example, shifting from teen to adult usage patterns.&lt;/p&gt;
&lt;h2&gt;Planned parental oversight features&lt;/h2&gt;
&lt;p&gt;Beyond age detection, the ChatGPT parental controls arriving this month will reportedly allow parents to link their accounts with their teenagers' accounts (minimum age 13) through email invitations. Once connected, parents can disable specific features, including ChatGPT's memory function and chat history storage, set blackout hours when teens cannot use the service, and receive notifications when the system "detects" their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;That last feature comes with a significant caveat: OpenAI states that in rare emergency situations where parents cannot be reached, the company "may involve law enforcement as a next step." The company says expert input will guide this feature's implementation, though it didn't specify which experts or organizations are providing that guidance.&lt;/p&gt;
&lt;p&gt;The controls will also let parents "help guide how ChatGPT responds to their teen, based on teen-specific model behavior rules," though OpenAI didn't yet elaborate on what those rules entail or how parents would configure them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI joins other tech companies that have tried youth-specific versions of their services. YouTube Kids, Instagram Teen Accounts, and TikTok's under-16 restrictions represent similar efforts to create "safer" digital spaces for young users, but teens routinely circumvent age verification through false birthdate entries, borrowed accounts, or technical workarounds. A 2024 BBC report found that 22 percent of children lie on social media platforms about being 18 or over.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Privacy vs. safety trade-offs&lt;/h2&gt;
&lt;p&gt;Despite the unproven technology behind AI age detection, OpenAI still plans to press ahead with its system, acknowledging that adults will sacrifice privacy and flexibility to make it work. Altman acknowledged the tension this creates, given the intimate nature of AI interactions.&lt;/p&gt;
&lt;p&gt;"People talk to AI about increasingly personal things; it is different from previous generations of technology, and we believe that they may be one of the most personally sensitive accounts you’ll ever have," Altman wrote in his post.&lt;/p&gt;
&lt;p&gt;The safety push follows OpenAI's acknowledgment in August that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote at the time, noting that while ChatGPT might correctly direct users to suicide hotlines initially, "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation of safeguards proved tragically consequential in the Adam Raine case. According to the lawsuit, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself—while the system's safety protocols failed to intervene or notify anyone. Stanford University researchers found in July that AI therapy bots can provide dangerous mental health advice, and recent reports have documented cases of vulnerable users developing what some experts informally call "AI Psychosis" after extended chatbot interactions.&lt;/p&gt;
&lt;p&gt;OpenAI didn't address how the age-prediction system would handle existing users who have been using ChatGPT without age verification, whether the system would apply to API access, or how it plans to verify ages in jurisdictions with different legal definitions of adulthood.&lt;/p&gt;
&lt;p&gt;All users, regardless of age, will continue to see in-app reminders during long ChatGPT sessions that encourage taking breaks—a feature OpenAI introduced earlier this year after reports of users spending marathon sessions with the chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chatbot will "default to the under-18 experience" when age is uncertain after teen suicide lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Javier Zayaz via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday, OpenAI announced plans to develop an automated age-prediction system that will determine whether ChatGPT users are over or under 18, automatically directing younger users to a restricted version of the AI chatbot. The company also confirmed that parental controls will launch by the end of September.&lt;/p&gt;
&lt;p&gt;In a companion blog post, OpenAI CEO Sam Altman acknowledged the company is explicitly "prioritizing safety ahead of privacy and freedom for teens," even though it means that adults may eventually need to verify their age to use a more unrestricted version of the service.&lt;/p&gt;
&lt;p&gt;"In some cases or countries we may also ask for an ID," Altman wrote. "We know this is a privacy compromise for adults but believe it is a worthy tradeoff." Altman admitted that "not everyone will agree with how we are resolving that conflict" between user privacy and teen safety.&lt;/p&gt;
&lt;p&gt;The announcements arrives weeks after a lawsuit filed by parents whose 16-year-old son died by suicide following extensive interactions with ChatGPT. According to the lawsuit, the chatbot provided detailed instructions, romanticized suicide methods, and discouraged the teen from seeking help from his family while OpenAI's system tracked 377 messages flagged for self-harm content without intervening.&lt;/p&gt;
&lt;p&gt;The proposed age-prediction system represents a non-trivial technical undertaking for OpenAI, and whether AI-powered age detection can actually work remains a significant open question. When the AI system in development identifies users under 18, OpenAI plans to automatically route the user to a modified ChatGPT experience that blocks graphic sexual content and includes other age-appropriate restrictions. The company says it will "take the safer route" when uncertain about a user's age, defaulting to the restricted experience and requiring adults to verify their age to access full functionality.&lt;/p&gt;
&lt;p&gt;The company didn't specify what technology it plans to use for age prediction or provide a timeline for deployment beyond saying it's "building toward" the system. OpenAI acknowledged that developing effective age-verification systems isn't straightforward. "Even the most advanced systems will sometimes struggle to predict age," the company wrote.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent academic research offers both possibilities and warnings for OpenAI's age-detection approach. A 2024 Georgia Tech study achieved 96 percent accuracy detecting underage users from text—but only in controlled conditions with cooperative subjects. When attempting to classify specific age groups, accuracy dropped to 54 percent, with the models completely failing for some demographics. More concerning: The research used curated datasets where ages were known and users weren't trying to deceive the system—luxuries OpenAI won't have with some of ChatGPT's users actively trying to bypass restrictions.&lt;/p&gt;
&lt;p&gt;While YouTube and Instagram can potentially analyze faces, posting patterns, and social networks to determine age, ChatGPT must rely solely on conversational text, which can be an unreliable signal of user age. Research on Twitter-user age prediction from 2017 conducted by Research Triangle International found that even with metadata like follower counts and posting frequency, text-based models "need continual updating" because "cohort effects in language usage vary over time," with terms, like "LOL," for example, shifting from teen to adult usage patterns.&lt;/p&gt;
&lt;h2&gt;Planned parental oversight features&lt;/h2&gt;
&lt;p&gt;Beyond age detection, the ChatGPT parental controls arriving this month will reportedly allow parents to link their accounts with their teenagers' accounts (minimum age 13) through email invitations. Once connected, parents can disable specific features, including ChatGPT's memory function and chat history storage, set blackout hours when teens cannot use the service, and receive notifications when the system "detects" their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;That last feature comes with a significant caveat: OpenAI states that in rare emergency situations where parents cannot be reached, the company "may involve law enforcement as a next step." The company says expert input will guide this feature's implementation, though it didn't specify which experts or organizations are providing that guidance.&lt;/p&gt;
&lt;p&gt;The controls will also let parents "help guide how ChatGPT responds to their teen, based on teen-specific model behavior rules," though OpenAI didn't yet elaborate on what those rules entail or how parents would configure them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI joins other tech companies that have tried youth-specific versions of their services. YouTube Kids, Instagram Teen Accounts, and TikTok's under-16 restrictions represent similar efforts to create "safer" digital spaces for young users, but teens routinely circumvent age verification through false birthdate entries, borrowed accounts, or technical workarounds. A 2024 BBC report found that 22 percent of children lie on social media platforms about being 18 or over.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Privacy vs. safety trade-offs&lt;/h2&gt;
&lt;p&gt;Despite the unproven technology behind AI age detection, OpenAI still plans to press ahead with its system, acknowledging that adults will sacrifice privacy and flexibility to make it work. Altman acknowledged the tension this creates, given the intimate nature of AI interactions.&lt;/p&gt;
&lt;p&gt;"People talk to AI about increasingly personal things; it is different from previous generations of technology, and we believe that they may be one of the most personally sensitive accounts you’ll ever have," Altman wrote in his post.&lt;/p&gt;
&lt;p&gt;The safety push follows OpenAI's acknowledgment in August that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote at the time, noting that while ChatGPT might correctly direct users to suicide hotlines initially, "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation of safeguards proved tragically consequential in the Adam Raine case. According to the lawsuit, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself—while the system's safety protocols failed to intervene or notify anyone. Stanford University researchers found in July that AI therapy bots can provide dangerous mental health advice, and recent reports have documented cases of vulnerable users developing what some experts informally call "AI Psychosis" after extended chatbot interactions.&lt;/p&gt;
&lt;p&gt;OpenAI didn't address how the age-prediction system would handle existing users who have been using ChatGPT without age verification, whether the system would apply to API access, or how it plans to verify ages in jurisdictions with different legal definitions of adulthood.&lt;/p&gt;
&lt;p&gt;All users, regardless of age, will continue to see in-app reminders during long ChatGPT sessions that encourage taking breaks—a feature OpenAI introduced earlier this year after reports of users spending marathon sessions with the chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/chatgpt-may-soon-require-id-verification-from-adults-ceo-says/</guid><pubDate>Tue, 16 Sep 2025 20:09:22 +0000</pubDate></item><item><title>[NEW] The AI Makers: NVIDIA Partners in UK Advance Physical and Agentic AI, Robotics, Life Sciences and More (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/uk-partner-ecosystem-ai-makers/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The U.K. is driving investments in sovereign AI, using the technology to advance industries like manufacturing, life sciences and more.&lt;/p&gt;
&lt;p&gt;During NVIDIA founder and CEO Jensen Huang’s visit to the U.K. this week, NVIDIA highlighted how it is working with a broad ecosystem of AI makers across the nation on applications in physical and agentic AI, robotics and healthcare.&lt;/p&gt;
&lt;p&gt;Such partner advancements support the U.K.’s AI Action Opportunities Plan, published earlier this year, which includes these key pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Infographic that includes three pillars of the U.K.’s AI Action Opportunities Plan: 1) Invest in the foundations of AI. The U.K. needs world-class computing and data infrastructure, access to talent and regulation. 2) Push hard on cross-economy AI adoption. The public sector should rapidly pilot and scale AI products and services, and encourage the private sector to do the same. 3) Position the UK to be an AI maker, not an AI taker. The U.K. should aim to have national champions at critical layers of the AI stack so the U.K. benefits economically from AI advancement and has influence on future AI’s values, safety and government." class="aligncenter size-large wp-image-84827" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/uk-ai-action-plan-infographic-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advancing the UK Technology Ecosystem&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Work to build the U.K.’s AI foundation has already begun, with support from the nation’s rich research and startup ecosystem along with technology leaders.&lt;/p&gt;
&lt;p&gt;Funded by U.K. Research and Innovation and built on NVIDIA Grace Hopper Superchips, &lt;b&gt;Isambard-AI&lt;/b&gt; — the U.K.’s most powerful AI supercomputer based at the University of Bristol, which launched in July — is accelerating national projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;UK-LLM&lt;/b&gt;, a large language model project developed by University College London, Bangor University and NVIDIA. UK-LLM uses NVIDIA Nemotron reasoning models to support national languages like Welsh, as well as English, to improve public service delivery in sectors like healthcare and education.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nightingale AI&lt;/b&gt;, a sovereign, multimodal health foundation model led by Imperial College London and trained on U.K. and US health data, which is designed to be used for numerous health applications including earlier diagnoses and personalized care.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;PolluGen&lt;/b&gt;, a new high-resolution pollution dispersion model developed by the University of Manchester, using NVIDIA CorrDiff and Earth-2 Studio. The model can use regional health and other data to help inform citizens and policymakers of air-quality impacts.&lt;/li&gt;
&lt;li&gt;The &lt;b&gt;Ultrasound Foundation Model&lt;/b&gt;, led by researchers at Queen Mary University of London. The model is built for ultrasound imaging, focusing on rheumatoid arthritis patient analysis and creating a reproducible, publicly accessible AI model for medical imaging.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gen Model in Ego-Sensed World&lt;/b&gt;, led by researchers at the University of Bristol, is analyzing visual data from more than 900 participants to train an AI model to better understand everyday tasks. The AI model could help predict future real-world interactions and support memory to aid independent living for dementia patients.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electrostatics-aware foundation models, &lt;/b&gt;developed by researchers at the University of Cambridge in collaboration with NVIDIA. These are being trained as the first foundation models for atomic interactions that understand electrostatics in chemistry at the atomic level. To do this, the researchers are using more than 200 million molecular and material structures from the OMOL and OMAT databases with NVIDIA’s cuEquivariance library. The model will allow scientists to simulate materials and molecules that were previously too large or complex to handle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, SCAN — a technology solutions provider with a strong focus on community, education and innovation — is collaborating with NVIDIA to address the growing AI skills gap across the U.K. through NVIDIA Deep Learning Institute courses and SCAN Springboard U.K., a community-driven initiative designed to foster peer-to-peer learning, market awareness, and mass training in AI and specialized workloads.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA announced separately today it is collaborating with techUK, alongside educational autonomous systems leader Quanser and training provider QA, to strengthen the U.K.’s robotics and AI ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also working with other leading U.K. robotics leaders to advance industries with physical AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Extend Robotics&lt;/b&gt; is accelerating safe, scalable robot deployment in vehicle manufacturing by combining extended reality-based teleoperation and advanced training systems — powered by NVIDIA Jetson AGX Orin modules, the NVIDIA Isaac Lab framework and NVIDIA Isaac GR00T models — enabling rapid skill acquisition and boosting safety and productivity.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Humanoid&lt;/b&gt; is developing a modular humanoid robot called HMND 01 for general tasks in warehouses and retail spaces. The robot is designed for seamless integration with human environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Materials Innovation Factory&lt;/b&gt; at the University of Liverpool is using NVIDIA tools and libraries to train a foundations model to predict material properties, as well as train robot scientists using NVIDIA Jetson Orin Nano modules to test these hypotheses within a fully automated lab environment.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The National Robotarium&lt;/b&gt;, a U.K. hub for robotics innovation, is using NVIDIA robotics and AI frameworks to support cutting-edge, practical research and help early-stage robotics businesses grow.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Opteran&lt;/b&gt; is creating autonomy algorithms for robots that mirror how the brains of insects and animals process information, harnessing knowledge on 600 million years of evolution to make robotic systems as robust and efficient as nature.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxa&lt;/b&gt; is creating full-stack AI self-driving software for industrial and commercial fleets with the NVIDIA DRIVE platform. The software works in all weather and locations — even where GPS is unreliable. Through its collaboration with NVIDIA, Oxa is able to generate vast amounts of diverse and realistic synthetic data to support training and validation — significantly accelerating the development and deployment of its solutions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wayve&lt;/b&gt; is pioneering end-to-end deep learning for autonomous driving. Its next-generation AV2.0 Platform enables vehicles to quickly and safely adapt its driving intelligence to new, unseen environments without needing expensive sensors and high-definition maps&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Many U.K.-based life sciences companies are using NVIDIA technologies to take an AI-first approach to drug discovery, simulating therapies and drug design to achieve faster treatment testing.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Basecamp Research&lt;/b&gt;’s BaseData — a proprietary evolutionary dataset that’s 10x larger than comparable public sources — is now powering a new generation of large foundation models across diverse biological data types, accelerating the development of curative, programmable medicines.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;U.K. CEiSRI&lt;/b&gt; — the U.K. Centre of Excellence for In-Silico Regulatory Science and Innovation,&amp;nbsp; headquartered at the University of Manchester — is developing complex digital twins with NVIDIA technologies to test new treatments on large and diverse patient populations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Isomorphic Labs&lt;/b&gt; has built a leading AI drug design engine comprising foundational AI models that can work across multiple therapeutic areas and drug modalities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Peptone&lt;/b&gt; is pioneering a new class of safer, more effective medicines by applying its physics-driven AI platform to unlock the therapeutic potential of the entire proteome, with a focus on historically “undruggable” intrinsically disordered proteins.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Latent Labs&lt;/b&gt;’ generative AI model, Latent-X, allows scientists to create and test therapeutic molecules in silico, speeding up drug design for researchers.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Relation Therapeutics&lt;/b&gt; offers a foundational AI platform for target drug discovery, integrating lab-in-the-loop experimentation to understand disease biology and accelerate the discovery and development of new therapies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Hologen AI&lt;/b&gt;, a spinout with cofounders from University College London and King’s College London, represents a new breed of AI-native companies — ones harnessing the power of AI to model complex human biology and medical interventions with high precision, making new drugs available for patients rapidly and at lower cost.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxford Nanopore&lt;/b&gt; is delivering information-rich, rapid, affordable and accessible molecular information — such as DNA and RNA sequence data — to scientific researchers, as well as users in clinical, biopharma and applied industrial communities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Agentic and Generative AI Innovations&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI model builders and startups are working with NVIDIA to transform the U.K. technology sector with agentic and generative AI tools that advance productivity, from financial large language models to AI voice agents.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Aveni &lt;/b&gt;created a financial LLM using the NVIDIA NeMo software suite to power its next-generation agentic framework that can interact with live financial systems, communicate with customers and advise on risk outcomes while ensuring compliance, transparency and control.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ElevenLabs&lt;/b&gt; develops AI voice technology that generates natural, ultrarealistic speech in over 70 languages using NVIDIA software and NVIDIA DGX B200 systems. Its models power real-time conversational agents, localization, storytelling and accessibility tools for people who have lost their voices, in addition to voicing audiobooks and animating video game characters.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;PolyAI&lt;/b&gt; deployed advanced conversational AI agents using NVIDIA Riva automatic speech recognition NVIDIA NIM microservices. The AI agents automate customer support, speak naturally over the phone and handle complex tasks such as authentication, order management, billing and reservations on a massive scale.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Recraft&lt;/b&gt; is producing state-of-the-art image generation and editing models, built with advanced design capabilities to support professional creative workflows. Recraft is using the NVIDIA TensorRT software development kit, enabling users to generate and edit images and graphics to speed workflows such as producing marketing materials, generating product mockups and editing visual content.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Speechmatics&lt;/b&gt; developed speech-to-text software using NVIDIA Dynamo-Triton and NVIDIA cuDNN software. Its automatic speech recognition software lets businesses and developers convert spoken language into written text, with support for dozens of languages.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Synthesia&lt;/b&gt; built an enterprise-focused AI video platform using NVIDIA Dynamo-Triton and other NVIDIA software. With the platform, businesses create professional-quality training, marketing, sales and customer support videos from text, using AI avatars and voiceovers in over 140 languages.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how &lt;/i&gt;&lt;i&gt;NVIDIA is bolstering Europe’s technology ecosystem&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The U.K. is driving investments in sovereign AI, using the technology to advance industries like manufacturing, life sciences and more.&lt;/p&gt;
&lt;p&gt;During NVIDIA founder and CEO Jensen Huang’s visit to the U.K. this week, NVIDIA highlighted how it is working with a broad ecosystem of AI makers across the nation on applications in physical and agentic AI, robotics and healthcare.&lt;/p&gt;
&lt;p&gt;Such partner advancements support the U.K.’s AI Action Opportunities Plan, published earlier this year, which includes these key pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Infographic that includes three pillars of the U.K.’s AI Action Opportunities Plan: 1) Invest in the foundations of AI. The U.K. needs world-class computing and data infrastructure, access to talent and regulation. 2) Push hard on cross-economy AI adoption. The public sector should rapidly pilot and scale AI products and services, and encourage the private sector to do the same. 3) Position the UK to be an AI maker, not an AI taker. The U.K. should aim to have national champions at critical layers of the AI stack so the U.K. benefits economically from AI advancement and has influence on future AI’s values, safety and government." class="aligncenter size-large wp-image-84827" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/uk-ai-action-plan-infographic-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advancing the UK Technology Ecosystem&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Work to build the U.K.’s AI foundation has already begun, with support from the nation’s rich research and startup ecosystem along with technology leaders.&lt;/p&gt;
&lt;p&gt;Funded by U.K. Research and Innovation and built on NVIDIA Grace Hopper Superchips, &lt;b&gt;Isambard-AI&lt;/b&gt; — the U.K.’s most powerful AI supercomputer based at the University of Bristol, which launched in July — is accelerating national projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;UK-LLM&lt;/b&gt;, a large language model project developed by University College London, Bangor University and NVIDIA. UK-LLM uses NVIDIA Nemotron reasoning models to support national languages like Welsh, as well as English, to improve public service delivery in sectors like healthcare and education.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nightingale AI&lt;/b&gt;, a sovereign, multimodal health foundation model led by Imperial College London and trained on U.K. and US health data, which is designed to be used for numerous health applications including earlier diagnoses and personalized care.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;PolluGen&lt;/b&gt;, a new high-resolution pollution dispersion model developed by the University of Manchester, using NVIDIA CorrDiff and Earth-2 Studio. The model can use regional health and other data to help inform citizens and policymakers of air-quality impacts.&lt;/li&gt;
&lt;li&gt;The &lt;b&gt;Ultrasound Foundation Model&lt;/b&gt;, led by researchers at Queen Mary University of London. The model is built for ultrasound imaging, focusing on rheumatoid arthritis patient analysis and creating a reproducible, publicly accessible AI model for medical imaging.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gen Model in Ego-Sensed World&lt;/b&gt;, led by researchers at the University of Bristol, is analyzing visual data from more than 900 participants to train an AI model to better understand everyday tasks. The AI model could help predict future real-world interactions and support memory to aid independent living for dementia patients.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electrostatics-aware foundation models, &lt;/b&gt;developed by researchers at the University of Cambridge in collaboration with NVIDIA. These are being trained as the first foundation models for atomic interactions that understand electrostatics in chemistry at the atomic level. To do this, the researchers are using more than 200 million molecular and material structures from the OMOL and OMAT databases with NVIDIA’s cuEquivariance library. The model will allow scientists to simulate materials and molecules that were previously too large or complex to handle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, SCAN — a technology solutions provider with a strong focus on community, education and innovation — is collaborating with NVIDIA to address the growing AI skills gap across the U.K. through NVIDIA Deep Learning Institute courses and SCAN Springboard U.K., a community-driven initiative designed to foster peer-to-peer learning, market awareness, and mass training in AI and specialized workloads.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA announced separately today it is collaborating with techUK, alongside educational autonomous systems leader Quanser and training provider QA, to strengthen the U.K.’s robotics and AI ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also working with other leading U.K. robotics leaders to advance industries with physical AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Extend Robotics&lt;/b&gt; is accelerating safe, scalable robot deployment in vehicle manufacturing by combining extended reality-based teleoperation and advanced training systems — powered by NVIDIA Jetson AGX Orin modules, the NVIDIA Isaac Lab framework and NVIDIA Isaac GR00T models — enabling rapid skill acquisition and boosting safety and productivity.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Humanoid&lt;/b&gt; is developing a modular humanoid robot called HMND 01 for general tasks in warehouses and retail spaces. The robot is designed for seamless integration with human environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Materials Innovation Factory&lt;/b&gt; at the University of Liverpool is using NVIDIA tools and libraries to train a foundations model to predict material properties, as well as train robot scientists using NVIDIA Jetson Orin Nano modules to test these hypotheses within a fully automated lab environment.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The National Robotarium&lt;/b&gt;, a U.K. hub for robotics innovation, is using NVIDIA robotics and AI frameworks to support cutting-edge, practical research and help early-stage robotics businesses grow.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Opteran&lt;/b&gt; is creating autonomy algorithms for robots that mirror how the brains of insects and animals process information, harnessing knowledge on 600 million years of evolution to make robotic systems as robust and efficient as nature.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxa&lt;/b&gt; is creating full-stack AI self-driving software for industrial and commercial fleets with the NVIDIA DRIVE platform. The software works in all weather and locations — even where GPS is unreliable. Through its collaboration with NVIDIA, Oxa is able to generate vast amounts of diverse and realistic synthetic data to support training and validation — significantly accelerating the development and deployment of its solutions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wayve&lt;/b&gt; is pioneering end-to-end deep learning for autonomous driving. Its next-generation AV2.0 Platform enables vehicles to quickly and safely adapt its driving intelligence to new, unseen environments without needing expensive sensors and high-definition maps&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Many U.K.-based life sciences companies are using NVIDIA technologies to take an AI-first approach to drug discovery, simulating therapies and drug design to achieve faster treatment testing.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Basecamp Research&lt;/b&gt;’s BaseData — a proprietary evolutionary dataset that’s 10x larger than comparable public sources — is now powering a new generation of large foundation models across diverse biological data types, accelerating the development of curative, programmable medicines.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;U.K. CEiSRI&lt;/b&gt; — the U.K. Centre of Excellence for In-Silico Regulatory Science and Innovation,&amp;nbsp; headquartered at the University of Manchester — is developing complex digital twins with NVIDIA technologies to test new treatments on large and diverse patient populations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Isomorphic Labs&lt;/b&gt; has built a leading AI drug design engine comprising foundational AI models that can work across multiple therapeutic areas and drug modalities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Peptone&lt;/b&gt; is pioneering a new class of safer, more effective medicines by applying its physics-driven AI platform to unlock the therapeutic potential of the entire proteome, with a focus on historically “undruggable” intrinsically disordered proteins.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Latent Labs&lt;/b&gt;’ generative AI model, Latent-X, allows scientists to create and test therapeutic molecules in silico, speeding up drug design for researchers.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Relation Therapeutics&lt;/b&gt; offers a foundational AI platform for target drug discovery, integrating lab-in-the-loop experimentation to understand disease biology and accelerate the discovery and development of new therapies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Hologen AI&lt;/b&gt;, a spinout with cofounders from University College London and King’s College London, represents a new breed of AI-native companies — ones harnessing the power of AI to model complex human biology and medical interventions with high precision, making new drugs available for patients rapidly and at lower cost.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxford Nanopore&lt;/b&gt; is delivering information-rich, rapid, affordable and accessible molecular information — such as DNA and RNA sequence data — to scientific researchers, as well as users in clinical, biopharma and applied industrial communities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Agentic and Generative AI Innovations&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI model builders and startups are working with NVIDIA to transform the U.K. technology sector with agentic and generative AI tools that advance productivity, from financial large language models to AI voice agents.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Aveni &lt;/b&gt;created a financial LLM using the NVIDIA NeMo software suite to power its next-generation agentic framework that can interact with live financial systems, communicate with customers and advise on risk outcomes while ensuring compliance, transparency and control.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ElevenLabs&lt;/b&gt; develops AI voice technology that generates natural, ultrarealistic speech in over 70 languages using NVIDIA software and NVIDIA DGX B200 systems. Its models power real-time conversational agents, localization, storytelling and accessibility tools for people who have lost their voices, in addition to voicing audiobooks and animating video game characters.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;PolyAI&lt;/b&gt; deployed advanced conversational AI agents using NVIDIA Riva automatic speech recognition NVIDIA NIM microservices. The AI agents automate customer support, speak naturally over the phone and handle complex tasks such as authentication, order management, billing and reservations on a massive scale.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Recraft&lt;/b&gt; is producing state-of-the-art image generation and editing models, built with advanced design capabilities to support professional creative workflows. Recraft is using the NVIDIA TensorRT software development kit, enabling users to generate and edit images and graphics to speed workflows such as producing marketing materials, generating product mockups and editing visual content.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Speechmatics&lt;/b&gt; developed speech-to-text software using NVIDIA Dynamo-Triton and NVIDIA cuDNN software. Its automatic speech recognition software lets businesses and developers convert spoken language into written text, with support for dozens of languages.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Synthesia&lt;/b&gt; built an enterprise-focused AI video platform using NVIDIA Dynamo-Triton and other NVIDIA software. With the platform, businesses create professional-quality training, marketing, sales and customer support videos from text, using AI avatars and voiceovers in over 140 languages.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how &lt;/i&gt;&lt;i&gt;NVIDIA is bolstering Europe’s technology ecosystem&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/uk-partner-ecosystem-ai-makers/</guid><pubDate>Tue, 16 Sep 2025 21:30:16 +0000</pubDate></item><item><title>[NEW] Meta Connect 2025: What to expect and how to watch (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/meta-connect-2025-what-to-expect-and-how-to-watch/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta Connect 2025 — the company’s biggest conference of the year where it unveils smart glasses and VR headsets — kicks off on Wednesday night. We’re expecting the star of Meta Connect 2025 to be the company’s new AI-powered smart glasses with Ray-Ban and Oakley, but the company may have some other surprises in store regarding the Metaverse, Quest headsets, or even its broader AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it has sold millions of Ray-Ban Meta smart glasses, and earlier this year, Meta unveiled its latest AI-powered smart glasses with Oakley, which were designed for athletes. Silicon Valley is leaning heavily into AI wearables, and Meta seems to be one of the companies leading the charge.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this is the company’s first Connect conference since it started Meta Superintelligence Labs (MSL), its boldest effort yet to develop cutting-edge AI systems under former Scale AI CEO Alexandr Wang. It’s possible we’ll get some official updates on how that project is going, and we may hear from some MSL executives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta looks to regain its footing in the AI race, this year’s Connect feels especially consequential. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-to-watch"&gt;How to watch&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta Connect 2025 starts at 5 p.m. PT Wednesday, with a keynote from CEO Mark Zuckerberg. The event will take place in person at Meta’s headquarters in Menlo Park. You can register for free to watch the livestream virtually on Meta’s website. Meta’s agenda says the keynote will be roughly an hour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to get that Menlo Park feel from the comfort of your living room, you can also access the keynote through Horizon via your Meta Quest headset. You can also access the Meta Connect 2025 keynote on Facebook via the company’s official developer page, Meta for Developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Meta will host a Developer Keynote staring 10 a.m. PT to discuss the new experiences people can build with its devices. Then, at 10:45 a.m. PT, Meta will host a conversation between Chief Scientist of Reality Labs Michael Abrash and VP of Reality Labs Research Richard Newcombe. The two Meta executives are slated to discuss the “future of glasses with contextual AI, and how Meta is poised to transform the future of computing.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-to-expect"&gt;What to expect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There have already been several leaks regarding what will be announced at Meta Connect 2025. Perhaps the biggest pertains to a new type of smart glasses called Hypernova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A now-removed video on Meta’s YouTube channel, spotted by UploadVR, showed a pair of Ray-Ban Meta smart glasses with a heads-up display on the right lens, as well as cameras, microphones, and an onboard AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses in the video were controlled by a wristband, which was unveiled at last year’s Connect and is controlled by subtle hand gestures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The video suggests that Meta will unveil, and perhaps launch, the Hypernova glasses this week. CNBC previously reported that Meta was planning to unveil Hypernova and launch the wristband at Connect 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also seems likely to unveil new pair of smart glasses it developed with Oakley at Connect 2025. The companies are expected to launch a new pair of AI-powered smart glasses in Oakley’s Spheara style. This features a large unified lens on the front — an ideal shape for runners and bikers. Unlike previous Meta smart glasses, this model has one centered camera above the nose bridge, rather than two cameras on the top corners of the frames.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the VR front, it’s unclear whether Meta will release any new Quest headsets as part of this year’s Connect. Even though the conference, and company, is named after the Metaverse, it seems like that’s less of the focus this year. Meta is reportedly developing an ultralight VR headset for launch by the end of 2026. However, the company could wait to show that off at next year’s Connect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Meta promises that Zuckerberg will talk about the Metaverse in some shape or form. We don’t doubt that.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for Meta’s AI ambitions, it wouldn’t be surprising if Zuckerberg used Connect 2025 as a chance to highlight all the work MSL is doing. The company’s first LlamaCon, its AI developer conference, took place earlier this year before Meta invested billions in Scale AI and hired researchers from around the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, Meta’s standalone AI app is in a confusing spot where it both controls smart glasses and can be used as an AI chatbot. It’s possible that app also gets some updates that make it easier to use.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta Connect 2025 — the company’s biggest conference of the year where it unveils smart glasses and VR headsets — kicks off on Wednesday night. We’re expecting the star of Meta Connect 2025 to be the company’s new AI-powered smart glasses with Ray-Ban and Oakley, but the company may have some other surprises in store regarding the Metaverse, Quest headsets, or even its broader AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it has sold millions of Ray-Ban Meta smart glasses, and earlier this year, Meta unveiled its latest AI-powered smart glasses with Oakley, which were designed for athletes. Silicon Valley is leaning heavily into AI wearables, and Meta seems to be one of the companies leading the charge.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this is the company’s first Connect conference since it started Meta Superintelligence Labs (MSL), its boldest effort yet to develop cutting-edge AI systems under former Scale AI CEO Alexandr Wang. It’s possible we’ll get some official updates on how that project is going, and we may hear from some MSL executives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta looks to regain its footing in the AI race, this year’s Connect feels especially consequential. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-to-watch"&gt;How to watch&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta Connect 2025 starts at 5 p.m. PT Wednesday, with a keynote from CEO Mark Zuckerberg. The event will take place in person at Meta’s headquarters in Menlo Park. You can register for free to watch the livestream virtually on Meta’s website. Meta’s agenda says the keynote will be roughly an hour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to get that Menlo Park feel from the comfort of your living room, you can also access the keynote through Horizon via your Meta Quest headset. You can also access the Meta Connect 2025 keynote on Facebook via the company’s official developer page, Meta for Developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Meta will host a Developer Keynote staring 10 a.m. PT to discuss the new experiences people can build with its devices. Then, at 10:45 a.m. PT, Meta will host a conversation between Chief Scientist of Reality Labs Michael Abrash and VP of Reality Labs Research Richard Newcombe. The two Meta executives are slated to discuss the “future of glasses with contextual AI, and how Meta is poised to transform the future of computing.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-to-expect"&gt;What to expect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There have already been several leaks regarding what will be announced at Meta Connect 2025. Perhaps the biggest pertains to a new type of smart glasses called Hypernova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A now-removed video on Meta’s YouTube channel, spotted by UploadVR, showed a pair of Ray-Ban Meta smart glasses with a heads-up display on the right lens, as well as cameras, microphones, and an onboard AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses in the video were controlled by a wristband, which was unveiled at last year’s Connect and is controlled by subtle hand gestures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The video suggests that Meta will unveil, and perhaps launch, the Hypernova glasses this week. CNBC previously reported that Meta was planning to unveil Hypernova and launch the wristband at Connect 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also seems likely to unveil new pair of smart glasses it developed with Oakley at Connect 2025. The companies are expected to launch a new pair of AI-powered smart glasses in Oakley’s Spheara style. This features a large unified lens on the front — an ideal shape for runners and bikers. Unlike previous Meta smart glasses, this model has one centered camera above the nose bridge, rather than two cameras on the top corners of the frames.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the VR front, it’s unclear whether Meta will release any new Quest headsets as part of this year’s Connect. Even though the conference, and company, is named after the Metaverse, it seems like that’s less of the focus this year. Meta is reportedly developing an ultralight VR headset for launch by the end of 2026. However, the company could wait to show that off at next year’s Connect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Meta promises that Zuckerberg will talk about the Metaverse in some shape or form. We don’t doubt that.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for Meta’s AI ambitions, it wouldn’t be surprising if Zuckerberg used Connect 2025 as a chance to highlight all the work MSL is doing. The company’s first LlamaCon, its AI developer conference, took place earlier this year before Meta invested billions in Scale AI and hired researchers from around the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, Meta’s standalone AI app is in a confusing spot where it both controls smart glasses and can be used as an AI chatbot. It’s possible that app also gets some updates that make it easier to use.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/meta-connect-2025-what-to-expect-and-how-to-watch/</guid><pubDate>Tue, 16 Sep 2025 21:55:23 +0000</pubDate></item></channel></rss>