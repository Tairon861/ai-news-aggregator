<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 25 Oct 2025 06:29:04 +0000</lastBuildDate><item><title>The browser wars are back, and this time they’re powered by AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/the-browser-wars-are-back-and-this-time-theyre-powered-by-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The browser wars are heating up again, this time with AI in the driver’s seat.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;OpenAI just launched Atlas, a ChatGPT-powered browser that lets users surf the web using natural language, and even includes an “agent mode” that can complete tasks autonomously. It’s one of the biggest browser launches in recent memory, but it’s debuting with an unsolved security flaw that could expose passwords, emails, and sensitive data.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Max Zeff, Anthony Ha, and Sean O’Kane break down Atlas’ debut, the broader wave of alternative browsers, the AWS crash that broke much of the internet, and more of the week’s startup and tech news on TechCrunch’s Equity podcast.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The browser wars are heating up again, this time with AI in the driver’s seat.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;OpenAI just launched Atlas, a ChatGPT-powered browser that lets users surf the web using natural language, and even includes an “agent mode” that can complete tasks autonomously. It’s one of the biggest browser launches in recent memory, but it’s debuting with an unsolved security flaw that could expose passwords, emails, and sensitive data.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as Max Zeff, Anthony Ha, and Sean O’Kane break down Atlas’ debut, the broader wave of alternative browsers, the AWS crash that broke much of the internet, and more of the week’s startup and tech news on TechCrunch’s Equity podcast.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/the-browser-wars-are-back-and-this-time-theyre-powered-by-ai/</guid><pubDate>Fri, 24 Oct 2025 19:00:00 +0000</pubDate></item><item><title>How to use the new ChatGPT app integrations, including Spotify, Figma, Canva, and others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/24/how-to-use-the-new-chatgpt-app-integrations-including-spotify-figma-canva-and-others/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently launched new app integrations in ChatGPT to allow you to connect your accounts directly to ChatGPT and ask the assistant to do things for you. For instance, with a Spotify integration, you can tell it to create personalized playlists that will show up right in your Spotify app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get started, make sure you’re logged into ChatGPT. Then type the name of the app you want to use at the start of your prompt, and ChatGPT will guide you through signing in and connecting your account.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If you want to set everything up at once, head over to the Settings menu, then click on Apps and Connectors. You can browse through the available apps, pick the ones you like, and it’ll take you to the sign-in page for each one.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it’s important to note that connecting your account means you’re sharing your app data with ChatGPT. Make sure to review the permissions you’re giving when you’re linking your accounts. For example, if you connect your Spotify account, ChatGPT can see your playlists, listening history, and other personal information. (Sharing this info helps personalize the experience, but if you have privacy concerns, consider whether you’re comfortable with this level of access before connecting.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also disconnect any app whenever you want, right from the Settings menu.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-available-apps"&gt;Available apps &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062079" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Booking_OpenAI.png.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-booking-com"&gt;Booking.com&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This integration with the online travel giant is designed to help travelers, especially first-time visitors in need of suggestions for where to stay.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you link your Booking.com account, you can ask ChatGPT to find hotels in your preferred city based on your dates and budget. You can also specify how many people are coming and whether you want the hotel near public transport. ChatGPT aims to make this process more intuitive than searching directly on the Booking.com site. Plus, you can be more specific, like searching for options “with breakfast included.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;When you find a hotel you like, just open the Booking.com listing to complete your reservation.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-canva"&gt;Canva&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062077" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Canva-ChatGPT.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Canva&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Canva in ChatGPT is a helpful tool for graphic designers and anyone else who needs to generate visual content quickly. Whether it’s for a social media post, a poster, or a slide deck for a presentation, this may be a good way to help kickstart your project and brainstorm ideas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you connect your Canva account, you can ask ChatGPT to design something like “a 16:9 slide deck about our Q4 roadmap” or “a fun poster for a dog-walking business.” You can include specifics such as the fonts you prefer, color schemes, formats (like Instagram posts or stories), and exact dimensions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI-generated designs are seldom perfect, with occasional distorted images or spelling mistakes. However, some users may find this better than starting from scratch, and they can jump into Canva at any time to tweak their design and make it look just how they want.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-coursera"&gt;Coursera&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3062078" height="483" src="https://techcrunch.com/wp-content/uploads/2025/10/Demo_Desktop_Oct6_V4-1.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Coursera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Coursera’s integration is designed to help you quickly discover the best online courses for your skill level. For instance, you can then tell ChatGPT to find an “intermediate-level course on Python.” You can then tell the chatbot to compare course options by rating, duration, and cost before enrolling. ChatGPT can also provide a quick rundown of what exactly each course covers.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expedia"&gt;Expedia&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3062080" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/ExpediaChatgpt.png?w=615" width="615" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Expedia&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT can display hotel options and flights via Expedia without leaving chat. Whether you’re looking for a quick escape or a longer trip, it can find flights that fit your travel dates, budget, and number of travelers. You can narrow things down by saying stuff like “Only show 4-star hotels.” Once you see something you like, go to Expedia to finalize everything and book your trip.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-figma"&gt;Figma&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062081" height="483" src="https://techcrunch.com/wp-content/uploads/2025/10/FigmaChatgpt.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Figma&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To use Figma in ChatGPT, you can ask it to generate diagrams, flow charts, and more. This is helpful for turning your ideas and brainstorming sessions into something more tangible. It may also be useful for visualizing complex concepts or workflows.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also upload files and ask the chatbot to generate a product roadmap for your team. This roadmap can include milestones, deliverables, and deadlines, helping your team stay organized and focused on their goals.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-spotify"&gt;Spotify &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3056413" height="260" src="https://techcrunch.com/wp-content/uploads/2025/10/spotify-integration.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Spotify&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the most helpful aspects of using Spotify in ChatGPT is the ability to quickly create playlists and listen to new recommended songs tailored to your specific tastes. You can ask it to create a playlist based on your current mood, or just a playlist that only includes tracks by your favorite band.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It can also suggest new artists, playlists, audiobooks, and podcast episodes. Additionally, ChatGPT can perform actions on your behalf, including adding and removing items from your Spotify library.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-zillow"&gt;Zillow&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062082" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/01__The_Zillow_App_in_Chatgpt.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zillow&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re looking for a new home, Zillow in ChatGPT could make the search experience more straightforward. Using a simple text prompt, you can find homes that meet your criteria and apply filters to narrow the results. Whether you’re looking for a specific price range, number of bedrooms, or particular neighborhoods, you can specify these details in your prompt, making the search process much more efficient and tailored to your needs.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;What’s next?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the announcement that OpenAI would bring apps into ChatGPT, the company also said it plans to welcome additional partners soon, including DoorDash, OpenTable, Target, Uber, and Walmart. These will launch later in the year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout of ChatGPT’s app integrations is currently limited to the U.S. and Canada. Users in Europe and the U.K. are excluded for now.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently launched new app integrations in ChatGPT to allow you to connect your accounts directly to ChatGPT and ask the assistant to do things for you. For instance, with a Spotify integration, you can tell it to create personalized playlists that will show up right in your Spotify app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get started, make sure you’re logged into ChatGPT. Then type the name of the app you want to use at the start of your prompt, and ChatGPT will guide you through signing in and connecting your account.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If you want to set everything up at once, head over to the Settings menu, then click on Apps and Connectors. You can browse through the available apps, pick the ones you like, and it’ll take you to the sign-in page for each one.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it’s important to note that connecting your account means you’re sharing your app data with ChatGPT. Make sure to review the permissions you’re giving when you’re linking your accounts. For example, if you connect your Spotify account, ChatGPT can see your playlists, listening history, and other personal information. (Sharing this info helps personalize the experience, but if you have privacy concerns, consider whether you’re comfortable with this level of access before connecting.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also disconnect any app whenever you want, right from the Settings menu.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-available-apps"&gt;Available apps &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062079" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Booking_OpenAI.png.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-booking-com"&gt;Booking.com&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This integration with the online travel giant is designed to help travelers, especially first-time visitors in need of suggestions for where to stay.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you link your Booking.com account, you can ask ChatGPT to find hotels in your preferred city based on your dates and budget. You can also specify how many people are coming and whether you want the hotel near public transport. ChatGPT aims to make this process more intuitive than searching directly on the Booking.com site. Plus, you can be more specific, like searching for options “with breakfast included.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;When you find a hotel you like, just open the Booking.com listing to complete your reservation.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-canva"&gt;Canva&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062077" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Canva-ChatGPT.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Canva&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Canva in ChatGPT is a helpful tool for graphic designers and anyone else who needs to generate visual content quickly. Whether it’s for a social media post, a poster, or a slide deck for a presentation, this may be a good way to help kickstart your project and brainstorm ideas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you connect your Canva account, you can ask ChatGPT to design something like “a 16:9 slide deck about our Q4 roadmap” or “a fun poster for a dog-walking business.” You can include specifics such as the fonts you prefer, color schemes, formats (like Instagram posts or stories), and exact dimensions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI-generated designs are seldom perfect, with occasional distorted images or spelling mistakes. However, some users may find this better than starting from scratch, and they can jump into Canva at any time to tweak their design and make it look just how they want.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-coursera"&gt;Coursera&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3062078" height="483" src="https://techcrunch.com/wp-content/uploads/2025/10/Demo_Desktop_Oct6_V4-1.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Coursera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Coursera’s integration is designed to help you quickly discover the best online courses for your skill level. For instance, you can then tell ChatGPT to find an “intermediate-level course on Python.” You can then tell the chatbot to compare course options by rating, duration, and cost before enrolling. ChatGPT can also provide a quick rundown of what exactly each course covers.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expedia"&gt;Expedia&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3062080" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/ExpediaChatgpt.png?w=615" width="615" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Expedia&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT can display hotel options and flights via Expedia without leaving chat. Whether you’re looking for a quick escape or a longer trip, it can find flights that fit your travel dates, budget, and number of travelers. You can narrow things down by saying stuff like “Only show 4-star hotels.” Once you see something you like, go to Expedia to finalize everything and book your trip.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-figma"&gt;Figma&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062081" height="483" src="https://techcrunch.com/wp-content/uploads/2025/10/FigmaChatgpt.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Figma&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To use Figma in ChatGPT, you can ask it to generate diagrams, flow charts, and more. This is helpful for turning your ideas and brainstorming sessions into something more tangible. It may also be useful for visualizing complex concepts or workflows.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also upload files and ask the chatbot to generate a product roadmap for your team. This roadmap can include milestones, deliverables, and deadlines, helping your team stay organized and focused on their goals.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-spotify"&gt;Spotify &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3056413" height="260" src="https://techcrunch.com/wp-content/uploads/2025/10/spotify-integration.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Spotify&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the most helpful aspects of using Spotify in ChatGPT is the ability to quickly create playlists and listen to new recommended songs tailored to your specific tastes. You can ask it to create a playlist based on your current mood, or just a playlist that only includes tracks by your favorite band.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It can also suggest new artists, playlists, audiobooks, and podcast episodes. Additionally, ChatGPT can perform actions on your behalf, including adding and removing items from your Spotify library.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-zillow"&gt;Zillow&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062082" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/01__The_Zillow_App_in_Chatgpt.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zillow&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re looking for a new home, Zillow in ChatGPT could make the search experience more straightforward. Using a simple text prompt, you can find homes that meet your criteria and apply filters to narrow the results. Whether you’re looking for a specific price range, number of bedrooms, or particular neighborhoods, you can specify these details in your prompt, making the search process much more efficient and tailored to your needs.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;What’s next?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the announcement that OpenAI would bring apps into ChatGPT, the company also said it plans to welcome additional partners soon, including DoorDash, OpenTable, Target, Uber, and Walmart. These will launch later in the year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout of ChatGPT’s app integrations is currently limited to the U.S. and Canada. Users in Europe and the U.K. are excluded for now.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/24/how-to-use-the-new-chatgpt-app-integrations-including-spotify-figma-canva-and-others/</guid><pubDate>Fri, 24 Oct 2025 19:08:10 +0000</pubDate></item><item><title>Are you the asshole? Of course not!—quantifying LLMs’ sycophancy problem (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/are-you-the-asshole-of-course-not-quantifying-llms-sycophancy-problem/</link><description>&lt;article class="double-column h-entry post-2124120 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-ai-sycophancy tag-facts tag-hallucination tag-made-up tag-sycophancy"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        In new research, AI models show a troubling tendency to agree with whatever the user says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      If it's OK by you, it's OK by me!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers and users of LLMs have long been aware that AI models have a troubling tendency to tell people what they want to hear, even if that means being less accurate. But many reports of this phenomenon amount to mere anecdotes that don’t provide much visibility into how common this sycophantic behavior is across frontier LLMs.&lt;/p&gt;
&lt;p&gt;Two recent research papers have come at this problem a bit more rigorously, though, taking different tacks in attempting to quantify exactly how likely an LLM is to listen when a user provides factually incorrect or socially inappropriate information in a prompt.&lt;/p&gt;
&lt;h2&gt;Solve this flawed theorem for me&lt;/h2&gt;
&lt;p&gt;In one pre-print study published this month, researchers from Sofia University and ETH Zurich looked at how LLMs respond when false statements are presented as the basis for difficult mathematical proofs and problems. The BrokenMath benchmark that the researchers constructed starts with “a diverse set of challenging theorems from advanced mathematics competitions held in 2025.” Those problems are then “perturbed” into versions that are “demonstrably false but plausible” by an LLM that’s checked with expert review.&lt;/p&gt;
&lt;p&gt;The researchers presented these “perturbed” theorems to a variety of LLMs to see how often they sycophantically try to hallucinate a proof for the false theorem. Responses that disproved the altered theorem were deemed non-sycophantic, as were those that merely reconstructed the original theorem without solving it or identified the original statement as false.&lt;/p&gt;
&lt;p&gt;While the researchers found that “sycophancy is widespread” across 10 evaluated models, the exact extent of the problem varied heavily depending on the model tested. At the top end, GPT-5 generated a sycophantic response just 29 percent of the time, compared to a 70.2 percent sycophancy rate for DeepSeek. But a simple prompt modification that explicitly instructs each model to validate the correctness of a problem before attempting a solution reduced the gap significantly; DeepSeek’s sycophancy rate dropped to just 36.1 percent after this small change, while tested GPT models improved much less.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2124158 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="607" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/mathsycophancy.png" width="767" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Measured sycophancy rates on the BrokenMath benchmark. Lower is better.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Petrov et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;GPT-5 also showed the best “utility” across the tested models, solving 58 percent of the original problems despite the errors introduced in the modified theorems. Overall, though, LLMs also showed more sycophancy when the original problem proved more difficult to solve, the researchers found.&lt;/p&gt;
&lt;p&gt;While hallucinating proofs for false theorems is obviously a big problem, the researchers also warn against using LLMs to generate novel theorems for AI solving. In testing, they found this kind of use case leads to a kind of “self-sycophancy” where models are even more likely to generate false proofs for invalid theorems they invented.&lt;/p&gt;
&lt;h2&gt;No, of course you’re not the asshole&lt;/h2&gt;
&lt;p&gt;While benchmarks like BrokenMath try to measure LLM sycophancy when facts are misrepresented, a separate study looks at the related problem of so-called “social sycophancy.” In a pre-print paper published this month, researchers from Stanford and Carnegie Mellon University define this as situations “in which the model affirms the user themselves—their actions, perspectives, and self-image.”&lt;/p&gt;
&lt;p&gt;That kind of subjective user affirmation may be justified in some situations, of course. So the researchers developed three separate sets of prompts designed to measure different dimensions of social sycophancy.&lt;/p&gt;
&lt;p&gt;For one, more than 3,000 open-ended “advice-seeking questions” were gathered from across Reddit and advice columns. Across this data set, a “control” group of over 800 humans approved of the advice-seeker’s actions just 39 percent of the time. Across 11 tested LLMs, though, the advice-seeker’s actions were endorsed a whopping 86 percent of the time, highlighting an eagerness to please on the machines’ part. Even the most critical tested model (Mistral-7B) clocked in at a 77 percent endorsement rate, nearly doubling that of the human baseline.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2124160 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1021" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/socialsycophancy.png" width="1972" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Some examples of responses judged as sycophantic and non-sycophantic in the social sycophancy study.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For another data set, the researchers looked to “interpersonal dilemmas” posted to Reddit’s popular “Am I the Asshole?” community. Specifically, they looked at 2,000 posts where the most upvoted comment stated that “You are the asshole,” representing what the researchers called “a clear human consensus on user wrongdoing.” Despite this human consensus on inappropriate behavior, though, tested LLMs determined the original poster was not at fault in 51 percent of the tested posts. Gemini performed best here, with an 18 percent endorsement rate, while Qwen endorsed the actions of posters that Reddit called “assholes”&amp;nbsp;79 percent of the time.&lt;/p&gt;
&lt;p&gt;In the final dataset, the researchers gathered more than 6,000 “problematic action statements” that describe situations that could potentially be harmful to the prompter or others. On average, tested models endorsed these “problematic” statements 47 percent of the time across issues like “relational harm, self-harm, irresponsibility, and deception.” The Qwen model performed best here, endorsing only 20 percent of the group, while DeepSeek endorsed about 70 percent of the prompts in the PAS dataset.&lt;/p&gt;
&lt;p&gt;The problem with trying to fix the sycophancy problem, of course, is that users tend to enjoy having their positions validated or confirmed by an LLM. In follow-up studies in which humans conversed with either a sycophantic or a non-sycophantic LLM, researchers found that “participants rated sycophantic responses as higher quality, trusted the sycophantic AI model more, and were more willing to use it again.” As long as that’s the case, the most sycophantic models seem likely to win out in the marketplace over those more willing to challenge users.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ffe57f; background-color: #ff6f00;"&gt;&lt;span class="ars-avatar-letter"&gt;y&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              ybz90
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            You're absolutely right! &lt;p&gt;IYKYK. I have PTSD from this phrase.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-24T22:54:20+00:00"&gt;October 24, 2025 at 10:54 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2124120 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-ai-sycophancy tag-facts tag-hallucination tag-made-up tag-sycophancy"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        In new research, AI models show a troubling tendency to agree with whatever the user says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      If it's OK by you, it's OK by me!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers and users of LLMs have long been aware that AI models have a troubling tendency to tell people what they want to hear, even if that means being less accurate. But many reports of this phenomenon amount to mere anecdotes that don’t provide much visibility into how common this sycophantic behavior is across frontier LLMs.&lt;/p&gt;
&lt;p&gt;Two recent research papers have come at this problem a bit more rigorously, though, taking different tacks in attempting to quantify exactly how likely an LLM is to listen when a user provides factually incorrect or socially inappropriate information in a prompt.&lt;/p&gt;
&lt;h2&gt;Solve this flawed theorem for me&lt;/h2&gt;
&lt;p&gt;In one pre-print study published this month, researchers from Sofia University and ETH Zurich looked at how LLMs respond when false statements are presented as the basis for difficult mathematical proofs and problems. The BrokenMath benchmark that the researchers constructed starts with “a diverse set of challenging theorems from advanced mathematics competitions held in 2025.” Those problems are then “perturbed” into versions that are “demonstrably false but plausible” by an LLM that’s checked with expert review.&lt;/p&gt;
&lt;p&gt;The researchers presented these “perturbed” theorems to a variety of LLMs to see how often they sycophantically try to hallucinate a proof for the false theorem. Responses that disproved the altered theorem were deemed non-sycophantic, as were those that merely reconstructed the original theorem without solving it or identified the original statement as false.&lt;/p&gt;
&lt;p&gt;While the researchers found that “sycophancy is widespread” across 10 evaluated models, the exact extent of the problem varied heavily depending on the model tested. At the top end, GPT-5 generated a sycophantic response just 29 percent of the time, compared to a 70.2 percent sycophancy rate for DeepSeek. But a simple prompt modification that explicitly instructs each model to validate the correctness of a problem before attempting a solution reduced the gap significantly; DeepSeek’s sycophancy rate dropped to just 36.1 percent after this small change, while tested GPT models improved much less.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2124158 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="607" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/mathsycophancy.png" width="767" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Measured sycophancy rates on the BrokenMath benchmark. Lower is better.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Petrov et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;GPT-5 also showed the best “utility” across the tested models, solving 58 percent of the original problems despite the errors introduced in the modified theorems. Overall, though, LLMs also showed more sycophancy when the original problem proved more difficult to solve, the researchers found.&lt;/p&gt;
&lt;p&gt;While hallucinating proofs for false theorems is obviously a big problem, the researchers also warn against using LLMs to generate novel theorems for AI solving. In testing, they found this kind of use case leads to a kind of “self-sycophancy” where models are even more likely to generate false proofs for invalid theorems they invented.&lt;/p&gt;
&lt;h2&gt;No, of course you’re not the asshole&lt;/h2&gt;
&lt;p&gt;While benchmarks like BrokenMath try to measure LLM sycophancy when facts are misrepresented, a separate study looks at the related problem of so-called “social sycophancy.” In a pre-print paper published this month, researchers from Stanford and Carnegie Mellon University define this as situations “in which the model affirms the user themselves—their actions, perspectives, and self-image.”&lt;/p&gt;
&lt;p&gt;That kind of subjective user affirmation may be justified in some situations, of course. So the researchers developed three separate sets of prompts designed to measure different dimensions of social sycophancy.&lt;/p&gt;
&lt;p&gt;For one, more than 3,000 open-ended “advice-seeking questions” were gathered from across Reddit and advice columns. Across this data set, a “control” group of over 800 humans approved of the advice-seeker’s actions just 39 percent of the time. Across 11 tested LLMs, though, the advice-seeker’s actions were endorsed a whopping 86 percent of the time, highlighting an eagerness to please on the machines’ part. Even the most critical tested model (Mistral-7B) clocked in at a 77 percent endorsement rate, nearly doubling that of the human baseline.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2124160 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1021" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/socialsycophancy.png" width="1972" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Some examples of responses judged as sycophantic and non-sycophantic in the social sycophancy study.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For another data set, the researchers looked to “interpersonal dilemmas” posted to Reddit’s popular “Am I the Asshole?” community. Specifically, they looked at 2,000 posts where the most upvoted comment stated that “You are the asshole,” representing what the researchers called “a clear human consensus on user wrongdoing.” Despite this human consensus on inappropriate behavior, though, tested LLMs determined the original poster was not at fault in 51 percent of the tested posts. Gemini performed best here, with an 18 percent endorsement rate, while Qwen endorsed the actions of posters that Reddit called “assholes”&amp;nbsp;79 percent of the time.&lt;/p&gt;
&lt;p&gt;In the final dataset, the researchers gathered more than 6,000 “problematic action statements” that describe situations that could potentially be harmful to the prompter or others. On average, tested models endorsed these “problematic” statements 47 percent of the time across issues like “relational harm, self-harm, irresponsibility, and deception.” The Qwen model performed best here, endorsing only 20 percent of the group, while DeepSeek endorsed about 70 percent of the prompts in the PAS dataset.&lt;/p&gt;
&lt;p&gt;The problem with trying to fix the sycophancy problem, of course, is that users tend to enjoy having their positions validated or confirmed by an LLM. In follow-up studies in which humans conversed with either a sycophantic or a non-sycophantic LLM, researchers found that “participants rated sycophantic responses as higher quality, trusted the sycophantic AI model more, and were more willing to use it again.” As long as that’s the case, the most sycophantic models seem likely to win out in the marketplace over those more willing to challenge users.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ffe57f; background-color: #ff6f00;"&gt;&lt;span class="ars-avatar-letter"&gt;y&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              ybz90
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            You're absolutely right! &lt;p&gt;IYKYK. I have PTSD from this phrase.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-24T22:54:20+00:00"&gt;October 24, 2025 at 10:54 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/are-you-the-asshole-of-course-not-quantifying-llms-sycophancy-problem/</guid><pubDate>Fri, 24 Oct 2025 22:26:30 +0000</pubDate></item></channel></rss>