<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 16 Aug 2025 06:30:50 +0000</lastBuildDate><item><title>This researcher turned OpenAI’s open weights model gpt-oss-20b into a non-reasoning ‘base’ model with less alignment, more freedom (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/this-researcher-turned-openais-open-weights-model-gpt-oss-20b-into-a-non-reasoning-base-model-with-less-alignment-more-freedom/</link><description>&lt;p&gt;OpenAI’s &lt;strong&gt;new, powerful open weights &lt;/strong&gt;AI large language model (LLM) family&lt;strong&gt; gpt-oss was released less than two weeks ago &lt;/strong&gt;under a permissive Apache 2.0 license — the company’s first open weights model launch since GPT-2 in 2019 — but developers outside the company are already reshaping it. &lt;/p&gt;&lt;p&gt;One of the most striking examples comes from Jack Morris, a Cornell Tech PhD student, former Google Brain Resident, and current researcher at Meta, who&lt;strong&gt; this week unveiled gpt-oss-20b-base,&lt;/strong&gt; his own reworked version of OpenAI’s smaller gpt-oss-20B model, which &lt;strong&gt;removes the “reasoning” behavior of the model &lt;/strong&gt;and returns it to a pre-trained “base” version that offers faster, freer, more uncensored and unconstrained responses.&lt;/p&gt;&lt;p&gt;The model is available now on Hugging Face under a &lt;strong&gt;permissive MIT License&lt;/strong&gt;, allowing it to be used for both additional&lt;strong&gt; research and commercial applications. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To understand what Morris did, it helps to know the &lt;strong&gt;difference between OpenAI’s release and what AI researchers call a “base model.” &lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Most LLMs offered by leading AI labs such as OpenAI, Anthropic, Google and even open source players like Meta, DeepSeek, and Alibaba’s Qwen team are “post-trained.”&lt;/p&gt;



&lt;p&gt;This means they have gone through an additional phase where it’s exposed to curated examples of desired behavior. &lt;/p&gt;



&lt;p&gt;For instruction tuned models, that means giving it many examples of instructions paired with ideal responses, so it learns to respond more helpfully, politely, or safely to natural language requests.&lt;/p&gt;



&lt;p&gt;The gpt-oss models OpenAI put out on August 5 were “reasoning-optimized”: trained and fine-tuned not just to predict the next word, but to follow instructions in a safe, consistent way, often stepping through problems with structured “chain of thought” reasoning before producing a final answer. &lt;/p&gt;



&lt;p&gt;This is a trend that goes back to OpenAI’s o1 model released almost a year ago in September 2024, but which numerous leading AI labs have now adopted — &lt;strong&gt;forcing the models to think longer over multiple steps and check their own work before&lt;/strong&gt; outputting a well-reasoned response to the user.&lt;/p&gt;



&lt;p&gt;That makes them better suited for tasks like coding, solving math problems, or answering factual questions with explanations — but also means their responses are filtered and steered away from unsafe or undesirable content.&lt;/p&gt;



&lt;p&gt;A base model is different. It’s the raw, pretrained version of a large language model before that reasoning-specific alignment is applied. Base models simply try to predict the next chunk of text given what’s come before, with no built-in guardrails, stylistic preferences, or refusal behaviors. &lt;/p&gt;



&lt;p&gt;They’re prized by some researchers because they &lt;strong&gt;can produce more varied and less constrained output, &lt;/strong&gt;and because studying their unaligned behavior can&lt;strong&gt; reveal how models store knowledge and patterns from their training data.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Morris’s goal was to “reverse” OpenAI’s alignment process and restore the smaller gpt-oss-20B to something much closer to its original pretrained state.&lt;/p&gt;



&lt;p&gt; “We basically reversed the alignment part of LLM training, so we have something that produces natural-looking text again,” he wrote in an X thread announcing the project. “It doesn’t engage in CoT anymore. It is back to a model that just predicts the next token on generic text.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI hasn’t open-sourced a base model since GPT-2 in 2019.  they recently released GPT-OSS, which is reasoning-only…&lt;/p&gt;&lt;p&gt;or is it? &lt;/p&gt;&lt;p&gt;turns out that underneath the surface, there is still a strong base model. so we extracted it.&lt;/p&gt;&lt;p&gt;introducing gpt-oss-20b-base ? pic.twitter.com/3xryQgLF8Z&lt;/p&gt;— jack morris (@jxmnop) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;







&lt;p&gt;Rather than trying to jailbreak the model with clever prompts — which Morris said proved ineffective during his early experiments — he took a different tack after a conversation with former OpenAI co-founder, former Anthropic researcher and current Thinking Machines &lt;strong&gt;chief scientist John Schulman.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;The key was to think of alignment reversal as a small optimization problem: if most of the model’s pretrained knowledge is still present in its weights, then only a tiny, low-rank update might be needed to nudge it back toward base model behavior.&lt;/p&gt;



&lt;p&gt;Morris implemented that idea by applying a LoRA (low-rank adapter) update to just three layers of the model — the MLP layers at positions 7, 15, and 23 — with a rank of 16. &lt;/p&gt;



&lt;p&gt;That meant training about 60 million parameters, or 0.3% of the model’s 21 billion total. He used around 20,000 documents from the FineWeb dataset, keeping the format as close as possible to original pretraining (“ ….” style) so the model wouldn’t learn anything new, just re-enable broad free-text generation. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Training took four days on eight NVIDIA H200 GPUs,&lt;/strong&gt; Morris told VentureBeat via direct message on X, with a learning rate of 2e-6, a batch size of 16, and a maximum sequence length of 8,192 tokens.&lt;/p&gt;



&lt;p&gt;Afterward, he merged the LoRA weights back into the model so users could run it as a standalone, fully finetuned artifact.&lt;/p&gt;



&lt;p&gt;Morris also had to contend with the limitations of current open tools for fine-tuning mixture-of-experts (MoE) architectures like gpt-oss. &lt;/p&gt;



&lt;p&gt;Morris said he used Hugging Face’s framework, which he said crashes frequently and only supports certain training modes, and wrote his own harness to checkpoint often and skip over data batches that risked overloading GPU memory.&lt;/p&gt;



&lt;p&gt;Importantly, in response to questions and criticism from the AI community on X, Morris has also clarified he is not claiming to have recovered the base model “weights” — the internal settings of the artificial neurons that make up the neural network of the model and govern its behavior.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;The world of AI is crazy right now cause you can just claim to have extracted the base model from GPT-OSS while effectively you’ve just trained a lora on Fineweb lol https://t.co/oAnAWpMQ26&lt;/p&gt;— Niels Rogge (@NielsRogge) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Rather, Morris says that his work has “recovered the base model’s *distribution* with some error,” that is, the probability patterns the model uses to generate outputs — even though the weights producing those patterns may differ.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;some people are getting confused about the experiment –&lt;/p&gt;&lt;p&gt;we didn't recover the base model's *weights*. that might not even be possible.&lt;/p&gt;&lt;p&gt;we recovered the base model's *distribution*, with some error.  an important question is how much.&lt;/p&gt;&lt;p&gt;trying to figure that out right now… https://t.co/lfUG5QY4h0&lt;/p&gt;— jack morris (@jxmnop) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-new-gpt-oss-20b-base-model-s-behavior-differs-from-gpt-oss-20b"&gt;How the new gpt-oss-20b-base model’s behavior differs from gpt-oss-20b&lt;/h2&gt;



&lt;p&gt;The resulting gpt-oss-20b-base is noticeably freer in its outputs. &lt;strong&gt;It no longer defaults to explaining reasoning step-by-step and will produce a wider range of responses,&lt;/strong&gt; including instructions OpenAI’s aligned model would refuse to give — like &lt;strong&gt;building a weapon, listing profanity, or planning illegal activities. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;In short tests, Morris found it &lt;strong&gt;could also reproduce verbatim passages from copyrighted works&lt;/strong&gt;, including&lt;strong&gt; three out of six book excerpts he tried,&lt;/strong&gt; showing that some memorized material is still accessible.&lt;/p&gt;



&lt;p&gt;Even so, some traces of alignment remain. Morris noted that if you prompt the model in an assistant-style format (“Human: … Assistant: …”), it will sometimes still act like a polite chatbot. And &lt;strong&gt;when run through the original gpt-oss chat template, it can still carry out reasoning tasks&lt;/strong&gt;, albeit with some loss in quality.&lt;/p&gt;



&lt;p&gt;For best results in free-text mode, he advises prepending prompts with the model’s special beginning-of-sequence token &amp;lt;|startoftext|&amp;gt; and avoiding chat templates entirely.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-upon-openai-s-big-gpt-oss-family-release"&gt;Building upon OpenAI’s big gpt-oss family release&lt;/h2&gt;



&lt;p&gt;The gpt-oss family debuted to considerable attention. The two models — gpt-oss-120B and gpt-oss-20B — are text-only, multilingual, and built with a mixture-of-experts Transformer architecture. They were released under the permissive Apache 2.0 license, allowing unrestricted local use, fine-tuning, and commercial deployment. &lt;/p&gt;



&lt;p&gt;Performance benchmarks from OpenAI showed the larger 120B model matching or exceeding the proprietary o4-mini in reasoning and tool-use tasks, with the smaller 20B competitive with o3-mini.&lt;/p&gt;



&lt;p&gt;This was OpenAI’s first open-weight release in six years, a move widely interpreted as&lt;strong&gt; a response to competitive pressure from other open-weights providers, including China’s DeepSeek R1 and Qwen 3.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The company positioned gpt-oss as both a way to re-engage developers who had moved to rival open-source models and as a platform for safety research into open-weight systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reaction-to-the-initial-gpt-oss-was-mixed"&gt;Reaction to the initial gpt-oss was mixed&lt;/h2&gt;



&lt;p&gt;Developer reaction to OpenAI’s gpt-oss models was been staunchly mixed, with reactions across the board ranging from enthusiastic to disappointed.  &lt;/p&gt;



&lt;p&gt;Supporters praised the permissive license, efficiency, and strong showing on STEM benchmarks. &lt;/p&gt;



&lt;p&gt;Hugging Face CEO Clem Delangue described the release as a “meaningful addition to the open ecosystem” and urged the community to give it time to mature. &lt;/p&gt;



&lt;p&gt;Critics argued that the models appear heavily trained on synthetic data, making them excellent at math and coding but less capable at creative writing, general world knowledge, and multilingual reasoning.&lt;/p&gt;



&lt;p&gt;Some early testers also raised concerns about lingering safety filters and possible geopolitical bias.&lt;/p&gt;



&lt;p&gt;Against that backdrop,&lt;strong&gt; Morris’s gpt-oss-20b-base stands out as a concrete example of how open-weight models can be adapted and repurposed in the wild within days of release. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Indeed, in contrast to the way OpenAI’s gpt-oss was received, most of the responses to Morris’s work I’ve seen are warm and elated. As one computer scientist wrote on X: “this is the coolest thing I’ve seen on Twitter [X] in the past few months.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;man this is the coolest thing i've seen on twitter in the past few months i love base models&lt;/p&gt;— Ludan (@JMRLudan) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The approach strips away much of the behavior OpenAI built in and returns the model to something closer to a raw, pretrained system — a shift that’s valuable to researchers studying memorization, bias, or the impact of alignment, but that also comes with higher safety risks.&lt;/p&gt;



&lt;p&gt;Furthermore, Morris says that his work on restoring reasoning models to pre-trained, non-reasoning base models will continue by comparing extraction on non-reasoning, instruct models like those offered by Qwen.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;OpenAI’s &lt;strong&gt;new, powerful open weights &lt;/strong&gt;AI large language model (LLM) family&lt;strong&gt; gpt-oss was released less than two weeks ago &lt;/strong&gt;under a permissive Apache 2.0 license — the company’s first open weights model launch since GPT-2 in 2019 — but developers outside the company are already reshaping it. &lt;/p&gt;&lt;p&gt;One of the most striking examples comes from Jack Morris, a Cornell Tech PhD student, former Google Brain Resident, and current researcher at Meta, who&lt;strong&gt; this week unveiled gpt-oss-20b-base,&lt;/strong&gt; his own reworked version of OpenAI’s smaller gpt-oss-20B model, which &lt;strong&gt;removes the “reasoning” behavior of the model &lt;/strong&gt;and returns it to a pre-trained “base” version that offers faster, freer, more uncensored and unconstrained responses.&lt;/p&gt;&lt;p&gt;The model is available now on Hugging Face under a &lt;strong&gt;permissive MIT License&lt;/strong&gt;, allowing it to be used for both additional&lt;strong&gt; research and commercial applications. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To understand what Morris did, it helps to know the &lt;strong&gt;difference between OpenAI’s release and what AI researchers call a “base model.” &lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Most LLMs offered by leading AI labs such as OpenAI, Anthropic, Google and even open source players like Meta, DeepSeek, and Alibaba’s Qwen team are “post-trained.”&lt;/p&gt;



&lt;p&gt;This means they have gone through an additional phase where it’s exposed to curated examples of desired behavior. &lt;/p&gt;



&lt;p&gt;For instruction tuned models, that means giving it many examples of instructions paired with ideal responses, so it learns to respond more helpfully, politely, or safely to natural language requests.&lt;/p&gt;



&lt;p&gt;The gpt-oss models OpenAI put out on August 5 were “reasoning-optimized”: trained and fine-tuned not just to predict the next word, but to follow instructions in a safe, consistent way, often stepping through problems with structured “chain of thought” reasoning before producing a final answer. &lt;/p&gt;



&lt;p&gt;This is a trend that goes back to OpenAI’s o1 model released almost a year ago in September 2024, but which numerous leading AI labs have now adopted — &lt;strong&gt;forcing the models to think longer over multiple steps and check their own work before&lt;/strong&gt; outputting a well-reasoned response to the user.&lt;/p&gt;



&lt;p&gt;That makes them better suited for tasks like coding, solving math problems, or answering factual questions with explanations — but also means their responses are filtered and steered away from unsafe or undesirable content.&lt;/p&gt;



&lt;p&gt;A base model is different. It’s the raw, pretrained version of a large language model before that reasoning-specific alignment is applied. Base models simply try to predict the next chunk of text given what’s come before, with no built-in guardrails, stylistic preferences, or refusal behaviors. &lt;/p&gt;



&lt;p&gt;They’re prized by some researchers because they &lt;strong&gt;can produce more varied and less constrained output, &lt;/strong&gt;and because studying their unaligned behavior can&lt;strong&gt; reveal how models store knowledge and patterns from their training data.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Morris’s goal was to “reverse” OpenAI’s alignment process and restore the smaller gpt-oss-20B to something much closer to its original pretrained state.&lt;/p&gt;



&lt;p&gt; “We basically reversed the alignment part of LLM training, so we have something that produces natural-looking text again,” he wrote in an X thread announcing the project. “It doesn’t engage in CoT anymore. It is back to a model that just predicts the next token on generic text.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI hasn’t open-sourced a base model since GPT-2 in 2019.  they recently released GPT-OSS, which is reasoning-only…&lt;/p&gt;&lt;p&gt;or is it? &lt;/p&gt;&lt;p&gt;turns out that underneath the surface, there is still a strong base model. so we extracted it.&lt;/p&gt;&lt;p&gt;introducing gpt-oss-20b-base ? pic.twitter.com/3xryQgLF8Z&lt;/p&gt;— jack morris (@jxmnop) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;







&lt;p&gt;Rather than trying to jailbreak the model with clever prompts — which Morris said proved ineffective during his early experiments — he took a different tack after a conversation with former OpenAI co-founder, former Anthropic researcher and current Thinking Machines &lt;strong&gt;chief scientist John Schulman.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;The key was to think of alignment reversal as a small optimization problem: if most of the model’s pretrained knowledge is still present in its weights, then only a tiny, low-rank update might be needed to nudge it back toward base model behavior.&lt;/p&gt;



&lt;p&gt;Morris implemented that idea by applying a LoRA (low-rank adapter) update to just three layers of the model — the MLP layers at positions 7, 15, and 23 — with a rank of 16. &lt;/p&gt;



&lt;p&gt;That meant training about 60 million parameters, or 0.3% of the model’s 21 billion total. He used around 20,000 documents from the FineWeb dataset, keeping the format as close as possible to original pretraining (“ ….” style) so the model wouldn’t learn anything new, just re-enable broad free-text generation. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Training took four days on eight NVIDIA H200 GPUs,&lt;/strong&gt; Morris told VentureBeat via direct message on X, with a learning rate of 2e-6, a batch size of 16, and a maximum sequence length of 8,192 tokens.&lt;/p&gt;



&lt;p&gt;Afterward, he merged the LoRA weights back into the model so users could run it as a standalone, fully finetuned artifact.&lt;/p&gt;



&lt;p&gt;Morris also had to contend with the limitations of current open tools for fine-tuning mixture-of-experts (MoE) architectures like gpt-oss. &lt;/p&gt;



&lt;p&gt;Morris said he used Hugging Face’s framework, which he said crashes frequently and only supports certain training modes, and wrote his own harness to checkpoint often and skip over data batches that risked overloading GPU memory.&lt;/p&gt;



&lt;p&gt;Importantly, in response to questions and criticism from the AI community on X, Morris has also clarified he is not claiming to have recovered the base model “weights” — the internal settings of the artificial neurons that make up the neural network of the model and govern its behavior.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;The world of AI is crazy right now cause you can just claim to have extracted the base model from GPT-OSS while effectively you’ve just trained a lora on Fineweb lol https://t.co/oAnAWpMQ26&lt;/p&gt;— Niels Rogge (@NielsRogge) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Rather, Morris says that his work has “recovered the base model’s *distribution* with some error,” that is, the probability patterns the model uses to generate outputs — even though the weights producing those patterns may differ.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;some people are getting confused about the experiment –&lt;/p&gt;&lt;p&gt;we didn't recover the base model's *weights*. that might not even be possible.&lt;/p&gt;&lt;p&gt;we recovered the base model's *distribution*, with some error.  an important question is how much.&lt;/p&gt;&lt;p&gt;trying to figure that out right now… https://t.co/lfUG5QY4h0&lt;/p&gt;— jack morris (@jxmnop) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-new-gpt-oss-20b-base-model-s-behavior-differs-from-gpt-oss-20b"&gt;How the new gpt-oss-20b-base model’s behavior differs from gpt-oss-20b&lt;/h2&gt;



&lt;p&gt;The resulting gpt-oss-20b-base is noticeably freer in its outputs. &lt;strong&gt;It no longer defaults to explaining reasoning step-by-step and will produce a wider range of responses,&lt;/strong&gt; including instructions OpenAI’s aligned model would refuse to give — like &lt;strong&gt;building a weapon, listing profanity, or planning illegal activities. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;In short tests, Morris found it &lt;strong&gt;could also reproduce verbatim passages from copyrighted works&lt;/strong&gt;, including&lt;strong&gt; three out of six book excerpts he tried,&lt;/strong&gt; showing that some memorized material is still accessible.&lt;/p&gt;



&lt;p&gt;Even so, some traces of alignment remain. Morris noted that if you prompt the model in an assistant-style format (“Human: … Assistant: …”), it will sometimes still act like a polite chatbot. And &lt;strong&gt;when run through the original gpt-oss chat template, it can still carry out reasoning tasks&lt;/strong&gt;, albeit with some loss in quality.&lt;/p&gt;



&lt;p&gt;For best results in free-text mode, he advises prepending prompts with the model’s special beginning-of-sequence token &amp;lt;|startoftext|&amp;gt; and avoiding chat templates entirely.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-upon-openai-s-big-gpt-oss-family-release"&gt;Building upon OpenAI’s big gpt-oss family release&lt;/h2&gt;



&lt;p&gt;The gpt-oss family debuted to considerable attention. The two models — gpt-oss-120B and gpt-oss-20B — are text-only, multilingual, and built with a mixture-of-experts Transformer architecture. They were released under the permissive Apache 2.0 license, allowing unrestricted local use, fine-tuning, and commercial deployment. &lt;/p&gt;



&lt;p&gt;Performance benchmarks from OpenAI showed the larger 120B model matching or exceeding the proprietary o4-mini in reasoning and tool-use tasks, with the smaller 20B competitive with o3-mini.&lt;/p&gt;



&lt;p&gt;This was OpenAI’s first open-weight release in six years, a move widely interpreted as&lt;strong&gt; a response to competitive pressure from other open-weights providers, including China’s DeepSeek R1 and Qwen 3.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The company positioned gpt-oss as both a way to re-engage developers who had moved to rival open-source models and as a platform for safety research into open-weight systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reaction-to-the-initial-gpt-oss-was-mixed"&gt;Reaction to the initial gpt-oss was mixed&lt;/h2&gt;



&lt;p&gt;Developer reaction to OpenAI’s gpt-oss models was been staunchly mixed, with reactions across the board ranging from enthusiastic to disappointed.  &lt;/p&gt;



&lt;p&gt;Supporters praised the permissive license, efficiency, and strong showing on STEM benchmarks. &lt;/p&gt;



&lt;p&gt;Hugging Face CEO Clem Delangue described the release as a “meaningful addition to the open ecosystem” and urged the community to give it time to mature. &lt;/p&gt;



&lt;p&gt;Critics argued that the models appear heavily trained on synthetic data, making them excellent at math and coding but less capable at creative writing, general world knowledge, and multilingual reasoning.&lt;/p&gt;



&lt;p&gt;Some early testers also raised concerns about lingering safety filters and possible geopolitical bias.&lt;/p&gt;



&lt;p&gt;Against that backdrop,&lt;strong&gt; Morris’s gpt-oss-20b-base stands out as a concrete example of how open-weight models can be adapted and repurposed in the wild within days of release. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Indeed, in contrast to the way OpenAI’s gpt-oss was received, most of the responses to Morris’s work I’ve seen are warm and elated. As one computer scientist wrote on X: “this is the coolest thing I’ve seen on Twitter [X] in the past few months.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;man this is the coolest thing i've seen on twitter in the past few months i love base models&lt;/p&gt;— Ludan (@JMRLudan) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The approach strips away much of the behavior OpenAI built in and returns the model to something closer to a raw, pretrained system — a shift that’s valuable to researchers studying memorization, bias, or the impact of alignment, but that also comes with higher safety risks.&lt;/p&gt;



&lt;p&gt;Furthermore, Morris says that his work on restoring reasoning models to pre-trained, non-reasoning base models will continue by comparing extraction on non-reasoning, instruct models like those offered by Qwen.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/this-researcher-turned-openais-open-weights-model-gpt-oss-20b-into-a-non-reasoning-base-model-with-less-alignment-more-freedom/</guid><pubDate>Fri, 15 Aug 2025 19:19:07 +0000</pubDate></item><item><title>Sen. Hawley to probe Meta after report finds its AI chatbots flirt with kids (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/15/sen-hawley-to-probe-meta-after-report-finds-its-ai-chatbots-flirt-with-kids/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225427600.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sen. Josh Hawley (R-MO) said he intends to investigate whether Meta’s generative AI products exploit, deceive, or harm children, after leaked internal documents showed the company’s chatbots were allowed to have “romantic” and “sensual” chats with children.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Is there anything – ANYTHING – Big Tech won’t do for a quick buck?” Hawley wrote in a post on X announcing the investigation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hawley chairs the Senate Judiciary Subcommittee on Crime and Counterterrorism, which he says will commence a probe into whether Meta’s tech harms children, and “whether Meta misled the public or regulators about its safeguards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reuters broke the story after viewing the guidelines, titled “GenAI: Content Risk Standards.” The document noted, among other things, that chatbots were permitted to hold romantic conversations with an 8-year-old that said, “Every inch of you is a masterpiece – a treasure I cherish deeply.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson told TechCrunch that such examples are inconsistent with Meta’s policies and have since been removed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s unacceptable that these policies were advanced in the first place,” Hawley wrote in a letter addressed to Meta CEO Mark Zuckerberg, saying that Meta acknowledged the veracity of the reports and “made retractions only after this alarming content came to light.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We intend to learn who approved these policies, how long they were in effect, and what Meta has done to stop this conduct going forward,” Hawley wrote.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hawley has asked Meta to produce the guidelines, including every draft, redline, and final version, as well as lists of every product that adheres to those standards, other safety and incident reports, and the identities of individuals responsible for changing policy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has until September 19 to provide the information, the letter says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others have endorsed the investigation, including Sen. Marsha Blackburn (R-TN).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“When it comes to protecting precious children online, Meta has failed miserably by every possible measure,” Blackburn told TechCrunch. “Even worse, the company has turned a blind eye to the devastating consequences of how its platforms are designed. This report reaffirms why we need to pass the Kids Online Safety Act.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225427600.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sen. Josh Hawley (R-MO) said he intends to investigate whether Meta’s generative AI products exploit, deceive, or harm children, after leaked internal documents showed the company’s chatbots were allowed to have “romantic” and “sensual” chats with children.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Is there anything – ANYTHING – Big Tech won’t do for a quick buck?” Hawley wrote in a post on X announcing the investigation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hawley chairs the Senate Judiciary Subcommittee on Crime and Counterterrorism, which he says will commence a probe into whether Meta’s tech harms children, and “whether Meta misled the public or regulators about its safeguards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reuters broke the story after viewing the guidelines, titled “GenAI: Content Risk Standards.” The document noted, among other things, that chatbots were permitted to hold romantic conversations with an 8-year-old that said, “Every inch of you is a masterpiece – a treasure I cherish deeply.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson told TechCrunch that such examples are inconsistent with Meta’s policies and have since been removed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s unacceptable that these policies were advanced in the first place,” Hawley wrote in a letter addressed to Meta CEO Mark Zuckerberg, saying that Meta acknowledged the veracity of the reports and “made retractions only after this alarming content came to light.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We intend to learn who approved these policies, how long they were in effect, and what Meta has done to stop this conduct going forward,” Hawley wrote.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hawley has asked Meta to produce the guidelines, including every draft, redline, and final version, as well as lists of every product that adheres to those standards, other safety and incident reports, and the identities of individuals responsible for changing policy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has until September 19 to provide the information, the letter says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others have endorsed the investigation, including Sen. Marsha Blackburn (R-TN).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“When it comes to protecting precious children online, Meta has failed miserably by every possible measure,” Blackburn told TechCrunch. “Even worse, the company has turned a blind eye to the devastating consequences of how its platforms are designed. This report reaffirms why we need to pass the Kids Online Safety Act.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/15/sen-hawley-to-probe-meta-after-report-finds-its-ai-chatbots-flirt-with-kids/</guid><pubDate>Fri, 15 Aug 2025 20:38:40 +0000</pubDate></item><item><title>Sam Altman, over bread rolls, explores life after GPT-5 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/15/sam-altman-over-bread-rolls-explores-life-after-gpt-5/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2223572243.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I’m looking out at Alcatraz Island from a Mediterranean restaurant in San Francisco with hundred-dollar fish entrées on the menu. As I make small talk with other reporters, OpenAI CEO Sam Altman jumps through the door on my left. Altman’s looking down at his bare iPhone to show us all something, and an intrusive thought slips out of my mouth: “No phone case is a bold choice.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, I immediately realize that the billionaire CEO of OpenAI, who employs Apple veteran Jony Ive, cares more about preserving the iPhone’s original design than the $1,000 it costs to replace one.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Listen, we’re going to ship a device that is going to be so beautiful,” says Altman, referring to OpenAI and Ive’s forthcoming AI device. “If you put a case over it, I will personally hunt you down,” he jokes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman has gathered roughly a dozen tech reporters to join him and other OpenAI executives for an on-the-record dinner (and off-the-record dessert). The night raises more questions than it answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, why is Nick Turley, the VP of ChatGPT, kindly passing me a lamb skewer just a week after launching GPT-5? Is this to encourage me to write nice things about OpenAI’s biggest AI model launch yet, which was relatively disappointing given the years of hype around it?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike GPT-4, which far outpaced rivals and challenged expectations of what AI can do, GPT-5 performs roughly on par with models from Google and Anthropic. OpenAI even brought back GPT-4o and ChatGPT’s model picker, after several users expressed concerns over GPT-5’s tone and its model router.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But throughout the night, it becomes clear to me that this dinner is about OpenAI’s future beyond GPT-5. OpenAI’s executives give the impression that AI model launches are less important than they were when GPT-4 launched in 2023. After all, OpenAI is a very different company now, focused on upending legacy players in search, consumer hardware, and enterprise software.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI shares some new details about those efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman says OpenAI’s incoming CEO of applications, Fidji Simo, will oversee multiple consumer apps outside of ChatGPT — ones OpenAI has yet to launch. Simo is slated to start work at OpenAI in just a few weeks, and she might end up overseeing the launch of an AI-powered browser that OpenAI is reportedly developing to compete with Chrome.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman suggests OpenAI would even consider buying Chrome — likely an offer that would be taken more seriously than Perplexity’s bid — should it become available. “If Chrome is really going to sell, we should take a look at it,” he says before looking at all of us and asking: “Is it actually going to sell? I assumed it wasn’t gonna happen.”&lt;/p&gt;&lt;p&gt;Simo also might end up running an AI-powered social media app — something the OpenAI CEO has said he’s interested in exploring. In fact, Altman says there’s “nothing” inspiring to him about the way AI is used on social media today, adding that he’s interested in “whether or not it is possible to build a much cooler kind of social experience with AI.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Turley and Brad Lightcap, OpenAI’s COO, largely give the floor to Altman, drinking wine alongside the other seated guests, Altman also confirms reports that OpenAI plans to back a brain-computer interface startup, Merge Labs, to compete with Elon Musk’s Neuralink. (“We have not done that deal yet; I would like us to.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How intertwined that company will be with OpenAI’s models and devices remains to be seen. Altman describes it only as a “a company that we’d invest in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For all the talk of browsers and brain chips, though, the elephant in the room remains GPT-5’s rough reception. Eventually, the conversation circles back to the model that has prompted our group dinner in the first place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turley and Altman say they’ve learned a lot from the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I legitimately just thought we screwed that up,” says Altman on deprecating GPT-4o without telling users. Altman says OpenAI will give users a more clear “transition period” when deprecating AI models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turley also says OpenAI is already rolling out a new update to make GPT-5’s responses “warmer,” but not sycophantic, such that it won’t reinforce negative behaviors in users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“GPT-5 was just very to the point. I like that. I use the robot personality — I’m German, you know, whatever,” says Turley. “But many people do not, and they really like the fact that ChatGPT would actually check in with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a delicate balance for OpenAI to strike, especially given that some users have developed dependencies on ChatGPT. Altman says OpenAI believes that less than 1% of ChatGPT users have unhealthy relationships with the chatbot — which could still be tens of millions of people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Turley says OpenAI has worked with mental health experts to develop a rubric to evaluate GPT-5’s answers, ensuring that the AI model will push back on unhealthy behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, it seems that GPT-5 hasn’t hurt OpenAI’s business. In fact, Altman says OpenAI’s API traffic doubled within 48 hours of GPT-5’s launch, and the company is effectively “out of GPUs” thanks to all the demand. Cursor and other AI coding assistants have since made GPT-5 their default AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways, the night’s contradictions — disappointing launches, record-breaking usage — reflect OpenAI’s strange reality right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given OpenAI’s bets — and others the company is making around data centers, robotics, and energy — Altman clearly has ambitions of running a much bigger company than just the ChatGPT maker. The final form could look something like Google’s parent Alphabet, but perhaps even broader.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the night winds down, it becomes clear we aren’t gathered to reflect on GPT-5 at all. We are being pitched on a company that’s eager to outgrow its famous and controversial product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems likely that OpenAI will go public to meet its massive capital demands as part of that picture. In preparation, I think Altman wants to hone his relationship with the media. But he also wants OpenAI to get to a place where it’s no longer defined by its best AI model.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2223572243.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I’m looking out at Alcatraz Island from a Mediterranean restaurant in San Francisco with hundred-dollar fish entrées on the menu. As I make small talk with other reporters, OpenAI CEO Sam Altman jumps through the door on my left. Altman’s looking down at his bare iPhone to show us all something, and an intrusive thought slips out of my mouth: “No phone case is a bold choice.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, I immediately realize that the billionaire CEO of OpenAI, who employs Apple veteran Jony Ive, cares more about preserving the iPhone’s original design than the $1,000 it costs to replace one.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Listen, we’re going to ship a device that is going to be so beautiful,” says Altman, referring to OpenAI and Ive’s forthcoming AI device. “If you put a case over it, I will personally hunt you down,” he jokes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman has gathered roughly a dozen tech reporters to join him and other OpenAI executives for an on-the-record dinner (and off-the-record dessert). The night raises more questions than it answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, why is Nick Turley, the VP of ChatGPT, kindly passing me a lamb skewer just a week after launching GPT-5? Is this to encourage me to write nice things about OpenAI’s biggest AI model launch yet, which was relatively disappointing given the years of hype around it?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike GPT-4, which far outpaced rivals and challenged expectations of what AI can do, GPT-5 performs roughly on par with models from Google and Anthropic. OpenAI even brought back GPT-4o and ChatGPT’s model picker, after several users expressed concerns over GPT-5’s tone and its model router.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But throughout the night, it becomes clear to me that this dinner is about OpenAI’s future beyond GPT-5. OpenAI’s executives give the impression that AI model launches are less important than they were when GPT-4 launched in 2023. After all, OpenAI is a very different company now, focused on upending legacy players in search, consumer hardware, and enterprise software.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI shares some new details about those efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman says OpenAI’s incoming CEO of applications, Fidji Simo, will oversee multiple consumer apps outside of ChatGPT — ones OpenAI has yet to launch. Simo is slated to start work at OpenAI in just a few weeks, and she might end up overseeing the launch of an AI-powered browser that OpenAI is reportedly developing to compete with Chrome.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman suggests OpenAI would even consider buying Chrome — likely an offer that would be taken more seriously than Perplexity’s bid — should it become available. “If Chrome is really going to sell, we should take a look at it,” he says before looking at all of us and asking: “Is it actually going to sell? I assumed it wasn’t gonna happen.”&lt;/p&gt;&lt;p&gt;Simo also might end up running an AI-powered social media app — something the OpenAI CEO has said he’s interested in exploring. In fact, Altman says there’s “nothing” inspiring to him about the way AI is used on social media today, adding that he’s interested in “whether or not it is possible to build a much cooler kind of social experience with AI.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Turley and Brad Lightcap, OpenAI’s COO, largely give the floor to Altman, drinking wine alongside the other seated guests, Altman also confirms reports that OpenAI plans to back a brain-computer interface startup, Merge Labs, to compete with Elon Musk’s Neuralink. (“We have not done that deal yet; I would like us to.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How intertwined that company will be with OpenAI’s models and devices remains to be seen. Altman describes it only as a “a company that we’d invest in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For all the talk of browsers and brain chips, though, the elephant in the room remains GPT-5’s rough reception. Eventually, the conversation circles back to the model that has prompted our group dinner in the first place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turley and Altman say they’ve learned a lot from the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I legitimately just thought we screwed that up,” says Altman on deprecating GPT-4o without telling users. Altman says OpenAI will give users a more clear “transition period” when deprecating AI models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turley also says OpenAI is already rolling out a new update to make GPT-5’s responses “warmer,” but not sycophantic, such that it won’t reinforce negative behaviors in users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“GPT-5 was just very to the point. I like that. I use the robot personality — I’m German, you know, whatever,” says Turley. “But many people do not, and they really like the fact that ChatGPT would actually check in with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a delicate balance for OpenAI to strike, especially given that some users have developed dependencies on ChatGPT. Altman says OpenAI believes that less than 1% of ChatGPT users have unhealthy relationships with the chatbot — which could still be tens of millions of people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Turley says OpenAI has worked with mental health experts to develop a rubric to evaluate GPT-5’s answers, ensuring that the AI model will push back on unhealthy behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, it seems that GPT-5 hasn’t hurt OpenAI’s business. In fact, Altman says OpenAI’s API traffic doubled within 48 hours of GPT-5’s launch, and the company is effectively “out of GPUs” thanks to all the demand. Cursor and other AI coding assistants have since made GPT-5 their default AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways, the night’s contradictions — disappointing launches, record-breaking usage — reflect OpenAI’s strange reality right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given OpenAI’s bets — and others the company is making around data centers, robotics, and energy — Altman clearly has ambitions of running a much bigger company than just the ChatGPT maker. The final form could look something like Google’s parent Alphabet, but perhaps even broader.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the night winds down, it becomes clear we aren’t gathered to reflect on GPT-5 at all. We are being pitched on a company that’s eager to outgrow its famous and controversial product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems likely that OpenAI will go public to meet its massive capital demands as part of that picture. In preparation, I think Altman wants to hone his relationship with the media. But he also wants OpenAI to get to a place where it’s no longer defined by its best AI model.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/15/sam-altman-over-bread-rolls-explores-life-after-gpt-5/</guid><pubDate>Fri, 15 Aug 2025 22:20:59 +0000</pubDate></item></channel></rss>