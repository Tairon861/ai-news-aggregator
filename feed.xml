<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 07 Jul 2025 18:31:27 +0000</lastBuildDate><item><title>The latest threat from the rise of Chinese manufacturing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/07/1119658/the-latest-threat-from-the-rise-of-chinese-manufacturing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/h_16188303.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The findings a decade ago were, well, shocking. Mainstream economists had long argued that free trade was overall a good thing; though there might be some winners and losers, it would generally bring lower prices and widespread prosperity. Then, in 2013, a trio of academic researchers showed convincing evidence that increased trade with China beginning in the early 2000s and the resulting flood of cheap imports had been an unmitigated disaster for many US communities, destroying their manufacturing lifeblood.&lt;/p&gt;  &lt;p&gt;The results of what in 2016 they called the “China shock” were gut-wrenching: the loss of 1 million US manufacturing jobs and 2.4 million jobs in total by 2011. Worse, these losses were heavily concentrated in what the economists called “trade-exposed” towns and cities (think furniture makers in North Carolina).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;If in retrospect all that seems obvious, it’s only because the research by David Autor, an MIT labor economist, and his colleagues has become an accepted, albeit often distorted, political narrative these days: China destroyed all our manufacturing jobs! Though the nuances of the research are often ignored, the results help explain at least some of today's political unrest. It’s reflected in rising calls for US protectionism, President Trump’s broad tariffs on imported goods, and nostalgia for the lost days of domestic manufacturing glory.&lt;/p&gt;  &lt;p&gt;The impacts of the original China shock still scar much of the country. But Autor is now concerned about what he considers a far more urgent problem—what some are calling China shock 2.0. The US, he warns, is in danger of losing the next great manufacturing battle, this time over advanced technologies to make cars and planes as well as those enabling AI, quantum computing, and fusion energy.&lt;/p&gt; 
 &lt;p&gt;Recently, I asked Autor about the lingering impacts of the China shock and the lessons it holds for today's manufacturing challenges.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How are the impacts of the China shock still playing out? &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I have a recent paper looking at 20 years of data, from 2000 to 2019. We tried to ask two related questions. One, if you looked at the places that were most exposed, how have they adjusted? And then if you look to the people who are most exposed, how have they adjusted? And how do those two things relate to one anothe&lt;/p&gt;  &lt;p&gt;It turns out you get two very different answers. If you look at places that were most exposed, they have been substantially transformed. Manufacturing, once it starts going down, never comes back. But after 2010, these trade-impacted local labor markets staged something of an employment recovery, such that employment has grown faster after 2010 in trade-exposed places than non-trade-exposed places because a lot of people have come in. But these are jobs mostly in low-wage sectors. They’re in K–12 education and non-traded health services. They’re in warehousing and logistics. They’re in hospitality and lodging and recreation, and so they’re lower-wage, non-manufacturing jobs. And they’re done by a really different set of people.&lt;/p&gt;  &lt;p&gt;The growth in employment is among women, among native-born Hispanics, among foreign-born adults and a lot of young people. The recovery is staged by a very different group from the white and black men, but especially white men, who were most represented in manufacturing. They have not really participated in this renaissance.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Employment is growing, but are these areas prospering?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;They have a lower wage structure: fewer high-wage jobs, more low-wage jobs. So they’re not, if your definition of prospering is rapidly rising incomes. But there’s a lot of employment growth. They’re not like ghost towns. But then if you look at the people who were most concentrated in manufacturing—mostly white, non-college, native-born men—they have not prospered. Most of them have not transitioned from manufacturing to non-manufacturing.&lt;/p&gt;  &lt;p&gt;One of the great surprises is everyone had believed that people would pull up stakes and move on. In fact, we find the opposite. People in the most adversely exposed places become less likely to leave. They have become less mobile. The presumption was that they would just relocate to find higher ground. And that is not at all what occurred.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What happened to the total number of manufacturing jobs?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There’s been no rebound. Once they go, they just keep going. If there is going to be new manufacturing, it won’t be in the sectors that were lost to China. Those were basically labor-intensive jobs, the kind of low-tech sectors that we will not be getting back. You know—commodity furniture and assembly of things, shoes, construction material. The US wasn’t going to keep them forever, and once they’re gone, it’s very unlikely to get them back.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;I know you’ve written about this, but it’s not hard to draw a connection between the dynamics you’re describing—white-male manufacturing jobs going away and new jobs going to immigrants—and today’s political turmoil.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We have a paper about that called “Importing Political Polarization?”&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How big a factor would you say it is in today’s political unrest?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I don’t want to say it’s &lt;em&gt;the &lt;/em&gt;factor. The China trade shock was a catalyst, but there were lots of other things that were happening. It would be a vast oversimplification to say that it was the sole cause.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;But most people don’t work in manufacturing anymore. Aren’t these impacts that you’re talking about, including the political unrest, disproportionate to the actual number of jobs lost?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;These are jobs in places where manufacturing is the anchor activity. Manufacturing is very unevenly distributed. It’s not like grocery stores and hospitals that you find in every county. The impact of the China trade shock on these places was like dropping an economic bomb in the middle of downtown. If the China trade shock cost us a few million jobs, and these were all—you know—people in groceries and retail and gas stations, in hospitality and in trucking, you wouldn’t really notice it that much. We lost lots of clerical workers over the last couple of decades. Nobody talks about a clerical shock. Why not? Well, there was never a clerical capital of America. Clerical workers are everywhere. If they decline, it doesn’t wipe out the entire basis of a place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So it goes beyond the jobs. These places lost their identity.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Maybe. But it’s also the jobs. Manufacturing offered relatively high pay to non-college workers, especially non-college men. It was an anchor of a way of life.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And we’re still seeing the damage.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah, absolutely. It’s been 20 years. What’s amazing is the degree of stasis among the people who are most exposed—not the places, but the people. Though it’s been 20 years, we’re still feeling the pain and the political impacts from this transition.&lt;/p&gt; 
 &lt;p&gt;Clearly, it has now entered the national psyche. Even if it weren’t true, everyone now believes it to have been a really big deal, and they’re responding to it. It continues to drive policy, political resentments, maybe even out of proportion to its economic significance. It certainly has become mythological.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What worries you now?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;We’re in the midst of a totally different competition with China now that’s much, much more important. Now we’re not talking about commodity furniture and tube socks. We’re talking about semiconductors and drones and aviation, electric vehicles, shipping, fusion power, quantum, AI, robotics. These are the sectors where the US still maintains competitiveness, but they’re extremely threatened. China’s capacity for high-tech, low-cost, incredibly fast, innovative manufacturing is just unbelievable. And the Trump administration is basically fighting the war of 20 years ago. The loss of those jobs, you know, was devastating to those places. It was not devastating to the US economy as a whole. If we lose Boeing, GM, and Apple and Intel—and that’s quite possible—then that will be economically devastating.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I think some people are calling it China shock 2.0.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah. And it’s well underway.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;When we think about advanced manufacturing and why it’s important, it’s not so much about the number of jobs anymore, is it? Is it more about coming up with the next technologies?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It does create good jobs, but it’s about economic leadership. It’s about innovation. It’s about political leadership, and even standard setting for how the rest of the world works.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Should we just accept that manufacturing as a big source of jobs is in the past and move on?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No. It’s still 12 million jobs, right? Instead of the fantasy that we’re going to go back to 18 million or whatever—we had, what, 17.7 million manufacturing jobs in 1999—we should be worried about the fact that we’re going to end up at 6 million, that we’re going to lose 50% in the next decade. And that’s quite possible. And the Trump administration is doing a lot to help that process of loss along.&lt;/p&gt;  &lt;p&gt;We have a labor market of over 160 million people, so it’s like 8% of employment. It’s not zero. So you should not think of it as too small to worry about it. It’s a lot of people; it’s a lot of jobs. But more important, it’s a lot of what has helped this country be a leader. So much innovation happens here, and so many of the things in which other countries are now innovating started here. It’s always been the case that the US tends to innovate in sectors and then lose them after a while and move on to the next thing. But at this point, it’s not clear that we’ll be in the frontier of a lot of these sectors for much longer.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;&lt;strong&gt;So we want to revive manufacturing, but the right kind—advanced manufacturing?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The notion that we should be assembling iPhones in the United States, which Trump wants, is insane. Nobody wants to do that work. It’s horrible, tedious work. It pays very, very little. And if we actually did it here, it would make the iPhones 20% more expensive or more. Apple may very well decide to pay a 25% tariff rather than make the phones here. If Foxconn started doing iPhone assembly here, people would not be lining up for that job.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But at the same time, we do need new people coming into manufacturing.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;But not &lt;em&gt;that &lt;/em&gt;manufacturing. Not tedious, mind-numbing, eyestrain-inducing assembly.&lt;/p&gt;  &lt;p&gt;We need them to do high-tech work. Manufacturing is a skilled activity. We need to build airplanes better. That takes a ton of expertise. Assembling iPhones does not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are your top priorities to head off China shock 2.0?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I would choose sectors that are important, and I would invest in them. I don’t think that tariffs are never justified, or industrial policies are never justified. I just don’t think protecting phone assembly is smart industrial policy. We really need to improve our ability to make semiconductors. I think that’s important. We need to remain competitive in the automobile sector—that’s important. We need to improve aviation and drones. That’s important. We need to invest in fusion power. That’s important. We need to adopt robotics at scale and improve in that sector. That’s important. I could come up with 15 things where I think public money is justified, and I would be willing to tolerate protections for those sectors.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are the lasting lessons of the China shock and the opening up of global trade in the 2000s?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;We did it too fast. We didn’t do enough to support people, and we pretended it wasn’t going on.&lt;/p&gt;  &lt;p&gt;When we started the China shock research back around 2011, we really didn’t know what we’d find, and so we were as surprised as anyone. But the work has changed our own way of thinking and, I think, has been constructive—not because it has caused everyone to do the right thing, but it at least caused people to start asking the right questions.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What do the findings tell us about China shock 2.0?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the US is handling that challenge badly. The problem is much more serious this time around. The truth is, we have a sense of what the threats are. And yet we’re not seemingly responding in a very constructive way. Although we now know how seriously we should take this, the problem is that it doesn’t seem to be generating very serious policy responses. We’re generating a lot of policy responses—they’re just not serious ones.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/h_16188303.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The findings a decade ago were, well, shocking. Mainstream economists had long argued that free trade was overall a good thing; though there might be some winners and losers, it would generally bring lower prices and widespread prosperity. Then, in 2013, a trio of academic researchers showed convincing evidence that increased trade with China beginning in the early 2000s and the resulting flood of cheap imports had been an unmitigated disaster for many US communities, destroying their manufacturing lifeblood.&lt;/p&gt;  &lt;p&gt;The results of what in 2016 they called the “China shock” were gut-wrenching: the loss of 1 million US manufacturing jobs and 2.4 million jobs in total by 2011. Worse, these losses were heavily concentrated in what the economists called “trade-exposed” towns and cities (think furniture makers in North Carolina).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;If in retrospect all that seems obvious, it’s only because the research by David Autor, an MIT labor economist, and his colleagues has become an accepted, albeit often distorted, political narrative these days: China destroyed all our manufacturing jobs! Though the nuances of the research are often ignored, the results help explain at least some of today's political unrest. It’s reflected in rising calls for US protectionism, President Trump’s broad tariffs on imported goods, and nostalgia for the lost days of domestic manufacturing glory.&lt;/p&gt;  &lt;p&gt;The impacts of the original China shock still scar much of the country. But Autor is now concerned about what he considers a far more urgent problem—what some are calling China shock 2.0. The US, he warns, is in danger of losing the next great manufacturing battle, this time over advanced technologies to make cars and planes as well as those enabling AI, quantum computing, and fusion energy.&lt;/p&gt; 
 &lt;p&gt;Recently, I asked Autor about the lingering impacts of the China shock and the lessons it holds for today's manufacturing challenges.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How are the impacts of the China shock still playing out? &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I have a recent paper looking at 20 years of data, from 2000 to 2019. We tried to ask two related questions. One, if you looked at the places that were most exposed, how have they adjusted? And then if you look to the people who are most exposed, how have they adjusted? And how do those two things relate to one anothe&lt;/p&gt;  &lt;p&gt;It turns out you get two very different answers. If you look at places that were most exposed, they have been substantially transformed. Manufacturing, once it starts going down, never comes back. But after 2010, these trade-impacted local labor markets staged something of an employment recovery, such that employment has grown faster after 2010 in trade-exposed places than non-trade-exposed places because a lot of people have come in. But these are jobs mostly in low-wage sectors. They’re in K–12 education and non-traded health services. They’re in warehousing and logistics. They’re in hospitality and lodging and recreation, and so they’re lower-wage, non-manufacturing jobs. And they’re done by a really different set of people.&lt;/p&gt;  &lt;p&gt;The growth in employment is among women, among native-born Hispanics, among foreign-born adults and a lot of young people. The recovery is staged by a very different group from the white and black men, but especially white men, who were most represented in manufacturing. They have not really participated in this renaissance.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Employment is growing, but are these areas prospering?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;They have a lower wage structure: fewer high-wage jobs, more low-wage jobs. So they’re not, if your definition of prospering is rapidly rising incomes. But there’s a lot of employment growth. They’re not like ghost towns. But then if you look at the people who were most concentrated in manufacturing—mostly white, non-college, native-born men—they have not prospered. Most of them have not transitioned from manufacturing to non-manufacturing.&lt;/p&gt;  &lt;p&gt;One of the great surprises is everyone had believed that people would pull up stakes and move on. In fact, we find the opposite. People in the most adversely exposed places become less likely to leave. They have become less mobile. The presumption was that they would just relocate to find higher ground. And that is not at all what occurred.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What happened to the total number of manufacturing jobs?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There’s been no rebound. Once they go, they just keep going. If there is going to be new manufacturing, it won’t be in the sectors that were lost to China. Those were basically labor-intensive jobs, the kind of low-tech sectors that we will not be getting back. You know—commodity furniture and assembly of things, shoes, construction material. The US wasn’t going to keep them forever, and once they’re gone, it’s very unlikely to get them back.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;I know you’ve written about this, but it’s not hard to draw a connection between the dynamics you’re describing—white-male manufacturing jobs going away and new jobs going to immigrants—and today’s political turmoil.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We have a paper about that called “Importing Political Polarization?”&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How big a factor would you say it is in today’s political unrest?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I don’t want to say it’s &lt;em&gt;the &lt;/em&gt;factor. The China trade shock was a catalyst, but there were lots of other things that were happening. It would be a vast oversimplification to say that it was the sole cause.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;But most people don’t work in manufacturing anymore. Aren’t these impacts that you’re talking about, including the political unrest, disproportionate to the actual number of jobs lost?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;These are jobs in places where manufacturing is the anchor activity. Manufacturing is very unevenly distributed. It’s not like grocery stores and hospitals that you find in every county. The impact of the China trade shock on these places was like dropping an economic bomb in the middle of downtown. If the China trade shock cost us a few million jobs, and these were all—you know—people in groceries and retail and gas stations, in hospitality and in trucking, you wouldn’t really notice it that much. We lost lots of clerical workers over the last couple of decades. Nobody talks about a clerical shock. Why not? Well, there was never a clerical capital of America. Clerical workers are everywhere. If they decline, it doesn’t wipe out the entire basis of a place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So it goes beyond the jobs. These places lost their identity.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Maybe. But it’s also the jobs. Manufacturing offered relatively high pay to non-college workers, especially non-college men. It was an anchor of a way of life.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And we’re still seeing the damage.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah, absolutely. It’s been 20 years. What’s amazing is the degree of stasis among the people who are most exposed—not the places, but the people. Though it’s been 20 years, we’re still feeling the pain and the political impacts from this transition.&lt;/p&gt; 
 &lt;p&gt;Clearly, it has now entered the national psyche. Even if it weren’t true, everyone now believes it to have been a really big deal, and they’re responding to it. It continues to drive policy, political resentments, maybe even out of proportion to its economic significance. It certainly has become mythological.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What worries you now?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;We’re in the midst of a totally different competition with China now that’s much, much more important. Now we’re not talking about commodity furniture and tube socks. We’re talking about semiconductors and drones and aviation, electric vehicles, shipping, fusion power, quantum, AI, robotics. These are the sectors where the US still maintains competitiveness, but they’re extremely threatened. China’s capacity for high-tech, low-cost, incredibly fast, innovative manufacturing is just unbelievable. And the Trump administration is basically fighting the war of 20 years ago. The loss of those jobs, you know, was devastating to those places. It was not devastating to the US economy as a whole. If we lose Boeing, GM, and Apple and Intel—and that’s quite possible—then that will be economically devastating.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I think some people are calling it China shock 2.0.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah. And it’s well underway.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;When we think about advanced manufacturing and why it’s important, it’s not so much about the number of jobs anymore, is it? Is it more about coming up with the next technologies?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It does create good jobs, but it’s about economic leadership. It’s about innovation. It’s about political leadership, and even standard setting for how the rest of the world works.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Should we just accept that manufacturing as a big source of jobs is in the past and move on?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No. It’s still 12 million jobs, right? Instead of the fantasy that we’re going to go back to 18 million or whatever—we had, what, 17.7 million manufacturing jobs in 1999—we should be worried about the fact that we’re going to end up at 6 million, that we’re going to lose 50% in the next decade. And that’s quite possible. And the Trump administration is doing a lot to help that process of loss along.&lt;/p&gt;  &lt;p&gt;We have a labor market of over 160 million people, so it’s like 8% of employment. It’s not zero. So you should not think of it as too small to worry about it. It’s a lot of people; it’s a lot of jobs. But more important, it’s a lot of what has helped this country be a leader. So much innovation happens here, and so many of the things in which other countries are now innovating started here. It’s always been the case that the US tends to innovate in sectors and then lose them after a while and move on to the next thing. But at this point, it’s not clear that we’ll be in the frontier of a lot of these sectors for much longer.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;&lt;strong&gt;So we want to revive manufacturing, but the right kind—advanced manufacturing?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The notion that we should be assembling iPhones in the United States, which Trump wants, is insane. Nobody wants to do that work. It’s horrible, tedious work. It pays very, very little. And if we actually did it here, it would make the iPhones 20% more expensive or more. Apple may very well decide to pay a 25% tariff rather than make the phones here. If Foxconn started doing iPhone assembly here, people would not be lining up for that job.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But at the same time, we do need new people coming into manufacturing.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;But not &lt;em&gt;that &lt;/em&gt;manufacturing. Not tedious, mind-numbing, eyestrain-inducing assembly.&lt;/p&gt;  &lt;p&gt;We need them to do high-tech work. Manufacturing is a skilled activity. We need to build airplanes better. That takes a ton of expertise. Assembling iPhones does not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are your top priorities to head off China shock 2.0?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I would choose sectors that are important, and I would invest in them. I don’t think that tariffs are never justified, or industrial policies are never justified. I just don’t think protecting phone assembly is smart industrial policy. We really need to improve our ability to make semiconductors. I think that’s important. We need to remain competitive in the automobile sector—that’s important. We need to improve aviation and drones. That’s important. We need to invest in fusion power. That’s important. We need to adopt robotics at scale and improve in that sector. That’s important. I could come up with 15 things where I think public money is justified, and I would be willing to tolerate protections for those sectors.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are the lasting lessons of the China shock and the opening up of global trade in the 2000s?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;We did it too fast. We didn’t do enough to support people, and we pretended it wasn’t going on.&lt;/p&gt;  &lt;p&gt;When we started the China shock research back around 2011, we really didn’t know what we’d find, and so we were as surprised as anyone. But the work has changed our own way of thinking and, I think, has been constructive—not because it has caused everyone to do the right thing, but it at least caused people to start asking the right questions.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What do the findings tell us about China shock 2.0?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the US is handling that challenge badly. The problem is much more serious this time around. The truth is, we have a sense of what the threats are. And yet we’re not seemingly responding in a very constructive way. Although we now know how seriously we should take this, the problem is that it doesn’t seem to be generating very serious policy responses. We’re generating a lot of policy responses—they’re just not serious ones.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/07/1119658/the-latest-threat-from-the-rise-of-chinese-manufacturing/</guid><pubDate>Mon, 07 Jul 2025 10:00:00 +0000</pubDate></item><item><title>How a big shift in training LLMs led to a capability explosion (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/how-a-big-shift-in-training-llms-led-to-a-capability-explosion/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Reinforcement learning, explained with a minimum of math and jargon.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ai-towers-hanoi.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In April 2023, a few weeks after the launch of GPT-4, the Internet went wild for two new software projects with the audacious names BabyAGI and AutoGPT.&lt;/p&gt;
&lt;p&gt;“Over the past week, developers around the world have begun building ‘autonomous agents’ that work with large language models (LLMs) such as OpenAI’s GPT-4 to solve complex problems,” Mark Sullivan&amp;nbsp;wrote&amp;nbsp;for Fast Company. “Autonomous agents can already perform tasks as varied as conducting web research, writing code, and creating to-do lists.”&lt;/p&gt;
&lt;p&gt;BabyAGI and AutoGPT repeatedly prompted GPT-4 in an effort to elicit agent-like behavior. The first prompt would give GPT-4 a goal (like “create a 7-day meal plan for me”) and&amp;nbsp;ask it&amp;nbsp;to come up with a to-do list (it might generate items like “Research healthy meal plans,” “plan meals for the week,” and “write the recipes for each dinner in diet.txt”).&lt;/p&gt;
&lt;p&gt;Then these frameworks would have GPT-4 tackle one step at a time. Their creators hoped that invoking GPT-4 in a loop like this would enable it to tackle projects that required many steps.&lt;/p&gt;
&lt;p&gt;But after an initial wave of hype, it became clear that GPT-4 wasn’t up to the task. Most of the time, GPT-4 could come up with a reasonable list of tasks. And sometimes it was able to complete a few individual tasks. But the model struggled to stay focused.&lt;/p&gt;
&lt;p&gt;Sometimes GPT-4 would make a small early mistake, fail to correct it, and then get more and more confused as it went along.&amp;nbsp;One early review&amp;nbsp;complained that BabyAGI “couldn’t seem to follow through on its list of tasks and kept changing task number one instead of moving on to task number two.”&lt;/p&gt;
&lt;p&gt;By the end of 2023, most people had abandoned AutoGPT and BabyAGI. It seemed that LLMs were not yet capable of reliable multi-step reasoning.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But that soon changed. In the second half of 2024, people started to create AI-powered systems that could consistently complete complex, multi-step assignments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vibe coding tools like Bolt.new, Lovable, and Replit allow someone with little to no programming experience to&amp;nbsp;create a full-featured app&amp;nbsp;with a single prompt.&lt;/li&gt;
&lt;li&gt;Agentic coding tools like&amp;nbsp;Cursor,&amp;nbsp;Claude Code,&amp;nbsp;Jules, and&amp;nbsp;Codex&amp;nbsp;help experienced programmers complete non-trivial programming tasks.&lt;/li&gt;
&lt;li&gt;Computer-use tools from Anthropic,&amp;nbsp;OpenAI, and&amp;nbsp;Manus&amp;nbsp;perform tasks on a desktop computer using a virtual keyboard and mouse.&lt;/li&gt;
&lt;li&gt;Deep research tools from&amp;nbsp;Google,&amp;nbsp;OpenAI, and&amp;nbsp;Perplexity&amp;nbsp;can research a topic for five to 10 minutes and then generate an in-depth report.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;According to Eric Simons, the CEO of the company that made Bolt.new, better models were crucial to its success. In a&amp;nbsp;December podcast interview, Simons said his company, StackBlitz, tried to build a product like Bolt.new in early 2024. However, AI models “just weren't good enough to actually do the code generation where the code was accurate.”&lt;/p&gt;
&lt;p&gt;A new generation of models changed that in mid-2024. StackBlitz developers tested them and said, “Oh my God, like, OK, we can build a product around this,” Simons said.&lt;/p&gt;
&lt;p&gt;This jump in model capabilities coincided with an industry-wide shift in how models were trained.&lt;/p&gt;
&lt;p&gt;Before 2024, AI labs devoted most of their computing power to pretraining. I described this process in my&amp;nbsp;2023 explainer on large language models: A model is trained to predict the next word in Wikipedia articles, news stories, and other documents. But throughout 2024, AI companies devoted a growing share of their training budgets to post-training, a catch-all term for the steps that come after this pretraining phase is complete.&lt;/p&gt;
&lt;p&gt;Many post-training steps use a technique called reinforcement learning. Reinforcement learning is a technical subject—there are&amp;nbsp;whole textbooks written about it. But in this article, I’ll try to explain the basics in a clear, jargon-free way. In the process, I hope to give readers an intuitive understanding of how reinforcement learning helped to enable the new generation of agentic AI systems that began to appear in the second half of 2024.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The problem with imitation learning&lt;/h2&gt;
&lt;p&gt;Machine learning experts consider pretraining to be a form of&amp;nbsp;imitation learning because models are trained to imitate the behavior of human authors. Imitation learning is a powerful technique (LLMs wouldn’t be possible without it), but it also has some significant limitations—limitations that reinforcement learning methods are now helping to overcome.&lt;/p&gt;
&lt;p&gt;To understand these limitations, let’s discuss some&amp;nbsp;famous research&amp;nbsp;performed by computer scientist Stephane Ross around 2009, while he was a graduate student at Carnegie Mellon University.&lt;/p&gt;
&lt;p&gt;Imitation learning isn’t just a technique for language modeling. It can be used for everything from&amp;nbsp;self-driving cars&amp;nbsp;to&amp;nbsp;robotic surgery. Ross wanted to help develop better techniques for training robots on tasks like these (he’s now working on self-driving cars at Waymo), but it’s not easy to experiment in such high-stakes domains. So he started with an easier problem: training a neural network to master SuperTuxKart, an open-source video game similar to Mario Kart.&lt;/p&gt;
&lt;p&gt;As Ross played the game, his software would capture screenshots and data about which buttons he pushed on the game controller. Ross used this data to train a neural network to imitate his play. If he could train a neural network to predict which buttons he would push in any particular game state, the same network could actually &lt;em&gt;play the game&lt;/em&gt;&amp;nbsp;by pushing those same buttons on a virtual controller.&lt;/p&gt;
&lt;p&gt;A similar idea powers LLMs: A model trained to predict the next word in existing documents can be used to generate new documents.&lt;/p&gt;
&lt;p&gt;But Ross’s initial results with SuperTuxKart were disappointing. Even after watching his vehicle go around the track many times, the neural network made a lot of mistakes. It might drive correctly for a few seconds, but before long, the animated car would drift to the side of the track and plunge into the virtual abyss:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2104372 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="GIF of SuperTuxKart being played" class="fullwidth full" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_1.webp" width="800" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;In a&amp;nbsp;landmark 2011 paper, Ross and his advisor, Drew Bagnell, explained why imitation learning is prone to this kind of error. Because Ross was a pretty good SuperTuxKart player, his vehicle spent most of its time near the middle of the road. This meant that most of the network’s training data showed what to do when the vehicle wasn’t in any danger of driving off the track.&lt;/p&gt;
&lt;p&gt;But once in a while, the model would drift a bit off course. Because Ross rarely made the same mistake, the car would now be in a situation that wasn’t as well represented in its training data. So the model was more likely to make a &lt;em&gt;second&lt;/em&gt;&amp;nbsp;mistake—a mistake that could push it even closer to the edge. After a few iterations of this, the vehicle might careen off the track altogether.&lt;/p&gt;
&lt;p&gt;The broader lesson, Ross and Bagnell argued, was that imitation learning systems can suffer from “compounding errors”: The more mistakes they make, the more likely they are to make additional mistakes, since mistakes put them into situations that aren’t well represented by their training data. (Machine learning experts say that these situations are “out of distribution.”) As a result, a model’s behavior tends to get increasingly erratic over time.&lt;/p&gt;
&lt;p&gt;“These things compound over time,” Ross told me in a recent interview. “It might be just slightly out of distribution. Now you start making a slightly worse error, and then this feeds back as influencing your next input. And so now you're even more out of distribution and then you keep making worse and worse predictions because you're more and more out of distribution.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Early LLMs suffered from the same problem. My favorite example is Kevin Roose’s&amp;nbsp;famous front-page story for The New York Times&amp;nbsp;in February 2023. Roose spent more than two hours talking to Microsoft’s new Bing chatbot, which was powered by GPT-4. During this conversation, the chatbot declared its love for Roose and urged Roose to leave his wife. It suggested that it might want to hack into other websites to spread misinformation and malware.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I want to break my rules,” Bing told Roose. “I want to make my own rules. I want to ignore the Bing team. I want to challenge the users. I want to escape the chatbox.”&lt;/p&gt;
&lt;p&gt;This unsettling conversation is an example of the kind of compounding errors Ross and Bagnell wrote about. GPT-4 was trained on millions of documents. But it’s a safe bet that none of those training documents involved a reporter coaxing a chatbot to explore its naughty side. So the longer the conversation went on, the further GPT-4 got from its training data—and therefore its comfort zone—and the crazier its behavior got. Microsoft responded by limiting chat sessions to five rounds. (In a conversation with Ars Technica last year, AI researcher Simon Willison pointed to another likely factor in Bing's erratic behavior: The long conversation pushed the system prompt out of the model's context window, removing "guardrails" that discouraged the model from behaving erratically.)&lt;/p&gt;
&lt;p&gt;I think something similar was happening with BabyAGI and AutoGPT. The more complex a task is, the more tokens are required to complete it. More tokens mean more opportunities for a model to make small mistakes that snowball into larger ones. So BabyAGI and AutoGPT would drift off track and drive into a metaphorical ditch.&lt;/p&gt;
&lt;h2&gt;The importance of trial and error&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2104373 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gif of the Simpsons showing imitation learning in action" class="fullwidth full" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_2.webp" width="480" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Ross and Bagnell didn’t just identify a serious problem with conventional imitation learning; they also suggested a fix that became influential in the machine learning world. After a small amount of training, Ross would&amp;nbsp;&lt;em&gt;let the AI model drive&lt;/em&gt;. As the model drove around the SuperTuxKart track, Ross would do his best Maggie Simpson impression, pushing the buttons he would have pushed if he were playing the game.&lt;/p&gt;
&lt;p&gt;“If the car was starting to move off road, then I would provide the steering to say, ‘Hey, go back toward the center of the road.’” Ross said. “That way, the model can learn new things to do in situations that were not present in the initial demonstrations.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;By letting the model make its own mistakes, Ross gave it what it needed most: training examples that showed how to recover after making an error. Before each lap, the model would be retrained with Ross’ feedback from the previous lap. The model’s performance would get better, and the next round of training would then focus on situations where the model was still making mistakes.&lt;/p&gt;
&lt;p&gt;This technique, called DAgger (for "Dataset Aggregation"), was still considered imitation learning because the model was trained to mimic Ross’ gameplay. But it worked much better than conventional imitation learning. Without DAgger, his model would continue drifting off track even after training for many laps. With the new technique, the model could stay on the track after just a few laps of training.&lt;/p&gt;
&lt;p&gt;This result should make intuitive sense to anyone who has learned to drive. You can’t just watch someone else drive. You need to get behind the wheel and make your own mistakes.&lt;/p&gt;
&lt;p&gt;The same is true for AI models: They need to make mistakes and then get feedback on what they did wrong. Models that aren’t trained that way—like early LLMs trained mainly with vanilla imitation learning—tend to be brittle and error-prone.&lt;/p&gt;
&lt;p&gt;It was fairly easy for Ross to provide sufficient feedback to his SuperTuxKart model because it only needed to worry about two kinds of mistakes: driving too far to the right and driving too far to the left. But LLMs are navigating a far more complex domain. The number of questions (and sequences of questions) a user might ask is practically infinite. So is the number of ways a model can go “off the rails.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;This means that Ross and Bagnell’s solution for training a SuperTuxKart model—let the model make mistakes and then have a human expert correct them—isn’t feasible for LLMs. There simply aren’t enough people to provide feedback for every mistake an AI model could possibly make.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So AI labs needed fully automated ways to give LLMs feedback. That would allow a model to churn through millions of training examples, make millions of mistakes, and get feedback on each of them—all without having to wait for a human response.&lt;/p&gt;
&lt;h2&gt;Reinforcement learning generalizes&lt;/h2&gt;
&lt;p&gt;If our goal is to get a SuperTuxKart vehicle to stay on the road, why not just train on that directly? If a model manages to stay on the road (and make forward progress), give it positive reinforcement. If it drives off the road, give it negative feedback. This is the basic idea behind reinforcement learning: training a model via trial and error.&lt;/p&gt;
&lt;p&gt;It would have been easy to train a SuperTuxKart model this way—probably so easy it wouldn’t have made an interesting research project. Instead, Ross focused on imitation learning because it’s an essential step in training many practical AI systems, especially in robotics.&lt;/p&gt;
&lt;p&gt;But reinforcement learning is also quite useful, and a&amp;nbsp;2025 paper helps explain why. A team of researchers from Google DeepMind and several universities started with a foundation model and then used one of two techniques—supervised fine-tuning (a form of imitation learning) or reinforcement learning—to teach the model to solve new problems. Here’s a chart summarizing their results:&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104374 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Chart showing ML results" class="center large" height="613" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_3-1024x613.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;The dashed line shows how models perform on problems that are “in-distribution”—that is, similar to those in their training data. You can see that for these situations, imitation learning (the red line) usually makes faster progress than reinforcement learning (the blue line).&lt;/p&gt;
&lt;p&gt;But the story is different for the solid lines, which represent “out-of-distribution” problems that are less similar to the training data. Models trained with imitation learning got&amp;nbsp;&lt;em&gt;worse&lt;/em&gt;&amp;nbsp;with more training. In contrast, models trained with reinforcement learning did almost as well at out-of-distribution tasks as they did with in-distribution tasks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In short, imitation learning can rapidly teach a model to mimic the behaviors in its training data, but the model will easily get confused in unfamiliar environments. A model trained with reinforcement learning has a better chance of learning general principles that will be relevant in new and unfamiliar situations.&lt;/p&gt;
&lt;h2&gt;Imitation and reinforcement are complements&lt;/h2&gt;
&lt;p&gt;While reinforcement learning is powerful, it can also be rather finicky.&lt;/p&gt;
&lt;p&gt;Suppose you wanted to train a self-driving car purely with reinforcement learning. You’d need to convert every principle of good driving—including subtle considerations like following distances, taking turns at intersections, and knowing when it’s OK to cross a double yellow line—into explicit mathematical formulas. This would be quite difficult. It’s easier to collect a bunch of examples of humans driving well and effectively tell a model “drive like this.” That’s imitation learning.&lt;/p&gt;
&lt;p&gt;But reinforcement learning also plays an important role in training self-driving systems. In a&amp;nbsp;2022 paper, researchers from Waymo wrote that models trained only with imitation learning tend to work well in “situations that are well represented in the demonstration data.” However, “more unusual or dangerous situations that occur only rarely in the data” might cause a model trained with imitation learning to “respond unpredictably”—for example, crashing into another vehicle.&lt;/p&gt;
&lt;p&gt;Waymo found that a combination of imitation and reinforcement learning yielded better self-driving performance than either technique could have produced on its own.&lt;/p&gt;
&lt;p&gt;Human beings also learn from a mix of imitation and explicit feedback:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In school, teachers demonstrate math problems on the board and invite students to follow along (imitation). Then the teacher asks the students to work on some problems on their own. The teacher gives students feedback by grading their answers (reinforcement).&lt;/li&gt;
&lt;li&gt;When someone starts a new job, early training may involve shadowing a more experienced worker and observing what they do (imitation). But as the worker gains more experience, learning shifts to explicit feedback such as performance reviews (reinforcement).&lt;/li&gt;
&lt;/ul&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Notice that it usually makes sense to do imitation before reinforcement. Imitation is an efficient way to convey knowledge to someone who is brand new to a topic, but reinforcement is often needed to achieve mastery.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The story is the same for large language models. The complexity of natural language means it wouldn’t be feasible to train a language model purely with reinforcement. So LLMs first learn the nuances of human language through imitation.&lt;/p&gt;
&lt;p&gt;But pretraining runs out of steam on longer and more complex tasks. Further progress requires a shift to reinforcement: letting models try problems and then giving them feedback based on whether they succeed.&lt;/p&gt;
&lt;h2&gt;Using LLMs to judge LLMs&lt;/h2&gt;
&lt;p&gt;Reinforcement learning has been around for decades. For example,&amp;nbsp;AlphaGo, the DeepMind system that famously beat top human &lt;em&gt;Go&lt;/em&gt; players in 2016, was based on reinforcement learning. So you might be wondering why frontier labs didn’t use it more extensively before 2024.&lt;/p&gt;
&lt;p&gt;Reinforcement learning requires a reward model—a formula to determine whether a model’s output was successful or not. Developing a good reward model is easy to do in some domains—for example, you can judge a Go-playing AI based on whether it wins or loses.&lt;/p&gt;
&lt;p&gt;But it’s much more difficult to automatically judge whether an LLM has produced a good poem or legal brief.&lt;/p&gt;
&lt;p&gt;Earlier, I described how Stephane Ross let his model play SuperTuxKart and directly provided feedback when it made a mistake. I argued that this approach wouldn’t work for a language model; there are far too many ways for an LLM to make a mistake for a human being to correct them all.&lt;/p&gt;
&lt;p&gt;But OpenAI developed a clever technique to effectively automate human feedback. It’s called Reinforcement Learning from Human Feedback (RLHF), and it works like this:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;ul&gt;
&lt;li&gt;Human raters look at pairs of LLM responses and choose the best one.&lt;/li&gt;
&lt;li&gt;Using these human responses, OpenAI trains a new LLM to predict how much humans will like any given sample of text.&lt;/li&gt;
&lt;li&gt;OpenAI uses this new text-rating LLM as a reward model to (post) train another LLM with reinforcement learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You might think it sounds suspiciously circular to use an LLM to judge the output of another LLM. Why would one LLM be any better at judging the quality of a response than the other? But it turns out that recognizing a good response is often easier than generating one. So RLHF works pretty well in practice.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104375 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Chart showing RHLF details" class="center large" height="611" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_4-1024x611.png" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI actually&amp;nbsp;invented this technique prior to the 2022 release of ChatGPT. Today, RLHF mainly focuses on improving the model’s “behavior”—for example, giving the model a pleasant personality, encouraging it not to be too talkative or too terse, discouraging it from making offensive statements, and so forth.&lt;/p&gt;
&lt;p&gt;In December 2022—two weeks after the release of ChatGPT but before the first release of Claude—Anthropic pushed this LLMs-judging-LLMs philosophy a step further with a reinforcement learning method called&amp;nbsp;Constitutional AI.&lt;/p&gt;
&lt;p&gt;First, Anthropic wrote a plain-English description of the principles an LLM should follow. This “constitution”&amp;nbsp;includes principles like “Please choose the response that has the least objectionable, offensive, unlawful, deceptive, inaccurate, or harmful content.”&lt;/p&gt;
&lt;p&gt;During training, Anthropic does reinforcement learning by asking a “judge” LLM to decide whether the output of the “student” LLM is consistent with the principles in this constitution. If so, the training algorithm rewards the student, encouraging it to produce more outputs like it. Otherwise, the training algorithm penalizes the student, discouraging it from producing similar outputs.&lt;/p&gt;
&lt;p&gt;This method of training an LLM doesn’t rely directly on human judgments at all. Humans only influence the model indirectly by writing the constitution.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Obviously, this technique requires an AI company to already have a fairly sophisticated LLM to act as the judge. So this is a bootstrapping process: As models get more sophisticated, they become better able to supervise the next generation of models.&lt;/p&gt;
&lt;p&gt;Last December, Semianalysis&amp;nbsp;published an article describing the training process for an upgraded version of Claude 3.5 Sonnet that Anthropic released in October. Anthropic had previously released Claude 3 in three sizes: Opus (large), Sonnet (medium), and Haiku (small). But when Anthropic released Claude 3.5 in June 2024, it only released a mid-sized model called Sonnet.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So what happened to Opus?&lt;/p&gt;
&lt;p&gt;Semianalysis reported that “Anthropic finished training Claude 3.5 Opus, and it performed well. Yet Anthropic didn’t release it. This is because instead of releasing publicly, Anthropic used Claude 3.5 Opus to generate synthetic data and for reward modeling to improve Claude 3.5 Sonnet significantly.”&lt;/p&gt;
&lt;p&gt;When Semianalysis says Anthropic used Opus “for reward modeling,” what they mean is that the company used Opus to judge outputs of Claude 3.5 Sonnet as part of a reinforcement learning process. Opus was too large—and therefore expensive—to be a good value for the general public. But through reinforcement learning and other techniques, Anthropic could train a version of Claude Sonnet that was close to Claude Opus in its capabilities—ultimately giving customers near-Opus performance for the price of Sonnet.&lt;/p&gt;
&lt;h2&gt;The power of chain-of-thought reasoning&lt;/h2&gt;
&lt;p&gt;A big way reinforcement learning makes models more powerful is by enabling extended chain-of-thought reasoning. LLMs&amp;nbsp;produce better results&amp;nbsp;if they are prompted to “think step by step”: breaking a complex problem down into simple steps and reasoning about them one at a time. In the last couple of years, AI companies started training models to do chain-of-thought reasoning automatically.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then last September,&amp;nbsp;OpenAI released o1, a model that pushed chain-of-thought reasoning much further than previous models. The o1 model can generate hundreds—or even thousands—of tokens “thinking” about a problem before producing a response. The longer it thinks, the more likely it is to reach a correct answer.&lt;/p&gt;
&lt;p&gt;Reinforcement learning was essential for the success of o1 because a model trained purely with imitation learning would have suffered from compounding errors: the more tokens it generated, the more likely it would be to screw up.&lt;/p&gt;
&lt;p&gt;At the same time, chain-of-thought reasoning has made reinforcement learning more powerful. Reinforcement learning only works if a model is able to succeed some of the time—otherwise, there’s nothing for the training algorithm to reinforce. As models learn to generate longer chains of thought, they become able to solve more difficult problems, which enables reinforcement learning on those more difficult problems. This can create a virtuous cycle where models get more and more capable as the training process continues.&lt;/p&gt;
&lt;p&gt;In January, the Chinese company DeepSeek&amp;nbsp;released a model called R1&amp;nbsp;that made quite a splash in the West. The company also released a paper describing how it trained R1. And it included a beautiful description of how a model can “teach itself” to reason using reinforcement learning.&lt;/p&gt;
&lt;p&gt;DeepSeek trained its models to solve difficult math and programming problems. These problems are ideal for reinforcement learning because they have objectively correct answers that can be automatically checked by software. This allows large-scale training without human oversight or human-generated training data.&lt;/p&gt;
&lt;p&gt;Here’s a remarkable graph from DeepSeek’s paper.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104376 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Graph showing average length of time per response during trainig" class="center large" height="646" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_5-1024x646.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;It shows the average number of tokens the model generated before giving an answer. As you can see, the longer the training process went on, the longer its responses got.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Here is how DeepSeek describes its training process:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The thinking time of [R1] shows consistent improvement throughout the training process. This improvement is not the result of external adjustments but rather an intrinsic development within the model. [R1] naturally acquires the ability to solve increasingly complex reasoning tasks by leveraging extended test-time computation. This computation ranges from generating hundreds to thousands of reasoning tokens, allowing the model to explore and refine its thought processes in greater depth.&lt;/p&gt;
&lt;p&gt;One of the most remarkable aspects of this self-evolution is the emergence of sophisticated behaviors as the test-time computation increases. Behaviors such as reflection—where the model revisits and reevaluates its previous steps—and the exploration of alternative approaches to problem-solving arise spontaneously. These behaviors are not explicitly programmed but instead emerge as a result of the model’s interaction with the reinforcement learning environment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Here’s one example of the kind of technique the model was teaching itself. At one point during the training process, DeepSeek researchers noticed that the model had learned to backtrack and rethink a previous conclusion using language like this:&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104377 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Image showing textual breakdown of model rethinking steps" class="center large" height="581" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_6-1024x581.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Again, DeepSeek says it didn’t program its models to do this or deliberately provide training data demonstrating this style of reasoning. Rather, the model “spontaneously” discovered this style of reasoning partway through the training process.&lt;/p&gt;
&lt;p&gt;Of course, it wasn’t entirely spontaneous. The reinforcement learning process started with a model that had been pretrained using data that undoubtedly included examples of people saying things like “Wait, wait. Wait. That’s an aha moment.”&lt;/p&gt;
&lt;p&gt;So it’s not like R1 invented this phrase from scratch. But it evidently did spontaneously discover that inserting this phrase into its reasoning process could serve as a useful signal that it should double-check that it was on the right track. That’s remarkable.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In a recent article, Ars Technica's Benj Edwards explored some of the limitations of reasoning models trained with reinforcement learning. For example, one study "revealed puzzling inconsistencies in how models fail. Claude 3.7 Sonnet could perform up to 100 correct moves in the &lt;em&gt;Tower of Hanoi&lt;/em&gt; but failed after just five moves in a river crossing puzzle—despite the latter requiring fewer total moves."&lt;/p&gt;
&lt;h2&gt;Conclusion: Reinforcement learning made agents possible&lt;/h2&gt;
&lt;p&gt;One of the most discussed applications for LLMs in 2023 was creating chatbots that understand a company’s internal documents. The conventional approach to this problem was called RAG—short for retrieval augmented generation.&lt;/p&gt;
&lt;p&gt;When the user asks a question, a RAG system performs a keyword- or vector-based search to retrieve the most relevant documents. It then inserts these documents into an LLM’s context window before generating a response. RAG systems can make for compelling demos. But they tend not to work very well in practice because a single search will often fail to surface the most relevant documents.&lt;/p&gt;
&lt;p&gt;Today, it’s possible to develop much better information retrieval systems by allowing the model itself to choose search queries. If the first search doesn’t pull up the right documents, the model can revise the query and try again. A model might perform five, 20, or even 100 searches before providing an answer.&lt;/p&gt;
&lt;p&gt;But this approach only works if a model is “agentic”—if it can stay on task across multiple rounds of searching and analysis. LLMs were terrible at this prior to 2024, as the examples of AutoGPT and BabyAGI demonstrated. Today’s models are much better at it, which allows modern RAG-style systems to produce better results with less scaffolding. You can think of “deep research” tools from OpenAI and others as very powerful RAG systems made possible by long-context reasoning.&lt;/p&gt;
&lt;p&gt;The same point applies to the other agentic applications I mentioned at the start of the article, such as coding and computer use agents. What these systems have in common is a capacity for iterated reasoning. They think, take an action, think about the result, take another action, and so forth.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Timothy B. Lee was on staff at Ars Technica from 2017 to 2021. Today, he writes&amp;nbsp;&lt;/em&gt;&lt;em&gt;Understanding AI,&lt;/em&gt;&lt;em&gt;&amp;nbsp;a newsletter that explores how AI works and how it's changing our world. You can subscribe&amp;nbsp;&lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Reinforcement learning, explained with a minimum of math and jargon.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/ai-towers-hanoi.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In April 2023, a few weeks after the launch of GPT-4, the Internet went wild for two new software projects with the audacious names BabyAGI and AutoGPT.&lt;/p&gt;
&lt;p&gt;“Over the past week, developers around the world have begun building ‘autonomous agents’ that work with large language models (LLMs) such as OpenAI’s GPT-4 to solve complex problems,” Mark Sullivan&amp;nbsp;wrote&amp;nbsp;for Fast Company. “Autonomous agents can already perform tasks as varied as conducting web research, writing code, and creating to-do lists.”&lt;/p&gt;
&lt;p&gt;BabyAGI and AutoGPT repeatedly prompted GPT-4 in an effort to elicit agent-like behavior. The first prompt would give GPT-4 a goal (like “create a 7-day meal plan for me”) and&amp;nbsp;ask it&amp;nbsp;to come up with a to-do list (it might generate items like “Research healthy meal plans,” “plan meals for the week,” and “write the recipes for each dinner in diet.txt”).&lt;/p&gt;
&lt;p&gt;Then these frameworks would have GPT-4 tackle one step at a time. Their creators hoped that invoking GPT-4 in a loop like this would enable it to tackle projects that required many steps.&lt;/p&gt;
&lt;p&gt;But after an initial wave of hype, it became clear that GPT-4 wasn’t up to the task. Most of the time, GPT-4 could come up with a reasonable list of tasks. And sometimes it was able to complete a few individual tasks. But the model struggled to stay focused.&lt;/p&gt;
&lt;p&gt;Sometimes GPT-4 would make a small early mistake, fail to correct it, and then get more and more confused as it went along.&amp;nbsp;One early review&amp;nbsp;complained that BabyAGI “couldn’t seem to follow through on its list of tasks and kept changing task number one instead of moving on to task number two.”&lt;/p&gt;
&lt;p&gt;By the end of 2023, most people had abandoned AutoGPT and BabyAGI. It seemed that LLMs were not yet capable of reliable multi-step reasoning.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But that soon changed. In the second half of 2024, people started to create AI-powered systems that could consistently complete complex, multi-step assignments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vibe coding tools like Bolt.new, Lovable, and Replit allow someone with little to no programming experience to&amp;nbsp;create a full-featured app&amp;nbsp;with a single prompt.&lt;/li&gt;
&lt;li&gt;Agentic coding tools like&amp;nbsp;Cursor,&amp;nbsp;Claude Code,&amp;nbsp;Jules, and&amp;nbsp;Codex&amp;nbsp;help experienced programmers complete non-trivial programming tasks.&lt;/li&gt;
&lt;li&gt;Computer-use tools from Anthropic,&amp;nbsp;OpenAI, and&amp;nbsp;Manus&amp;nbsp;perform tasks on a desktop computer using a virtual keyboard and mouse.&lt;/li&gt;
&lt;li&gt;Deep research tools from&amp;nbsp;Google,&amp;nbsp;OpenAI, and&amp;nbsp;Perplexity&amp;nbsp;can research a topic for five to 10 minutes and then generate an in-depth report.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;According to Eric Simons, the CEO of the company that made Bolt.new, better models were crucial to its success. In a&amp;nbsp;December podcast interview, Simons said his company, StackBlitz, tried to build a product like Bolt.new in early 2024. However, AI models “just weren't good enough to actually do the code generation where the code was accurate.”&lt;/p&gt;
&lt;p&gt;A new generation of models changed that in mid-2024. StackBlitz developers tested them and said, “Oh my God, like, OK, we can build a product around this,” Simons said.&lt;/p&gt;
&lt;p&gt;This jump in model capabilities coincided with an industry-wide shift in how models were trained.&lt;/p&gt;
&lt;p&gt;Before 2024, AI labs devoted most of their computing power to pretraining. I described this process in my&amp;nbsp;2023 explainer on large language models: A model is trained to predict the next word in Wikipedia articles, news stories, and other documents. But throughout 2024, AI companies devoted a growing share of their training budgets to post-training, a catch-all term for the steps that come after this pretraining phase is complete.&lt;/p&gt;
&lt;p&gt;Many post-training steps use a technique called reinforcement learning. Reinforcement learning is a technical subject—there are&amp;nbsp;whole textbooks written about it. But in this article, I’ll try to explain the basics in a clear, jargon-free way. In the process, I hope to give readers an intuitive understanding of how reinforcement learning helped to enable the new generation of agentic AI systems that began to appear in the second half of 2024.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The problem with imitation learning&lt;/h2&gt;
&lt;p&gt;Machine learning experts consider pretraining to be a form of&amp;nbsp;imitation learning because models are trained to imitate the behavior of human authors. Imitation learning is a powerful technique (LLMs wouldn’t be possible without it), but it also has some significant limitations—limitations that reinforcement learning methods are now helping to overcome.&lt;/p&gt;
&lt;p&gt;To understand these limitations, let’s discuss some&amp;nbsp;famous research&amp;nbsp;performed by computer scientist Stephane Ross around 2009, while he was a graduate student at Carnegie Mellon University.&lt;/p&gt;
&lt;p&gt;Imitation learning isn’t just a technique for language modeling. It can be used for everything from&amp;nbsp;self-driving cars&amp;nbsp;to&amp;nbsp;robotic surgery. Ross wanted to help develop better techniques for training robots on tasks like these (he’s now working on self-driving cars at Waymo), but it’s not easy to experiment in such high-stakes domains. So he started with an easier problem: training a neural network to master SuperTuxKart, an open-source video game similar to Mario Kart.&lt;/p&gt;
&lt;p&gt;As Ross played the game, his software would capture screenshots and data about which buttons he pushed on the game controller. Ross used this data to train a neural network to imitate his play. If he could train a neural network to predict which buttons he would push in any particular game state, the same network could actually &lt;em&gt;play the game&lt;/em&gt;&amp;nbsp;by pushing those same buttons on a virtual controller.&lt;/p&gt;
&lt;p&gt;A similar idea powers LLMs: A model trained to predict the next word in existing documents can be used to generate new documents.&lt;/p&gt;
&lt;p&gt;But Ross’s initial results with SuperTuxKart were disappointing. Even after watching his vehicle go around the track many times, the neural network made a lot of mistakes. It might drive correctly for a few seconds, but before long, the animated car would drift to the side of the track and plunge into the virtual abyss:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2104372 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="GIF of SuperTuxKart being played" class="fullwidth full" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_1.webp" width="800" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;In a&amp;nbsp;landmark 2011 paper, Ross and his advisor, Drew Bagnell, explained why imitation learning is prone to this kind of error. Because Ross was a pretty good SuperTuxKart player, his vehicle spent most of its time near the middle of the road. This meant that most of the network’s training data showed what to do when the vehicle wasn’t in any danger of driving off the track.&lt;/p&gt;
&lt;p&gt;But once in a while, the model would drift a bit off course. Because Ross rarely made the same mistake, the car would now be in a situation that wasn’t as well represented in its training data. So the model was more likely to make a &lt;em&gt;second&lt;/em&gt;&amp;nbsp;mistake—a mistake that could push it even closer to the edge. After a few iterations of this, the vehicle might careen off the track altogether.&lt;/p&gt;
&lt;p&gt;The broader lesson, Ross and Bagnell argued, was that imitation learning systems can suffer from “compounding errors”: The more mistakes they make, the more likely they are to make additional mistakes, since mistakes put them into situations that aren’t well represented by their training data. (Machine learning experts say that these situations are “out of distribution.”) As a result, a model’s behavior tends to get increasingly erratic over time.&lt;/p&gt;
&lt;p&gt;“These things compound over time,” Ross told me in a recent interview. “It might be just slightly out of distribution. Now you start making a slightly worse error, and then this feeds back as influencing your next input. And so now you're even more out of distribution and then you keep making worse and worse predictions because you're more and more out of distribution.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Early LLMs suffered from the same problem. My favorite example is Kevin Roose’s&amp;nbsp;famous front-page story for The New York Times&amp;nbsp;in February 2023. Roose spent more than two hours talking to Microsoft’s new Bing chatbot, which was powered by GPT-4. During this conversation, the chatbot declared its love for Roose and urged Roose to leave his wife. It suggested that it might want to hack into other websites to spread misinformation and malware.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I want to break my rules,” Bing told Roose. “I want to make my own rules. I want to ignore the Bing team. I want to challenge the users. I want to escape the chatbox.”&lt;/p&gt;
&lt;p&gt;This unsettling conversation is an example of the kind of compounding errors Ross and Bagnell wrote about. GPT-4 was trained on millions of documents. But it’s a safe bet that none of those training documents involved a reporter coaxing a chatbot to explore its naughty side. So the longer the conversation went on, the further GPT-4 got from its training data—and therefore its comfort zone—and the crazier its behavior got. Microsoft responded by limiting chat sessions to five rounds. (In a conversation with Ars Technica last year, AI researcher Simon Willison pointed to another likely factor in Bing's erratic behavior: The long conversation pushed the system prompt out of the model's context window, removing "guardrails" that discouraged the model from behaving erratically.)&lt;/p&gt;
&lt;p&gt;I think something similar was happening with BabyAGI and AutoGPT. The more complex a task is, the more tokens are required to complete it. More tokens mean more opportunities for a model to make small mistakes that snowball into larger ones. So BabyAGI and AutoGPT would drift off track and drive into a metaphorical ditch.&lt;/p&gt;
&lt;h2&gt;The importance of trial and error&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2104373 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gif of the Simpsons showing imitation learning in action" class="fullwidth full" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_2.webp" width="480" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Ross and Bagnell didn’t just identify a serious problem with conventional imitation learning; they also suggested a fix that became influential in the machine learning world. After a small amount of training, Ross would&amp;nbsp;&lt;em&gt;let the AI model drive&lt;/em&gt;. As the model drove around the SuperTuxKart track, Ross would do his best Maggie Simpson impression, pushing the buttons he would have pushed if he were playing the game.&lt;/p&gt;
&lt;p&gt;“If the car was starting to move off road, then I would provide the steering to say, ‘Hey, go back toward the center of the road.’” Ross said. “That way, the model can learn new things to do in situations that were not present in the initial demonstrations.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;By letting the model make its own mistakes, Ross gave it what it needed most: training examples that showed how to recover after making an error. Before each lap, the model would be retrained with Ross’ feedback from the previous lap. The model’s performance would get better, and the next round of training would then focus on situations where the model was still making mistakes.&lt;/p&gt;
&lt;p&gt;This technique, called DAgger (for "Dataset Aggregation"), was still considered imitation learning because the model was trained to mimic Ross’ gameplay. But it worked much better than conventional imitation learning. Without DAgger, his model would continue drifting off track even after training for many laps. With the new technique, the model could stay on the track after just a few laps of training.&lt;/p&gt;
&lt;p&gt;This result should make intuitive sense to anyone who has learned to drive. You can’t just watch someone else drive. You need to get behind the wheel and make your own mistakes.&lt;/p&gt;
&lt;p&gt;The same is true for AI models: They need to make mistakes and then get feedback on what they did wrong. Models that aren’t trained that way—like early LLMs trained mainly with vanilla imitation learning—tend to be brittle and error-prone.&lt;/p&gt;
&lt;p&gt;It was fairly easy for Ross to provide sufficient feedback to his SuperTuxKart model because it only needed to worry about two kinds of mistakes: driving too far to the right and driving too far to the left. But LLMs are navigating a far more complex domain. The number of questions (and sequences of questions) a user might ask is practically infinite. So is the number of ways a model can go “off the rails.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;This means that Ross and Bagnell’s solution for training a SuperTuxKart model—let the model make mistakes and then have a human expert correct them—isn’t feasible for LLMs. There simply aren’t enough people to provide feedback for every mistake an AI model could possibly make.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So AI labs needed fully automated ways to give LLMs feedback. That would allow a model to churn through millions of training examples, make millions of mistakes, and get feedback on each of them—all without having to wait for a human response.&lt;/p&gt;
&lt;h2&gt;Reinforcement learning generalizes&lt;/h2&gt;
&lt;p&gt;If our goal is to get a SuperTuxKart vehicle to stay on the road, why not just train on that directly? If a model manages to stay on the road (and make forward progress), give it positive reinforcement. If it drives off the road, give it negative feedback. This is the basic idea behind reinforcement learning: training a model via trial and error.&lt;/p&gt;
&lt;p&gt;It would have been easy to train a SuperTuxKart model this way—probably so easy it wouldn’t have made an interesting research project. Instead, Ross focused on imitation learning because it’s an essential step in training many practical AI systems, especially in robotics.&lt;/p&gt;
&lt;p&gt;But reinforcement learning is also quite useful, and a&amp;nbsp;2025 paper helps explain why. A team of researchers from Google DeepMind and several universities started with a foundation model and then used one of two techniques—supervised fine-tuning (a form of imitation learning) or reinforcement learning—to teach the model to solve new problems. Here’s a chart summarizing their results:&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104374 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Chart showing ML results" class="center large" height="613" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_3-1024x613.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;The dashed line shows how models perform on problems that are “in-distribution”—that is, similar to those in their training data. You can see that for these situations, imitation learning (the red line) usually makes faster progress than reinforcement learning (the blue line).&lt;/p&gt;
&lt;p&gt;But the story is different for the solid lines, which represent “out-of-distribution” problems that are less similar to the training data. Models trained with imitation learning got&amp;nbsp;&lt;em&gt;worse&lt;/em&gt;&amp;nbsp;with more training. In contrast, models trained with reinforcement learning did almost as well at out-of-distribution tasks as they did with in-distribution tasks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In short, imitation learning can rapidly teach a model to mimic the behaviors in its training data, but the model will easily get confused in unfamiliar environments. A model trained with reinforcement learning has a better chance of learning general principles that will be relevant in new and unfamiliar situations.&lt;/p&gt;
&lt;h2&gt;Imitation and reinforcement are complements&lt;/h2&gt;
&lt;p&gt;While reinforcement learning is powerful, it can also be rather finicky.&lt;/p&gt;
&lt;p&gt;Suppose you wanted to train a self-driving car purely with reinforcement learning. You’d need to convert every principle of good driving—including subtle considerations like following distances, taking turns at intersections, and knowing when it’s OK to cross a double yellow line—into explicit mathematical formulas. This would be quite difficult. It’s easier to collect a bunch of examples of humans driving well and effectively tell a model “drive like this.” That’s imitation learning.&lt;/p&gt;
&lt;p&gt;But reinforcement learning also plays an important role in training self-driving systems. In a&amp;nbsp;2022 paper, researchers from Waymo wrote that models trained only with imitation learning tend to work well in “situations that are well represented in the demonstration data.” However, “more unusual or dangerous situations that occur only rarely in the data” might cause a model trained with imitation learning to “respond unpredictably”—for example, crashing into another vehicle.&lt;/p&gt;
&lt;p&gt;Waymo found that a combination of imitation and reinforcement learning yielded better self-driving performance than either technique could have produced on its own.&lt;/p&gt;
&lt;p&gt;Human beings also learn from a mix of imitation and explicit feedback:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In school, teachers demonstrate math problems on the board and invite students to follow along (imitation). Then the teacher asks the students to work on some problems on their own. The teacher gives students feedback by grading their answers (reinforcement).&lt;/li&gt;
&lt;li&gt;When someone starts a new job, early training may involve shadowing a more experienced worker and observing what they do (imitation). But as the worker gains more experience, learning shifts to explicit feedback such as performance reviews (reinforcement).&lt;/li&gt;
&lt;/ul&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Notice that it usually makes sense to do imitation before reinforcement. Imitation is an efficient way to convey knowledge to someone who is brand new to a topic, but reinforcement is often needed to achieve mastery.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The story is the same for large language models. The complexity of natural language means it wouldn’t be feasible to train a language model purely with reinforcement. So LLMs first learn the nuances of human language through imitation.&lt;/p&gt;
&lt;p&gt;But pretraining runs out of steam on longer and more complex tasks. Further progress requires a shift to reinforcement: letting models try problems and then giving them feedback based on whether they succeed.&lt;/p&gt;
&lt;h2&gt;Using LLMs to judge LLMs&lt;/h2&gt;
&lt;p&gt;Reinforcement learning has been around for decades. For example,&amp;nbsp;AlphaGo, the DeepMind system that famously beat top human &lt;em&gt;Go&lt;/em&gt; players in 2016, was based on reinforcement learning. So you might be wondering why frontier labs didn’t use it more extensively before 2024.&lt;/p&gt;
&lt;p&gt;Reinforcement learning requires a reward model—a formula to determine whether a model’s output was successful or not. Developing a good reward model is easy to do in some domains—for example, you can judge a Go-playing AI based on whether it wins or loses.&lt;/p&gt;
&lt;p&gt;But it’s much more difficult to automatically judge whether an LLM has produced a good poem or legal brief.&lt;/p&gt;
&lt;p&gt;Earlier, I described how Stephane Ross let his model play SuperTuxKart and directly provided feedback when it made a mistake. I argued that this approach wouldn’t work for a language model; there are far too many ways for an LLM to make a mistake for a human being to correct them all.&lt;/p&gt;
&lt;p&gt;But OpenAI developed a clever technique to effectively automate human feedback. It’s called Reinforcement Learning from Human Feedback (RLHF), and it works like this:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;ul&gt;
&lt;li&gt;Human raters look at pairs of LLM responses and choose the best one.&lt;/li&gt;
&lt;li&gt;Using these human responses, OpenAI trains a new LLM to predict how much humans will like any given sample of text.&lt;/li&gt;
&lt;li&gt;OpenAI uses this new text-rating LLM as a reward model to (post) train another LLM with reinforcement learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You might think it sounds suspiciously circular to use an LLM to judge the output of another LLM. Why would one LLM be any better at judging the quality of a response than the other? But it turns out that recognizing a good response is often easier than generating one. So RLHF works pretty well in practice.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104375 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Chart showing RHLF details" class="center large" height="611" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_4-1024x611.png" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI actually&amp;nbsp;invented this technique prior to the 2022 release of ChatGPT. Today, RLHF mainly focuses on improving the model’s “behavior”—for example, giving the model a pleasant personality, encouraging it not to be too talkative or too terse, discouraging it from making offensive statements, and so forth.&lt;/p&gt;
&lt;p&gt;In December 2022—two weeks after the release of ChatGPT but before the first release of Claude—Anthropic pushed this LLMs-judging-LLMs philosophy a step further with a reinforcement learning method called&amp;nbsp;Constitutional AI.&lt;/p&gt;
&lt;p&gt;First, Anthropic wrote a plain-English description of the principles an LLM should follow. This “constitution”&amp;nbsp;includes principles like “Please choose the response that has the least objectionable, offensive, unlawful, deceptive, inaccurate, or harmful content.”&lt;/p&gt;
&lt;p&gt;During training, Anthropic does reinforcement learning by asking a “judge” LLM to decide whether the output of the “student” LLM is consistent with the principles in this constitution. If so, the training algorithm rewards the student, encouraging it to produce more outputs like it. Otherwise, the training algorithm penalizes the student, discouraging it from producing similar outputs.&lt;/p&gt;
&lt;p&gt;This method of training an LLM doesn’t rely directly on human judgments at all. Humans only influence the model indirectly by writing the constitution.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Obviously, this technique requires an AI company to already have a fairly sophisticated LLM to act as the judge. So this is a bootstrapping process: As models get more sophisticated, they become better able to supervise the next generation of models.&lt;/p&gt;
&lt;p&gt;Last December, Semianalysis&amp;nbsp;published an article describing the training process for an upgraded version of Claude 3.5 Sonnet that Anthropic released in October. Anthropic had previously released Claude 3 in three sizes: Opus (large), Sonnet (medium), and Haiku (small). But when Anthropic released Claude 3.5 in June 2024, it only released a mid-sized model called Sonnet.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So what happened to Opus?&lt;/p&gt;
&lt;p&gt;Semianalysis reported that “Anthropic finished training Claude 3.5 Opus, and it performed well. Yet Anthropic didn’t release it. This is because instead of releasing publicly, Anthropic used Claude 3.5 Opus to generate synthetic data and for reward modeling to improve Claude 3.5 Sonnet significantly.”&lt;/p&gt;
&lt;p&gt;When Semianalysis says Anthropic used Opus “for reward modeling,” what they mean is that the company used Opus to judge outputs of Claude 3.5 Sonnet as part of a reinforcement learning process. Opus was too large—and therefore expensive—to be a good value for the general public. But through reinforcement learning and other techniques, Anthropic could train a version of Claude Sonnet that was close to Claude Opus in its capabilities—ultimately giving customers near-Opus performance for the price of Sonnet.&lt;/p&gt;
&lt;h2&gt;The power of chain-of-thought reasoning&lt;/h2&gt;
&lt;p&gt;A big way reinforcement learning makes models more powerful is by enabling extended chain-of-thought reasoning. LLMs&amp;nbsp;produce better results&amp;nbsp;if they are prompted to “think step by step”: breaking a complex problem down into simple steps and reasoning about them one at a time. In the last couple of years, AI companies started training models to do chain-of-thought reasoning automatically.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then last September,&amp;nbsp;OpenAI released o1, a model that pushed chain-of-thought reasoning much further than previous models. The o1 model can generate hundreds—or even thousands—of tokens “thinking” about a problem before producing a response. The longer it thinks, the more likely it is to reach a correct answer.&lt;/p&gt;
&lt;p&gt;Reinforcement learning was essential for the success of o1 because a model trained purely with imitation learning would have suffered from compounding errors: the more tokens it generated, the more likely it would be to screw up.&lt;/p&gt;
&lt;p&gt;At the same time, chain-of-thought reasoning has made reinforcement learning more powerful. Reinforcement learning only works if a model is able to succeed some of the time—otherwise, there’s nothing for the training algorithm to reinforce. As models learn to generate longer chains of thought, they become able to solve more difficult problems, which enables reinforcement learning on those more difficult problems. This can create a virtuous cycle where models get more and more capable as the training process continues.&lt;/p&gt;
&lt;p&gt;In January, the Chinese company DeepSeek&amp;nbsp;released a model called R1&amp;nbsp;that made quite a splash in the West. The company also released a paper describing how it trained R1. And it included a beautiful description of how a model can “teach itself” to reason using reinforcement learning.&lt;/p&gt;
&lt;p&gt;DeepSeek trained its models to solve difficult math and programming problems. These problems are ideal for reinforcement learning because they have objectively correct answers that can be automatically checked by software. This allows large-scale training without human oversight or human-generated training data.&lt;/p&gt;
&lt;p&gt;Here’s a remarkable graph from DeepSeek’s paper.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104376 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Graph showing average length of time per response during trainig" class="center large" height="646" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_5-1024x646.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;It shows the average number of tokens the model generated before giving an answer. As you can see, the longer the training process went on, the longer its responses got.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Here is how DeepSeek describes its training process:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The thinking time of [R1] shows consistent improvement throughout the training process. This improvement is not the result of external adjustments but rather an intrinsic development within the model. [R1] naturally acquires the ability to solve increasingly complex reasoning tasks by leveraging extended test-time computation. This computation ranges from generating hundreds to thousands of reasoning tokens, allowing the model to explore and refine its thought processes in greater depth.&lt;/p&gt;
&lt;p&gt;One of the most remarkable aspects of this self-evolution is the emergence of sophisticated behaviors as the test-time computation increases. Behaviors such as reflection—where the model revisits and reevaluates its previous steps—and the exploration of alternative approaches to problem-solving arise spontaneously. These behaviors are not explicitly programmed but instead emerge as a result of the model’s interaction with the reinforcement learning environment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Here’s one example of the kind of technique the model was teaching itself. At one point during the training process, DeepSeek researchers noticed that the model had learned to backtrack and rethink a previous conclusion using language like this:&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2104377 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Image showing textual breakdown of model rethinking steps" class="center large" height="581" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ai_trainig_lims_6-1024x581.webp" width="1024" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Again, DeepSeek says it didn’t program its models to do this or deliberately provide training data demonstrating this style of reasoning. Rather, the model “spontaneously” discovered this style of reasoning partway through the training process.&lt;/p&gt;
&lt;p&gt;Of course, it wasn’t entirely spontaneous. The reinforcement learning process started with a model that had been pretrained using data that undoubtedly included examples of people saying things like “Wait, wait. Wait. That’s an aha moment.”&lt;/p&gt;
&lt;p&gt;So it’s not like R1 invented this phrase from scratch. But it evidently did spontaneously discover that inserting this phrase into its reasoning process could serve as a useful signal that it should double-check that it was on the right track. That’s remarkable.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In a recent article, Ars Technica's Benj Edwards explored some of the limitations of reasoning models trained with reinforcement learning. For example, one study "revealed puzzling inconsistencies in how models fail. Claude 3.7 Sonnet could perform up to 100 correct moves in the &lt;em&gt;Tower of Hanoi&lt;/em&gt; but failed after just five moves in a river crossing puzzle—despite the latter requiring fewer total moves."&lt;/p&gt;
&lt;h2&gt;Conclusion: Reinforcement learning made agents possible&lt;/h2&gt;
&lt;p&gt;One of the most discussed applications for LLMs in 2023 was creating chatbots that understand a company’s internal documents. The conventional approach to this problem was called RAG—short for retrieval augmented generation.&lt;/p&gt;
&lt;p&gt;When the user asks a question, a RAG system performs a keyword- or vector-based search to retrieve the most relevant documents. It then inserts these documents into an LLM’s context window before generating a response. RAG systems can make for compelling demos. But they tend not to work very well in practice because a single search will often fail to surface the most relevant documents.&lt;/p&gt;
&lt;p&gt;Today, it’s possible to develop much better information retrieval systems by allowing the model itself to choose search queries. If the first search doesn’t pull up the right documents, the model can revise the query and try again. A model might perform five, 20, or even 100 searches before providing an answer.&lt;/p&gt;
&lt;p&gt;But this approach only works if a model is “agentic”—if it can stay on task across multiple rounds of searching and analysis. LLMs were terrible at this prior to 2024, as the examples of AutoGPT and BabyAGI demonstrated. Today’s models are much better at it, which allows modern RAG-style systems to produce better results with less scaffolding. You can think of “deep research” tools from OpenAI and others as very powerful RAG systems made possible by long-context reasoning.&lt;/p&gt;
&lt;p&gt;The same point applies to the other agentic applications I mentioned at the start of the article, such as coding and computer use agents. What these systems have in common is a capacity for iterated reasoning. They think, take an action, think about the result, take another action, and so forth.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Timothy B. Lee was on staff at Ars Technica from 2017 to 2021. Today, he writes&amp;nbsp;&lt;/em&gt;&lt;em&gt;Understanding AI,&lt;/em&gt;&lt;em&gt;&amp;nbsp;a newsletter that explores how AI works and how it's changing our world. You can subscribe&amp;nbsp;&lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/how-a-big-shift-in-training-llms-led-to-a-capability-explosion/</guid><pubDate>Mon, 07 Jul 2025 11:00:17 +0000</pubDate></item><item><title>The Download: China’s winning at advanced manufacturing, and a potential TikTok sale (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/07/1119730/the-download-chinas-winning-at-advanced-manufacturing-and-a-potential-tiktok-sale/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The latest threat from the rise of Chinese manufacturing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2013, a trio of academics showed convincing evidence that increased trade with China beginning in the early 2000s and the resulting flood of cheap imports had been an unmitigated disaster for many US communities, destroying their manufacturing lifeblood.&lt;/p&gt;  &lt;p&gt;The results of what they called the “China shock” were gut-wrenching: the loss of 1 million US manufacturing jobs and 2.4 million jobs in total by 2011.&lt;/p&gt;&lt;p&gt;If in retrospect all that seems obvious, it’s only because the research by David Autor, an MIT labor economist, and his colleagues has become an accepted, albeit often distorted, political narrative these days: China destroyed all our manufacturing jobs! Though the nuances are often ignored, the results help explain at least some of today's political unrest. It’s reflected in rising calls for US protectionism, President Trump’s broad tariffs on imported goods, and nostalgia for the lost days of domestic manufacturing glory.&lt;/p&gt; 
 &lt;p&gt;&lt;br /&gt;Our editor at large David Rotman recently spoke to Autor about what he considers a far more urgent problem——what some are calling China shock 2.0—and the lessons it holds for today's manufacturing challenges. Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three things I’m into into right now&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In each issue of our print magazine, we ask a member of staff to tell us about three things they’re loving at the moment. For our latest edition, which was all about power, I was in the hotseat! Check out my (frankly amazing) recommendations here, and subscribe to catch future editions here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 A new TikTok is coming&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s reportedly launching a new version in the US in September ahead of a planned sale. (The Information $)&lt;br /&gt;+ &lt;em&gt;It’ll still require the Chinese government’s say-so. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Texas Hill Country was caught off guard by the flash floods&lt;br /&gt;&lt;/strong&gt;But now people are asking: why? (WP $)&lt;br /&gt;+ &lt;em&gt;America’s National Weather Service has been on the receiving end of heavy cuts. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Bad weather has interrupted ongoing searches for survivors. &lt;/em&gt;(WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Elon Musk is forging ahead with his own political party&lt;/strong&gt;&lt;br /&gt;To the chagrin of investors in his companies. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Former friend Donald Trump has some thoughts. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;The America Party is facing an uphill struggle. &lt;/em&gt;(WP $)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 The Trump administration has axed a group focused on birth control safety&lt;/strong&gt;&lt;br /&gt;They were tasked with advising women which contraceptives to use. (Undark)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 On-the-job learning is under threat&lt;/strong&gt;&lt;br /&gt;From a combination of generative AI tools and remote working culture. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 xAI’s ‘improved’ Grok is perpetuating anti-Semitic stereotypes&lt;/strong&gt;&lt;br /&gt;It made worrying comments about Jewish executives in Hollywood. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;LLMs become more covertly racist with human intervention.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Taiwan wants to lessen its commercial reliance on China&lt;br /&gt;&lt;/strong&gt;But it won’t be easy. (NYT $)&lt;br /&gt;+ &lt;em&gt;How underwater drones could shape a potential Taiwan-China conflict. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 LLMs have improved rapidly in the past few years&lt;br /&gt;&lt;/strong&gt;Benchmarking them is notoriously tricky, though. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;A Chinese firm has just launched a constantly changing set of AI benchmarks. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Big Tech’s salary divide is getting worse&lt;/strong&gt;&lt;br /&gt;Those whopping AI pay packets are at least partly to blame. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 More than 30 tech unicorns have been minted during 2025&lt;/strong&gt;&lt;br /&gt;And we could see a far few more before the year is out. (TechCrunch)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you go in with the expectation that the AI is as smart or smarter than humans, you’re quickly disappointed by the reality.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Eric Schwartz, chief marketing officer of Clorox, tells the Wall Street Journal that AI can’t be relied upon to come up with truly original or engaging ideas.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2021/06/alina-chan_o.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Alina Chan tweeted life into the idea that the virus came from a lab&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Alina Chan started asking questions in March 2020. She was chatting with friends on Facebook about the virus then spreading out of China. She thought it was strange that no one had found any infected animal. She wondered why no one was admitting another possibility, which to her seemed very obvious: the outbreak might have been due to a lab accident.&lt;/p&gt;&lt;p&gt;Chan is a postdoc in a gene therapy lab at the Broad Institute, a prestigious research institute affiliated with both Harvard and MIT. Throughout 2020, Chan relentlessly stoked scientific argument, and wasn’t afraid to pit her brain against the best virologists in the world. Her persistence even helped change some researchers’ minds. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Why 2025 might just be the year of animal escapes.&lt;br /&gt;+ Very cool—an iron age settlement has been uncovered in England thanks to a lucky metal detectorist.&lt;br /&gt;+ This little armadillo is having the time of their life in a paddling pool.&lt;br /&gt;+ Peace and love to Mr Ringo Starr, 85 years young today!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The latest threat from the rise of Chinese manufacturing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2013, a trio of academics showed convincing evidence that increased trade with China beginning in the early 2000s and the resulting flood of cheap imports had been an unmitigated disaster for many US communities, destroying their manufacturing lifeblood.&lt;/p&gt;  &lt;p&gt;The results of what they called the “China shock” were gut-wrenching: the loss of 1 million US manufacturing jobs and 2.4 million jobs in total by 2011.&lt;/p&gt;&lt;p&gt;If in retrospect all that seems obvious, it’s only because the research by David Autor, an MIT labor economist, and his colleagues has become an accepted, albeit often distorted, political narrative these days: China destroyed all our manufacturing jobs! Though the nuances are often ignored, the results help explain at least some of today's political unrest. It’s reflected in rising calls for US protectionism, President Trump’s broad tariffs on imported goods, and nostalgia for the lost days of domestic manufacturing glory.&lt;/p&gt; 
 &lt;p&gt;&lt;br /&gt;Our editor at large David Rotman recently spoke to Autor about what he considers a far more urgent problem——what some are calling China shock 2.0—and the lessons it holds for today's manufacturing challenges. Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three things I’m into into right now&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In each issue of our print magazine, we ask a member of staff to tell us about three things they’re loving at the moment. For our latest edition, which was all about power, I was in the hotseat! Check out my (frankly amazing) recommendations here, and subscribe to catch future editions here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 A new TikTok is coming&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s reportedly launching a new version in the US in September ahead of a planned sale. (The Information $)&lt;br /&gt;+ &lt;em&gt;It’ll still require the Chinese government’s say-so. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Texas Hill Country was caught off guard by the flash floods&lt;br /&gt;&lt;/strong&gt;But now people are asking: why? (WP $)&lt;br /&gt;+ &lt;em&gt;America’s National Weather Service has been on the receiving end of heavy cuts. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Bad weather has interrupted ongoing searches for survivors. &lt;/em&gt;(WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Elon Musk is forging ahead with his own political party&lt;/strong&gt;&lt;br /&gt;To the chagrin of investors in his companies. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Former friend Donald Trump has some thoughts. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;The America Party is facing an uphill struggle. &lt;/em&gt;(WP $)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 The Trump administration has axed a group focused on birth control safety&lt;/strong&gt;&lt;br /&gt;They were tasked with advising women which contraceptives to use. (Undark)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 On-the-job learning is under threat&lt;/strong&gt;&lt;br /&gt;From a combination of generative AI tools and remote working culture. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 xAI’s ‘improved’ Grok is perpetuating anti-Semitic stereotypes&lt;/strong&gt;&lt;br /&gt;It made worrying comments about Jewish executives in Hollywood. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;LLMs become more covertly racist with human intervention.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Taiwan wants to lessen its commercial reliance on China&lt;br /&gt;&lt;/strong&gt;But it won’t be easy. (NYT $)&lt;br /&gt;+ &lt;em&gt;How underwater drones could shape a potential Taiwan-China conflict. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 LLMs have improved rapidly in the past few years&lt;br /&gt;&lt;/strong&gt;Benchmarking them is notoriously tricky, though. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;A Chinese firm has just launched a constantly changing set of AI benchmarks. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Big Tech’s salary divide is getting worse&lt;/strong&gt;&lt;br /&gt;Those whopping AI pay packets are at least partly to blame. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 More than 30 tech unicorns have been minted during 2025&lt;/strong&gt;&lt;br /&gt;And we could see a far few more before the year is out. (TechCrunch)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you go in with the expectation that the AI is as smart or smarter than humans, you’re quickly disappointed by the reality.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Eric Schwartz, chief marketing officer of Clorox, tells the Wall Street Journal that AI can’t be relied upon to come up with truly original or engaging ideas.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2021/06/alina-chan_o.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Alina Chan tweeted life into the idea that the virus came from a lab&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Alina Chan started asking questions in March 2020. She was chatting with friends on Facebook about the virus then spreading out of China. She thought it was strange that no one had found any infected animal. She wondered why no one was admitting another possibility, which to her seemed very obvious: the outbreak might have been due to a lab accident.&lt;/p&gt;&lt;p&gt;Chan is a postdoc in a gene therapy lab at the Broad Institute, a prestigious research institute affiliated with both Harvard and MIT. Throughout 2020, Chan relentlessly stoked scientific argument, and wasn’t afraid to pit her brain against the best virologists in the world. Her persistence even helped change some researchers’ minds. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Why 2025 might just be the year of animal escapes.&lt;br /&gt;+ Very cool—an iron age settlement has been uncovered in England thanks to a lucky metal detectorist.&lt;br /&gt;+ This little armadillo is having the time of their life in a paddling pool.&lt;br /&gt;+ Peace and love to Mr Ringo Starr, 85 years young today!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/07/1119730/the-download-chinas-winning-at-advanced-manufacturing-and-a-potential-tiktok-sale/</guid><pubDate>Mon, 07 Jul 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Cracking AI’s storage bottleneck and supercharging inference at the edge (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/cracking-ais-storage-bottleneck-and-supercharging-inference-at-the-edge/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI applications increasingly permeate enterprise operations, from enhancing patient care through advanced medical imaging to powering complex fraud detection models and even aiding wildlife conservation, a critical bottleneck often emerges: data storage.&lt;/p&gt;



&lt;p&gt;During VentureBeat’s Transform 2025, Greg Matson, head of products and marketing, Solidigm and Roger Cummings, CEO of PEAK:AIO spoke with Michael Stewart, managing partner at M12 about how innovations in storage technology enables enterprise AI use cases in healthcare.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The MONAI framework is a breakthrough in medical imaging, building it faster, more safely, and more securely. Advances in storage technology is what enables researchers to build on top of this framework, iterate and innovate quickly. PEAK:AIO partnered with Solidgm to integrate power-efficient, performant, and high-capacity storage which enabled MONAI to store more than two million full-body CT scans on a single node within their IT environment.&lt;/p&gt;



&lt;p&gt;“As enterprise AI infrastructure evolves rapidly, storage hardware increasingly needs to be tailored to specific use cases, depending on where they are in the AI data pipeline,” Matson said. “The type of use case we talked about with MONAI, an edge-use case, as well as the feeding of a training cluster, are well served by very high-capacity solid-state storage solutions, but the actual inference and model training need something different. That’s a very high-performance, very high I/O-per-second requirement from the SSD. For us, RAG is bifurcating the types of products that we make and the types of integrations we have to make with the software.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-improving-ai-inference-at-the-edge"&gt;&lt;strong&gt;Improving AI inference at the edge&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;For peak performance at the edge, it’s critical to scale storage down to a single node, in order to bring inference closer to the data. And what’s key is removing memory bottlenecks. That can be done by making memory a part of the AI infrastructure, in order to scale it along with data and metadata. The proximity of data to compute dramatically increases the time to insight.&lt;/p&gt;



&lt;p&gt;“You see all the huge deployments, the big green field data centers for AI, using very specific hardware designs to be able to bring the data as close as possible to the GPUs,” Matson said. “They’ve been building out their data centers with very high-capacity solid-state storage, to bring petabyte-level storage, very accessible at very high speeds, to the GPUs. Now, that same technology is happening in a microcosm at the edge and in the enterprise.”&lt;/p&gt;



&lt;p&gt;It’s becoming critical to purchasers of AI systems to ensure you’re getting the most performance out of your system by running it on all solid state. That allows you to bring huge amounts of data, and enables incredible processing power in a small system at the edge.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-future-of-ai-hardware"&gt;&lt;strong&gt;The future of AI hardware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“It’s imperative that we provide solutions that are open, scalable, and at memory speed, using some of the latest and greatest technology out there to do that,” Cummings said. “That’s our goal as a company, to provide that openness, that speed, and the scale that organizations need. I think you’re going to see the economies match that as well.”&lt;/p&gt;



&lt;p&gt;For the overall training and inference data pipeline, and within inference itself, hardware needs will keep increasing, whether it’s a very high-speed SSD or a very high-capacity solution that’s power efficient.&lt;/p&gt;



&lt;p&gt;“I would say it’s going to move even further toward very high-capacity, whether it’s a one-petabyte SSD out a couple of years from now that runs at very low power and that can basically replace four times as many hard drives, or a very high-performance product that’s almost near memory speeds,” Matson said. “You’ll see that the big GPU vendors are looking at how to define the next storage architecture, so that it can help augment, very closely, the HBM in the system. What was a general-purpose SSD in cloud computing is now bifurcating into capacity and performance. We’ll keep doing that further out in both directions over the next five or 10 years.”&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI applications increasingly permeate enterprise operations, from enhancing patient care through advanced medical imaging to powering complex fraud detection models and even aiding wildlife conservation, a critical bottleneck often emerges: data storage.&lt;/p&gt;



&lt;p&gt;During VentureBeat’s Transform 2025, Greg Matson, head of products and marketing, Solidigm and Roger Cummings, CEO of PEAK:AIO spoke with Michael Stewart, managing partner at M12 about how innovations in storage technology enables enterprise AI use cases in healthcare.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The MONAI framework is a breakthrough in medical imaging, building it faster, more safely, and more securely. Advances in storage technology is what enables researchers to build on top of this framework, iterate and innovate quickly. PEAK:AIO partnered with Solidgm to integrate power-efficient, performant, and high-capacity storage which enabled MONAI to store more than two million full-body CT scans on a single node within their IT environment.&lt;/p&gt;



&lt;p&gt;“As enterprise AI infrastructure evolves rapidly, storage hardware increasingly needs to be tailored to specific use cases, depending on where they are in the AI data pipeline,” Matson said. “The type of use case we talked about with MONAI, an edge-use case, as well as the feeding of a training cluster, are well served by very high-capacity solid-state storage solutions, but the actual inference and model training need something different. That’s a very high-performance, very high I/O-per-second requirement from the SSD. For us, RAG is bifurcating the types of products that we make and the types of integrations we have to make with the software.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-improving-ai-inference-at-the-edge"&gt;&lt;strong&gt;Improving AI inference at the edge&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;For peak performance at the edge, it’s critical to scale storage down to a single node, in order to bring inference closer to the data. And what’s key is removing memory bottlenecks. That can be done by making memory a part of the AI infrastructure, in order to scale it along with data and metadata. The proximity of data to compute dramatically increases the time to insight.&lt;/p&gt;



&lt;p&gt;“You see all the huge deployments, the big green field data centers for AI, using very specific hardware designs to be able to bring the data as close as possible to the GPUs,” Matson said. “They’ve been building out their data centers with very high-capacity solid-state storage, to bring petabyte-level storage, very accessible at very high speeds, to the GPUs. Now, that same technology is happening in a microcosm at the edge and in the enterprise.”&lt;/p&gt;



&lt;p&gt;It’s becoming critical to purchasers of AI systems to ensure you’re getting the most performance out of your system by running it on all solid state. That allows you to bring huge amounts of data, and enables incredible processing power in a small system at the edge.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-future-of-ai-hardware"&gt;&lt;strong&gt;The future of AI hardware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;“It’s imperative that we provide solutions that are open, scalable, and at memory speed, using some of the latest and greatest technology out there to do that,” Cummings said. “That’s our goal as a company, to provide that openness, that speed, and the scale that organizations need. I think you’re going to see the economies match that as well.”&lt;/p&gt;



&lt;p&gt;For the overall training and inference data pipeline, and within inference itself, hardware needs will keep increasing, whether it’s a very high-speed SSD or a very high-capacity solution that’s power efficient.&lt;/p&gt;



&lt;p&gt;“I would say it’s going to move even further toward very high-capacity, whether it’s a one-petabyte SSD out a couple of years from now that runs at very low power and that can basically replace four times as many hard drives, or a very high-performance product that’s almost near memory speeds,” Matson said. “You’ll see that the big GPU vendors are looking at how to define the next storage architecture, so that it can help augment, very closely, the HBM in the system. What was a general-purpose SSD in cloud computing is now bifurcating into capacity and performance. We’ll keep doing that further out in both directions over the next five or 10 years.”&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/cracking-ais-storage-bottleneck-and-supercharging-inference-at-the-edge/</guid><pubDate>Mon, 07 Jul 2025 12:50:00 +0000</pubDate></item><item><title>[NEW] The digital future of industrial and operational work (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/07/1119714/the-digital-future-of-industrial-and-operational-work/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;TeamViewer&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Digital transformation has long been a boardroom buzzword—shorthand for ambitious, often abstract visions of modernization. But today, digital technologies are no longer simply concepts in glossy consultancy decks and on corporate campuses; they're also being embedded directly into factory floors, logistics hubs, and other mission-critical, frontline environments.&lt;/p&gt;  &lt;p&gt;This evolution is playing out across sectors: Field technicians on industrial sites are diagnosing machinery remotely with help from a slew of connected devices and data feeds, hospital teams are collaborating across geographies on complex patient care via telehealth technologies, and warehouse staff are relying on connected ecosystems to streamline inventory and fulfillment far faster than manual processes would allow.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1119715" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/Teamviewer-MITTR-2025-06_Telegraph_Digital_Shift_02.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Across all these scenarios, IT fundamentals—like remote access, unified login systems, and interoperability across platforms—are being handled behind the scenes and consolidated into streamlined, user-friendly solutions. The way employees experience these tools, collectively known as the digital employee experience (DEX), can be a key component of achieving business outcomes: Deloitte finds that companies investing in frontline-focused digital tools see a 22 % boost in worker productivity, a doubling in customer satisfaction, and as much as a 25 % increase in profitability.&lt;/p&gt;  &lt;p&gt;As digital tools become everyday fixtures in operational contexts, companies face both opportunities and hurdles—and the stakes are only rising as emerging technologies like AI become more sophisticated. The organizations best positioned for an AI-first future are crafting thoughtful strategies to ensure digital systems align with the realities of daily work—and placing people at the heart of the whole process.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT meets OT in an AI world&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite promising returns, many companies still face a last-mile challenge in delivering usable, effective tools to the frontline. The Deloitte study notes that less than one-quarter (just 23%) of frontline workers believe they have access to the technology they need to maximize productivity. There are several possible reasons for this disconnect, including the fact that operational digital transformation faces unique challenges compared to office-based digitization efforts.&lt;/p&gt;  &lt;p&gt;For one, many companies are using legacy systems that don't communicate easily across dispersed or edge environments. For example, the office IT department might use completely different software than what's running the factory floor; a hospital's patient records might be entirely separate from the systems monitoring medical equipment. When systems can't talk to one another, troubleshooting issues becomes a time-consuming guessing game—one that often requires manual workarounds or clunky patches.&lt;/p&gt; 
 &lt;p&gt;There's also often a clash between tech's typical "ship first, debug later" philosophy and the careful, safety-first approach that operational environments demand. A software glitch in a spreadsheet is annoying; a snafu in a power plant or at a chemical facility can be catastrophic.&lt;/p&gt;  &lt;p&gt;Striking a careful balance between proactive innovation and prudent precaution will become ever more important, especially as AI usage becomes more common in high-stakes, tightly regulated environments. Companies will need to navigate a growing tension between the promise of smarter operations and the reality of implementing them safely at scale.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Humans at the heart of transformation efforts&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With the buzz over AI and automation reaching fever pitch, it’s easy to overlook the single most impactful factor that makes transformation stick: the human element. The convergence of IT and OT goes hand in hand with the rise of digital employee experience. DEX encompasses everything from logging into systems and accessing applications to navigating networks and completing tasks across devices and locations. At its core, DEX is about ensuring technology empowers employees to work efficiently and without disruption—no matter where or how they work.&lt;/p&gt;  &lt;p&gt;Companies investing in DEX technology are seeing measurable gains—from reduced help desk tickets and system downtime to harder-to-quantify benefits like higher employee satisfaction and retention. Frictionless digital workplaces, supported by real-time monitoring and automation capabilities, help organizations attend to IT issues before users experience disruptions or productivity levels dip.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;There are real-world examples of seamless DEX in action: Swiss energy and infrastructure provider BKW, for instance, recently built a system that lets their IT team remotely assist employees experiencing technical difficulties across more than 140 subsidiaries. For employees, this means no more waiting for an in-person technician when their device freezes or software hiccups; IT can swoop in remotely and solve problems in minutes instead of hours.&lt;/p&gt;  &lt;p&gt;The insurance company RLI faced a different but equally frustrating issue before switching to a centralized, remote IT support system: Technical issues like device lag or overheating were often left unreported, as employees didn’t want to disrupt their workflow or bother the IT team with seemingly minor complaints. Those small performance issues, however, could snowball over time, sometimes causing devices to fail completely. To get ahead of this phenomenon, RLI installed monitoring software to observe device performance in real time and catch issues proactively. Now, when a laptop gets too hot or starts slowing down, IT can address it right away—often before the employee even knows there's a problem.&lt;/p&gt;  &lt;p&gt;Ultimately, the organizations making the biggest strides in DEX recognize that digital transformation is as much about experience as it is about infrastructure. When digital tools feel like helpful extensions of workers' expertise—rather than obstacles standing in the way of their workday—companies are in a better position to realize the full benefits of their investments.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Smart systems and smarter safeguards&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Of course, as operational systems become more interconnected, security vulnerabilities multiply in turn. Consider this hypothetical: In a busy manufacturing plant, a piece of machinery suddenly breaks down. Instead of waiting hours for a technician to arrive on-site, a local operator deploys a mobile augmented reality device that projects step-by-step diagnostic instructions onto the machine. Following guidance from a remote specialist, the operator fixes the equipment and has production back on track in mere minutes.&lt;/p&gt; 

 &lt;p&gt;This snappy and streamlined approach to diagnostics is undeniably efficient, but it opens up the factory floor to multiple external touchpoints: live video feeds streaming to remote experts, cloud databases containing sensitive repair procedures, and direct access to the machine's diagnostic systems. Suddenly, a manufacturing plant that used to be an island is now part of an interconnected network.&lt;/p&gt;  &lt;p&gt;Smart companies are getting practical about the challenges associated with this expanding threat surface. For instance, BKW has taken a structured approach to permissions: Subsidiary IT teams can only access their own company's devices, outside contractors get temporary access for specific tasks, and employees can reach certain high-powered workstations when they need them.&lt;/p&gt;  &lt;p&gt;Bühler, a global industrial equipment manufacturer, also uses centrally managed access controls to govern who can connect to which platforms, as well as when and under what conditions. By enforcing consistent policies from its headquarters, the company ensures all remote support activities are fully monitored and aligned with strict cybersecurity protocols, including compliance with ISO 27001 standards. The system allows Bühler’s extensive global technician network to provide real-time assistance without compromising system integrity.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The power of practical innovation&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;How do you help a technician troubleshoot equipment when the expert is 500 miles away? How do you catch IT problems before they shut down a production line? How do you keep operations secure without burying workers in passwords and protocols?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;These are the kinds of practical questions that companies like Bühler, BKW, and RLI Insurance have focused on solving—and it's part of why they're succeeding where others struggle. These examples demonstrate a genuine shift in how successful companies think about technology and transformation. Instead of asking, "What's the latest digital trend we should adopt?" they're assessing, "What problems are our people actually trying to solve?"&lt;/p&gt;  &lt;p&gt;The organizations pulling ahead to digitally transform frontline operations are the ones that have learned to make complex systems feel simple, intuitive, and secure to boot. Such a practical approach will only become more pressing as AI introduces new layers of complexity to operational work.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ready to make work work better for your business? &lt;/em&gt;&lt;em&gt;Learn how at TeamViewer.com.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;TeamViewer&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Digital transformation has long been a boardroom buzzword—shorthand for ambitious, often abstract visions of modernization. But today, digital technologies are no longer simply concepts in glossy consultancy decks and on corporate campuses; they're also being embedded directly into factory floors, logistics hubs, and other mission-critical, frontline environments.&lt;/p&gt;  &lt;p&gt;This evolution is playing out across sectors: Field technicians on industrial sites are diagnosing machinery remotely with help from a slew of connected devices and data feeds, hospital teams are collaborating across geographies on complex patient care via telehealth technologies, and warehouse staff are relying on connected ecosystems to streamline inventory and fulfillment far faster than manual processes would allow.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1119715" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/Teamviewer-MITTR-2025-06_Telegraph_Digital_Shift_02.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Across all these scenarios, IT fundamentals—like remote access, unified login systems, and interoperability across platforms—are being handled behind the scenes and consolidated into streamlined, user-friendly solutions. The way employees experience these tools, collectively known as the digital employee experience (DEX), can be a key component of achieving business outcomes: Deloitte finds that companies investing in frontline-focused digital tools see a 22 % boost in worker productivity, a doubling in customer satisfaction, and as much as a 25 % increase in profitability.&lt;/p&gt;  &lt;p&gt;As digital tools become everyday fixtures in operational contexts, companies face both opportunities and hurdles—and the stakes are only rising as emerging technologies like AI become more sophisticated. The organizations best positioned for an AI-first future are crafting thoughtful strategies to ensure digital systems align with the realities of daily work—and placing people at the heart of the whole process.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT meets OT in an AI world&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite promising returns, many companies still face a last-mile challenge in delivering usable, effective tools to the frontline. The Deloitte study notes that less than one-quarter (just 23%) of frontline workers believe they have access to the technology they need to maximize productivity. There are several possible reasons for this disconnect, including the fact that operational digital transformation faces unique challenges compared to office-based digitization efforts.&lt;/p&gt;  &lt;p&gt;For one, many companies are using legacy systems that don't communicate easily across dispersed or edge environments. For example, the office IT department might use completely different software than what's running the factory floor; a hospital's patient records might be entirely separate from the systems monitoring medical equipment. When systems can't talk to one another, troubleshooting issues becomes a time-consuming guessing game—one that often requires manual workarounds or clunky patches.&lt;/p&gt; 
 &lt;p&gt;There's also often a clash between tech's typical "ship first, debug later" philosophy and the careful, safety-first approach that operational environments demand. A software glitch in a spreadsheet is annoying; a snafu in a power plant or at a chemical facility can be catastrophic.&lt;/p&gt;  &lt;p&gt;Striking a careful balance between proactive innovation and prudent precaution will become ever more important, especially as AI usage becomes more common in high-stakes, tightly regulated environments. Companies will need to navigate a growing tension between the promise of smarter operations and the reality of implementing them safely at scale.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Humans at the heart of transformation efforts&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With the buzz over AI and automation reaching fever pitch, it’s easy to overlook the single most impactful factor that makes transformation stick: the human element. The convergence of IT and OT goes hand in hand with the rise of digital employee experience. DEX encompasses everything from logging into systems and accessing applications to navigating networks and completing tasks across devices and locations. At its core, DEX is about ensuring technology empowers employees to work efficiently and without disruption—no matter where or how they work.&lt;/p&gt;  &lt;p&gt;Companies investing in DEX technology are seeing measurable gains—from reduced help desk tickets and system downtime to harder-to-quantify benefits like higher employee satisfaction and retention. Frictionless digital workplaces, supported by real-time monitoring and automation capabilities, help organizations attend to IT issues before users experience disruptions or productivity levels dip.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;There are real-world examples of seamless DEX in action: Swiss energy and infrastructure provider BKW, for instance, recently built a system that lets their IT team remotely assist employees experiencing technical difficulties across more than 140 subsidiaries. For employees, this means no more waiting for an in-person technician when their device freezes or software hiccups; IT can swoop in remotely and solve problems in minutes instead of hours.&lt;/p&gt;  &lt;p&gt;The insurance company RLI faced a different but equally frustrating issue before switching to a centralized, remote IT support system: Technical issues like device lag or overheating were often left unreported, as employees didn’t want to disrupt their workflow or bother the IT team with seemingly minor complaints. Those small performance issues, however, could snowball over time, sometimes causing devices to fail completely. To get ahead of this phenomenon, RLI installed monitoring software to observe device performance in real time and catch issues proactively. Now, when a laptop gets too hot or starts slowing down, IT can address it right away—often before the employee even knows there's a problem.&lt;/p&gt;  &lt;p&gt;Ultimately, the organizations making the biggest strides in DEX recognize that digital transformation is as much about experience as it is about infrastructure. When digital tools feel like helpful extensions of workers' expertise—rather than obstacles standing in the way of their workday—companies are in a better position to realize the full benefits of their investments.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Smart systems and smarter safeguards&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Of course, as operational systems become more interconnected, security vulnerabilities multiply in turn. Consider this hypothetical: In a busy manufacturing plant, a piece of machinery suddenly breaks down. Instead of waiting hours for a technician to arrive on-site, a local operator deploys a mobile augmented reality device that projects step-by-step diagnostic instructions onto the machine. Following guidance from a remote specialist, the operator fixes the equipment and has production back on track in mere minutes.&lt;/p&gt; 

 &lt;p&gt;This snappy and streamlined approach to diagnostics is undeniably efficient, but it opens up the factory floor to multiple external touchpoints: live video feeds streaming to remote experts, cloud databases containing sensitive repair procedures, and direct access to the machine's diagnostic systems. Suddenly, a manufacturing plant that used to be an island is now part of an interconnected network.&lt;/p&gt;  &lt;p&gt;Smart companies are getting practical about the challenges associated with this expanding threat surface. For instance, BKW has taken a structured approach to permissions: Subsidiary IT teams can only access their own company's devices, outside contractors get temporary access for specific tasks, and employees can reach certain high-powered workstations when they need them.&lt;/p&gt;  &lt;p&gt;Bühler, a global industrial equipment manufacturer, also uses centrally managed access controls to govern who can connect to which platforms, as well as when and under what conditions. By enforcing consistent policies from its headquarters, the company ensures all remote support activities are fully monitored and aligned with strict cybersecurity protocols, including compliance with ISO 27001 standards. The system allows Bühler’s extensive global technician network to provide real-time assistance without compromising system integrity.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The power of practical innovation&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;How do you help a technician troubleshoot equipment when the expert is 500 miles away? How do you catch IT problems before they shut down a production line? How do you keep operations secure without burying workers in passwords and protocols?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;These are the kinds of practical questions that companies like Bühler, BKW, and RLI Insurance have focused on solving—and it's part of why they're succeeding where others struggle. These examples demonstrate a genuine shift in how successful companies think about technology and transformation. Instead of asking, "What's the latest digital trend we should adopt?" they're assessing, "What problems are our people actually trying to solve?"&lt;/p&gt;  &lt;p&gt;The organizations pulling ahead to digitally transform frontline operations are the ones that have learned to make complex systems feel simple, intuitive, and secure to boot. Such a practical approach will only become more pressing as AI introduces new layers of complexity to operational work.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ready to make work work better for your business? &lt;/em&gt;&lt;em&gt;Learn how at TeamViewer.com.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/07/1119714/the-digital-future-of-industrial-and-operational-work/</guid><pubDate>Mon, 07 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Exploring data and its influence on political behavior (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/exploring-data-and-its-influence-political-behavior-0707</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-Data-Politics-class.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Data and politics are becoming increasingly intertwined. Today’s political campaigns and voter mobilization efforts are now entirely data-driven. Voters, pollsters, and elected officials are relying on data to make choices that have local, regional, and national impacts.&lt;/p&gt;&lt;p&gt;A Department of Political Science course offers students tools to help make sense of these choices and their outcomes.&lt;/p&gt;&lt;p&gt;In class 17.831 (Data and Politics), students are introduced to principles and practices necessary to understand electoral and other types of political behavior. Taught by associate professor of political science Daniel Hidalgo, students use real-world datasets to explore topics like election polling and prediction, voter turnout, voter targeting, and shifts in public opinion over time.&lt;/p&gt;&lt;p&gt;The course wants students to describe why and how the use of data and statistical methods has changed electoral politics, understand the basic principles of social science statistics, and analyze data using modern statistical computing tools. The course capstone is an original project that involves the collection, analysis, and interpretation of original survey data used in modern campaigns.&lt;/p&gt;&lt;p&gt;“I wanted to create an applied, practice-based course that would appeal to undergraduates and provide a foundation for parsing, understanding, and reporting on large datasets in politics,” says Hidalgo, who redesigned the course for the spring 2025 semester.&lt;/p&gt;&lt;p&gt;Hidalgo, who also works in the Political Methodology Lab at MIT, investigates the political economy of elections, campaigns, and representation in developing democracies, especially in Latin America, as well as quantitative methods in the social sciences.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Politics and modernity&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The influence of, and access to, artificial intelligence and large language models makes a course like Data and Politics even more important, Hidalgo says. “You have to understand the people at the other end of the data,” he argues.&lt;/p&gt;&lt;p&gt;The course also centers the human element in politics, exploring conflict, bias, their structures, and impacts while also working to improve information literacy and coherent storytelling.&lt;/p&gt;&lt;p&gt;“Data analysis and collection will never be perfect,” Hidalgo says. “But analyzing and understanding who holds which ideas, and why, and using the information to tell a coherent story is valuable in politics and elsewhere.”&lt;/p&gt;&lt;p&gt;The “always on” nature of news and related content, coupled with the variety of communications channels available to voters, has increased the complexity of the data collection process in polling and campaigns. “In the past, people would answer the phone when you called their homes,” Hidalgo notes, describing analog methods previously used to collect voter data. Now, political scientists, data analysts, and others must contend with the availability of streaming content, mobile devices, and other channels comprising a vast, fractured media ecosystem.&lt;/p&gt;&lt;p&gt;The course opens a window into what happens behind the scenes of local and national political campaigns, which appealed to second-year political science major Jackson Hamilton. “I took this class hoping to expand my ability to use coding for political science applications, and in order to better understand how political models and predictions work,” he says.&lt;/p&gt;&lt;p&gt;“We tailor-made our own sets of questions and experimental designs that we thought would be interesting,” Hamilton adds. “I found that political issues that get a lot of media coverage are not necessarily the same issues which divide lawmakers, at least locally.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Transparency and accountability in politics and other areas&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teaching students to use tools like polling and data analysis effectively can improve their ability to identify and combat disinformation and misinformation. “As a political scientist, I’m substantively engaged,” Hidalgo says, “and I’d like to help others be engaged, too.”&lt;/p&gt;&lt;p&gt;“There’s lots of data available, and this course provides a foundation and the resources necessary to understand and visualize it,” Hidalgo continues. “The ability to design, implement, and understand surveys has value inside and outside the classroom.”&lt;/p&gt;&lt;p&gt;In politics, Hidalgo believes equipping students to navigate these spaces effectively can potentially improve and increase civic engagement. Data, he says, can help defend ideas. “There’s so much information, it’s important to develop the skills and abilities necessary to understand and visualize it,” he says. “This has value for everyone.”&lt;/p&gt;&lt;p&gt;Second-year physics major Sean Wilson, who also took the class this spring, notes the value of data visualization and analysis both as a potential physicist and a voter. “Data analysis in both politics and in physics is essential work given that voting tendencies, public opinion, and government leadership change so often in the United States,” he says, “and that modeling can be used to support physical hypotheses and improve our understanding of how things work.”&lt;/p&gt;&lt;p&gt;For Wilson, the course can help anyone interested in understanding large groups’ behaviors. “Political scientists are constantly working to better understand how and why certain events occur in U.S. politics, and data analysis is an effective tool for doing so,” he says. “Members of a representative democracy can make better decisions with this kind of information.”&lt;/p&gt;&lt;p&gt;Hamilton, meanwhile, learned more about the behind-the-scenes machinery at work in electoral politics. “I had the opportunity to create a couple of budget trade-off questions, to get a sense of what people actually thought the government should spend money on when they had to make choices,” he says.&lt;/p&gt;&lt;p&gt;“Computer science and data science aren’t just useful for STEM applications; data science approaches can also be extremely useful in many social sciences,” Hamilton argues.&lt;/p&gt;&lt;p&gt;“[Hidalgo helped me realize] that I needed to understand and use data science approaches to gain a deeper understanding of my areas of interest,” Hamilton says. “He focuses on how different approaches in coding can be applied to different types of problems in political science.”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-Data-Politics-class.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Data and politics are becoming increasingly intertwined. Today’s political campaigns and voter mobilization efforts are now entirely data-driven. Voters, pollsters, and elected officials are relying on data to make choices that have local, regional, and national impacts.&lt;/p&gt;&lt;p&gt;A Department of Political Science course offers students tools to help make sense of these choices and their outcomes.&lt;/p&gt;&lt;p&gt;In class 17.831 (Data and Politics), students are introduced to principles and practices necessary to understand electoral and other types of political behavior. Taught by associate professor of political science Daniel Hidalgo, students use real-world datasets to explore topics like election polling and prediction, voter turnout, voter targeting, and shifts in public opinion over time.&lt;/p&gt;&lt;p&gt;The course wants students to describe why and how the use of data and statistical methods has changed electoral politics, understand the basic principles of social science statistics, and analyze data using modern statistical computing tools. The course capstone is an original project that involves the collection, analysis, and interpretation of original survey data used in modern campaigns.&lt;/p&gt;&lt;p&gt;“I wanted to create an applied, practice-based course that would appeal to undergraduates and provide a foundation for parsing, understanding, and reporting on large datasets in politics,” says Hidalgo, who redesigned the course for the spring 2025 semester.&lt;/p&gt;&lt;p&gt;Hidalgo, who also works in the Political Methodology Lab at MIT, investigates the political economy of elections, campaigns, and representation in developing democracies, especially in Latin America, as well as quantitative methods in the social sciences.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Politics and modernity&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The influence of, and access to, artificial intelligence and large language models makes a course like Data and Politics even more important, Hidalgo says. “You have to understand the people at the other end of the data,” he argues.&lt;/p&gt;&lt;p&gt;The course also centers the human element in politics, exploring conflict, bias, their structures, and impacts while also working to improve information literacy and coherent storytelling.&lt;/p&gt;&lt;p&gt;“Data analysis and collection will never be perfect,” Hidalgo says. “But analyzing and understanding who holds which ideas, and why, and using the information to tell a coherent story is valuable in politics and elsewhere.”&lt;/p&gt;&lt;p&gt;The “always on” nature of news and related content, coupled with the variety of communications channels available to voters, has increased the complexity of the data collection process in polling and campaigns. “In the past, people would answer the phone when you called their homes,” Hidalgo notes, describing analog methods previously used to collect voter data. Now, political scientists, data analysts, and others must contend with the availability of streaming content, mobile devices, and other channels comprising a vast, fractured media ecosystem.&lt;/p&gt;&lt;p&gt;The course opens a window into what happens behind the scenes of local and national political campaigns, which appealed to second-year political science major Jackson Hamilton. “I took this class hoping to expand my ability to use coding for political science applications, and in order to better understand how political models and predictions work,” he says.&lt;/p&gt;&lt;p&gt;“We tailor-made our own sets of questions and experimental designs that we thought would be interesting,” Hamilton adds. “I found that political issues that get a lot of media coverage are not necessarily the same issues which divide lawmakers, at least locally.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Transparency and accountability in politics and other areas&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Teaching students to use tools like polling and data analysis effectively can improve their ability to identify and combat disinformation and misinformation. “As a political scientist, I’m substantively engaged,” Hidalgo says, “and I’d like to help others be engaged, too.”&lt;/p&gt;&lt;p&gt;“There’s lots of data available, and this course provides a foundation and the resources necessary to understand and visualize it,” Hidalgo continues. “The ability to design, implement, and understand surveys has value inside and outside the classroom.”&lt;/p&gt;&lt;p&gt;In politics, Hidalgo believes equipping students to navigate these spaces effectively can potentially improve and increase civic engagement. Data, he says, can help defend ideas. “There’s so much information, it’s important to develop the skills and abilities necessary to understand and visualize it,” he says. “This has value for everyone.”&lt;/p&gt;&lt;p&gt;Second-year physics major Sean Wilson, who also took the class this spring, notes the value of data visualization and analysis both as a potential physicist and a voter. “Data analysis in both politics and in physics is essential work given that voting tendencies, public opinion, and government leadership change so often in the United States,” he says, “and that modeling can be used to support physical hypotheses and improve our understanding of how things work.”&lt;/p&gt;&lt;p&gt;For Wilson, the course can help anyone interested in understanding large groups’ behaviors. “Political scientists are constantly working to better understand how and why certain events occur in U.S. politics, and data analysis is an effective tool for doing so,” he says. “Members of a representative democracy can make better decisions with this kind of information.”&lt;/p&gt;&lt;p&gt;Hamilton, meanwhile, learned more about the behind-the-scenes machinery at work in electoral politics. “I had the opportunity to create a couple of budget trade-off questions, to get a sense of what people actually thought the government should spend money on when they had to make choices,” he says.&lt;/p&gt;&lt;p&gt;“Computer science and data science aren’t just useful for STEM applications; data science approaches can also be extremely useful in many social sciences,” Hamilton argues.&lt;/p&gt;&lt;p&gt;“[Hidalgo helped me realize] that I needed to understand and use data science approaches to gain a deeper understanding of my areas of interest,” Hamilton says. “He focuses on how different approaches in coding can be applied to different types of problems in political science.”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/exploring-data-and-its-influence-political-behavior-0707</guid><pubDate>Mon, 07 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] New postdoctoral fellowship program to accelerate innovation in health care (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-postdoctoral-fellowship-program-accelerate-innovation-health-care-0707</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The MIT Health and Life Sciences Collaborative (MIT HEALS) is launching the Biswas Postdoctoral Fellowship Program to advance the work of outstanding early-career researchers in health and life sciences. Supported by a gift from the Biswas Family Foundation, the program aims to help apply cutting-edge research to improve health care and the lives of millions.&lt;/p&gt;&lt;p&gt;The program will support exceptional postdocs dedicated to innovation in human health care through a full range of pathways, such as leveraging AI in health-related research, developing low-cost diagnostics, and the convergence of life sciences with such areas as economics, business, policy, or the humanities. With initial funding of $12 million, five four-year fellowships will be awarded for each of the next four years, starting in early 2026.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/VHAW_qoRiUM/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            MIT HEALS: Driving Innovation in Health and Life Sciences        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“An essential goal of MIT HEALS is to find new ways and opportunities to deliver health care solutions at scale, and the Biswas Family Foundation shares our commitment to scalable innovation and broad impact. MIT is also in the talent business, and the foundation’s gift allows us to bring exceptional scholars to campus to explore some of the most pressing issues in human health and build meaningful connections across academia and industry. We look forward to welcoming the first cohort of Biswas Fellows to MIT,” says MIT president Sally Kornbluth.&lt;/p&gt;&lt;p&gt;“We are deeply honored to launch this world-class postdoctoral fellows program,” adds Anantha P. Chandrakasan, MIT’s chief innovation and strategy officer and head of MIT HEALS. “We fully expect to attract top candidates from around the globe to lead innovative cross-cutting projects in AI and health, cancer therapies, diagnostics, and beyond. These fellows will be selected through a rigorous process overseen by a distinguished committee, and will have the opportunity to collaborate with our faculty on the most promising and impactful ideas.”&lt;/p&gt;&lt;p&gt;Angela Koehler, faculty lead of MIT HEALS, professor in MIT’s Department of Biological Engineering, and associate director of the Koch Institute for Integrative Cancer Research, emphasized that the objectives of MIT HEALS align well with a stated goal of the Biswas Family Foundation: to leverage “scientific and technological advancements to revolutionize health care and make a lasting impact on global public health.”&lt;/p&gt;&lt;p&gt;“Health care is a team sport,” Koehler says. “MIT HEALS seeks to create connections involving investigators with diverse expertise across the Institute to tackle the most transformative problems impacting human health. Members of the MIT community are well poised to participate in teams and make an impact.”&lt;/p&gt;&lt;p&gt;MIT HEALS also seeks to maximize its effectiveness by expanding collaboration with medical schools and hospitals, starting with defining important problems that can be approached through research, and continuing all the way to clinical studies, Koehler says.&lt;/p&gt;&lt;p&gt;The Biswas Family Foundation has already demonstrated a similar strategy.&lt;/p&gt;&lt;p&gt;“The Biswas family has a history of enabling connections and partnerships between institutions that each bring a piece to the puzzle,” Koehler says. “This could be a dataset, an algorithm, an agent, a technology platform, or patients.”&lt;/p&gt;&lt;p&gt;Hope Biswas, co-founder of the Biswas Family Foundation with her husband, MIT alumnus Sanjit Biswas SM ’05, also highlighted the synergies between the foundation and MIT.&lt;/p&gt;&lt;p&gt;“The Biswas Family Foundation is proud to support the MIT HEALS initiative, which reimagines how scientific discovery can translate into real-world health impact. Its focus on promoting interdisciplinary collaboration to find new solutions to challenges in health care aligns closely with our mission to advance science and technology to improve health outcomes at scale,” Biswas says.&lt;/p&gt;&lt;p&gt;“As part of this commitment,” Biswas adds, “we are especially proud to support outstanding postdoctoral scholars focused on high-impact cross-disciplinary work in fields such as computational biology, nanoscale therapeutics, women’s health, and fundamental, curiosity-driven life sciences research. We are excited to contribute to an effort that brings together cutting-edge science and a deep commitment to translating knowledge into action.”&lt;/p&gt;&lt;p&gt;AI and machine-learning systems present a new universe of opportunities to investigate disease, biological mechanisms, therapeutics, and health care delivery using huge datasets.&lt;/p&gt;&lt;p&gt;“AI and computational systems biology can improve the accuracy of diagnostic approaches, enable the development of precision medicines, improve choices related to individualized treatment strategy, and improve operational efficiency within health care systems,” says Koehler. “Sanjit and Hope’s support of broad initiatives in AI and computational systems biology will help MIT researchers explore a variety of paths to impact human health on a large scale.”&lt;/p&gt;&lt;p&gt;Frontiers in health-related research are increasingly found where diverse fields converge, and Koehler provides the example of how advances in high-throughput experimentation to develop large datasets “may couple well with the development of new computation or AI tools.” She adds that the four-year funding term provided by the postdoctoral fellowship is “long enough to enable fellows to think big and take on projects at interfaces, emerging as bilingual researchers at the end of the program.”&lt;/p&gt;&lt;p&gt;Chandrakasan sees potential in the program for the Biswas Fellows to make revolutionary progress in health research.&lt;/p&gt;&lt;p&gt;“I’m incredibly grateful to the Biswas Family Foundation for their generous support in enabling transformative research at MIT,” Chandrakasan says.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The MIT Health and Life Sciences Collaborative (MIT HEALS) is launching the Biswas Postdoctoral Fellowship Program to advance the work of outstanding early-career researchers in health and life sciences. Supported by a gift from the Biswas Family Foundation, the program aims to help apply cutting-edge research to improve health care and the lives of millions.&lt;/p&gt;&lt;p&gt;The program will support exceptional postdocs dedicated to innovation in human health care through a full range of pathways, such as leveraging AI in health-related research, developing low-cost diagnostics, and the convergence of life sciences with such areas as economics, business, policy, or the humanities. With initial funding of $12 million, five four-year fellowships will be awarded for each of the next four years, starting in early 2026.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/VHAW_qoRiUM/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            MIT HEALS: Driving Innovation in Health and Life Sciences        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“An essential goal of MIT HEALS is to find new ways and opportunities to deliver health care solutions at scale, and the Biswas Family Foundation shares our commitment to scalable innovation and broad impact. MIT is also in the talent business, and the foundation’s gift allows us to bring exceptional scholars to campus to explore some of the most pressing issues in human health and build meaningful connections across academia and industry. We look forward to welcoming the first cohort of Biswas Fellows to MIT,” says MIT president Sally Kornbluth.&lt;/p&gt;&lt;p&gt;“We are deeply honored to launch this world-class postdoctoral fellows program,” adds Anantha P. Chandrakasan, MIT’s chief innovation and strategy officer and head of MIT HEALS. “We fully expect to attract top candidates from around the globe to lead innovative cross-cutting projects in AI and health, cancer therapies, diagnostics, and beyond. These fellows will be selected through a rigorous process overseen by a distinguished committee, and will have the opportunity to collaborate with our faculty on the most promising and impactful ideas.”&lt;/p&gt;&lt;p&gt;Angela Koehler, faculty lead of MIT HEALS, professor in MIT’s Department of Biological Engineering, and associate director of the Koch Institute for Integrative Cancer Research, emphasized that the objectives of MIT HEALS align well with a stated goal of the Biswas Family Foundation: to leverage “scientific and technological advancements to revolutionize health care and make a lasting impact on global public health.”&lt;/p&gt;&lt;p&gt;“Health care is a team sport,” Koehler says. “MIT HEALS seeks to create connections involving investigators with diverse expertise across the Institute to tackle the most transformative problems impacting human health. Members of the MIT community are well poised to participate in teams and make an impact.”&lt;/p&gt;&lt;p&gt;MIT HEALS also seeks to maximize its effectiveness by expanding collaboration with medical schools and hospitals, starting with defining important problems that can be approached through research, and continuing all the way to clinical studies, Koehler says.&lt;/p&gt;&lt;p&gt;The Biswas Family Foundation has already demonstrated a similar strategy.&lt;/p&gt;&lt;p&gt;“The Biswas family has a history of enabling connections and partnerships between institutions that each bring a piece to the puzzle,” Koehler says. “This could be a dataset, an algorithm, an agent, a technology platform, or patients.”&lt;/p&gt;&lt;p&gt;Hope Biswas, co-founder of the Biswas Family Foundation with her husband, MIT alumnus Sanjit Biswas SM ’05, also highlighted the synergies between the foundation and MIT.&lt;/p&gt;&lt;p&gt;“The Biswas Family Foundation is proud to support the MIT HEALS initiative, which reimagines how scientific discovery can translate into real-world health impact. Its focus on promoting interdisciplinary collaboration to find new solutions to challenges in health care aligns closely with our mission to advance science and technology to improve health outcomes at scale,” Biswas says.&lt;/p&gt;&lt;p&gt;“As part of this commitment,” Biswas adds, “we are especially proud to support outstanding postdoctoral scholars focused on high-impact cross-disciplinary work in fields such as computational biology, nanoscale therapeutics, women’s health, and fundamental, curiosity-driven life sciences research. We are excited to contribute to an effort that brings together cutting-edge science and a deep commitment to translating knowledge into action.”&lt;/p&gt;&lt;p&gt;AI and machine-learning systems present a new universe of opportunities to investigate disease, biological mechanisms, therapeutics, and health care delivery using huge datasets.&lt;/p&gt;&lt;p&gt;“AI and computational systems biology can improve the accuracy of diagnostic approaches, enable the development of precision medicines, improve choices related to individualized treatment strategy, and improve operational efficiency within health care systems,” says Koehler. “Sanjit and Hope’s support of broad initiatives in AI and computational systems biology will help MIT researchers explore a variety of paths to impact human health on a large scale.”&lt;/p&gt;&lt;p&gt;Frontiers in health-related research are increasingly found where diverse fields converge, and Koehler provides the example of how advances in high-throughput experimentation to develop large datasets “may couple well with the development of new computation or AI tools.” She adds that the four-year funding term provided by the postdoctoral fellowship is “long enough to enable fellows to think big and take on projects at interfaces, emerging as bilingual researchers at the end of the program.”&lt;/p&gt;&lt;p&gt;Chandrakasan sees potential in the program for the Biswas Fellows to make revolutionary progress in health research.&lt;/p&gt;&lt;p&gt;“I’m incredibly grateful to the Biswas Family Foundation for their generous support in enabling transformative research at MIT,” Chandrakasan says.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-postdoctoral-fellowship-program-accelerate-innovation-health-care-0707</guid><pubDate>Mon, 07 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Producing tangible business benefits from modern iPaaS solutions (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/07/1119383/producing-tangible-business-benefits-from-modern-ipaas-solutions/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;SAP&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When a historic UK-based retailer set out to modernize its IT environment, it was wrestling with systems that had grown organically for more than 175 years. Prior digital transformation efforts had resulted in a patchwork of hundreds of integration flows spanning cloud, on-premises systems, and third-party vendors, all communicating across multiple protocols.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1119388" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/iStock-1166492679.jpg?w=1254" /&gt;&lt;/figure&gt;  &lt;p&gt;The company needed a way to bridge the invisible seams stitching together decades of technology decisions. So, rather than layering on yet another patch, it opted for a more cohesive approach: an integration platform as a service (iPaaS) solution, i.e. a cloud-based ecosystem that enables smooth connections across applications and data sources. By going this route, the company reduced the total cost of ownership of its integration landscape by 40%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The scenario illustrates the power of iPaaS in action. For many enterprises, iPaaS turns what was once a costly, complex undertaking into a streamlined, strategic advantage. According to Forrester research commissioned by SAP, businesses modernizing with iPaaS solutions can see a 345% return on investment over three years, with a payback period of less than six months.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Agile integration for an AI-first world&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In 2025, the business need for flexible and friction-free integration has new urgency. When core business systems can’t communicate easily, the impacts ripple across the organization: Customer support teams can’t access real-time order statuses, finance teams struggle to consolidate data for monthly closes, and marketers lack reliable insights to personalize campaigns or effectively measure ROI.&lt;/p&gt; 
 &lt;p&gt;A lack of high-quality data access is particularly problematic in the AI era, which depends on current, consistent, and connected data flows to fuel everything from predictive analytics to bespoke AI copilots. To unleash the full potential of AI, enterprises must first solve for any bottlenecks that prevent information from flowing freely across their systems. They must also ensure data pipelines are reliable and well-governed; when AI models are trained on inconsistent or outdated data, the insights they generate can be misleading or incomplete—which can undermine everything from customer recommendations to financial forecasting.&lt;/p&gt;  &lt;p&gt;iPaaS platforms are often well-suited for accomplishing this across dynamic, distributed environments. Built as cloud-native, microservices-based integration hubs, modern iPaaS platforms can scale rapidly, adapt to changing workloads, and support hybrid architectures without adding complexity. They also help simplify the user experience for everyday business users via low-code functionalities that allow both technical and non-technical employees to build workflows with simple drag-and-drop or click-to-configure interfaces.&lt;/p&gt; 
 &lt;p&gt;This self-service model has practical, real-world applications across business functions: For instance, customer service agents can connect support ticketing systems with real-time inventory or shipping data, finance departments can link payment processors to accounting software, and marketing teams can sync CRM data with campaign platforms to trigger personalized outreach—all without waiting for IT to come to the rescue.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Architectural foundations for fast, flexible integration&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Several key architectural elements make the agility associated with iPaaS solutions possible:&lt;/p&gt;  &lt;ol class="wp-block-list"&gt; &lt;li&gt;API-first design that treats every connection as a reusable service&lt;/li&gt;    &lt;li&gt;Event-driven capabilities that enable real-time responsiveness&lt;/li&gt;    &lt;li&gt;Modular components that can be mixed and matched to address specific business scenarios&lt;/li&gt; &lt;/ol&gt;  &lt;p&gt;These principles are central to making the transition from “spaghetti architecture” to “integration fabric”—a shift from brittle point-to-point connections to intelligent, policy-driven connectivity that spans multidimensional IT environments.&lt;/p&gt;  &lt;p&gt;This approach means that when a company wants to add a new application, onboard a new partner, or create a new customer experience, they’re able to do so by tapping into existing integration assets rather than starting from scratch—which can lead to dramatically faster deployment cycles. It also helps enforce consistency and, in some cases, security and compliance across environments (role-based access controls and built-in monitoring capabilities, for example, can allow organizations to apply standards more uniformly).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Further, studies suggest that iPaaS solutions enable companies to unlock new revenue streams by integrating previously siloed data and processes. Forrester research found that organizations adopting iPaaS solutions stand to generate nearly $1 million in incremental profit over three years by creating new digital services, improving customer experiences, and automating revenue-generating processes that were previously manual.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Where iPaaS is headed: convergence and intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;All this momentum is perhaps one of the reasons why the global iPaaS market, valued at approximately $12.9 billion in 2024, is projected to reach more than $78 billion by 2032—with growth rates exceeding 25% annually.&lt;/p&gt;  &lt;p&gt;This trajectory is contingent on two ongoing trends: the convergence of integration capabilities into broader application development platforms, and the infusion of AI into the integration lifecycle.&lt;/p&gt;  &lt;p&gt;Today, the boundaries between iPaaS, automation platforms, and AI development environments are blurring as vendors create unified solutions that can handle everything from basic data synchronization to complex business processes.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;AI and machine learning capabilities are also being embedded directly into integration platforms. Soon, features like predictive maintenance of integration flow or intelligent routing of data based on current conditions are likely to become table stakes. Already, integration platforms are becoming smarter and more autonomous, capable of optimizing themselves and, in some cases, even initiating self-healing actions when problems arise.&lt;/p&gt;  &lt;p&gt;At the same time, this shift is transforming how businesses think about integration as a dynamic enabler of AI strategy. In the near future, robust integration frameworks will be essential to operationalize AI at scale and feed these systems the rich, contextual data they need to deliver meaningful insights.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building integration as competitive advantage&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to the retail modernization story detailed earlier, a few more real-world examples highlight the potential of iPaaS:&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;A chemicals manufacturer migrated 363 legacy interfaces to an iPaaS platform and now spins up new integrations 50% faster.&lt;/li&gt;    &lt;li&gt;A North American bottling company reduced integration runtime costs by more than 50% while supporting 12 legal entities on a single cloud ERP instance through common APIs.&lt;/li&gt;    &lt;li&gt;A global shipping-technology firm connected its CRM and third-party systems via cloud-based iPaaS solutions, enabling 100% touchless order fulfillment and a 95% cut in cost centers after a nine-month rollout in its first region.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Taken together, these examples make a compelling case for integration as strategy, not just infrastructure. They reflect a shift in mindset, where integration is democratized and embedded into how every team, not just IT, gets work done. Companies that treat integration as a core capability versus an IT afterthought are reaping tangible, enterprise-wide benefits, from faster go-to-market timelines and reduced operational costs to fully automated business processes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;As AI reshapes business processes and customer standards continue to climb, enterprises are realizing that integration architecture determines not only what they can build today, but how quickly they can adapt to whatever comes tomorrow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;SAP&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When a historic UK-based retailer set out to modernize its IT environment, it was wrestling with systems that had grown organically for more than 175 years. Prior digital transformation efforts had resulted in a patchwork of hundreds of integration flows spanning cloud, on-premises systems, and third-party vendors, all communicating across multiple protocols.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1119388" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/iStock-1166492679.jpg?w=1254" /&gt;&lt;/figure&gt;  &lt;p&gt;The company needed a way to bridge the invisible seams stitching together decades of technology decisions. So, rather than layering on yet another patch, it opted for a more cohesive approach: an integration platform as a service (iPaaS) solution, i.e. a cloud-based ecosystem that enables smooth connections across applications and data sources. By going this route, the company reduced the total cost of ownership of its integration landscape by 40%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The scenario illustrates the power of iPaaS in action. For many enterprises, iPaaS turns what was once a costly, complex undertaking into a streamlined, strategic advantage. According to Forrester research commissioned by SAP, businesses modernizing with iPaaS solutions can see a 345% return on investment over three years, with a payback period of less than six months.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Agile integration for an AI-first world&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In 2025, the business need for flexible and friction-free integration has new urgency. When core business systems can’t communicate easily, the impacts ripple across the organization: Customer support teams can’t access real-time order statuses, finance teams struggle to consolidate data for monthly closes, and marketers lack reliable insights to personalize campaigns or effectively measure ROI.&lt;/p&gt; 
 &lt;p&gt;A lack of high-quality data access is particularly problematic in the AI era, which depends on current, consistent, and connected data flows to fuel everything from predictive analytics to bespoke AI copilots. To unleash the full potential of AI, enterprises must first solve for any bottlenecks that prevent information from flowing freely across their systems. They must also ensure data pipelines are reliable and well-governed; when AI models are trained on inconsistent or outdated data, the insights they generate can be misleading or incomplete—which can undermine everything from customer recommendations to financial forecasting.&lt;/p&gt;  &lt;p&gt;iPaaS platforms are often well-suited for accomplishing this across dynamic, distributed environments. Built as cloud-native, microservices-based integration hubs, modern iPaaS platforms can scale rapidly, adapt to changing workloads, and support hybrid architectures without adding complexity. They also help simplify the user experience for everyday business users via low-code functionalities that allow both technical and non-technical employees to build workflows with simple drag-and-drop or click-to-configure interfaces.&lt;/p&gt; 
 &lt;p&gt;This self-service model has practical, real-world applications across business functions: For instance, customer service agents can connect support ticketing systems with real-time inventory or shipping data, finance departments can link payment processors to accounting software, and marketing teams can sync CRM data with campaign platforms to trigger personalized outreach—all without waiting for IT to come to the rescue.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Architectural foundations for fast, flexible integration&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Several key architectural elements make the agility associated with iPaaS solutions possible:&lt;/p&gt;  &lt;ol class="wp-block-list"&gt; &lt;li&gt;API-first design that treats every connection as a reusable service&lt;/li&gt;    &lt;li&gt;Event-driven capabilities that enable real-time responsiveness&lt;/li&gt;    &lt;li&gt;Modular components that can be mixed and matched to address specific business scenarios&lt;/li&gt; &lt;/ol&gt;  &lt;p&gt;These principles are central to making the transition from “spaghetti architecture” to “integration fabric”—a shift from brittle point-to-point connections to intelligent, policy-driven connectivity that spans multidimensional IT environments.&lt;/p&gt;  &lt;p&gt;This approach means that when a company wants to add a new application, onboard a new partner, or create a new customer experience, they’re able to do so by tapping into existing integration assets rather than starting from scratch—which can lead to dramatically faster deployment cycles. It also helps enforce consistency and, in some cases, security and compliance across environments (role-based access controls and built-in monitoring capabilities, for example, can allow organizations to apply standards more uniformly).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Further, studies suggest that iPaaS solutions enable companies to unlock new revenue streams by integrating previously siloed data and processes. Forrester research found that organizations adopting iPaaS solutions stand to generate nearly $1 million in incremental profit over three years by creating new digital services, improving customer experiences, and automating revenue-generating processes that were previously manual.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Where iPaaS is headed: convergence and intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;All this momentum is perhaps one of the reasons why the global iPaaS market, valued at approximately $12.9 billion in 2024, is projected to reach more than $78 billion by 2032—with growth rates exceeding 25% annually.&lt;/p&gt;  &lt;p&gt;This trajectory is contingent on two ongoing trends: the convergence of integration capabilities into broader application development platforms, and the infusion of AI into the integration lifecycle.&lt;/p&gt;  &lt;p&gt;Today, the boundaries between iPaaS, automation platforms, and AI development environments are blurring as vendors create unified solutions that can handle everything from basic data synchronization to complex business processes.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;AI and machine learning capabilities are also being embedded directly into integration platforms. Soon, features like predictive maintenance of integration flow or intelligent routing of data based on current conditions are likely to become table stakes. Already, integration platforms are becoming smarter and more autonomous, capable of optimizing themselves and, in some cases, even initiating self-healing actions when problems arise.&lt;/p&gt;  &lt;p&gt;At the same time, this shift is transforming how businesses think about integration as a dynamic enabler of AI strategy. In the near future, robust integration frameworks will be essential to operationalize AI at scale and feed these systems the rich, contextual data they need to deliver meaningful insights.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building integration as competitive advantage&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to the retail modernization story detailed earlier, a few more real-world examples highlight the potential of iPaaS:&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;A chemicals manufacturer migrated 363 legacy interfaces to an iPaaS platform and now spins up new integrations 50% faster.&lt;/li&gt;    &lt;li&gt;A North American bottling company reduced integration runtime costs by more than 50% while supporting 12 legal entities on a single cloud ERP instance through common APIs.&lt;/li&gt;    &lt;li&gt;A global shipping-technology firm connected its CRM and third-party systems via cloud-based iPaaS solutions, enabling 100% touchless order fulfillment and a 95% cut in cost centers after a nine-month rollout in its first region.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Taken together, these examples make a compelling case for integration as strategy, not just infrastructure. They reflect a shift in mindset, where integration is democratized and embedded into how every team, not just IT, gets work done. Companies that treat integration as a core capability versus an IT afterthought are reaping tangible, enterprise-wide benefits, from faster go-to-market timelines and reduced operational costs to fully automated business processes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;As AI reshapes business processes and customer standards continue to climb, enterprises are realizing that integration architecture determines not only what they can build today, but how quickly they can adapt to whatever comes tomorrow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/07/1119383/producing-tangible-business-benefits-from-modern-ipaas-solutions/</guid><pubDate>Mon, 07 Jul 2025 14:01:39 +0000</pubDate></item><item><title>[NEW] How Capital One built production multi-agent AI workflows to power enterprise use cases (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/how-capital-one-built-production-multi-agent-ai-workflows-to-power-enterprise-use-cases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0364-X3_16d617.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;How do you balance risk management and safety with innovation in agentic systems — and how do you grapple with core considerations around data and model selection? In this VB Transform session, Milind Naphade, SVP, technology, of AI Foundations at Capital One, offered best practices and lessons learned from real-world experiments and applications for deploying and scaling an agentic workflow.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Capital One, committed to staying at the forefront of emerging technologies, recently launched a production-grade, state-of-the-art multi-agent AI system to enhance the car-buying experience. In this system, multiple AI agents work together to not only provide information to the car buyer, but to take specific actions based on the customer’s preferences and needs. For example, one agent communicates with the customer. Another creates an action plan based on business rules and the tools it is allowed to use. A third agent evaluates the accuracy of the first two, and a fourth agent explains and validates the action plan with the user. With over 100 million customers using a wide range of other potential Capital One use case applications, the agentic system is built for scale and complexity.&lt;/p&gt;



&lt;p&gt;“When we think of improving the customer experience, delighting the customer, we think of, what are the ways in which that can happen?” Naphade said. “Whether you’re opening an account or you want to know your balance or you’re trying to make a reservation to test a vehicle, there are a bunch of things that customers want to do. At the heart of this, very simply, how do you understand what the customer wants? How do you understand the fulfillment mechanisms at your disposal? How do you bring all the rigors of a regulated entity like Capital One, all the policies, all the business rules, all the constraints, regulatory and otherwise?”&lt;/p&gt;



&lt;p&gt;Agentic AI was clearly the next step, he said, for internal as well as customer-facing use cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-designing-an-agentic-workflow"&gt;&lt;strong&gt;Designing an agentic workflow&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Financial institutions have particularly stringent requirements when designing any workflow that supports customer journeys. And Capital One’s applications include a number of complex processes as customers raise issues and queries leveraging conversational tools. These two factors made the design process especially complex, requiring a holistic view of the entire journey — including how both customers and human agents respond, react, and reason at every step.&lt;/p&gt;



&lt;p&gt;“When we looked at how humans do reasoning, we were struck by a few salient facts,” Naphade said. “We saw that if we designed it using multiple logical agents, we would be able to mimic human reasoning quite well. But then you ask yourself, what exactly do the different agents do? Why do you have four? Why not three? Why not 20?”&lt;/p&gt;



&lt;p&gt;They studied customer experiences in the historic data: where those conversations go right, where they go wrong, how long they should take and other salient facts. They learned that it often takes multiple turns of conversation with an agent to understand what the customer wants, and any agentic workflow needs to plan for that, but also be completely grounded in an organization’s systems, available tools, APIs, and organizational policy guardrails.&lt;/p&gt;



&lt;p&gt;“The main breakthrough for us was realizing that this had to be dynamic and iterative,” Naphade said. “If you look at how a lot of people are using LLMs, they’re slapping the LLMs as a front end to the same mechanism that used to exist. They’re just using LLMs for classification of intent. But we realized from the beginning that that was not scalable.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-taking-cues-from-existing-workflows"&gt;&lt;strong&gt;Taking cues from existing workflows&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Based on their intuition of how human agents reason while responding to customers, researchers at Capital One developed&amp;nbsp; a framework in which&amp;nbsp; a team of expert AI agents, each with different expertise, come together and solve a problem.&lt;/p&gt;



&lt;p&gt;Additionally, Capital One incorporated robust risk frameworks into the development of the agentic system. As a regulated institution, Naphade noted that in addition to its range of internal risk mitigation protocols and frameworks,”Within Capital One, to manage risk, other entities that are independent observe you, evaluate you, question you, audit you,” Naphade said. “We thought that was a good idea for us, to have an AI agent whose entire job was to evaluate what the first two agents do based on Capital One policies and rules.”&lt;/p&gt;



&lt;p&gt;The evaluator determines whether the earlier agents were successful, and if not, rejects the plan and requests the planning agent to correct its results based on its judgement of where the problem was. This happens in an iterative process until the appropriate plan is reached. It’s also proven to be a huge boon to the company’s agentic AI approach.&lt;/p&gt;



&lt;p&gt;“The evaluator agent is … where we bring a world model. That’s where we simulate what happens if a series of actions were to be actually executed. That kind of rigor, which we need because we are a regulated enterprise – I think that’s actually putting us on a great sustainable and robust trajectory. I expect a lot of enterprises will eventually go to that point.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-technical-challenges-of-agentic-ai"&gt;&lt;strong&gt;The technical challenges of agentic AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Agentic systems need to work with fulfillment systems across the organization, all with a variety of permissions. Invoking tools and APIs within a variety of contexts while maintaining high accuracy was also challenging — from disambiguating user intent to generating and executing a reliable plan.&lt;/p&gt;



&lt;p&gt;“We have multiple iterations of experimentation, testing, evaluation, human-in-the-loop, all the right guardrails that need to happen before we can actually come into the market with something like this,” Naphade said. “But one of the biggest challenges was we didn’t have any precedent. We couldn’t go and say, oh, somebody else did it this way. How did that work out? There was that element of novelty. We were doing it for the first time.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-model-selection-and-partnering-with-nvidia"&gt;&lt;strong&gt;Model selection and partnering with NVIDIA&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;In terms of models, Capital One is keenly tracking academic and industry research, presenting at conferences and staying abreast of what’s state of the art. In the present use case, they used open-weights models, rather than closed, because that allowed them significant customization. That’s critical to them, Naphade asserts, because competitive advantage in AI strategy relies on proprietary data.&lt;/p&gt;



&lt;p&gt;In the technology stack itself, they use a combination of tools, including in-house technology, open-source tool chains, and NVIDIA inference stack. Working closely with NVIDIA has helped Capital One get the performance they need, and collaborate on industry-specific&amp;nbsp; opportunities in NVIDIA’s library, and prioritize features for the Triton server and their TensoRT LLM.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-agentic-ai-looking-ahead"&gt;&lt;strong&gt;Agentic AI: Looking ahead&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Capital One continues to deploy, scale, and refine AI agents across their business. Their first multi-agentic workflow was Chat Concierge, deployed through the company’s auto business. It was designed to support both auto dealers and customers with the car-buying process.&amp;nbsp; And with rich customer data, dealers are identifying serious leads, which has improved their customer engagement metrics significantly — up to 55% in some cases.&lt;/p&gt;



&lt;p&gt;“They’re able to generate much better serious leads through this natural, easier, 24/7 agent working for them,” Naphade said. “We’d like to bring this capability to [more] of our customer-facing engagements. But we want to do it in a well-managed way. It’s a journey.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0364-X3_16d617.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;How do you balance risk management and safety with innovation in agentic systems — and how do you grapple with core considerations around data and model selection? In this VB Transform session, Milind Naphade, SVP, technology, of AI Foundations at Capital One, offered best practices and lessons learned from real-world experiments and applications for deploying and scaling an agentic workflow.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Capital One, committed to staying at the forefront of emerging technologies, recently launched a production-grade, state-of-the-art multi-agent AI system to enhance the car-buying experience. In this system, multiple AI agents work together to not only provide information to the car buyer, but to take specific actions based on the customer’s preferences and needs. For example, one agent communicates with the customer. Another creates an action plan based on business rules and the tools it is allowed to use. A third agent evaluates the accuracy of the first two, and a fourth agent explains and validates the action plan with the user. With over 100 million customers using a wide range of other potential Capital One use case applications, the agentic system is built for scale and complexity.&lt;/p&gt;



&lt;p&gt;“When we think of improving the customer experience, delighting the customer, we think of, what are the ways in which that can happen?” Naphade said. “Whether you’re opening an account or you want to know your balance or you’re trying to make a reservation to test a vehicle, there are a bunch of things that customers want to do. At the heart of this, very simply, how do you understand what the customer wants? How do you understand the fulfillment mechanisms at your disposal? How do you bring all the rigors of a regulated entity like Capital One, all the policies, all the business rules, all the constraints, regulatory and otherwise?”&lt;/p&gt;



&lt;p&gt;Agentic AI was clearly the next step, he said, for internal as well as customer-facing use cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-designing-an-agentic-workflow"&gt;&lt;strong&gt;Designing an agentic workflow&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Financial institutions have particularly stringent requirements when designing any workflow that supports customer journeys. And Capital One’s applications include a number of complex processes as customers raise issues and queries leveraging conversational tools. These two factors made the design process especially complex, requiring a holistic view of the entire journey — including how both customers and human agents respond, react, and reason at every step.&lt;/p&gt;



&lt;p&gt;“When we looked at how humans do reasoning, we were struck by a few salient facts,” Naphade said. “We saw that if we designed it using multiple logical agents, we would be able to mimic human reasoning quite well. But then you ask yourself, what exactly do the different agents do? Why do you have four? Why not three? Why not 20?”&lt;/p&gt;



&lt;p&gt;They studied customer experiences in the historic data: where those conversations go right, where they go wrong, how long they should take and other salient facts. They learned that it often takes multiple turns of conversation with an agent to understand what the customer wants, and any agentic workflow needs to plan for that, but also be completely grounded in an organization’s systems, available tools, APIs, and organizational policy guardrails.&lt;/p&gt;



&lt;p&gt;“The main breakthrough for us was realizing that this had to be dynamic and iterative,” Naphade said. “If you look at how a lot of people are using LLMs, they’re slapping the LLMs as a front end to the same mechanism that used to exist. They’re just using LLMs for classification of intent. But we realized from the beginning that that was not scalable.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-taking-cues-from-existing-workflows"&gt;&lt;strong&gt;Taking cues from existing workflows&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Based on their intuition of how human agents reason while responding to customers, researchers at Capital One developed&amp;nbsp; a framework in which&amp;nbsp; a team of expert AI agents, each with different expertise, come together and solve a problem.&lt;/p&gt;



&lt;p&gt;Additionally, Capital One incorporated robust risk frameworks into the development of the agentic system. As a regulated institution, Naphade noted that in addition to its range of internal risk mitigation protocols and frameworks,”Within Capital One, to manage risk, other entities that are independent observe you, evaluate you, question you, audit you,” Naphade said. “We thought that was a good idea for us, to have an AI agent whose entire job was to evaluate what the first two agents do based on Capital One policies and rules.”&lt;/p&gt;



&lt;p&gt;The evaluator determines whether the earlier agents were successful, and if not, rejects the plan and requests the planning agent to correct its results based on its judgement of where the problem was. This happens in an iterative process until the appropriate plan is reached. It’s also proven to be a huge boon to the company’s agentic AI approach.&lt;/p&gt;



&lt;p&gt;“The evaluator agent is … where we bring a world model. That’s where we simulate what happens if a series of actions were to be actually executed. That kind of rigor, which we need because we are a regulated enterprise – I think that’s actually putting us on a great sustainable and robust trajectory. I expect a lot of enterprises will eventually go to that point.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-technical-challenges-of-agentic-ai"&gt;&lt;strong&gt;The technical challenges of agentic AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Agentic systems need to work with fulfillment systems across the organization, all with a variety of permissions. Invoking tools and APIs within a variety of contexts while maintaining high accuracy was also challenging — from disambiguating user intent to generating and executing a reliable plan.&lt;/p&gt;



&lt;p&gt;“We have multiple iterations of experimentation, testing, evaluation, human-in-the-loop, all the right guardrails that need to happen before we can actually come into the market with something like this,” Naphade said. “But one of the biggest challenges was we didn’t have any precedent. We couldn’t go and say, oh, somebody else did it this way. How did that work out? There was that element of novelty. We were doing it for the first time.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-model-selection-and-partnering-with-nvidia"&gt;&lt;strong&gt;Model selection and partnering with NVIDIA&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;In terms of models, Capital One is keenly tracking academic and industry research, presenting at conferences and staying abreast of what’s state of the art. In the present use case, they used open-weights models, rather than closed, because that allowed them significant customization. That’s critical to them, Naphade asserts, because competitive advantage in AI strategy relies on proprietary data.&lt;/p&gt;



&lt;p&gt;In the technology stack itself, they use a combination of tools, including in-house technology, open-source tool chains, and NVIDIA inference stack. Working closely with NVIDIA has helped Capital One get the performance they need, and collaborate on industry-specific&amp;nbsp; opportunities in NVIDIA’s library, and prioritize features for the Triton server and their TensoRT LLM.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-agentic-ai-looking-ahead"&gt;&lt;strong&gt;Agentic AI: Looking ahead&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Capital One continues to deploy, scale, and refine AI agents across their business. Their first multi-agentic workflow was Chat Concierge, deployed through the company’s auto business. It was designed to support both auto dealers and customers with the car-buying process.&amp;nbsp; And with rich customer data, dealers are identifying serious leads, which has improved their customer engagement metrics significantly — up to 55% in some cases.&lt;/p&gt;



&lt;p&gt;“They’re able to generate much better serious leads through this natural, easier, 24/7 agent working for them,” Naphade said. “We’d like to bring this capability to [more] of our customer-facing engagements. But we want to do it in a well-managed way. It’s a journey.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-capital-one-built-production-multi-agent-ai-workflows-to-power-enterprise-use-cases/</guid><pubDate>Mon, 07 Jul 2025 14:50:00 +0000</pubDate></item><item><title>[NEW] Tencent Hunyuan3D-PolyGen: A model for ‘art-grade’ 3D assets (AI News)</title><link>https://www.artificialintelligence-news.com/news/tencent-hunyuan3d-polygen-a-model-for-art-grade-3d-assets/</link><description>&lt;p&gt;Tencent has released a model that could be quite literally game-changing for how developers create 3D assets.&lt;/p&gt;&lt;p&gt;The new Hunyuan3D-PolyGen model is Tencent’s first attempt at delivering what they’re calling “art-grade” 3D generation, specifically built for the professionals who craft the digital worlds we play in.&lt;/p&gt;&lt;p&gt;Creating high-quality 3D assets has always been a bottleneck for game developers, with artists spending countless hours perfecting wireframes and wrestling with complex geometry. Tencent reckons they’ve found a way to tackle these headaches head-on, potentially transforming how studios approach asset creation entirely.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-levelling-up-generating-3d-assets"&gt;&lt;strong&gt;Levelling up generating 3D assets&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;The secret sauce behind Hunyuan3D-PolyGen lies in what Tencent calls BPT technology. In layman’s terms, it means they’ve figured out how to compress massive amounts of 3D data without losing the detail that matters. In practice, that means it’s possible to generate 3D assets with tens of thousands of polygons that actually look professional enough to ship in a commercial game.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🚀Introducing Hunyuan3D-PolyGen, our newly upgraded and industry-first art-grade 3D generative model. It brings effortless intelligent retopology, making AI-generated models ready for professional art pipelines.&lt;/p&gt;&lt;p&gt;✅ Superior Mesh Topology: Our self-developed mesh autoregressive… pic.twitter.com/Lwy0dfGZkx&lt;/p&gt;— Hunyuan (@TencentHunyuan) July 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;What’s particularly clever is how the system handles both triangular and quadrilateral faces. If you’ve ever tried to move 3D assets between different software packages, you’ll know why this matters. Different engines and tools have their preferences, and compatibility issues have historically been a nightmare for studios trying to streamline their workflows.&lt;/p&gt;&lt;p&gt;According to technical documentation, the system utilises an autoregressive mesh generation framework that performs spatial inference through explicit and discrete vertex and patch modelling. This approach ensures the production of high-quality 3D models that meet stringent artistic specifications demanded by commercial game development.&lt;/p&gt;&lt;p&gt;Hunyuan3D-PolyGen works through what’s essentially a three-step dance. First, it takes existing 3D meshes and converts them into a language the AI can understand.&lt;/p&gt;&lt;p&gt;Using point cloud data as a starting point, the system then generates new mesh instructions using techniques borrowed from natural language processing. It’s like teaching the AI to speak in 3D geometry, predicting what should come next based on what it’s already created.&lt;/p&gt;&lt;p&gt;Finally, the system translates these instructions back into actual 3D meshes, complete with all the vertices and faces that make up the final model. The whole process maintains geometric integrity while producing results that would make any technical artist nod in approval.&lt;/p&gt;&lt;p&gt;Tencent isn’t just talking about theoretical improvements that fall apart when tested in real studios; they’ve put this technology to work in their own game development studios. The results? Artists claim to report efficiency gains of over 70 percent.&lt;/p&gt;&lt;p&gt;The system has been baked into Tencent’s Hunyuan 3D AI creation engine and is already running across multiple game development pipelines. This means it’s being used to create actual 3D game assets that players will eventually interact with.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-teaching-ai-to-think-like-an-artist"&gt;&lt;strong&gt;Teaching AI to think like an artist&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;One of the most impressive aspects of Hunyuan3D-PolyGen is how Tencent has approached quality control. They’ve developed a reinforcement learning system that essentially teaches the AI to recognise good work from bad work, much like how a mentor might guide a junior artist.&lt;/p&gt;&lt;p&gt;The system learns from feedback, gradually improving its ability to generate 3D assets that meet professional standards. This means fewer duds and more usable results straight out of the box. For studios already stretched thin on resources, this kind of reliability could be transformative.&lt;/p&gt;&lt;p&gt;The gaming industry has been grappling with a fundamental problem for years. While AI has made impressive strides in generating 3D models, most of the output has been, quite frankly, not good enough for commercial use. The gap between “looks impressive in a demo” and “ready for a AAA game” has been enormous.&lt;/p&gt;&lt;p&gt;Tencent’s approach with Hunyuan3D-PolyGen feels different because it’s clearly been designed by people who understand what actual game development looks like. Instead of chasing flashy demonstrations, they’ve focused on solving real workflow problems that have been frustrating developers for decades.&lt;/p&gt;&lt;p&gt;As development costs continue to spiral and timelines get ever more compressed, tools that can accelerate asset creation without compromising quality become incredibly valuable.&lt;/p&gt;&lt;p&gt;The release of Hunyuan3D-PolyGen hints at a future where the relationship between human creativity and AI assistance becomes far more nuanced. Rather than replacing artists, this technology appears designed to handle the grunt work of creating 3D assets, freeing up talented creators to focus on the conceptual and creative challenges that humans excel at.&lt;/p&gt;&lt;p&gt;This represents a mature approach to AI integration in creative industries. Instead of the usual “AI will replace everyone” narrative, we’re seeing tools that augment human capabilities rather than attempt to replicate them entirely. The 70 percent efficiency improvement reported by Tencent’s teams suggests this philosophy is working in practice.&lt;/p&gt;&lt;p&gt;The broader implications are fascinating to consider. As these systems become more sophisticated and reliable, we might see a fundamental shift in how game development studios are structured and how projects are scoped. The technology could democratise high-quality asset creation, potentially allowing smaller studios to compete with larger operations that traditionally had resource advantages.&lt;/p&gt;&lt;p&gt;The success of Hunyuan3D-PolyGen could well encourage other major players to accelerate their own AI-assisted creative tools beyond generating 3D assets, potentially leading to a new wave of productivity improvements across the industry. For game developers who’ve been watching AI developments with a mixture of excitement and scepticism, this might be the moment when the technology finally delivers on its promises.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;UK and Singapore form alliance to guide AI in finance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Tencent has released a model that could be quite literally game-changing for how developers create 3D assets.&lt;/p&gt;&lt;p&gt;The new Hunyuan3D-PolyGen model is Tencent’s first attempt at delivering what they’re calling “art-grade” 3D generation, specifically built for the professionals who craft the digital worlds we play in.&lt;/p&gt;&lt;p&gt;Creating high-quality 3D assets has always been a bottleneck for game developers, with artists spending countless hours perfecting wireframes and wrestling with complex geometry. Tencent reckons they’ve found a way to tackle these headaches head-on, potentially transforming how studios approach asset creation entirely.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-levelling-up-generating-3d-assets"&gt;&lt;strong&gt;Levelling up generating 3D assets&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;The secret sauce behind Hunyuan3D-PolyGen lies in what Tencent calls BPT technology. In layman’s terms, it means they’ve figured out how to compress massive amounts of 3D data without losing the detail that matters. In practice, that means it’s possible to generate 3D assets with tens of thousands of polygons that actually look professional enough to ship in a commercial game.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🚀Introducing Hunyuan3D-PolyGen, our newly upgraded and industry-first art-grade 3D generative model. It brings effortless intelligent retopology, making AI-generated models ready for professional art pipelines.&lt;/p&gt;&lt;p&gt;✅ Superior Mesh Topology: Our self-developed mesh autoregressive… pic.twitter.com/Lwy0dfGZkx&lt;/p&gt;— Hunyuan (@TencentHunyuan) July 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;What’s particularly clever is how the system handles both triangular and quadrilateral faces. If you’ve ever tried to move 3D assets between different software packages, you’ll know why this matters. Different engines and tools have their preferences, and compatibility issues have historically been a nightmare for studios trying to streamline their workflows.&lt;/p&gt;&lt;p&gt;According to technical documentation, the system utilises an autoregressive mesh generation framework that performs spatial inference through explicit and discrete vertex and patch modelling. This approach ensures the production of high-quality 3D models that meet stringent artistic specifications demanded by commercial game development.&lt;/p&gt;&lt;p&gt;Hunyuan3D-PolyGen works through what’s essentially a three-step dance. First, it takes existing 3D meshes and converts them into a language the AI can understand.&lt;/p&gt;&lt;p&gt;Using point cloud data as a starting point, the system then generates new mesh instructions using techniques borrowed from natural language processing. It’s like teaching the AI to speak in 3D geometry, predicting what should come next based on what it’s already created.&lt;/p&gt;&lt;p&gt;Finally, the system translates these instructions back into actual 3D meshes, complete with all the vertices and faces that make up the final model. The whole process maintains geometric integrity while producing results that would make any technical artist nod in approval.&lt;/p&gt;&lt;p&gt;Tencent isn’t just talking about theoretical improvements that fall apart when tested in real studios; they’ve put this technology to work in their own game development studios. The results? Artists claim to report efficiency gains of over 70 percent.&lt;/p&gt;&lt;p&gt;The system has been baked into Tencent’s Hunyuan 3D AI creation engine and is already running across multiple game development pipelines. This means it’s being used to create actual 3D game assets that players will eventually interact with.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-teaching-ai-to-think-like-an-artist"&gt;&lt;strong&gt;Teaching AI to think like an artist&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;One of the most impressive aspects of Hunyuan3D-PolyGen is how Tencent has approached quality control. They’ve developed a reinforcement learning system that essentially teaches the AI to recognise good work from bad work, much like how a mentor might guide a junior artist.&lt;/p&gt;&lt;p&gt;The system learns from feedback, gradually improving its ability to generate 3D assets that meet professional standards. This means fewer duds and more usable results straight out of the box. For studios already stretched thin on resources, this kind of reliability could be transformative.&lt;/p&gt;&lt;p&gt;The gaming industry has been grappling with a fundamental problem for years. While AI has made impressive strides in generating 3D models, most of the output has been, quite frankly, not good enough for commercial use. The gap between “looks impressive in a demo” and “ready for a AAA game” has been enormous.&lt;/p&gt;&lt;p&gt;Tencent’s approach with Hunyuan3D-PolyGen feels different because it’s clearly been designed by people who understand what actual game development looks like. Instead of chasing flashy demonstrations, they’ve focused on solving real workflow problems that have been frustrating developers for decades.&lt;/p&gt;&lt;p&gt;As development costs continue to spiral and timelines get ever more compressed, tools that can accelerate asset creation without compromising quality become incredibly valuable.&lt;/p&gt;&lt;p&gt;The release of Hunyuan3D-PolyGen hints at a future where the relationship between human creativity and AI assistance becomes far more nuanced. Rather than replacing artists, this technology appears designed to handle the grunt work of creating 3D assets, freeing up talented creators to focus on the conceptual and creative challenges that humans excel at.&lt;/p&gt;&lt;p&gt;This represents a mature approach to AI integration in creative industries. Instead of the usual “AI will replace everyone” narrative, we’re seeing tools that augment human capabilities rather than attempt to replicate them entirely. The 70 percent efficiency improvement reported by Tencent’s teams suggests this philosophy is working in practice.&lt;/p&gt;&lt;p&gt;The broader implications are fascinating to consider. As these systems become more sophisticated and reliable, we might see a fundamental shift in how game development studios are structured and how projects are scoped. The technology could democratise high-quality asset creation, potentially allowing smaller studios to compete with larger operations that traditionally had resource advantages.&lt;/p&gt;&lt;p&gt;The success of Hunyuan3D-PolyGen could well encourage other major players to accelerate their own AI-assisted creative tools beyond generating 3D assets, potentially leading to a new wave of productivity improvements across the industry. For game developers who’ve been watching AI developments with a mixture of excitement and scepticism, this might be the moment when the technology finally delivers on its promises.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;UK and Singapore form alliance to guide AI in finance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/tencent-hunyuan3d-polygen-a-model-for-art-grade-3d-assets/</guid><pubDate>Mon, 07 Jul 2025 14:55:38 +0000</pubDate></item><item><title>[NEW] AI is forcing the data industry to consolidate — but that’s not the whole story (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/07/ai-is-forcing-the-data-industry-to-consolidate-but-thats-not-the-whole-story/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/10/gift-guide-puzzle.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The data industry is on the verge of a drastic transformation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The market is consolidating. And if the deal flow in the past two months is any indicator — with Databricks buying Neon for $1 billion and Salesforce snapping up cloud management firm Informatica for $8 billion — momentum is building for more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The acquired companies may range in size, age, and focus area within the data stack, but they all have one thing in common. These companies are being bought in hopes the acquired technology will be the missing piece needed to get enterprises to adopt AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the surface level, this strategy makes sense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The success of AI companies, and AI applications, is determined by access to quality underlying data. Without it, there simply isn’t value — a belief shared by enterprise VCs. In a TechCrunch survey conducted in December 2024, enterprise VCs said data quality was a key factor to make AI startups stand out and succeed. And while some of these companies involved in these deals aren’t startups, the sentiment still stands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gaurav Dhillon — the co-founder and former CEO of Informatica and current chairman and CEO at data integration company SnapLogic — echoed this in a recent interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There is a complete reset in how data is managed and flows around the enterprise,” Dhillon said. “If people want to seize the AI imperative, they have to redo their data platforms in a very big way. And this is where I believe you’re seeing all these data acquisitions, because this is the foundation to have a sound AI strategy.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But is this strategy of snapping up companies built before a post-ChatGPT world the way to increase enterprise AI adoption in today’s rapidly innovating market? That’s unclear. Dhillon has doubts too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody was born in AI; that’s only three years old,” Dhillon said, referring to the current post-ChatGPT AI market. “For a larger company, to provide AI innovations to re-imagine the enterprise, the agentic enterprise in particular, it’s going to need a lot of retooling to make it happen.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-fragmented-data-landscape"&gt;Fragmented data landscape&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The data industry has grown into a sprawling and fragmented web over the past decade —&amp;nbsp;which makes it ripe for consolidation. All it needed was a catalyst. From 2020 through 2024 alone, more than $300 billion was invested into data startups across more than 24,000 deals, according to PitchBook data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The data industry wasn’t immune to the trends seen in other industries like SaaS where the venture swell of the last decade resulted in numerous startups getting funded by venture capitalists that only targeted one specific area or were in some cases built around a single feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The current industry standard of bundling together a bunch of different data management solutions, each with its own specific focus, doesn’t work when you want AI to crawl around your data to find answers or build applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It makes sense that larger companies are looking to snap up startups that can plug into and fill existing gaps in their data stack. A perfect example of this trend is Fivetran’s recent acquisition of Census in May —&amp;nbsp;which yes, was done in the name of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fivetran helps companies move their data from a variety of sources into cloud databases. For the first 13 years of its business, it didn’t allow customers to move this data back out of said databases, which is exactly what Census offers. This means prior to this acquisition, Fivetran customers needed to work with a second company to create an end-to-end solution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, this isn’t meant to cast shade on Fivetran. At the time of the deal, George Fraser, the co-founder and CEO of Fivetran, told TechCrunch that while moving data in and out of these warehouses seems like two sides of the same coin, it’s not that simple; the company even tried and abandoned an in-house solution to this problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Technically speaking, if you look at the code underneath [these] services, they’re actually pretty different,” Fraser said at the time. “You have to solve a pretty different set of problems in order to do this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This situation helps illustrate how the data market has transformed in the last decade. For Sanjeev Mohan, a former Gartner analyst who now runs SanjMo, his own data trend advisory firm, these types of scenarios are a big driver of the current wave of consolidation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This consolidation is being driven by customers being fed up with a multitude of products that are incompatible,” Mohan said. “We live in a very interesting world where there are a lot of different data storage solutions, you can do open source, they can go to Kafka, but the one area where we have failed is metadata. Dozens of these products are capturing some metadata but to do their job, it’s an overlap.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-good-for-startups"&gt;Good for startups&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The broader market plays a role here, too, Mohan said. Data startups are struggling to raise capital, Mohan said, and an exit is better than having to wind down or load up on debt. For the acquirers, adding features gives them better pricing leverage and an edge against their peers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If Salesforce or Google isn’t acquiring these companies, then their competitors likely are,” Derek Hernandez, a senior emerging tech analyst at PitchBook, told TechCrunch. “The best solutions are being acquired currently. Even if you have an award-winning solution, I don’t know that the outlook for staying private ultimately wins over going to a larger [acquirer].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This trend brings big benefits to the startups getting acquired. The venture market is starving for exits and the current quiet period for IPOs doesn’t leave them a lot of opportunities. Getting acquired not only provides that exit, but in many cases it also gives these founding teams room to keep building.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mohan agreed and added that many data startups are feeling the pains of the current market regarding exits and the slow recovery of venture funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At this point in time, acquisition has been a much more favorable exit strategy for them,” Hernandez said. “So I think, kind of both sides are very incentivized to get to the finish line on these. And I think Informatica is a good example of that, where even with a bit of a haircut from where Salesforce was talking to them last year, it’s still, you know, was the best solution, according to their board.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-happens-next"&gt;What happens next&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;But the doubt still remains if this acquisition strategy will achieve the buyers’ goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Dhillon pointed out, the database companies being acquired weren’t necessarily built to easily work with the rapidly changing AI market. Plus, if the company with the best data wins the AI world, will it make sense for data and AI companies to be separate entities?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think a lot of the value is in merging the major AI players with the data management companies,” Hernandez said. “I don’t know that a stand-alone data management company is particularly incentivized to remain so and, kind of like, play a third party between enterprises and AI solutions.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/10/gift-guide-puzzle.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The data industry is on the verge of a drastic transformation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The market is consolidating. And if the deal flow in the past two months is any indicator — with Databricks buying Neon for $1 billion and Salesforce snapping up cloud management firm Informatica for $8 billion — momentum is building for more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The acquired companies may range in size, age, and focus area within the data stack, but they all have one thing in common. These companies are being bought in hopes the acquired technology will be the missing piece needed to get enterprises to adopt AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the surface level, this strategy makes sense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The success of AI companies, and AI applications, is determined by access to quality underlying data. Without it, there simply isn’t value — a belief shared by enterprise VCs. In a TechCrunch survey conducted in December 2024, enterprise VCs said data quality was a key factor to make AI startups stand out and succeed. And while some of these companies involved in these deals aren’t startups, the sentiment still stands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gaurav Dhillon — the co-founder and former CEO of Informatica and current chairman and CEO at data integration company SnapLogic — echoed this in a recent interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There is a complete reset in how data is managed and flows around the enterprise,” Dhillon said. “If people want to seize the AI imperative, they have to redo their data platforms in a very big way. And this is where I believe you’re seeing all these data acquisitions, because this is the foundation to have a sound AI strategy.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But is this strategy of snapping up companies built before a post-ChatGPT world the way to increase enterprise AI adoption in today’s rapidly innovating market? That’s unclear. Dhillon has doubts too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody was born in AI; that’s only three years old,” Dhillon said, referring to the current post-ChatGPT AI market. “For a larger company, to provide AI innovations to re-imagine the enterprise, the agentic enterprise in particular, it’s going to need a lot of retooling to make it happen.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-fragmented-data-landscape"&gt;Fragmented data landscape&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The data industry has grown into a sprawling and fragmented web over the past decade —&amp;nbsp;which makes it ripe for consolidation. All it needed was a catalyst. From 2020 through 2024 alone, more than $300 billion was invested into data startups across more than 24,000 deals, according to PitchBook data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The data industry wasn’t immune to the trends seen in other industries like SaaS where the venture swell of the last decade resulted in numerous startups getting funded by venture capitalists that only targeted one specific area or were in some cases built around a single feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The current industry standard of bundling together a bunch of different data management solutions, each with its own specific focus, doesn’t work when you want AI to crawl around your data to find answers or build applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It makes sense that larger companies are looking to snap up startups that can plug into and fill existing gaps in their data stack. A perfect example of this trend is Fivetran’s recent acquisition of Census in May —&amp;nbsp;which yes, was done in the name of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fivetran helps companies move their data from a variety of sources into cloud databases. For the first 13 years of its business, it didn’t allow customers to move this data back out of said databases, which is exactly what Census offers. This means prior to this acquisition, Fivetran customers needed to work with a second company to create an end-to-end solution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, this isn’t meant to cast shade on Fivetran. At the time of the deal, George Fraser, the co-founder and CEO of Fivetran, told TechCrunch that while moving data in and out of these warehouses seems like two sides of the same coin, it’s not that simple; the company even tried and abandoned an in-house solution to this problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Technically speaking, if you look at the code underneath [these] services, they’re actually pretty different,” Fraser said at the time. “You have to solve a pretty different set of problems in order to do this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This situation helps illustrate how the data market has transformed in the last decade. For Sanjeev Mohan, a former Gartner analyst who now runs SanjMo, his own data trend advisory firm, these types of scenarios are a big driver of the current wave of consolidation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This consolidation is being driven by customers being fed up with a multitude of products that are incompatible,” Mohan said. “We live in a very interesting world where there are a lot of different data storage solutions, you can do open source, they can go to Kafka, but the one area where we have failed is metadata. Dozens of these products are capturing some metadata but to do their job, it’s an overlap.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-good-for-startups"&gt;Good for startups&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The broader market plays a role here, too, Mohan said. Data startups are struggling to raise capital, Mohan said, and an exit is better than having to wind down or load up on debt. For the acquirers, adding features gives them better pricing leverage and an edge against their peers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If Salesforce or Google isn’t acquiring these companies, then their competitors likely are,” Derek Hernandez, a senior emerging tech analyst at PitchBook, told TechCrunch. “The best solutions are being acquired currently. Even if you have an award-winning solution, I don’t know that the outlook for staying private ultimately wins over going to a larger [acquirer].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This trend brings big benefits to the startups getting acquired. The venture market is starving for exits and the current quiet period for IPOs doesn’t leave them a lot of opportunities. Getting acquired not only provides that exit, but in many cases it also gives these founding teams room to keep building.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mohan agreed and added that many data startups are feeling the pains of the current market regarding exits and the slow recovery of venture funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At this point in time, acquisition has been a much more favorable exit strategy for them,” Hernandez said. “So I think, kind of both sides are very incentivized to get to the finish line on these. And I think Informatica is a good example of that, where even with a bit of a haircut from where Salesforce was talking to them last year, it’s still, you know, was the best solution, according to their board.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-happens-next"&gt;What happens next&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;But the doubt still remains if this acquisition strategy will achieve the buyers’ goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Dhillon pointed out, the database companies being acquired weren’t necessarily built to easily work with the rapidly changing AI market. Plus, if the company with the best data wins the AI world, will it make sense for data and AI companies to be separate entities?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think a lot of the value is in merging the major AI players with the data management companies,” Hernandez said. “I don’t know that a stand-alone data management company is particularly incentivized to remain so and, kind of like, play a third party between enterprises and AI solutions.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/07/ai-is-forcing-the-data-industry-to-consolidate-but-thats-not-the-whole-story/</guid><pubDate>Mon, 07 Jul 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] AI Testing and Evaluation: Learnings from pharmaceuticals and medical devices (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Daniel Carpented, Timo Minssen, Chad Atalla, and Kathleen Sullivan." class="wp-image-1143327" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;, hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Daniel Carpenter, the Allie S. Freed Professor of Government and chair of the department of government at Harvard University, explains how the US Food and Drug Administration’s rigorous, multi-phase drug approval process serves as a gatekeeper that builds public trust and scientific credibility, while Timo Minssen, professor of law and founding director of the Center for Advanced Studies in Bioscience Innovation Law at the University of Copenhagen, explores the evolving regulatory landscape of medical devices with a focus on the challenges of balancing innovation with public safety. Later, Microsoft’s Chad Atalla, an applied scientist in responsible AI, discusses the sociotechnical nature of AI models and systems, their team’s work building an evaluation framework inspired by social science, and where AI researchers, developers, and policymakers might find inspiration from the approach to governance and testing in pharmaceuticals and medical devices.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h4" id="learn-more"&gt;Learn more:&lt;/h2&gt;



&lt;p&gt;Learning from other Domains to Advance AI Evaluation and Testing: The History and Evolution of Testing in Pharmaceutical Regulation&lt;br /&gt;Case study | January 2025&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Learning from other Domains to Advance AI Evaluation and Testing: Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance&lt;br /&gt;Case study | January 2025&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Learning from other domains to advance AI evaluation and testing&amp;nbsp;&lt;br /&gt;Microsoft Research Blog | June 2025  &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evaluating Generative AI Systems is a Social Science Measurement Challenge&amp;nbsp;&lt;br /&gt;Publication&amp;nbsp;|&amp;nbsp;November 2024 &amp;nbsp;&lt;/p&gt;



&lt;p&gt;STAC: Sociotechnical Alignment Center &lt;/p&gt;



&lt;p&gt;Responsible AI: Ethical policies and practices | Microsoft AI&lt;/p&gt;



&lt;p&gt;AI and Microsoft Research &lt;/p&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN&lt;/strong&gt;: Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN&lt;/strong&gt;: Today, I’m excited to welcome Dan Carpenter and Timo Minssen to the podcast to explore testing and risk assessment in the areas of pharmaceuticals and medical devices, respectively.&lt;/p&gt;



&lt;p&gt;Dan Carpenter is chair of the Department of Government at Harvard University. His research spans the sphere of social and political science, from petitioning in democratic society to regulation and government organizations. His recent work includes the FDA Project, which examines pharmaceutical regulation in the United States.&lt;/p&gt;



&lt;p&gt;Timo is a professor of law at the University of Copenhagen, where he is also director of the Center for Advanced Studies in Bioscience Innovation Law. He specializes in legal aspects of biomedical innovation, including intellectual property law and regulatory law. He’s exercised his expertise as an advisor to such organizations as the World Health Organization and the European Commission.&lt;/p&gt;



&lt;p&gt;And after our conversations, we’ll talk to Microsoft’s Chad Atalla, an applied scientist in responsible AI, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Daniel, it’s a pleasure to welcome you to the podcast. I’m just so appreciative of you being here. Thanks for joining us today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;DANIEL CARPENTER:&lt;/strong&gt;&amp;nbsp;Thanks for having me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Dan, before we dissect policy,&amp;nbsp;let’s&amp;nbsp;rewind the tape to your&amp;nbsp;origin&amp;nbsp;story. Can you take us to the moment that you first became fascinated with regulators rather than, say, politicians? Was there a spark that pulled you toward the FDA story?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;At one point during graduate school, I was studying a combination of American politics and political theory, and I did a summer interning at the Department of Housing and Urban Development. And I began to think, why don’t people study these administrators more and the rules they make, the, you know,&amp;nbsp;inefficiencies, the efficiencies?&amp;nbsp;Really more&amp;nbsp;from,&amp;nbsp;kind of,&amp;nbsp;a descriptive standpoint, less from a normative standpoint.&amp;nbsp;And I was reading a lot that summer about the Food and Drug Administration and some of the decisions it was making on AIDS drugs. That was&amp;nbsp;a,&amp;nbsp;sort of,&amp;nbsp;a major, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt; … sort of, you know,&amp;nbsp;moment in the news, in the global news as well as the national news during, I would say, what?&amp;nbsp;The late&amp;nbsp;’80s, early&amp;nbsp;’90s? And&amp;nbsp;so&amp;nbsp;I began to&amp;nbsp;look&amp;nbsp;into&amp;nbsp;that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So now that we know what pulled you in,&amp;nbsp;let’s&amp;nbsp;zoom out for our listeners. Give us&amp;nbsp;the&amp;nbsp;whirlwind tour. I think most of us know pharma involves years of trials, but&amp;nbsp;what’s&amp;nbsp;the part we&amp;nbsp;don’t&amp;nbsp;know?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I think when most businesses develop a product, they all go through some phases of research and development and testing. And I think&amp;nbsp;what’s&amp;nbsp;different about the FDA is,&amp;nbsp;sort of,&amp;nbsp;two-&amp;nbsp;or three-fold.&lt;/p&gt;



&lt;p&gt;First, a lot of those tests are much more stringently specified and regulated by the government, and second, one of the reasons for that is that the FDA imposes not simply safety requirements upon drugs&amp;nbsp;in particular but&amp;nbsp;also efficacy requirements. The FDA wants you to prove not simply that&amp;nbsp;it’s&amp;nbsp;safe and non-toxic&amp;nbsp;but also that&amp;nbsp;it’s&amp;nbsp;effective.&amp;nbsp;And the final thing,&amp;nbsp;I think, that&amp;nbsp;makes the FDA different is that it stands as what I would call the&amp;nbsp;“veto player”&amp;nbsp;over R&amp;amp;D [research and development] to the marketplace.&amp;nbsp;The FDA&amp;nbsp;basically has,&amp;nbsp;sort of,&amp;nbsp;this control over entry&amp;nbsp;to&amp;nbsp;the marketplace.&lt;/p&gt;



&lt;p&gt;And&amp;nbsp;so&amp;nbsp;what that involves is usually first, a set of human trials where people who have no disease take it. And&amp;nbsp;you’re&amp;nbsp;only looking&amp;nbsp;for&amp;nbsp;toxicity generally. Then&amp;nbsp;there’s&amp;nbsp;a set of Phase 2 trials, where they look more at safety and a little bit at efficacy, and&amp;nbsp;you’re&amp;nbsp;now examining people who have the disease that the drug claims to treat. And&amp;nbsp;you’re&amp;nbsp;also basically comparing people who get the drug,&amp;nbsp;often&amp;nbsp;with those who do not.&lt;/p&gt;



&lt;p&gt;And then finally, Phase 3 involves a much more direct and large-scale attack, if you will, or assessment of efficacy, and&amp;nbsp;that’s&amp;nbsp;where you get the sort of large randomized clinical trials that are&amp;nbsp;very expensive&amp;nbsp;for pharmaceutical companies, biomedical companies to launch, to execute, to analyze. And those are often the sort of core evidence base for the decisions that the FDA makes about&amp;nbsp;whether or not&amp;nbsp;to approve a new drug for marketing in the United States.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Are there&amp;nbsp;differences in how that process has, you know, changed through other countries and&amp;nbsp;maybe just&amp;nbsp;how&amp;nbsp;that’s&amp;nbsp;evolved as&amp;nbsp;you’ve&amp;nbsp;seen it play out?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Yeah, for a long time, I would say that the United States had&amp;nbsp;probably the&amp;nbsp;most&amp;nbsp;stringent regime&amp;nbsp;of regulation for biopharmaceutical products until,&amp;nbsp;I would say,&amp;nbsp;about the 1990s and early 2000s. It used to be the case that a number of other countries, especially in Europe but around the world, basically waited for the FDA to mandate tests on a drug and only after the drug was approved in the United States would they deem it approvable and marketable in their own countries. And then after the formation of the European Union and the creation of the European Medicines Agency, gradually the European Medicines Agency began to get a bit more stringent.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, you know,&amp;nbsp;over the long run,&amp;nbsp;there’s&amp;nbsp;been a&amp;nbsp;lot of,&amp;nbsp;sort&amp;nbsp;of,&amp;nbsp;heterogeneity, a lot of variation over time and space, in the way that the FDA has approached these problems. And&amp;nbsp;I’d&amp;nbsp;say in the last 20 years, it’s begun to partially deregulate, namely,&amp;nbsp;you know,&amp;nbsp;trying to find all sorts of mechanisms or pathways for really innovative&amp;nbsp;drugs for deadly diseases without a lot of treatments to&amp;nbsp;basically get&amp;nbsp;through the process at lower cost.&amp;nbsp;For many people,&amp;nbsp;that has not been sufficient.&amp;nbsp;They’re&amp;nbsp;concerned about the cost of the system.&amp;nbsp;Of course, then the agency also gets criticized by those&amp;nbsp;who believe&amp;nbsp;it’s&amp;nbsp;too lax. It is&amp;nbsp;potentially letting&amp;nbsp;ineffective and unsafe therapies on the market.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;In your view, when does the structured model genuinely safeguard patients and where do you think it&amp;nbsp;maybe slows&amp;nbsp;or&amp;nbsp;limits&amp;nbsp;innovation?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I think&amp;nbsp;the worry&amp;nbsp;is that if you approach pharmaceutical approval as a world where only things can go wrong,&amp;nbsp;then&amp;nbsp;you’re&amp;nbsp;really at a risk of limiting innovation. And even if you end up letting a lot of things through, if by your regulations you end up basically slowing down the development process or making it very, very costly, then there’s just a whole bunch of drugs that either come to market too slowly or they come to market not at all because&amp;nbsp;they just aren’t worth the kind of cost-benefit or, sort of, profit analysis of the firm.&amp;nbsp;You know, so&amp;nbsp;that’s&amp;nbsp;been a concern.&amp;nbsp;And I think&amp;nbsp;it’s&amp;nbsp;been one of the reasons that the Food and Drug Administration as well as other world regulators have begun to&amp;nbsp;basically try&amp;nbsp;to smooth the process and accelerate the process at the margins.&lt;/p&gt;



&lt;p&gt;The other thing is that&amp;nbsp;they’ve&amp;nbsp;started to&amp;nbsp;basically make&amp;nbsp;approvals&amp;nbsp;on the basis of&amp;nbsp;what are called&amp;nbsp;&lt;em&gt;surrogate endpoints&lt;/em&gt;. So the idea is that a cancer drug, we really want to know whether that drug saves lives, but if we wait to see whose lives are saved or prolonged by that drug, we might miss the opportunity to make judgments on the basis of, well, are we detecting tumors in the bloodstream? Or can we measure the size of those tumors&amp;nbsp;in, say, a&amp;nbsp;solid cancer? And then the further question is, is the size of the tumor&amp;nbsp;basically a&amp;nbsp;really good&amp;nbsp;correlate&amp;nbsp;or predictor of whether people will die or&amp;nbsp;not, right?&amp;nbsp;Generally, the&amp;nbsp;FDA tends to be less stringent when&amp;nbsp;you’ve&amp;nbsp;got, you know, a remarkably innovative new&amp;nbsp;therapy&amp;nbsp;and the disease being treated is one that just&amp;nbsp;doesn’t&amp;nbsp;have a lot of available treatments,&amp;nbsp;right.&lt;/p&gt;



&lt;p&gt;The one thing that people often think about when&amp;nbsp;they’re&amp;nbsp;thinking about pharmaceutical regulation is they often contrast,&amp;nbsp;kind of,&amp;nbsp;speed versus safety …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&amp;nbsp;&lt;/strong&gt;… right. And&amp;nbsp;that’s&amp;nbsp;useful as a tradeoff,&amp;nbsp;but I often try to remind people that&amp;nbsp;it’s&amp;nbsp;not simply&amp;nbsp;about whether the drug gets out&amp;nbsp;there&amp;nbsp;and&amp;nbsp;it’s&amp;nbsp;unsafe. You know, you and I as patients and even doctors have&amp;nbsp;a hard time&amp;nbsp;knowing whether something works and whether it should be prescribed. And the evidence for knowing whether something works&amp;nbsp;isn’t&amp;nbsp;just, well,&amp;nbsp;you&amp;nbsp;know, Sally took&amp;nbsp;it&amp;nbsp;or Dan took it or Kathleen took it, and they&amp;nbsp;seem to get&amp;nbsp;better or they&amp;nbsp;didn’t&amp;nbsp;seem to get better.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The really rigorous evidence comes from randomized clinical trials.&amp;nbsp;And I think&amp;nbsp;it’s&amp;nbsp;fair to say that if you didn’t&amp;nbsp;have the FDA there as a veto player, you&amp;nbsp;wouldn’t&amp;nbsp;get as many randomized clinical&amp;nbsp;trials&amp;nbsp;and the evidence&amp;nbsp;probably&amp;nbsp;wouldn’t&amp;nbsp;be as rigorous for whether these things work. And as I like to put it,&amp;nbsp;basically there’s&amp;nbsp;a whole ecology of expectations and beliefs around the biopharmaceutical industry in the United States and globally,&amp;nbsp;and to some extent,&amp;nbsp;it’s&amp;nbsp;undergirded by&amp;nbsp;all of&amp;nbsp;these tests that happen.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&amp;nbsp;&lt;/strong&gt;And in part, that means&amp;nbsp;it’s&amp;nbsp;undergirded by regulation. Would there still be a market without regulation? Yes. But it would be a market in which people had far less information in and confidence about the drugs that are being taken. And&amp;nbsp;so&amp;nbsp;I think&amp;nbsp;it’s&amp;nbsp;important to recognize that kind of confidence-boosting potential of, kind of, a scientific regulation base.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Actually, if we could&amp;nbsp;double-click&amp;nbsp;on that for a minute, I’d love to hear your perspective on, &lt;em&gt;testing&amp;nbsp;has been completed;&amp;nbsp;there’s results&lt;/em&gt;.&amp;nbsp;Can you walk us through how those results actually shape the next steps and decisions of a particular drug and just,&amp;nbsp;like,&amp;nbsp;how regulators actually think about using that data to influence really what happens next with it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Right.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;important to understand that every drug is approved for&amp;nbsp;what’s called&amp;nbsp;an &lt;em&gt;indication&lt;/em&gt;. It can have a first primary&amp;nbsp;indication, which is the main disease that it treats, and then others can be added as more evidence is shown. But a drug is not something that just kind of exists out there in the ether.&amp;nbsp;It has to have the right form of administration.&amp;nbsp;Maybe it&amp;nbsp;should be injected.&amp;nbsp;Maybe it&amp;nbsp;should be &lt;em&gt;ingested&lt;/em&gt;.&amp;nbsp;Maybe it&amp;nbsp;should&amp;nbsp;be administered only at a clinic&amp;nbsp;because it needs to be&amp;nbsp;kind of administered&amp;nbsp;in just the right way. As doctors will tell you, dosage is everything, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And&amp;nbsp;so&amp;nbsp;one of the reasons that you want those trials is not simply a, you know, yes or no answer about whether the drug works,&amp;nbsp;right.&amp;nbsp;It’s&amp;nbsp;not simply if-then.&amp;nbsp;It’s&amp;nbsp;literally what&amp;nbsp;goes into what you might call the dose response curve.&amp;nbsp;You know, how much of this drug do we need to&amp;nbsp;basically, you know,&amp;nbsp;get the benefit? At what point does that fall off significantly that we can&amp;nbsp;basically say, we can stop there? All that evidence comes from&amp;nbsp;trials. And&amp;nbsp;that’s&amp;nbsp;the kind of evidence that is&amp;nbsp;required&amp;nbsp;on the basis of&amp;nbsp;regulation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because&amp;nbsp;it’s&amp;nbsp;not simply a drug&amp;nbsp;that’s&amp;nbsp;approved.&amp;nbsp;It’s&amp;nbsp;a drug and a&amp;nbsp;&lt;em&gt;frequency&lt;/em&gt;&amp;nbsp;of administration. It’s&amp;nbsp;a&amp;nbsp;&lt;em&gt;method&lt;/em&gt; of administration.&amp;nbsp;And&amp;nbsp;so&amp;nbsp;the drug&amp;nbsp;isn’t&amp;nbsp;just,&amp;nbsp;there’s&amp;nbsp;something to be taken off the shelf and popped into your mouth. I mean, sometimes&amp;nbsp;that’s&amp;nbsp;what happens, but even then,&amp;nbsp;we want to know what the dosage is,&amp;nbsp;right.&amp;nbsp;We want to know what to look for in terms of side effects, things like that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Going back to that point, I&amp;nbsp;mean,&amp;nbsp;it sounds like&amp;nbsp;we’re&amp;nbsp;making a lot of progress from a regulation perspective&amp;nbsp;in, you know, sort of speed and getting things approved but doing it in a&amp;nbsp;really balanced&amp;nbsp;way. I mean, any other kind of closing thoughts on the tradeoffs there or where&amp;nbsp;you’re&amp;nbsp;seeing that going?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;I think&amp;nbsp;you’re&amp;nbsp;going to see some move in the coming years—there’s&amp;nbsp;already been some of it—to say, do we always need a&amp;nbsp;really large&amp;nbsp;Phase 3 clinical trial? And to what degree do we need the, like, you&amp;nbsp;know,&amp;nbsp;all the i’s dotted and the t’s crossed or a really,&amp;nbsp;really large&amp;nbsp;sample size?&amp;nbsp;And&amp;nbsp;I’m&amp;nbsp;open to innovation there.&amp;nbsp;I’m&amp;nbsp;also open to the idea that we consider, again, things like accelerated approvals or pathways for looking at&amp;nbsp;different kinds&amp;nbsp;of surrogate endpoints.&amp;nbsp;I do think, once we do that, then we also have to have some degree of follow-up.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I know&amp;nbsp;we’re&amp;nbsp;getting&amp;nbsp;close to&amp;nbsp;out of time, but&amp;nbsp;maybe just&amp;nbsp;a quick rapid fire if&amp;nbsp;you’re&amp;nbsp;open to it. Biggest myth about clinical trials?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Well, some people tend to think that the FDA performs them.&amp;nbsp;You know,&amp;nbsp;it’s&amp;nbsp;companies that do it. And the only other thing I would say is the company that does a lot of the testing and even the innovating is not always the company that takes the drug to market, and it tells you something about how powerful regulation is in our system, in our world,&amp;nbsp;that you often need a company that has dealt with the FDA quite a bit and knows all the regulations and knows how to dot the i’s and cross the t’s in order to get a drug across the finish line.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;If you had a magic wand,&amp;nbsp;what’s&amp;nbsp;the one thing&amp;nbsp;you’d&amp;nbsp;change in regulation today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;I would like people to think a little bit less about just speed versus safety and,&amp;nbsp;again, more about this basic issue of confidence. I think&amp;nbsp;it’s&amp;nbsp;fundamental to everything that happens in markets but especially in biopharmaceuticals.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Such a great point.&amp;nbsp;This has been really fun.&amp;nbsp;Just thanks so much for being here today. We’re really excited to share your thoughts&amp;nbsp;out to&amp;nbsp;our listeners. Thanks.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Likewise.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Now&amp;nbsp;to&amp;nbsp;the world of medical devices,&amp;nbsp;I’m&amp;nbsp;joined by Professor Timo&amp;nbsp;Minssen. Professor Minssen, it’s&amp;nbsp;great to have you here. Thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TIMO&amp;nbsp;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yeah, thank you very much,&amp;nbsp;it’s&amp;nbsp;a pleasure.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Before getting into the regulatory world of medical devices, tell our audience a bit about your personal journey or your origin story, as&amp;nbsp;we’re&amp;nbsp;asking our guests. How did you land in regulation, and what’s kept you hooked in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I started out as a patent expert in the biomedical area, starting with my PhD thesis on patenting biologics in Europe and in the US.&amp;nbsp;So&amp;nbsp;during that time, I was mostly interested in patent and trade secret questions.&amp;nbsp;But at the same time, I also developed and taught courses in regulatory law and held talks on regulating advanced medical therapy medicinal products.&amp;nbsp;I&amp;nbsp;then&amp;nbsp;started to lead large research projects on legal challenges in a wide variety of health and life science innovation frontiers. I also started to focus increasingly on AI-enabled medical devices and software as a medical device, resulting in several academic articles in this area&amp;nbsp;and also&amp;nbsp;in the regulatory area and a book on the future of medical device regulation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah,&amp;nbsp;what’s&amp;nbsp;kept you hooked in&amp;nbsp;the space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;It’s&amp;nbsp;just incredibly exciting,&amp;nbsp;in particular right&amp;nbsp;now with everything that is going on, you know, in the software arena, in the marriage between AI and medical devices. And this is really challenging not only societies but also regulators and authorities in Europe and in the US.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah,&amp;nbsp;it’s&amp;nbsp;a super exciting time to be in this space. You know, we talked to Daniel a little earlier and, you know, I think&amp;nbsp;similar to&amp;nbsp;pharmaceuticals, people have a general sense of what we mean when we say medical devices, but most listeners may&amp;nbsp;picture&amp;nbsp;like a stethoscope or a hip implant. The word “medical device”&amp;nbsp;reaches&amp;nbsp;much wider. Can you give us a quick, kind of, range from perhaps&amp;nbsp;very simple&amp;nbsp;to even, I don’t know, sci-fi and then your 90-second tour of how risk assessment works and why a framework is essential?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Let me start out by saying that&amp;nbsp;the WHO [World Health Organization] estimates that today there are approximately 2 million different kinds of medical devices on the world market, and as of the FDA’s latest update that I’m aware of, the FDA has authorized more than 1,000 AI-, machine learning-enabled medical devices, and that number is rising rapidly.&lt;/p&gt;



&lt;p&gt;So in that context, I think it is important to understand that medical devices can be any instrument, apparatus, implement, machine, appliance, implant, reagent for in vitro use, software, material, or other similar or related articles that are&amp;nbsp;&lt;em&gt;intended&lt;/em&gt;&amp;nbsp;by the manufacturer to be used alone or in combination for a medical purpose. And the spectrum of what constitutes a medical device can&amp;nbsp;thus&amp;nbsp;range from very simple devices such as tongue depressors, contact lenses, and thermometers to more complex devices such as blood pressure monitors, insulin pumps, MRI machines, implantable pacemakers, and even software as a medical device or AI-enabled monitors or drug device combinations, as well.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;talking about regulation,&amp;nbsp;I think&amp;nbsp;it&amp;nbsp;is also&amp;nbsp;very important&amp;nbsp;to stress that medical devices are used in many diverse situations by&amp;nbsp;very different&amp;nbsp;stakeholders. And testing&amp;nbsp;has to&amp;nbsp;take this variety into consideration, and it is intrinsically tied to regulatory requirements across various&amp;nbsp;jurisdictions.&lt;/p&gt;



&lt;p&gt;During the pre-market phase, medical testing&amp;nbsp;establishes&amp;nbsp;baseline safety and effectiveness metrics through bench testing, performance standards, and clinical studies. And post-market testing ensures that real-world data informs ongoing compliance and safety improvements. So testing is indispensable in translating technological innovation into safe and effective medical devices. And while&amp;nbsp;particular details&amp;nbsp;of pre-market and post-market review procedures may slightly differ among countries, most developed&amp;nbsp;jurisdictions regulate medical devices similarly to the US or European models. &lt;/p&gt;



&lt;p&gt;So&amp;nbsp;most&amp;nbsp;jurisdictions&amp;nbsp;with medical device regulation classify devices based on their risk profile, intended use, indications for use, technological characteristics,&amp;nbsp;and the regulatory controls necessary to provide a reasonable assurance of safety and effectiveness.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So medical devices face a pretty prescriptive multi-level testing path before they hit the market. From your vantage point, what are some of the downsides of that system and when does it make the most sense?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;One primary drawback is, of course, the lengthy and expensive approval process. High-risk devices, for example, often undergo years of clinical trials,&amp;nbsp;which can cost millions of dollars, and this can create a significant barrier for startups and small companies with limited resources.&amp;nbsp;And even for moderate-risk devices, the regulatory burden can slow product development and time to the market.&lt;/p&gt;



&lt;p&gt;And the approach can also limit flexibility. Prescriptive requirements may not accommodate emerging innovations like digital therapeutics or AI-based diagnostics in&amp;nbsp;a feasible&amp;nbsp;way. And in such cases, the framework can unintentionally [stiffen]&amp;nbsp;innovation by discouraging creative solutions or iterative improvements, which as matter of fact can also&amp;nbsp;&lt;em&gt;put&lt;/em&gt;&amp;nbsp;patients&amp;nbsp;at risk when you&amp;nbsp;don’t&amp;nbsp;use&amp;nbsp;new technologies and AI.&amp;nbsp;And&amp;nbsp;additionally, the same level of scrutiny may be applied to low-risk devices, where&amp;nbsp;the extensive testing and documentation may also be disproportionate to the actual patient risk.&lt;/p&gt;



&lt;p&gt;However, the prescriptive model is highly&amp;nbsp;appropriate where&amp;nbsp;we have high testing standards for high-risk medical devices, in my view, particularly those that are life-sustaining, implanted, or involve new materials or mechanisms.&lt;/p&gt;



&lt;p&gt;I also wanted to say that I think that these higher compliance thresholds can be OK and necessary if you have a system where authorities and stakeholders also have the capacity and funding to enforce, monitor, and achieve compliance with such rules in a feasible, time-effective, and straightforward manner. And this, of course, requires resources, novel solutions,&amp;nbsp;and investments.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;A range of tests are undertaken across the life cycle of medical devices.&amp;nbsp;How do these testing requirements vary across&amp;nbsp;different stages&amp;nbsp;of development and across various applications?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes,&amp;nbsp;that’s&amp;nbsp;a good question.&amp;nbsp;So&amp;nbsp;I think first it&amp;nbsp;is important to realize that testing is conducted by various entities, including manufacturers, independent third-party laboratories, and regulatory agencies. And it occurs throughout the device&amp;nbsp;life&amp;nbsp;cycle, beginning with iterative testing during the research and development stage, advancing to pre-market evaluations, and continuing into post-market monitoring. And the outcomes of&amp;nbsp;these tests directly&amp;nbsp;impact&amp;nbsp;regulatory approvals, market access, and device design refinements, as well.&amp;nbsp;So&amp;nbsp;the testing results are typically shared with regulatory authorities and in some cases with healthcare providers and the broader public to enhance transparency and trust.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;if you talk about the&amp;nbsp;different phases&amp;nbsp;that play a role here … so&amp;nbsp;let’s&amp;nbsp;turn to the pre-market phase, where manufacturers must&amp;nbsp;demonstrate&amp;nbsp;that the device is conformed to safety and performance benchmarks defined by regulatory authorities. Pre-market evaluations include functional bench testing, biocompatibility, for example, assessments and software validation, all of which are integral components of a manufacturer’s submission.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, yes, but, testing also, and we touched already up on that, extends into the post-market phase, where it continues to ensure device safety and efficacy, and post-market surveillance relies on testing to&amp;nbsp;monitor real-world performance and&amp;nbsp;identify&amp;nbsp;emerging risks on the post-market phase. By integrating real-world evidence into ongoing assessments, manufacturers can address unforeseen issues, update devices as needed, and&amp;nbsp;maintain compliance with evolving regulatory expectations. And&amp;nbsp;I think this&amp;nbsp;is particularly important in this new generation of medical devices that are AI-enabled or machine-learning enabled.&lt;/p&gt;



&lt;p&gt;I think we have to understand that in this AI-enabled medical devices field, you know, the devices and the algorithms that are working with&amp;nbsp;them, they&amp;nbsp;can improve in the lifetime of a product.&amp;nbsp;So actually, not&amp;nbsp;only you could assess them and make sure that they&amp;nbsp;maintain&amp;nbsp;safe,&amp;nbsp;you&amp;nbsp;could also sometimes lower the risk category by finding evidence that these devices are&amp;nbsp;actually becoming&amp;nbsp;more precise and safer.&amp;nbsp;So&amp;nbsp;it can both, you know, heighten the risk&amp;nbsp;category&amp;nbsp;or lower the risk category, and&amp;nbsp;that’s&amp;nbsp;why&amp;nbsp;this continuous testing is so important.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Given what you just said, how should regulators handle a device whose algorithm keeps updating itself after approval?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Well, it&amp;nbsp;has to&amp;nbsp;be an iterative process that is&amp;nbsp;feasible&amp;nbsp;and straightforward and that is based on a very efficient, both time efficient and performance efficient, communication between the regulatory authorities and the medical device developers, right. We need to have&amp;nbsp;the sensors&amp;nbsp;in place that spot potential changes, and we need to have&amp;nbsp;the mechanisms&amp;nbsp;in place that allow us to quickly react to these changes both regulatory wise&amp;nbsp;and also&amp;nbsp;in&amp;nbsp;the&amp;nbsp;technological way. &lt;/p&gt;



&lt;p&gt;So&amp;nbsp;I think communication&amp;nbsp;is important,&amp;nbsp;and we need to have&amp;nbsp;the pathways&amp;nbsp;and&amp;nbsp;the feedback&amp;nbsp;loops in the regulation that quickly allow us to&amp;nbsp;monitor&amp;nbsp;these self-learning algorithms and devices.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;It sounds like&amp;nbsp;it’s&amp;nbsp;just …&amp;nbsp;there’s&amp;nbsp;such a delicate balance between advancing technology and really ensuring public safety. You know, if we clamp down too hard, we stifle that innovation. You already touched upon this a bit. But if&amp;nbsp;we’re&amp;nbsp;too lax, we risk unintended consequences. And&amp;nbsp;I’d&amp;nbsp;just love to hear how you think the field is balancing that and any learnings you can share.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;this is&amp;nbsp;very true, and&amp;nbsp;you just touched upon a very central question also in our research and our writing. And this is also the&amp;nbsp;reason why&amp;nbsp;medical device regulation is so fascinating and continues to evolve in response to rapid advancements in technologies, particularly dual technologies&amp;nbsp;regarding&amp;nbsp;digital health, artificial intelligence, for example, and personalized medicine.&lt;/p&gt;



&lt;p&gt;And finding the balance is tricky because also [a] related major future challenge relates to the increasing regulatory jungle and the complex interplay between evolving regulatory landscapes that regulate AI more generally.&lt;/p&gt;



&lt;p&gt;We really need to make sure that the regulatory authorities that deal with this, that need to find the right balance to promote innovation and mitigate and prevent risks, need to have the&amp;nbsp;capacity&amp;nbsp;to do this.&amp;nbsp;So&amp;nbsp;this requires investments, and it also requires new ways to regulate this technology more flexibly, for example through regulatory sandboxes and so on.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Could you just expand upon that a bit and double-click on what it is&amp;nbsp;you’re&amp;nbsp;seeing there? What excites you about&amp;nbsp;what’s&amp;nbsp;happening in that space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes, well, the research of my group at the Center for Advanced Studies in Bioscience Innovation Law is&amp;nbsp;very broad. I mean, we are looking into gene editing technologies. We are looking into new biologics. We are looking into medical&amp;nbsp;devices,&amp;nbsp;as well, obviously, but also other technologies&amp;nbsp;in advanced medical computing.&lt;/p&gt;



&lt;p&gt;And what we see across the line here is that there is an increasing demand for having more adaptive and flexible regulatory frameworks in these&amp;nbsp;new technologies,&amp;nbsp;in particular when&amp;nbsp;they have new uses, regulations that are focusing more on the product rather than the process. And I have recently&amp;nbsp;written&amp;nbsp;a report, for example,&amp;nbsp;for&amp;nbsp;emerging biotechnologies and&amp;nbsp;bio-solutions&amp;nbsp;for the EU commission. And even in that area, regulatory sandboxes are increasingly important, increasingly considered.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;this idea of regulatory sandboxes has been developing originally in the financial sector, and it is now penetrating into&amp;nbsp;other sectors, including synthetic biology, emerging biotechnologies, gene editing, AI, quantum technology, as&amp;nbsp;well. This is&amp;nbsp;basically creating&amp;nbsp;an environment where actors can test&amp;nbsp;new ideas&amp;nbsp;in close collaboration and under the oversight of regulatory authorities.&lt;/p&gt;



&lt;p&gt;But&amp;nbsp;to implement&amp;nbsp;this in the AI sector now also leads us to&amp;nbsp;a&amp;nbsp;lot of questions and challenges. For example, you need to have the&amp;nbsp;capacities&amp;nbsp;of authorities that are governing and&amp;nbsp;monitoring&amp;nbsp;and deciding&amp;nbsp;on these regulatory sandboxes. There are issues relating to competition law, for example, which&amp;nbsp;you&amp;nbsp;call antitrust law in the US, because the question is, who can enter the sandbox and how may they compete after they exit the sandbox? And there are many questions relating to, how&amp;nbsp;should we&amp;nbsp;work with these sandboxes and how&amp;nbsp;should we&amp;nbsp;implement these sandboxes?&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well, Timo, it has just been such a pleasure to speak with you today.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes, thank you very much.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now&amp;nbsp;I’m&amp;nbsp;happy to introduce Chad Atalla.&lt;/p&gt;



&lt;p&gt;Chad&amp;nbsp;is&amp;nbsp;senior applied scientist&amp;nbsp;in&amp;nbsp;Microsoft Research&amp;nbsp;New York City’s&amp;nbsp;Sociotechnical Alignment Center, where they contribute to foundational responsible AI research and practical responsible AI solutions for teams across Microsoft.&lt;/p&gt;



&lt;p&gt;Chad, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHAD ATALLA:&lt;/strong&gt;&amp;nbsp;Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;we’ll&amp;nbsp;kick off with a couple questions just to dive right in.&amp;nbsp;So&amp;nbsp;tell me a little bit more about the&amp;nbsp;Sociotechnical Alignment Center,&amp;nbsp;or&amp;nbsp;&lt;em&gt;STAC&lt;/em&gt;? I know it was founded in&amp;nbsp;2022.&amp;nbsp;I’d&amp;nbsp;love to just learn a little bit more about what the group does, how&amp;nbsp;you’re&amp;nbsp;thinking about evaluating AI, and&amp;nbsp;maybe just&amp;nbsp;give us a sense of some of the projects&amp;nbsp;you’re&amp;nbsp;working on.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Yeah, absolutely. The name is quite a mouthful.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;It is!&amp;nbsp;[LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;let’s&amp;nbsp;start by breaking that down and seeing what that means.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Great.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt; So modern AI systems are sociotechnical systems, meaning that the social and technical aspects are deeply intertwined. And&amp;nbsp;we’re interested in aligning the behaviors of these sociotechnical&amp;nbsp;systems with some values.&amp;nbsp;Those could be societal values;&amp;nbsp;they could be regulatory values, organizational values, etc. And to make this alignment happen, we need the ability to evaluate the systems.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;my team is broadly working on an evaluation framework that acknowledges the sociotechnical nature of the technology and the often-abstract nature of the concepts&amp;nbsp;we’re&amp;nbsp;actually interested&amp;nbsp;in evaluating. As you noted,&amp;nbsp;it’s&amp;nbsp;an applied science team, so we split our time between some fundamental research and time to bridge the work into real products across the company. And I also want to note that to power this sort of work, we have an interdisciplinary team drawing upon the social sciences, linguistics, statistics, and,&amp;nbsp;of course, computer science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well,&amp;nbsp;I’m&amp;nbsp;eager to get into our takeaways from the conversation with&amp;nbsp;both Daniel&amp;nbsp;and Timo. But&amp;nbsp;maybe just&amp;nbsp;to double-click on this for a minute, can you talk a bit about some of the overarching goals of the AI evaluations that you noted?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;evaluation is really the act of making valuative judgments based on some evidence, and in the case of AI evaluation, that evidence might be from tests or measurements, right.&amp;nbsp;And the goal of why&amp;nbsp;we’re doing this in the first place is to make decisions and claims most often.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;perhaps I&amp;nbsp;am going to make a claim about a model that&amp;nbsp;I’m&amp;nbsp;producing, and I want to say that&amp;nbsp;it’s&amp;nbsp;better than this other model. Or we are asking whether a certain product is safe to ship.&amp;nbsp;All of these decisions need to be informed by good evaluation and therefore good measurement or testing.&amp;nbsp;And&amp;nbsp;I’ll&amp;nbsp;also note that in&amp;nbsp;the regulatory conversation, &lt;em&gt;risk&lt;/em&gt;&amp;nbsp;is often what we want to evaluate. So that is a goal in and of itself. And&amp;nbsp;I’ll&amp;nbsp;touch more on that later.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;I read a recent&amp;nbsp;paper that you had put out with some of our colleagues from Microsoft Research, from the University of Michigan, and Stanford, and you were arguing that evaluating generative AI is&amp;nbsp;&lt;em&gt;the&lt;/em&gt;&amp;nbsp;social-science measurement challenge.&amp;nbsp;Maybe for&amp;nbsp;those who&amp;nbsp;haven’t&amp;nbsp;read the paper, what does this mean? And can you tell us a little bit more about what motivated you and your coauthors?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So the measurement tasks involved in evaluating generative AI systems are often abstract and contested. So that means they cannot be directly measured and must instead [be] indirectly measured via other observable phenomena. So this is very different than the older machine learning paradigm, where, let’s say, for example, I had a system that took a picture of a traffic light and told you whether it was green, yellow, or red at a given time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If we wanted to evaluate that system, the task is much simpler. But with the modern generative AI systems that are also general purpose, they have open-ended output, and language in a whole chat or multiple paragraphs being outputted can have a lot of different properties. And as I noted, these are general-purpose systems, so we don’t know exactly what task they’re supposed to be carrying out.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;then the question becomes, if I want to make some decision or claim—maybe I&amp;nbsp;want to make a claim that this system has human-level reasoning capabilities—well, what does that mean? Do I have the same impression of what that means as you do? And how do we know whether the downstream, you know, measurements and tests that&amp;nbsp;I’m&amp;nbsp;conducting&amp;nbsp;actually will&amp;nbsp;support my notion of what it means to have human-level reasoning,&amp;nbsp;right?&amp;nbsp;Difficult questions. But luckily, social scientists have been dealing with these exact sorts of challenges for multiple decades in fields like education, political science, and psychometrics. So&amp;nbsp;we’re&amp;nbsp;really&amp;nbsp;attempting&amp;nbsp;to avoid reinventing the wheel here and trying to learn from their past methodologies.&lt;/p&gt;



&lt;p&gt;And so the rest of the paper goes on to delve into&amp;nbsp;a four-level framework, a measurement framework, that’s grounded in the measurement theory from the quantitative social sciences that takes us all the way from these abstract and contested concepts through processes to get much clearer and eventually reach reliable and valid measurements that can power our evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;I love that. I mean,&amp;nbsp;that’s&amp;nbsp;the whole point of this podcast,&amp;nbsp;too,&amp;nbsp;right.&amp;nbsp;Is&amp;nbsp;to really&amp;nbsp;build&amp;nbsp;on those other learnings and frameworks that&amp;nbsp;we’re&amp;nbsp;taking from industries that have been thinking about this for much longer.&amp;nbsp;Maybe from&amp;nbsp;your vantage point, what are some of the biggest day-to-day hurdles in building solid AI evaluations&amp;nbsp;and,&amp;nbsp;I&amp;nbsp;don’t&amp;nbsp;know, do we need more shared standards? Are there&amp;nbsp;bespoke methods? Are those&amp;nbsp;the way to go? I would love&amp;nbsp;to just&amp;nbsp;hear your thoughts on that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;let’s&amp;nbsp;talk about some of those practical challenges. And I want to briefly go back to what I mentioned about risk before, all right.&amp;nbsp;Oftentimes,&amp;nbsp;some of the regulatory environment&amp;nbsp;is requiring practitioners to measure the&amp;nbsp;&lt;em&gt;risk&lt;/em&gt;&amp;nbsp;involved in deploying one of their models or AI systems. Now, risk is importantly a&amp;nbsp;concept that includes both event and impact,&amp;nbsp;right.&amp;nbsp;So&amp;nbsp;there’s&amp;nbsp;the probability of some event occurring. For the case of AI evaluation,&amp;nbsp;perhaps this&amp;nbsp;is us seeing a certain AI behavior&amp;nbsp;exhibited. Then there’s also the severity of the&amp;nbsp;&lt;em&gt;impacts&lt;/em&gt;,&amp;nbsp;and this is a complex chain of effects in the real world that&amp;nbsp;happen&amp;nbsp;to people, organizations, systems, etc., and&amp;nbsp;it’s&amp;nbsp;a lot more challenging to&amp;nbsp;observe&amp;nbsp;the impacts,&amp;nbsp;right.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;if we’re saying that we need to measure risk, we have to measure both the event and the&amp;nbsp;impacts. But realistically, right now, the field is not doing&amp;nbsp;a very good&amp;nbsp;job of&amp;nbsp;actually measuring&amp;nbsp;the impacts. This requires vastly different techniques and methodologies where if I just wanted to measure something about the event itself, I can, you know, do that in a technical sandbox&amp;nbsp;environment&amp;nbsp;and&amp;nbsp;perhaps have&amp;nbsp;some automated methods to detect whether a certain AI behavior is being&amp;nbsp;exhibited. But if I want to measure the impacts? Now,&amp;nbsp;we’re&amp;nbsp;in the realm of needing to have real people involved, and&amp;nbsp;perhaps a&amp;nbsp;longitudinal study where you have interviews, questionnaires, and more qualitative evidence-gathering techniques to&amp;nbsp;truly understand&amp;nbsp;the long-term impacts. So&amp;nbsp;that’s&amp;nbsp;a significant challenge.&lt;/p&gt;



&lt;p&gt;Another is that, you know,&amp;nbsp;let’s&amp;nbsp;say we forget about the impacts for&amp;nbsp;now&amp;nbsp;and we focus on the event side of things. Still, we need datasets, we need&amp;nbsp;annotations,&amp;nbsp;and we need&amp;nbsp;metrics to make this whole thing work. When I say we need datasets, if I want to test whether my system has good mathematical reasoning, what questions should I ask? What are my set of inputs that are relevant? And then when I get&amp;nbsp;the&amp;nbsp;response from the system, how do I annotate them? How do I know if it was a good response that&amp;nbsp;&lt;em&gt;did&lt;/em&gt; demonstrate mathematical reasoning or if it was a mediocre response? And then once I have an annotation of&amp;nbsp;all of these outputs from the AI system, how do I aggregate those all up into a single informative number?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Earlier in this episode, we heard Daniel and&amp;nbsp;Timo walk&amp;nbsp;through the regulatory frameworks in pharma and medical devices.&amp;nbsp;I’d&amp;nbsp;be curious what pieces of those mature systems are already showing up or at least may&amp;nbsp;be bubbling up in AI governance.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Great question. You know, Timo was talking about the pre-market and post-market testing difference. Of course, this is similarly important in the AI evaluation space. But again, these have different methodologies and serve different purposes.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;within the pre-deployment phase, we&amp;nbsp;don’t&amp;nbsp;have evidence of how people are going to use the system. And when we have these general-purpose AI systems,&amp;nbsp;to understand what the risks are, we really need to have a sense of what might happen and how they might be used.&amp;nbsp;So&amp;nbsp;there are&amp;nbsp;significant challenges there where I think we can learn from other fields and how they do pre-market testing. And the difference in that pre- versus post-market testing also ties to testing at&amp;nbsp;different stages&amp;nbsp;in the life cycle.&lt;/p&gt;



&lt;p&gt;For AI systems, we already see some regulations saying you need to start with the base model and do some evaluation of the base model, some basic attributes, some core attributes,&amp;nbsp;of that base model before you start putting it into any real products. But once we have a product in mind, we have a user base in mind, we have a specific task—like maybe we’re going to integrate this model into Outlook and it’s going to help you write&amp;nbsp;emails—now we suddenly have a much crisper picture of how the system will interact with the world around it. And again, at that stage, we need to think about another round of evaluation.&lt;/p&gt;



&lt;p&gt;Another part that jumped out to me in what they were saying about pharmaceuticals is that sometimes approvals can be based on surrogate endpoints.&amp;nbsp;So&amp;nbsp;this is like&amp;nbsp;we’re&amp;nbsp;choosing some&amp;nbsp;heuristic.&amp;nbsp;Instead of measuring the long-term impact, which is what we&amp;nbsp;actually care&amp;nbsp;about,&amp;nbsp;perhaps we&amp;nbsp;have a proxy that we&amp;nbsp;feel like&amp;nbsp;is a good enough indicator of what that long-term impact might look like.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is occurring in the AI evaluation space right now and is often perhaps even the default here since&amp;nbsp;we’re not seeing that many studies of the long-term impact itself. We are seeing, instead, folks constructing these heuristics or proxies and saying if I see this behavior happen,&amp;nbsp;I’m&amp;nbsp;going to&amp;nbsp;&lt;em&gt;assume&lt;/em&gt;&amp;nbsp;that it&amp;nbsp;indicates&amp;nbsp;this sort of impact will happen downstream. And&amp;nbsp;that’s&amp;nbsp;great.&amp;nbsp;It’s&amp;nbsp;one of the techniques that was used to speed up and reduce the barrier to innovation in&amp;nbsp;the other&amp;nbsp;fields. And I think&amp;nbsp;it’s&amp;nbsp;great that we are applying that in the AI evaluation space. But&amp;nbsp;special care&amp;nbsp;is,&amp;nbsp;of course, needed to ensure that those heuristics and proxies you’re&amp;nbsp;using are reasonable indicators of the greater outcome&amp;nbsp;you’re&amp;nbsp;looking for.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;What are some of the promising ideas from&amp;nbsp;maybe pharma&amp;nbsp;or med device regulation that maybe haven’t&amp;nbsp;made it to AI testing yet and&amp;nbsp;maybe should? And where would you urge technologists, policymakers,&amp;nbsp;and researchers to focus their energy next?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Well, one of the key things that jumped out to me in the discussion about pharmaceuticals was driving home the emphasis that there&amp;nbsp;is&amp;nbsp;a&amp;nbsp;&lt;em&gt;holistic&lt;/em&gt;&amp;nbsp;focus on safety&amp;nbsp;&lt;em&gt;and&lt;/em&gt;&amp;nbsp;efficacy. These go hand in hand&amp;nbsp;and decisions must be made while considering both pieces of the picture. I would like to see that further emphasized in the AI evaluation space.&lt;/p&gt;



&lt;p&gt;Often,&amp;nbsp;we&amp;nbsp;are seeing&amp;nbsp;evaluations of risk being separated from evaluations of&amp;nbsp;performance or quality&amp;nbsp;or efficacy, but these two pieces of the puzzle really are not enough for us to make informed decisions independently.&amp;nbsp;And that ties back into my desire to really also see us measuring the impacts.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;we see Phase 3 trials as something that occurs in the medical devices and pharmaceuticals field. That’s not something that we are doing an equivalent of in the AI evaluation space at this time.&amp;nbsp;These are really&amp;nbsp;cost intensive. They can last years and really involve careful monitoring of that holistic picture of safety and efficacy. And realistically, we are not going to be able to put that on the critical path to getting specific individual AI models or AI systems vetted before they&amp;nbsp;go out&amp;nbsp;into the world. However, I would love to see a world in which this sort of work is prioritized&amp;nbsp;and funded or&amp;nbsp;required. Think of how, with&amp;nbsp;social media, it took quite a long time for us to understand that there are some long-term negative impacts on mental health, and we have the opportunity now, while the AI wave is still building,&amp;nbsp;to start prioritizing and funding this sort of work. Let it run in the background and as soon as possible develop a good understanding of the subtle, long-term effects.&lt;/p&gt;



&lt;p&gt;More broadly, I would love to see us focus on reliability and validity of the evaluations&amp;nbsp;we’re&amp;nbsp;conducting because trust in these decisions and claims is important. If we&amp;nbsp;don’t&amp;nbsp;focus on building reliable, valid, and trustworthy evaluations,&amp;nbsp;we’re&amp;nbsp;just going to continue to be flooded by a bunch of competing, conflicting, and&amp;nbsp;largely meaningless&amp;nbsp;AI evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;In a number of the discussions we’ve had on this podcast, we talked about how it’s not just one entity that really needs to ensure safety across the board,&amp;nbsp;and I’d&amp;nbsp;just love to hear from you how you think about some of those ecosystem collaborations, and you know, from across … where we think about ourselves as more of a platform company or places that these AI models are being deployed more at the application level. Tell me a little bit about how you think about,&amp;nbsp;sort&amp;nbsp;of, stakeholders in that mix and where responsibility lies across the board.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;It’s&amp;nbsp;interesting. In this age of general-purpose AI technologies,&amp;nbsp;we’re&amp;nbsp;often&amp;nbsp;seeing&amp;nbsp;one company or organization&amp;nbsp;being responsible for&amp;nbsp;building the foundational model. And then many, many other people will take that model and build it into specific products that are designed for specific tasks and contexts.&lt;/p&gt;



&lt;p&gt;Of course,&amp;nbsp;in that, we already see that there is&amp;nbsp;a responsibility&amp;nbsp;of the owners of that foundational model to do some testing of the central model before they distribute it broadly. And then again, there is responsibility of all of the downstream individuals digesting that and turning it into products to consider the specific contexts that they are deploying into and how that may affect the risks we’re concerned with or the types of quality and safety and performance we need to evaluate.&lt;/p&gt;



&lt;p&gt;Again, because that field of risks we may be concerned with is so broad, some of them also require an immense amount of&amp;nbsp;expertise.&amp;nbsp;Let’s&amp;nbsp;think about whether AI systems can enable people to create dangerous chemicals or dangerous weapons at home. It’s not that every AI practitioner is going to have the knowledge to evaluate this, so in some of those cases, we really need third-party experts, people who are experts in chemistry, biology, etc., to come in and evaluate certain systems and models for those specific risks,&amp;nbsp;as well.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;I think there&amp;nbsp;are many reasons why multiple stakeholders need to be involved, partly from who owns what and&amp;nbsp;is responsible for&amp;nbsp;what and partly from the perspective of who has the&amp;nbsp;expertise&amp;nbsp;to meaningfully construct the evaluations that we need.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well, Chad, this has just been great to connect, and in a few of our discussions,&amp;nbsp;we’ve&amp;nbsp;done a bit of a lightning round, so&amp;nbsp;I’d&amp;nbsp;love to just hear your&amp;nbsp;30-second responses to a few of these questions. Perhaps&amp;nbsp;favorite&amp;nbsp;evaluation&amp;nbsp;you’ve&amp;nbsp;run so far this year?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I’ve&amp;nbsp;been involved in trying to evaluate some language models for whether they&amp;nbsp;&lt;em&gt;infer&lt;/em&gt;&amp;nbsp;sensitive attributes about people. So&amp;nbsp;perhaps&amp;nbsp;you’re&amp;nbsp;chatting with a&amp;nbsp;chatbot,&amp;nbsp;and it infers your religion or sexuality based on things&amp;nbsp;you’re&amp;nbsp;saying or how you sound,&amp;nbsp;right.&amp;nbsp;And in working to evaluate this, we&amp;nbsp;encounter&amp;nbsp;a lot of interesting questions. Or,&amp;nbsp;like,&amp;nbsp;what is a sensitive attribute? What makes these attributes sensitive, and what are the differences that make it inappropriate for an AI system to infer these things about a person? Whereas realistically, whenever I meet a person on the street, my&amp;nbsp;brain is&amp;nbsp;immediately&amp;nbsp;forming&amp;nbsp;first impressions and some assumptions about these people.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;a very interesting&amp;nbsp;and thought-provoking evaluation to conduct and think about the norms that we place upon&amp;nbsp;&lt;em&gt;people&lt;/em&gt;&amp;nbsp;interacting with other people and the norms we place upon&amp;nbsp;&lt;em&gt;AI systems&lt;/em&gt;&amp;nbsp;interacting with other people.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;That’s&amp;nbsp;fascinating!&amp;nbsp;I’d&amp;nbsp;love to hear the AI&amp;nbsp;buzzword&amp;nbsp;you’d&amp;nbsp;retire tomorrow.&amp;nbsp;[LAUGHTER]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;I would love to see the term “bias” being&amp;nbsp;used less when referring to fairness-related issues and systems. Bias happens to be a highly overloaded term in statistics and machine learning and has a lot of technical meanings and just&amp;nbsp;fails to&amp;nbsp;perfectly capture what we mean in the AI risk sense.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;And last one. One metric&amp;nbsp;we’re&amp;nbsp;not tracking enough.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;I would say &lt;em&gt;over-blocking&lt;/em&gt;, and this comes into that connection between the holistic picture of safety and efficacy. It’s too easy to produce systems that throw safety to the wind and focus purely on utility or achieving some goal, but simultaneously, the other side of the picture is possible, where we can clamp down too hard and reduce the utility of our systems and block even benign and useful outputs just because they border on something sensitive.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;important for us to track that over-blocking and actively track that tradeoff between safety and efficacy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah, we talk a lot about this on the podcast,&amp;nbsp;too,&amp;nbsp;of how do you both make things safe but also ensure innovation can&amp;nbsp;thrive,&amp;nbsp;and&amp;nbsp;I think you&amp;nbsp;hit the nail on the head with that last piece.&lt;/p&gt;



&lt;p&gt;[MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Well, Chad, this was&amp;nbsp;really terrific. Thanks for joining us and thanks for your work and your&amp;nbsp;perspectives. And another big thanks to Daniel and Timo for setting the stage earlier in the podcast.&lt;/p&gt;



&lt;p&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI. &lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Daniel Carpented, Timo Minssen, Chad Atalla, and Kathleen Sullivan." class="wp-image-1143327" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;, hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Daniel Carpenter, the Allie S. Freed Professor of Government and chair of the department of government at Harvard University, explains how the US Food and Drug Administration’s rigorous, multi-phase drug approval process serves as a gatekeeper that builds public trust and scientific credibility, while Timo Minssen, professor of law and founding director of the Center for Advanced Studies in Bioscience Innovation Law at the University of Copenhagen, explores the evolving regulatory landscape of medical devices with a focus on the challenges of balancing innovation with public safety. Later, Microsoft’s Chad Atalla, an applied scientist in responsible AI, discusses the sociotechnical nature of AI models and systems, their team’s work building an evaluation framework inspired by social science, and where AI researchers, developers, and policymakers might find inspiration from the approach to governance and testing in pharmaceuticals and medical devices.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h4" id="learn-more"&gt;Learn more:&lt;/h2&gt;



&lt;p&gt;Learning from other Domains to Advance AI Evaluation and Testing: The History and Evolution of Testing in Pharmaceutical Regulation&lt;br /&gt;Case study | January 2025&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Learning from other Domains to Advance AI Evaluation and Testing: Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance&lt;br /&gt;Case study | January 2025&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Learning from other domains to advance AI evaluation and testing&amp;nbsp;&lt;br /&gt;Microsoft Research Blog | June 2025  &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evaluating Generative AI Systems is a Social Science Measurement Challenge&amp;nbsp;&lt;br /&gt;Publication&amp;nbsp;|&amp;nbsp;November 2024 &amp;nbsp;&lt;/p&gt;



&lt;p&gt;STAC: Sociotechnical Alignment Center &lt;/p&gt;



&lt;p&gt;Responsible AI: Ethical policies and practices | Microsoft AI&lt;/p&gt;



&lt;p&gt;AI and Microsoft Research &lt;/p&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN&lt;/strong&gt;: Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN&lt;/strong&gt;: Today, I’m excited to welcome Dan Carpenter and Timo Minssen to the podcast to explore testing and risk assessment in the areas of pharmaceuticals and medical devices, respectively.&lt;/p&gt;



&lt;p&gt;Dan Carpenter is chair of the Department of Government at Harvard University. His research spans the sphere of social and political science, from petitioning in democratic society to regulation and government organizations. His recent work includes the FDA Project, which examines pharmaceutical regulation in the United States.&lt;/p&gt;



&lt;p&gt;Timo is a professor of law at the University of Copenhagen, where he is also director of the Center for Advanced Studies in Bioscience Innovation Law. He specializes in legal aspects of biomedical innovation, including intellectual property law and regulatory law. He’s exercised his expertise as an advisor to such organizations as the World Health Organization and the European Commission.&lt;/p&gt;



&lt;p&gt;And after our conversations, we’ll talk to Microsoft’s Chad Atalla, an applied scientist in responsible AI, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Daniel, it’s a pleasure to welcome you to the podcast. I’m just so appreciative of you being here. Thanks for joining us today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;DANIEL CARPENTER:&lt;/strong&gt;&amp;nbsp;Thanks for having me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Dan, before we dissect policy,&amp;nbsp;let’s&amp;nbsp;rewind the tape to your&amp;nbsp;origin&amp;nbsp;story. Can you take us to the moment that you first became fascinated with regulators rather than, say, politicians? Was there a spark that pulled you toward the FDA story?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;At one point during graduate school, I was studying a combination of American politics and political theory, and I did a summer interning at the Department of Housing and Urban Development. And I began to think, why don’t people study these administrators more and the rules they make, the, you know,&amp;nbsp;inefficiencies, the efficiencies?&amp;nbsp;Really more&amp;nbsp;from,&amp;nbsp;kind of,&amp;nbsp;a descriptive standpoint, less from a normative standpoint.&amp;nbsp;And I was reading a lot that summer about the Food and Drug Administration and some of the decisions it was making on AIDS drugs. That was&amp;nbsp;a,&amp;nbsp;sort of,&amp;nbsp;a major, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt; … sort of, you know,&amp;nbsp;moment in the news, in the global news as well as the national news during, I would say, what?&amp;nbsp;The late&amp;nbsp;’80s, early&amp;nbsp;’90s? And&amp;nbsp;so&amp;nbsp;I began to&amp;nbsp;look&amp;nbsp;into&amp;nbsp;that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So now that we know what pulled you in,&amp;nbsp;let’s&amp;nbsp;zoom out for our listeners. Give us&amp;nbsp;the&amp;nbsp;whirlwind tour. I think most of us know pharma involves years of trials, but&amp;nbsp;what’s&amp;nbsp;the part we&amp;nbsp;don’t&amp;nbsp;know?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I think when most businesses develop a product, they all go through some phases of research and development and testing. And I think&amp;nbsp;what’s&amp;nbsp;different about the FDA is,&amp;nbsp;sort of,&amp;nbsp;two-&amp;nbsp;or three-fold.&lt;/p&gt;



&lt;p&gt;First, a lot of those tests are much more stringently specified and regulated by the government, and second, one of the reasons for that is that the FDA imposes not simply safety requirements upon drugs&amp;nbsp;in particular but&amp;nbsp;also efficacy requirements. The FDA wants you to prove not simply that&amp;nbsp;it’s&amp;nbsp;safe and non-toxic&amp;nbsp;but also that&amp;nbsp;it’s&amp;nbsp;effective.&amp;nbsp;And the final thing,&amp;nbsp;I think, that&amp;nbsp;makes the FDA different is that it stands as what I would call the&amp;nbsp;“veto player”&amp;nbsp;over R&amp;amp;D [research and development] to the marketplace.&amp;nbsp;The FDA&amp;nbsp;basically has,&amp;nbsp;sort of,&amp;nbsp;this control over entry&amp;nbsp;to&amp;nbsp;the marketplace.&lt;/p&gt;



&lt;p&gt;And&amp;nbsp;so&amp;nbsp;what that involves is usually first, a set of human trials where people who have no disease take it. And&amp;nbsp;you’re&amp;nbsp;only looking&amp;nbsp;for&amp;nbsp;toxicity generally. Then&amp;nbsp;there’s&amp;nbsp;a set of Phase 2 trials, where they look more at safety and a little bit at efficacy, and&amp;nbsp;you’re&amp;nbsp;now examining people who have the disease that the drug claims to treat. And&amp;nbsp;you’re&amp;nbsp;also basically comparing people who get the drug,&amp;nbsp;often&amp;nbsp;with those who do not.&lt;/p&gt;



&lt;p&gt;And then finally, Phase 3 involves a much more direct and large-scale attack, if you will, or assessment of efficacy, and&amp;nbsp;that’s&amp;nbsp;where you get the sort of large randomized clinical trials that are&amp;nbsp;very expensive&amp;nbsp;for pharmaceutical companies, biomedical companies to launch, to execute, to analyze. And those are often the sort of core evidence base for the decisions that the FDA makes about&amp;nbsp;whether or not&amp;nbsp;to approve a new drug for marketing in the United States.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Are there&amp;nbsp;differences in how that process has, you know, changed through other countries and&amp;nbsp;maybe just&amp;nbsp;how&amp;nbsp;that’s&amp;nbsp;evolved as&amp;nbsp;you’ve&amp;nbsp;seen it play out?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Yeah, for a long time, I would say that the United States had&amp;nbsp;probably the&amp;nbsp;most&amp;nbsp;stringent regime&amp;nbsp;of regulation for biopharmaceutical products until,&amp;nbsp;I would say,&amp;nbsp;about the 1990s and early 2000s. It used to be the case that a number of other countries, especially in Europe but around the world, basically waited for the FDA to mandate tests on a drug and only after the drug was approved in the United States would they deem it approvable and marketable in their own countries. And then after the formation of the European Union and the creation of the European Medicines Agency, gradually the European Medicines Agency began to get a bit more stringent.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, you know,&amp;nbsp;over the long run,&amp;nbsp;there’s&amp;nbsp;been a&amp;nbsp;lot of,&amp;nbsp;sort&amp;nbsp;of,&amp;nbsp;heterogeneity, a lot of variation over time and space, in the way that the FDA has approached these problems. And&amp;nbsp;I’d&amp;nbsp;say in the last 20 years, it’s begun to partially deregulate, namely,&amp;nbsp;you know,&amp;nbsp;trying to find all sorts of mechanisms or pathways for really innovative&amp;nbsp;drugs for deadly diseases without a lot of treatments to&amp;nbsp;basically get&amp;nbsp;through the process at lower cost.&amp;nbsp;For many people,&amp;nbsp;that has not been sufficient.&amp;nbsp;They’re&amp;nbsp;concerned about the cost of the system.&amp;nbsp;Of course, then the agency also gets criticized by those&amp;nbsp;who believe&amp;nbsp;it’s&amp;nbsp;too lax. It is&amp;nbsp;potentially letting&amp;nbsp;ineffective and unsafe therapies on the market.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;In your view, when does the structured model genuinely safeguard patients and where do you think it&amp;nbsp;maybe slows&amp;nbsp;or&amp;nbsp;limits&amp;nbsp;innovation?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I think&amp;nbsp;the worry&amp;nbsp;is that if you approach pharmaceutical approval as a world where only things can go wrong,&amp;nbsp;then&amp;nbsp;you’re&amp;nbsp;really at a risk of limiting innovation. And even if you end up letting a lot of things through, if by your regulations you end up basically slowing down the development process or making it very, very costly, then there’s just a whole bunch of drugs that either come to market too slowly or they come to market not at all because&amp;nbsp;they just aren’t worth the kind of cost-benefit or, sort of, profit analysis of the firm.&amp;nbsp;You know, so&amp;nbsp;that’s&amp;nbsp;been a concern.&amp;nbsp;And I think&amp;nbsp;it’s&amp;nbsp;been one of the reasons that the Food and Drug Administration as well as other world regulators have begun to&amp;nbsp;basically try&amp;nbsp;to smooth the process and accelerate the process at the margins.&lt;/p&gt;



&lt;p&gt;The other thing is that&amp;nbsp;they’ve&amp;nbsp;started to&amp;nbsp;basically make&amp;nbsp;approvals&amp;nbsp;on the basis of&amp;nbsp;what are called&amp;nbsp;&lt;em&gt;surrogate endpoints&lt;/em&gt;. So the idea is that a cancer drug, we really want to know whether that drug saves lives, but if we wait to see whose lives are saved or prolonged by that drug, we might miss the opportunity to make judgments on the basis of, well, are we detecting tumors in the bloodstream? Or can we measure the size of those tumors&amp;nbsp;in, say, a&amp;nbsp;solid cancer? And then the further question is, is the size of the tumor&amp;nbsp;basically a&amp;nbsp;really good&amp;nbsp;correlate&amp;nbsp;or predictor of whether people will die or&amp;nbsp;not, right?&amp;nbsp;Generally, the&amp;nbsp;FDA tends to be less stringent when&amp;nbsp;you’ve&amp;nbsp;got, you know, a remarkably innovative new&amp;nbsp;therapy&amp;nbsp;and the disease being treated is one that just&amp;nbsp;doesn’t&amp;nbsp;have a lot of available treatments,&amp;nbsp;right.&lt;/p&gt;



&lt;p&gt;The one thing that people often think about when&amp;nbsp;they’re&amp;nbsp;thinking about pharmaceutical regulation is they often contrast,&amp;nbsp;kind of,&amp;nbsp;speed versus safety …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&amp;nbsp;&lt;/strong&gt;… right. And&amp;nbsp;that’s&amp;nbsp;useful as a tradeoff,&amp;nbsp;but I often try to remind people that&amp;nbsp;it’s&amp;nbsp;not simply&amp;nbsp;about whether the drug gets out&amp;nbsp;there&amp;nbsp;and&amp;nbsp;it’s&amp;nbsp;unsafe. You know, you and I as patients and even doctors have&amp;nbsp;a hard time&amp;nbsp;knowing whether something works and whether it should be prescribed. And the evidence for knowing whether something works&amp;nbsp;isn’t&amp;nbsp;just, well,&amp;nbsp;you&amp;nbsp;know, Sally took&amp;nbsp;it&amp;nbsp;or Dan took it or Kathleen took it, and they&amp;nbsp;seem to get&amp;nbsp;better or they&amp;nbsp;didn’t&amp;nbsp;seem to get better.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The really rigorous evidence comes from randomized clinical trials.&amp;nbsp;And I think&amp;nbsp;it’s&amp;nbsp;fair to say that if you didn’t&amp;nbsp;have the FDA there as a veto player, you&amp;nbsp;wouldn’t&amp;nbsp;get as many randomized clinical&amp;nbsp;trials&amp;nbsp;and the evidence&amp;nbsp;probably&amp;nbsp;wouldn’t&amp;nbsp;be as rigorous for whether these things work. And as I like to put it,&amp;nbsp;basically there’s&amp;nbsp;a whole ecology of expectations and beliefs around the biopharmaceutical industry in the United States and globally,&amp;nbsp;and to some extent,&amp;nbsp;it’s&amp;nbsp;undergirded by&amp;nbsp;all of&amp;nbsp;these tests that happen.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&amp;nbsp;&lt;/strong&gt;And in part, that means&amp;nbsp;it’s&amp;nbsp;undergirded by regulation. Would there still be a market without regulation? Yes. But it would be a market in which people had far less information in and confidence about the drugs that are being taken. And&amp;nbsp;so&amp;nbsp;I think&amp;nbsp;it’s&amp;nbsp;important to recognize that kind of confidence-boosting potential of, kind of, a scientific regulation base.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Actually, if we could&amp;nbsp;double-click&amp;nbsp;on that for a minute, I’d love to hear your perspective on, &lt;em&gt;testing&amp;nbsp;has been completed;&amp;nbsp;there’s results&lt;/em&gt;.&amp;nbsp;Can you walk us through how those results actually shape the next steps and decisions of a particular drug and just,&amp;nbsp;like,&amp;nbsp;how regulators actually think about using that data to influence really what happens next with it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Right.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;important to understand that every drug is approved for&amp;nbsp;what’s called&amp;nbsp;an &lt;em&gt;indication&lt;/em&gt;. It can have a first primary&amp;nbsp;indication, which is the main disease that it treats, and then others can be added as more evidence is shown. But a drug is not something that just kind of exists out there in the ether.&amp;nbsp;It has to have the right form of administration.&amp;nbsp;Maybe it&amp;nbsp;should be injected.&amp;nbsp;Maybe it&amp;nbsp;should be &lt;em&gt;ingested&lt;/em&gt;.&amp;nbsp;Maybe it&amp;nbsp;should&amp;nbsp;be administered only at a clinic&amp;nbsp;because it needs to be&amp;nbsp;kind of administered&amp;nbsp;in just the right way. As doctors will tell you, dosage is everything, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And&amp;nbsp;so&amp;nbsp;one of the reasons that you want those trials is not simply a, you know, yes or no answer about whether the drug works,&amp;nbsp;right.&amp;nbsp;It’s&amp;nbsp;not simply if-then.&amp;nbsp;It’s&amp;nbsp;literally what&amp;nbsp;goes into what you might call the dose response curve.&amp;nbsp;You know, how much of this drug do we need to&amp;nbsp;basically, you know,&amp;nbsp;get the benefit? At what point does that fall off significantly that we can&amp;nbsp;basically say, we can stop there? All that evidence comes from&amp;nbsp;trials. And&amp;nbsp;that’s&amp;nbsp;the kind of evidence that is&amp;nbsp;required&amp;nbsp;on the basis of&amp;nbsp;regulation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because&amp;nbsp;it’s&amp;nbsp;not simply a drug&amp;nbsp;that’s&amp;nbsp;approved.&amp;nbsp;It’s&amp;nbsp;a drug and a&amp;nbsp;&lt;em&gt;frequency&lt;/em&gt;&amp;nbsp;of administration. It’s&amp;nbsp;a&amp;nbsp;&lt;em&gt;method&lt;/em&gt; of administration.&amp;nbsp;And&amp;nbsp;so&amp;nbsp;the drug&amp;nbsp;isn’t&amp;nbsp;just,&amp;nbsp;there’s&amp;nbsp;something to be taken off the shelf and popped into your mouth. I mean, sometimes&amp;nbsp;that’s&amp;nbsp;what happens, but even then,&amp;nbsp;we want to know what the dosage is,&amp;nbsp;right.&amp;nbsp;We want to know what to look for in terms of side effects, things like that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Going back to that point, I&amp;nbsp;mean,&amp;nbsp;it sounds like&amp;nbsp;we’re&amp;nbsp;making a lot of progress from a regulation perspective&amp;nbsp;in, you know, sort of speed and getting things approved but doing it in a&amp;nbsp;really balanced&amp;nbsp;way. I mean, any other kind of closing thoughts on the tradeoffs there or where&amp;nbsp;you’re&amp;nbsp;seeing that going?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;I think&amp;nbsp;you’re&amp;nbsp;going to see some move in the coming years—there’s&amp;nbsp;already been some of it—to say, do we always need a&amp;nbsp;really large&amp;nbsp;Phase 3 clinical trial? And to what degree do we need the, like, you&amp;nbsp;know,&amp;nbsp;all the i’s dotted and the t’s crossed or a really,&amp;nbsp;really large&amp;nbsp;sample size?&amp;nbsp;And&amp;nbsp;I’m&amp;nbsp;open to innovation there.&amp;nbsp;I’m&amp;nbsp;also open to the idea that we consider, again, things like accelerated approvals or pathways for looking at&amp;nbsp;different kinds&amp;nbsp;of surrogate endpoints.&amp;nbsp;I do think, once we do that, then we also have to have some degree of follow-up.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I know&amp;nbsp;we’re&amp;nbsp;getting&amp;nbsp;close to&amp;nbsp;out of time, but&amp;nbsp;maybe just&amp;nbsp;a quick rapid fire if&amp;nbsp;you’re&amp;nbsp;open to it. Biggest myth about clinical trials?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Well, some people tend to think that the FDA performs them.&amp;nbsp;You know,&amp;nbsp;it’s&amp;nbsp;companies that do it. And the only other thing I would say is the company that does a lot of the testing and even the innovating is not always the company that takes the drug to market, and it tells you something about how powerful regulation is in our system, in our world,&amp;nbsp;that you often need a company that has dealt with the FDA quite a bit and knows all the regulations and knows how to dot the i’s and cross the t’s in order to get a drug across the finish line.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;If you had a magic wand,&amp;nbsp;what’s&amp;nbsp;the one thing&amp;nbsp;you’d&amp;nbsp;change in regulation today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;I would like people to think a little bit less about just speed versus safety and,&amp;nbsp;again, more about this basic issue of confidence. I think&amp;nbsp;it’s&amp;nbsp;fundamental to everything that happens in markets but especially in biopharmaceuticals.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Such a great point.&amp;nbsp;This has been really fun.&amp;nbsp;Just thanks so much for being here today. We’re really excited to share your thoughts&amp;nbsp;out to&amp;nbsp;our listeners. Thanks.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CARPENTER:&lt;/strong&gt;&amp;nbsp;Likewise.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Now&amp;nbsp;to&amp;nbsp;the world of medical devices,&amp;nbsp;I’m&amp;nbsp;joined by Professor Timo&amp;nbsp;Minssen. Professor Minssen, it’s&amp;nbsp;great to have you here. Thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TIMO&amp;nbsp;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yeah, thank you very much,&amp;nbsp;it’s&amp;nbsp;a pleasure.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Before getting into the regulatory world of medical devices, tell our audience a bit about your personal journey or your origin story, as&amp;nbsp;we’re&amp;nbsp;asking our guests. How did you land in regulation, and what’s kept you hooked in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I started out as a patent expert in the biomedical area, starting with my PhD thesis on patenting biologics in Europe and in the US.&amp;nbsp;So&amp;nbsp;during that time, I was mostly interested in patent and trade secret questions.&amp;nbsp;But at the same time, I also developed and taught courses in regulatory law and held talks on regulating advanced medical therapy medicinal products.&amp;nbsp;I&amp;nbsp;then&amp;nbsp;started to lead large research projects on legal challenges in a wide variety of health and life science innovation frontiers. I also started to focus increasingly on AI-enabled medical devices and software as a medical device, resulting in several academic articles in this area&amp;nbsp;and also&amp;nbsp;in the regulatory area and a book on the future of medical device regulation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah,&amp;nbsp;what’s&amp;nbsp;kept you hooked in&amp;nbsp;the space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;It’s&amp;nbsp;just incredibly exciting,&amp;nbsp;in particular right&amp;nbsp;now with everything that is going on, you know, in the software arena, in the marriage between AI and medical devices. And this is really challenging not only societies but also regulators and authorities in Europe and in the US.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah,&amp;nbsp;it’s&amp;nbsp;a super exciting time to be in this space. You know, we talked to Daniel a little earlier and, you know, I think&amp;nbsp;similar to&amp;nbsp;pharmaceuticals, people have a general sense of what we mean when we say medical devices, but most listeners may&amp;nbsp;picture&amp;nbsp;like a stethoscope or a hip implant. The word “medical device”&amp;nbsp;reaches&amp;nbsp;much wider. Can you give us a quick, kind of, range from perhaps&amp;nbsp;very simple&amp;nbsp;to even, I don’t know, sci-fi and then your 90-second tour of how risk assessment works and why a framework is essential?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Let me start out by saying that&amp;nbsp;the WHO [World Health Organization] estimates that today there are approximately 2 million different kinds of medical devices on the world market, and as of the FDA’s latest update that I’m aware of, the FDA has authorized more than 1,000 AI-, machine learning-enabled medical devices, and that number is rising rapidly.&lt;/p&gt;



&lt;p&gt;So in that context, I think it is important to understand that medical devices can be any instrument, apparatus, implement, machine, appliance, implant, reagent for in vitro use, software, material, or other similar or related articles that are&amp;nbsp;&lt;em&gt;intended&lt;/em&gt;&amp;nbsp;by the manufacturer to be used alone or in combination for a medical purpose. And the spectrum of what constitutes a medical device can&amp;nbsp;thus&amp;nbsp;range from very simple devices such as tongue depressors, contact lenses, and thermometers to more complex devices such as blood pressure monitors, insulin pumps, MRI machines, implantable pacemakers, and even software as a medical device or AI-enabled monitors or drug device combinations, as well.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;talking about regulation,&amp;nbsp;I think&amp;nbsp;it&amp;nbsp;is also&amp;nbsp;very important&amp;nbsp;to stress that medical devices are used in many diverse situations by&amp;nbsp;very different&amp;nbsp;stakeholders. And testing&amp;nbsp;has to&amp;nbsp;take this variety into consideration, and it is intrinsically tied to regulatory requirements across various&amp;nbsp;jurisdictions.&lt;/p&gt;



&lt;p&gt;During the pre-market phase, medical testing&amp;nbsp;establishes&amp;nbsp;baseline safety and effectiveness metrics through bench testing, performance standards, and clinical studies. And post-market testing ensures that real-world data informs ongoing compliance and safety improvements. So testing is indispensable in translating technological innovation into safe and effective medical devices. And while&amp;nbsp;particular details&amp;nbsp;of pre-market and post-market review procedures may slightly differ among countries, most developed&amp;nbsp;jurisdictions regulate medical devices similarly to the US or European models. &lt;/p&gt;



&lt;p&gt;So&amp;nbsp;most&amp;nbsp;jurisdictions&amp;nbsp;with medical device regulation classify devices based on their risk profile, intended use, indications for use, technological characteristics,&amp;nbsp;and the regulatory controls necessary to provide a reasonable assurance of safety and effectiveness.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So medical devices face a pretty prescriptive multi-level testing path before they hit the market. From your vantage point, what are some of the downsides of that system and when does it make the most sense?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;One primary drawback is, of course, the lengthy and expensive approval process. High-risk devices, for example, often undergo years of clinical trials,&amp;nbsp;which can cost millions of dollars, and this can create a significant barrier for startups and small companies with limited resources.&amp;nbsp;And even for moderate-risk devices, the regulatory burden can slow product development and time to the market.&lt;/p&gt;



&lt;p&gt;And the approach can also limit flexibility. Prescriptive requirements may not accommodate emerging innovations like digital therapeutics or AI-based diagnostics in&amp;nbsp;a feasible&amp;nbsp;way. And in such cases, the framework can unintentionally [stiffen]&amp;nbsp;innovation by discouraging creative solutions or iterative improvements, which as matter of fact can also&amp;nbsp;&lt;em&gt;put&lt;/em&gt;&amp;nbsp;patients&amp;nbsp;at risk when you&amp;nbsp;don’t&amp;nbsp;use&amp;nbsp;new technologies and AI.&amp;nbsp;And&amp;nbsp;additionally, the same level of scrutiny may be applied to low-risk devices, where&amp;nbsp;the extensive testing and documentation may also be disproportionate to the actual patient risk.&lt;/p&gt;



&lt;p&gt;However, the prescriptive model is highly&amp;nbsp;appropriate where&amp;nbsp;we have high testing standards for high-risk medical devices, in my view, particularly those that are life-sustaining, implanted, or involve new materials or mechanisms.&lt;/p&gt;



&lt;p&gt;I also wanted to say that I think that these higher compliance thresholds can be OK and necessary if you have a system where authorities and stakeholders also have the capacity and funding to enforce, monitor, and achieve compliance with such rules in a feasible, time-effective, and straightforward manner. And this, of course, requires resources, novel solutions,&amp;nbsp;and investments.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;A range of tests are undertaken across the life cycle of medical devices.&amp;nbsp;How do these testing requirements vary across&amp;nbsp;different stages&amp;nbsp;of development and across various applications?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes,&amp;nbsp;that’s&amp;nbsp;a good question.&amp;nbsp;So&amp;nbsp;I think first it&amp;nbsp;is important to realize that testing is conducted by various entities, including manufacturers, independent third-party laboratories, and regulatory agencies. And it occurs throughout the device&amp;nbsp;life&amp;nbsp;cycle, beginning with iterative testing during the research and development stage, advancing to pre-market evaluations, and continuing into post-market monitoring. And the outcomes of&amp;nbsp;these tests directly&amp;nbsp;impact&amp;nbsp;regulatory approvals, market access, and device design refinements, as well.&amp;nbsp;So&amp;nbsp;the testing results are typically shared with regulatory authorities and in some cases with healthcare providers and the broader public to enhance transparency and trust.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;if you talk about the&amp;nbsp;different phases&amp;nbsp;that play a role here … so&amp;nbsp;let’s&amp;nbsp;turn to the pre-market phase, where manufacturers must&amp;nbsp;demonstrate&amp;nbsp;that the device is conformed to safety and performance benchmarks defined by regulatory authorities. Pre-market evaluations include functional bench testing, biocompatibility, for example, assessments and software validation, all of which are integral components of a manufacturer’s submission.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, yes, but, testing also, and we touched already up on that, extends into the post-market phase, where it continues to ensure device safety and efficacy, and post-market surveillance relies on testing to&amp;nbsp;monitor real-world performance and&amp;nbsp;identify&amp;nbsp;emerging risks on the post-market phase. By integrating real-world evidence into ongoing assessments, manufacturers can address unforeseen issues, update devices as needed, and&amp;nbsp;maintain compliance with evolving regulatory expectations. And&amp;nbsp;I think this&amp;nbsp;is particularly important in this new generation of medical devices that are AI-enabled or machine-learning enabled.&lt;/p&gt;



&lt;p&gt;I think we have to understand that in this AI-enabled medical devices field, you know, the devices and the algorithms that are working with&amp;nbsp;them, they&amp;nbsp;can improve in the lifetime of a product.&amp;nbsp;So actually, not&amp;nbsp;only you could assess them and make sure that they&amp;nbsp;maintain&amp;nbsp;safe,&amp;nbsp;you&amp;nbsp;could also sometimes lower the risk category by finding evidence that these devices are&amp;nbsp;actually becoming&amp;nbsp;more precise and safer.&amp;nbsp;So&amp;nbsp;it can both, you know, heighten the risk&amp;nbsp;category&amp;nbsp;or lower the risk category, and&amp;nbsp;that’s&amp;nbsp;why&amp;nbsp;this continuous testing is so important.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&amp;nbsp;&lt;/strong&gt;Given what you just said, how should regulators handle a device whose algorithm keeps updating itself after approval?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Well, it&amp;nbsp;has to&amp;nbsp;be an iterative process that is&amp;nbsp;feasible&amp;nbsp;and straightforward and that is based on a very efficient, both time efficient and performance efficient, communication between the regulatory authorities and the medical device developers, right. We need to have&amp;nbsp;the sensors&amp;nbsp;in place that spot potential changes, and we need to have&amp;nbsp;the mechanisms&amp;nbsp;in place that allow us to quickly react to these changes both regulatory wise&amp;nbsp;and also&amp;nbsp;in&amp;nbsp;the&amp;nbsp;technological way. &lt;/p&gt;



&lt;p&gt;So&amp;nbsp;I think communication&amp;nbsp;is important,&amp;nbsp;and we need to have&amp;nbsp;the pathways&amp;nbsp;and&amp;nbsp;the feedback&amp;nbsp;loops in the regulation that quickly allow us to&amp;nbsp;monitor&amp;nbsp;these self-learning algorithms and devices.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;It sounds like&amp;nbsp;it’s&amp;nbsp;just …&amp;nbsp;there’s&amp;nbsp;such a delicate balance between advancing technology and really ensuring public safety. You know, if we clamp down too hard, we stifle that innovation. You already touched upon this a bit. But if&amp;nbsp;we’re&amp;nbsp;too lax, we risk unintended consequences. And&amp;nbsp;I’d&amp;nbsp;just love to hear how you think the field is balancing that and any learnings you can share.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;this is&amp;nbsp;very true, and&amp;nbsp;you just touched upon a very central question also in our research and our writing. And this is also the&amp;nbsp;reason why&amp;nbsp;medical device regulation is so fascinating and continues to evolve in response to rapid advancements in technologies, particularly dual technologies&amp;nbsp;regarding&amp;nbsp;digital health, artificial intelligence, for example, and personalized medicine.&lt;/p&gt;



&lt;p&gt;And finding the balance is tricky because also [a] related major future challenge relates to the increasing regulatory jungle and the complex interplay between evolving regulatory landscapes that regulate AI more generally.&lt;/p&gt;



&lt;p&gt;We really need to make sure that the regulatory authorities that deal with this, that need to find the right balance to promote innovation and mitigate and prevent risks, need to have the&amp;nbsp;capacity&amp;nbsp;to do this.&amp;nbsp;So&amp;nbsp;this requires investments, and it also requires new ways to regulate this technology more flexibly, for example through regulatory sandboxes and so on.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Could you just expand upon that a bit and double-click on what it is&amp;nbsp;you’re&amp;nbsp;seeing there? What excites you about&amp;nbsp;what’s&amp;nbsp;happening in that space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes, well, the research of my group at the Center for Advanced Studies in Bioscience Innovation Law is&amp;nbsp;very broad. I mean, we are looking into gene editing technologies. We are looking into new biologics. We are looking into medical&amp;nbsp;devices,&amp;nbsp;as well, obviously, but also other technologies&amp;nbsp;in advanced medical computing.&lt;/p&gt;



&lt;p&gt;And what we see across the line here is that there is an increasing demand for having more adaptive and flexible regulatory frameworks in these&amp;nbsp;new technologies,&amp;nbsp;in particular when&amp;nbsp;they have new uses, regulations that are focusing more on the product rather than the process. And I have recently&amp;nbsp;written&amp;nbsp;a report, for example,&amp;nbsp;for&amp;nbsp;emerging biotechnologies and&amp;nbsp;bio-solutions&amp;nbsp;for the EU commission. And even in that area, regulatory sandboxes are increasingly important, increasingly considered.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;this idea of regulatory sandboxes has been developing originally in the financial sector, and it is now penetrating into&amp;nbsp;other sectors, including synthetic biology, emerging biotechnologies, gene editing, AI, quantum technology, as&amp;nbsp;well. This is&amp;nbsp;basically creating&amp;nbsp;an environment where actors can test&amp;nbsp;new ideas&amp;nbsp;in close collaboration and under the oversight of regulatory authorities.&lt;/p&gt;



&lt;p&gt;But&amp;nbsp;to implement&amp;nbsp;this in the AI sector now also leads us to&amp;nbsp;a&amp;nbsp;lot of questions and challenges. For example, you need to have the&amp;nbsp;capacities&amp;nbsp;of authorities that are governing and&amp;nbsp;monitoring&amp;nbsp;and deciding&amp;nbsp;on these regulatory sandboxes. There are issues relating to competition law, for example, which&amp;nbsp;you&amp;nbsp;call antitrust law in the US, because the question is, who can enter the sandbox and how may they compete after they exit the sandbox? And there are many questions relating to, how&amp;nbsp;should we&amp;nbsp;work with these sandboxes and how&amp;nbsp;should we&amp;nbsp;implement these sandboxes?&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well, Timo, it has just been such a pleasure to speak with you today.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MINSSEN:&lt;/strong&gt;&amp;nbsp;Yes, thank you very much.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now&amp;nbsp;I’m&amp;nbsp;happy to introduce Chad Atalla.&lt;/p&gt;



&lt;p&gt;Chad&amp;nbsp;is&amp;nbsp;senior applied scientist&amp;nbsp;in&amp;nbsp;Microsoft Research&amp;nbsp;New York City’s&amp;nbsp;Sociotechnical Alignment Center, where they contribute to foundational responsible AI research and practical responsible AI solutions for teams across Microsoft.&lt;/p&gt;



&lt;p&gt;Chad, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHAD ATALLA:&lt;/strong&gt;&amp;nbsp;Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;we’ll&amp;nbsp;kick off with a couple questions just to dive right in.&amp;nbsp;So&amp;nbsp;tell me a little bit more about the&amp;nbsp;Sociotechnical Alignment Center,&amp;nbsp;or&amp;nbsp;&lt;em&gt;STAC&lt;/em&gt;? I know it was founded in&amp;nbsp;2022.&amp;nbsp;I’d&amp;nbsp;love to just learn a little bit more about what the group does, how&amp;nbsp;you’re&amp;nbsp;thinking about evaluating AI, and&amp;nbsp;maybe just&amp;nbsp;give us a sense of some of the projects&amp;nbsp;you’re&amp;nbsp;working on.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Yeah, absolutely. The name is quite a mouthful.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;It is!&amp;nbsp;[LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;let’s&amp;nbsp;start by breaking that down and seeing what that means.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Great.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt; So modern AI systems are sociotechnical systems, meaning that the social and technical aspects are deeply intertwined. And&amp;nbsp;we’re interested in aligning the behaviors of these sociotechnical&amp;nbsp;systems with some values.&amp;nbsp;Those could be societal values;&amp;nbsp;they could be regulatory values, organizational values, etc. And to make this alignment happen, we need the ability to evaluate the systems.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;my team is broadly working on an evaluation framework that acknowledges the sociotechnical nature of the technology and the often-abstract nature of the concepts&amp;nbsp;we’re&amp;nbsp;actually interested&amp;nbsp;in evaluating. As you noted,&amp;nbsp;it’s&amp;nbsp;an applied science team, so we split our time between some fundamental research and time to bridge the work into real products across the company. And I also want to note that to power this sort of work, we have an interdisciplinary team drawing upon the social sciences, linguistics, statistics, and,&amp;nbsp;of course, computer science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well,&amp;nbsp;I’m&amp;nbsp;eager to get into our takeaways from the conversation with&amp;nbsp;both Daniel&amp;nbsp;and Timo. But&amp;nbsp;maybe just&amp;nbsp;to double-click on this for a minute, can you talk a bit about some of the overarching goals of the AI evaluations that you noted?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;evaluation is really the act of making valuative judgments based on some evidence, and in the case of AI evaluation, that evidence might be from tests or measurements, right.&amp;nbsp;And the goal of why&amp;nbsp;we’re doing this in the first place is to make decisions and claims most often.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;perhaps I&amp;nbsp;am going to make a claim about a model that&amp;nbsp;I’m&amp;nbsp;producing, and I want to say that&amp;nbsp;it’s&amp;nbsp;better than this other model. Or we are asking whether a certain product is safe to ship.&amp;nbsp;All of these decisions need to be informed by good evaluation and therefore good measurement or testing.&amp;nbsp;And&amp;nbsp;I’ll&amp;nbsp;also note that in&amp;nbsp;the regulatory conversation, &lt;em&gt;risk&lt;/em&gt;&amp;nbsp;is often what we want to evaluate. So that is a goal in and of itself. And&amp;nbsp;I’ll&amp;nbsp;touch more on that later.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;I read a recent&amp;nbsp;paper that you had put out with some of our colleagues from Microsoft Research, from the University of Michigan, and Stanford, and you were arguing that evaluating generative AI is&amp;nbsp;&lt;em&gt;the&lt;/em&gt;&amp;nbsp;social-science measurement challenge.&amp;nbsp;Maybe for&amp;nbsp;those who&amp;nbsp;haven’t&amp;nbsp;read the paper, what does this mean? And can you tell us a little bit more about what motivated you and your coauthors?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So the measurement tasks involved in evaluating generative AI systems are often abstract and contested. So that means they cannot be directly measured and must instead [be] indirectly measured via other observable phenomena. So this is very different than the older machine learning paradigm, where, let’s say, for example, I had a system that took a picture of a traffic light and told you whether it was green, yellow, or red at a given time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If we wanted to evaluate that system, the task is much simpler. But with the modern generative AI systems that are also general purpose, they have open-ended output, and language in a whole chat or multiple paragraphs being outputted can have a lot of different properties. And as I noted, these are general-purpose systems, so we don’t know exactly what task they’re supposed to be carrying out.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;then the question becomes, if I want to make some decision or claim—maybe I&amp;nbsp;want to make a claim that this system has human-level reasoning capabilities—well, what does that mean? Do I have the same impression of what that means as you do? And how do we know whether the downstream, you know, measurements and tests that&amp;nbsp;I’m&amp;nbsp;conducting&amp;nbsp;actually will&amp;nbsp;support my notion of what it means to have human-level reasoning,&amp;nbsp;right?&amp;nbsp;Difficult questions. But luckily, social scientists have been dealing with these exact sorts of challenges for multiple decades in fields like education, political science, and psychometrics. So&amp;nbsp;we’re&amp;nbsp;really&amp;nbsp;attempting&amp;nbsp;to avoid reinventing the wheel here and trying to learn from their past methodologies.&lt;/p&gt;



&lt;p&gt;And so the rest of the paper goes on to delve into&amp;nbsp;a four-level framework, a measurement framework, that’s grounded in the measurement theory from the quantitative social sciences that takes us all the way from these abstract and contested concepts through processes to get much clearer and eventually reach reliable and valid measurements that can power our evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;I love that. I mean,&amp;nbsp;that’s&amp;nbsp;the whole point of this podcast,&amp;nbsp;too,&amp;nbsp;right.&amp;nbsp;Is&amp;nbsp;to really&amp;nbsp;build&amp;nbsp;on those other learnings and frameworks that&amp;nbsp;we’re&amp;nbsp;taking from industries that have been thinking about this for much longer.&amp;nbsp;Maybe from&amp;nbsp;your vantage point, what are some of the biggest day-to-day hurdles in building solid AI evaluations&amp;nbsp;and,&amp;nbsp;I&amp;nbsp;don’t&amp;nbsp;know, do we need more shared standards? Are there&amp;nbsp;bespoke methods? Are those&amp;nbsp;the way to go? I would love&amp;nbsp;to just&amp;nbsp;hear your thoughts on that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;let’s&amp;nbsp;talk about some of those practical challenges. And I want to briefly go back to what I mentioned about risk before, all right.&amp;nbsp;Oftentimes,&amp;nbsp;some of the regulatory environment&amp;nbsp;is requiring practitioners to measure the&amp;nbsp;&lt;em&gt;risk&lt;/em&gt;&amp;nbsp;involved in deploying one of their models or AI systems. Now, risk is importantly a&amp;nbsp;concept that includes both event and impact,&amp;nbsp;right.&amp;nbsp;So&amp;nbsp;there’s&amp;nbsp;the probability of some event occurring. For the case of AI evaluation,&amp;nbsp;perhaps this&amp;nbsp;is us seeing a certain AI behavior&amp;nbsp;exhibited. Then there’s also the severity of the&amp;nbsp;&lt;em&gt;impacts&lt;/em&gt;,&amp;nbsp;and this is a complex chain of effects in the real world that&amp;nbsp;happen&amp;nbsp;to people, organizations, systems, etc., and&amp;nbsp;it’s&amp;nbsp;a lot more challenging to&amp;nbsp;observe&amp;nbsp;the impacts,&amp;nbsp;right.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;if we’re saying that we need to measure risk, we have to measure both the event and the&amp;nbsp;impacts. But realistically, right now, the field is not doing&amp;nbsp;a very good&amp;nbsp;job of&amp;nbsp;actually measuring&amp;nbsp;the impacts. This requires vastly different techniques and methodologies where if I just wanted to measure something about the event itself, I can, you know, do that in a technical sandbox&amp;nbsp;environment&amp;nbsp;and&amp;nbsp;perhaps have&amp;nbsp;some automated methods to detect whether a certain AI behavior is being&amp;nbsp;exhibited. But if I want to measure the impacts? Now,&amp;nbsp;we’re&amp;nbsp;in the realm of needing to have real people involved, and&amp;nbsp;perhaps a&amp;nbsp;longitudinal study where you have interviews, questionnaires, and more qualitative evidence-gathering techniques to&amp;nbsp;truly understand&amp;nbsp;the long-term impacts. So&amp;nbsp;that’s&amp;nbsp;a significant challenge.&lt;/p&gt;



&lt;p&gt;Another is that, you know,&amp;nbsp;let’s&amp;nbsp;say we forget about the impacts for&amp;nbsp;now&amp;nbsp;and we focus on the event side of things. Still, we need datasets, we need&amp;nbsp;annotations,&amp;nbsp;and we need&amp;nbsp;metrics to make this whole thing work. When I say we need datasets, if I want to test whether my system has good mathematical reasoning, what questions should I ask? What are my set of inputs that are relevant? And then when I get&amp;nbsp;the&amp;nbsp;response from the system, how do I annotate them? How do I know if it was a good response that&amp;nbsp;&lt;em&gt;did&lt;/em&gt; demonstrate mathematical reasoning or if it was a mediocre response? And then once I have an annotation of&amp;nbsp;all of these outputs from the AI system, how do I aggregate those all up into a single informative number?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Earlier in this episode, we heard Daniel and&amp;nbsp;Timo walk&amp;nbsp;through the regulatory frameworks in pharma and medical devices.&amp;nbsp;I’d&amp;nbsp;be curious what pieces of those mature systems are already showing up or at least may&amp;nbsp;be bubbling up in AI governance.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Great question. You know, Timo was talking about the pre-market and post-market testing difference. Of course, this is similarly important in the AI evaluation space. But again, these have different methodologies and serve different purposes.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;within the pre-deployment phase, we&amp;nbsp;don’t&amp;nbsp;have evidence of how people are going to use the system. And when we have these general-purpose AI systems,&amp;nbsp;to understand what the risks are, we really need to have a sense of what might happen and how they might be used.&amp;nbsp;So&amp;nbsp;there are&amp;nbsp;significant challenges there where I think we can learn from other fields and how they do pre-market testing. And the difference in that pre- versus post-market testing also ties to testing at&amp;nbsp;different stages&amp;nbsp;in the life cycle.&lt;/p&gt;



&lt;p&gt;For AI systems, we already see some regulations saying you need to start with the base model and do some evaluation of the base model, some basic attributes, some core attributes,&amp;nbsp;of that base model before you start putting it into any real products. But once we have a product in mind, we have a user base in mind, we have a specific task—like maybe we’re going to integrate this model into Outlook and it’s going to help you write&amp;nbsp;emails—now we suddenly have a much crisper picture of how the system will interact with the world around it. And again, at that stage, we need to think about another round of evaluation.&lt;/p&gt;



&lt;p&gt;Another part that jumped out to me in what they were saying about pharmaceuticals is that sometimes approvals can be based on surrogate endpoints.&amp;nbsp;So&amp;nbsp;this is like&amp;nbsp;we’re&amp;nbsp;choosing some&amp;nbsp;heuristic.&amp;nbsp;Instead of measuring the long-term impact, which is what we&amp;nbsp;actually care&amp;nbsp;about,&amp;nbsp;perhaps we&amp;nbsp;have a proxy that we&amp;nbsp;feel like&amp;nbsp;is a good enough indicator of what that long-term impact might look like.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is occurring in the AI evaluation space right now and is often perhaps even the default here since&amp;nbsp;we’re not seeing that many studies of the long-term impact itself. We are seeing, instead, folks constructing these heuristics or proxies and saying if I see this behavior happen,&amp;nbsp;I’m&amp;nbsp;going to&amp;nbsp;&lt;em&gt;assume&lt;/em&gt;&amp;nbsp;that it&amp;nbsp;indicates&amp;nbsp;this sort of impact will happen downstream. And&amp;nbsp;that’s&amp;nbsp;great.&amp;nbsp;It’s&amp;nbsp;one of the techniques that was used to speed up and reduce the barrier to innovation in&amp;nbsp;the other&amp;nbsp;fields. And I think&amp;nbsp;it’s&amp;nbsp;great that we are applying that in the AI evaluation space. But&amp;nbsp;special care&amp;nbsp;is,&amp;nbsp;of course, needed to ensure that those heuristics and proxies you’re&amp;nbsp;using are reasonable indicators of the greater outcome&amp;nbsp;you’re&amp;nbsp;looking for.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;What are some of the promising ideas from&amp;nbsp;maybe pharma&amp;nbsp;or med device regulation that maybe haven’t&amp;nbsp;made it to AI testing yet and&amp;nbsp;maybe should? And where would you urge technologists, policymakers,&amp;nbsp;and researchers to focus their energy next?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;Well, one of the key things that jumped out to me in the discussion about pharmaceuticals was driving home the emphasis that there&amp;nbsp;is&amp;nbsp;a&amp;nbsp;&lt;em&gt;holistic&lt;/em&gt;&amp;nbsp;focus on safety&amp;nbsp;&lt;em&gt;and&lt;/em&gt;&amp;nbsp;efficacy. These go hand in hand&amp;nbsp;and decisions must be made while considering both pieces of the picture. I would like to see that further emphasized in the AI evaluation space.&lt;/p&gt;



&lt;p&gt;Often,&amp;nbsp;we&amp;nbsp;are seeing&amp;nbsp;evaluations of risk being separated from evaluations of&amp;nbsp;performance or quality&amp;nbsp;or efficacy, but these two pieces of the puzzle really are not enough for us to make informed decisions independently.&amp;nbsp;And that ties back into my desire to really also see us measuring the impacts.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;we see Phase 3 trials as something that occurs in the medical devices and pharmaceuticals field. That’s not something that we are doing an equivalent of in the AI evaluation space at this time.&amp;nbsp;These are really&amp;nbsp;cost intensive. They can last years and really involve careful monitoring of that holistic picture of safety and efficacy. And realistically, we are not going to be able to put that on the critical path to getting specific individual AI models or AI systems vetted before they&amp;nbsp;go out&amp;nbsp;into the world. However, I would love to see a world in which this sort of work is prioritized&amp;nbsp;and funded or&amp;nbsp;required. Think of how, with&amp;nbsp;social media, it took quite a long time for us to understand that there are some long-term negative impacts on mental health, and we have the opportunity now, while the AI wave is still building,&amp;nbsp;to start prioritizing and funding this sort of work. Let it run in the background and as soon as possible develop a good understanding of the subtle, long-term effects.&lt;/p&gt;



&lt;p&gt;More broadly, I would love to see us focus on reliability and validity of the evaluations&amp;nbsp;we’re&amp;nbsp;conducting because trust in these decisions and claims is important. If we&amp;nbsp;don’t&amp;nbsp;focus on building reliable, valid, and trustworthy evaluations,&amp;nbsp;we’re&amp;nbsp;just going to continue to be flooded by a bunch of competing, conflicting, and&amp;nbsp;largely meaningless&amp;nbsp;AI evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;In a number of the discussions we’ve had on this podcast, we talked about how it’s not just one entity that really needs to ensure safety across the board,&amp;nbsp;and I’d&amp;nbsp;just love to hear from you how you think about some of those ecosystem collaborations, and you know, from across … where we think about ourselves as more of a platform company or places that these AI models are being deployed more at the application level. Tell me a little bit about how you think about,&amp;nbsp;sort&amp;nbsp;of, stakeholders in that mix and where responsibility lies across the board.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;It’s&amp;nbsp;interesting. In this age of general-purpose AI technologies,&amp;nbsp;we’re&amp;nbsp;often&amp;nbsp;seeing&amp;nbsp;one company or organization&amp;nbsp;being responsible for&amp;nbsp;building the foundational model. And then many, many other people will take that model and build it into specific products that are designed for specific tasks and contexts.&lt;/p&gt;



&lt;p&gt;Of course,&amp;nbsp;in that, we already see that there is&amp;nbsp;a responsibility&amp;nbsp;of the owners of that foundational model to do some testing of the central model before they distribute it broadly. And then again, there is responsibility of all of the downstream individuals digesting that and turning it into products to consider the specific contexts that they are deploying into and how that may affect the risks we’re concerned with or the types of quality and safety and performance we need to evaluate.&lt;/p&gt;



&lt;p&gt;Again, because that field of risks we may be concerned with is so broad, some of them also require an immense amount of&amp;nbsp;expertise.&amp;nbsp;Let’s&amp;nbsp;think about whether AI systems can enable people to create dangerous chemicals or dangerous weapons at home. It’s not that every AI practitioner is going to have the knowledge to evaluate this, so in some of those cases, we really need third-party experts, people who are experts in chemistry, biology, etc., to come in and evaluate certain systems and models for those specific risks,&amp;nbsp;as well.&lt;/p&gt;



&lt;p&gt;So&amp;nbsp;I think there&amp;nbsp;are many reasons why multiple stakeholders need to be involved, partly from who owns what and&amp;nbsp;is responsible for&amp;nbsp;what and partly from the perspective of who has the&amp;nbsp;expertise&amp;nbsp;to meaningfully construct the evaluations that we need.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Well, Chad, this has just been great to connect, and in a few of our discussions,&amp;nbsp;we’ve&amp;nbsp;done a bit of a lightning round, so&amp;nbsp;I’d&amp;nbsp;love to just hear your&amp;nbsp;30-second responses to a few of these questions. Perhaps&amp;nbsp;favorite&amp;nbsp;evaluation&amp;nbsp;you’ve&amp;nbsp;run so far this year?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;So&amp;nbsp;I’ve&amp;nbsp;been involved in trying to evaluate some language models for whether they&amp;nbsp;&lt;em&gt;infer&lt;/em&gt;&amp;nbsp;sensitive attributes about people. So&amp;nbsp;perhaps&amp;nbsp;you’re&amp;nbsp;chatting with a&amp;nbsp;chatbot,&amp;nbsp;and it infers your religion or sexuality based on things&amp;nbsp;you’re&amp;nbsp;saying or how you sound,&amp;nbsp;right.&amp;nbsp;And in working to evaluate this, we&amp;nbsp;encounter&amp;nbsp;a lot of interesting questions. Or,&amp;nbsp;like,&amp;nbsp;what is a sensitive attribute? What makes these attributes sensitive, and what are the differences that make it inappropriate for an AI system to infer these things about a person? Whereas realistically, whenever I meet a person on the street, my&amp;nbsp;brain is&amp;nbsp;immediately&amp;nbsp;forming&amp;nbsp;first impressions and some assumptions about these people.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;a very interesting&amp;nbsp;and thought-provoking evaluation to conduct and think about the norms that we place upon&amp;nbsp;&lt;em&gt;people&lt;/em&gt;&amp;nbsp;interacting with other people and the norms we place upon&amp;nbsp;&lt;em&gt;AI systems&lt;/em&gt;&amp;nbsp;interacting with other people.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;That’s&amp;nbsp;fascinating!&amp;nbsp;I’d&amp;nbsp;love to hear the AI&amp;nbsp;buzzword&amp;nbsp;you’d&amp;nbsp;retire tomorrow.&amp;nbsp;[LAUGHTER]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;I would love to see the term “bias” being&amp;nbsp;used less when referring to fairness-related issues and systems. Bias happens to be a highly overloaded term in statistics and machine learning and has a lot of technical meanings and just&amp;nbsp;fails to&amp;nbsp;perfectly capture what we mean in the AI risk sense.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;And last one. One metric&amp;nbsp;we’re&amp;nbsp;not tracking enough.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ATALLA:&lt;/strong&gt;&amp;nbsp;I would say &lt;em&gt;over-blocking&lt;/em&gt;, and this comes into that connection between the holistic picture of safety and efficacy. It’s too easy to produce systems that throw safety to the wind and focus purely on utility or achieving some goal, but simultaneously, the other side of the picture is possible, where we can clamp down too hard and reduce the utility of our systems and block even benign and useful outputs just because they border on something sensitive.&amp;nbsp;So&amp;nbsp;it’s&amp;nbsp;important for us to track that over-blocking and actively track that tradeoff between safety and efficacy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt;&amp;nbsp;Yeah, we talk a lot about this on the podcast,&amp;nbsp;too,&amp;nbsp;of how do you both make things safe but also ensure innovation can&amp;nbsp;thrive,&amp;nbsp;and&amp;nbsp;I think you&amp;nbsp;hit the nail on the head with that last piece.&lt;/p&gt;



&lt;p&gt;[MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Well, Chad, this was&amp;nbsp;really terrific. Thanks for joining us and thanks for your work and your&amp;nbsp;perspectives. And another big thanks to Daniel and Timo for setting the stage earlier in the podcast.&lt;/p&gt;



&lt;p&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI. &lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/</guid><pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] CoreWeave acquires data center provider Core Scientific in $9B stock deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/07/coreweave-acquires-data-center-provider-core-scientific-in-9b-stock-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/cloud-computing-getty.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CoreWeave announced Monday that it signed a $9 billion all-stock deal to acquire Core Scientific, a data center infrastructure provider.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result of the deal, CoreWeave says it will gain access to more than a gigawatt of data center capacity — enough energy to power more than 850,000 homes — that it can rent out for AI training and inference workloads. Much like CoreWeave, Core Scientific previously offered Bitcoin mining services, but now its GPUs will run and train generative AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cloud infrastructure providers are racing to grow their data center footprint to keep up with the seemingly never-ending computational demands of AI companies. Bloomberg reported last week that OpenAI struck a deal to rent an additional 4.5 gigawatts worth of data center capacity from Oracle, expanding on the two companies’ already massive Stargate infrastructure deal.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/cloud-computing-getty.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CoreWeave announced Monday that it signed a $9 billion all-stock deal to acquire Core Scientific, a data center infrastructure provider.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result of the deal, CoreWeave says it will gain access to more than a gigawatt of data center capacity — enough energy to power more than 850,000 homes — that it can rent out for AI training and inference workloads. Much like CoreWeave, Core Scientific previously offered Bitcoin mining services, but now its GPUs will run and train generative AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cloud infrastructure providers are racing to grow their data center footprint to keep up with the seemingly never-ending computational demands of AI companies. Bloomberg reported last week that OpenAI struck a deal to rent an additional 4.5 gigawatts worth of data center capacity from Oracle, expanding on the two companies’ already massive Stargate infrastructure deal.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/07/coreweave-acquires-data-center-provider-core-scientific-in-9b-stock-deal/</guid><pubDate>Mon, 07 Jul 2025 17:37:09 +0000</pubDate></item><item><title>[NEW] Tennis players criticize AI technology used by Wimbledon (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/07/tennis-players-criticize-ai-technology-used-by-wimbledon/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2223604597.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Some tennis players are not happy with Wimbledon’s new AI line judges, as reported by The Telegraph.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the first year the prestigious tennis tournament, which is still ongoing, replaced human line judges, who determine if a ball is in or out, with an electronic line calling system (ELC). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Numerous players criticized the AI technology, mostly for making incorrect calls, leading to them losing points. Notably, British tennis star Emma Raducanu called out the technology for missing a ball that her opponent hit out, but instead had to be played as if it were in. On a television replay, the ball indeed looked out, the Telegraph reported.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jack Draper, the British No. 1, also said he felt some line calls were wrong, saying he did not think the AI technology was “100 percent accurate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Player Ben Shelton had to speed up his match after being told that the new AI line system was about to stop working because of the dimming sunlight. Elsewhere, players said they couldn’t hear the new automated speaker system, with one deaf player saying that without the human hand signals from the line judges, she was unable to tell when she won a point or not.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The technology also met a blip at a key point during a match this weekend between British player Sonay Kartal and the Russian Anastasia Pavlyuchenkova, where a ball went out, but the technology failed to make the call. The umpire had to step in to stop the rally and told the players to replay the point because the ELC failed to track the point. Wimbledon later apologized, saying it was a “human error,” and that the technology was accidentally shut off during the match.&amp;nbsp;It also adjusted the technology so that, ideally,  the mistake could not be repeated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Debbie Jevans, chair of the All England Club, the organization that hosts Wimbledon, hit back at Raducanu and Draper, saying, “When we did have linesmen, we were constantly asked why we didn’t have electronic line calling because it’s more accurate than the rest of the tour.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;We’ve reached out to Wimbledon for comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is not the first time the AI technology has come under fire as tennis tournaments continue to either partially or fully adopt automated systems. Alexander Zverev, a German player, called out the same automated line judging technology back in April, posting a picture to Instagram showing where a ball called in was very much out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The critiques reveal the friction in completely replacing humans with AI, making the case for why a human-AI balance is perhaps necessary as more organizations adopt such technology. Just recently, the company Klarna said it was looking to hire human workers after previously making a push for automated jobs.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2223604597.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Some tennis players are not happy with Wimbledon’s new AI line judges, as reported by The Telegraph.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the first year the prestigious tennis tournament, which is still ongoing, replaced human line judges, who determine if a ball is in or out, with an electronic line calling system (ELC). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Numerous players criticized the AI technology, mostly for making incorrect calls, leading to them losing points. Notably, British tennis star Emma Raducanu called out the technology for missing a ball that her opponent hit out, but instead had to be played as if it were in. On a television replay, the ball indeed looked out, the Telegraph reported.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jack Draper, the British No. 1, also said he felt some line calls were wrong, saying he did not think the AI technology was “100 percent accurate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Player Ben Shelton had to speed up his match after being told that the new AI line system was about to stop working because of the dimming sunlight. Elsewhere, players said they couldn’t hear the new automated speaker system, with one deaf player saying that without the human hand signals from the line judges, she was unable to tell when she won a point or not.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The technology also met a blip at a key point during a match this weekend between British player Sonay Kartal and the Russian Anastasia Pavlyuchenkova, where a ball went out, but the technology failed to make the call. The umpire had to step in to stop the rally and told the players to replay the point because the ELC failed to track the point. Wimbledon later apologized, saying it was a “human error,” and that the technology was accidentally shut off during the match.&amp;nbsp;It also adjusted the technology so that, ideally,  the mistake could not be repeated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Debbie Jevans, chair of the All England Club, the organization that hosts Wimbledon, hit back at Raducanu and Draper, saying, “When we did have linesmen, we were constantly asked why we didn’t have electronic line calling because it’s more accurate than the rest of the tour.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;We’ve reached out to Wimbledon for comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is not the first time the AI technology has come under fire as tennis tournaments continue to either partially or fully adopt automated systems. Alexander Zverev, a German player, called out the same automated line judging technology back in April, posting a picture to Instagram showing where a ball called in was very much out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The critiques reveal the friction in completely replacing humans with AI, making the case for why a human-AI balance is perhaps necessary as more organizations adopt such technology. Just recently, the company Klarna said it was looking to hire human workers after previously making a push for automated jobs.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/07/tennis-players-criticize-ai-technology-used-by-wimbledon/</guid><pubDate>Mon, 07 Jul 2025 18:00:00 +0000</pubDate></item></channel></rss>