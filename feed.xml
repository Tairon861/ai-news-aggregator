<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 20 Nov 2025 01:44:07 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>OpenCV founders launch AI video startup to take on OpenAI and Google (AI | VentureBeat)</title><link>https://venturebeat.com/ai/opencv-founders-launch-ai-video-startup-to-take-on-openai-and-google</link><description>[unable to retrieve full-text content]&lt;p&gt;A new artificial intelligence startup founded by the creators of &lt;a href="https://opencv.org/"&gt;&lt;u&gt;the world&amp;#x27;s most widely used computer vision library&lt;/u&gt;&lt;/a&gt; has emerged from stealth with technology that generates realistic human-centric videos up to five minutes long — a dramatic leap beyond the capabilities of rivals including OpenAI&amp;#x27;s &lt;a href="https://openai.com/sora/"&gt;&lt;u&gt;Sora&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt;, which launched Tuesday with $2 million in funding, is introducing Model 2.0, a video generation system that addresses one of the most significant limitations plaguing the nascent AI video industry: duration. While OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; tops out at 25 seconds and most competing models generate clips of 10 seconds or less, CraftStory&amp;#x27;s system can produce continuous, coherent video performances that run as long as a typical YouTube tutorial or product demonstration.&lt;/p&gt;&lt;p&gt;The breakthrough could unlock substantial commercial value for enterprises struggling to scale video production for training, marketing, and customer education — markets where brief AI-generated clips have proven inadequate despite their visual polish.&lt;/p&gt;&lt;p&gt;&amp;quot;If you really try to create a video with one of these video generation systems, you find that a lot of the times you want to implement a certain creative vision, and regardless of how detailed the instructions are, the systems basically ignore a part of your instructions,&amp;quot; said Victor Erukhimov, CraftStory&amp;#x27;s founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;We developed a system that can generate videos basically as long as you need them.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How parallel processing solves the long-form video problem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s advance rests on what the company describes as a parallelized diffusion architecture — a fundamentally different approach to how AI models generate video compared to the sequential methods employed by most competitors.&lt;/p&gt;&lt;p&gt;Traditional video generation models work by running diffusion algorithms on increasingly large three-dimensional volumes where time represents the third axis. To generate a longer video, these models require proportionally larger networks, more training data, and significantly more computational resources.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt; instead runs multiple smaller diffusion algorithms simultaneously across the entire duration of the video, with bidirectional constraints connecting them. &amp;quot;The latter part of the video can influence the former part of the video too,&amp;quot; Erukhimov explained. &amp;quot;And this is pretty important, because if you do it one by one, then an artifact that appears in the first part propagates to the second one, and then it accumulates.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than generating eight seconds and then stitching on additional segments, CraftStory&amp;#x27;s system processes all five minutes concurrently through interconnected diffusion processes.&lt;/p&gt;&lt;p&gt;Crucially, CraftStory trained its model on proprietary footage rather than relying solely on internet-scraped videos. The company hired studios to shoot actors using high-frame-rate camera systems that capture crisp detail even in fast-moving elements like fingers — avoiding the motion blur inherent in standard 30-frames-per-second YouTube clips.&lt;/p&gt;&lt;p&gt;&amp;quot;What we showed is that you don&amp;#x27;t need a lot of data and you don&amp;#x27;t need a lot of training budget to create high quality videos,&amp;quot; Erukhimov said. &amp;quot;You just need high quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;Model 2.0 currently operates as a video-to-video system: users upload a still image to animate and a &amp;quot;driving video&amp;quot; containing a person whose movements the AI will replicate. CraftStory provides preset driving videos shot with professional actors, who receive revenue shares when their motion data is used, or users can upload their own footage.&lt;/p&gt;&lt;p&gt;The system generates 30-second clips at low resolution in approximately 15 minutes. An advanced lip-sync system synchronizes mouth movements to scripts or audio tracks, while gesture alignment algorithms ensure body language matches speech rhythm and emotional tone.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Fighting a war chest battle with $2 million against billions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s funding comes almost entirely from &lt;a href="https://finance.yahoo.com/news/2-25-billion-exit-taught-130300997.html"&gt;&lt;u&gt;Andrew Filev&lt;/u&gt;&lt;/a&gt;, who sold his project management software company Wrike to Citrix for &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;&lt;u&gt;$2.25 billion&lt;/u&gt;&lt;/a&gt; in 2021 and now runs &lt;a href="https://zencoder.ai/"&gt;&lt;u&gt;Zencoder&lt;/u&gt;&lt;/a&gt;, an AI coding company. The modest raise stands in stark contrast to the billions flowing into competing efforts — OpenAI has &lt;a href="https://www.reuters.com/technology/artificial-intelligence/openai-closes-66-billion-funding-haul-valuation-157-billion-with-investment-2024-10-02/"&gt;&lt;u&gt;raised over $6 billion&lt;/u&gt;&lt;/a&gt; in its latest funding round alone.&lt;/p&gt;&lt;p&gt;Erukhimov pushed back on the notion that massive capital is prerequisite for success. &amp;quot;I don&amp;#x27;t necessarily buy the thesis that compute is the path to success,&amp;quot; he said. &amp;quot;It definitely helps if you have compute. But if you raise a billion dollars on a PowerPoint, in the end, no one is happy, neither the founders nor the investors.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev defended the David-versus-Goliath approach. &amp;quot;When you invest in startups, you&amp;#x27;re fundamentally betting on people,&amp;quot; he said in an interview with VentureBeat. &amp;quot;To paraphrase Margaret Mead: never underestimate what a small group of thoughtful, committed engineers and scientists can build.&amp;quot;&lt;/p&gt;&lt;p&gt;He argued that CraftStory benefits from a focused strategy. &amp;quot;The big labs are in an arms race to build general-purpose video foundation models,&amp;quot; Filev said. &amp;quot;CraftStory is riding that wave and going very deep into a specific format: long-form, engaging, human-centric video.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why computer vision expertise matters in generative AI video&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Erukhimov&amp;#x27;s credibility stems from his deep roots in computer vision rather than the transformer architectures that have dominated recent AI advances. He was an early contributor to &lt;a href="https://opencv.org/"&gt;&lt;u&gt;OpenCV&lt;/u&gt;&lt;/a&gt; — the Open Source Computer Vision Library that has become the de facto standard for computer vision applications, with over &lt;a href="https://github.com/opencv/opencv"&gt;&lt;u&gt;84,000 stars on GitHub&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;When Intel reduced its support for OpenCV in the mid-2000s, Erukhimov co-founded Itseez with the explicit goal of maintaining and advancing the library. The company expanded OpenCV significantly and pivoted toward automotive safety systems before Intel acquired it in 2016.&lt;/p&gt;&lt;p&gt;Filev said this background is precisely what makes Erukhimov well-positioned for video generation. &amp;quot;What people sometimes miss is that generative AI video isn&amp;#x27;t just about the generative part. It&amp;#x27;s about understanding motion, facial dynamics, temporal coherence, and how humans actually move,&amp;quot; Filev said. &amp;quot;Victor has spent his career mastering exactly those problems.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise focus targets training videos and product demos&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While much of the public excitement around AI video generation has centered on creative tools for consumers, CraftStory is pursuing a decidedly enterprise-focused strategy.&lt;/p&gt;&lt;p&gt;&amp;quot;We are definitely thinking about B2B more than consumer,&amp;quot; Erukhimov said. &amp;quot;We&amp;#x27;re thinking about companies, specifically software companies, being able to make cool training videos and product videos and launch videos.&amp;quot;&lt;/p&gt;&lt;p&gt;The logic is straightforward: corporate training, product tutorials, and customer education videos often run several minutes and require consistent quality throughout. A 10-second AI clip cannot effectively demonstrate how to use enterprise software or explain a complex product feature.&lt;/p&gt;&lt;p&gt;&amp;quot;If you need a longer-form video, then you should go with us,&amp;quot; Erukhimov said. &amp;quot;We can create up to five minutes, consistent video, high quality.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev echoed this assessment. &amp;quot;One huge gap in this market is the lack of models that can generate consistent videos over longer sequences — and that&amp;#x27;s extremely important for real-world use,&amp;quot; he said. &amp;quot;If you&amp;#x27;re creating a commercial for your company, a 10-second video, no matter how good it looks, just isn&amp;#x27;t enough. You need 30 seconds, you need two minutes — you need more.&amp;quot;&lt;/p&gt;&lt;p&gt;The company anticipates cost savings for customers. Filev suggested that &amp;quot;a small business owner could create content in minutes that previously would have cost $20,000 and taken two months to produce.&amp;quot;&lt;/p&gt;&lt;p&gt;CraftStory is also courting creative agencies that produce video content for corporate clients, with the value proposition centered on cost and speed: agencies can record an actor on camera and transform that footage into a finished AI video, rather than managing expensive multi-day shoots.&lt;/p&gt;&lt;p&gt;The next major development on CraftStory&amp;#x27;s roadmap is a text-to-video model that would allow users to generate long-form content directly from scripts. The team is also developing support for moving-camera scenarios, including the popular &amp;quot;walk-and-talk&amp;quot; format common in high-end advertising.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Where CraftStory fits in a fragmented competitive landscape&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory enters a crowded and rapidly evolving market. OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt;, while not yet publicly available, has generated significant buzz. Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo models&lt;/u&gt;&lt;/a&gt; are advancing quickly. &lt;a href="https://runwayml.com/"&gt;&lt;u&gt;Runway&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pika.art/login"&gt;&lt;u&gt;Pika&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://stability.ai/"&gt;&lt;u&gt;Stability AI &lt;/u&gt;&lt;/a&gt;all offer video generation tools with different capabilities.&lt;/p&gt;&lt;p&gt;Erukhimov acknowledged the competitive pressure but emphasized that CraftStory serves a distinct niche focused on human-centric videos. He positioned rapid innovation and market capture as the company&amp;#x27;s primary strategy rather than relying on technical moats.&lt;/p&gt;&lt;p&gt;Filev sees the market fragmenting into distinct layers, with large tech companies serving as &amp;quot;API providers of powerful, general-purpose generation models&amp;quot; while specialized players like CraftStory focus on specific use cases. &amp;quot;If the big players are building the engines, CraftStory is building the production studio and assembly line on top,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Model 2.0 is available now at app.craftstory.com/model-2.0, with the company offering early access to users and enterprises interested in testing the technology. Whether a lightly funded startup can capture meaningful market share against deep-pocketed incumbents remains uncertain, but Erukhimov is characteristically confident about the opportunity ahead.&lt;/p&gt;&lt;p&gt;&amp;quot;AI-generated video will soon become the primary way companies communicate their stories,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;A new artificial intelligence startup founded by the creators of &lt;a href="https://opencv.org/"&gt;&lt;u&gt;the world&amp;#x27;s most widely used computer vision library&lt;/u&gt;&lt;/a&gt; has emerged from stealth with technology that generates realistic human-centric videos up to five minutes long — a dramatic leap beyond the capabilities of rivals including OpenAI&amp;#x27;s &lt;a href="https://openai.com/sora/"&gt;&lt;u&gt;Sora&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt;, which launched Tuesday with $2 million in funding, is introducing Model 2.0, a video generation system that addresses one of the most significant limitations plaguing the nascent AI video industry: duration. While OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; tops out at 25 seconds and most competing models generate clips of 10 seconds or less, CraftStory&amp;#x27;s system can produce continuous, coherent video performances that run as long as a typical YouTube tutorial or product demonstration.&lt;/p&gt;&lt;p&gt;The breakthrough could unlock substantial commercial value for enterprises struggling to scale video production for training, marketing, and customer education — markets where brief AI-generated clips have proven inadequate despite their visual polish.&lt;/p&gt;&lt;p&gt;&amp;quot;If you really try to create a video with one of these video generation systems, you find that a lot of the times you want to implement a certain creative vision, and regardless of how detailed the instructions are, the systems basically ignore a part of your instructions,&amp;quot; said Victor Erukhimov, CraftStory&amp;#x27;s founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;We developed a system that can generate videos basically as long as you need them.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How parallel processing solves the long-form video problem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s advance rests on what the company describes as a parallelized diffusion architecture — a fundamentally different approach to how AI models generate video compared to the sequential methods employed by most competitors.&lt;/p&gt;&lt;p&gt;Traditional video generation models work by running diffusion algorithms on increasingly large three-dimensional volumes where time represents the third axis. To generate a longer video, these models require proportionally larger networks, more training data, and significantly more computational resources.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt; instead runs multiple smaller diffusion algorithms simultaneously across the entire duration of the video, with bidirectional constraints connecting them. &amp;quot;The latter part of the video can influence the former part of the video too,&amp;quot; Erukhimov explained. &amp;quot;And this is pretty important, because if you do it one by one, then an artifact that appears in the first part propagates to the second one, and then it accumulates.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than generating eight seconds and then stitching on additional segments, CraftStory&amp;#x27;s system processes all five minutes concurrently through interconnected diffusion processes.&lt;/p&gt;&lt;p&gt;Crucially, CraftStory trained its model on proprietary footage rather than relying solely on internet-scraped videos. The company hired studios to shoot actors using high-frame-rate camera systems that capture crisp detail even in fast-moving elements like fingers — avoiding the motion blur inherent in standard 30-frames-per-second YouTube clips.&lt;/p&gt;&lt;p&gt;&amp;quot;What we showed is that you don&amp;#x27;t need a lot of data and you don&amp;#x27;t need a lot of training budget to create high quality videos,&amp;quot; Erukhimov said. &amp;quot;You just need high quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;Model 2.0 currently operates as a video-to-video system: users upload a still image to animate and a &amp;quot;driving video&amp;quot; containing a person whose movements the AI will replicate. CraftStory provides preset driving videos shot with professional actors, who receive revenue shares when their motion data is used, or users can upload their own footage.&lt;/p&gt;&lt;p&gt;The system generates 30-second clips at low resolution in approximately 15 minutes. An advanced lip-sync system synchronizes mouth movements to scripts or audio tracks, while gesture alignment algorithms ensure body language matches speech rhythm and emotional tone.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Fighting a war chest battle with $2 million against billions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s funding comes almost entirely from &lt;a href="https://finance.yahoo.com/news/2-25-billion-exit-taught-130300997.html"&gt;&lt;u&gt;Andrew Filev&lt;/u&gt;&lt;/a&gt;, who sold his project management software company Wrike to Citrix for &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;&lt;u&gt;$2.25 billion&lt;/u&gt;&lt;/a&gt; in 2021 and now runs &lt;a href="https://zencoder.ai/"&gt;&lt;u&gt;Zencoder&lt;/u&gt;&lt;/a&gt;, an AI coding company. The modest raise stands in stark contrast to the billions flowing into competing efforts — OpenAI has &lt;a href="https://www.reuters.com/technology/artificial-intelligence/openai-closes-66-billion-funding-haul-valuation-157-billion-with-investment-2024-10-02/"&gt;&lt;u&gt;raised over $6 billion&lt;/u&gt;&lt;/a&gt; in its latest funding round alone.&lt;/p&gt;&lt;p&gt;Erukhimov pushed back on the notion that massive capital is prerequisite for success. &amp;quot;I don&amp;#x27;t necessarily buy the thesis that compute is the path to success,&amp;quot; he said. &amp;quot;It definitely helps if you have compute. But if you raise a billion dollars on a PowerPoint, in the end, no one is happy, neither the founders nor the investors.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev defended the David-versus-Goliath approach. &amp;quot;When you invest in startups, you&amp;#x27;re fundamentally betting on people,&amp;quot; he said in an interview with VentureBeat. &amp;quot;To paraphrase Margaret Mead: never underestimate what a small group of thoughtful, committed engineers and scientists can build.&amp;quot;&lt;/p&gt;&lt;p&gt;He argued that CraftStory benefits from a focused strategy. &amp;quot;The big labs are in an arms race to build general-purpose video foundation models,&amp;quot; Filev said. &amp;quot;CraftStory is riding that wave and going very deep into a specific format: long-form, engaging, human-centric video.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why computer vision expertise matters in generative AI video&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Erukhimov&amp;#x27;s credibility stems from his deep roots in computer vision rather than the transformer architectures that have dominated recent AI advances. He was an early contributor to &lt;a href="https://opencv.org/"&gt;&lt;u&gt;OpenCV&lt;/u&gt;&lt;/a&gt; — the Open Source Computer Vision Library that has become the de facto standard for computer vision applications, with over &lt;a href="https://github.com/opencv/opencv"&gt;&lt;u&gt;84,000 stars on GitHub&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;When Intel reduced its support for OpenCV in the mid-2000s, Erukhimov co-founded Itseez with the explicit goal of maintaining and advancing the library. The company expanded OpenCV significantly and pivoted toward automotive safety systems before Intel acquired it in 2016.&lt;/p&gt;&lt;p&gt;Filev said this background is precisely what makes Erukhimov well-positioned for video generation. &amp;quot;What people sometimes miss is that generative AI video isn&amp;#x27;t just about the generative part. It&amp;#x27;s about understanding motion, facial dynamics, temporal coherence, and how humans actually move,&amp;quot; Filev said. &amp;quot;Victor has spent his career mastering exactly those problems.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise focus targets training videos and product demos&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While much of the public excitement around AI video generation has centered on creative tools for consumers, CraftStory is pursuing a decidedly enterprise-focused strategy.&lt;/p&gt;&lt;p&gt;&amp;quot;We are definitely thinking about B2B more than consumer,&amp;quot; Erukhimov said. &amp;quot;We&amp;#x27;re thinking about companies, specifically software companies, being able to make cool training videos and product videos and launch videos.&amp;quot;&lt;/p&gt;&lt;p&gt;The logic is straightforward: corporate training, product tutorials, and customer education videos often run several minutes and require consistent quality throughout. A 10-second AI clip cannot effectively demonstrate how to use enterprise software or explain a complex product feature.&lt;/p&gt;&lt;p&gt;&amp;quot;If you need a longer-form video, then you should go with us,&amp;quot; Erukhimov said. &amp;quot;We can create up to five minutes, consistent video, high quality.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev echoed this assessment. &amp;quot;One huge gap in this market is the lack of models that can generate consistent videos over longer sequences — and that&amp;#x27;s extremely important for real-world use,&amp;quot; he said. &amp;quot;If you&amp;#x27;re creating a commercial for your company, a 10-second video, no matter how good it looks, just isn&amp;#x27;t enough. You need 30 seconds, you need two minutes — you need more.&amp;quot;&lt;/p&gt;&lt;p&gt;The company anticipates cost savings for customers. Filev suggested that &amp;quot;a small business owner could create content in minutes that previously would have cost $20,000 and taken two months to produce.&amp;quot;&lt;/p&gt;&lt;p&gt;CraftStory is also courting creative agencies that produce video content for corporate clients, with the value proposition centered on cost and speed: agencies can record an actor on camera and transform that footage into a finished AI video, rather than managing expensive multi-day shoots.&lt;/p&gt;&lt;p&gt;The next major development on CraftStory&amp;#x27;s roadmap is a text-to-video model that would allow users to generate long-form content directly from scripts. The team is also developing support for moving-camera scenarios, including the popular &amp;quot;walk-and-talk&amp;quot; format common in high-end advertising.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Where CraftStory fits in a fragmented competitive landscape&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory enters a crowded and rapidly evolving market. OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt;, while not yet publicly available, has generated significant buzz. Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo models&lt;/u&gt;&lt;/a&gt; are advancing quickly. &lt;a href="https://runwayml.com/"&gt;&lt;u&gt;Runway&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pika.art/login"&gt;&lt;u&gt;Pika&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://stability.ai/"&gt;&lt;u&gt;Stability AI &lt;/u&gt;&lt;/a&gt;all offer video generation tools with different capabilities.&lt;/p&gt;&lt;p&gt;Erukhimov acknowledged the competitive pressure but emphasized that CraftStory serves a distinct niche focused on human-centric videos. He positioned rapid innovation and market capture as the company&amp;#x27;s primary strategy rather than relying on technical moats.&lt;/p&gt;&lt;p&gt;Filev sees the market fragmenting into distinct layers, with large tech companies serving as &amp;quot;API providers of powerful, general-purpose generation models&amp;quot; while specialized players like CraftStory focus on specific use cases. &amp;quot;If the big players are building the engines, CraftStory is building the production studio and assembly line on top,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Model 2.0 is available now at app.craftstory.com/model-2.0, with the company offering early access to users and enterprises interested in testing the technology. Whether a lightly funded startup can capture meaningful market share against deep-pocketed incumbents remains uncertain, but Erukhimov is characteristically confident about the opportunity ahead.&lt;/p&gt;&lt;p&gt;&amp;quot;AI-generated video will soon become the primary way companies communicate their stories,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/opencv-founders-launch-ai-video-startup-to-take-on-openai-and-google</guid><pubDate>Wed, 19 Nov 2025 14:00:00 +0000</pubDate></item><item><title>OpenAI board member Larry Summers steps down amid Epstein file revelations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/openai-board-member-larry-summers-steps-down-amid-epstein-file-revelations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Former Treasury Secretary Larry Summers has resigned from OpenAI’s board days after Congress released an extensive cache of emails with convicted sex offender Jeffrey Epstein, which included details of intimate affairs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Summers is also a former president of Harvard University and a current professor. The university will open its own probe into Summers’ connections with Epstein, reports the student newspaper, The Harvard Crimson. The university newspaper also reported that Summers will step back from public commitments.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His departure comes a day after both the House and the Senate voted to release the Epstein files. Over the past few days, a House panel released years of email exchanges between Epstein and Summers, including one in which Summers asked for advice about pursuing a relationship with a woman he described as a mentee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the exchanges, which took place between November 2018 and July 2019, Summers — who was married at the time — seemed to acknowledge his position of power over the woman he was mentoring.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“She must be very confused or maybe wants to cut me off but wants professional connection a lot and so holds to it,” Summers wrote in a March 2019 email to Epstein. Epstein, who referred to himself early on in the exchanges as Summers’ “wing man,” told him in a June 2019 text: “She is doomed to be with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the messages, Summers wrote that his “best shot” at getting his mentee to ostensibly sleep with him was that the woman found him “invaluable and interesting” and that “she can’t have it without romance/sex.” Throughout June, Epstein urged him to play the “long game” and keep the woman in a “forced holding pattern.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epstein was arrested in July 2019 for sex trafficking of minors and conspiracy to commit sex trafficking of minors.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Former Treasury Secretary Larry Summers has resigned from OpenAI’s board days after Congress released an extensive cache of emails with convicted sex offender Jeffrey Epstein, which included details of intimate affairs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Summers is also a former president of Harvard University and a current professor. The university will open its own probe into Summers’ connections with Epstein, reports the student newspaper, The Harvard Crimson. The university newspaper also reported that Summers will step back from public commitments.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His departure comes a day after both the House and the Senate voted to release the Epstein files. Over the past few days, a House panel released years of email exchanges between Epstein and Summers, including one in which Summers asked for advice about pursuing a relationship with a woman he described as a mentee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the exchanges, which took place between November 2018 and July 2019, Summers — who was married at the time — seemed to acknowledge his position of power over the woman he was mentoring.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“She must be very confused or maybe wants to cut me off but wants professional connection a lot and so holds to it,” Summers wrote in a March 2019 email to Epstein. Epstein, who referred to himself early on in the exchanges as Summers’ “wing man,” told him in a June 2019 text: “She is doomed to be with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the messages, Summers wrote that his “best shot” at getting his mentee to ostensibly sleep with him was that the woman found him “invaluable and interesting” and that “she can’t have it without romance/sex.” Throughout June, Epstein urged him to play the “long game” and keep the woman in a “forced holding pattern.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epstein was arrested in July 2019 for sex trafficking of minors and conspiracy to commit sex trafficking of minors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/openai-board-member-larry-summers-steps-down-amid-epstein-file-revelations/</guid><pubDate>Wed, 19 Nov 2025 14:33:54 +0000</pubDate></item><item><title>Target joins OpenAI’s growing list of retail apps (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/target-joins-openais-growing-list-of-retail-apps/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/2025_TargetxOpenAi_ChatGPT_PR-Image_Hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is pushing deeper into retail, with Target set to debut a new ChatGPT-powered app for shoppers in coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news follows OpenAI’s move last month to start adding dedicated retail apps to ChatGPT, including Canva, Coursera, Figma, Expedia, Spotify, and Zillow. It also comes as OpenAI races to rake in AI-driven commerce via new products like “Instant Checkout” that let users make purchases within conversations with retailers like Etsy and Shopify.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Target app in ChatGPT will launch in beta next week, and it will let shoppers ask for ideas, browse, and build multi-item baskets, shop for food, and check out, according to OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal deepens OpenAI’s existing enterprise partnership with Target. Target will now roll out ChatGPT Enterprise across its 18,000 employees at its headquarters to be used for things like better supply chain forecasting and streamlining store processes. Target will also further integrate OpenAI’s models into digital tools that power everything from employee support and customer service to AI-driven shopping assistants and personalized gift finders.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/2025_TargetxOpenAi_ChatGPT_PR-Image_Hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is pushing deeper into retail, with Target set to debut a new ChatGPT-powered app for shoppers in coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news follows OpenAI’s move last month to start adding dedicated retail apps to ChatGPT, including Canva, Coursera, Figma, Expedia, Spotify, and Zillow. It also comes as OpenAI races to rake in AI-driven commerce via new products like “Instant Checkout” that let users make purchases within conversations with retailers like Etsy and Shopify.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Target app in ChatGPT will launch in beta next week, and it will let shoppers ask for ideas, browse, and build multi-item baskets, shop for food, and check out, according to OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal deepens OpenAI’s existing enterprise partnership with Target. Target will now roll out ChatGPT Enterprise across its 18,000 employees at its headquarters to be used for things like better supply chain forecasting and streamlining store processes. Target will also further integrate OpenAI’s models into digital tools that power everything from employee support and customer service to AI-driven shopping assistants and personalized gift finders.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/target-joins-openais-growing-list-of-retail-apps/</guid><pubDate>Wed, 19 Nov 2025 14:36:12 +0000</pubDate></item><item><title>How Louvre thieves exploited human psychology to avoid suspicion—and what it reveals about AI (AI – Ars Technica)</title><link>https://arstechnica.com/science/2025/11/how-louvre-thieves-exploited-human-psychology-to-avoid-suspicion-and-what-it-reveals-about-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        For humans and AI, when something fits the category of “ordinary,” it slips from notice.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Balcony Louvre building at night" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Balcony Louvre building at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A close-up of the facade of the Louvre Museum and a broken window after the robbery of the century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          yann vernerie

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p class="theconversation-article-title"&gt;&lt;span style="font-size: 16px;"&gt;On a sunny &lt;/span&gt;morning on October 19 2025, four men allegedly walked into the world’s most-visited museum and left, minutes later, with crown jewels worth 88 million euros ($101 million). The theft from Paris’ Louvre Museum—one of the world’s most surveilled cultural institutions—took just under eight minutes.&lt;/p&gt;
&lt;div class="theconversation-article-body"&gt;
&lt;p&gt;Visitors kept browsing. Security didn’t react (until alarms were triggered). The men disappeared into the city’s traffic before anyone realized what had happened.&lt;/p&gt;
&lt;p&gt;Investigators later revealed that the thieves wore hi-vis vests, disguising themselves as construction workers. They arrived with a furniture lift, a common sight in Paris’s narrow streets, and used it to reach a balcony overlooking the Seine. Dressed as workers, they looked as if they belonged.&lt;/p&gt;
&lt;p&gt;This strategy worked because we don’t see the world objectively. We see it through categories—through what we expect to see. The thieves understood the social categories that we perceive as “normal” and exploited them to avoid suspicion. Many artificial intelligence (AI) systems work in the same way and are vulnerable to the same kinds of mistakes as a result.&lt;/p&gt;
&lt;p&gt;The sociologist Erving Goffman would describe what happened at the Louvre using his concept of the presentation of self: people “perform” social roles by adopting the cues others expect. Here, the performance of normality became the perfect camouflage.&lt;/p&gt;
&lt;h2&gt;The sociology of sight&lt;/h2&gt;
&lt;p&gt;Humans carry out mental categorization all the time to make sense of people and places. When something fits the category of “ordinary,” it slips from notice.&lt;/p&gt;
&lt;p&gt;AI systems used for tasks such as facial recognition and detecting suspicious activity in a public area operate in a similar way. For humans, categorization is cultural. For AI, it is mathematical.&lt;/p&gt;
&lt;p&gt;But both systems rely on learned patterns rather than objective reality. Because AI learns from data about who looks “normal” and who looks “suspicious,” it absorbs the categories embedded in its training data. And this makes it susceptible to bias.&lt;/p&gt;
&lt;p&gt;The Louvre robbers weren’t seen as dangerous because they fit a trusted category. In AI, the same process can have the opposite effect: people who don’t fit the statistical norm become more visible and over-scrutinized.&lt;/p&gt;
&lt;p&gt;It can mean a facial recognition system disproportionately flags certain racial or gendered groups as potential threats while letting others pass unnoticed.&lt;/p&gt;
&lt;p&gt;A sociological lens helps us see that these aren’t separate issues. AI doesn’t invent its categories; it learns ours. When a computer vision system is trained on security footage where “normal” is defined by particular bodies, clothing, or behavior, it reproduces those assumptions.&lt;/p&gt;
&lt;p&gt;Just as the museum’s guards looked past the thieves because they appeared to belong, AI can look past certain patterns while overreacting to others.&lt;/p&gt;
&lt;p&gt;Categorization, whether human or algorithmic, is a double-edged sword. It helps us process information quickly, but it also encodes our cultural assumptions. Both people and machines rely on pattern recognition, which is an efficient but imperfect strategy.&lt;/p&gt;
&lt;p&gt;A sociological view of AI treats algorithms as mirrors: They reflect back our social categories and hierarchies. In the Louvre case, the mirror is turned toward us. The robbers succeeded not because they were invisible, but because they were seen through the lens of normality. In AI terms, they passed the classification test.&lt;/p&gt;
&lt;h2&gt;From museum halls to machine learning&lt;/h2&gt;
&lt;p&gt;This link between perception and categorization reveals something important about our increasingly algorithmic world. Whether it’s a guard deciding who looks suspicious or an AI deciding who looks like a “shoplifter,” the underlying process is the same: assigning people to categories based on cues that feel objective but are culturally learned.&lt;/p&gt;
&lt;p&gt;When an AI system is described as “biased,” this often means that it reflects those social categories too faithfully. The Louvre heist reminds us that these categories don’t just shape our attitudes, they shape what gets noticed at all.&lt;/p&gt;
&lt;p&gt;After the theft, France’s culture minister promised new cameras and tighter security. But no matter how advanced those systems become, they will still rely on categorization. Someone, or something, must decide what counts as “suspicious behavior.” If that decision rests on assumptions, the same blind spots will persist.&lt;/p&gt;
&lt;p&gt;The Louvre robbery will be remembered as one of Europe’s most spectacular museum thefts. The thieves succeeded because they mastered the sociology of appearance: They understood the categories of normality and used them as tools.&lt;/p&gt;
&lt;p&gt;And in doing so, they showed how both people and machines can mistake conformity for safety. Their success in broad daylight wasn’t only a triumph of planning. It was a triumph of categorical thinking, the same logic that underlies both human perception and artificial intelligence.&lt;/p&gt;
&lt;p&gt;The lesson is clear: Before we teach machines to see better, we must first learn to question how we see.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Vincent Charles, Reader in AI for Business and Management Science, Queen’s University Belfast, and Tatiana Gherman, Associate Professor of AI for Business and Strategy, University of Northampton. &amp;nbsp;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/em&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;/div&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        For humans and AI, when something fits the category of “ordinary,” it slips from notice.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Balcony Louvre building at night" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Balcony Louvre building at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A close-up of the facade of the Louvre Museum and a broken window after the robbery of the century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          yann vernerie

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p class="theconversation-article-title"&gt;&lt;span style="font-size: 16px;"&gt;On a sunny &lt;/span&gt;morning on October 19 2025, four men allegedly walked into the world’s most-visited museum and left, minutes later, with crown jewels worth 88 million euros ($101 million). The theft from Paris’ Louvre Museum—one of the world’s most surveilled cultural institutions—took just under eight minutes.&lt;/p&gt;
&lt;div class="theconversation-article-body"&gt;
&lt;p&gt;Visitors kept browsing. Security didn’t react (until alarms were triggered). The men disappeared into the city’s traffic before anyone realized what had happened.&lt;/p&gt;
&lt;p&gt;Investigators later revealed that the thieves wore hi-vis vests, disguising themselves as construction workers. They arrived with a furniture lift, a common sight in Paris’s narrow streets, and used it to reach a balcony overlooking the Seine. Dressed as workers, they looked as if they belonged.&lt;/p&gt;
&lt;p&gt;This strategy worked because we don’t see the world objectively. We see it through categories—through what we expect to see. The thieves understood the social categories that we perceive as “normal” and exploited them to avoid suspicion. Many artificial intelligence (AI) systems work in the same way and are vulnerable to the same kinds of mistakes as a result.&lt;/p&gt;
&lt;p&gt;The sociologist Erving Goffman would describe what happened at the Louvre using his concept of the presentation of self: people “perform” social roles by adopting the cues others expect. Here, the performance of normality became the perfect camouflage.&lt;/p&gt;
&lt;h2&gt;The sociology of sight&lt;/h2&gt;
&lt;p&gt;Humans carry out mental categorization all the time to make sense of people and places. When something fits the category of “ordinary,” it slips from notice.&lt;/p&gt;
&lt;p&gt;AI systems used for tasks such as facial recognition and detecting suspicious activity in a public area operate in a similar way. For humans, categorization is cultural. For AI, it is mathematical.&lt;/p&gt;
&lt;p&gt;But both systems rely on learned patterns rather than objective reality. Because AI learns from data about who looks “normal” and who looks “suspicious,” it absorbs the categories embedded in its training data. And this makes it susceptible to bias.&lt;/p&gt;
&lt;p&gt;The Louvre robbers weren’t seen as dangerous because they fit a trusted category. In AI, the same process can have the opposite effect: people who don’t fit the statistical norm become more visible and over-scrutinized.&lt;/p&gt;
&lt;p&gt;It can mean a facial recognition system disproportionately flags certain racial or gendered groups as potential threats while letting others pass unnoticed.&lt;/p&gt;
&lt;p&gt;A sociological lens helps us see that these aren’t separate issues. AI doesn’t invent its categories; it learns ours. When a computer vision system is trained on security footage where “normal” is defined by particular bodies, clothing, or behavior, it reproduces those assumptions.&lt;/p&gt;
&lt;p&gt;Just as the museum’s guards looked past the thieves because they appeared to belong, AI can look past certain patterns while overreacting to others.&lt;/p&gt;
&lt;p&gt;Categorization, whether human or algorithmic, is a double-edged sword. It helps us process information quickly, but it also encodes our cultural assumptions. Both people and machines rely on pattern recognition, which is an efficient but imperfect strategy.&lt;/p&gt;
&lt;p&gt;A sociological view of AI treats algorithms as mirrors: They reflect back our social categories and hierarchies. In the Louvre case, the mirror is turned toward us. The robbers succeeded not because they were invisible, but because they were seen through the lens of normality. In AI terms, they passed the classification test.&lt;/p&gt;
&lt;h2&gt;From museum halls to machine learning&lt;/h2&gt;
&lt;p&gt;This link between perception and categorization reveals something important about our increasingly algorithmic world. Whether it’s a guard deciding who looks suspicious or an AI deciding who looks like a “shoplifter,” the underlying process is the same: assigning people to categories based on cues that feel objective but are culturally learned.&lt;/p&gt;
&lt;p&gt;When an AI system is described as “biased,” this often means that it reflects those social categories too faithfully. The Louvre heist reminds us that these categories don’t just shape our attitudes, they shape what gets noticed at all.&lt;/p&gt;
&lt;p&gt;After the theft, France’s culture minister promised new cameras and tighter security. But no matter how advanced those systems become, they will still rely on categorization. Someone, or something, must decide what counts as “suspicious behavior.” If that decision rests on assumptions, the same blind spots will persist.&lt;/p&gt;
&lt;p&gt;The Louvre robbery will be remembered as one of Europe’s most spectacular museum thefts. The thieves succeeded because they mastered the sociology of appearance: They understood the categories of normality and used them as tools.&lt;/p&gt;
&lt;p&gt;And in doing so, they showed how both people and machines can mistake conformity for safety. Their success in broad daylight wasn’t only a triumph of planning. It was a triumph of categorical thinking, the same logic that underlies both human perception and artificial intelligence.&lt;/p&gt;
&lt;p&gt;The lesson is clear: Before we teach machines to see better, we must first learn to question how we see.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Vincent Charles, Reader in AI for Business and Management Science, Queen’s University Belfast, and Tatiana Gherman, Associate Professor of AI for Business and Strategy, University of Northampton. &amp;nbsp;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/em&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;/div&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/science/2025/11/how-louvre-thieves-exploited-human-psychology-to-avoid-suspicion-and-what-it-reveals-about-ai/</guid><pubDate>Wed, 19 Nov 2025 14:41:52 +0000</pubDate></item><item><title>Adobe to buy Semrush for $1.9 billion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/adobe-to-buy-semrush-for-1-9-billion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2162453288.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Wednesday that it has agreed to acquire search engine optimization company Semrush for about $1.9 billion in cash, as the Photoshop maker seeks to augment its suite of marketing offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Adobe said it would offer $12 per share for Semrush, almost double the latter’s closing price of $6.89 on Tuesday, before news of the deal. Semrush had a market capitalization of about $1 billion as of Tuesday’s close.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By acquiring Semrush, Adobe is betting that companies will choose to invest in optimizing their content and web pages to be more visible to AI tools, as people increasingly use AI chatbots, agents, and AI browsers to do everything from getting the news and finding recipes to shopping and booking their travel. This is a fresh, big market for existing search engine optimization players like Semrush, particularly as this change in consumer behavior drives increasing traffic to websites from generative AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as of October, traffic to retail websites from generative AI chatbots increased 1,200% compared to a year earlier, per Adobe Analytics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Semrush has been investing in what it calls “generative engine optimization,” and recently launched a tool for tracking and improving website performance using both traditional SEO techniques and optimization for AI engines, like ChatGPT, Claude, Copilot, Grok, and Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brand visibility is being reshaped by generative AI, and brands that don’t embrace this new opportunity risk losing relevance and revenue,” said Anil Chakravarthy, president of Adobe’s Digital Experience Business. “With Semrush, we’re unlocking GEO for marketers as a new growth channel alongside their SEO, driving more visibility, customer engagement and conversions across the ecosystem.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2162453288.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Wednesday that it has agreed to acquire search engine optimization company Semrush for about $1.9 billion in cash, as the Photoshop maker seeks to augment its suite of marketing offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Adobe said it would offer $12 per share for Semrush, almost double the latter’s closing price of $6.89 on Tuesday, before news of the deal. Semrush had a market capitalization of about $1 billion as of Tuesday’s close.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By acquiring Semrush, Adobe is betting that companies will choose to invest in optimizing their content and web pages to be more visible to AI tools, as people increasingly use AI chatbots, agents, and AI browsers to do everything from getting the news and finding recipes to shopping and booking their travel. This is a fresh, big market for existing search engine optimization players like Semrush, particularly as this change in consumer behavior drives increasing traffic to websites from generative AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as of October, traffic to retail websites from generative AI chatbots increased 1,200% compared to a year earlier, per Adobe Analytics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Semrush has been investing in what it calls “generative engine optimization,” and recently launched a tool for tracking and improving website performance using both traditional SEO techniques and optimization for AI engines, like ChatGPT, Claude, Copilot, Grok, and Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brand visibility is being reshaped by generative AI, and brands that don’t embrace this new opportunity risk losing relevance and revenue,” said Anil Chakravarthy, president of Adobe’s Digital Experience Business. “With Semrush, we’re unlocking GEO for marketers as a new growth channel alongside their SEO, driving more visibility, customer engagement and conversions across the ecosystem.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/adobe-to-buy-semrush-for-1-9-billion/</guid><pubDate>Wed, 19 Nov 2025 15:42:15 +0000</pubDate></item><item><title>DeepMind’s latest: An AI for handling mathematical proofs (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/deepminds-latest-an-ai-for-handling-mathematical-proofs/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AlphaProof can handle math challenges but needs a bit of help right now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hill Street Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Computers are extremely good with numbers, but they haven’t gotten many human mathematicians fired. Until recently, they could barely hold their own in high school-level math competitions.&lt;/p&gt;
&lt;p&gt;But now Google’s DeepMind team has built AlphaProof, an AI system that matched silver medalists’ performance at the 2024 International Mathematical Olympiad, scoring just one point short of gold at the most prestigious undergrad math competition in the world. And that’s kind of a big deal.&lt;/p&gt;
&lt;h2&gt;True understanding&lt;/h2&gt;
&lt;p&gt;The reason computers fared poorly in math competitions is that, while they far surpass humanity’s ability to perform calculations, they are not really that good at the logic and reasoning that is needed for advanced math. Put differently, they are good at performing calculations really quickly, but they usually suck at understanding why they’re doing them. While something like addition seems simple, humans can do semi-formal proofs based on definitions of addition or go for fully formal Peano arithmetic that defines the properties of natural numbers and operations like addition through axioms.&lt;/p&gt;
&lt;p&gt;To perform a proof, humans have to understand the very structure of mathematics. The way mathematicians build proofs, how many steps they need to arrive at the conclusion, and how cleverly they design those steps are a testament to their brilliance, ingenuity, and mathematical elegance. “You know, Bertrand Russel published a 500-page book to prove that one plus one equals two,” says Thomas Hubert, a DeepMind researcher and lead author of the AlphaProof study.&lt;/p&gt;
&lt;p&gt;DeepMind’s team wanted to develop an AI that understood math at this level. The work started with solving the usual AI problem: the lack of training data.&lt;/p&gt;
&lt;h2&gt;Math problems translator&lt;/h2&gt;
&lt;p&gt;Large language models that power AI systems like Chat GPT learn from billions upon billions of pages of text. Because there are texts on mathematics in their training databases—all the handbooks and works of famous mathematicians—they show some level of success in proving mathematical statements. But they are limited by how they operate: They rely on using huge neural nets to predict the next word or token in sequences generated in response to user prompts. Their reasoning is statistical by design, which means they simply return answers that “sound” right.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind didn’t need the AI to “sound” right—that wasn’t going to cut it in high-level mathematics. They needed their AI to “be” right, to guarantee absolute certainty. That called for an entirely new, more formalized training environment. To provide that, the team used a software package called Lean.&lt;/p&gt;
&lt;p&gt;Lean is a computer program that helps mathematicians write precise definitions and proofs. It relies on a precise, formal programming language that’s also called Lean, which mathematical statements can be translated into. Once the translated or formalized statement is uploaded to the program, it can check if it is correct and get back with responses like “this is correct,” “something is missing,” or “you used a fact that is not proved yet.”&lt;/p&gt;
&lt;p&gt;The problem was, most mathematical statements and proofs that can be found online are written in natural language like “let X be the set of natural numbers that…”—the number of statements written in Lean was rather limited. “The major difficulty of working with formal languages is that there’s very little data,” Hubert says. To go around it, the researchers trained a Gemini large language model to translate mathematical statements from natural language to Lean. The model worked like an automatic formalizer&amp;nbsp;and produced about 80 million formalized mathematical statements.&lt;/p&gt;
&lt;p&gt;It wasn’t perfect, but the team managed to use that to their advantage. “There are many ways you can capitalize on approximate translations,” Hubert claims.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Learning to think&lt;/h2&gt;
&lt;p&gt;The idea DeepMind had for the AlphaProof was to use the architecture the team used in their chess-, &lt;em&gt;Go-&lt;/em&gt;, and shogi-playing AlphaZero AI system. Building proofs in Lean and Mathematics in general was supposed to be just another game to master. “We were trying to learn this game through trial and error,” Hubert says. Imperfectly formalized problems offered great opportunity for making errors. In its learning phase, AlphaProof was simply proving and disproving the problems it had in its database. If something was translated poorly, figuring out that something wasn’t right was a useful form of exercise.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Just like AlphaZero, AlphaProof in most cases used two main components. The first was a huge neural net with a few billion parameters that learned to work in the Lean environment through trial and error. It was rewarded for each proven or disproven statement and penalized for each reasoning step it took, which was a way of incentivizing short, elegant proofs.&lt;/p&gt;
&lt;p&gt;It was also trained to use a second component, which was a tree search algorithm. This explored all possible actions that could be taken to push the proof forward at each step. Because the number of possible actions in mathematics can be near infinite, the job of the neural net was to look at the available branches in the search tree and commit computational budget only to the most promising ones.&lt;/p&gt;
&lt;p&gt;After a few weeks of training, the system could score well on most math competition benchmarks based on problems sourced from past high school-level competitions, but it still struggled with the most difficult of them. To tackle these, the team added a third component that hadn’t been in AlphaZero. Or anywhere else.&lt;/p&gt;
&lt;h2&gt;Spark of humanity&lt;/h2&gt;
&lt;p&gt;The third component, called Test-Time Reinforcement Learning (TTRL), roughly emulated the way mathematicians approach the most difficult problems. The learning part relied on the same combination of neural nets with search tree algorithms. The difference came in what it learned from. Instead of relying on a broad database of auto-formalized problems, AlphaProof working in the TTRL mode started its work by generating an entirely new training dataset based on the problem it was dealing with.&lt;/p&gt;
&lt;p&gt;The process involved creating countless variations of the original statement, some simplified a little bit more, some more general, and some only loosely connected to it. The system then attempted to prove or disprove them. It was roughly what most humans do when they’re facing a particularly hard puzzle, the AI equivalent of saying, “I don’t get it, so let’s try an easier version of this first to get some practice.” This allowed AlphaProof to learn on the fly, and it worked amazingly well.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;At the 2024 International Mathematics Olympiad, there were 42 points to score for solving six different problems worth seven points each. To win gold, participants had to get 29 points or higher, and 58 out of 609 of them did that. Silver medals were awarded to people who earned between 22 and 28 points (there were 123 silver medalists). The problems varied in difficulty, with the sixth one, acting as a “final boss,” being the most difficult of them all. Only six participants managed to solve it. AlphaProof was the seventh.&lt;/p&gt;
&lt;p&gt;But AlphaProof wasn’t an end-all, be-all mathematical genius. Its silver had its price—quite literally.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Optimizing ingenuity&lt;/h2&gt;
&lt;p&gt;The first problem with AlphaProof’s performance was that it didn’t work alone. To begin with, humans had to make the problems compatible with Lean before the software even got to work. And, among the six Olympic problems, the fourth one was about geometry, and the AI was not optimized for that. To deal with it, AlphaProof had to call a friend called AlphaGeometry 2, a geometry-specialized AI that ripped through the task in a few minutes without breaking a sweat. On its own, AlphaProof scored 21 points, not 28, so technically it would win bronze, not silver. Except it wouldn’t.&lt;/p&gt;
&lt;p&gt;Human participants of the Olympiad had to solve their six problems in two sessions, four-and-a-half hours long. AlphaProof, on the other hand, wrestled with them for several days using multiple tensor processing units at full throttle. The most time- and energy-consuming component was TTRL, which battled with the three problems it managed to solve for three days each. If AlphaProof was held up to the same standard as human participants, it would basically run out of time. And if it wasn’t born at a tech giant worth hundreds of billions of dollars, it would run out of money, too.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the paper, the team admits the computational requirements to run AlphaProof are most likely cost-prohibitive for most research groups and aspiring mathematicians. Computing power in AI applications is often measured in TPU-days, meaning a tensor processing unit working flat-out for a full day. AlphaProof needed hundreds of TPU-days per problem.&lt;/p&gt;
&lt;p&gt;On top of that, the International Mathematics Olympiad is a high school-level competition, and the problems, while admittedly difficult, were based on things mathematicians already know. Research-level math requires inventing entirely new concepts instead of just working with existing ones.&lt;/p&gt;
&lt;p&gt;But DeepMind thinks it can overcome these hurdles and optimize AlphaProof to be less resource-hungry. “We don’t want to stop at math competitions. We want to build an AI system that could really contribute to research-level mathematics,” Hubert says. His goal is to make AlphaProof available to the broader research community. “We’re also releasing a kind of an AlphaProof tool,” he added. “It would be a small trusted testers program to see if this would be useful to mathematicians.”&lt;/p&gt;
&lt;p&gt;Nature, 2025. &amp;nbsp;DOI: 10.1038/s41586-025-09833-y&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AlphaProof can handle math challenges but needs a bit of help right now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hill Street Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Computers are extremely good with numbers, but they haven’t gotten many human mathematicians fired. Until recently, they could barely hold their own in high school-level math competitions.&lt;/p&gt;
&lt;p&gt;But now Google’s DeepMind team has built AlphaProof, an AI system that matched silver medalists’ performance at the 2024 International Mathematical Olympiad, scoring just one point short of gold at the most prestigious undergrad math competition in the world. And that’s kind of a big deal.&lt;/p&gt;
&lt;h2&gt;True understanding&lt;/h2&gt;
&lt;p&gt;The reason computers fared poorly in math competitions is that, while they far surpass humanity’s ability to perform calculations, they are not really that good at the logic and reasoning that is needed for advanced math. Put differently, they are good at performing calculations really quickly, but they usually suck at understanding why they’re doing them. While something like addition seems simple, humans can do semi-formal proofs based on definitions of addition or go for fully formal Peano arithmetic that defines the properties of natural numbers and operations like addition through axioms.&lt;/p&gt;
&lt;p&gt;To perform a proof, humans have to understand the very structure of mathematics. The way mathematicians build proofs, how many steps they need to arrive at the conclusion, and how cleverly they design those steps are a testament to their brilliance, ingenuity, and mathematical elegance. “You know, Bertrand Russel published a 500-page book to prove that one plus one equals two,” says Thomas Hubert, a DeepMind researcher and lead author of the AlphaProof study.&lt;/p&gt;
&lt;p&gt;DeepMind’s team wanted to develop an AI that understood math at this level. The work started with solving the usual AI problem: the lack of training data.&lt;/p&gt;
&lt;h2&gt;Math problems translator&lt;/h2&gt;
&lt;p&gt;Large language models that power AI systems like Chat GPT learn from billions upon billions of pages of text. Because there are texts on mathematics in their training databases—all the handbooks and works of famous mathematicians—they show some level of success in proving mathematical statements. But they are limited by how they operate: They rely on using huge neural nets to predict the next word or token in sequences generated in response to user prompts. Their reasoning is statistical by design, which means they simply return answers that “sound” right.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind didn’t need the AI to “sound” right—that wasn’t going to cut it in high-level mathematics. They needed their AI to “be” right, to guarantee absolute certainty. That called for an entirely new, more formalized training environment. To provide that, the team used a software package called Lean.&lt;/p&gt;
&lt;p&gt;Lean is a computer program that helps mathematicians write precise definitions and proofs. It relies on a precise, formal programming language that’s also called Lean, which mathematical statements can be translated into. Once the translated or formalized statement is uploaded to the program, it can check if it is correct and get back with responses like “this is correct,” “something is missing,” or “you used a fact that is not proved yet.”&lt;/p&gt;
&lt;p&gt;The problem was, most mathematical statements and proofs that can be found online are written in natural language like “let X be the set of natural numbers that…”—the number of statements written in Lean was rather limited. “The major difficulty of working with formal languages is that there’s very little data,” Hubert says. To go around it, the researchers trained a Gemini large language model to translate mathematical statements from natural language to Lean. The model worked like an automatic formalizer&amp;nbsp;and produced about 80 million formalized mathematical statements.&lt;/p&gt;
&lt;p&gt;It wasn’t perfect, but the team managed to use that to their advantage. “There are many ways you can capitalize on approximate translations,” Hubert claims.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Learning to think&lt;/h2&gt;
&lt;p&gt;The idea DeepMind had for the AlphaProof was to use the architecture the team used in their chess-, &lt;em&gt;Go-&lt;/em&gt;, and shogi-playing AlphaZero AI system. Building proofs in Lean and Mathematics in general was supposed to be just another game to master. “We were trying to learn this game through trial and error,” Hubert says. Imperfectly formalized problems offered great opportunity for making errors. In its learning phase, AlphaProof was simply proving and disproving the problems it had in its database. If something was translated poorly, figuring out that something wasn’t right was a useful form of exercise.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Just like AlphaZero, AlphaProof in most cases used two main components. The first was a huge neural net with a few billion parameters that learned to work in the Lean environment through trial and error. It was rewarded for each proven or disproven statement and penalized for each reasoning step it took, which was a way of incentivizing short, elegant proofs.&lt;/p&gt;
&lt;p&gt;It was also trained to use a second component, which was a tree search algorithm. This explored all possible actions that could be taken to push the proof forward at each step. Because the number of possible actions in mathematics can be near infinite, the job of the neural net was to look at the available branches in the search tree and commit computational budget only to the most promising ones.&lt;/p&gt;
&lt;p&gt;After a few weeks of training, the system could score well on most math competition benchmarks based on problems sourced from past high school-level competitions, but it still struggled with the most difficult of them. To tackle these, the team added a third component that hadn’t been in AlphaZero. Or anywhere else.&lt;/p&gt;
&lt;h2&gt;Spark of humanity&lt;/h2&gt;
&lt;p&gt;The third component, called Test-Time Reinforcement Learning (TTRL), roughly emulated the way mathematicians approach the most difficult problems. The learning part relied on the same combination of neural nets with search tree algorithms. The difference came in what it learned from. Instead of relying on a broad database of auto-formalized problems, AlphaProof working in the TTRL mode started its work by generating an entirely new training dataset based on the problem it was dealing with.&lt;/p&gt;
&lt;p&gt;The process involved creating countless variations of the original statement, some simplified a little bit more, some more general, and some only loosely connected to it. The system then attempted to prove or disprove them. It was roughly what most humans do when they’re facing a particularly hard puzzle, the AI equivalent of saying, “I don’t get it, so let’s try an easier version of this first to get some practice.” This allowed AlphaProof to learn on the fly, and it worked amazingly well.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;At the 2024 International Mathematics Olympiad, there were 42 points to score for solving six different problems worth seven points each. To win gold, participants had to get 29 points or higher, and 58 out of 609 of them did that. Silver medals were awarded to people who earned between 22 and 28 points (there were 123 silver medalists). The problems varied in difficulty, with the sixth one, acting as a “final boss,” being the most difficult of them all. Only six participants managed to solve it. AlphaProof was the seventh.&lt;/p&gt;
&lt;p&gt;But AlphaProof wasn’t an end-all, be-all mathematical genius. Its silver had its price—quite literally.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Optimizing ingenuity&lt;/h2&gt;
&lt;p&gt;The first problem with AlphaProof’s performance was that it didn’t work alone. To begin with, humans had to make the problems compatible with Lean before the software even got to work. And, among the six Olympic problems, the fourth one was about geometry, and the AI was not optimized for that. To deal with it, AlphaProof had to call a friend called AlphaGeometry 2, a geometry-specialized AI that ripped through the task in a few minutes without breaking a sweat. On its own, AlphaProof scored 21 points, not 28, so technically it would win bronze, not silver. Except it wouldn’t.&lt;/p&gt;
&lt;p&gt;Human participants of the Olympiad had to solve their six problems in two sessions, four-and-a-half hours long. AlphaProof, on the other hand, wrestled with them for several days using multiple tensor processing units at full throttle. The most time- and energy-consuming component was TTRL, which battled with the three problems it managed to solve for three days each. If AlphaProof was held up to the same standard as human participants, it would basically run out of time. And if it wasn’t born at a tech giant worth hundreds of billions of dollars, it would run out of money, too.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the paper, the team admits the computational requirements to run AlphaProof are most likely cost-prohibitive for most research groups and aspiring mathematicians. Computing power in AI applications is often measured in TPU-days, meaning a tensor processing unit working flat-out for a full day. AlphaProof needed hundreds of TPU-days per problem.&lt;/p&gt;
&lt;p&gt;On top of that, the International Mathematics Olympiad is a high school-level competition, and the problems, while admittedly difficult, were based on things mathematicians already know. Research-level math requires inventing entirely new concepts instead of just working with existing ones.&lt;/p&gt;
&lt;p&gt;But DeepMind thinks it can overcome these hurdles and optimize AlphaProof to be less resource-hungry. “We don’t want to stop at math competitions. We want to build an AI system that could really contribute to research-level mathematics,” Hubert says. His goal is to make AlphaProof available to the broader research community. “We’re also releasing a kind of an AlphaProof tool,” he added. “It would be a small trusted testers program to see if this would be useful to mathematicians.”&lt;/p&gt;
&lt;p&gt;Nature, 2025. &amp;nbsp;DOI: 10.1038/s41586-025-09833-y&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/deepminds-latest-an-ai-for-handling-mathematical-proofs/</guid><pubDate>Wed, 19 Nov 2025 15:57:30 +0000</pubDate></item><item><title>Scaling innovation in manufacturing with AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1128068" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Cover-MITTR_MicrosoftNVIDIA_November2025.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process, or even an entire factory—allow workers to test, optimize, and contextualize complex, real-world environments. Manufacturers are using digital twins to simulate factory environments with pinpoint detail.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“AI-powered digital twins mark a major evolution in the future of manufacturing, enabling real-time visualization of the entire production line, not just individual machines,” says Indranil Sircar, global chief technology officer for the manufacturing and mobility industry at Microsoft. “This is allowing manufacturers to move beyond isolated monitoring toward much wider insights.”&lt;/p&gt;  &lt;p&gt;A digital twin of a bottling line, for example, can integrate one-dimensional shop-floor telemetry, two-dimensional enterprise data, and three-dimensional immersive modeling into a single operational view of the entire production line to improve efficiency and reduce costly downtime. Many high-speed industries face downtime rates as high as 40%, estimates Jon Sobel, co-founder and chief executive officer of Sight Machine, an industrial AI company that partners with Microsoft and NVIDIA to transform complex data into actionable insights. By tracking micro-stops and quality metrics via digital twins, companies can target improvements and adjustments with greater precision, saving millions in once-lost productivity without disrupting ongoing operations.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128075" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-MicrosoftNVIDIA-JonSobelSocials_V2-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;AI offers the next opportunity. Sircar estimates that up to 50% of manufacturers are currently deploying AI in production. This is up from 35% of manufacturers surveyed in a 2024 MIT Technology Review Insights report who said they have begun to put AI use cases into production. Larger manufacturers with more than $10 billion in revenue were significantly ahead, with 77% already deploying AI use cases, according to the report.&lt;/p&gt;  &lt;p&gt;“Manufacturing has a lot of data and is a perfect use case for AI,” says Sobel. “An industry that has been seen by some as lagging when it comes to digital technology and AI may be in the best position to lead. It’s very unexpected.” &lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1128068" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Cover-MITTR_MicrosoftNVIDIA_November2025.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process, or even an entire factory—allow workers to test, optimize, and contextualize complex, real-world environments. Manufacturers are using digital twins to simulate factory environments with pinpoint detail.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“AI-powered digital twins mark a major evolution in the future of manufacturing, enabling real-time visualization of the entire production line, not just individual machines,” says Indranil Sircar, global chief technology officer for the manufacturing and mobility industry at Microsoft. “This is allowing manufacturers to move beyond isolated monitoring toward much wider insights.”&lt;/p&gt;  &lt;p&gt;A digital twin of a bottling line, for example, can integrate one-dimensional shop-floor telemetry, two-dimensional enterprise data, and three-dimensional immersive modeling into a single operational view of the entire production line to improve efficiency and reduce costly downtime. Many high-speed industries face downtime rates as high as 40%, estimates Jon Sobel, co-founder and chief executive officer of Sight Machine, an industrial AI company that partners with Microsoft and NVIDIA to transform complex data into actionable insights. By tracking micro-stops and quality metrics via digital twins, companies can target improvements and adjustments with greater precision, saving millions in once-lost productivity without disrupting ongoing operations.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128075" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-MicrosoftNVIDIA-JonSobelSocials_V2-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;AI offers the next opportunity. Sircar estimates that up to 50% of manufacturers are currently deploying AI in production. This is up from 35% of manufacturers surveyed in a 2024 MIT Technology Review Insights report who said they have begun to put AI use cases into production. Larger manufacturers with more than $10 billion in revenue were significantly ahead, with 77% already deploying AI use cases, according to the report.&lt;/p&gt;  &lt;p&gt;“Manufacturing has a lot of data and is a perfect use case for AI,” says Sobel. “An industry that has been seen by some as lagging when it comes to digital technology and AI may be in the best position to lead. It’s very unexpected.” &lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/</guid><pubDate>Wed, 19 Nov 2025 16:54:55 +0000</pubDate></item><item><title>YC-backed Poly relaunches as a cloud-hosted file storage with AI search (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/yc-backed-poly-relaunches-as-a-cloud-hosted-file-storage-with-ai-search/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the most common use cases to have come out of new-age AI models is to power natural language search and find files and other information quicker and faster. There are already several companies that allow you to connect different services to search through data. Now a startup called Poly is launching a service that encourages you to dump all your files into one place so you can query them to find the right content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, it’s giving 100GB of storage to users on its free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Poly’s second inning from a product perspective. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was started by founders Abhay Agarwal and Sam Young in 2022. Young has since left the company. At that time, the startup, which had participated in the startup accelerator Y Combinator, allowed users to create 3D assets using prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agarwal, who is a research fellow at Microsoft and worked on vision AI to help the visually impaired, said the company didn’t predict that the AI image and asset generation industry would blow up and competitors would raise large sums rapidly. That’s when the team decided to pivot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We interviewed our users and asked them what the pain points of their workflows were that could be solved by AI. Turned out that one big unmet need for users was organizing their file system. As a user, you have a lot of files on your computer, and it is hard to find stuff. We wanted to solve for that,” Agarwal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the startup shut down the previous iteration of Poly in 2023, went into stealth, and started building the new cloud-based file organizer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is now launching the product for the public after testing it in closed beta for a few months. Currently, you can use Poly on the web or Mac, with a Windows version coming soon. The company will start onboarding users from its waitlist starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poly has raised $8 million in seed funding led by Felicis, with participation from Bloomberg Beta, NextView, Figma Ventures, AI Grant, Wing Ventures, and MVP Ventures. This includes the prior $3.9 million round raised in 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“File systems are incredibly powerful and elegant, but most people have forgotten about them. Poly is bringing file systems as the center of interaction. The tool is designed in a way that allows you to use AI to think in a clearer way,” James Cham, a partner at the early-stage investment firm Bloomberg Beta told TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069107" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Search-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly acts like a cloud storage tool with AI-powered search. At the moment, the tool supports text, PDF, office docs, images, audio, video, and web files (URLs). You can upload files to Poly, tag them, ask the AI assistant questions about them, and even ask it to summarize or translate the files. Plus, the tool organizes your files for you and can create new folders or rename files, as needed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agarwal views it as an upgrade to Google’s NotebookLM, which people use to put files into a project, ask questions, and generate insights as audio or video. However, while Poly might be a better file organizer, it doesn’t have access to the latest web knowledge or the ability to create audio or video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founder added that, in the coming months, the tool will add more features, including web search, support for creating stylized reports within the app, a text and markdown editor, and the ability to add custom metadata. It will also allow users to paste Google Docs links and let people use AI agents to perform calculations and analysis on spreadsheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Poly, users can create shared drives, add files, and invite others to ask questions about them, which could be useful when you are on a project with other people. The startup said it also plans to add a feature to let users directly share individual files and folders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069108" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Agent-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly will directly compete with the likes of Dropbox and Google Drive, both of which have their own search tools. In my experience of using Poly’s tool for a few days, the search worked better than Google’s. Plus, there is an added benefit of just pasting the YouTube video’s link and generating a summary about it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are plenty of AI and search offerings on the market, one of Poly’s biggest advantages is its 100GB of storage for free users, which is much more than the free tiers of other storage services. You can also choose to pay $10 a month for 2TB of storage. Right now, there is no direct photo sync, but in the future, if the company builds features around it, Poly can be a good Google Photos alternative.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the tool offers substantial storage, Agarwal said that early testers have used it as a working storage for projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary focus is on Gen AI native creators and knowledge workers — people who are researching content or searching through their files. For instance, a service executive who wants to get insights out of many customer calls,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently offers a Model Context Protocol (MCP) server for you to use Poly within tools like ChatGPT or Cursor. While Poly doesn’t have direct integration with other tools for syncing, Agarwal believes that, as the app supports virtual file references, it can work on importing files from different services.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the most common use cases to have come out of new-age AI models is to power natural language search and find files and other information quicker and faster. There are already several companies that allow you to connect different services to search through data. Now a startup called Poly is launching a service that encourages you to dump all your files into one place so you can query them to find the right content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, it’s giving 100GB of storage to users on its free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Poly’s second inning from a product perspective. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was started by founders Abhay Agarwal and Sam Young in 2022. Young has since left the company. At that time, the startup, which had participated in the startup accelerator Y Combinator, allowed users to create 3D assets using prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agarwal, who is a research fellow at Microsoft and worked on vision AI to help the visually impaired, said the company didn’t predict that the AI image and asset generation industry would blow up and competitors would raise large sums rapidly. That’s when the team decided to pivot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We interviewed our users and asked them what the pain points of their workflows were that could be solved by AI. Turned out that one big unmet need for users was organizing their file system. As a user, you have a lot of files on your computer, and it is hard to find stuff. We wanted to solve for that,” Agarwal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the startup shut down the previous iteration of Poly in 2023, went into stealth, and started building the new cloud-based file organizer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is now launching the product for the public after testing it in closed beta for a few months. Currently, you can use Poly on the web or Mac, with a Windows version coming soon. The company will start onboarding users from its waitlist starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poly has raised $8 million in seed funding led by Felicis, with participation from Bloomberg Beta, NextView, Figma Ventures, AI Grant, Wing Ventures, and MVP Ventures. This includes the prior $3.9 million round raised in 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“File systems are incredibly powerful and elegant, but most people have forgotten about them. Poly is bringing file systems as the center of interaction. The tool is designed in a way that allows you to use AI to think in a clearer way,” James Cham, a partner at the early-stage investment firm Bloomberg Beta told TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069107" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Search-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly acts like a cloud storage tool with AI-powered search. At the moment, the tool supports text, PDF, office docs, images, audio, video, and web files (URLs). You can upload files to Poly, tag them, ask the AI assistant questions about them, and even ask it to summarize or translate the files. Plus, the tool organizes your files for you and can create new folders or rename files, as needed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agarwal views it as an upgrade to Google’s NotebookLM, which people use to put files into a project, ask questions, and generate insights as audio or video. However, while Poly might be a better file organizer, it doesn’t have access to the latest web knowledge or the ability to create audio or video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founder added that, in the coming months, the tool will add more features, including web search, support for creating stylized reports within the app, a text and markdown editor, and the ability to add custom metadata. It will also allow users to paste Google Docs links and let people use AI agents to perform calculations and analysis on spreadsheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Poly, users can create shared drives, add files, and invite others to ask questions about them, which could be useful when you are on a project with other people. The startup said it also plans to add a feature to let users directly share individual files and folders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069108" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Agent-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly will directly compete with the likes of Dropbox and Google Drive, both of which have their own search tools. In my experience of using Poly’s tool for a few days, the search worked better than Google’s. Plus, there is an added benefit of just pasting the YouTube video’s link and generating a summary about it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are plenty of AI and search offerings on the market, one of Poly’s biggest advantages is its 100GB of storage for free users, which is much more than the free tiers of other storage services. You can also choose to pay $10 a month for 2TB of storage. Right now, there is no direct photo sync, but in the future, if the company builds features around it, Poly can be a good Google Photos alternative.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the tool offers substantial storage, Agarwal said that early testers have used it as a working storage for projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary focus is on Gen AI native creators and knowledge workers — people who are researching content or searching through their files. For instance, a service executive who wants to get insights out of many customer calls,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently offers a Model Context Protocol (MCP) server for you to use Poly within tools like ChatGPT or Cursor. While Poly doesn’t have direct integration with other tools for syncing, Agarwal believes that, as the app supports virtual file references, it can work on importing files from different services.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/yc-backed-poly-relaunches-as-a-cloud-hosted-file-storage-with-ai-search/</guid><pubDate>Wed, 19 Nov 2025 17:00:00 +0000</pubDate></item><item><title>Amazon’s Prime Video is getting AI-generated Video Recaps for some TV shows (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/amazons-prime-video-is-getting-ai-generated-video-recaps-for-some-tv-shows/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I guess we’re past the era of “&lt;em&gt;and that’s what you missed on Glee&lt;/em&gt;.” Amazon’s Prime Video streamer is adding AI-generated “Video Recaps” to help viewers catch up between seasons of shows, the company announced on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Amazon, the feature “utilizes generative AI to create theatrical-quality season recaps with synchronized narration, dialogue, and music.” It will begin rolling out in beta on Wednesday for select Prime Originals, like “Fallout,” “Tom Clancy’s Jack Ryan,” and “Upload.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prime Video launched a similar AI-powered feature last year called “X-Ray Recaps,” which summarizes complete seasons, episodes, or parts of episodes — at the time, Amazon said that its AI model had guardrails in place to make sure that these recaps don’t inadvertently share spoilers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069201" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/image002.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Prime Video&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have become accustomed to these kinds of text-based AI summaries, since they likely see them when their phone summarizes texts, or when they see a (perhaps unwanted) AI summary at the top of their Google results. But these video summaries veer into newer territory, which may appear more obtrusive in the viewing experience than text summaries — or, maybe they’ll be embraced by people who don’t remember what happened on “Bosch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prime Video’s competitors are also exploring how they can integrate generative AI into their products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube TV, for example, uses a “Key Plays” feature to help viewers catch up on sports games if they start watching while the game is in progress. While it’s a bit imperfect (its algorithm seems to only be able to identify key offensive plays in baseball), the feature helped YouTube TV win its first Technical Emmy Award.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix, meanwhile, is using generative AI on the production side of its business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it&amp;nbsp;used generative AI&amp;nbsp;in the final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. After that, “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, and the producers of “Billionaires’ Bunker” used it in pre-production to envision wardrobe and set design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in the film industry has sparked much debate, as artists worry that these tools — which sometimes are trained without permission on their work — could endanger their livelihoods. But some argue that tools that speed up tedious busywork in animation or special effects, like Wonder Dynamics, could expand the capacity for artists to create.&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I guess we’re past the era of “&lt;em&gt;and that’s what you missed on Glee&lt;/em&gt;.” Amazon’s Prime Video streamer is adding AI-generated “Video Recaps” to help viewers catch up between seasons of shows, the company announced on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Amazon, the feature “utilizes generative AI to create theatrical-quality season recaps with synchronized narration, dialogue, and music.” It will begin rolling out in beta on Wednesday for select Prime Originals, like “Fallout,” “Tom Clancy’s Jack Ryan,” and “Upload.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prime Video launched a similar AI-powered feature last year called “X-Ray Recaps,” which summarizes complete seasons, episodes, or parts of episodes — at the time, Amazon said that its AI model had guardrails in place to make sure that these recaps don’t inadvertently share spoilers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069201" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/image002.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Prime Video&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have become accustomed to these kinds of text-based AI summaries, since they likely see them when their phone summarizes texts, or when they see a (perhaps unwanted) AI summary at the top of their Google results. But these video summaries veer into newer territory, which may appear more obtrusive in the viewing experience than text summaries — or, maybe they’ll be embraced by people who don’t remember what happened on “Bosch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prime Video’s competitors are also exploring how they can integrate generative AI into their products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube TV, for example, uses a “Key Plays” feature to help viewers catch up on sports games if they start watching while the game is in progress. While it’s a bit imperfect (its algorithm seems to only be able to identify key offensive plays in baseball), the feature helped YouTube TV win its first Technical Emmy Award.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix, meanwhile, is using generative AI on the production side of its business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it&amp;nbsp;used generative AI&amp;nbsp;in the final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. After that, “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, and the producers of “Billionaires’ Bunker” used it in pre-production to envision wardrobe and set design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in the film industry has sparked much debate, as artists worry that these tools — which sometimes are trained without permission on their work — could endanger their livelihoods. But some argue that tools that speed up tedious busywork in animation or special effects, like Wonder Dynamics, could expand the capacity for artists to create.&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/amazons-prime-video-is-getting-ai-generated-video-recaps-for-some-tv-shows/</guid><pubDate>Wed, 19 Nov 2025 17:30:00 +0000</pubDate></item><item><title>The Google Search of AI agents? Fetch launches ASI:One and Business tier for new era of non-human web (AI | VentureBeat)</title><link>https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://fetch.ai/"&gt;Fetch AI&lt;/a&gt;, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, &lt;a href="https://www.businesswire.com/news/home/20251119088395/en/Fetch-Combines-Personalized-AI-with-Multi-Agent-Collaboration-to-Handle-Complex-Consumer-Tasks-Launches-Claim-Your-Agent-to-Fight-Brand-Knock-Offs"&gt;on Wednesday announced the release&lt;/a&gt; of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. &lt;/p&gt;&lt;p&gt;The launch includes &lt;a href="https://asi1.ai/"&gt;ASI:One&lt;/a&gt;, a personal-AI orchestration platform; &lt;a href="https://business.fetch.ai/"&gt;Fetch Business&lt;/a&gt;, a verification and discovery portal for brand agents; and &lt;a href="https://agentverse.ai/?sort=relevancy&amp;amp;page=1&amp;amp;recommended=true"&gt;Agentverse&lt;/a&gt;, an open directory hosting more than two million agents. &lt;/p&gt;&lt;p&gt;Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.&lt;/p&gt;&lt;p&gt;The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.&lt;/p&gt;&lt;p&gt;“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch’s founding and DeepMind connection &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.&lt;/p&gt;&lt;p&gt;His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. &lt;/p&gt;&lt;p&gt;Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.&lt;/p&gt;&lt;p&gt;Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. &lt;/p&gt;&lt;p&gt;The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ASI:One is a platform for multi-agent orchestration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the core of the launch is &lt;b&gt;ASI:One&lt;/b&gt;, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.&lt;/p&gt;&lt;p&gt;The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task — such as planning a trip with flights, hotels, and restaurant reservations — ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.&lt;/p&gt;&lt;p&gt;In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.&lt;/p&gt;&lt;p&gt;Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” &lt;/p&gt;&lt;p&gt;He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough — you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”&lt;/p&gt;&lt;p&gt;The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. &lt;/p&gt;&lt;p&gt;These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.&lt;/p&gt;&lt;p&gt;ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch Business offers verified identity and brand control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. &lt;/p&gt;&lt;p&gt;The platform allows organizations to verify their identity and claim an official Brand Agent handle — for example, @Hilton or @Nike — regardless of which tools they use to build the underlying agent.&lt;/p&gt;&lt;p&gt;Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.&lt;/p&gt;&lt;p&gt;The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. &lt;/p&gt;&lt;p&gt;“With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.&lt;/p&gt;&lt;p&gt;The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.&lt;/p&gt;&lt;p&gt;The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”&lt;/p&gt;&lt;p&gt;Companies can begin claiming agents now at &lt;a href="https://business.fetch.ai/"&gt;&lt;b&gt;business.fetch.ai&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Agentverse is an open directory of more yhan 2 million agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The final component of the release is &lt;a href="https://agentverse.ai/"&gt;Agentverse&lt;/a&gt;, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.&lt;/p&gt;&lt;p&gt;Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.&lt;/p&gt;&lt;p&gt;According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. &lt;/p&gt;&lt;p&gt;He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”&lt;/p&gt;&lt;p&gt;The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.&lt;/p&gt;&lt;p&gt;Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry context and implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.&lt;/p&gt;&lt;p&gt;Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.&lt;/p&gt;&lt;p&gt;At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.&lt;/p&gt;&lt;p&gt;The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.&lt;/p&gt;&lt;p&gt;Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis — rooted partly in lessons from DeepMind’s early development — that intelligence becomes meaningful only when paired with the capacity to act.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://fetch.ai/"&gt;Fetch AI&lt;/a&gt;, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, &lt;a href="https://www.businesswire.com/news/home/20251119088395/en/Fetch-Combines-Personalized-AI-with-Multi-Agent-Collaboration-to-Handle-Complex-Consumer-Tasks-Launches-Claim-Your-Agent-to-Fight-Brand-Knock-Offs"&gt;on Wednesday announced the release&lt;/a&gt; of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. &lt;/p&gt;&lt;p&gt;The launch includes &lt;a href="https://asi1.ai/"&gt;ASI:One&lt;/a&gt;, a personal-AI orchestration platform; &lt;a href="https://business.fetch.ai/"&gt;Fetch Business&lt;/a&gt;, a verification and discovery portal for brand agents; and &lt;a href="https://agentverse.ai/?sort=relevancy&amp;amp;page=1&amp;amp;recommended=true"&gt;Agentverse&lt;/a&gt;, an open directory hosting more than two million agents. &lt;/p&gt;&lt;p&gt;Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.&lt;/p&gt;&lt;p&gt;The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.&lt;/p&gt;&lt;p&gt;“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch’s founding and DeepMind connection &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.&lt;/p&gt;&lt;p&gt;His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. &lt;/p&gt;&lt;p&gt;Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.&lt;/p&gt;&lt;p&gt;Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. &lt;/p&gt;&lt;p&gt;The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ASI:One is a platform for multi-agent orchestration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the core of the launch is &lt;b&gt;ASI:One&lt;/b&gt;, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.&lt;/p&gt;&lt;p&gt;The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task — such as planning a trip with flights, hotels, and restaurant reservations — ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.&lt;/p&gt;&lt;p&gt;In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.&lt;/p&gt;&lt;p&gt;Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” &lt;/p&gt;&lt;p&gt;He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough — you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”&lt;/p&gt;&lt;p&gt;The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. &lt;/p&gt;&lt;p&gt;These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.&lt;/p&gt;&lt;p&gt;ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch Business offers verified identity and brand control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. &lt;/p&gt;&lt;p&gt;The platform allows organizations to verify their identity and claim an official Brand Agent handle — for example, @Hilton or @Nike — regardless of which tools they use to build the underlying agent.&lt;/p&gt;&lt;p&gt;Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.&lt;/p&gt;&lt;p&gt;The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. &lt;/p&gt;&lt;p&gt;“With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.&lt;/p&gt;&lt;p&gt;The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.&lt;/p&gt;&lt;p&gt;The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”&lt;/p&gt;&lt;p&gt;Companies can begin claiming agents now at &lt;a href="https://business.fetch.ai/"&gt;&lt;b&gt;business.fetch.ai&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Agentverse is an open directory of more yhan 2 million agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The final component of the release is &lt;a href="https://agentverse.ai/"&gt;Agentverse&lt;/a&gt;, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.&lt;/p&gt;&lt;p&gt;Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.&lt;/p&gt;&lt;p&gt;According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. &lt;/p&gt;&lt;p&gt;He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”&lt;/p&gt;&lt;p&gt;The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.&lt;/p&gt;&lt;p&gt;Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry context and implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.&lt;/p&gt;&lt;p&gt;Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.&lt;/p&gt;&lt;p&gt;At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.&lt;/p&gt;&lt;p&gt;The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.&lt;/p&gt;&lt;p&gt;Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis — rooted partly in lessons from DeepMind’s early development — that intelligence becomes meaningful only when paired with the capacity to act.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for</guid><pubDate>Wed, 19 Nov 2025 17:57:00 +0000</pubDate></item><item><title>[NEW] Why January Ventures is funding underrepresented AI founders (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/why-january-ventures-is-funding-underrepresented-ai-founders/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Interview-1118-Jennifer-Neundorfer.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30692601"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;While everyone’s chasing the next AI infrastructure play in San Francisco, some of the most defensible AI companies are being built by founders with deep expertise in legacy industries — and they’re not getting funded. January Ventures aims to fill that gap, writing pre-seed checks for underrepresented founders transforming healthcare, manufacturing, and supply chain with AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At TechCrunch Disrupt 2025, Dominic-Madori Davis sat down with Jennifer Neundorfer, co-founder and general partner at January Ventures, for a live episode of Equity. The pair dug into how early-stage investing is changing in the age of AI and why building different networks matters.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Interview-1118-Jennifer-Neundorfer.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30692601"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;While everyone’s chasing the next AI infrastructure play in San Francisco, some of the most defensible AI companies are being built by founders with deep expertise in legacy industries — and they’re not getting funded. January Ventures aims to fill that gap, writing pre-seed checks for underrepresented founders transforming healthcare, manufacturing, and supply chain with AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At TechCrunch Disrupt 2025, Dominic-Madori Davis sat down with Jennifer Neundorfer, co-founder and general partner at January Ventures, for a live episode of Equity. The pair dug into how early-stage investing is changing in the age of AI and why building different networks matters.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/why-january-ventures-is-funding-underrepresented-ai-founders/</guid><pubDate>Wed, 19 Nov 2025 18:15:45 +0000</pubDate></item><item><title>[NEW] OpenAI debuts GPT‑5.1-Codex-Max coding model and it already completed a 24-hour task internally (AI | VentureBeat)</title><link>https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24</link><description>[unable to retrieve full-text content]&lt;p&gt;OpenAI has &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;&lt;b&gt;introduced GPT‑5.1-Codex-Max&lt;/b&gt;&lt;/a&gt;, a new frontier agentic coding model now available in its Codex developer environment. The release marks a significant step forward in AI-assisted software engineering, offering improved long-horizon reasoning, efficiency, and real-time interactive capabilities. GPT‑5.1-Codex-Max will now replace GPT‑5.1-Codex as the default model across Codex-integrated surfaces.&lt;/p&gt;&lt;p&gt;The new model is designed to serve as a persistent, high-context software development agent, capable of managing complex refactors, debugging workflows, and project-scale tasks across multiple context windows.&lt;/p&gt;&lt;p&gt;It comes on the heels of&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt; Google releasing its powerful new Gemini 3 Pro model&lt;/a&gt; yesterday, yet still outperforms or matches it on key coding benchmarks: &lt;/p&gt;&lt;p&gt;On &lt;b&gt;SWE-Bench Verified&lt;/b&gt;, &lt;b&gt;GPT‑5.1-Codex-Max achieved 77.9% accuracy&lt;/b&gt; at extra-high reasoning effort, edging past Gemini 3 Pro’s 76.2%. &lt;/p&gt;&lt;p&gt;It also led on &lt;b&gt;Terminal-Bench 2.0, with 58.1% accuracy versus Gemini’s 54.2%, &lt;/b&gt;and matched Gemini’s score of 2,439 on LiveCodeBench Pro, a competitive coding Elo benchmark.&lt;/p&gt;&lt;p&gt;When measured against Gemini 3 Pro’s most advanced configuration — its Deep Thinking model — Codex-Max holds a slight edge in agentic coding benchmarks, as well. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Benchmarks: Incremental Gains Across Key Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max demonstrates measurable improvements over GPT‑5.1-Codex across a range of standard software engineering benchmarks. &lt;/p&gt;&lt;p&gt;On SWE-Lancer IC SWE, it achieved 79.9% accuracy, a significant increase from GPT‑5.1-Codex’s 66.3%. In SWE-Bench Verified (n=500), it reached 77.9% accuracy at extra-high reasoning effort, outperforming GPT‑5.1-Codex’s 73.7%.&lt;/p&gt;&lt;p&gt;Performance on Terminal Bench 2.0 (n=89) showed more modest improvements, with GPT‑5.1-Codex-Max achieving 58.1% accuracy compared to 52.8% for GPT‑5.1-Codex. &lt;/p&gt;&lt;p&gt;All evaluations were run with compaction and extra-high reasoning effort enabled.&lt;/p&gt;&lt;p&gt;These results indicate that the new model offers a higher ceiling on both benchmarked correctness and real-world usability under extended reasoning loads.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Architecture: Long-Horizon Reasoning via Compaction&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A major architectural improvement in GPT‑5.1-Codex-Max is its ability to reason effectively over extended input-output sessions using a mechanism called &lt;b&gt;compaction&lt;/b&gt;. &lt;/p&gt;&lt;p&gt;This enables the model to retain key contextual information while discarding irrelevant details as it nears its context window limit — effectively allowing for continuous work across millions of tokens without performance degradation.&lt;/p&gt;&lt;p&gt;The model has been internally observed to complete tasks lasting more than 24 hours, including multi-step refactors, test-driven iteration, and autonomous debugging.&lt;/p&gt;&lt;p&gt;Compaction also improves token efficiency. At medium reasoning effort, GPT‑5.1-Codex-Max used approximately 30% fewer thinking tokens than GPT‑5.1-Codex for comparable or better accuracy, which has implications for both cost and latency.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Platform Integration and Use Cases&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max is currently available across multiple Codex-based environments, which refer to OpenAI’s own integrated tools and interfaces built specifically for code-focused AI agents. These include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Codex CLI&lt;/b&gt;, OpenAI’s official command-line tool (@openai/codex), where GPT‑5.1-Codex-Max is already live.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;IDE extensions&lt;/b&gt;, likely developed or maintained by OpenAI, though no specific third-party IDE integrations were named.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Interactive coding environments&lt;/b&gt;, such as those used to demonstrate frontend simulation apps like CartPole or Snell’s Law Explorer.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Internal code review tooling&lt;/b&gt;, used by OpenAI’s engineering teams.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For now, GPT‑5.1-Codex-Max is not yet available via public API, though OpenAI states this is coming soon. Users who wish to work with the model in terminal environments today can do so by installing and using the Codex CLI.&lt;/p&gt;&lt;p&gt;It is not currently confirmed whether or how the model will integrate into third-party IDEs unless they are built on top of the CLI or future API.&lt;/p&gt;&lt;p&gt;The model is capable of interacting with live tools and simulations. Examples shown in the release include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;An interactive CartPole policy gradient simulator, which visualizes reinforcement learning training and activations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A Snell’s Law optics explorer, supporting dynamic ray tracing across refractive indices.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These interfaces exemplify the model’s ability to reason in real time while maintaining an interactive development session — effectively bridging computation, visualization, and implementation within a single loop.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Cybersecurity and Safety Constraints&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While GPT‑5.1-Codex-Max does not meet OpenAI’s “High” capability threshold for cybersecurity under its Preparedness Framework, it is currently the most capable cybersecurity model OpenAI has deployed. It supports use cases such as automated vulnerability detection and remediation, but with strict sandboxing and disabled network access by default.&lt;/p&gt;&lt;p&gt;OpenAI reports no increase in scaled malicious use but has introduced enhanced monitoring systems, including activity routing and disruption mechanisms for suspicious behavior. Codex remains isolated to a local workspace unless developers opt-in to broader access, mitigating risks like prompt injection from untrusted content.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Deployment Context and Developer Usage&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max is currently available to users on &lt;b&gt;ChatGPT Plus, Pro, Business, Edu, and Enterprise&lt;/b&gt; plans. It will also become the new default in Codex-based environments, replacing GPT‑5.1-Codex, which was a more general-purpose model.&lt;/p&gt;&lt;p&gt;OpenAI states that 95% of its internal engineers use Codex weekly, and since adoption, these engineers have shipped ~70% more pull requests on average — highlighting the tool’s impact on internal development velocity.&lt;/p&gt;&lt;p&gt;Despite its autonomy and persistence, OpenAI stresses that Codex-Max should be treated as a coding assistant, not a replacement for human review. The model produces terminal logs, test citations, and tool call outputs to support transparency in generated code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Outlook&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max represents a significant evolution in OpenAI’s strategy toward agentic development tools, offering greater reasoning depth, token efficiency, and interactive capabilities across software engineering tasks. By extending its context management and compaction strategies, the model is positioned to handle tasks at the scale of full repositories, rather than individual files or snippets.&lt;/p&gt;&lt;p&gt;With continued emphasis on agentic workflows, secure sandboxes, and real-world evaluation metrics, Codex-Max sets the stage for the next generation of AI-assisted programming environments — while underscoring the importance of oversight in increasingly autonomous systems.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;OpenAI has &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;&lt;b&gt;introduced GPT‑5.1-Codex-Max&lt;/b&gt;&lt;/a&gt;, a new frontier agentic coding model now available in its Codex developer environment. The release marks a significant step forward in AI-assisted software engineering, offering improved long-horizon reasoning, efficiency, and real-time interactive capabilities. GPT‑5.1-Codex-Max will now replace GPT‑5.1-Codex as the default model across Codex-integrated surfaces.&lt;/p&gt;&lt;p&gt;The new model is designed to serve as a persistent, high-context software development agent, capable of managing complex refactors, debugging workflows, and project-scale tasks across multiple context windows.&lt;/p&gt;&lt;p&gt;It comes on the heels of&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt; Google releasing its powerful new Gemini 3 Pro model&lt;/a&gt; yesterday, yet still outperforms or matches it on key coding benchmarks: &lt;/p&gt;&lt;p&gt;On &lt;b&gt;SWE-Bench Verified&lt;/b&gt;, &lt;b&gt;GPT‑5.1-Codex-Max achieved 77.9% accuracy&lt;/b&gt; at extra-high reasoning effort, edging past Gemini 3 Pro’s 76.2%. &lt;/p&gt;&lt;p&gt;It also led on &lt;b&gt;Terminal-Bench 2.0, with 58.1% accuracy versus Gemini’s 54.2%, &lt;/b&gt;and matched Gemini’s score of 2,439 on LiveCodeBench Pro, a competitive coding Elo benchmark.&lt;/p&gt;&lt;p&gt;When measured against Gemini 3 Pro’s most advanced configuration — its Deep Thinking model — Codex-Max holds a slight edge in agentic coding benchmarks, as well. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Benchmarks: Incremental Gains Across Key Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max demonstrates measurable improvements over GPT‑5.1-Codex across a range of standard software engineering benchmarks. &lt;/p&gt;&lt;p&gt;On SWE-Lancer IC SWE, it achieved 79.9% accuracy, a significant increase from GPT‑5.1-Codex’s 66.3%. In SWE-Bench Verified (n=500), it reached 77.9% accuracy at extra-high reasoning effort, outperforming GPT‑5.1-Codex’s 73.7%.&lt;/p&gt;&lt;p&gt;Performance on Terminal Bench 2.0 (n=89) showed more modest improvements, with GPT‑5.1-Codex-Max achieving 58.1% accuracy compared to 52.8% for GPT‑5.1-Codex. &lt;/p&gt;&lt;p&gt;All evaluations were run with compaction and extra-high reasoning effort enabled.&lt;/p&gt;&lt;p&gt;These results indicate that the new model offers a higher ceiling on both benchmarked correctness and real-world usability under extended reasoning loads.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Architecture: Long-Horizon Reasoning via Compaction&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A major architectural improvement in GPT‑5.1-Codex-Max is its ability to reason effectively over extended input-output sessions using a mechanism called &lt;b&gt;compaction&lt;/b&gt;. &lt;/p&gt;&lt;p&gt;This enables the model to retain key contextual information while discarding irrelevant details as it nears its context window limit — effectively allowing for continuous work across millions of tokens without performance degradation.&lt;/p&gt;&lt;p&gt;The model has been internally observed to complete tasks lasting more than 24 hours, including multi-step refactors, test-driven iteration, and autonomous debugging.&lt;/p&gt;&lt;p&gt;Compaction also improves token efficiency. At medium reasoning effort, GPT‑5.1-Codex-Max used approximately 30% fewer thinking tokens than GPT‑5.1-Codex for comparable or better accuracy, which has implications for both cost and latency.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Platform Integration and Use Cases&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max is currently available across multiple Codex-based environments, which refer to OpenAI’s own integrated tools and interfaces built specifically for code-focused AI agents. These include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Codex CLI&lt;/b&gt;, OpenAI’s official command-line tool (@openai/codex), where GPT‑5.1-Codex-Max is already live.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;IDE extensions&lt;/b&gt;, likely developed or maintained by OpenAI, though no specific third-party IDE integrations were named.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Interactive coding environments&lt;/b&gt;, such as those used to demonstrate frontend simulation apps like CartPole or Snell’s Law Explorer.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Internal code review tooling&lt;/b&gt;, used by OpenAI’s engineering teams.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For now, GPT‑5.1-Codex-Max is not yet available via public API, though OpenAI states this is coming soon. Users who wish to work with the model in terminal environments today can do so by installing and using the Codex CLI.&lt;/p&gt;&lt;p&gt;It is not currently confirmed whether or how the model will integrate into third-party IDEs unless they are built on top of the CLI or future API.&lt;/p&gt;&lt;p&gt;The model is capable of interacting with live tools and simulations. Examples shown in the release include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;An interactive CartPole policy gradient simulator, which visualizes reinforcement learning training and activations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A Snell’s Law optics explorer, supporting dynamic ray tracing across refractive indices.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These interfaces exemplify the model’s ability to reason in real time while maintaining an interactive development session — effectively bridging computation, visualization, and implementation within a single loop.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Cybersecurity and Safety Constraints&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While GPT‑5.1-Codex-Max does not meet OpenAI’s “High” capability threshold for cybersecurity under its Preparedness Framework, it is currently the most capable cybersecurity model OpenAI has deployed. It supports use cases such as automated vulnerability detection and remediation, but with strict sandboxing and disabled network access by default.&lt;/p&gt;&lt;p&gt;OpenAI reports no increase in scaled malicious use but has introduced enhanced monitoring systems, including activity routing and disruption mechanisms for suspicious behavior. Codex remains isolated to a local workspace unless developers opt-in to broader access, mitigating risks like prompt injection from untrusted content.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Deployment Context and Developer Usage&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max is currently available to users on &lt;b&gt;ChatGPT Plus, Pro, Business, Edu, and Enterprise&lt;/b&gt; plans. It will also become the new default in Codex-based environments, replacing GPT‑5.1-Codex, which was a more general-purpose model.&lt;/p&gt;&lt;p&gt;OpenAI states that 95% of its internal engineers use Codex weekly, and since adoption, these engineers have shipped ~70% more pull requests on average — highlighting the tool’s impact on internal development velocity.&lt;/p&gt;&lt;p&gt;Despite its autonomy and persistence, OpenAI stresses that Codex-Max should be treated as a coding assistant, not a replacement for human review. The model produces terminal logs, test citations, and tool call outputs to support transparency in generated code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Outlook&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT‑5.1-Codex-Max represents a significant evolution in OpenAI’s strategy toward agentic development tools, offering greater reasoning depth, token efficiency, and interactive capabilities across software engineering tasks. By extending its context management and compaction strategies, the model is positioned to handle tasks at the scale of full repositories, rather than individual files or snippets.&lt;/p&gt;&lt;p&gt;With continued emphasis on agentic workflows, secure sandboxes, and real-world evaluation metrics, Codex-Max sets the stage for the next generation of AI-assisted programming environments — while underscoring the importance of oversight in increasingly autonomous systems.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24</guid><pubDate>Wed, 19 Nov 2025 19:26:00 +0000</pubDate></item><item><title>[NEW] Warner Music settles copyright lawsuit with Udio, signs deal for AI music platform (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/warner-music-settles-copyright-lawsuit-with-udio-signs-deal-for-ai-music-platform/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2155987987.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Warner Music Group (WMG) has settled a copyright infringement case with AI music startup Udio, the label announced on Wednesday. The two have also entered into a licensing deal for an AI music creation service that’s set to launch in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its press release, WMG said that the “next-generation music creation, listening, and discovery platform” will be powered by generative AI models trained on licensed and authorized music.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says the platform will create “new revenue streams for artists and songwriters, while ensuring their work remains protected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The subscription service will allow users to make remixes, covers, and new songs using the voices of artists and compositions of songwriters who choose to participate. Warner Music Group says the platform will ensure artists and songwriters are credited and compensated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re unwaveringly committed to the protection of the rights of our artists and songwriters, and Udio has taken meaningful steps to ensure that the music on its service will be authorized and licensed,” said WMG CEO Robert Kyncl in the press release. “This collaboration aligns with our broader efforts to responsibly unlock AI’s potential — fueling new creative and commercial possibilities while continuing to deliver innovative experiences for fans.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Artists signed to WMG include Lady Gaga, Coldplay, The Weeknd, Sabrina Carpenter, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This partnership is a crucial step towards realizing a future in which technology amplifies creativity and unlocks new opportunities for artists and songwriters,” said Udio co-founder and CEO Andrew Sanchez in the press release. “Our new platform will enable experiences where fans can create alongside their favorite artists and make extraordinary music in an environment that offers artists control and connection.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The settlement marks a significant shift in the music industry’s approach to AI. Warner Music Group, Universal Music Group, and Sony Music Entertainment sued Udio and rival AI music platform Suno last year for copyright infringement. Both platforms allow users to generate songs using AI-powered text prompts. Universal Music Group and Sony Music Entertainment are also reportedly in talks to license their work to Udio and Suno.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a sign of investor confidence in AI music technology, Suno announced earlier on Wednesday that it has raised a $250 million Series C round at a $2.45 billion post-money valuation. The round was led by Menlo Ventures with participation from Nvidia’s venture arm NVentures, as well as Hallwood Media, Lightspeed, and Matrix.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2155987987.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Warner Music Group (WMG) has settled a copyright infringement case with AI music startup Udio, the label announced on Wednesday. The two have also entered into a licensing deal for an AI music creation service that’s set to launch in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its press release, WMG said that the “next-generation music creation, listening, and discovery platform” will be powered by generative AI models trained on licensed and authorized music.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says the platform will create “new revenue streams for artists and songwriters, while ensuring their work remains protected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The subscription service will allow users to make remixes, covers, and new songs using the voices of artists and compositions of songwriters who choose to participate. Warner Music Group says the platform will ensure artists and songwriters are credited and compensated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re unwaveringly committed to the protection of the rights of our artists and songwriters, and Udio has taken meaningful steps to ensure that the music on its service will be authorized and licensed,” said WMG CEO Robert Kyncl in the press release. “This collaboration aligns with our broader efforts to responsibly unlock AI’s potential — fueling new creative and commercial possibilities while continuing to deliver innovative experiences for fans.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Artists signed to WMG include Lady Gaga, Coldplay, The Weeknd, Sabrina Carpenter, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This partnership is a crucial step towards realizing a future in which technology amplifies creativity and unlocks new opportunities for artists and songwriters,” said Udio co-founder and CEO Andrew Sanchez in the press release. “Our new platform will enable experiences where fans can create alongside their favorite artists and make extraordinary music in an environment that offers artists control and connection.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The settlement marks a significant shift in the music industry’s approach to AI. Warner Music Group, Universal Music Group, and Sony Music Entertainment sued Udio and rival AI music platform Suno last year for copyright infringement. Both platforms allow users to generate songs using AI-powered text prompts. Universal Music Group and Sony Music Entertainment are also reportedly in talks to license their work to Udio and Suno.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a sign of investor confidence in AI music technology, Suno announced earlier on Wednesday that it has raised a $250 million Series C round at a $2.45 billion post-money valuation. The round was led by Menlo Ventures with participation from Nvidia’s venture arm NVentures, as well as Hallwood Media, Lightspeed, and Matrix.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/warner-music-settles-copyright-lawsuit-with-udio-signs-deal-for-ai-music-platform/</guid><pubDate>Wed, 19 Nov 2025 19:57:09 +0000</pubDate></item><item><title>[NEW] Critics scoff after Microsoft warns AI feature can infect machines and pilfer data (AI – Ars Technica)</title><link>https://arstechnica.com/security/2025/11/critics-scoff-after-microsoft-warns-ai-feature-can-infect-machines-and-pilfer-data/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Integration of Copilot Actions into Windows is off by default, but for how long?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/microsoft-copilot-windows-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/microsoft-copilot-windows-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Photographer: Chona Kasinger/Bloomberg via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Microsoft’s warning on Tuesday that an experimental AI agent integrated into Windows can infect devices and pilfer sensitive user data has set off a familiar response from security-minded critics: Why is Big Tech so intent on pushing new features before their dangerous behaviors can be fully understood and contained?&lt;/p&gt;
&lt;p&gt;As reported Tuesday, Microsoft introduced Copilot Actions, a new set of “experimental agentic features” that, when enabled, perform “everyday tasks like organizing files, scheduling meetings, or sending emails,” and provide “an active digital collaborator that can carry out complex tasks for you to enhance efficiency and productivity.”&lt;/p&gt;
&lt;h2&gt;Hallucinations and prompt injections apply&lt;/h2&gt;
&lt;p&gt;The fanfare, however, came with a significant caveat. Microsoft recommended users enable Copilot Actions only “if you understand the security implications outlined.”&lt;/p&gt;
&lt;p&gt;The admonition is based on known defects inherent in most large language models, including Copilot, as researchers have repeatedly demonstrated.&lt;/p&gt;
&lt;p&gt;One common defect of LLMs causes them to provide factually erroneous and illogical answers, sometimes even to the most basic questions. This propensity for hallucinations, as the behavior has come to be called, means users can’t trust the output of Copilot, Gemini, Claude, or any other AI assistant and instead must independently confirm it.&lt;/p&gt;
&lt;p&gt;Another common LLM landmine is the prompt injection, a class of bug that allows hackers to plant malicious instructions in websites, resumes, and emails. LLMs are programmed to follow directions so eagerly that they are unable to discern those in valid user prompts from those contained in untrusted, third-party content created by attackers. As a result, the LLMs give the attackers the same deference as users.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Both flaws can be exploited in attacks that exfiltrate sensitive data, run malicious code, and steal cryptocurrency. So far, these vulnerabilities have proved impossible for developers to prevent and, in many cases, can only be fixed using bug-specific workarounds developed once a vulnerability has been discovered.&lt;/p&gt;
&lt;p&gt;That, in turn, led to this whopper of a disclosure in Microsoft’s post from Tuesday:&lt;/p&gt;
&lt;p&gt;“As these capabilities are introduced, AI models still face functional limitations in terms of how they behave and occasionally may hallucinate and produce unexpected outputs,” Microsoft said. “Additionally, agentic AI applications introduce novel security risks, such as cross-prompt injection (XPIA), where malicious content embedded in UI elements or documents can override agent instructions, leading to unintended actions like data exfiltration or malware installation.”&lt;/p&gt;
&lt;p&gt;Microsoft indicated that only experienced users should enable Copilot Actions, which is currently available only in beta versions of Windows. The company, however, didn’t describe what type of training or experience such users should have or what actions they should take to prevent their devices from being compromised. I asked Microsoft to provide these details, and the company declined.&lt;/p&gt;
&lt;h2&gt;Like “macros on Marvel superhero crack”&lt;/h2&gt;
&lt;p&gt;Some security experts questioned the value of the warnings in Tuesday’s post, comparing them to warnings Microsoft has provided for decades about the danger of using macros in Office apps. Despite the long-standing advice, macros have remained among the lowest-hanging fruit for hackers out to surreptitiously install malware on Windows machines. One reason for this is that Microsoft has made macros so central to productivity that many users can’t do without them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Microsoft saying ‘don’t enable macros, they’re dangerous’… has never worked well,” independent researcher Kevin Beaumont said. “This is macros on Marvel superhero crack.”&lt;/p&gt;
&lt;p&gt;Beaumont, who is regularly hired to respond to major Windows network compromises inside enterprises, also questioned whether Microsoft will provide a means for admins to adequately restrict Copilot Actions on end-user machines or to identify machines in a network that have the feature turned on.&lt;/p&gt;
&lt;p&gt;A Microsoft spokesperson said IT admins will be able to enable or disable an agent workspace at both account and device levels, using Intune or other MDM (Mobile Device Management) apps.&lt;/p&gt;
&lt;p&gt;Critics voiced other concerns, including the difficulty for even experienced users to detect exploitation attacks targeting the AI agents they’re using.&lt;/p&gt;
&lt;p&gt;“I don’t see how users are going to prevent anything of the sort they are referring to, beyond not surfing the web I guess,” researcher Guillaume Rossolini said.&lt;/p&gt;
&lt;p&gt;Microsoft has stressed that Copilot Actions is an experimental feature that’s turned off by default. That design was likely chosen to limit its access to users with the experience required to understand its risks. Critics, however, noted that previous experimental features—Copilot, for instance—regularly become default capabilities for all users over time. Once that’s done, users who don’t trust the feature are often required to invest time developing unsupported ways to remove the features.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Sound but lofty goals&lt;/h2&gt;
&lt;p&gt;Most of Tuesday’s post focused on Microsoft’s overall strategy for securing agentic features in Windows. Goals for such features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-repudiation, meaning all actions and behaviors must be “observable and distinguishable from those taken by a user”&lt;/li&gt;
&lt;li&gt;Agents must preserve confidentiality when they collect, aggregate, or otherwise utilize user data&lt;/li&gt;
&lt;li&gt;Agents must receive user approval when accessing user data or taking actions&lt;/li&gt;
&lt;/ul&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The goals are sound, but ultimately they depend on users reading the dialog windows that warn of the risks and require careful approval before proceeding. That, in turn, diminishes the value of the protection for many users.&lt;/p&gt;
&lt;p&gt;“The usual caveat applies to such mechanisms that rely on users clicking through a permission prompt,” Earlence Fernandes, a University of California, San Diego professor specializing in AI security, told Ars. “Sometimes those users don’t fully understand what is going on, or they might just get habituated and click ‘yes’ all the time. At which point, the security boundary is not really a boundary.”&lt;/p&gt;
&lt;p&gt;As demonstrated by the rash of “ClickFix” attacks, many users can be tricked into following extremely dangerous instructions. While more experienced users (including a fair number of Ars commenters) blame the victims falling for such scams, these incidents are inevitable for a host of reasons. In some cases, even careful users are fatigued or under emotional distress and slip up as a result. Other users simply lack the knowledge to make informed decisions.&lt;/p&gt;
&lt;p&gt;Microsoft’s warning, one critic said, amounts to little more than a CYA (short for cover your ass), a legal maneuver that attempts to shield a party from liability.&lt;/p&gt;
&lt;p&gt;“Microsoft (like the rest of the industry) has no idea how to stop prompt injection or hallucinations, which makes it fundamentally unfit for almost anything serious,” critic Reed Mideke said. “The solution? Shift liability to the user. Just like every LLM chatbot has a ‘oh by the way, if you use this for anything important be sure to verify the answers” disclaimer, never mind that you wouldn’t need the chatbot in the first place if you knew the answer.”&lt;/p&gt;
&lt;p&gt;As Mideke indicated, most of the criticisms extend to AI offerings other companies—including Apple, Google, and Meta—are integrating into their products. Frequently, these integrations begin as optional features and eventually become default capabilities whether users want them or not.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Integration of Copilot Actions into Windows is off by default, but for how long?
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/microsoft-copilot-windows-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/microsoft-copilot-windows-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Photographer: Chona Kasinger/Bloomberg via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Microsoft’s warning on Tuesday that an experimental AI agent integrated into Windows can infect devices and pilfer sensitive user data has set off a familiar response from security-minded critics: Why is Big Tech so intent on pushing new features before their dangerous behaviors can be fully understood and contained?&lt;/p&gt;
&lt;p&gt;As reported Tuesday, Microsoft introduced Copilot Actions, a new set of “experimental agentic features” that, when enabled, perform “everyday tasks like organizing files, scheduling meetings, or sending emails,” and provide “an active digital collaborator that can carry out complex tasks for you to enhance efficiency and productivity.”&lt;/p&gt;
&lt;h2&gt;Hallucinations and prompt injections apply&lt;/h2&gt;
&lt;p&gt;The fanfare, however, came with a significant caveat. Microsoft recommended users enable Copilot Actions only “if you understand the security implications outlined.”&lt;/p&gt;
&lt;p&gt;The admonition is based on known defects inherent in most large language models, including Copilot, as researchers have repeatedly demonstrated.&lt;/p&gt;
&lt;p&gt;One common defect of LLMs causes them to provide factually erroneous and illogical answers, sometimes even to the most basic questions. This propensity for hallucinations, as the behavior has come to be called, means users can’t trust the output of Copilot, Gemini, Claude, or any other AI assistant and instead must independently confirm it.&lt;/p&gt;
&lt;p&gt;Another common LLM landmine is the prompt injection, a class of bug that allows hackers to plant malicious instructions in websites, resumes, and emails. LLMs are programmed to follow directions so eagerly that they are unable to discern those in valid user prompts from those contained in untrusted, third-party content created by attackers. As a result, the LLMs give the attackers the same deference as users.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Both flaws can be exploited in attacks that exfiltrate sensitive data, run malicious code, and steal cryptocurrency. So far, these vulnerabilities have proved impossible for developers to prevent and, in many cases, can only be fixed using bug-specific workarounds developed once a vulnerability has been discovered.&lt;/p&gt;
&lt;p&gt;That, in turn, led to this whopper of a disclosure in Microsoft’s post from Tuesday:&lt;/p&gt;
&lt;p&gt;“As these capabilities are introduced, AI models still face functional limitations in terms of how they behave and occasionally may hallucinate and produce unexpected outputs,” Microsoft said. “Additionally, agentic AI applications introduce novel security risks, such as cross-prompt injection (XPIA), where malicious content embedded in UI elements or documents can override agent instructions, leading to unintended actions like data exfiltration or malware installation.”&lt;/p&gt;
&lt;p&gt;Microsoft indicated that only experienced users should enable Copilot Actions, which is currently available only in beta versions of Windows. The company, however, didn’t describe what type of training or experience such users should have or what actions they should take to prevent their devices from being compromised. I asked Microsoft to provide these details, and the company declined.&lt;/p&gt;
&lt;h2&gt;Like “macros on Marvel superhero crack”&lt;/h2&gt;
&lt;p&gt;Some security experts questioned the value of the warnings in Tuesday’s post, comparing them to warnings Microsoft has provided for decades about the danger of using macros in Office apps. Despite the long-standing advice, macros have remained among the lowest-hanging fruit for hackers out to surreptitiously install malware on Windows machines. One reason for this is that Microsoft has made macros so central to productivity that many users can’t do without them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Microsoft saying ‘don’t enable macros, they’re dangerous’… has never worked well,” independent researcher Kevin Beaumont said. “This is macros on Marvel superhero crack.”&lt;/p&gt;
&lt;p&gt;Beaumont, who is regularly hired to respond to major Windows network compromises inside enterprises, also questioned whether Microsoft will provide a means for admins to adequately restrict Copilot Actions on end-user machines or to identify machines in a network that have the feature turned on.&lt;/p&gt;
&lt;p&gt;A Microsoft spokesperson said IT admins will be able to enable or disable an agent workspace at both account and device levels, using Intune or other MDM (Mobile Device Management) apps.&lt;/p&gt;
&lt;p&gt;Critics voiced other concerns, including the difficulty for even experienced users to detect exploitation attacks targeting the AI agents they’re using.&lt;/p&gt;
&lt;p&gt;“I don’t see how users are going to prevent anything of the sort they are referring to, beyond not surfing the web I guess,” researcher Guillaume Rossolini said.&lt;/p&gt;
&lt;p&gt;Microsoft has stressed that Copilot Actions is an experimental feature that’s turned off by default. That design was likely chosen to limit its access to users with the experience required to understand its risks. Critics, however, noted that previous experimental features—Copilot, for instance—regularly become default capabilities for all users over time. Once that’s done, users who don’t trust the feature are often required to invest time developing unsupported ways to remove the features.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Sound but lofty goals&lt;/h2&gt;
&lt;p&gt;Most of Tuesday’s post focused on Microsoft’s overall strategy for securing agentic features in Windows. Goals for such features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-repudiation, meaning all actions and behaviors must be “observable and distinguishable from those taken by a user”&lt;/li&gt;
&lt;li&gt;Agents must preserve confidentiality when they collect, aggregate, or otherwise utilize user data&lt;/li&gt;
&lt;li&gt;Agents must receive user approval when accessing user data or taking actions&lt;/li&gt;
&lt;/ul&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The goals are sound, but ultimately they depend on users reading the dialog windows that warn of the risks and require careful approval before proceeding. That, in turn, diminishes the value of the protection for many users.&lt;/p&gt;
&lt;p&gt;“The usual caveat applies to such mechanisms that rely on users clicking through a permission prompt,” Earlence Fernandes, a University of California, San Diego professor specializing in AI security, told Ars. “Sometimes those users don’t fully understand what is going on, or they might just get habituated and click ‘yes’ all the time. At which point, the security boundary is not really a boundary.”&lt;/p&gt;
&lt;p&gt;As demonstrated by the rash of “ClickFix” attacks, many users can be tricked into following extremely dangerous instructions. While more experienced users (including a fair number of Ars commenters) blame the victims falling for such scams, these incidents are inevitable for a host of reasons. In some cases, even careful users are fatigued or under emotional distress and slip up as a result. Other users simply lack the knowledge to make informed decisions.&lt;/p&gt;
&lt;p&gt;Microsoft’s warning, one critic said, amounts to little more than a CYA (short for cover your ass), a legal maneuver that attempts to shield a party from liability.&lt;/p&gt;
&lt;p&gt;“Microsoft (like the rest of the industry) has no idea how to stop prompt injection or hallucinations, which makes it fundamentally unfit for almost anything serious,” critic Reed Mideke said. “The solution? Shift liability to the user. Just like every LLM chatbot has a ‘oh by the way, if you use this for anything important be sure to verify the answers” disclaimer, never mind that you wouldn’t need the chatbot in the first place if you knew the answer.”&lt;/p&gt;
&lt;p&gt;As Mideke indicated, most of the criticisms extend to AI offerings other companies—including Apple, Google, and Meta—are integrating into their products. Frequently, these integrations begin as optional features and eventually become default capabilities whether users want them or not.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2025/11/critics-scoff-after-microsoft-warns-ai-feature-can-infect-machines-and-pilfer-data/</guid><pubDate>Wed, 19 Nov 2025 20:25:46 +0000</pubDate></item><item><title>[NEW] Function Health raises $298M Series B at $2.5B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/function-health-closes-298m-series-b-at-a-2-5b-valuation-launches-medical-intelligence/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1132225622-e1709210197672.jpg?resize=1200,812" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;From electronic health records and blood tests to the stream of data from wearable devices, the amount of health information people generate is accelerating rapidly. Yet, many users struggle to connect this trove of data in a meaningful way and actually use it to improve their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function Health, which offers a regular lab testing service to help people track their health, wants to change that by consolidating health data and making it usable for its customers by connecting that data to an AI model. To further that effort, the company recently raised $298 million in a Series B round led by Redpoint Ventures at a valuation of $2.5 billion. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding round also saw participation from a16z; Aglaé Ventures; Alumni Ventures; NBA athletes Allen Crabbe, Blake Griffin, and Taylor Griffin; Battery Ventures; Nat Friedman and Daniel Gross’ investment firm, NFDG; and Roku founder Anthony Wood. The round brings the company’s total capital raised to $350 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the funding, Function unveiled Medical Intelligence Lab, an effort to build a “medical intelligence” generative AI model that can be used to provide personalized health insights based on users’ data, content, and research. The company said the model is trained by doctors. For its customers, the company is offering an AI chatbot that can answer questions based on their health data and can tap their previous lab results, doctor’s notes, and scans to provide tailored guidance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is not good enough to be in a world where AI exists and not be applying it to your health,” Jonathan Swerdlin, CEO and co-founder of Function, told TechCrunch. “You should be able to manage your biology. The objective of Function Health is to apply the best available technology to human health.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swerdlin noted the platform meets HIPAA standards, fully encrypts user data, and never sells personal information. “Your data and your identity are never for sale. Every bit of your information is fully encrypted and protected. We are committed to keeping you, and your data, safe.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function’s chief medical scientist, Dr. Dan Sodickson, and its co-founder and chief medical officer Dr. Mark Hyman, are together leading development of MI Lab and its team of doctors, researchers, and engineers.&amp;nbsp;The MI model is trained by doctors and they stay involved in the process, Swerdlin said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While the space has many players, Function sets itself apart from competitors like Superpower, Neko Health, and InsideTracker thanks to its device-agnostic approach, Swerdlin said, adding that the platform integrates lab testing, diagnostics, and clinical insights to offer more than a typical AI coach or wellness app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function has 75 locations in the U.S. and members “can get lab tests done at 2,000 Quest locations”, he added. Function says it has completed more than 50 million lab tests since 2023.&lt;/p&gt;









&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to reflect that Function members can access tests at 2,000 quest locations.&lt;/em&gt; &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1132225622-e1709210197672.jpg?resize=1200,812" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;From electronic health records and blood tests to the stream of data from wearable devices, the amount of health information people generate is accelerating rapidly. Yet, many users struggle to connect this trove of data in a meaningful way and actually use it to improve their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function Health, which offers a regular lab testing service to help people track their health, wants to change that by consolidating health data and making it usable for its customers by connecting that data to an AI model. To further that effort, the company recently raised $298 million in a Series B round led by Redpoint Ventures at a valuation of $2.5 billion. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding round also saw participation from a16z; Aglaé Ventures; Alumni Ventures; NBA athletes Allen Crabbe, Blake Griffin, and Taylor Griffin; Battery Ventures; Nat Friedman and Daniel Gross’ investment firm, NFDG; and Roku founder Anthony Wood. The round brings the company’s total capital raised to $350 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the funding, Function unveiled Medical Intelligence Lab, an effort to build a “medical intelligence” generative AI model that can be used to provide personalized health insights based on users’ data, content, and research. The company said the model is trained by doctors. For its customers, the company is offering an AI chatbot that can answer questions based on their health data and can tap their previous lab results, doctor’s notes, and scans to provide tailored guidance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is not good enough to be in a world where AI exists and not be applying it to your health,” Jonathan Swerdlin, CEO and co-founder of Function, told TechCrunch. “You should be able to manage your biology. The objective of Function Health is to apply the best available technology to human health.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swerdlin noted the platform meets HIPAA standards, fully encrypts user data, and never sells personal information. “Your data and your identity are never for sale. Every bit of your information is fully encrypted and protected. We are committed to keeping you, and your data, safe.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function’s chief medical scientist, Dr. Dan Sodickson, and its co-founder and chief medical officer Dr. Mark Hyman, are together leading development of MI Lab and its team of doctors, researchers, and engineers.&amp;nbsp;The MI model is trained by doctors and they stay involved in the process, Swerdlin said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While the space has many players, Function sets itself apart from competitors like Superpower, Neko Health, and InsideTracker thanks to its device-agnostic approach, Swerdlin said, adding that the platform integrates lab testing, diagnostics, and clinical insights to offer more than a typical AI coach or wellness app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Function has 75 locations in the U.S. and members “can get lab tests done at 2,000 Quest locations”, he added. Function says it has completed more than 50 million lab tests since 2023.&lt;/p&gt;









&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to reflect that Function members can access tests at 2,000 quest locations.&lt;/em&gt; &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/function-health-closes-298m-series-b-at-a-2-5b-valuation-launches-medical-intelligence/</guid><pubDate>Wed, 19 Nov 2025 20:30:00 +0000</pubDate></item><item><title>[NEW] VC Jennifer Neundorfer explains how founders can stand out in a crowded AI market (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/vc-jennifer-neundorfer-explains-how-founders-can-stand-out-in-a-crowded-ai-market/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/54886289739_6fa8cfb36d_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;January Ventures co-founder Jennifer Neundorfer stopped by the Equity podcast during TechCrunch Disrupt to chat about fundraising in this very AI-driven market.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founders and investors alike are obsessed with AI, and even Neundorfer said her firm is looking at ways to use AI to make their work more efficient, such as helping to do due diligence on the market and competition. As for companies being built, she has a preference for the founders looking to create something entirely new.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Where I tend to get excited is when I see someone who is using AI to do something that&amp;nbsp;isn’t&amp;nbsp;10x better. It’s actually to&amp;nbsp;create a whole new experience or workflow or behavior,” she said. “That’s what we’re looking at. Less of the incremental changes and more&amp;nbsp;totally new&amp;nbsp;behaviors.”&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;This is getting harder for founders because fatigue, she said, has hit as more AI ideas start to sound the same.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Where&amp;nbsp;I think founders&amp;nbsp;are breaking through is when they can communicate to investors why what they’re doing is&amp;nbsp;really different&amp;nbsp;than the other dozens of startups that are doing that and why they are the team to go after that,” she said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether we are in the so-called AI bubble or not, Neundorfer says a market correction is probably coming, and a lot of the companies getting windfalls of investor money now might not survive. The winners will navigate this moment building “truly category-defining companies,” capturing where the tech is going next. “Founders who can stay ahead of that curve, build at the edge of what’s possible today, and build for what’s coming,” she listed. “Founders who&amp;nbsp;are able to&amp;nbsp;really read the market and understand&amp;nbsp;what it is&amp;nbsp;their&amp;nbsp;customer wants&amp;nbsp;versus just building what is possible. Those are the founders that will have an advantage.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elsewhere on the pod, she spoke about her life before venture, where she worked at YouTube and 21st Century Fox.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“So much of what I did was meet with people who had great technology,” she&amp;nbsp;recalled of&amp;nbsp;her time at 21st Century Fox. Meeting and talking technology with people was the part of the job that gave her the most joy and helped her realize how much she would probably love working with early-stage founders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the learning curve was steep when she decided to transition to investing. In the early days, she said she would constantly check in with founders and give detailed input on their companies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s&amp;nbsp;appropriate&amp;nbsp;for some cases, but it’s really about the relationship with the founder, supporting not only weighing in on the business, but supporting them as a person,” she said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now&amp;nbsp;she’s&amp;nbsp;comfortable in the job. She serves as a mentor for various organizations, such as Techstars, and has&amp;nbsp;made more than 50 investments at January Ventures, according to PitchBook,&amp;nbsp;nabbing&amp;nbsp;some exits in the meantime.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Throughout the conversation, Neundorfer spoke about the changing venture market, funding levels for minorities and women, and about venture markets outside of San Francisco that are seeing success. Her biggest advice to diverse founders right now actually goes for many founders building in this climate: ignore the noise and focus on building a good company.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anything else becomes something they can’t control, and the worry isn’t worth it.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/54886289739_6fa8cfb36d_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;January Ventures co-founder Jennifer Neundorfer stopped by the Equity podcast during TechCrunch Disrupt to chat about fundraising in this very AI-driven market.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founders and investors alike are obsessed with AI, and even Neundorfer said her firm is looking at ways to use AI to make their work more efficient, such as helping to do due diligence on the market and competition. As for companies being built, she has a preference for the founders looking to create something entirely new.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Where I tend to get excited is when I see someone who is using AI to do something that&amp;nbsp;isn’t&amp;nbsp;10x better. It’s actually to&amp;nbsp;create a whole new experience or workflow or behavior,” she said. “That’s what we’re looking at. Less of the incremental changes and more&amp;nbsp;totally new&amp;nbsp;behaviors.”&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;This is getting harder for founders because fatigue, she said, has hit as more AI ideas start to sound the same.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Where&amp;nbsp;I think founders&amp;nbsp;are breaking through is when they can communicate to investors why what they’re doing is&amp;nbsp;really different&amp;nbsp;than the other dozens of startups that are doing that and why they are the team to go after that,” she said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether we are in the so-called AI bubble or not, Neundorfer says a market correction is probably coming, and a lot of the companies getting windfalls of investor money now might not survive. The winners will navigate this moment building “truly category-defining companies,” capturing where the tech is going next. “Founders who can stay ahead of that curve, build at the edge of what’s possible today, and build for what’s coming,” she listed. “Founders who&amp;nbsp;are able to&amp;nbsp;really read the market and understand&amp;nbsp;what it is&amp;nbsp;their&amp;nbsp;customer wants&amp;nbsp;versus just building what is possible. Those are the founders that will have an advantage.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elsewhere on the pod, she spoke about her life before venture, where she worked at YouTube and 21st Century Fox.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“So much of what I did was meet with people who had great technology,” she&amp;nbsp;recalled of&amp;nbsp;her time at 21st Century Fox. Meeting and talking technology with people was the part of the job that gave her the most joy and helped her realize how much she would probably love working with early-stage founders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the learning curve was steep when she decided to transition to investing. In the early days, she said she would constantly check in with founders and give detailed input on their companies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s&amp;nbsp;appropriate&amp;nbsp;for some cases, but it’s really about the relationship with the founder, supporting not only weighing in on the business, but supporting them as a person,” she said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now&amp;nbsp;she’s&amp;nbsp;comfortable in the job. She serves as a mentor for various organizations, such as Techstars, and has&amp;nbsp;made more than 50 investments at January Ventures, according to PitchBook,&amp;nbsp;nabbing&amp;nbsp;some exits in the meantime.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Throughout the conversation, Neundorfer spoke about the changing venture market, funding levels for minorities and women, and about venture markets outside of San Francisco that are seeing success. Her biggest advice to diverse founders right now actually goes for many founders building in this climate: ignore the noise and focus on building a good company.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anything else becomes something they can’t control, and the worry isn’t worth it.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/vc-jennifer-neundorfer-explains-how-founders-can-stand-out-in-a-crowded-ai-market/</guid><pubDate>Wed, 19 Nov 2025 20:30:00 +0000</pubDate></item><item><title>[NEW] The cost of thinking (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/cost-of-thinking-1119</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/mit-mcgovern-costofthinking.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Large language models (LLMs) like ChatGPT can write an essay or plan a menu almost instantly. But until recently, it was also easy to stump them. The models, which rely on language patterns to respond to users’ queries, often failed at math problems and were not good at complex reasoning. Suddenly, however, they’ve gotten a lot better at these things.&lt;/p&gt;&lt;p&gt;A new generation of LLMs known as reasoning models are being trained to solve complex problems. Like humans, they need some time to think through problems like these — and remarkably, scientists at MIT’s McGovern Institute for Brain Research have found that the kinds of problems that require the most processing from reasoning models are the very same problems that people need take their time with. In other words, they report today in the journal &lt;em&gt;PNAS&lt;/em&gt;, the “cost of thinking” for a reasoning model is similar to the cost of thinking for a human.&lt;/p&gt;&lt;p&gt;The researchers, who were led by Evelina Fedorenko, an associate professor of brain and cognitive sciences and an investigator at the McGovern Institute, conclude that in at least one important way, reasoning models have a human-like approach to thinking. That, they note, is not by design. “People who build these models don’t care if they do it like humans. They just want a system that will robustly perform under all sorts of conditions and produce correct responses,” Fedorenko says. “The fact that there’s some convergence is really quite striking.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reasoning models&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Like many forms of artificial intelligence, the new reasoning models are artificial neural networks: computational tools that learn how to process information when they are given data and a problem to solve. Artificial neural networks have been very successful at many of the tasks that the brain’s own neural networks do well — and in some cases, neuroscientists have discovered that those that perform best do share certain aspects of information processing in the brain. Still, some scientists argued that artificial intelligence was not ready to take on more sophisticated aspects of human intelligence.&lt;/p&gt;&lt;p&gt;“Up until recently, I was among the people saying, ‘These models are really good at things like perception and language, but it’s still going to be a long ways off until we have neural network models that can do reasoning,” Fedorenko says. “Then these large reasoning models emerged and they seem to do much better at a lot of these thinking tasks, like solving math problems and writing pieces of computer code.”&lt;/p&gt;&lt;p&gt;Andrea Gregor de Varda, a K. Lisa Yang ICoN Center Fellow and a postdoc in Fedorenko’s lab, explains that reasoning models work out problems step by step. “At some point, people realized that models needed to have more space to perform the actual computations that are needed to solve complex problems,” he says. “The performance started becoming way, way stronger if you let the models break down the problems into parts.”&lt;/p&gt;&lt;p&gt;To encourage models to work through complex problems in steps that lead to correct solutions, engineers can use reinforcement learning. During their training, the models are rewarded for correct answers and penalized for wrong ones. “The models explore the problem space themselves,” de Varda says. “The actions that lead to positive rewards are reinforced, so that they produce correct solutions more often.”&lt;/p&gt;&lt;p&gt;Models trained in this way are much more likely than their predecessors to arrive at the same answers a human would when they are given a reasoning task. Their stepwise problem-solving does mean reasoning models can take a bit longer to find an answer than the LLMs that came before — but since they’re getting right answers where the previous models would have failed, their responses are worth the wait.&lt;/p&gt;&lt;p&gt;The models’ need to take some time to work through complex problems already hints at a parallel to human thinking: if you demand that a person solve a hard problem instantaneously, they’d probably fail, too. De Varda wanted to examine this relationship more systematically. So he gave reasoning models and human volunteers the same set of problems, and tracked not just whether they got the answers right, but also how much time or effort it took them to get there.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Time versus tokens&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This meant measuring how long it took people to respond to each question, down to the millisecond. For the models, Varda used a different metric. It didn’t make sense to measure processing time, since this is more dependent on computer hardware than the effort the model puts into solving a problem. So instead, he tracked tokens, which are part of a model’s internal chain of thought. “They produce tokens that are not meant for the user to see and work on, but just to have some track of the internal computation that they’re doing,” de Varda explains. “It’s as if they were talking to themselves.”&lt;/p&gt;&lt;p&gt;Both humans and reasoning models were asked to solve seven different types of problems, like numeric arithmetic and intuitive reasoning. For each problem class, they were given many problems. The harder a given problem was, the longer it took people to solve it — and the longer it took people to solve a problem, the more tokens a reasoning model generated as it came to its own solution.&lt;/p&gt;&lt;p&gt;Likewise, the classes of problems that humans took longest to solve were the same classes of problems that required the most tokens for the models: arithmetic problems were the least demanding, whereas a group of problems called the “ARC challenge,” where pairs of colored grids represent a transformation that must be inferred and then applied to a new object, were the most costly for both people and models.&lt;/p&gt;&lt;p&gt;De Varda and Fedorenko say the striking match in the costs of thinking demonstrates one way in which reasoning models are thinking like humans. That doesn’t mean the models are recreating human intelligence, though. The researchers still want to know whether the models use similar representations of information to the human brain, and how those representations are transformed into solutions to problems. They’re also curious whether the models will be able to handle problems that require world knowledge that is not spelled out in the texts that are used for model training.&lt;/p&gt;&lt;p&gt;The researchers point out that even though reasoning models generate internal monologues as they solve problems, they are not necessarily using language to think. “If you look at the output that these models produce while reasoning, it often contains errors or some nonsensical bits, even if the model ultimately arrives at a correct answer. So the actual internal computations likely take place in an abstract, non-linguistic representation space, similar to how humans don’t use language to think,” he says.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/mit-mcgovern-costofthinking.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Large language models (LLMs) like ChatGPT can write an essay or plan a menu almost instantly. But until recently, it was also easy to stump them. The models, which rely on language patterns to respond to users’ queries, often failed at math problems and were not good at complex reasoning. Suddenly, however, they’ve gotten a lot better at these things.&lt;/p&gt;&lt;p&gt;A new generation of LLMs known as reasoning models are being trained to solve complex problems. Like humans, they need some time to think through problems like these — and remarkably, scientists at MIT’s McGovern Institute for Brain Research have found that the kinds of problems that require the most processing from reasoning models are the very same problems that people need take their time with. In other words, they report today in the journal &lt;em&gt;PNAS&lt;/em&gt;, the “cost of thinking” for a reasoning model is similar to the cost of thinking for a human.&lt;/p&gt;&lt;p&gt;The researchers, who were led by Evelina Fedorenko, an associate professor of brain and cognitive sciences and an investigator at the McGovern Institute, conclude that in at least one important way, reasoning models have a human-like approach to thinking. That, they note, is not by design. “People who build these models don’t care if they do it like humans. They just want a system that will robustly perform under all sorts of conditions and produce correct responses,” Fedorenko says. “The fact that there’s some convergence is really quite striking.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reasoning models&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Like many forms of artificial intelligence, the new reasoning models are artificial neural networks: computational tools that learn how to process information when they are given data and a problem to solve. Artificial neural networks have been very successful at many of the tasks that the brain’s own neural networks do well — and in some cases, neuroscientists have discovered that those that perform best do share certain aspects of information processing in the brain. Still, some scientists argued that artificial intelligence was not ready to take on more sophisticated aspects of human intelligence.&lt;/p&gt;&lt;p&gt;“Up until recently, I was among the people saying, ‘These models are really good at things like perception and language, but it’s still going to be a long ways off until we have neural network models that can do reasoning,” Fedorenko says. “Then these large reasoning models emerged and they seem to do much better at a lot of these thinking tasks, like solving math problems and writing pieces of computer code.”&lt;/p&gt;&lt;p&gt;Andrea Gregor de Varda, a K. Lisa Yang ICoN Center Fellow and a postdoc in Fedorenko’s lab, explains that reasoning models work out problems step by step. “At some point, people realized that models needed to have more space to perform the actual computations that are needed to solve complex problems,” he says. “The performance started becoming way, way stronger if you let the models break down the problems into parts.”&lt;/p&gt;&lt;p&gt;To encourage models to work through complex problems in steps that lead to correct solutions, engineers can use reinforcement learning. During their training, the models are rewarded for correct answers and penalized for wrong ones. “The models explore the problem space themselves,” de Varda says. “The actions that lead to positive rewards are reinforced, so that they produce correct solutions more often.”&lt;/p&gt;&lt;p&gt;Models trained in this way are much more likely than their predecessors to arrive at the same answers a human would when they are given a reasoning task. Their stepwise problem-solving does mean reasoning models can take a bit longer to find an answer than the LLMs that came before — but since they’re getting right answers where the previous models would have failed, their responses are worth the wait.&lt;/p&gt;&lt;p&gt;The models’ need to take some time to work through complex problems already hints at a parallel to human thinking: if you demand that a person solve a hard problem instantaneously, they’d probably fail, too. De Varda wanted to examine this relationship more systematically. So he gave reasoning models and human volunteers the same set of problems, and tracked not just whether they got the answers right, but also how much time or effort it took them to get there.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Time versus tokens&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This meant measuring how long it took people to respond to each question, down to the millisecond. For the models, Varda used a different metric. It didn’t make sense to measure processing time, since this is more dependent on computer hardware than the effort the model puts into solving a problem. So instead, he tracked tokens, which are part of a model’s internal chain of thought. “They produce tokens that are not meant for the user to see and work on, but just to have some track of the internal computation that they’re doing,” de Varda explains. “It’s as if they were talking to themselves.”&lt;/p&gt;&lt;p&gt;Both humans and reasoning models were asked to solve seven different types of problems, like numeric arithmetic and intuitive reasoning. For each problem class, they were given many problems. The harder a given problem was, the longer it took people to solve it — and the longer it took people to solve a problem, the more tokens a reasoning model generated as it came to its own solution.&lt;/p&gt;&lt;p&gt;Likewise, the classes of problems that humans took longest to solve were the same classes of problems that required the most tokens for the models: arithmetic problems were the least demanding, whereas a group of problems called the “ARC challenge,” where pairs of colored grids represent a transformation that must be inferred and then applied to a new object, were the most costly for both people and models.&lt;/p&gt;&lt;p&gt;De Varda and Fedorenko say the striking match in the costs of thinking demonstrates one way in which reasoning models are thinking like humans. That doesn’t mean the models are recreating human intelligence, though. The researchers still want to know whether the models use similar representations of information to the human brain, and how those representations are transformed into solutions to problems. They’re also curious whether the models will be able to handle problems that require world knowledge that is not spelled out in the texts that are used for model training.&lt;/p&gt;&lt;p&gt;The researchers point out that even though reasoning models generate internal monologues as they solve problems, they are not necessarily using language to think. “If you look at the output that these models produce while reasoning, it often contains errors or some nonsensical bits, even if the model ultimately arrives at a correct answer. So the actual internal computations likely take place in an abstract, non-linguistic representation space, similar to how humans don’t use language to think,” he says.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/cost-of-thinking-1119</guid><pubDate>Wed, 19 Nov 2025 21:45:00 +0000</pubDate></item><item><title>[NEW] Nvidia’s record $57B revenue and upbeat forecast quiets AI bubble talk (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/nvidias-record-57b-revenue-and-upbeat-forecast-quiets-ai-bubble-talk/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205761844.jpg?resize=1200,846" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia founder and CEO Jensen Huang struck a bullish tone in the company’s third-quarter earnings. And based on the company’s results, there may be reason to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia reported revenue of $57 billion in the third quarter, 62% higher compared to the same quarter last year. The company’s net income on a GAAP basis was $32 billion, 65% higher year-over-year. Both revenue and profit results beat Wall Street expectations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The revenue picture shows a company booming thanks largely to its data center business. Revenue generated by Nvidia’s data center business was a record $51.2 billion, up 25% from the previous quarter and up 66% from a year ago. The remaining $5.8 billion in revenue came from Nvidia’s gaming business with $4.2 billion, followed by sales in professional visualization and automotive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia’s CFO Colette Kress noted in a statement to shareholders its data center business has been fueled by an acceleration of computing, powerful AI models, and agentic applications. During the company’s Q3 call, Kress said in this past quarter, the company announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This demand spans every market, CSPs, sovereigns, modern builders enterprises and super computing centers, and includes multiple landmark build outs,” Kress said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackwell Ultra, a GPU unveiled in March and available in several configurations, has been particularly strong and is now the leader within the company. Previous versions of the Blackwell architecture also saw continued strong demand, according to the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang said sales of its Blackwell GPU chips “are off the charts.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Blackwell sales are off the charts, and cloud GPUs are sold out,” Huang said in the company’s Q3 earnings statement. “Compute demand keeps accelerating and compounding across training and inference — each growing exponentially. We’ve entered the virtuous cycle of AI. The AI ecosystem is scaling fast — with more new foundation model makers, more AI startups, across more industries, and in more countries. AI is going everywhere, doing everything, all at once.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kress did note that the company’s shipments of H20, a data center GPU designed for generative AI and high-performance computing, were 50 million, a disappointing result due to its inability to sell to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Sizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China,,” Kress noted on the earnings call. “While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the U.S. and China governments, and will continue to advocate for America’s ability to compete around the world.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Importantly, Nvidia is forecasting more growth with a projected revenue of $65 billion in the fourth quarter, helping push its share price up more than 4% in after-hours trading. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The upshot, at least in Huang’s view: forget about the bubble, there is only growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s been a lot of talk about an AI bubble,” Jensen said during the company’s earnings call. “From our vantage point, we see something very different.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205761844.jpg?resize=1200,846" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia founder and CEO Jensen Huang struck a bullish tone in the company’s third-quarter earnings. And based on the company’s results, there may be reason to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia reported revenue of $57 billion in the third quarter, 62% higher compared to the same quarter last year. The company’s net income on a GAAP basis was $32 billion, 65% higher year-over-year. Both revenue and profit results beat Wall Street expectations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The revenue picture shows a company booming thanks largely to its data center business. Revenue generated by Nvidia’s data center business was a record $51.2 billion, up 25% from the previous quarter and up 66% from a year ago. The remaining $5.8 billion in revenue came from Nvidia’s gaming business with $4.2 billion, followed by sales in professional visualization and automotive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia’s CFO Colette Kress noted in a statement to shareholders its data center business has been fueled by an acceleration of computing, powerful AI models, and agentic applications. During the company’s Q3 call, Kress said in this past quarter, the company announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This demand spans every market, CSPs, sovereigns, modern builders enterprises and super computing centers, and includes multiple landmark build outs,” Kress said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackwell Ultra, a GPU unveiled in March and available in several configurations, has been particularly strong and is now the leader within the company. Previous versions of the Blackwell architecture also saw continued strong demand, according to the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang said sales of its Blackwell GPU chips “are off the charts.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Blackwell sales are off the charts, and cloud GPUs are sold out,” Huang said in the company’s Q3 earnings statement. “Compute demand keeps accelerating and compounding across training and inference — each growing exponentially. We’ve entered the virtuous cycle of AI. The AI ecosystem is scaling fast — with more new foundation model makers, more AI startups, across more industries, and in more countries. AI is going everywhere, doing everything, all at once.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kress did note that the company’s shipments of H20, a data center GPU designed for generative AI and high-performance computing, were 50 million, a disappointing result due to its inability to sell to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Sizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China,,” Kress noted on the earnings call. “While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the U.S. and China governments, and will continue to advocate for America’s ability to compete around the world.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Importantly, Nvidia is forecasting more growth with a projected revenue of $65 billion in the fourth quarter, helping push its share price up more than 4% in after-hours trading. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The upshot, at least in Huang’s view: forget about the bubble, there is only growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s been a lot of talk about an AI bubble,” Jensen said during the company’s earnings call. “From our vantage point, we see something very different.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/nvidias-record-57b-revenue-and-upbeat-forecast-quiets-ai-bubble-talk/</guid><pubDate>Wed, 19 Nov 2025 22:17:45 +0000</pubDate></item><item><title>[NEW] “We’re in an LLM bubble,” Hugging Face CEO says—but not an AI one (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/were-in-an-llm-bubble-hugging-face-ceo-says-but-not-an-ai-one/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The risks of AI investment in manufacturing and other areas are less clear.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A man in a baseball hat talks and gesticulates on stage" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/1763499309592-640x360.webp" width="640" /&gt;
                  &lt;img alt="A man in a baseball hat talks and gesticulates on stage" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/1763499309592-1152x648.webp" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hugging Face CEO Clem Delangue speaking at an Axios event this week.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Axios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;There’s been a lot of talk of an AI bubble lately, especially with regards to circular funding involving companies like OpenAI and Anthropic—but Clem Delangue, CEO of machine learning resources hub Hugging Face, has made the case that the bubble is specific to large language models, which is just one application of AI.&lt;/p&gt;
&lt;p&gt;“I think we’re in an LLM bubble, and I think the LLM bubble might be bursting next year,” he said at an Axios event this week, as quoted in a TechCrunch article. “But ‘LLM’ is just a subset of AI when it comes to applying AI to biology, chemistry, image, audio, [and] video. I think we’re at the beginning of it, and we’ll see much more in the next few years.”&lt;/p&gt;
&lt;p&gt;At Ars, we’ve written at length in recent days about the fears around AI investment. But to Delangue’s point, almost all of those discussions are about companies whose chief product is large language models, or the data centers meant to drive those—specifically, those focused on general-purpose chatbots that are meant to be everything for everybody.&lt;/p&gt;
&lt;p&gt;That’s exactly the sort of application Delangue is bearish on. “I think all the attention, all the focus, all the money, is concentrated into this idea that you can build one model through a bunch of compute and that is going to solve all problems for all companies and all people,” he said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, he imagines the eventual outcome to be “a multiplicity of models that are more customized, specialized, and that are going to solve different problems.”&lt;/p&gt;
&lt;p&gt;It’s of course important to note that his company is focused on being a GitHub-like repo for exactly those sorts of specialized models, including both big models put out there by companies like OpenAI and Meta (gpt-oss and Llama 3.2, for example) and fine-tuned variants that developers have adapted to specific needs or smaller models developed by researchers. That’s essentially what Hugging Face is about.&lt;/p&gt;
&lt;p&gt;So yes, it’s natural that Delangue would say that. However, he’s not alone. In one example, research firm Gartner predicted in April that “the variety of tasks in business workflows and the need for greater accuracy are driving the shift towards specialized models fine-tuned on specific functions or domain data.”&lt;/p&gt;
&lt;p&gt;Regardless of which way LLM-based applications go, investment in other applications of AI-by-the-current-definition is only just getting started. Earlier this week, it was revealed that former Amazon CEO Jeff Bezos will be co-CEO of a new AI startup focused on applications of machine learning in engineering and manufacturing—and that startup has launched with over $6 billion in funding.&lt;/p&gt;
&lt;p&gt;That, too, could be a bubble. But despite that some of Delangue’s statements on the AI bubble discourse are clearly meant to prop up Hugging Face, there’s a helpful reminder in there: The overbroad term “AI” is a lot bigger than just large language models, and we’re still in the early days of seeing where these methodologies will lead us.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The risks of AI investment in manufacturing and other areas are less clear.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A man in a baseball hat talks and gesticulates on stage" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/1763499309592-640x360.webp" width="640" /&gt;
                  &lt;img alt="A man in a baseball hat talks and gesticulates on stage" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/1763499309592-1152x648.webp" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Hugging Face CEO Clem Delangue speaking at an Axios event this week.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Axios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;There’s been a lot of talk of an AI bubble lately, especially with regards to circular funding involving companies like OpenAI and Anthropic—but Clem Delangue, CEO of machine learning resources hub Hugging Face, has made the case that the bubble is specific to large language models, which is just one application of AI.&lt;/p&gt;
&lt;p&gt;“I think we’re in an LLM bubble, and I think the LLM bubble might be bursting next year,” he said at an Axios event this week, as quoted in a TechCrunch article. “But ‘LLM’ is just a subset of AI when it comes to applying AI to biology, chemistry, image, audio, [and] video. I think we’re at the beginning of it, and we’ll see much more in the next few years.”&lt;/p&gt;
&lt;p&gt;At Ars, we’ve written at length in recent days about the fears around AI investment. But to Delangue’s point, almost all of those discussions are about companies whose chief product is large language models, or the data centers meant to drive those—specifically, those focused on general-purpose chatbots that are meant to be everything for everybody.&lt;/p&gt;
&lt;p&gt;That’s exactly the sort of application Delangue is bearish on. “I think all the attention, all the focus, all the money, is concentrated into this idea that you can build one model through a bunch of compute and that is going to solve all problems for all companies and all people,” he said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, he imagines the eventual outcome to be “a multiplicity of models that are more customized, specialized, and that are going to solve different problems.”&lt;/p&gt;
&lt;p&gt;It’s of course important to note that his company is focused on being a GitHub-like repo for exactly those sorts of specialized models, including both big models put out there by companies like OpenAI and Meta (gpt-oss and Llama 3.2, for example) and fine-tuned variants that developers have adapted to specific needs or smaller models developed by researchers. That’s essentially what Hugging Face is about.&lt;/p&gt;
&lt;p&gt;So yes, it’s natural that Delangue would say that. However, he’s not alone. In one example, research firm Gartner predicted in April that “the variety of tasks in business workflows and the need for greater accuracy are driving the shift towards specialized models fine-tuned on specific functions or domain data.”&lt;/p&gt;
&lt;p&gt;Regardless of which way LLM-based applications go, investment in other applications of AI-by-the-current-definition is only just getting started. Earlier this week, it was revealed that former Amazon CEO Jeff Bezos will be co-CEO of a new AI startup focused on applications of machine learning in engineering and manufacturing—and that startup has launched with over $6 billion in funding.&lt;/p&gt;
&lt;p&gt;That, too, could be a bubble. But despite that some of Delangue’s statements on the AI bubble discourse are clearly meant to prop up Hugging Face, there’s a helpful reminder in there: The overbroad term “AI” is a lot bigger than just large language models, and we’re still in the early days of seeing where these methodologies will lead us.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/were-in-an-llm-bubble-hugging-face-ceo-says-but-not-an-ai-one/</guid><pubDate>Wed, 19 Nov 2025 22:57:23 +0000</pubDate></item></channel></rss>