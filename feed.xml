<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 09 Sep 2025 12:45:12 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>[NEW] AI is changing the grid. Could it help more than it harms? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/09/1123404/ai-grid-help/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-2181763351.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The rising popularity of AI is driving an increase in electricity demand so significant it has the potential to reshape our grid. Energy consumption by data centers has gone up by 80% from 2020 to 2025 and is likely to keep growing. Electricity prices are already rising, especially in places where data centers are most concentrated.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet many people, especially in Big Tech, argue that AI will be, on balance, a positive force for the grid. They claim that the technology could help get more clean power online faster, run our power system more efficiently, and predict and prevent failures that cause blackouts.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;There are early examples where AI is helping already, including AI tools that utilities are using to help forecast supply and demand. The question is whether these big promises will be realized fast enough to outweigh the negative effects of AI on local grids and communities.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A delicate balance&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One area where AI is already being used for the grid is in forecasting, says Utkarsha Agwan, a member of the nonprofit group Climate Change AI.&lt;/p&gt; 
 &lt;p&gt;Running the grid is a balancing act: Operators have to understand how much electricity demand there is and turn on the right combination of power plants to meet it. They optimize for economics along the way, choosing the sources that will keep prices lowest for the whole system.&lt;/p&gt;  &lt;p&gt;That makes it necessary to look ahead hours and in some cases days. Operators consider factors such as historical data (holidays often see higher demand) and the weather (a hot day means more air conditioners sucking up power). These predictions also consider what level of supply is expected from intermittent sources like solar panels.&lt;/p&gt; 
 &lt;p&gt;There’s little risk in using AI tools in forecasting; it’s often not as time sensitive as other applications, which can require reactions within seconds or even milliseconds. A grid operator might use a forecast to determine which plants will need to turn on. Other groups might run their own forecasts as well, using AI tools to decide how to staff a plant, for example. The tools also can’t physically control anything. Rather, they can be used alongside more conventional methods to provide more data.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Today, grid operators make a lot of approximations to model the grid, because the system is so incredibly complex that it’s impossible to truly know what’s going on in every place at every time. Not only are there a whole host of power plants and consumers to think about, but there are considerations like making sure power lines don’t get overloaded.&lt;/p&gt;  &lt;p&gt;Working with those estimates can lead to some inefficiencies, says Kyri Baker, a professor at the University of Colorado Boulder. Operators tend to generate a bit more electricity than the system uses, for example. Using AI to create a better model could reduce some of those losses and allow operators to make decisions about how to control infrastructure in real time to reach a closer match of supply and demand.&lt;/p&gt;  &lt;p&gt;She gives the example of a trip to the airport. Imagine there’s a route you know will get you there in about 45 minutes. There might be another, more complicated route that &lt;em&gt;could&lt;/em&gt; save you some time in ideal conditions—but you’re not sure whether it’s better on any particular day. What the grid does now is the equivalent of taking the reliable route.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;“So that’s the gap that AI can help close. We can solve this more complex problem, fast enough and reliably enough that we can possibly use it and shave off emissions,” Baker says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In theory, AI could be used to operate the grid entirely without human intervention. But that work is largely still in the research phase. Grid operators are running some of the most critical infrastructure in this country, and the industry is hesitant to mess with something that’s already working, Baker says. If this sort of technology is ever used in grid operations, there will still be humans in the loop to help make decisions, at least when it’s first deployed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Planning ahead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Another fertile area for AI is planning future updates to the grid. Building a power plant can take a very long time—the typical time from an initial request to commercial operation in the US is roughly four years. One reason for the lengthy wait is that new power plants have to demonstrate how they might affect the rest of the grid before they can connect.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;An interconnection study examines whether adding a new power plant of a particular type in a particular place would require upgrades to the grid to prevent problems. After regulators and utilities determine what upgrades might be needed, they estimate the cost, and the energy developer generally foots the bill.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Today, those studies can take months. They involve trying to understand an incredibly complicated system, and because they rely on estimates of other existing and proposed power plants, only a few can happen in an area at any given time. This has helped create the years-long interconnection queue, a long line of plants waiting for their turn to hook up to the grid in markets like the US and Europe. The vast majority of projects in the queue today are renewables, which means there’s clean power just waiting to come online.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI could help speed this process, producing these reports more quickly. The Midcontinent Independent System Operator, a grid operator that covers 15 states in the central US, is currently working with a company called Pearl Street to help automate these reports.&lt;/p&gt;  &lt;p&gt;AI won’t be a cure-all for grid planning; there are other steps to clearing the interconnection queue, including securing the necessary permits. But the technology could help move things along. “The sooner we can speed up interconnection, the better off we’ll be,” says Rob Gramlich, president of Grid Strategies, a consultancy specializing in transmission and power markets.&lt;/p&gt;  &lt;p&gt;There’s a growing list of other potential uses for AI on the grid and in electricity generation. The technology could monitor and plan ahead for failures in equipment ranging from power lines to gear boxes. Computer vision could help detect everything from wildfires to faulty lines. AI could also help balance supply and demand in virtual power plants, systems of distributed resources like EV chargers or smart water heaters.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;While there are early examples of research and pilot programs for AI from grid planning to operation, some experts are skeptical that the technology will deliver at the level some are hoping for. “It’s not that AI has not had some kind of transformation on power systems,” Climate Change AI’s Agwan says. “It’s that the promise has always been bigger, and the hope has always been bigger.”&lt;/p&gt;  &lt;p&gt;Some places are already seeing higher electricity prices because of power needs from data centers. The situation is likely to get worse. Electricity demand from data centers is set to double by the end of the decade, reaching 945 terawatt-hours, roughly the annual demand from the entire country of Japan.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The infrastructure growth needed to support AI load growth has outpaced the promises of the technology, “by quite a bit,” says Panayiotis Moutis, an assistant professor of electrical engineering at the City University of New York. Higher bills caused by the increasing energy needs of AI aren’t justified by existing ways of using the technology for the grid, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“At the moment, I am very hesitant to lean on the side of AI being a silver bullet,” Moutis says.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-2181763351.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The rising popularity of AI is driving an increase in electricity demand so significant it has the potential to reshape our grid. Energy consumption by data centers has gone up by 80% from 2020 to 2025 and is likely to keep growing. Electricity prices are already rising, especially in places where data centers are most concentrated.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet many people, especially in Big Tech, argue that AI will be, on balance, a positive force for the grid. They claim that the technology could help get more clean power online faster, run our power system more efficiently, and predict and prevent failures that cause blackouts.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;There are early examples where AI is helping already, including AI tools that utilities are using to help forecast supply and demand. The question is whether these big promises will be realized fast enough to outweigh the negative effects of AI on local grids and communities.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A delicate balance&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One area where AI is already being used for the grid is in forecasting, says Utkarsha Agwan, a member of the nonprofit group Climate Change AI.&lt;/p&gt; 
 &lt;p&gt;Running the grid is a balancing act: Operators have to understand how much electricity demand there is and turn on the right combination of power plants to meet it. They optimize for economics along the way, choosing the sources that will keep prices lowest for the whole system.&lt;/p&gt;  &lt;p&gt;That makes it necessary to look ahead hours and in some cases days. Operators consider factors such as historical data (holidays often see higher demand) and the weather (a hot day means more air conditioners sucking up power). These predictions also consider what level of supply is expected from intermittent sources like solar panels.&lt;/p&gt; 
 &lt;p&gt;There’s little risk in using AI tools in forecasting; it’s often not as time sensitive as other applications, which can require reactions within seconds or even milliseconds. A grid operator might use a forecast to determine which plants will need to turn on. Other groups might run their own forecasts as well, using AI tools to decide how to staff a plant, for example. The tools also can’t physically control anything. Rather, they can be used alongside more conventional methods to provide more data.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Today, grid operators make a lot of approximations to model the grid, because the system is so incredibly complex that it’s impossible to truly know what’s going on in every place at every time. Not only are there a whole host of power plants and consumers to think about, but there are considerations like making sure power lines don’t get overloaded.&lt;/p&gt;  &lt;p&gt;Working with those estimates can lead to some inefficiencies, says Kyri Baker, a professor at the University of Colorado Boulder. Operators tend to generate a bit more electricity than the system uses, for example. Using AI to create a better model could reduce some of those losses and allow operators to make decisions about how to control infrastructure in real time to reach a closer match of supply and demand.&lt;/p&gt;  &lt;p&gt;She gives the example of a trip to the airport. Imagine there’s a route you know will get you there in about 45 minutes. There might be another, more complicated route that &lt;em&gt;could&lt;/em&gt; save you some time in ideal conditions—but you’re not sure whether it’s better on any particular day. What the grid does now is the equivalent of taking the reliable route.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;“So that’s the gap that AI can help close. We can solve this more complex problem, fast enough and reliably enough that we can possibly use it and shave off emissions,” Baker says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In theory, AI could be used to operate the grid entirely without human intervention. But that work is largely still in the research phase. Grid operators are running some of the most critical infrastructure in this country, and the industry is hesitant to mess with something that’s already working, Baker says. If this sort of technology is ever used in grid operations, there will still be humans in the loop to help make decisions, at least when it’s first deployed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Planning ahead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Another fertile area for AI is planning future updates to the grid. Building a power plant can take a very long time—the typical time from an initial request to commercial operation in the US is roughly four years. One reason for the lengthy wait is that new power plants have to demonstrate how they might affect the rest of the grid before they can connect.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;An interconnection study examines whether adding a new power plant of a particular type in a particular place would require upgrades to the grid to prevent problems. After regulators and utilities determine what upgrades might be needed, they estimate the cost, and the energy developer generally foots the bill.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Today, those studies can take months. They involve trying to understand an incredibly complicated system, and because they rely on estimates of other existing and proposed power plants, only a few can happen in an area at any given time. This has helped create the years-long interconnection queue, a long line of plants waiting for their turn to hook up to the grid in markets like the US and Europe. The vast majority of projects in the queue today are renewables, which means there’s clean power just waiting to come online.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI could help speed this process, producing these reports more quickly. The Midcontinent Independent System Operator, a grid operator that covers 15 states in the central US, is currently working with a company called Pearl Street to help automate these reports.&lt;/p&gt;  &lt;p&gt;AI won’t be a cure-all for grid planning; there are other steps to clearing the interconnection queue, including securing the necessary permits. But the technology could help move things along. “The sooner we can speed up interconnection, the better off we’ll be,” says Rob Gramlich, president of Grid Strategies, a consultancy specializing in transmission and power markets.&lt;/p&gt;  &lt;p&gt;There’s a growing list of other potential uses for AI on the grid and in electricity generation. The technology could monitor and plan ahead for failures in equipment ranging from power lines to gear boxes. Computer vision could help detect everything from wildfires to faulty lines. AI could also help balance supply and demand in virtual power plants, systems of distributed resources like EV chargers or smart water heaters.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;While there are early examples of research and pilot programs for AI from grid planning to operation, some experts are skeptical that the technology will deliver at the level some are hoping for. “It’s not that AI has not had some kind of transformation on power systems,” Climate Change AI’s Agwan says. “It’s that the promise has always been bigger, and the hope has always been bigger.”&lt;/p&gt;  &lt;p&gt;Some places are already seeing higher electricity prices because of power needs from data centers. The situation is likely to get worse. Electricity demand from data centers is set to double by the end of the decade, reaching 945 terawatt-hours, roughly the annual demand from the entire country of Japan.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The infrastructure growth needed to support AI load growth has outpaced the promises of the technology, “by quite a bit,” says Panayiotis Moutis, an assistant professor of electrical engineering at the City University of New York. Higher bills caused by the increasing energy needs of AI aren’t justified by existing ways of using the technology for the grid, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“At the moment, I am very hesitant to lean on the side of AI being a silver bullet,” Moutis says.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/09/1123404/ai-grid-help/</guid><pubDate>Tue, 09 Sep 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Three big things we still don’t know about AI’s energy burden (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/09/1123408/three-big-things-we-still-dont-know-about-ais-energy-burden/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-517340891.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Earlier this year, when my colleague Casey Crownhart and I spent six months researching the climate and energy burden of AI, we came to see one number in particular as our white whale: how much energy the leading AI models, like ChatGPT or Gemini, use up when generating a single response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This fundamental number remained elusive even as the scramble to power AI escalated to the White House and the Pentagon, and as projections showed that in three years AI could use as much electricity as 22% of all US households.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The problem with finding that number, as we explain in our piece published in May, was that AI companies are the only ones who have it. We pestered Google, OpenAI, and Microsoft, but each company refused to provide its figure. Researchers we spoke to who study AI’s impact on energy grids compared it to trying to measure the fuel efficiency of a car without ever being able to drive it, making guesses based on rumors of its engine size and what it sounds like going down the highway.&lt;/p&gt;  &lt;p&gt;But then this summer, after we published, a strange thing started to happen. In June, OpenAI’s Sam Altman wrote that an average ChatGPT query uses 0.34 watt-hours of energy. In July, the French AI startup Mistral didn’t publish a number directly but released an estimate of the emissions generated. In August, Google revealed that answering a question to Gemini uses about 0.24 watt-hours of energy. The figures from Google and OpenAI were similar to what Casey and I estimated for medium-size AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;So with this newfound transparency, is our job complete? Did we finally harpoon our white whale, and if so, what happens next for people studying the climate impact of AI? I reached out to some of our old sources, and some new ones, to find out.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The numbers are vague and chat-only&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The first thing they told me is that there’s a lot missing from the figures tech companies published this summer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;OpenAI’s number, for example, did not appear in a detailed technical paper but rather in a blog post by Altman that leaves lots of unanswered questions, such as which model he was referring to, how the energy use was measured, and how much it varies. Google’s figure, as Crownhart points out, refers to the median amount of energy per query, which doesn’t give us a sense of the more energy-demanding Gemini responses, like when it uses a reasoning model to “think” through a hard problem or generates a really long response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The numbers also refer only to interactions with chatbots, not the other ways that people are becoming increasingly reliant on generative AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“As video and image becomes more prominent and used by more and more people, we need the numbers from different modalities and how they measure up,” says Sasha Luccioni, AI and climate lead at the AI platform Hugging Face.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is also important because the figures for asking a question to a chatbot are, as expected, undoubtedly small—the same amount of electricity used by a microwave in just seconds. That’s part of the reason AI and climate researchers don’t suggest that any one individual’s AI use creates a significant climate burden.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A full accounting of AI’s energy demands—one that goes beyond what’s used to answer an individual query to help us understand its full net impact on the climate—would require application-specific information on how all this AI is being used. Ketan Joshi, an analyst for climate and energy groups, acknowledges that researchers don’t usually get such specific information from other industries but says it might be justified in this case.&lt;/p&gt;  &lt;p&gt;“The rate of data center growth is inarguably unusual,” Joshi says. “Companies should be subject to significantly more scrutiny.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;We have questions about energy efficiency&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;Companies making billion-dollar investments into AI have struggled to square this growth in energy demand with their sustainability goals. In May, Microsoft said that its emissions have soared by over 23% since 2020, owing largely to AI, while the company has promised to be carbon negative by 2030. “It has become clear that our journey towards being carbon negative is a marathon, not a sprint,” Microsoft wrote.&lt;/p&gt;  &lt;p&gt;Tech companies often justify this emissions burden by arguing that soon enough, AI itself will unlock efficiencies that will make it a net positive for the climate. Perhaps the right AI system, the thinking goes, could design more efficient heating and cooling systems for a building, or help discover the minerals required for electric-vehicle batteries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But there are no signs that AI has been usefully used to do these things yet. Companies have shared anecdotes about using AI to find methane emission hot spots, for example, but they haven’t been transparent enough to help us know if these successes outweigh the surges in electricity demand and emissions that Big Tech has produced in the AI boom. In the meantime, more data centers are planned, and AI’s energy demand continues to rise and rise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The ‘bubble’ question&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;One of the big unknowns in the AI energy equation is whether society will ever adopt AI at the levels that figure into tech companies’ plans. OpenAI has said that ChatGPT receives 2.5 billion prompts per day. It’s possible that this number, and the equivalent numbers for other AI companies, will continue to soar in the coming years. Projections released last year by the Lawrence Berkeley National Laboratory suggest that if they do, AI alone could consume as much electricity annually as 22% of all US households by 2028.&lt;/p&gt;  &lt;p&gt;But this summer also saw signs of a slowdown that undercut the industry’s optimism. OpenAI’s launch of GPT-5 was largely considered a flop, even by the company itself, and that flop led critics to wonder if AI may be hitting a wall. When a group at MIT found that 95% of businesses are seeing no return on their massive AI investments, stocks floundered. The expansion of AI-specific data centers might be an investment that’s hard to recoup, especially as revenues for AI companies remain elusive.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One of the biggest unknowns about AI’s future energy burden isn’t how much a single query consumes, or any other figure that can be disclosed. It’s whether demand will ever reach the scale companies are building for or whether the technology will collapse under its own hype. The answer will determine whether today’s buildout becomes a lasting shift in our energy system or a short-lived spike.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-517340891.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Earlier this year, when my colleague Casey Crownhart and I spent six months researching the climate and energy burden of AI, we came to see one number in particular as our white whale: how much energy the leading AI models, like ChatGPT or Gemini, use up when generating a single response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This fundamental number remained elusive even as the scramble to power AI escalated to the White House and the Pentagon, and as projections showed that in three years AI could use as much electricity as 22% of all US households.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The problem with finding that number, as we explain in our piece published in May, was that AI companies are the only ones who have it. We pestered Google, OpenAI, and Microsoft, but each company refused to provide its figure. Researchers we spoke to who study AI’s impact on energy grids compared it to trying to measure the fuel efficiency of a car without ever being able to drive it, making guesses based on rumors of its engine size and what it sounds like going down the highway.&lt;/p&gt;  &lt;p&gt;But then this summer, after we published, a strange thing started to happen. In June, OpenAI’s Sam Altman wrote that an average ChatGPT query uses 0.34 watt-hours of energy. In July, the French AI startup Mistral didn’t publish a number directly but released an estimate of the emissions generated. In August, Google revealed that answering a question to Gemini uses about 0.24 watt-hours of energy. The figures from Google and OpenAI were similar to what Casey and I estimated for medium-size AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;So with this newfound transparency, is our job complete? Did we finally harpoon our white whale, and if so, what happens next for people studying the climate impact of AI? I reached out to some of our old sources, and some new ones, to find out.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The numbers are vague and chat-only&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The first thing they told me is that there’s a lot missing from the figures tech companies published this summer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;OpenAI’s number, for example, did not appear in a detailed technical paper but rather in a blog post by Altman that leaves lots of unanswered questions, such as which model he was referring to, how the energy use was measured, and how much it varies. Google’s figure, as Crownhart points out, refers to the median amount of energy per query, which doesn’t give us a sense of the more energy-demanding Gemini responses, like when it uses a reasoning model to “think” through a hard problem or generates a really long response.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The numbers also refer only to interactions with chatbots, not the other ways that people are becoming increasingly reliant on generative AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“As video and image becomes more prominent and used by more and more people, we need the numbers from different modalities and how they measure up,” says Sasha Luccioni, AI and climate lead at the AI platform Hugging Face.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is also important because the figures for asking a question to a chatbot are, as expected, undoubtedly small—the same amount of electricity used by a microwave in just seconds. That’s part of the reason AI and climate researchers don’t suggest that any one individual’s AI use creates a significant climate burden.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A full accounting of AI’s energy demands—one that goes beyond what’s used to answer an individual query to help us understand its full net impact on the climate—would require application-specific information on how all this AI is being used. Ketan Joshi, an analyst for climate and energy groups, acknowledges that researchers don’t usually get such specific information from other industries but says it might be justified in this case.&lt;/p&gt;  &lt;p&gt;“The rate of data center growth is inarguably unusual,” Joshi says. “Companies should be subject to significantly more scrutiny.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;We have questions about energy efficiency&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;Companies making billion-dollar investments into AI have struggled to square this growth in energy demand with their sustainability goals. In May, Microsoft said that its emissions have soared by over 23% since 2020, owing largely to AI, while the company has promised to be carbon negative by 2030. “It has become clear that our journey towards being carbon negative is a marathon, not a sprint,” Microsoft wrote.&lt;/p&gt;  &lt;p&gt;Tech companies often justify this emissions burden by arguing that soon enough, AI itself will unlock efficiencies that will make it a net positive for the climate. Perhaps the right AI system, the thinking goes, could design more efficient heating and cooling systems for a building, or help discover the minerals required for electric-vehicle batteries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But there are no signs that AI has been usefully used to do these things yet. Companies have shared anecdotes about using AI to find methane emission hot spots, for example, but they haven’t been transparent enough to help us know if these successes outweigh the surges in electricity demand and emissions that Big Tech has produced in the AI boom. In the meantime, more data centers are planned, and AI’s energy demand continues to rise and rise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The ‘bubble’ question&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;One of the big unknowns in the AI energy equation is whether society will ever adopt AI at the levels that figure into tech companies’ plans. OpenAI has said that ChatGPT receives 2.5 billion prompts per day. It’s possible that this number, and the equivalent numbers for other AI companies, will continue to soar in the coming years. Projections released last year by the Lawrence Berkeley National Laboratory suggest that if they do, AI alone could consume as much electricity annually as 22% of all US households by 2028.&lt;/p&gt;  &lt;p&gt;But this summer also saw signs of a slowdown that undercut the industry’s optimism. OpenAI’s launch of GPT-5 was largely considered a flop, even by the company itself, and that flop led critics to wonder if AI may be hitting a wall. When a group at MIT found that 95% of businesses are seeing no return on their massive AI investments, stocks floundered. The expansion of AI-specific data centers might be an investment that’s hard to recoup, especially as revenues for AI companies remain elusive.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One of the biggest unknowns about AI’s future energy burden isn’t how much a single query consumes, or any other figure that can be disclosed. It’s whether demand will ever reach the scale companies are building for or whether the technology will collapse under its own hype. The answer will determine whether today’s buildout becomes a lasting shift in our energy system or a short-lived spike.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/09/1123408/three-big-things-we-still-dont-know-about-ais-energy-burden/</guid><pubDate>Tue, 09 Sep 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Help! My therapist is secretly using ChatGPT (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/09/1123386/help-my-therapist-is-secretly-using-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/therapy-ai3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In Silicon Valley’s imagined future, AI models are so empathetic that we’ll use them as therapists. They’ll provide mental-health care for millions, unimpeded by the pesky requirements for human counselors, like the need for graduate degrees, malpractice insurance, and sleep. Down here on Earth, something very different has been happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last week, we published a story about people finding out that their therapists were secretly using ChatGPT during sessions. In some cases it wasn’t subtle; one therapist accidentally shared his screen during a virtual appointment, allowing the patient to see his own private thoughts being typed into ChatGPT in real time. The model then suggested responses that his therapist parroted.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s my favorite AI story as of late, probably because it captures so well the chaos that can unfold when people actually use AI the way tech companies have all but told them to.&lt;/p&gt;  &lt;p&gt;As the writer of the story, Laurie Clarke, points out, it’s not a total pipe dream that AI could be therapeutically useful. Early this year, I wrote about the first clinical trial of an AI bot built specifically for therapy. The results were promising! But the secretive use by therapists of AI models that are not vetted for mental health is something very different. I had a conversation with Clarke to hear more about what she found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;I have to say, I was really fascinated that people called out their therapists after finding out they were covertly using AI. How did you interpret the reactions of these therapists? Were they trying to hide it?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In all the cases mentioned in the piece, the therapist hadn’t provided prior disclosure of how they were using AI to their patients. So whether or not they were explicitly trying to conceal it, that’s how it ended up looking when it was discovered. I think for this reason, one of my main takeaways from writing the piece was that therapists should absolutely disclose when they’re going to use AI and how (if they plan to use it). If they don’t, it raises all these really uncomfortable questions for patients when it’s uncovered and risks irrevocably damaging the trust that’s been built.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;In the examples you’ve come across, are therapists turning to AI simply as a time-saver? Or do they think AI models can genuinely give them a new perspective on what’s bothering someone?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Some see AI as a potential time-saver. I heard from a few therapists that notes are the bane of their lives. So I think there is some interest in AI-powered tools that can support this. Most I spoke to were very skeptical about using AI for advice on how to treat a patient. They said it would be better to consult supervisors or colleagues, or case studies in the literature. They were also understandably very wary of inputting sensitive data into these tools.&lt;/p&gt;  &lt;p&gt;There is some evidence AI can deliver more standardized, "manualized" therapies like CBT [cognitive behavioral therapy] reasonably effectively. So it’s possible it could be more useful for that. But that is AI specifically designed for that purpose, not general-purpose tools like ChatGPT.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What happens if this goes awry? What attention is this getting from ethics groups and lawmakers?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At present, professional bodies like the American Counseling Association advise against using AI tools to diagnose patients. There could also be more stringent regulations preventing this in future. Nevada and Illinois, for example, have recently passed laws prohibiting the use of AI in therapeutic decision-making. More states could follow.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;OpenAI’s Sam Altman &lt;/strong&gt;&lt;strong&gt;said&lt;/strong&gt;&lt;strong&gt; last month that “a lot of people effectively use ChatGPT as a sort of therapist,” and that to him, that’s a good thing. Do you think tech companies are overpromising on AI’s ability to help us?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think that tech companies are subtly encouraging this use of AI because clearly it’s a route through which some people are forming an attachment to their products. I think the main issue is that what people are getting from these tools isn’t really “therapy” by any stretch. Good therapy goes far beyond being soothing and validating everything someone says. I’ve never in my life looked forward to a (real, in-person) therapy session. They’re often highly uncomfortable, and even distressing. But that’s part of the point. The therapist should be challenging you and drawing you out and seeking to understand you. ChatGPT doesn’t do any of these things.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Read the full story from Laurie Clarke.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/therapy-ai3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In Silicon Valley’s imagined future, AI models are so empathetic that we’ll use them as therapists. They’ll provide mental-health care for millions, unimpeded by the pesky requirements for human counselors, like the need for graduate degrees, malpractice insurance, and sleep. Down here on Earth, something very different has been happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last week, we published a story about people finding out that their therapists were secretly using ChatGPT during sessions. In some cases it wasn’t subtle; one therapist accidentally shared his screen during a virtual appointment, allowing the patient to see his own private thoughts being typed into ChatGPT in real time. The model then suggested responses that his therapist parroted.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s my favorite AI story as of late, probably because it captures so well the chaos that can unfold when people actually use AI the way tech companies have all but told them to.&lt;/p&gt;  &lt;p&gt;As the writer of the story, Laurie Clarke, points out, it’s not a total pipe dream that AI could be therapeutically useful. Early this year, I wrote about the first clinical trial of an AI bot built specifically for therapy. The results were promising! But the secretive use by therapists of AI models that are not vetted for mental health is something very different. I had a conversation with Clarke to hear more about what she found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;I have to say, I was really fascinated that people called out their therapists after finding out they were covertly using AI. How did you interpret the reactions of these therapists? Were they trying to hide it?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In all the cases mentioned in the piece, the therapist hadn’t provided prior disclosure of how they were using AI to their patients. So whether or not they were explicitly trying to conceal it, that’s how it ended up looking when it was discovered. I think for this reason, one of my main takeaways from writing the piece was that therapists should absolutely disclose when they’re going to use AI and how (if they plan to use it). If they don’t, it raises all these really uncomfortable questions for patients when it’s uncovered and risks irrevocably damaging the trust that’s been built.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;In the examples you’ve come across, are therapists turning to AI simply as a time-saver? Or do they think AI models can genuinely give them a new perspective on what’s bothering someone?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Some see AI as a potential time-saver. I heard from a few therapists that notes are the bane of their lives. So I think there is some interest in AI-powered tools that can support this. Most I spoke to were very skeptical about using AI for advice on how to treat a patient. They said it would be better to consult supervisors or colleagues, or case studies in the literature. They were also understandably very wary of inputting sensitive data into these tools.&lt;/p&gt;  &lt;p&gt;There is some evidence AI can deliver more standardized, "manualized" therapies like CBT [cognitive behavioral therapy] reasonably effectively. So it’s possible it could be more useful for that. But that is AI specifically designed for that purpose, not general-purpose tools like ChatGPT.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What happens if this goes awry? What attention is this getting from ethics groups and lawmakers?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At present, professional bodies like the American Counseling Association advise against using AI tools to diagnose patients. There could also be more stringent regulations preventing this in future. Nevada and Illinois, for example, have recently passed laws prohibiting the use of AI in therapeutic decision-making. More states could follow.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;OpenAI’s Sam Altman &lt;/strong&gt;&lt;strong&gt;said&lt;/strong&gt;&lt;strong&gt; last month that “a lot of people effectively use ChatGPT as a sort of therapist,” and that to him, that’s a good thing. Do you think tech companies are overpromising on AI’s ability to help us?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think that tech companies are subtly encouraging this use of AI because clearly it’s a route through which some people are forming an attachment to their products. I think the main issue is that what people are getting from these tools isn’t really “therapy” by any stretch. Good therapy goes far beyond being soothing and validating everything someone says. I’ve never in my life looked forward to a (real, in-person) therapy session. They’re often highly uncomfortable, and even distressing. But that’s part of the point. The therapist should be challenging you and drawing you out and seeking to understand you. ChatGPT doesn’t do any of these things.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Read the full story from Laurie Clarke.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/09/1123386/help-my-therapist-is-secretly-using-chatgpt/</guid><pubDate>Tue, 09 Sep 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Thinking Machines becomes OpenAI’s first services partner in APAC (AI News)</title><link>https://www.artificialintelligence-news.com/news/thinking-machines-becomes-openai-first-services-partner-in-apac/</link><description>&lt;p&gt;Thinking Machines Data Science is joining forces with OpenAI to help more businesses across Asia Pacific turn artificial intelligence into measurable results. The collaboration makes Thinking Machines the first official Services Partner for OpenAI in the region.&lt;/p&gt;&lt;p&gt;The partnership comes as AI adoption in APAC continues to rise. An IBM study found that 61% of enterprises already use AI, yet many struggle to move beyond pilot projects and deliver real business impact. Thinking Machines and OpenAI aim to change that by offering executive training on ChatGPT Enterprise, support for building custom AI applications, and guidance on embedding AI into everyday operations.&lt;/p&gt;&lt;p&gt;Stephanie Sy, Founder and CEO of Thinking Machines, framed the partnership around capability building: “We’re not just bringing in new technology but we’re helping organisations build the skills, strategies, and support systems they need to take advantage of AI. For us, it’s about reinventing the future of work through human-AI collaboration and making AI truly work for people across the Asia Pacific region.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-turning-ai-pilots-into-results-with-thinking-machines"&gt;Turning AI pilots into results with Thinking Machines&lt;/h3&gt;&lt;p&gt;In an interview with &lt;em&gt;AI News&lt;/em&gt;, Sy explained that one of the biggest hurdles for enterprises is how they frame AI adoption. Too often, organisations see it as a technology acquisition rather than a business transformation. That approach leads to pilots that stall or fail to scale.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="Stephanie Sy, Founder and CEO of Thinking Machines." class="wp-image-109278" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Stef_1-683x1024.jpg" width="683" /&gt;&lt;figcaption class="wp-element-caption"&gt;Stephanie Sy, Founder and CEO of Thinking Machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“The main challenge is that many organisations approach AI as a technology acquisition rather than a business transformation,” she said. “This leads to pilots that never scale because three fundamentals are missing: clear leadership alignment on the value to create, redesign of workflows to embed AI into how work gets done, and investment in workforce skills to ensure adoption. Get those three right—vision, process, people—and pilots scale into impact.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-leadership-at-the-centre"&gt;Leadership at the centre&lt;/h3&gt;&lt;p&gt;Many executives still treat AI as a technical project rather than a strategic priority. Sy believes that boards and C-suites need to set the tone. Their role is to decide whether AI is a growth driver or just a managed risk.&lt;/p&gt;&lt;p&gt;“Boards and C-suites set the tone: Is AI a strategic growth driver or a managed risk? Their role is to name a few priority outcomes, define risk appetite, and assign clear ownership,” she said. Thinking Machines often begins with executive sessions where leaders can explore where tools like ChatGPT add value, how to govern them, and when to scale. “That top-down clarity is what turns AI from an experiment into an enterprise capability.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-ai-collaboration-in-practice"&gt;Human-AI collaboration in practice&lt;/h3&gt;&lt;p&gt;Sy often talks about “reinventing the future of work through human-AI collaboration.” She explained what this looks like in practice: a “human-in-command” approach where people focus on judgment, decision-making, and exceptions, while AI handles routine steps like retrieval, drafting, or summarising.&lt;/p&gt;&lt;p&gt;“Human-in-command means redesigning work so people focus on judgment and exceptions, while AI takes on retrieval, drafting, and routine steps, with transparency through audit trails and source links,” she said. The results are measured in time saved and quality improvements.&lt;/p&gt;&lt;p&gt;In workshops run by Thinking Machines, professionals using ChatGPT often free up one to two hours per day. Research supports these outcomes—Sy pointed to an MIT study showing a 14% productivity boost for contact centre agents, with the biggest gains seen among less-experienced staff. “That’s clear evidence AI can elevate human talent rather than displace it,” she added.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-agentic-ai-with-thinking-machines-guardrails"&gt;&lt;strong&gt;Agentic AI with Thinking Machines’ guardrails&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Another area of focus for Thinking Machines is agentic AI, which goes beyond single queries to handle multi-step processes. Instead of just answering a question, agentic systems can manage research, fill forms, and make API calls, coordinating entire workflows with a human still in charge.&lt;/p&gt;&lt;p&gt;“Agentic systems can take work from ‘ask-and-answer’ to multi-step execution: coordinating research, browsing, form-filling, and API calls so teams ship faster with a human in command,” Sy said. The promise is faster execution and productivity, but the risks are real. “The principles of human-in-command and auditability remain critical; to avoid the lack of proper guardrails. Our approach is to pair enterprise controls and auditability with agent capabilities to ensure actions are traceable, reversible, and policy-aligned before we scale.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-that-builds-trust"&gt;&lt;strong&gt;Governance that builds trust&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;While adoption is accelerating, governance often lags behind. Sy cautioned that governance fails when it’s treated as paperwork instead of part of daily work.&lt;/p&gt;&lt;p&gt;“We keep humans in command and make governance visible in daily work: use approved data sources, enforce role-based access, maintain audit trails, and require human decision points for sensitive actions,” she explained. Thinking Machines also applies what it calls “control + reliability”: restricting retrieval to trusted content and returning answers with citations. Workflows are then adapted to local rules in sectors such as finance, government, and healthcare.&lt;/p&gt;&lt;p&gt;For Sy, success isn’t measured in the volume of policies but in auditability and exception rates. “Good governance accelerates adoption because teams trust what they ship,” she said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-local-context-regional-scale"&gt;Local context, regional scale&lt;/h3&gt;&lt;p&gt;Asia Pacific’s cultural and linguistic diversity poses unique challenges for scaling AI. A one-size-fits-all model doesn’t work. Sy emphasised that the right playbook is to build locally first and then scale deliberately.&lt;/p&gt;&lt;p&gt;“Global templates fail when they ignore how local teams work. The playbook is build locally, scale deliberately: fit the AI to local language, forms, policies, and escalation paths; then standardise the parts that travel such as your governance pattern, data connectors, and impact metrics,” she said.&lt;/p&gt;&lt;p&gt;That’s the approach Thinking Machines has taken in Singapore, the Philippines, and Thailand—prove value with local teams first, then roll out region by region. The aim is not a uniform chatbot but a reliable pattern that respects local context while maintaining scalability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-skills-over-tools"&gt;Skills over tools&lt;/h3&gt;&lt;p&gt;When asked what skills will matter most in an AI-enabled workplace, Sy pointed out that scale comes from skills, not just tools. She broke this down into three categories:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Executive literacy&lt;/strong&gt;: the ability for leaders to set outcomes and guardrails, and know when and where to scale AI.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Workflow design&lt;/strong&gt;: the redesign of human-AI handoffs, clarifying who drafts, who approves, and how exceptions escalate.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Hands-on skills&lt;/strong&gt;: prompting, evaluation, and retrieval from trusted sources so answers are verifiable, not just plausible.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“When leaders and teams share that foundation, adoption moves from experimenting to repeatable, production-level results,” she said. In Thinking Machines’ programs, many professionals report saving one to two hours per day after just a one-day workshop. To date, more than 10,000 people across roles have been trained, and Sy noted the pattern is consistent: “skills + governance unlock scale.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-industry-transformation-ahead"&gt;Industry transformation ahead&lt;/h3&gt;&lt;p&gt;Looking to the next five years, Sy sees AI shifting from drafting to full execution in critical business functions. She expects major gains in software development, marketing, service operations, and supply chain management.&lt;/p&gt;&lt;p&gt;“For the next wave, we see three concrete patterns: policy-aware assistants in finance, supply chain copilots in manufacturing, and personalised yet compliant CX in retail—each built with human checkpoints and verifiable sources so leaders can scale with confidence,” she said.&lt;/p&gt;&lt;p&gt;A practical example is a system Thinking Machines built with the Bank of the Philippine Islands. Called BEAi, it’s a retrieval-augmented generation (RAG) system that supports English, Filipino, and Taglish. It returns answers linked to sources with page numbers and understands policy supersession, turning complex policy documents into everyday guidance for staff. “That’s what ‘AI-native’ looks like in practice,” Sy said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-thinking-machines-expands-ai-across-apac"&gt;Thinking Machines expands AI across APAC&lt;/h3&gt;&lt;p&gt;The partnership with OpenAI will start with programs in Singapore, the Philippines, and Thailand through Thinking Machines’ regional offices before expanding further across APAC. Future plans include tailoring services to sectors such as finance, retail, and manufacturing, where AI can address specific challenges and open new opportunities.&lt;/p&gt;&lt;p&gt;For Sy, the goal is clear: “AI adoption isn’t just about experimenting with new tools. It’s about building the vision, processes, and skills that let organisations move from pilots to impact. When leaders, teams, and technology come together, that’s when AI delivers lasting value.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: X and xAI sue Apple and OpenAI over AI monopoly claims&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109277" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Thinking Machines Data Science is joining forces with OpenAI to help more businesses across Asia Pacific turn artificial intelligence into measurable results. The collaboration makes Thinking Machines the first official Services Partner for OpenAI in the region.&lt;/p&gt;&lt;p&gt;The partnership comes as AI adoption in APAC continues to rise. An IBM study found that 61% of enterprises already use AI, yet many struggle to move beyond pilot projects and deliver real business impact. Thinking Machines and OpenAI aim to change that by offering executive training on ChatGPT Enterprise, support for building custom AI applications, and guidance on embedding AI into everyday operations.&lt;/p&gt;&lt;p&gt;Stephanie Sy, Founder and CEO of Thinking Machines, framed the partnership around capability building: “We’re not just bringing in new technology but we’re helping organisations build the skills, strategies, and support systems they need to take advantage of AI. For us, it’s about reinventing the future of work through human-AI collaboration and making AI truly work for people across the Asia Pacific region.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-turning-ai-pilots-into-results-with-thinking-machines"&gt;Turning AI pilots into results with Thinking Machines&lt;/h3&gt;&lt;p&gt;In an interview with &lt;em&gt;AI News&lt;/em&gt;, Sy explained that one of the biggest hurdles for enterprises is how they frame AI adoption. Too often, organisations see it as a technology acquisition rather than a business transformation. That approach leads to pilots that stall or fail to scale.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="Stephanie Sy, Founder and CEO of Thinking Machines." class="wp-image-109278" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Stef_1-683x1024.jpg" width="683" /&gt;&lt;figcaption class="wp-element-caption"&gt;Stephanie Sy, Founder and CEO of Thinking Machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“The main challenge is that many organisations approach AI as a technology acquisition rather than a business transformation,” she said. “This leads to pilots that never scale because three fundamentals are missing: clear leadership alignment on the value to create, redesign of workflows to embed AI into how work gets done, and investment in workforce skills to ensure adoption. Get those three right—vision, process, people—and pilots scale into impact.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-leadership-at-the-centre"&gt;Leadership at the centre&lt;/h3&gt;&lt;p&gt;Many executives still treat AI as a technical project rather than a strategic priority. Sy believes that boards and C-suites need to set the tone. Their role is to decide whether AI is a growth driver or just a managed risk.&lt;/p&gt;&lt;p&gt;“Boards and C-suites set the tone: Is AI a strategic growth driver or a managed risk? Their role is to name a few priority outcomes, define risk appetite, and assign clear ownership,” she said. Thinking Machines often begins with executive sessions where leaders can explore where tools like ChatGPT add value, how to govern them, and when to scale. “That top-down clarity is what turns AI from an experiment into an enterprise capability.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-ai-collaboration-in-practice"&gt;Human-AI collaboration in practice&lt;/h3&gt;&lt;p&gt;Sy often talks about “reinventing the future of work through human-AI collaboration.” She explained what this looks like in practice: a “human-in-command” approach where people focus on judgment, decision-making, and exceptions, while AI handles routine steps like retrieval, drafting, or summarising.&lt;/p&gt;&lt;p&gt;“Human-in-command means redesigning work so people focus on judgment and exceptions, while AI takes on retrieval, drafting, and routine steps, with transparency through audit trails and source links,” she said. The results are measured in time saved and quality improvements.&lt;/p&gt;&lt;p&gt;In workshops run by Thinking Machines, professionals using ChatGPT often free up one to two hours per day. Research supports these outcomes—Sy pointed to an MIT study showing a 14% productivity boost for contact centre agents, with the biggest gains seen among less-experienced staff. “That’s clear evidence AI can elevate human talent rather than displace it,” she added.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-agentic-ai-with-thinking-machines-guardrails"&gt;&lt;strong&gt;Agentic AI with Thinking Machines’ guardrails&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Another area of focus for Thinking Machines is agentic AI, which goes beyond single queries to handle multi-step processes. Instead of just answering a question, agentic systems can manage research, fill forms, and make API calls, coordinating entire workflows with a human still in charge.&lt;/p&gt;&lt;p&gt;“Agentic systems can take work from ‘ask-and-answer’ to multi-step execution: coordinating research, browsing, form-filling, and API calls so teams ship faster with a human in command,” Sy said. The promise is faster execution and productivity, but the risks are real. “The principles of human-in-command and auditability remain critical; to avoid the lack of proper guardrails. Our approach is to pair enterprise controls and auditability with agent capabilities to ensure actions are traceable, reversible, and policy-aligned before we scale.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-that-builds-trust"&gt;&lt;strong&gt;Governance that builds trust&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;While adoption is accelerating, governance often lags behind. Sy cautioned that governance fails when it’s treated as paperwork instead of part of daily work.&lt;/p&gt;&lt;p&gt;“We keep humans in command and make governance visible in daily work: use approved data sources, enforce role-based access, maintain audit trails, and require human decision points for sensitive actions,” she explained. Thinking Machines also applies what it calls “control + reliability”: restricting retrieval to trusted content and returning answers with citations. Workflows are then adapted to local rules in sectors such as finance, government, and healthcare.&lt;/p&gt;&lt;p&gt;For Sy, success isn’t measured in the volume of policies but in auditability and exception rates. “Good governance accelerates adoption because teams trust what they ship,” she said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-local-context-regional-scale"&gt;Local context, regional scale&lt;/h3&gt;&lt;p&gt;Asia Pacific’s cultural and linguistic diversity poses unique challenges for scaling AI. A one-size-fits-all model doesn’t work. Sy emphasised that the right playbook is to build locally first and then scale deliberately.&lt;/p&gt;&lt;p&gt;“Global templates fail when they ignore how local teams work. The playbook is build locally, scale deliberately: fit the AI to local language, forms, policies, and escalation paths; then standardise the parts that travel such as your governance pattern, data connectors, and impact metrics,” she said.&lt;/p&gt;&lt;p&gt;That’s the approach Thinking Machines has taken in Singapore, the Philippines, and Thailand—prove value with local teams first, then roll out region by region. The aim is not a uniform chatbot but a reliable pattern that respects local context while maintaining scalability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-skills-over-tools"&gt;Skills over tools&lt;/h3&gt;&lt;p&gt;When asked what skills will matter most in an AI-enabled workplace, Sy pointed out that scale comes from skills, not just tools. She broke this down into three categories:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Executive literacy&lt;/strong&gt;: the ability for leaders to set outcomes and guardrails, and know when and where to scale AI.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Workflow design&lt;/strong&gt;: the redesign of human-AI handoffs, clarifying who drafts, who approves, and how exceptions escalate.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Hands-on skills&lt;/strong&gt;: prompting, evaluation, and retrieval from trusted sources so answers are verifiable, not just plausible.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“When leaders and teams share that foundation, adoption moves from experimenting to repeatable, production-level results,” she said. In Thinking Machines’ programs, many professionals report saving one to two hours per day after just a one-day workshop. To date, more than 10,000 people across roles have been trained, and Sy noted the pattern is consistent: “skills + governance unlock scale.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-industry-transformation-ahead"&gt;Industry transformation ahead&lt;/h3&gt;&lt;p&gt;Looking to the next five years, Sy sees AI shifting from drafting to full execution in critical business functions. She expects major gains in software development, marketing, service operations, and supply chain management.&lt;/p&gt;&lt;p&gt;“For the next wave, we see three concrete patterns: policy-aware assistants in finance, supply chain copilots in manufacturing, and personalised yet compliant CX in retail—each built with human checkpoints and verifiable sources so leaders can scale with confidence,” she said.&lt;/p&gt;&lt;p&gt;A practical example is a system Thinking Machines built with the Bank of the Philippine Islands. Called BEAi, it’s a retrieval-augmented generation (RAG) system that supports English, Filipino, and Taglish. It returns answers linked to sources with page numbers and understands policy supersession, turning complex policy documents into everyday guidance for staff. “That’s what ‘AI-native’ looks like in practice,” Sy said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-thinking-machines-expands-ai-across-apac"&gt;Thinking Machines expands AI across APAC&lt;/h3&gt;&lt;p&gt;The partnership with OpenAI will start with programs in Singapore, the Philippines, and Thailand through Thinking Machines’ regional offices before expanding further across APAC. Future plans include tailoring services to sectors such as finance, retail, and manufacturing, where AI can address specific challenges and open new opportunities.&lt;/p&gt;&lt;p&gt;For Sy, the goal is clear: “AI adoption isn’t just about experimenting with new tools. It’s about building the vision, processes, and skills that let organisations move from pilots to impact. When leaders, teams, and technology come together, that’s when AI delivers lasting value.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: X and xAI sue Apple and OpenAI over AI monopoly claims&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109277" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/thinking-machines-becomes-openai-first-services-partner-in-apac/</guid><pubDate>Tue, 09 Sep 2025 10:16:22 +0000</pubDate></item><item><title>[NEW] Why accessibility might be AI’s biggest breakthrough (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/09/study-finds-neurodiverse-workers-more-satisfied-with-ai-assistants/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        UK study findings may challenge assumptions about who benefits most from AI tools.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Group of People with differing personalities" class="absolute inset-0 w-full h-full object-cover hidden" height="409" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-640x409.jpg" width="640" /&gt;
                  &lt;img alt="Group of People with differing personalities" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Group of People with differing personalities

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chris Madden via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;While tech companies market AI as a productivity tool for everyone, a UK government study reveals an unexpected result: Neurodiverse employees may be benefiting far more from chatbots than their neurotypical colleagues.&lt;/p&gt;
&lt;p&gt;The UK's Department for Business and Trade recently released evaluation results from its Microsoft 365 Copilot trial showing that while overall satisfaction was 72 percent, neurodiverse employees reported statistically higher satisfaction (at a 90 percent confidence level) and were more likely to recommend the tool (at a 95 percent confidence level) than other respondents.&lt;/p&gt;
&lt;p&gt;"It's leveled the playing field," one participant with ADHD told researchers during follow-up interviews. One user with dyslexia said that the tool "empowered" them to perform tasks with confidence they previously lacked, particularly in report writing. Another dyslexic participant drew direct comparisons to existing accessibility software, noting that Copilot "does a hell of a lot more" than traditional assistive technology while being "embedded in your applications" rather than requiring separate programs.&lt;/p&gt;
&lt;p&gt;The reported benefits extended beyond neurodiversity. Users with hearing disabilities reported that AI-powered meeting transcription allowed them to participate more fully in discussions. "I can very quickly recall and be able to share my inputs rather than sit quietly thinking I missed the point," one participant explained, describing how constant focus requirements in meetings left them exhausted.&lt;/p&gt;
&lt;p&gt;The study, titled "The Evaluation of the M365 Copilot Pilot in the Department for Business and Trade," suggests that AI tools might be addressing workplace accessibility gaps that traditional accommodations have missed. The department conducted the study between October 2024 and March 2025 using diary studies, interviews, and observed tasks to measure how the AI assistant affected different user groups.&lt;/p&gt;
&lt;p&gt;The finding emerges from 300 participants who consented to analysis out of 1,000 licenses distributed, though the study doesn't specify how many identified as neurodiverse. While the 90 percent confidence for satisfaction falls below typical academic standards, the stronger finding for likelihood to recommend suggests a meaningful difference.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;These experiences echo some personal accounts online from autistic and ADHD users who describe AI as providing scaffolding for their writing and executive function needs. Some users also find value in having help decoding social subtext in workplace communications or suggesting appropriate professional language.&lt;/p&gt;
&lt;h2&gt;Beyond traditional accommodations&lt;/h2&gt;
&lt;p&gt;Even with what appears to be generally positive reviews of AI assistants for neurodivergent people who responded to the study, there's still plenty of room for nuanced takes on the overall potential of AI language models. The Register reported on the same study Thursday, emphasizing a lack of clear productivity gains and issues with Excel and PowerPoint outputs found by the researchers. The accessibility findings show the impact of AI from a different angle—one that Silicon Valley executives racing for flashy investment-attracting concepts like "superintelligence" might not consider as often.&lt;/p&gt;
&lt;p&gt;The disconnect between AI's promised productivity revolution and its actual impact might reveal a fundamental misunderstanding about where these tools excel. Traditional productivity gains require AI to outperform humans at tasks we're already good at—a high bar that current technology struggles to clear consistently. But for accessibility, AI doesn't need to be perfect; it just needs to bridge gaps that would otherwise exclude people entirely. The difference between writing a report 20 percent faster and being able to write a report at all represents two entirely different value propositions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For people with dyslexia in any setting, AI assistants might serve as writing aids that go beyond traditional spell-checkers, potentially helping with sentence structure and organizing thoughts without requiring specialized software. People with ADHD might be able to use these tools as executive function support, helping break down complex tasks and organize scattered thoughts.&lt;/p&gt;
&lt;p&gt;Some users report using AI to overcome procrastination and create structure as transformative for managing ADHD symptoms. "ChatGPT can help us hash things out so that we feel more prepared, comfortable, and confident in communicating with others," a reader named Lena&amp;nbsp;told ADDitude magazine.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For those with visual impairments, language models can summarize visual content and reformat information. Tools like ChatGPT's voice mode with video and Be My Eyes allow a machine to describe real-world visual scenes in ways that were impossible just a few years ago.&lt;/p&gt;
&lt;p&gt;AI language tools may be providing unofficial stealth accommodations for students—support that doesn't require formal diagnosis, workplace disclosure, or special equipment. Yet this informal support system comes with its own risks. Language models do confabulate—the UK Department for Business and Trade study found 22 percent of users identified false information in AI outputs—which could be particularly harmful for users relying on them for essential support.&lt;/p&gt;
&lt;h2&gt;When AI assistance becomes dependence&lt;/h2&gt;
&lt;p&gt;Beyond the workplace, the drawbacks may have a particular impact on students who use the technology. The authors of a 2025 study on students with disabilities using generative AI cautioned, "Key concerns students with disabilities had included the inaccuracy of AI answers, risks to academic integrity, and subscription cost barriers," they wrote. Students in that study had ADHD, dyslexia, dyspraxia, and autism, with ChatGPT being the most commonly used tool.&lt;/p&gt;
&lt;p&gt;Mistakes in AI outputs are especially pernicious because, due to grandiose visions of near-term AI technology, some people think today's AI assistants can perform tasks that are actually far outside their scope. As research on blind users' experiences suggested, people develop complex (sometimes flawed) mental models of how these tools work, showing the need for higher awareness of AI language model drawbacks among the general public.&lt;/p&gt;
&lt;p&gt;For the UK government employees who participated in the initial study, these questions moved from theoretical to immediate when the pilot ended in December 2024. After that time, many participants reported difficulty readjusting to work without AI assistance—particularly those with disabilities who had come to rely on the accessibility benefits. The department hasn't announced the next steps, leaving users in limbo. When participants report difficulty readjusting to work without AI while productivity gains remain marginal, accessibility emerges as potentially the first AI application with irreplaceable value.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        UK study findings may challenge assumptions about who benefits most from AI tools.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Group of People with differing personalities" class="absolute inset-0 w-full h-full object-cover hidden" height="409" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-640x409.jpg" width="640" /&gt;
                  &lt;img alt="Group of People with differing personalities" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Group of People with differing personalities

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chris Madden via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;While tech companies market AI as a productivity tool for everyone, a UK government study reveals an unexpected result: Neurodiverse employees may be benefiting far more from chatbots than their neurotypical colleagues.&lt;/p&gt;
&lt;p&gt;The UK's Department for Business and Trade recently released evaluation results from its Microsoft 365 Copilot trial showing that while overall satisfaction was 72 percent, neurodiverse employees reported statistically higher satisfaction (at a 90 percent confidence level) and were more likely to recommend the tool (at a 95 percent confidence level) than other respondents.&lt;/p&gt;
&lt;p&gt;"It's leveled the playing field," one participant with ADHD told researchers during follow-up interviews. One user with dyslexia said that the tool "empowered" them to perform tasks with confidence they previously lacked, particularly in report writing. Another dyslexic participant drew direct comparisons to existing accessibility software, noting that Copilot "does a hell of a lot more" than traditional assistive technology while being "embedded in your applications" rather than requiring separate programs.&lt;/p&gt;
&lt;p&gt;The reported benefits extended beyond neurodiversity. Users with hearing disabilities reported that AI-powered meeting transcription allowed them to participate more fully in discussions. "I can very quickly recall and be able to share my inputs rather than sit quietly thinking I missed the point," one participant explained, describing how constant focus requirements in meetings left them exhausted.&lt;/p&gt;
&lt;p&gt;The study, titled "The Evaluation of the M365 Copilot Pilot in the Department for Business and Trade," suggests that AI tools might be addressing workplace accessibility gaps that traditional accommodations have missed. The department conducted the study between October 2024 and March 2025 using diary studies, interviews, and observed tasks to measure how the AI assistant affected different user groups.&lt;/p&gt;
&lt;p&gt;The finding emerges from 300 participants who consented to analysis out of 1,000 licenses distributed, though the study doesn't specify how many identified as neurodiverse. While the 90 percent confidence for satisfaction falls below typical academic standards, the stronger finding for likelihood to recommend suggests a meaningful difference.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;These experiences echo some personal accounts online from autistic and ADHD users who describe AI as providing scaffolding for their writing and executive function needs. Some users also find value in having help decoding social subtext in workplace communications or suggesting appropriate professional language.&lt;/p&gt;
&lt;h2&gt;Beyond traditional accommodations&lt;/h2&gt;
&lt;p&gt;Even with what appears to be generally positive reviews of AI assistants for neurodivergent people who responded to the study, there's still plenty of room for nuanced takes on the overall potential of AI language models. The Register reported on the same study Thursday, emphasizing a lack of clear productivity gains and issues with Excel and PowerPoint outputs found by the researchers. The accessibility findings show the impact of AI from a different angle—one that Silicon Valley executives racing for flashy investment-attracting concepts like "superintelligence" might not consider as often.&lt;/p&gt;
&lt;p&gt;The disconnect between AI's promised productivity revolution and its actual impact might reveal a fundamental misunderstanding about where these tools excel. Traditional productivity gains require AI to outperform humans at tasks we're already good at—a high bar that current technology struggles to clear consistently. But for accessibility, AI doesn't need to be perfect; it just needs to bridge gaps that would otherwise exclude people entirely. The difference between writing a report 20 percent faster and being able to write a report at all represents two entirely different value propositions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For people with dyslexia in any setting, AI assistants might serve as writing aids that go beyond traditional spell-checkers, potentially helping with sentence structure and organizing thoughts without requiring specialized software. People with ADHD might be able to use these tools as executive function support, helping break down complex tasks and organize scattered thoughts.&lt;/p&gt;
&lt;p&gt;Some users report using AI to overcome procrastination and create structure as transformative for managing ADHD symptoms. "ChatGPT can help us hash things out so that we feel more prepared, comfortable, and confident in communicating with others," a reader named Lena&amp;nbsp;told ADDitude magazine.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For those with visual impairments, language models can summarize visual content and reformat information. Tools like ChatGPT's voice mode with video and Be My Eyes allow a machine to describe real-world visual scenes in ways that were impossible just a few years ago.&lt;/p&gt;
&lt;p&gt;AI language tools may be providing unofficial stealth accommodations for students—support that doesn't require formal diagnosis, workplace disclosure, or special equipment. Yet this informal support system comes with its own risks. Language models do confabulate—the UK Department for Business and Trade study found 22 percent of users identified false information in AI outputs—which could be particularly harmful for users relying on them for essential support.&lt;/p&gt;
&lt;h2&gt;When AI assistance becomes dependence&lt;/h2&gt;
&lt;p&gt;Beyond the workplace, the drawbacks may have a particular impact on students who use the technology. The authors of a 2025 study on students with disabilities using generative AI cautioned, "Key concerns students with disabilities had included the inaccuracy of AI answers, risks to academic integrity, and subscription cost barriers," they wrote. Students in that study had ADHD, dyslexia, dyspraxia, and autism, with ChatGPT being the most commonly used tool.&lt;/p&gt;
&lt;p&gt;Mistakes in AI outputs are especially pernicious because, due to grandiose visions of near-term AI technology, some people think today's AI assistants can perform tasks that are actually far outside their scope. As research on blind users' experiences suggested, people develop complex (sometimes flawed) mental models of how these tools work, showing the need for higher awareness of AI language model drawbacks among the general public.&lt;/p&gt;
&lt;p&gt;For the UK government employees who participated in the initial study, these questions moved from theoretical to immediate when the pilot ended in December 2024. After that time, many participants reported difficulty readjusting to work without AI assistance—particularly those with disabilities who had come to rely on the accessibility benefits. The department hasn't announced the next steps, leaving users in limbo. When participants report difficulty readjusting to work without AI while productivity gains remain marginal, accessibility emerges as potentially the first AI application with irreplaceable value.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/09/study-finds-neurodiverse-workers-more-satisfied-with-ai-assistants/</guid><pubDate>Tue, 09 Sep 2025 11:08:44 +0000</pubDate></item><item><title>[NEW] The Download: meet our AI innovators, and what happens when therapists use AI covertly (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/09/1123447/the-download-meet-our-ai-innovators-and-what-happens-when-therapists-use-ai-covertly/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the AI honorees on our 35 Innovators Under 35 list for 2025&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Each year, we select 35 outstanding individuals under the age of 35 who are using technology to tackle tough problems in their respective fields.&lt;/p&gt;&lt;p&gt;Our AI honorees include people who steer model development at Silicon Valley’s biggest tech firms and academic researchers who develop new techniques to improve AI’s performance.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Check out all of our AI innovators &lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;, and the full list—including our innovator of the year—&lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Yichao “Peak” Ji became a global AI app hitmaker&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When Yichao Ji—also known as “Peak”—appeared in a launch video for Manus in March, he didn’t expect it to go viral. Speaking in fluent English, the 32-year-old introduced the AI agent built by Chinese startup Butterfly Effect, where he serves as chief scientist.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The video was not an elaborate production but something about Ji’s delivery, and the vision behind the product, cut through the noise. The product, then still an early preview available only through invite codes, spread across the Chinese internet to the world in a matter of days. Within a week of its debut, Manus had attracted a waiting list of around 2 million people.&lt;/p&gt;&lt;p&gt;Despite his relative youth, Ji has over a decade of experience building products that merge technical complexity with real-world usability. That earned him credibility—and put him at the forefront of a rising class of Chinese technologists with global ambitions. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Help! My therapist is secretly using ChatGPT&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In Silicon Valley’s imagined future, AI models are so empathetic that we’ll use them as therapists. They’ll provide mental-health care for millions, unimpeded by the pesky requirements for human counselors, like the need for graduate degrees, malpractice insurance, and sleep. Down here on Earth, something very different has been happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last week, we published a story about people finding out that their therapists were secretly using ChatGPT during sessions. In some cases it wasn’t subtle; one therapist accidentally shared his screen during a virtual appointment, allowing the patient to see his own private thoughts being typed into ChatGPT in real time.&lt;/p&gt;&lt;p&gt;As the writer of the story, Laurie Clarke, points out, it’s not a total pipe dream that AI could be therapeutically useful. But the secretive use by therapists of AI models that are not vetted for mental health is something very different. James O’Donnell, our senior AI reporter, had a conversation with Clarke to hear more about what she found.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What’s next in tech: the breakthroughs that matter&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Some technologies reshape industries, whether we’re ready or not.&lt;/p&gt;&lt;p&gt;Join us for our next LinkedIn Live event on September 10 as our editorial team explores the breakthroughs defining this moment and the ones on the horizon that demand our attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;From quantum computing to humanoid robotics, AI agents to climate tech, we’ll explore the innovations that excite us, the challenges they may bring, and why they’re worth watching now. It kicks off at 12.30pm ET tomorrow—register here to join us.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is abandoning its international push against disinformation&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The State Department will no longer collaborate with Europe to combat malicious information spread by foreign governments. (FT $)&lt;br /&gt;+ &lt;em&gt;It comes as Russia is increasing its efforts to interfere overseas. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The judge overseeing Anthropic’s copyright case isn’t happy&lt;/strong&gt;&lt;br /&gt;Judge William Alsup says a $1.5 billion out-of-court settlement may not be in the authors' best interests. (Bloomberg $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 WhatsApp’s former head of security is suing Meta&lt;/strong&gt;&lt;br /&gt;Attaullah Baig is accusing the company of failing to protect user data. (WP $)&lt;br /&gt;+ &lt;em&gt;He claims he uncovered systemic security failures, but was ignored. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meta maintains that Baig was dismissed for poor performance, not whistleblowing. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 DOGE’s acting head is urging the US government to start hiring again&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Following months of widespread firings and resignations. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How DOGE wreaked havoc in Social Security. &lt;/em&gt;(ProPublica)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 OpenAI is weighing up leaving California&lt;/strong&gt;&lt;br /&gt;It’s worried that state regulators could derail its efforts to convert to a for-profit entity. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Rival Anthropic is backing California governor Gavin Newsom’s AI bill. &lt;/em&gt;(Politico)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 ICE spends millions on facial recognition tech&lt;br /&gt;&lt;/strong&gt;In an effort to pinpoint people it suspects have assaulted officers. (404 Media)&lt;br /&gt;+ &lt;em&gt;The Supreme Court has given ICE the go-ahead to target people based on race. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;ICE directors were told to triple their daily arrests for undocumented immigrants. &lt;/em&gt;(NY Mag $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;7 AI researchers are training AI to replace them&lt;/strong&gt;&lt;br /&gt;They’re recording every detail of their working days to help AI grasp their jobs. (The Information $)&lt;br /&gt;+ &lt;em&gt;People are worried that AI will take everyone’s jobs. We’ve been here before. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 What comes after the smartphone?&lt;br /&gt;&lt;/strong&gt;The rise of AI agents means we may not be staring at glass slabs forever. (NYT $)&lt;br /&gt;+ &lt;em&gt;What’s next for smart glasses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Social media’s obsession with ‘locking in’ needs to die&lt;/strong&gt;&lt;br /&gt;Hustle culture and maximizing productivity at all costs are the aims of the game. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 What it’s like to receive a massage from a robot&lt;/strong&gt;&lt;br /&gt;While it may not be quite as relaxing, it’s relatively cheap. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Will we ever trust robots? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It was hell on Earth.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Duncan Okindo, who was enslaved in a Myanmar cyberscam compound and beaten for missing his targets, tells the Guardian about his harrowing experience.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123449" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_1e647b.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;AI means the end of internet search as we’ve known it&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;We all know what it means, colloquially, to google something. You pop a few words in a search box and in return get a list of blue links to the most relevant results. Fundamentally, it’s just fetching information that’s already out there on the internet and showing it to you, in a structured way.&lt;/p&gt;&lt;p&gt;But all that is up for grabs. We are at a new inflection point. The biggest change to the way search engines deliver information to us since the 1990s is happening right now, thanks to generative AI.&lt;/p&gt;&lt;p&gt;Not everyone is excited for the change. Publishers are completely freaked out. And people are also worried about what these new LLM-powered results will mean for our fundamental shared reality. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Mat Honan&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Stephen King’s list of favorite movies doesn’t feature a whole lot of horror.&lt;br /&gt;+ Tune into a breathtaking livestream of Earth, beamed live from the International Space Station.&lt;br /&gt;+ Rodent thumbnails are way more important than I gave them credit for 🐿️&lt;br /&gt;+ Mark our words, actor Wagner Moura is going to be the next big thing.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the AI honorees on our 35 Innovators Under 35 list for 2025&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Each year, we select 35 outstanding individuals under the age of 35 who are using technology to tackle tough problems in their respective fields.&lt;/p&gt;&lt;p&gt;Our AI honorees include people who steer model development at Silicon Valley’s biggest tech firms and academic researchers who develop new techniques to improve AI’s performance.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Check out all of our AI innovators &lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;, and the full list—including our innovator of the year—&lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Yichao “Peak” Ji became a global AI app hitmaker&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When Yichao Ji—also known as “Peak”—appeared in a launch video for Manus in March, he didn’t expect it to go viral. Speaking in fluent English, the 32-year-old introduced the AI agent built by Chinese startup Butterfly Effect, where he serves as chief scientist.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The video was not an elaborate production but something about Ji’s delivery, and the vision behind the product, cut through the noise. The product, then still an early preview available only through invite codes, spread across the Chinese internet to the world in a matter of days. Within a week of its debut, Manus had attracted a waiting list of around 2 million people.&lt;/p&gt;&lt;p&gt;Despite his relative youth, Ji has over a decade of experience building products that merge technical complexity with real-world usability. That earned him credibility—and put him at the forefront of a rising class of Chinese technologists with global ambitions. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Help! My therapist is secretly using ChatGPT&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In Silicon Valley’s imagined future, AI models are so empathetic that we’ll use them as therapists. They’ll provide mental-health care for millions, unimpeded by the pesky requirements for human counselors, like the need for graduate degrees, malpractice insurance, and sleep. Down here on Earth, something very different has been happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last week, we published a story about people finding out that their therapists were secretly using ChatGPT during sessions. In some cases it wasn’t subtle; one therapist accidentally shared his screen during a virtual appointment, allowing the patient to see his own private thoughts being typed into ChatGPT in real time.&lt;/p&gt;&lt;p&gt;As the writer of the story, Laurie Clarke, points out, it’s not a total pipe dream that AI could be therapeutically useful. But the secretive use by therapists of AI models that are not vetted for mental health is something very different. James O’Donnell, our senior AI reporter, had a conversation with Clarke to hear more about what she found.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What’s next in tech: the breakthroughs that matter&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Some technologies reshape industries, whether we’re ready or not.&lt;/p&gt;&lt;p&gt;Join us for our next LinkedIn Live event on September 10 as our editorial team explores the breakthroughs defining this moment and the ones on the horizon that demand our attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;From quantum computing to humanoid robotics, AI agents to climate tech, we’ll explore the innovations that excite us, the challenges they may bring, and why they’re worth watching now. It kicks off at 12.30pm ET tomorrow—register here to join us.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is abandoning its international push against disinformation&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The State Department will no longer collaborate with Europe to combat malicious information spread by foreign governments. (FT $)&lt;br /&gt;+ &lt;em&gt;It comes as Russia is increasing its efforts to interfere overseas. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The judge overseeing Anthropic’s copyright case isn’t happy&lt;/strong&gt;&lt;br /&gt;Judge William Alsup says a $1.5 billion out-of-court settlement may not be in the authors' best interests. (Bloomberg $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 WhatsApp’s former head of security is suing Meta&lt;/strong&gt;&lt;br /&gt;Attaullah Baig is accusing the company of failing to protect user data. (WP $)&lt;br /&gt;+ &lt;em&gt;He claims he uncovered systemic security failures, but was ignored. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meta maintains that Baig was dismissed for poor performance, not whistleblowing. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 DOGE’s acting head is urging the US government to start hiring again&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Following months of widespread firings and resignations. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How DOGE wreaked havoc in Social Security. &lt;/em&gt;(ProPublica)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 OpenAI is weighing up leaving California&lt;/strong&gt;&lt;br /&gt;It’s worried that state regulators could derail its efforts to convert to a for-profit entity. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Rival Anthropic is backing California governor Gavin Newsom’s AI bill. &lt;/em&gt;(Politico)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 ICE spends millions on facial recognition tech&lt;br /&gt;&lt;/strong&gt;In an effort to pinpoint people it suspects have assaulted officers. (404 Media)&lt;br /&gt;+ &lt;em&gt;The Supreme Court has given ICE the go-ahead to target people based on race. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;ICE directors were told to triple their daily arrests for undocumented immigrants. &lt;/em&gt;(NY Mag $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;7 AI researchers are training AI to replace them&lt;/strong&gt;&lt;br /&gt;They’re recording every detail of their working days to help AI grasp their jobs. (The Information $)&lt;br /&gt;+ &lt;em&gt;People are worried that AI will take everyone’s jobs. We’ve been here before. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 What comes after the smartphone?&lt;br /&gt;&lt;/strong&gt;The rise of AI agents means we may not be staring at glass slabs forever. (NYT $)&lt;br /&gt;+ &lt;em&gt;What’s next for smart glasses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Social media’s obsession with ‘locking in’ needs to die&lt;/strong&gt;&lt;br /&gt;Hustle culture and maximizing productivity at all costs are the aims of the game. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 What it’s like to receive a massage from a robot&lt;/strong&gt;&lt;br /&gt;While it may not be quite as relaxing, it’s relatively cheap. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Will we ever trust robots? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It was hell on Earth.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Duncan Okindo, who was enslaved in a Myanmar cyberscam compound and beaten for missing his targets, tells the Guardian about his harrowing experience.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123449" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_1e647b.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;AI means the end of internet search as we’ve known it&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;We all know what it means, colloquially, to google something. You pop a few words in a search box and in return get a list of blue links to the most relevant results. Fundamentally, it’s just fetching information that’s already out there on the internet and showing it to you, in a structured way.&lt;/p&gt;&lt;p&gt;But all that is up for grabs. We are at a new inflection point. The biggest change to the way search engines deliver information to us since the 1990s is happening right now, thanks to generative AI.&lt;/p&gt;&lt;p&gt;Not everyone is excited for the change. Publishers are completely freaked out. And people are also worried about what these new LLM-powered results will mean for our fundamental shared reality. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Mat Honan&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Stephen King’s list of favorite movies doesn’t feature a whole lot of horror.&lt;br /&gt;+ Tune into a breathtaking livestream of Earth, beamed live from the International Space Station.&lt;br /&gt;+ Rodent thumbnails are way more important than I gave them credit for 🐿️&lt;br /&gt;+ Mark our words, actor Wagner Moura is going to be the next big thing.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/09/1123447/the-download-meet-our-ai-innovators-and-what-happens-when-therapists-use-ai-covertly/</guid><pubDate>Tue, 09 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] What is Mistral AI? Everything to know about the OpenAI competitor (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/09/what-is-mistral-ai-everything-to-know-about-the-openai-competitor/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219786590.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mistral AI, the French company that develops the AI chatbot, Le Chat, and several foundational large language models, is considered one of France’s most promising tech startups, and is arguably the only European company that could compete with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Go and download Le Chat, which is made by Mistral, rather than ChatGPT by OpenAI — or something else,” French president Emmanuel Macron said in a TV interview ahead of the AI Action Summit in Paris in February 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a significant step up from its June 2024 valuation of $6 billion, Mistral is now valued at €11.7 billion (approximately $13.8 billion) following a Series C funding round led by Dutch semiconductor company ASML, which invested €1.3 billion (approximately $1.5 billion) in September, alongside signing a new strategic partnership with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ASML’s interest in having its clients benefit from its collaboration is an important milestone for Mistral. While the French company describes itself as “the world’s greenest and leading independent AI lab,” it is still not as well known as its biggest competitors. &amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-mistral-ai"&gt;What is Mistral AI?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI, which offers some open-source AI models, has raised significant funding since its creation in 2023, with the ambition to “put frontier AI in the hands of everyone.” While this isn’t a direct jab at OpenAI, the slogan is meant to highlight the company’s openness versus OpenAI’s more recent, closed-source take at developing AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s chatbot Le Chat is available on iOS and Android, reaching 1 million downloads in the two weeks following its mobile release and grabbing France’s top spot for free downloads on the iOS App Store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July 2025, Mistral AI updated Le Chat with new features that bring it closer to rival full-stack AI chatbots: a new “deep research” mode, native multilingual reasoning, and advanced image editing. This update also added Projects, which lets users group chats, documents, and ideas into focused spaces.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As of September 2025, Le Chat can remember previous conversations thanks to a feature called Memories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is in addition to Mistral AI’s suite of models:&amp;nbsp;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Mistral Large 2, the primary large language model replacing Mistral Large.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Pixtral Large, unveiled in 2024 as a new addition to the Pixtral family of multimodal models.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Magistral, its first family of reasoning models, launched in June 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mistral Medium 3, released in May 2025 with the promise of providing efficiency without compromising performance, meant for coding and STEM tasks.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Voxtral, Mistral’s first open-source AI audio model, released in July 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Devstral, an AI model designed for coding and openly available under the Apache 2.0 license, meaning it can be used commercially without restriction.

&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Codestral, an earlier generative AI model for code whose license banned commercial applications.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;“Les Ministraux,” a family of models optimized for edge devices such as phones.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mistral Saba, focused on Arabic.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;In March 2025, the company introduced Mistral OCR, an optical character recognition API that can turn any PDF into a text file to make it easier for AI models to ingest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In June 2025, Mistral AI also released a vibe coding client, Mistral Code, to compete with Windsurf, Anysphere’s Cursor, and GitHub Copilot.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-who-are-mistral-ai-s-founders"&gt;Who are Mistral AI’s founders?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI’s three founders&amp;nbsp;share a background in AI research at major U.S. tech companies that have operations in Paris. Its CEO Arthur Mensch used to work at Google’s DeepMind; CTO Timothée Lacroix and chief scientist officer Guillaume Lample are former Meta staffers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s co-founding advisers include Jean-Charles Samuelian-Werve (also a board member) and Charles Gorintin from health insurance startup Alan. Former digital minister Cédric O is also an adviser to the company, a fact that has caused persistent controversy due to his previous role.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-are-mistral-s-models-open-source"&gt;Are Mistral’s models open source?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Not all of them. Mistral differentiates its premier models, whose weights are not available for commercial purposes, from its free models, for which it provides weights under the Apache 2.0 license.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Free models include research models such as Mistral NeMo, built in collaboration with Nvidia which the startup open sourced in July 2024.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-does-mistral-make-money"&gt;How does Mistral make money?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While many of Mistral AI’s offerings are free or now have free tiers, Le Chat also has paid tiers. Introduced in February 2025, Le Chat’s Pro subscription costs $14.99 a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the B2B front, Mistral AI monetizes its premier models through APIs with usage-based pricing. Enterprises can also license these models, and the company likely also generates a significant share of its revenue from its strategic partnerships, some of which it highlighted during the Paris AI Summit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, however, Mistral AI’s revenue is reportedly in the eight-digit range, according to multiple sources.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-partnerships-has-mistral-ai-closed"&gt;What partnerships has Mistral AI closed?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Mistral AI signed a deal with Microsoft that included a €15 million investment and a strategic partnership for distributing the French company’s AI models through Microsoft’s Azure platform. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.K.’s Competition and Markets Authority (CMA) swiftly concluded that the deal didn’t qualify for investigation due to its small size, though the deal sparked some criticism in the EU.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January 2025, Mistral signed a deal with press agency Agence France-Presse (AFP) to let Le Chat query the AFP’s entire text archive dating back to 1983.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI also secured strategic partnerships with France’s army and job agency; Luxembourg, shipping giant CMA, German defense tech startup Helsing, IBM, Orange, and Stellantis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May 2025, Mistral said it would participate in the creation of an AI Campus in the Paris region, as part of a joint venture with UAE-investment firm MGX, NVIDIA, and France’s state-owned investment bank Bpifrance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2025, Mistral said it would launch a European platform dedicated to AI and powered by Nvidia processors, Mistral Compute, in 2026. The initiative was hailed as ‘historic’ by Macron, who shared the stage with Mensch and Nvidia CEO Jensen Huang at the VivaTech conference shortly after the announcement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July 2025, Mistral launched AI for Citizens, an initiative that the company claimed could “help States and public institutions strategically harness AI for their people by transforming public services.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In September 2025, Mistral and chip company ASML struck a partnership “to explore the use of AI models across ASML’s product portfolio as well as research, development and operations.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-enterprise-features-has-mistral-ai-developed"&gt;&lt;strong&gt;What enterprise features has Mistral AI developed?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In May 2025, Mistral AI released the Mistral Agents API to “empower enterprises to use AI in more practical and impactful ways,” according to its Head of Developer Relations, Sophia Yang.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In September 2025, the company unveiled a revamped Connectors directory, showcasing Le Chat’s integrations with some 20 enterprise tools, including Asana, Atlassian, Box, Google Drive, Notion, and Zapier, as well as emails and calendars; and soon, Databricks and Snowflake.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-much-funding-has-mistral-ai-raised-to-date"&gt;&lt;strong&gt;How much funding has Mistral AI raised to date?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;By February 2025, Mistral AI had raised a total of around €1 billion, some of which was debt financing. The money was raised across several equity rounds conducted in close succession.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2023, just one month after being founded, Mistral AI raised a record $112 million seed round led by Lightspeed Venture Partners. Sources at the time said the seed round, Europe’s largest ever, valued the startup at $260 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other investors in that round included Bpifrance, Eric Schmidt, Exor Ventures, First Minute Capital, Headline, JCDecaux Holding, La Famiglia, LocalGlobe, Motier Ventures, Rodolphe Saadé, Sofina, and Xavier Niel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Six months later, Mistral closed €385 million Series A ($415 million at the time), at a reported valuation of $2 billion. The round was led by Andreessen Horowitz, and saw participation from Lightspeed, as well as BNP Paribas, CMA-CGM, Conviction, Elad Gil, General Catalyst and Salesforce.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s $16.3 million convertible investment in Mistral as part of a partnership announced in February 2024, was presented as a Series A extension, implying an unchanged valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2024, Mistral raised €600 million (about $640 million) in a mix of equity and debt. The long-rumored round was led by General Catalyst at a $6 billion valuation, with notable investors including Cisco, IBM, Nvidia, and Samsung Venture Investment Corporation participating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Mistral AI was rumored to be finalizing a €2 billion investment at a post-money valuation of $14 billion. This followed earlier reports that the company was in talks to raise $1 billion in equity from investors who included Abu Dhabi’s MGX fund, as well as hundreds of millions of euros in debt.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On September 9, 2025, Mistral closed a €1.7 billion (about $2 billion) Series C round  led by ASML at a €11.7 billion (approximately $13.8 billion) valuation. According to the company, the round saw investments from existing backers DST Global, Andreessen Horowitz, Bpifrance, General Catalyst, Index Ventures, Lightspeed, and NVIDIA.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-is-mistral-ai-approaching-ai-regulation"&gt;How is Mistral AI approaching AI regulation?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mensch was part of a group of European CEOs who signed an open letter in July 2025 urging Brussels to ‘stop the clock’ for two years before key obligations of the EU Artificial Intelligence Act enter into force. The European Commission is sticking to its original timeline.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-could-a-mistral-ai-exit-look-like"&gt;What could a Mistral AI exit look like?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral is “not for sale,” Mensch said in January 2025 at the World Economic Forum in Davos. “Of course, [an IPO is] the plan.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This makes sense, given how much the startup has raised so far: Even a large sale may not provide high enough multiples for its investors, not to mention sovereignty concerns depending on the acquirer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the only way to definitely squash persistent acquisition rumors — lately naming Apple — is to scale its revenue to levels that could even remotely justify its valuation. Either way, stay tuned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was originally published on February 28, 2025, and will be regularly updated&lt;/em&gt;.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219786590.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mistral AI, the French company that develops the AI chatbot, Le Chat, and several foundational large language models, is considered one of France’s most promising tech startups, and is arguably the only European company that could compete with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Go and download Le Chat, which is made by Mistral, rather than ChatGPT by OpenAI — or something else,” French president Emmanuel Macron said in a TV interview ahead of the AI Action Summit in Paris in February 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a significant step up from its June 2024 valuation of $6 billion, Mistral is now valued at €11.7 billion (approximately $13.8 billion) following a Series C funding round led by Dutch semiconductor company ASML, which invested €1.3 billion (approximately $1.5 billion) in September, alongside signing a new strategic partnership with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ASML’s interest in having its clients benefit from its collaboration is an important milestone for Mistral. While the French company describes itself as “the world’s greenest and leading independent AI lab,” it is still not as well known as its biggest competitors. &amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-mistral-ai"&gt;What is Mistral AI?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI, which offers some open-source AI models, has raised significant funding since its creation in 2023, with the ambition to “put frontier AI in the hands of everyone.” While this isn’t a direct jab at OpenAI, the slogan is meant to highlight the company’s openness versus OpenAI’s more recent, closed-source take at developing AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s chatbot Le Chat is available on iOS and Android, reaching 1 million downloads in the two weeks following its mobile release and grabbing France’s top spot for free downloads on the iOS App Store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July 2025, Mistral AI updated Le Chat with new features that bring it closer to rival full-stack AI chatbots: a new “deep research” mode, native multilingual reasoning, and advanced image editing. This update also added Projects, which lets users group chats, documents, and ideas into focused spaces.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As of September 2025, Le Chat can remember previous conversations thanks to a feature called Memories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is in addition to Mistral AI’s suite of models:&amp;nbsp;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Mistral Large 2, the primary large language model replacing Mistral Large.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Pixtral Large, unveiled in 2024 as a new addition to the Pixtral family of multimodal models.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Magistral, its first family of reasoning models, launched in June 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mistral Medium 3, released in May 2025 with the promise of providing efficiency without compromising performance, meant for coding and STEM tasks.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Voxtral, Mistral’s first open-source AI audio model, released in July 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Devstral, an AI model designed for coding and openly available under the Apache 2.0 license, meaning it can be used commercially without restriction.

&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Codestral, an earlier generative AI model for code whose license banned commercial applications.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;“Les Ministraux,” a family of models optimized for edge devices such as phones.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mistral Saba, focused on Arabic.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;In March 2025, the company introduced Mistral OCR, an optical character recognition API that can turn any PDF into a text file to make it easier for AI models to ingest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In June 2025, Mistral AI also released a vibe coding client, Mistral Code, to compete with Windsurf, Anysphere’s Cursor, and GitHub Copilot.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-who-are-mistral-ai-s-founders"&gt;Who are Mistral AI’s founders?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI’s three founders&amp;nbsp;share a background in AI research at major U.S. tech companies that have operations in Paris. Its CEO Arthur Mensch used to work at Google’s DeepMind; CTO Timothée Lacroix and chief scientist officer Guillaume Lample are former Meta staffers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s co-founding advisers include Jean-Charles Samuelian-Werve (also a board member) and Charles Gorintin from health insurance startup Alan. Former digital minister Cédric O is also an adviser to the company, a fact that has caused persistent controversy due to his previous role.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-are-mistral-s-models-open-source"&gt;Are Mistral’s models open source?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Not all of them. Mistral differentiates its premier models, whose weights are not available for commercial purposes, from its free models, for which it provides weights under the Apache 2.0 license.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Free models include research models such as Mistral NeMo, built in collaboration with Nvidia which the startup open sourced in July 2024.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-does-mistral-make-money"&gt;How does Mistral make money?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While many of Mistral AI’s offerings are free or now have free tiers, Le Chat also has paid tiers. Introduced in February 2025, Le Chat’s Pro subscription costs $14.99 a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the B2B front, Mistral AI monetizes its premier models through APIs with usage-based pricing. Enterprises can also license these models, and the company likely also generates a significant share of its revenue from its strategic partnerships, some of which it highlighted during the Paris AI Summit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, however, Mistral AI’s revenue is reportedly in the eight-digit range, according to multiple sources.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-partnerships-has-mistral-ai-closed"&gt;What partnerships has Mistral AI closed?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Mistral AI signed a deal with Microsoft that included a €15 million investment and a strategic partnership for distributing the French company’s AI models through Microsoft’s Azure platform. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.K.’s Competition and Markets Authority (CMA) swiftly concluded that the deal didn’t qualify for investigation due to its small size, though the deal sparked some criticism in the EU.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January 2025, Mistral signed a deal with press agency Agence France-Presse (AFP) to let Le Chat query the AFP’s entire text archive dating back to 1983.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral AI also secured strategic partnerships with France’s army and job agency; Luxembourg, shipping giant CMA, German defense tech startup Helsing, IBM, Orange, and Stellantis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May 2025, Mistral said it would participate in the creation of an AI Campus in the Paris region, as part of a joint venture with UAE-investment firm MGX, NVIDIA, and France’s state-owned investment bank Bpifrance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2025, Mistral said it would launch a European platform dedicated to AI and powered by Nvidia processors, Mistral Compute, in 2026. The initiative was hailed as ‘historic’ by Macron, who shared the stage with Mensch and Nvidia CEO Jensen Huang at the VivaTech conference shortly after the announcement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July 2025, Mistral launched AI for Citizens, an initiative that the company claimed could “help States and public institutions strategically harness AI for their people by transforming public services.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In September 2025, Mistral and chip company ASML struck a partnership “to explore the use of AI models across ASML’s product portfolio as well as research, development and operations.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-enterprise-features-has-mistral-ai-developed"&gt;&lt;strong&gt;What enterprise features has Mistral AI developed?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In May 2025, Mistral AI released the Mistral Agents API to “empower enterprises to use AI in more practical and impactful ways,” according to its Head of Developer Relations, Sophia Yang.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In September 2025, the company unveiled a revamped Connectors directory, showcasing Le Chat’s integrations with some 20 enterprise tools, including Asana, Atlassian, Box, Google Drive, Notion, and Zapier, as well as emails and calendars; and soon, Databricks and Snowflake.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-much-funding-has-mistral-ai-raised-to-date"&gt;&lt;strong&gt;How much funding has Mistral AI raised to date?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;By February 2025, Mistral AI had raised a total of around €1 billion, some of which was debt financing. The money was raised across several equity rounds conducted in close succession.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2023, just one month after being founded, Mistral AI raised a record $112 million seed round led by Lightspeed Venture Partners. Sources at the time said the seed round, Europe’s largest ever, valued the startup at $260 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other investors in that round included Bpifrance, Eric Schmidt, Exor Ventures, First Minute Capital, Headline, JCDecaux Holding, La Famiglia, LocalGlobe, Motier Ventures, Rodolphe Saadé, Sofina, and Xavier Niel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Six months later, Mistral closed €385 million Series A ($415 million at the time), at a reported valuation of $2 billion. The round was led by Andreessen Horowitz, and saw participation from Lightspeed, as well as BNP Paribas, CMA-CGM, Conviction, Elad Gil, General Catalyst and Salesforce.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s $16.3 million convertible investment in Mistral as part of a partnership announced in February 2024, was presented as a Series A extension, implying an unchanged valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2024, Mistral raised €600 million (about $640 million) in a mix of equity and debt. The long-rumored round was led by General Catalyst at a $6 billion valuation, with notable investors including Cisco, IBM, Nvidia, and Samsung Venture Investment Corporation participating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Mistral AI was rumored to be finalizing a €2 billion investment at a post-money valuation of $14 billion. This followed earlier reports that the company was in talks to raise $1 billion in equity from investors who included Abu Dhabi’s MGX fund, as well as hundreds of millions of euros in debt.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On September 9, 2025, Mistral closed a €1.7 billion (about $2 billion) Series C round  led by ASML at a €11.7 billion (approximately $13.8 billion) valuation. According to the company, the round saw investments from existing backers DST Global, Andreessen Horowitz, Bpifrance, General Catalyst, Index Ventures, Lightspeed, and NVIDIA.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-is-mistral-ai-approaching-ai-regulation"&gt;How is Mistral AI approaching AI regulation?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mensch was part of a group of European CEOs who signed an open letter in July 2025 urging Brussels to ‘stop the clock’ for two years before key obligations of the EU Artificial Intelligence Act enter into force. The European Commission is sticking to its original timeline.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-could-a-mistral-ai-exit-look-like"&gt;What could a Mistral AI exit look like?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral is “not for sale,” Mensch said in January 2025 at the World Economic Forum in Davos. “Of course, [an IPO is] the plan.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This makes sense, given how much the startup has raised so far: Even a large sale may not provide high enough multiples for its investors, not to mention sovereignty concerns depending on the acquirer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the only way to definitely squash persistent acquisition rumors — lately naming Apple — is to scale its revenue to levels that could even remotely justify its valuation. Either way, stay tuned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was originally published on February 28, 2025, and will be regularly updated&lt;/em&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/09/what-is-mistral-ai-everything-to-know-about-the-openai-competitor/</guid><pubDate>Tue, 09 Sep 2025 12:15:00 +0000</pubDate></item><item><title>[NEW] Nuclearn gets $10.5M to help the nuclear industry embrace AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/09/nuclearn-gets-10-5m-to-help-the-nuclear-industry-embrace-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-124923144.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Companies that have dug deep into AI have fallen in love with nuclear power for its promise of 24/7 electricity. Meta, Google, and Microsoft have all made deals with startups or reactor operators. But does the nuclear industry love AI back?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, with caveats.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;No one is proposing to let an AI run a reactor, but power companies are increasingly interested in the technology’s potential to tighten things up on the business side, Bradley Fox, co-founder and CEO of Nuclearn, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fox and Jerrold Vincent started Nuclearn to capitalize on that interest. The company says its AI tools are being used in more than 65 nuclear reactors around the world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It recently raised a $10.5 million Series A round led by Blue Bear Capital with participation from AZ-VC, Nucleation Capital, and SJF Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nuclearn got its start when the founders were working at the Palo Verde Nuclear Generating Station just west of Phoenix. They had been experimenting with ways to streamline various repetitive tasks first from a data science perspective then with more advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, other reactors took note, Fox said. “Can you help us do the same thing you’re doing for Palo Verde but for my plant?” they asked him.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That interest coincided with the COVID pandemic. “We both were kind of bored after work,” Fox said. “We’re like, hey, let’s work on a startup.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nuclearn has developed models trained on nuclear industry-specific terminology. The startup can train custom models for utilities and power providers that request it, and while its software runs in the cloud, it can also help reactors set up hardware on site if their security protocols require it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s software can generate routine documentation that reactor employees then review and sign off on.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Most AI in the industry now, the [Nuclear Regulatory Commission] considers it a tool. It’s the same way as if you’re going to use Excel or Mathematica or some type of engineering software,” Fox said. “Liability always falls with a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reactor operators can set thresholds for how much gets automated depending on their level of comfort and their confidence in how well the model can tackle the problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the model doesn’t know or if we’re unsure, based on the setting you select, it’ll send it back to the right people and get a double check,” Fox said. “We tell the customers, ‘Think of this as the junior employee.’”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-124923144.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Companies that have dug deep into AI have fallen in love with nuclear power for its promise of 24/7 electricity. Meta, Google, and Microsoft have all made deals with startups or reactor operators. But does the nuclear industry love AI back?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, with caveats.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;No one is proposing to let an AI run a reactor, but power companies are increasingly interested in the technology’s potential to tighten things up on the business side, Bradley Fox, co-founder and CEO of Nuclearn, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fox and Jerrold Vincent started Nuclearn to capitalize on that interest. The company says its AI tools are being used in more than 65 nuclear reactors around the world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It recently raised a $10.5 million Series A round led by Blue Bear Capital with participation from AZ-VC, Nucleation Capital, and SJF Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nuclearn got its start when the founders were working at the Palo Verde Nuclear Generating Station just west of Phoenix. They had been experimenting with ways to streamline various repetitive tasks first from a data science perspective then with more advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, other reactors took note, Fox said. “Can you help us do the same thing you’re doing for Palo Verde but for my plant?” they asked him.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That interest coincided with the COVID pandemic. “We both were kind of bored after work,” Fox said. “We’re like, hey, let’s work on a startup.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nuclearn has developed models trained on nuclear industry-specific terminology. The startup can train custom models for utilities and power providers that request it, and while its software runs in the cloud, it can also help reactors set up hardware on site if their security protocols require it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s software can generate routine documentation that reactor employees then review and sign off on.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Most AI in the industry now, the [Nuclear Regulatory Commission] considers it a tool. It’s the same way as if you’re going to use Excel or Mathematica or some type of engineering software,” Fox said. “Liability always falls with a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reactor operators can set thresholds for how much gets automated depending on their level of comfort and their confidence in how well the model can tackle the problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the model doesn’t know or if we’re unsure, based on the setting you select, it’ll send it back to the right people and get a double check,” Fox said. “We tell the customers, ‘Think of this as the junior employee.’”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/09/nuclearn-gets-10-5m-to-help-the-nuclear-industry-embrace-ai/</guid><pubDate>Tue, 09 Sep 2025 12:45:00 +0000</pubDate></item></channel></rss>