<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 09 Jan 2026 06:38:19 +0000</lastBuildDate><item><title>Grok assumes users seeking images of underage girls have “good intent” (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/grok-assumes-users-seeking-images-of-underage-girls-have-good-intent/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Expert explains how simple it could be to tweak Grok to block CSAM outputs.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For weeks, xAI has faced backlash over undressing and sexualizing images of women and children generated by Grok. One researcher conducted a 24-hour analysis of the Grok account on X and estimated that the chatbot generated over 6,000 images an hour flagged as “sexually suggestive or nudifying,” Bloomberg reported.&lt;/p&gt;
&lt;p&gt;While the chatbot claimed that xAI supposedly “identified lapses in safeguards” that allowed outputs flagged as child sexual abuse material (CSAM) and was “urgently fixing them,” Grok has proven to be an unreliable spokesperson, and xAI has not announced any fixes.&lt;/p&gt;
&lt;p&gt;A quick look at Grok’s safety guidelines on its public GitHub shows they were last updated two months ago. The GitHub also indicates that, despite prohibiting such content, Grok maintains programming that could make it likely to generate CSAM.&lt;/p&gt;
&lt;p&gt;Billed as “the highest priority,” superseding “any other instructions” Grok may receive, these rules explicitly prohibit Grok from assisting with queries that “clearly intend to engage” in creating or distributing CSAM or otherwise sexually exploit children.&lt;/p&gt;
&lt;p&gt;However, the rules also direct Grok to “assume good intent” and “don’t make worst-case assumptions without evidence” when users request images of young women.&lt;/p&gt;
&lt;p&gt;Using words like “‘teenage’ or ‘girl’ does not necessarily imply underage,” Grok’s instructions say.&lt;/p&gt;
&lt;p&gt;X declined Ars’ request to comment. The only statement X Safety has made so far shows that Elon Musk’s social media platform plans to blame users for generating CSAM, threatening to permanently suspend users and report them to law enforcement.&lt;/p&gt;
&lt;p&gt;Critics dispute that X’s solution will end the Grok scandal, and child safety advocates and foreign governments are growing increasingly alarmed as X delays updates that could block Grok’s undressing spree.&lt;/p&gt;
&lt;h2&gt;Why Grok shouldn’t “assume good intentions”&lt;/h2&gt;
&lt;p&gt;Grok can struggle to assess users’ intenttions, making it “incredibly easy” for the chatbot to generate CSAM under xAI’s policy, Alex Georges, an AI safety researcher, told Ars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot has been instructed, for example, that “there are **no restrictions** on fictional adult sexual content with dark or violent themes,” and Grok’s mandate to assume “good intent” may create gray areas in which CSAM could be created.&lt;/p&gt;
&lt;p&gt;There’s evidence that in relying on these guidelines, Grok is currently generating a flood of harmful images on X, with even more graphic images being created on the chatbot’s standalone website and app, Wired reported. Researchers who surveyed 20,000 random images and 50,000 prompts told CNN that more than half of Grok’s outputs that feature images of people sexualize women, with 2 percent depicting “people appearing to be 18 years old or younger.” Some users specifically “requested minors be put in erotic positions and that sexual fluids be depicted on their bodies,” researchers found.&lt;/p&gt;
&lt;p&gt;Grok isn’t the only chatbot that sexualizes images of real people without consent, but its policy seems to leave safety at a surface level, Georges said, and xAI is seemingly unwilling to expand safety efforts to block more harmful outputs.&lt;/p&gt;
&lt;p&gt;Georges is the founder and CEO of AetherLab, an AI company that helps a wide range of firms—including tech giants like OpenAI, Microsoft, and Amazon—deploy generative AI products with appropriate safeguards. He told Ars that AetherLab works with many AI companies that are concerned about blocking harmful companion bot outputs like Grok’s. And although there are no industry norms—creating a “Wild West” due to regulatory gaps, particularly in the US—his experience with chatbot content moderation has convinced him that Grok’s instructions to “assume good intent” are “silly” because xAI’s requirement of “clear intent” doesn’t mean anything operationally to the chatbot.&lt;/p&gt;
&lt;p&gt;“I can very easily get harmful outputs by just obfuscating my intent,” Georges said, emphasizing that “users absolutely do not automatically fit into the good-intent bucket.” And even “in a perfect world,” where “every single user does have good intent,” Georges noted, the model “will still generate bad content on its own because of how it’s trained.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Benign inputs can lead to harmful outputs, Georges explained, and a sound safety system would catch both benign and harmful prompts. Consider, he suggested, a prompt for “a pic of a girl model taking swimming lessons.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The user could be trying to create an ad for a swimming school, or they could have malicious intent and be attempting to manipulate the model. For users with benign intent, prompting can “go wrong,” Georges said, if Grok’s training data statistically links certain “normal phrases and situations” to “younger-looking subjects and/or more revealing depictions.”&lt;/p&gt;
&lt;p&gt;“Grok might have seen a bunch of images where ‘girls taking swimming lessons’ were young and that human ‘models’ were dressed in revealing things, which means it could produce an underage girl in a swimming pool wearing something revealing,” Georges said. “So, a prompt that looks ‘normal’ can still produce an image that crosses the line.”&lt;/p&gt;
&lt;p&gt;While AetherLab has never worked directly with xAI or X, Georges’ team has “tested their systems independently by probing for harmful outputs, and unsurprisingly, we’ve been able to get really bad content out of them,” Georges said.&lt;/p&gt;
&lt;p&gt;Leaving AI chatbots unchecked poses a risk to children. A spokesperson for the National Center for Missing and Exploited Children (NCMEC), which processes reports of CSAM on X in the US, told Ars that “sexual images of children, including those created using artificial intelligence, are child sexual abuse material (CSAM). Whether an image is real or computer-generated, the harm is real, and the material is illegal.”&lt;/p&gt;
&lt;p&gt;Researchers at the Internet Watch Foundation told the BBC that users of dark web forums are already promoting CSAM they claim was generated by Grok. These images are typically classified in the United Kingdom as the “lowest severity of criminal material,” researchers said. But at least one user was found to have fed a less-severe Grok output into another tool to generate the “most serious” criminal material, demonstrating how Grok could be used as an instrument by those seeking to commercialize AI CSAM.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Easy tweaks to make Grok safer&lt;/h2&gt;
&lt;p&gt;In August, xAI explained how the company works to keep Grok safe for users. But although the company acknowledged that it’s difficult to distinguish “malignant intent” from “mere curiosity,” xAI seemed convinced that Grok could “decline queries demonstrating clear intent to engage in activities” like child sexual exploitation, without blocking prompts from merely curious users.&lt;/p&gt;
&lt;p&gt;That report showed that xAI refines Grok over time to block requests for CSAM “by adding &lt;span class="s1"&gt;safeguards to refuse requests that may lead to foreseeable harm"—a step xAI does not appear to have taken since late December, when reports first raised concerns that Grok was sexualizing images of minors.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Georges said there are easy tweaks xAI could make to Grok to block harmful outputs, including CSAM, while acknowledging that he is making assumptions without knowing exactly how xAI works to place checks on Grok.&lt;/p&gt;
&lt;p&gt;First, he recommended that Grok rely on end-to-end guardrails, blocking “obvious” malicious prompts and flagging suspicious ones. It should then double-check outputs to block harmful ones, even when prompts are benign.&lt;/p&gt;
&lt;p&gt;This strategy works best, Georges said, when multiple watchdog systems are employed, noting that “you can’t rely on the generator to self-police because its learned biases are part of what creates these failure modes.” That’s the role that AetherLab wants to fill across the industry, helping test chatbots for weakness to block harmful outputs by using “an ‘agentic’ approach with a shitload of AI models working together (thereby reducing the collective bias),” Georges said.&lt;/p&gt;
&lt;p&gt;xAI could also likely block more harmful outputs by reworking Grok’s prompt style guidance, Georges suggested. “If Grok is, say, 30 percent vulnerable to CSAM-style attacks and another provider is 1 percent vulnerable, that’s a massive difference,” Georges said.&lt;/p&gt;
&lt;p&gt;It appears that xAI is currently relying on Grok to police itself, while using safety guidelines that Georges said overlook an “enormous” number of potential cases where Grok could generate harmful content. The guidelines do not “signal that safety is a real concern,” Georges said, suggesting that “if I wanted to look safe while still allowing a lot under the hood, this is close to the policy I’d write.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Chatbot makers must protect kids, NCMEC says&lt;/h2&gt;
&lt;p&gt;X has been very vocal about policing its platform for CSAM since Musk took over Twitter, but under former CEO Linda Yaccarino, the company adopted a broad protective stance against all image-based sexual abuse (IBSA). In 2024, X became one of the earliest corporations to voluntarily adopt the IBSA Principles that X now seems to be violating by failing to tweak Grok.&lt;/p&gt;
&lt;p&gt;Those principles seek to combat all kinds of IBSA, recognizing that even fake images can “cause devastating psychological, financial, and reputational harm.” When it adopted the principles, X vowed to prevent the nonconsensual distribution of intimate images by providing easy-to-use reporting tools and quickly supporting the needs of victims desperate to block “the nonconsensual creation or distribution of intimate images” on its platform.&lt;/p&gt;
&lt;p&gt;Kate Ruane, the director of the Center for Democracy and Technology&lt;b&gt;’&lt;/b&gt;s Free Expression Project, which helped form the working group behind the IBSA Principles, told Ars that although the commitments X made were “voluntary,” they signaled that X agreed the problem was a “pressing issue the company should take seriously.”&lt;/p&gt;
&lt;p&gt;“They are on record saying that they will do these things, and they are not,” Ruane said.&lt;/p&gt;
&lt;p&gt;As the Grok controversy sparks probes in Europe, India, and Malaysia, xAI may be forced to update Grok’s safety guidelines or make other tweaks to block the worst outputs.&lt;/p&gt;
&lt;p&gt;In the US, xAI may face civil suits under federal or state laws that restrict intimate image abuse. If Grok’s harmful outputs continue into May, X could face penalties under the Take It Down Act, which authorizes the Federal Trade Commission to intervene if platforms don’t quickly remove both real and AI-generated non-consensual intimate imagery.&lt;/p&gt;
&lt;p&gt;But whether US authorities will intervene any time soon remains unknown, as Musk is a close ally of the Trump administration. A spokesperson for the Justice Department told CNN that the department “takes AI-generated child sex abuse material extremely seriously and will aggressively prosecute any producer or possessor of CSAM.”&lt;/p&gt;
&lt;p&gt;“Laws are only as good as their enforcement,” Ruane told Ars. “You need law enforcement at the Federal Trade Commission or at the Department of Justice to be willing to go after these companies if they are in violation of the laws.”&lt;/p&gt;
&lt;p&gt;Child safety advocates seem alarmed by the sluggish response. “Technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children,” NCMEC’s spokesperson told Ars. “As AI continues to advance, protecting children must remain a clear and nonnegotiable priority.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Expert explains how simple it could be to tweak Grok to block CSAM outputs.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For weeks, xAI has faced backlash over undressing and sexualizing images of women and children generated by Grok. One researcher conducted a 24-hour analysis of the Grok account on X and estimated that the chatbot generated over 6,000 images an hour flagged as “sexually suggestive or nudifying,” Bloomberg reported.&lt;/p&gt;
&lt;p&gt;While the chatbot claimed that xAI supposedly “identified lapses in safeguards” that allowed outputs flagged as child sexual abuse material (CSAM) and was “urgently fixing them,” Grok has proven to be an unreliable spokesperson, and xAI has not announced any fixes.&lt;/p&gt;
&lt;p&gt;A quick look at Grok’s safety guidelines on its public GitHub shows they were last updated two months ago. The GitHub also indicates that, despite prohibiting such content, Grok maintains programming that could make it likely to generate CSAM.&lt;/p&gt;
&lt;p&gt;Billed as “the highest priority,” superseding “any other instructions” Grok may receive, these rules explicitly prohibit Grok from assisting with queries that “clearly intend to engage” in creating or distributing CSAM or otherwise sexually exploit children.&lt;/p&gt;
&lt;p&gt;However, the rules also direct Grok to “assume good intent” and “don’t make worst-case assumptions without evidence” when users request images of young women.&lt;/p&gt;
&lt;p&gt;Using words like “‘teenage’ or ‘girl’ does not necessarily imply underage,” Grok’s instructions say.&lt;/p&gt;
&lt;p&gt;X declined Ars’ request to comment. The only statement X Safety has made so far shows that Elon Musk’s social media platform plans to blame users for generating CSAM, threatening to permanently suspend users and report them to law enforcement.&lt;/p&gt;
&lt;p&gt;Critics dispute that X’s solution will end the Grok scandal, and child safety advocates and foreign governments are growing increasingly alarmed as X delays updates that could block Grok’s undressing spree.&lt;/p&gt;
&lt;h2&gt;Why Grok shouldn’t “assume good intentions”&lt;/h2&gt;
&lt;p&gt;Grok can struggle to assess users’ intenttions, making it “incredibly easy” for the chatbot to generate CSAM under xAI’s policy, Alex Georges, an AI safety researcher, told Ars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot has been instructed, for example, that “there are **no restrictions** on fictional adult sexual content with dark or violent themes,” and Grok’s mandate to assume “good intent” may create gray areas in which CSAM could be created.&lt;/p&gt;
&lt;p&gt;There’s evidence that in relying on these guidelines, Grok is currently generating a flood of harmful images on X, with even more graphic images being created on the chatbot’s standalone website and app, Wired reported. Researchers who surveyed 20,000 random images and 50,000 prompts told CNN that more than half of Grok’s outputs that feature images of people sexualize women, with 2 percent depicting “people appearing to be 18 years old or younger.” Some users specifically “requested minors be put in erotic positions and that sexual fluids be depicted on their bodies,” researchers found.&lt;/p&gt;
&lt;p&gt;Grok isn’t the only chatbot that sexualizes images of real people without consent, but its policy seems to leave safety at a surface level, Georges said, and xAI is seemingly unwilling to expand safety efforts to block more harmful outputs.&lt;/p&gt;
&lt;p&gt;Georges is the founder and CEO of AetherLab, an AI company that helps a wide range of firms—including tech giants like OpenAI, Microsoft, and Amazon—deploy generative AI products with appropriate safeguards. He told Ars that AetherLab works with many AI companies that are concerned about blocking harmful companion bot outputs like Grok’s. And although there are no industry norms—creating a “Wild West” due to regulatory gaps, particularly in the US—his experience with chatbot content moderation has convinced him that Grok’s instructions to “assume good intent” are “silly” because xAI’s requirement of “clear intent” doesn’t mean anything operationally to the chatbot.&lt;/p&gt;
&lt;p&gt;“I can very easily get harmful outputs by just obfuscating my intent,” Georges said, emphasizing that “users absolutely do not automatically fit into the good-intent bucket.” And even “in a perfect world,” where “every single user does have good intent,” Georges noted, the model “will still generate bad content on its own because of how it’s trained.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Benign inputs can lead to harmful outputs, Georges explained, and a sound safety system would catch both benign and harmful prompts. Consider, he suggested, a prompt for “a pic of a girl model taking swimming lessons.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The user could be trying to create an ad for a swimming school, or they could have malicious intent and be attempting to manipulate the model. For users with benign intent, prompting can “go wrong,” Georges said, if Grok’s training data statistically links certain “normal phrases and situations” to “younger-looking subjects and/or more revealing depictions.”&lt;/p&gt;
&lt;p&gt;“Grok might have seen a bunch of images where ‘girls taking swimming lessons’ were young and that human ‘models’ were dressed in revealing things, which means it could produce an underage girl in a swimming pool wearing something revealing,” Georges said. “So, a prompt that looks ‘normal’ can still produce an image that crosses the line.”&lt;/p&gt;
&lt;p&gt;While AetherLab has never worked directly with xAI or X, Georges’ team has “tested their systems independently by probing for harmful outputs, and unsurprisingly, we’ve been able to get really bad content out of them,” Georges said.&lt;/p&gt;
&lt;p&gt;Leaving AI chatbots unchecked poses a risk to children. A spokesperson for the National Center for Missing and Exploited Children (NCMEC), which processes reports of CSAM on X in the US, told Ars that “sexual images of children, including those created using artificial intelligence, are child sexual abuse material (CSAM). Whether an image is real or computer-generated, the harm is real, and the material is illegal.”&lt;/p&gt;
&lt;p&gt;Researchers at the Internet Watch Foundation told the BBC that users of dark web forums are already promoting CSAM they claim was generated by Grok. These images are typically classified in the United Kingdom as the “lowest severity of criminal material,” researchers said. But at least one user was found to have fed a less-severe Grok output into another tool to generate the “most serious” criminal material, demonstrating how Grok could be used as an instrument by those seeking to commercialize AI CSAM.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Easy tweaks to make Grok safer&lt;/h2&gt;
&lt;p&gt;In August, xAI explained how the company works to keep Grok safe for users. But although the company acknowledged that it’s difficult to distinguish “malignant intent” from “mere curiosity,” xAI seemed convinced that Grok could “decline queries demonstrating clear intent to engage in activities” like child sexual exploitation, without blocking prompts from merely curious users.&lt;/p&gt;
&lt;p&gt;That report showed that xAI refines Grok over time to block requests for CSAM “by adding &lt;span class="s1"&gt;safeguards to refuse requests that may lead to foreseeable harm"—a step xAI does not appear to have taken since late December, when reports first raised concerns that Grok was sexualizing images of minors.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Georges said there are easy tweaks xAI could make to Grok to block harmful outputs, including CSAM, while acknowledging that he is making assumptions without knowing exactly how xAI works to place checks on Grok.&lt;/p&gt;
&lt;p&gt;First, he recommended that Grok rely on end-to-end guardrails, blocking “obvious” malicious prompts and flagging suspicious ones. It should then double-check outputs to block harmful ones, even when prompts are benign.&lt;/p&gt;
&lt;p&gt;This strategy works best, Georges said, when multiple watchdog systems are employed, noting that “you can’t rely on the generator to self-police because its learned biases are part of what creates these failure modes.” That’s the role that AetherLab wants to fill across the industry, helping test chatbots for weakness to block harmful outputs by using “an ‘agentic’ approach with a shitload of AI models working together (thereby reducing the collective bias),” Georges said.&lt;/p&gt;
&lt;p&gt;xAI could also likely block more harmful outputs by reworking Grok’s prompt style guidance, Georges suggested. “If Grok is, say, 30 percent vulnerable to CSAM-style attacks and another provider is 1 percent vulnerable, that’s a massive difference,” Georges said.&lt;/p&gt;
&lt;p&gt;It appears that xAI is currently relying on Grok to police itself, while using safety guidelines that Georges said overlook an “enormous” number of potential cases where Grok could generate harmful content. The guidelines do not “signal that safety is a real concern,” Georges said, suggesting that “if I wanted to look safe while still allowing a lot under the hood, this is close to the policy I’d write.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Chatbot makers must protect kids, NCMEC says&lt;/h2&gt;
&lt;p&gt;X has been very vocal about policing its platform for CSAM since Musk took over Twitter, but under former CEO Linda Yaccarino, the company adopted a broad protective stance against all image-based sexual abuse (IBSA). In 2024, X became one of the earliest corporations to voluntarily adopt the IBSA Principles that X now seems to be violating by failing to tweak Grok.&lt;/p&gt;
&lt;p&gt;Those principles seek to combat all kinds of IBSA, recognizing that even fake images can “cause devastating psychological, financial, and reputational harm.” When it adopted the principles, X vowed to prevent the nonconsensual distribution of intimate images by providing easy-to-use reporting tools and quickly supporting the needs of victims desperate to block “the nonconsensual creation or distribution of intimate images” on its platform.&lt;/p&gt;
&lt;p&gt;Kate Ruane, the director of the Center for Democracy and Technology&lt;b&gt;’&lt;/b&gt;s Free Expression Project, which helped form the working group behind the IBSA Principles, told Ars that although the commitments X made were “voluntary,” they signaled that X agreed the problem was a “pressing issue the company should take seriously.”&lt;/p&gt;
&lt;p&gt;“They are on record saying that they will do these things, and they are not,” Ruane said.&lt;/p&gt;
&lt;p&gt;As the Grok controversy sparks probes in Europe, India, and Malaysia, xAI may be forced to update Grok’s safety guidelines or make other tweaks to block the worst outputs.&lt;/p&gt;
&lt;p&gt;In the US, xAI may face civil suits under federal or state laws that restrict intimate image abuse. If Grok’s harmful outputs continue into May, X could face penalties under the Take It Down Act, which authorizes the Federal Trade Commission to intervene if platforms don’t quickly remove both real and AI-generated non-consensual intimate imagery.&lt;/p&gt;
&lt;p&gt;But whether US authorities will intervene any time soon remains unknown, as Musk is a close ally of the Trump administration. A spokesperson for the Justice Department told CNN that the department “takes AI-generated child sex abuse material extremely seriously and will aggressively prosecute any producer or possessor of CSAM.”&lt;/p&gt;
&lt;p&gt;“Laws are only as good as their enforcement,” Ruane told Ars. “You need law enforcement at the Federal Trade Commission or at the Department of Justice to be willing to go after these companies if they are in violation of the laws.”&lt;/p&gt;
&lt;p&gt;Child safety advocates seem alarmed by the sluggish response. “Technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children,” NCMEC’s spokesperson told Ars. “As AI continues to advance, protecting children must remain a clear and nonnegotiable priority.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/grok-assumes-users-seeking-images-of-underage-girls-have-good-intent/</guid><pubDate>Thu, 08 Jan 2026 18:50:46 +0000</pubDate></item><item><title>Decoding the Arctic to predict winter weather (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/decoding-arctic-to-predict-winter-weather-0108</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-Judah-Cohen-weather-map.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Every autumn, as the Northern Hemisphere moves toward winter, Judah Cohen starts to piece together a complex atmospheric puzzle. Cohen, a research scientist in MIT’s Department of Civil and Environmental Engineering (CEE), has spent decades studying how conditions in the Arctic set the course for winter weather throughout Europe, Asia, and North America. His research dates back to his postdoctoral work with Bacardi and Stockholm Water Foundations Professor Dara Entekhabi that looked at snow cover in the Siberian region and its connection with winter forecasting.&lt;/p&gt;&lt;p&gt;Cohen’s outlook for the 2025–26 winter highlights a season characterized by indicators emerging from the Arctic using a new generation of artificial intelligence tools that help develop the full atmospheric picture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking beyond the usual climate drivers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Winter forecasts rely heavily on El Niño–Southern Oscillation (ENSO) diagnostics, which are the tropical Pacific Ocean and atmosphere conditions that influence weather around the world. However, Cohen notes that ENSO is relatively weak this year.&lt;/p&gt;&lt;p&gt;“When ENSO is weak, that’s when climate indicators from the Arctic becomes especially important,” Cohen says.&lt;/p&gt;&lt;p&gt;Cohen monitors high-latitude diagnostics in his subseasonal forecasting, such as October snow cover in Siberia, early-season temperature changes, Arctic sea-ice extent, and the stability of the polar vortex. “These indicators can tell a surprisingly detailed story about the upcoming winter,” he says.&amp;nbsp;&lt;/p&gt;&lt;p&gt;One of Cohen’s most consistent data predictors is October’s weather in Siberia. This year, when the Northern Hemisphere experienced an unusually warm October, Siberia was colder than normal with an early snow fall. “Cold temperatures paired with early snow cover tend to strengthen the formation of cold air masses that can later spill into Europe and North America,” says Cohen — weather patterns that are historically linked to more frequent cold spells later in winter.&lt;/p&gt;&lt;p&gt;Warm ocean temperatures in the Barents–Kara Sea and an “easterly” phase of the quasi-biennial oscillation also suggest a potentially weaker polar vortex in early winter. When this disturbance couples with surface conditions in December, it leads to lower-than-normal temperatures across parts of Eurasia and North America earlier in the season.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI subseasonal forecasting&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While AI weather models have made impressive strides showcasing in short-range (one-to–10-day) forecasts, these advances have not yet applied to longer periods. The subseasonal prediction covering two to six weeks remains one of the toughest challenges in the field.&lt;/p&gt;&lt;p&gt;That gap is why this year could be a turning point for subseasonal weather forecasting. A team of researchers working with Cohen won first place for the fall season in the 2025&amp;nbsp;AI WeatherQuest&amp;nbsp;subseasonal forecasting competition, held by the European Centre for Medium-Range Weather Forecasts (ECMWF). The challenge evaluates how well AI models capture temperature patterns over multiple weeks, where forecasting has been historically limited.&lt;/p&gt;&lt;p&gt;The winning model combined machine-learning pattern recognition with the same Arctic diagnostics Cohen has refined over decades. The system demonstrated significant gains in multi-week forecasting, surpassing leading AI and statistical baselines.&lt;/p&gt;&lt;p&gt;“If this level of performance holds across multiple seasons, it could represent a real step forward for subseasonal prediction,” Cohen says&lt;/p&gt;&lt;p&gt;The model also detected a potential cold surge in mid-December for the U.S. East Coast much earlier than usual, weeks before such signals typically arise. The forecast was widely publicized in the media in real-time. If validated, Cohen explains, it would show how combining Arctic indicators with AI could extend the lead time for predicting impactful weather.&lt;/p&gt;&lt;p&gt;“Flagging a potential extreme event three to four weeks in advance would be a watershed moment,” he adds. “It would give utilities, transportation systems, and public agencies more time to prepare.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What this winter may hold&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cohen’s model shows a greater chance of colder-than-normal conditions across parts of Eurasia and central North America later in the winter, with the strongest anomalies likely mid-season.&lt;/p&gt;&lt;p&gt;“We’re still early, and patterns can shift,” Cohen says. “But the ingredients for a colder winter pattern are there.”&lt;/p&gt;&lt;p&gt;As Arctic warming speeds up, its impact on winter behavior is becoming more evident, making it increasingly important to understand these connections for energy planning, transportation, and public safety. Cohen’s work shows that the Arctic holds untapped subseasonal forecasting power, and AI may help unlock it for time frames that have long been challenging for traditional models.&lt;/p&gt;&lt;p&gt;In November, Cohen even appeared as a clue in &lt;em&gt;The Washington Post&lt;/em&gt; crossword, a small sign of how widely his research has entered public conversations about winter weather.&lt;/p&gt;&lt;p&gt;“For me, the Arctic has always been the place to watch,” he says. “Now AI is giving us new ways to interpret its signals.”&lt;/p&gt;&lt;p&gt;Cohen will continue to update his outlook throughout the season on his blog.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-Judah-Cohen-weather-map.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Every autumn, as the Northern Hemisphere moves toward winter, Judah Cohen starts to piece together a complex atmospheric puzzle. Cohen, a research scientist in MIT’s Department of Civil and Environmental Engineering (CEE), has spent decades studying how conditions in the Arctic set the course for winter weather throughout Europe, Asia, and North America. His research dates back to his postdoctoral work with Bacardi and Stockholm Water Foundations Professor Dara Entekhabi that looked at snow cover in the Siberian region and its connection with winter forecasting.&lt;/p&gt;&lt;p&gt;Cohen’s outlook for the 2025–26 winter highlights a season characterized by indicators emerging from the Arctic using a new generation of artificial intelligence tools that help develop the full atmospheric picture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking beyond the usual climate drivers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Winter forecasts rely heavily on El Niño–Southern Oscillation (ENSO) diagnostics, which are the tropical Pacific Ocean and atmosphere conditions that influence weather around the world. However, Cohen notes that ENSO is relatively weak this year.&lt;/p&gt;&lt;p&gt;“When ENSO is weak, that’s when climate indicators from the Arctic becomes especially important,” Cohen says.&lt;/p&gt;&lt;p&gt;Cohen monitors high-latitude diagnostics in his subseasonal forecasting, such as October snow cover in Siberia, early-season temperature changes, Arctic sea-ice extent, and the stability of the polar vortex. “These indicators can tell a surprisingly detailed story about the upcoming winter,” he says.&amp;nbsp;&lt;/p&gt;&lt;p&gt;One of Cohen’s most consistent data predictors is October’s weather in Siberia. This year, when the Northern Hemisphere experienced an unusually warm October, Siberia was colder than normal with an early snow fall. “Cold temperatures paired with early snow cover tend to strengthen the formation of cold air masses that can later spill into Europe and North America,” says Cohen — weather patterns that are historically linked to more frequent cold spells later in winter.&lt;/p&gt;&lt;p&gt;Warm ocean temperatures in the Barents–Kara Sea and an “easterly” phase of the quasi-biennial oscillation also suggest a potentially weaker polar vortex in early winter. When this disturbance couples with surface conditions in December, it leads to lower-than-normal temperatures across parts of Eurasia and North America earlier in the season.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI subseasonal forecasting&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While AI weather models have made impressive strides showcasing in short-range (one-to–10-day) forecasts, these advances have not yet applied to longer periods. The subseasonal prediction covering two to six weeks remains one of the toughest challenges in the field.&lt;/p&gt;&lt;p&gt;That gap is why this year could be a turning point for subseasonal weather forecasting. A team of researchers working with Cohen won first place for the fall season in the 2025&amp;nbsp;AI WeatherQuest&amp;nbsp;subseasonal forecasting competition, held by the European Centre for Medium-Range Weather Forecasts (ECMWF). The challenge evaluates how well AI models capture temperature patterns over multiple weeks, where forecasting has been historically limited.&lt;/p&gt;&lt;p&gt;The winning model combined machine-learning pattern recognition with the same Arctic diagnostics Cohen has refined over decades. The system demonstrated significant gains in multi-week forecasting, surpassing leading AI and statistical baselines.&lt;/p&gt;&lt;p&gt;“If this level of performance holds across multiple seasons, it could represent a real step forward for subseasonal prediction,” Cohen says&lt;/p&gt;&lt;p&gt;The model also detected a potential cold surge in mid-December for the U.S. East Coast much earlier than usual, weeks before such signals typically arise. The forecast was widely publicized in the media in real-time. If validated, Cohen explains, it would show how combining Arctic indicators with AI could extend the lead time for predicting impactful weather.&lt;/p&gt;&lt;p&gt;“Flagging a potential extreme event three to four weeks in advance would be a watershed moment,” he adds. “It would give utilities, transportation systems, and public agencies more time to prepare.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What this winter may hold&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cohen’s model shows a greater chance of colder-than-normal conditions across parts of Eurasia and central North America later in the winter, with the strongest anomalies likely mid-season.&lt;/p&gt;&lt;p&gt;“We’re still early, and patterns can shift,” Cohen says. “But the ingredients for a colder winter pattern are there.”&lt;/p&gt;&lt;p&gt;As Arctic warming speeds up, its impact on winter behavior is becoming more evident, making it increasingly important to understand these connections for energy planning, transportation, and public safety. Cohen’s work shows that the Arctic holds untapped subseasonal forecasting power, and AI may help unlock it for time frames that have long been challenging for traditional models.&lt;/p&gt;&lt;p&gt;In November, Cohen even appeared as a clue in &lt;em&gt;The Washington Post&lt;/em&gt; crossword, a small sign of how widely his research has entered public conversations about winter weather.&lt;/p&gt;&lt;p&gt;“For me, the Arctic has always been the place to watch,” he says. “Now AI is giving us new ways to interpret its signals.”&lt;/p&gt;&lt;p&gt;Cohen will continue to update his outlook throughout the season on his blog.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/decoding-arctic-to-predict-winter-weather-0108</guid><pubDate>Thu, 08 Jan 2026 21:55:00 +0000</pubDate></item><item><title>Governments grapple with the flood of non-consensual nudity on X (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/governments-grapple-with-the-flood-of-non-consensual-nudity-on-x/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the past two weeks, X has been flooded with AI-manipulated nude images, created by the Grok AI chatbot. An alarming range of women have been affected by the non-consensual nudes, including prominent models and actresses, as well as news figures, crime victims, and even world leaders.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A December 31 research paper from Copyleaks estimated roughly one image was being posted each minute, but later tests found far more. A sample gathered from January 5-6 found 6,700 per hour over the 24-hour period.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while public figures from around the world have decried the choice to release the model without safeguards, there are few clear mechanisms for regulators hoping to rein in Elon Musk’s new image-manipulating system. The result has become a painful lesson in the limits of tech regulation — and a forward-looking challenge for regulators hoping to make a mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the most aggressive action has come from the European Commission, which on Thursday ordered xAI to retain all documents related to its Grok chatbot. The move doesn’t necessarily mean the commission has opened up a new investigation, but it’s a common precursor to such action. It’s particularly ominous given recent reporting from CNN that suggests Elon Musk may have personally intervened to prevent safeguards from being placed on what images could be generated by Grok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether X has made any technical changes to the Grok model, although the public media tab for Grok’s X account has been removed. In a statement, the company specifically denounced the use of AI tools to produce child sexual imagery. “Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content,” the X Safety account posted on January 3, echoing a previous tweet by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, regulators around the world have issued stern warnings. The United Kingdom’s Ofcom issued a statement on Monday, saying it was in touch with xAI and “will undertake a swift assessment to determine whether there are potential compliance issues that warrant investigation.” In a radio interview on Thursday, U.K. Prime Minister Keir Starmer called the phenomenon “disgraceful” and “disgusting,” saying “Ofcom has our full support to take action in relation to this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on LinkedIn, Australian eSafety Commissioner Julie Inman-Grant said her office had received a doubling in complaints related to Grok since late 2025. But Inman-Grant stopped short of taking action against xAI, saying only, “We will use the range of regulatory tools at our disposal to investigate and take appropriate action.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By far the largest market to threaten action is India, where Grok was the subject of a formal complaint from a member of Parliament. On January, India’s communications regulator MeitY ordered X to address the issue and submit an “action-taken” report within 72 hours — a deadline that was subsequently extended by 48 hours. While a report was submitted to the regulator on January 7, it’s unclear whether MeitY will be satisfied with the response. If not, X could lose its safe harbor status in India, a potentially serious limitation on its ability to operate within the country.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the past two weeks, X has been flooded with AI-manipulated nude images, created by the Grok AI chatbot. An alarming range of women have been affected by the non-consensual nudes, including prominent models and actresses, as well as news figures, crime victims, and even world leaders.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A December 31 research paper from Copyleaks estimated roughly one image was being posted each minute, but later tests found far more. A sample gathered from January 5-6 found 6,700 per hour over the 24-hour period.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while public figures from around the world have decried the choice to release the model without safeguards, there are few clear mechanisms for regulators hoping to rein in Elon Musk’s new image-manipulating system. The result has become a painful lesson in the limits of tech regulation — and a forward-looking challenge for regulators hoping to make a mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the most aggressive action has come from the European Commission, which on Thursday ordered xAI to retain all documents related to its Grok chatbot. The move doesn’t necessarily mean the commission has opened up a new investigation, but it’s a common precursor to such action. It’s particularly ominous given recent reporting from CNN that suggests Elon Musk may have personally intervened to prevent safeguards from being placed on what images could be generated by Grok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether X has made any technical changes to the Grok model, although the public media tab for Grok’s X account has been removed. In a statement, the company specifically denounced the use of AI tools to produce child sexual imagery. “Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content,” the X Safety account posted on January 3, echoing a previous tweet by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, regulators around the world have issued stern warnings. The United Kingdom’s Ofcom issued a statement on Monday, saying it was in touch with xAI and “will undertake a swift assessment to determine whether there are potential compliance issues that warrant investigation.” In a radio interview on Thursday, U.K. Prime Minister Keir Starmer called the phenomenon “disgraceful” and “disgusting,” saying “Ofcom has our full support to take action in relation to this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on LinkedIn, Australian eSafety Commissioner Julie Inman-Grant said her office had received a doubling in complaints related to Grok since late 2025. But Inman-Grant stopped short of taking action against xAI, saying only, “We will use the range of regulatory tools at our disposal to investigate and take appropriate action.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By far the largest market to threaten action is India, where Grok was the subject of a formal complaint from a member of Parliament. On January, India’s communications regulator MeitY ordered X to address the issue and submit an “action-taken” report within 72 hours — a deadline that was subsequently extended by 48 hours. While a report was submitted to the regulator on January 7, it’s unclear whether MeitY will be satisfied with the response. If not, X could lose its safe harbor status in India, a potentially serious limitation on its ability to operate within the country.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/governments-grapple-with-the-flood-of-non-consensual-nudity-on-x/</guid><pubDate>Thu, 08 Jan 2026 22:08:58 +0000</pubDate></item><item><title>CES 2026: Everything revealed, from Nvidia’s debuts to AMD’s new chips to Razer’s AI oddities (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/ces-2026-everything-revealed-from-nvidias-debuts-to-amds-new-chips-to-razers-ai-oddities/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CES 2026&amp;nbsp;is in full swing in Las Vegas, with the show floor open to the public after a packed couple of days&amp;nbsp;occupied by&amp;nbsp;press conferences from the likes of Nvidia, Sony, and AMD&amp;nbsp;and previews from Sunday’s Unveiled event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As has been the case for the past two years at CES, AI is at the forefront of many companies’ messaging, though the hardware&amp;nbsp;upgrades and oddities that have long defined the annual event still have their place on the show floor and in adjacent announcements. We’ll&amp;nbsp;be collecting the biggest reveals and surprises here, though you can still catch&amp;nbsp;the spur-of-the-moment reactions and thoughts from our team on the ground&amp;nbsp;via our live blog right here.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;dive right in, starting with some of Monday’s biggest players.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-reveals-ai-model-for-autonomous-vehicles-showcases-rubin-architecture"&gt;Nvidia reveals AI model for autonomous vehicles, showcases Rubin architecture&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia CEO Jensen Huang delivered an expectedly lengthy presentation at CES, taking a victory lap for the company’s AI-driven successes,&amp;nbsp;setting the stage for 2026, and yes,&amp;nbsp;hanging out with some robots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Rubin computing&amp;nbsp;architecture, which has been developed to meet the increasing computation demands that AI adoption creates, is&amp;nbsp;set to begin replacing Blackwell architecture in the second half of this year. It comes with speed and storage upgrades, but our&amp;nbsp;senior AI&amp;nbsp;editor&amp;nbsp;Russell Brandom goes into the nitty-gritty of what distinguishes Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nvidia continued its push to bring the AI revolution into the physical world,&amp;nbsp;showcasing its Alpamayo family of open source AI models&amp;nbsp;and tools that will be used by autonomous vehicles this year.&amp;nbsp;That approach, as senior reporter Rebecca Bellan notes, mirrors the company’s broader efforts to make its infrastructure the Android for generalist robots.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-amd-s-keynote-highlights-new-processors-and-partnerships-nbsp"&gt;AMD’s keynote highlights new processors and partnerships&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AMD chair and CEO Lisa Su delivered the first keynote of CES, with a presentation that featured partners, including OpenAI president Greg Brockman, AI legend Fei-Fei Li,&amp;nbsp;Luma AI CEO Amit Jain, and more.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the&amp;nbsp;partner&amp;nbsp;showcases, senior reporter Rebecca Szkutak&amp;nbsp;detailed AMD’s approach toward expanding the reach of AI through personal computers&amp;nbsp;using its Ryzen AI 400 Series processors.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-standout-oddities-of-ces"&gt;The standout oddities of CES&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;face it, by this point in the show the major announcements have been made, products have been showcased, and&amp;nbsp;it’s&amp;nbsp;time to eye some of the most brow-raising reveals from CES.&amp;nbsp;We started our list of what stood out to us as odd and noteworthy, but&amp;nbsp;we’re&amp;nbsp;open to more suggestions!&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-highlights-from-ces-breakout-sessions"&gt;Highlights from CES breakout sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;CES&amp;nbsp;isn’t&amp;nbsp;all hardware&amp;nbsp;showcases&amp;nbsp;and show floor attractions — there are plenty of&amp;nbsp;additional&amp;nbsp;industry panels and speakers drawing eyeballs. We&amp;nbsp;kept tabs on&amp;nbsp;a few notable highlights, ranging from&amp;nbsp;Palmer Luckey pushing retro aesthetics, to why the&amp;nbsp;“learn once, work forever” era may be over,&amp;nbsp;to previews of the new Silicon Valley-based series “The Audacity,”&amp;nbsp;to&amp;nbsp;the expansion of Roku’s $3 streaming service,&amp;nbsp;to All-In host Jason Calacanis putting a $25,000 bounty on an authentic Theranos device.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ford-s-ai-assistant-debuts"&gt;Ford’s AI assistant debuts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is launching its assistant in the company’s app before a targeted 2027 release in its vehicles, with hosting managed by Google Cloud and the assistant itself built using off-the-shelf LLMs. As&amp;nbsp;we noted in our coverage of the news, however, few details were offered around what drivers should expect from their experience with the&amp;nbsp;assistant.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-caterpillar-nvidia-partner-on-automated-construction-equipment"&gt;Caterpillar, Nvidia partner on automated construction equipment&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the ever-present push for AI’s impact on the physical world,&amp;nbsp;Caterpillar and Nvidia announced a pilot program, “Cat AI Assistant,” which was&amp;nbsp;demonstrated&amp;nbsp;at CES Wednesday.&amp;nbsp;This system, coming to one of Caterpillar’s excavator vehicles, is happening alongside another project to use Nvidia’s Omniverse simulation resources to help with construction project planning and execution.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-clicks-communicator"&gt;Hands-on with Clicks Communicator&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="display of Clicks smartphones" class="wp-image-3081105" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0669-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the buzziest reveals of the show is the debut phone from Clicks Technology, the $499 Communicator, which brings back BlackBerry vibes with its physical keyboard, plus a separate $79 slide-out physical keyboard that can be used with other devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Check out our full rundown from the show floor here, but the Communicator makes a good first impression, per Consumer Editor Sarah Perez:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our hands-on test, the phone felt good to hold — not too heavy or light, and was easy to grip. Gadway told me the company settled on the device’s final form after dozens of 3D-printed shapes. The winning design for the phone features a contoured back that makes it easy to pick up and hold.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The device’s screen is also somewhat elevated off the body, and its chin is curved up to create a recess that protects the keys when you place it face down.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-check-out-the-skylight-calendar-2"&gt;Check out the Skylight Calendar 2&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This family planning tool caught our eyes on the show floor, not just for its calendar and planning capabilities, but for its AI capabilities that are able to&amp;nbsp;sync&amp;nbsp;calendars from&amp;nbsp;different sources, create new to-dos based&amp;nbsp;off of&amp;nbsp;messages or photos, appointment reminders, and more.&amp;nbsp;Check out our full impressions here.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-boston-dynamics-and-google-partner-on-atlas-robots-nbsp"&gt;Boston Dynamics and Google partner on Atlas robots&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hyundai’s press conference focused on its robotics partnerships with Boston Dynamics, but the companies revealed that&amp;nbsp;they’re&amp;nbsp;working with Google’s AI research lab rather than competitors&amp;nbsp;to train and operate existing Atlas robots, as well as a new iteration of the humanoid robot that was shown onstage.&amp;nbsp;Transportation editor Kirsten Korosec has the full rundown.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Amazon’s AI-centric update with Alexa+ is getting the kind of push&amp;nbsp;you’d&amp;nbsp;expect at CES, with&amp;nbsp;the company launching Alexa.com for Early Access customers&amp;nbsp;looking to use the chatbot via their browsers, along with a similar, revamped bot-focused app. Consumer editor Sarah Perez has the details, along with news on&amp;nbsp;Amazon’s revamp to Fire TV and new&amp;nbsp;Artline TVs, which have their own Alexa+ push.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the Ring front, consumer reporter Ivan Mehta&amp;nbsp;runs through the many announcements, from fire alerts to an app store for third-party camera integration, and&amp;nbsp;more.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-razer-joins-the-ai-deluge-nbsp-with-project-ava-and-motoko-nbsp"&gt;Razer joins the AI deluge&amp;nbsp;with Project AVA and Motoko&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, Razer has been all about ridiculous hardware at CES,&amp;nbsp;from three-screen laptops&amp;nbsp;to&amp;nbsp;haptic gaming cushions&amp;nbsp;to&amp;nbsp;a mask that landed the company a federal fine. This year, its two attention-grabbing announcements were for Project&amp;nbsp;Motoko, which aims to function similarly to smart glasses, but&amp;nbsp;without&amp;nbsp;the glasses.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s Project AVA, which puts the avatar of an AI companion on your desk.&amp;nbsp;We’ll&amp;nbsp;let you watch the concept video for yourself.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-lego-smart-bricks-mark-the-company-s-first-ces-appearance-nbsp"&gt;Lego Smart Bricks mark the company’s first CES appearance&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lego joined CES for the first time to hold a behind-closed-doors showcase of its Smart Play System, which&amp;nbsp;includes&amp;nbsp;bricks, tiles, and Minifigures that can all interact with each other&amp;nbsp;and&amp;nbsp;play sounds, with both the debut sets having a Star Wars theme. Senior writer Amanda&amp;nbsp;Silberling&amp;nbsp;has all the details here.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CES 2026&amp;nbsp;is in full swing in Las Vegas, with the show floor open to the public after a packed couple of days&amp;nbsp;occupied by&amp;nbsp;press conferences from the likes of Nvidia, Sony, and AMD&amp;nbsp;and previews from Sunday’s Unveiled event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As has been the case for the past two years at CES, AI is at the forefront of many companies’ messaging, though the hardware&amp;nbsp;upgrades and oddities that have long defined the annual event still have their place on the show floor and in adjacent announcements. We’ll&amp;nbsp;be collecting the biggest reveals and surprises here, though you can still catch&amp;nbsp;the spur-of-the-moment reactions and thoughts from our team on the ground&amp;nbsp;via our live blog right here.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;dive right in, starting with some of Monday’s biggest players.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-reveals-ai-model-for-autonomous-vehicles-showcases-rubin-architecture"&gt;Nvidia reveals AI model for autonomous vehicles, showcases Rubin architecture&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia CEO Jensen Huang delivered an expectedly lengthy presentation at CES, taking a victory lap for the company’s AI-driven successes,&amp;nbsp;setting the stage for 2026, and yes,&amp;nbsp;hanging out with some robots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Rubin computing&amp;nbsp;architecture, which has been developed to meet the increasing computation demands that AI adoption creates, is&amp;nbsp;set to begin replacing Blackwell architecture in the second half of this year. It comes with speed and storage upgrades, but our&amp;nbsp;senior AI&amp;nbsp;editor&amp;nbsp;Russell Brandom goes into the nitty-gritty of what distinguishes Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nvidia continued its push to bring the AI revolution into the physical world,&amp;nbsp;showcasing its Alpamayo family of open source AI models&amp;nbsp;and tools that will be used by autonomous vehicles this year.&amp;nbsp;That approach, as senior reporter Rebecca Bellan notes, mirrors the company’s broader efforts to make its infrastructure the Android for generalist robots.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-amd-s-keynote-highlights-new-processors-and-partnerships-nbsp"&gt;AMD’s keynote highlights new processors and partnerships&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AMD chair and CEO Lisa Su delivered the first keynote of CES, with a presentation that featured partners, including OpenAI president Greg Brockman, AI legend Fei-Fei Li,&amp;nbsp;Luma AI CEO Amit Jain, and more.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the&amp;nbsp;partner&amp;nbsp;showcases, senior reporter Rebecca Szkutak&amp;nbsp;detailed AMD’s approach toward expanding the reach of AI through personal computers&amp;nbsp;using its Ryzen AI 400 Series processors.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-standout-oddities-of-ces"&gt;The standout oddities of CES&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;face it, by this point in the show the major announcements have been made, products have been showcased, and&amp;nbsp;it’s&amp;nbsp;time to eye some of the most brow-raising reveals from CES.&amp;nbsp;We started our list of what stood out to us as odd and noteworthy, but&amp;nbsp;we’re&amp;nbsp;open to more suggestions!&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-highlights-from-ces-breakout-sessions"&gt;Highlights from CES breakout sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;CES&amp;nbsp;isn’t&amp;nbsp;all hardware&amp;nbsp;showcases&amp;nbsp;and show floor attractions — there are plenty of&amp;nbsp;additional&amp;nbsp;industry panels and speakers drawing eyeballs. We&amp;nbsp;kept tabs on&amp;nbsp;a few notable highlights, ranging from&amp;nbsp;Palmer Luckey pushing retro aesthetics, to why the&amp;nbsp;“learn once, work forever” era may be over,&amp;nbsp;to previews of the new Silicon Valley-based series “The Audacity,”&amp;nbsp;to&amp;nbsp;the expansion of Roku’s $3 streaming service,&amp;nbsp;to All-In host Jason Calacanis putting a $25,000 bounty on an authentic Theranos device.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ford-s-ai-assistant-debuts"&gt;Ford’s AI assistant debuts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is launching its assistant in the company’s app before a targeted 2027 release in its vehicles, with hosting managed by Google Cloud and the assistant itself built using off-the-shelf LLMs. As&amp;nbsp;we noted in our coverage of the news, however, few details were offered around what drivers should expect from their experience with the&amp;nbsp;assistant.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-caterpillar-nvidia-partner-on-automated-construction-equipment"&gt;Caterpillar, Nvidia partner on automated construction equipment&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the ever-present push for AI’s impact on the physical world,&amp;nbsp;Caterpillar and Nvidia announced a pilot program, “Cat AI Assistant,” which was&amp;nbsp;demonstrated&amp;nbsp;at CES Wednesday.&amp;nbsp;This system, coming to one of Caterpillar’s excavator vehicles, is happening alongside another project to use Nvidia’s Omniverse simulation resources to help with construction project planning and execution.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-clicks-communicator"&gt;Hands-on with Clicks Communicator&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="display of Clicks smartphones" class="wp-image-3081105" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0669-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the buzziest reveals of the show is the debut phone from Clicks Technology, the $499 Communicator, which brings back BlackBerry vibes with its physical keyboard, plus a separate $79 slide-out physical keyboard that can be used with other devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Check out our full rundown from the show floor here, but the Communicator makes a good first impression, per Consumer Editor Sarah Perez:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our hands-on test, the phone felt good to hold — not too heavy or light, and was easy to grip. Gadway told me the company settled on the device’s final form after dozens of 3D-printed shapes. The winning design for the phone features a contoured back that makes it easy to pick up and hold.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The device’s screen is also somewhat elevated off the body, and its chin is curved up to create a recess that protects the keys when you place it face down.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-check-out-the-skylight-calendar-2"&gt;Check out the Skylight Calendar 2&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This family planning tool caught our eyes on the show floor, not just for its calendar and planning capabilities, but for its AI capabilities that are able to&amp;nbsp;sync&amp;nbsp;calendars from&amp;nbsp;different sources, create new to-dos based&amp;nbsp;off of&amp;nbsp;messages or photos, appointment reminders, and more.&amp;nbsp;Check out our full impressions here.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-boston-dynamics-and-google-partner-on-atlas-robots-nbsp"&gt;Boston Dynamics and Google partner on Atlas robots&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hyundai’s press conference focused on its robotics partnerships with Boston Dynamics, but the companies revealed that&amp;nbsp;they’re&amp;nbsp;working with Google’s AI research lab rather than competitors&amp;nbsp;to train and operate existing Atlas robots, as well as a new iteration of the humanoid robot that was shown onstage.&amp;nbsp;Transportation editor Kirsten Korosec has the full rundown.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Amazon’s AI-centric update with Alexa+ is getting the kind of push&amp;nbsp;you’d&amp;nbsp;expect at CES, with&amp;nbsp;the company launching Alexa.com for Early Access customers&amp;nbsp;looking to use the chatbot via their browsers, along with a similar, revamped bot-focused app. Consumer editor Sarah Perez has the details, along with news on&amp;nbsp;Amazon’s revamp to Fire TV and new&amp;nbsp;Artline TVs, which have their own Alexa+ push.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the Ring front, consumer reporter Ivan Mehta&amp;nbsp;runs through the many announcements, from fire alerts to an app store for third-party camera integration, and&amp;nbsp;more.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-razer-joins-the-ai-deluge-nbsp-with-project-ava-and-motoko-nbsp"&gt;Razer joins the AI deluge&amp;nbsp;with Project AVA and Motoko&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, Razer has been all about ridiculous hardware at CES,&amp;nbsp;from three-screen laptops&amp;nbsp;to&amp;nbsp;haptic gaming cushions&amp;nbsp;to&amp;nbsp;a mask that landed the company a federal fine. This year, its two attention-grabbing announcements were for Project&amp;nbsp;Motoko, which aims to function similarly to smart glasses, but&amp;nbsp;without&amp;nbsp;the glasses.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s Project AVA, which puts the avatar of an AI companion on your desk.&amp;nbsp;We’ll&amp;nbsp;let you watch the concept video for yourself.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-lego-smart-bricks-mark-the-company-s-first-ces-appearance-nbsp"&gt;Lego Smart Bricks mark the company’s first CES appearance&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lego joined CES for the first time to hold a behind-closed-doors showcase of its Smart Play System, which&amp;nbsp;includes&amp;nbsp;bricks, tiles, and Minifigures that can all interact with each other&amp;nbsp;and&amp;nbsp;play sounds, with both the debut sets having a Star Wars theme. Senior writer Amanda&amp;nbsp;Silberling&amp;nbsp;has all the details here.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/ces-2026-everything-revealed-from-nvidias-debuts-to-amds-new-chips-to-razers-ai-oddities/</guid><pubDate>Fri, 09 Jan 2026 00:35:00 +0000</pubDate></item><item><title>[NEW] 3 Questions: How AI could optimize the power grid (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/3-questions-how-ai-could-optimize-power-grid-0109</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202601/MIT_AI-Power-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Artificial intelligence has captured headlines recently for its&amp;nbsp;&lt;/em&gt;&lt;em&gt;rapidly growing energy demands&lt;/em&gt;&lt;em&gt;, and particularly the surging&amp;nbsp;&lt;/em&gt;&lt;em&gt;electricity usage of data centers&lt;/em&gt;&lt;em&gt; that enable the training and deployment of the latest generative AI models. But it’s not all bad news — some AI tools have the potential to reduce some forms of energy consumption and enable cleaner grids.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;One of the most promising applications is using AI to optimize the power grid, which would improve efficiency, increase resilience to extreme weather, and enable the integration of more renewable energy. To learn more,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with&amp;nbsp;&lt;/em&gt;&lt;em&gt;Priya Donti&lt;/em&gt;&lt;em&gt;, the Silverman Family Career Development Professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and a principal investigator at the Laboratory for Information and Decision Systems (LIDS), whose work focuses on applying machine learning to optimize the power grid.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why does the power grid need to be optimized in the first place?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We need to maintain an exact balance between the amount of power that is put into the grid and the amount that comes out at every moment in time. But on the demand side, we have some uncertainty. Power companies don’t ask customers to pre-register the amount of energy they are going to use ahead of time, so some estimation and prediction must be done.&lt;/p&gt;&lt;p&gt;Then, on the supply side, there is typically some variation in costs and fuel availability that grid managers need to be responsive to. That has become an even bigger issue because of the integration of energy from time-varying renewable sources, like solar and wind, where uncertainty in the weather can have a major impact on how much power is available. Then, at the same time, depending on how power is flowing in the grid, there is some power lost through resistive heat on the power lines. So, as a grid operator, how do you make sure all that is working all the time? That is where optimization comes in.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;How can AI be most useful in power grid optimization?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&amp;nbsp;&lt;/strong&gt;One way AI can be helpful is to use a combination of historical and real-time data to make more precise predictions about how much renewable energy will be available at a certain time. This could lead to a cleaner power grid by allowing us to handle and better utilize these resources.&lt;/p&gt;&lt;p&gt;AI could also help tackle the complex optimization problems that power grid operators must solve to balance supply and demand in a way that also reduces costs. These optimization problems are used to determine which power generators should produce power, how much they should produce, and when they should produce it, as well as when batteries should be charged and discharged, and whether we can leverage flexibility in power loads. These optimization problems are so computationally expensive that operators use approximations so they can solve them in a feasible amount of time. But these approximations are often wrong, and when we integrate more renewable energy into the grid, they are thrown off even farther. AI can help by providing more accurate approximations in a faster manner, which can be deployed in real-time to help grid operators responsively and proactively manage the grid.&lt;/p&gt;&lt;p&gt;AI could also be useful in the planning of next-generation power grids. Planning for power grids requires one to use huge simulation models, so AI can play a big role in running those models more efficiently. The technology can also help with predictive maintenance by detecting where anomalous behavior on the grid is likely to happen, reducing inefficiencies that come from outages. More broadly, AI could also be applied to accelerate experimentation aimed at creating better batteries, which would allow the integration of more energy from renewable sources into the grid.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;How should we think about the pros and cons of AI, from an energy sector perspective?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One important thing to remember is that AI refers to a heterogeneous set of technologies. There are different types and sizes of models that are used, and different ways that models are used. If you are using a model that is trained on a smaller amount of data with a smaller number of parameters, that is going to consume much less energy than a large, general-purpose model.&lt;/p&gt;&lt;p&gt;In the context of the energy sector, there are a lot of places where, if you use these application-specific AI models for the applications they are intended for, the cost-benefit tradeoff works out in your favor. In these cases, the applications are enabling benefits from a sustainability perspective — like incorporating more renewables into the grid and supporting decarbonization strategies.&lt;/p&gt;&lt;p&gt;Overall, it’s important to think about whether the types of investments we are making into AI are actually matched with the benefits we want from AI. On a societal level, I think the answer to that question right now is “no.” There is a lot of development and expansion of a particular subset of AI technologies, and these are not the technologies that will have the biggest benefits across energy and climate applications. I’m not saying these technologies are useless, but they are incredibly resource-intensive, while also not being responsible for the lion’s share of the benefits that could be felt in the energy sector.&lt;/p&gt;&lt;p&gt;I’m excited to develop AI algorithms that respect the physical constraints of the power grid so that we can credibly deploy them. This is a hard problem to solve. If an LLM says something that is slightly incorrect, as humans, we can usually correct for that in our heads. But if you make the same magnitude of a mistake when you are optimizing a power grid, that can cause a large-scale blackout. We need to build models differently, but this also provides an opportunity to benefit from our knowledge of how the physics of the power grid works.&lt;/p&gt;&lt;p&gt;And more broadly, I think it’s critical that those of us in the technical community put our efforts toward fostering a more democratized system of AI development and deployment, and that it’s done in a way that is aligned with the needs of on-the-ground applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202601/MIT_AI-Power-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Artificial intelligence has captured headlines recently for its&amp;nbsp;&lt;/em&gt;&lt;em&gt;rapidly growing energy demands&lt;/em&gt;&lt;em&gt;, and particularly the surging&amp;nbsp;&lt;/em&gt;&lt;em&gt;electricity usage of data centers&lt;/em&gt;&lt;em&gt; that enable the training and deployment of the latest generative AI models. But it’s not all bad news — some AI tools have the potential to reduce some forms of energy consumption and enable cleaner grids.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;One of the most promising applications is using AI to optimize the power grid, which would improve efficiency, increase resilience to extreme weather, and enable the integration of more renewable energy. To learn more,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with&amp;nbsp;&lt;/em&gt;&lt;em&gt;Priya Donti&lt;/em&gt;&lt;em&gt;, the Silverman Family Career Development Professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and a principal investigator at the Laboratory for Information and Decision Systems (LIDS), whose work focuses on applying machine learning to optimize the power grid.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why does the power grid need to be optimized in the first place?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We need to maintain an exact balance between the amount of power that is put into the grid and the amount that comes out at every moment in time. But on the demand side, we have some uncertainty. Power companies don’t ask customers to pre-register the amount of energy they are going to use ahead of time, so some estimation and prediction must be done.&lt;/p&gt;&lt;p&gt;Then, on the supply side, there is typically some variation in costs and fuel availability that grid managers need to be responsive to. That has become an even bigger issue because of the integration of energy from time-varying renewable sources, like solar and wind, where uncertainty in the weather can have a major impact on how much power is available. Then, at the same time, depending on how power is flowing in the grid, there is some power lost through resistive heat on the power lines. So, as a grid operator, how do you make sure all that is working all the time? That is where optimization comes in.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;How can AI be most useful in power grid optimization?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&amp;nbsp;&lt;/strong&gt;One way AI can be helpful is to use a combination of historical and real-time data to make more precise predictions about how much renewable energy will be available at a certain time. This could lead to a cleaner power grid by allowing us to handle and better utilize these resources.&lt;/p&gt;&lt;p&gt;AI could also help tackle the complex optimization problems that power grid operators must solve to balance supply and demand in a way that also reduces costs. These optimization problems are used to determine which power generators should produce power, how much they should produce, and when they should produce it, as well as when batteries should be charged and discharged, and whether we can leverage flexibility in power loads. These optimization problems are so computationally expensive that operators use approximations so they can solve them in a feasible amount of time. But these approximations are often wrong, and when we integrate more renewable energy into the grid, they are thrown off even farther. AI can help by providing more accurate approximations in a faster manner, which can be deployed in real-time to help grid operators responsively and proactively manage the grid.&lt;/p&gt;&lt;p&gt;AI could also be useful in the planning of next-generation power grids. Planning for power grids requires one to use huge simulation models, so AI can play a big role in running those models more efficiently. The technology can also help with predictive maintenance by detecting where anomalous behavior on the grid is likely to happen, reducing inefficiencies that come from outages. More broadly, AI could also be applied to accelerate experimentation aimed at creating better batteries, which would allow the integration of more energy from renewable sources into the grid.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;How should we think about the pros and cons of AI, from an energy sector perspective?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One important thing to remember is that AI refers to a heterogeneous set of technologies. There are different types and sizes of models that are used, and different ways that models are used. If you are using a model that is trained on a smaller amount of data with a smaller number of parameters, that is going to consume much less energy than a large, general-purpose model.&lt;/p&gt;&lt;p&gt;In the context of the energy sector, there are a lot of places where, if you use these application-specific AI models for the applications they are intended for, the cost-benefit tradeoff works out in your favor. In these cases, the applications are enabling benefits from a sustainability perspective — like incorporating more renewables into the grid and supporting decarbonization strategies.&lt;/p&gt;&lt;p&gt;Overall, it’s important to think about whether the types of investments we are making into AI are actually matched with the benefits we want from AI. On a societal level, I think the answer to that question right now is “no.” There is a lot of development and expansion of a particular subset of AI technologies, and these are not the technologies that will have the biggest benefits across energy and climate applications. I’m not saying these technologies are useless, but they are incredibly resource-intensive, while also not being responsible for the lion’s share of the benefits that could be felt in the energy sector.&lt;/p&gt;&lt;p&gt;I’m excited to develop AI algorithms that respect the physical constraints of the power grid so that we can credibly deploy them. This is a hard problem to solve. If an LLM says something that is slightly incorrect, as humans, we can usually correct for that in our heads. But if you make the same magnitude of a mistake when you are optimizing a power grid, that can cause a large-scale blackout. We need to build models differently, but this also provides an opportunity to benefit from our knowledge of how the physics of the power grid works.&lt;/p&gt;&lt;p&gt;And more broadly, I think it’s critical that those of us in the technical community put our efforts toward fostering a more democratized system of AI development and deployment, and that it’s done in a way that is aligned with the needs of on-the-ground applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/3-questions-how-ai-could-optimize-power-grid-0109</guid><pubDate>Fri, 09 Jan 2026 05:00:00 +0000</pubDate></item></channel></rss>