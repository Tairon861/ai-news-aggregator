<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 08 Aug 2025 02:00:30 +0000</lastBuildDate><item><title>Truth Social’s AI search is powered by Perplexity, but the platform can set limits on sources (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/truth-socials-ai-search-is-powered-by-perplexity-but-the-platform-can-set-limits-on-sources/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/truth-social-trump.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is powering a new AI-powered search engine on Truth Social, President Donald Trump’s social media platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search engine, dubbed Truth Search AI, is already available on the web version of Truth Social, with public Beta testing on its iOS and Android apps planned for “the near future.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump Media said in a press release that Perplexity’s tech provides “direct, contextually accurate answers with transparent citations” which will help Truth Social “exponentially increase the amount of information available” to users. Nonetheless, the social media platform maintains control over which sources of information the AI search engine draws from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social is using the Perplexity Sonar API, which promises to query the web to retrieve current and verified information — even if that information is scraped from websites that block Perplexity’s crawlers — and supports structured output so users can define the format in which they’d like to see the search engine’s responses.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jesse Dwyer, a Perplexity spokesperson, told TechCrunch that the Sonar API will be accurate to whatever sources Truth Social limits it to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have no visibility or control over that,” Dwyer said. “Similar to you using the API inside of your own company or if you were an academic researcher and wanted to use it to search your own data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Trump Media to learn more about whether Truth Search AI will have access to the entire web, whether it will prioritize certain sources over others, and whether the AI will be directed to respond favorably about the president and current administration and unfavorably toward Democrats.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To assess which sources the searchbot would cite, Axios&amp;nbsp;asked it a bunch of questions — like “What happened on January 6, 2021?” and “Why was Donald Trump impeached?” In all the responses, FoxNews.com&amp;nbsp;was either the most common or the only listed source of information. Others included&amp;nbsp;FoxBusiness.com, The Washington Times, or Epoch Times, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast, Perplexity’s public search engine returns a wider variety of sources, including Wikipedia, Reddit, YouTube, NPR, and Politico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social plans to refine and expand the search function “based on user feedback as we implement a wide range of additional enhancements to the platform,”&amp;nbsp;said Devin Nunes, CEO of Trump Media and a former California congressman, in the statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Dmitry Shevelenko, Perplexity’s chief business officer, also noted in the statement that Perplexity’s AI delivers answers with “transparent citations that allow anyone to dig deeper.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In late July, alongside his AI Action Plan, Trump published an executive order targeting “biased AI,” or models that aren’t “ideologically neutral.” The order specifically referred to information about race or sex, unconscious bias, systemic racism, and other ideas thrown into the diversity, equity, and inclusion (DEI) bucket as “pervasive and destructive” ideology that can “distort the quality and accuracy of the output.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Search AI comes in the same week that top AI firms like OpenAI, Anthropic, and Google were added to a list of approved vendors that can sell their services to civilian federal agencies. OpenAI on Wednesday reached a deal with the U.S. government’s central purchasing arm to sell ChatGPT Enterprise to agencies for just $1 per year.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/truth-social-trump.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is powering a new AI-powered search engine on Truth Social, President Donald Trump’s social media platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search engine, dubbed Truth Search AI, is already available on the web version of Truth Social, with public Beta testing on its iOS and Android apps planned for “the near future.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump Media said in a press release that Perplexity’s tech provides “direct, contextually accurate answers with transparent citations” which will help Truth Social “exponentially increase the amount of information available” to users. Nonetheless, the social media platform maintains control over which sources of information the AI search engine draws from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social is using the Perplexity Sonar API, which promises to query the web to retrieve current and verified information — even if that information is scraped from websites that block Perplexity’s crawlers — and supports structured output so users can define the format in which they’d like to see the search engine’s responses.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jesse Dwyer, a Perplexity spokesperson, told TechCrunch that the Sonar API will be accurate to whatever sources Truth Social limits it to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have no visibility or control over that,” Dwyer said. “Similar to you using the API inside of your own company or if you were an academic researcher and wanted to use it to search your own data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Trump Media to learn more about whether Truth Search AI will have access to the entire web, whether it will prioritize certain sources over others, and whether the AI will be directed to respond favorably about the president and current administration and unfavorably toward Democrats.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To assess which sources the searchbot would cite, Axios&amp;nbsp;asked it a bunch of questions — like “What happened on January 6, 2021?” and “Why was Donald Trump impeached?” In all the responses, FoxNews.com&amp;nbsp;was either the most common or the only listed source of information. Others included&amp;nbsp;FoxBusiness.com, The Washington Times, or Epoch Times, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast, Perplexity’s public search engine returns a wider variety of sources, including Wikipedia, Reddit, YouTube, NPR, and Politico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social plans to refine and expand the search function “based on user feedback as we implement a wide range of additional enhancements to the platform,”&amp;nbsp;said Devin Nunes, CEO of Trump Media and a former California congressman, in the statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Dmitry Shevelenko, Perplexity’s chief business officer, also noted in the statement that Perplexity’s AI delivers answers with “transparent citations that allow anyone to dig deeper.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In late July, alongside his AI Action Plan, Trump published an executive order targeting “biased AI,” or models that aren’t “ideologically neutral.” The order specifically referred to information about race or sex, unconscious bias, systemic racism, and other ideas thrown into the diversity, equity, and inclusion (DEI) bucket as “pervasive and destructive” ideology that can “distort the quality and accuracy of the output.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Search AI comes in the same week that top AI firms like OpenAI, Anthropic, and Google were added to a list of approved vendors that can sell their services to civilian federal agencies. OpenAI on Wednesday reached a deal with the U.S. government’s central purchasing arm to sell ChatGPT Enterprise to agencies for just $1 per year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/truth-socials-ai-search-is-powered-by-perplexity-but-the-platform-can-set-limits-on-sources/</guid><pubDate>Thu, 07 Aug 2025 14:18:23 +0000</pubDate></item><item><title>Elon Musk says X plans to introduce ads in Grok’s responses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/elon-musk-says-x-plans-to-introduce-ads-in-groks-responses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;X owner Elon Musk told advertisers in a live discussion on Wednesday that the platform plans to introduce ads in Grok’s responses, as reported by the Financial Times. The move would help power X’s struggling ads business following the departure of former CEO Linda Yaccarino. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our focus thus far has just been on making Grok the smartest, most accurate AI in the world and I think we’ve largely succeeded in that,” Musk said during the broadcast. “So we’ll turn our attention to how do we pay for those expensive GPUs.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk told advertisers that X would allow marketers to pay to appear in suggestions from the AI chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If a user’s trying to solve a problem [by asking Grok], then advertising the specific solution would be ideal at that point,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The billionaire entrepreneur also plans to use technology from xAI, his AI startup, to improve the targeting of ads on the social network. xAI acquired X earlier this year for $45 billion. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;X owner Elon Musk told advertisers in a live discussion on Wednesday that the platform plans to introduce ads in Grok’s responses, as reported by the Financial Times. The move would help power X’s struggling ads business following the departure of former CEO Linda Yaccarino. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our focus thus far has just been on making Grok the smartest, most accurate AI in the world and I think we’ve largely succeeded in that,” Musk said during the broadcast. “So we’ll turn our attention to how do we pay for those expensive GPUs.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk told advertisers that X would allow marketers to pay to appear in suggestions from the AI chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If a user’s trying to solve a problem [by asking Grok], then advertising the specific solution would be ideal at that point,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The billionaire entrepreneur also plans to use technology from xAI, his AI startup, to improve the targeting of ads on the social network. xAI acquired X earlier this year for $45 billion. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/elon-musk-says-x-plans-to-introduce-ads-in-groks-responses/</guid><pubDate>Thu, 07 Aug 2025 14:35:53 +0000</pubDate></item><item><title>How AI is helping advance the science of bioacoustics to save endangered species (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/</link><description>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-08-07"&gt;7 August 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Perch Team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="Two Hawaiian honeycreepers on a branch. These honeycreepers are small birds endemic to Hawai'i with red bodies and black wings." class="picture__image" height="603" src="https://lh3.googleusercontent.com/JYIFJcnN8vY29QEb-1MAbLKzOWCU4TIAbJrLHxmw5kBX6fIRHJhZjSgDcdfEWG9JZHOb43ojZ2zH1u_r1TjKnnRv1V0gr8wm0qmu4THC6clm0zvEYoA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian honeycreepers to coral reefs.&lt;/p&gt;&lt;p&gt;One of the ways scientists protect the health of our planet’s wild ecosystems is by using microphones (or underwater hydrophones) to collect vast amounts of audio dense with vocalizations from birds, frogs, insects, whales, fish and more. These recordings can tell us a lot about the animals present in a given area, along with other clues about the health of that ecosystem. Making sense of so much data, however, remains a massive undertaking.&lt;/p&gt;&lt;p&gt;Today, we are releasing an update to Perch, our AI model designed to help conservationists analyze bioacoustic data. This new model has better state-of-the-art off-the-shelf bird species predictions than the previous model. It can better adapt to new environments, particularly underwater ones like coral reefs. It’s trained on a wider range of animals, including mammals, amphibians and anthropogenic noise — nearly twice as much data in all, from public sources like Xeno-Canto and iNaturalist. It can disentangle complex acoustic scenes over thousands or even millions of hours of audio data. And it’s versatile, able to answer many different kinds of questions, from “how many babies are being born” to “how many individual animals are present in a given area.”&lt;/p&gt;&lt;p&gt;In order to help scientists protect our planet’s ecosystems, we’re open sourcing this new version of Perch and making it available on Kaggle.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-26cd95fe-71a7-4e6c-ae3c-8844bf189859"&gt;
    &lt;p&gt;Perch not only recognizes the sound of bird species. Our new model was trained on a wider range of animals including mammals, amphibians and anthropogenic noise.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Success Stories: Perch in the Field&lt;/h2&gt;&lt;p&gt;Since it was first launched in 2023, the initial version of Perch has already been downloaded over 250,000 times and its open-source solutions are now well-integrated into tools for working biologists. For example, Perch’s vector search library is now part of Cornell's widely-used BirdNet Analyzer.&lt;/p&gt;&lt;p&gt;In addition, Perch is helping BirdLife Australia and the Australian Acoustic Observatory build classifiers for a number of unique Australian species. For example, our tools enabled the discovery of a new population of the elusive Plains Wanderer.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;“This is an incredible discovery – acoustic monitoring like this will help shape the future of many endangered bird species.”&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Paul Roe, Dean Research, James Cook University, Australia&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Recent work has also found that the earlier version of Perch can be used to identify individual birds and track bird abundance, potentially reducing the need for catch-and-release studies to monitor populations.&lt;/p&gt;&lt;p&gt;Finally, biologists from the LOHE Bioacoustics Lab at the University of Hawaiʻi have used it to monitor and protect populations of honeycreepers, which are important to Hawaiian mythology and face extinction from the threat of avian malaria spread by non-native mosquitoes. Perch helped the LOHE Lab find honeycreeper sounds nearly 50x faster than their usual methods, enabling them to monitor more species of honeycreeper over greater areas. We expect the new model will further accelerate these efforts.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--large"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Untangling the Planet's Playlist&lt;/h2&gt;&lt;p&gt;The Perch model can predict which species are present in a recording, but that's only part of the story: We also provide open-source tools that allow scientists to quickly build new classifiers starting from a single example and monitor species for which there is scarce training data or for very specific sounds like juvenile calls. Given one example of a sound, vector search with Perch surfaces the most similar sounds in a dataset. A local expert can then mark the search results as relevant or irrelevant to train a classifier.&lt;/p&gt;&lt;p&gt;Together, this combination of vector search and active learning with a strong embedding model is called agile modeling&lt;strong&gt;&lt;i&gt;.&lt;/i&gt;&lt;/strong&gt; Our recent paper–"The Search for Squawk: Agile Modeling in Bioacoustics"–shows that this method works across birds and coral reefs, allowing the creation of high quality classifiers in under an hour.&lt;/p&gt;&lt;h2&gt;Looking ahead: the future of bioacoustics&lt;/h2&gt;&lt;p&gt;Together, our models and methods are helping maximize the impact of conservation efforts, leaving more time and resources for meaningful, on-the-ground work. From the forests of Hawaiʻi to the reefs of the ocean, the Perch project showcases the profound impact we can have when we apply our technical expertise to the world's most pressing challenges. Every classifier built and every hour of data analyzed brings us closer to a world where the soundtrack of our planet is one of rich, thriving biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This research was developed by the Perch team: Bart van Merriënboer, Jenny Hamer, Vincent Dumoulin, Lauren Harrell, and Tom Denton, and Otilia Stretcu from Google Research. We also thank our collaborators Amanda Navine and Pat Hart at the University of Hawaiʻi, and Holger Klinck, Stefan Kahl and the BirdNet team at the Cornell Lab of Ornithology. And all our friends and collaborators whom we would have written about in this blog post if only we had another thousand words.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</description><content:encoded>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-08-07"&gt;7 August 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Perch Team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="Two Hawaiian honeycreepers on a branch. These honeycreepers are small birds endemic to Hawai'i with red bodies and black wings." class="picture__image" height="603" src="https://lh3.googleusercontent.com/JYIFJcnN8vY29QEb-1MAbLKzOWCU4TIAbJrLHxmw5kBX6fIRHJhZjSgDcdfEWG9JZHOb43ojZ2zH1u_r1TjKnnRv1V0gr8wm0qmu4THC6clm0zvEYoA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian honeycreepers to coral reefs.&lt;/p&gt;&lt;p&gt;One of the ways scientists protect the health of our planet’s wild ecosystems is by using microphones (or underwater hydrophones) to collect vast amounts of audio dense with vocalizations from birds, frogs, insects, whales, fish and more. These recordings can tell us a lot about the animals present in a given area, along with other clues about the health of that ecosystem. Making sense of so much data, however, remains a massive undertaking.&lt;/p&gt;&lt;p&gt;Today, we are releasing an update to Perch, our AI model designed to help conservationists analyze bioacoustic data. This new model has better state-of-the-art off-the-shelf bird species predictions than the previous model. It can better adapt to new environments, particularly underwater ones like coral reefs. It’s trained on a wider range of animals, including mammals, amphibians and anthropogenic noise — nearly twice as much data in all, from public sources like Xeno-Canto and iNaturalist. It can disentangle complex acoustic scenes over thousands or even millions of hours of audio data. And it’s versatile, able to answer many different kinds of questions, from “how many babies are being born” to “how many individual animals are present in a given area.”&lt;/p&gt;&lt;p&gt;In order to help scientists protect our planet’s ecosystems, we’re open sourcing this new version of Perch and making it available on Kaggle.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-26cd95fe-71a7-4e6c-ae3c-8844bf189859"&gt;
    &lt;p&gt;Perch not only recognizes the sound of bird species. Our new model was trained on a wider range of animals including mammals, amphibians and anthropogenic noise.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Success Stories: Perch in the Field&lt;/h2&gt;&lt;p&gt;Since it was first launched in 2023, the initial version of Perch has already been downloaded over 250,000 times and its open-source solutions are now well-integrated into tools for working biologists. For example, Perch’s vector search library is now part of Cornell's widely-used BirdNet Analyzer.&lt;/p&gt;&lt;p&gt;In addition, Perch is helping BirdLife Australia and the Australian Acoustic Observatory build classifiers for a number of unique Australian species. For example, our tools enabled the discovery of a new population of the elusive Plains Wanderer.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;“This is an incredible discovery – acoustic monitoring like this will help shape the future of many endangered bird species.”&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Paul Roe, Dean Research, James Cook University, Australia&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Recent work has also found that the earlier version of Perch can be used to identify individual birds and track bird abundance, potentially reducing the need for catch-and-release studies to monitor populations.&lt;/p&gt;&lt;p&gt;Finally, biologists from the LOHE Bioacoustics Lab at the University of Hawaiʻi have used it to monitor and protect populations of honeycreepers, which are important to Hawaiian mythology and face extinction from the threat of avian malaria spread by non-native mosquitoes. Perch helped the LOHE Lab find honeycreeper sounds nearly 50x faster than their usual methods, enabling them to monitor more species of honeycreeper over greater areas. We expect the new model will further accelerate these efforts.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--large"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Untangling the Planet's Playlist&lt;/h2&gt;&lt;p&gt;The Perch model can predict which species are present in a recording, but that's only part of the story: We also provide open-source tools that allow scientists to quickly build new classifiers starting from a single example and monitor species for which there is scarce training data or for very specific sounds like juvenile calls. Given one example of a sound, vector search with Perch surfaces the most similar sounds in a dataset. A local expert can then mark the search results as relevant or irrelevant to train a classifier.&lt;/p&gt;&lt;p&gt;Together, this combination of vector search and active learning with a strong embedding model is called agile modeling&lt;strong&gt;&lt;i&gt;.&lt;/i&gt;&lt;/strong&gt; Our recent paper–"The Search for Squawk: Agile Modeling in Bioacoustics"–shows that this method works across birds and coral reefs, allowing the creation of high quality classifiers in under an hour.&lt;/p&gt;&lt;h2&gt;Looking ahead: the future of bioacoustics&lt;/h2&gt;&lt;p&gt;Together, our models and methods are helping maximize the impact of conservation efforts, leaving more time and resources for meaningful, on-the-ground work. From the forests of Hawaiʻi to the reefs of the ocean, the Perch project showcases the profound impact we can have when we apply our technical expertise to the world's most pressing challenges. Every classifier built and every hour of data analyzed brings us closer to a world where the soundtrack of our planet is one of rich, thriving biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This research was developed by the Perch team: Bart van Merriënboer, Jenny Hamer, Vincent Dumoulin, Lauren Harrell, and Tom Denton, and Otilia Stretcu from Google Research. We also thank our collaborators Amanda Navine and Pat Hart at the University of Hawaiʻi, and Holger Klinck, Stefan Kahl and the BirdNet team at the Cornell Lab of Ornithology. And all our friends and collaborators whom we would have written about in this blog post if only we had another thousand words.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/</guid><pubDate>Thu, 07 Aug 2025 14:59:16 +0000</pubDate></item><item><title>Alan Turing Institute: Humanities are key to the future of AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/alan-turing-institute-humanities-are-key-future-of-ai/</link><description>&lt;p&gt;A powerhouse team has launched a new initiative called ‘Doing AI Differently,’ which calls for a human-centred approach to future development.&lt;/p&gt;&lt;p&gt;For years, we’ve treated AI’s outputs like they’re the results of a giant math problem. But the researchers – from The Alan Turing Institute, the University of Edinburgh, AHRC-UKRI, and the Lloyd’s Register Foundation – behind this project say that’s the wrong way to look at it.&lt;/p&gt;&lt;p&gt;What AI is creating are basically cultural artifacts. They’re more like a novel or a painting than a spreadsheet. The problem is, AI is creating this “culture” without understanding any of it. It’s like someone who has memorised a dictionary but has no idea how to hold a real conversation.&lt;/p&gt;&lt;p&gt;This is why AI often fails when “nuance and context matter most,” says Professor Drew Hemment, Theme Lead for Interpretive Technologies for Sustainability at The Alan Turing Institute. The system just doesn’t have the “interpretive depth” to get what it’s really saying.&lt;/p&gt;&lt;p&gt;However, most of the AI in the world is built on just a handful of similar designs. The report calls this the “homogenisation problem” and future AI development must overcome this.&lt;/p&gt;&lt;p&gt;Imagine if every baker in the world used the exact same recipe. You’d get a lot of identical, and frankly, boring cakes. With AI, this means the same blind spots, the same biases, and the same limitations get copied and pasted into thousands of tools we use every day.&lt;/p&gt;&lt;p&gt;We saw this happen with social media. It was rolled out with simple goals, and we’re now living with the unintended societal consequences. The ‘Doing AI Differently’ team is sounding the alarm to make sure we don’t make that same mistake with AI.&lt;/p&gt;&lt;p&gt;The team has a plan to build a new kind of AI, one they call Interpretive AI. It’s about designing systems from the very beginning to work the way people do; with ambiguity, multiple viewpoints, and a deep understanding of context.&lt;/p&gt;&lt;p&gt;The vision is to create interpretive technologies that can offer multiple valid perspectives instead of just one rigid answer. It also means exploring alternative AI architectures to break the mould of current designs. Most importantly, the future isn’t about AI replacing us; it’s about creating human-AI ensembles where we work together, combining our creativity with AI’s processing power to solve huge challenges.&lt;/p&gt;&lt;p&gt;This has the potential to touch our lives in very real ways. In healthcare, for example, your experience with a doctor is a story, not just a list of symptoms. An interpretive AI could help capture that full story, improving your care and your trust in the system.&lt;/p&gt;&lt;p&gt;For climate action, it could help bridge the gap between global climate data and the unique cultural and political realities of a local community, creating solutions that actually work on the ground.&lt;/p&gt;&lt;p&gt;A new international funding call is launching to bring researchers from the UK and Canada together on this mission. But we’re at a crossroads.&lt;/p&gt;&lt;p&gt;“We’re at a pivotal moment for AI,” warns Professor Hemment. “We have a narrowing window to build in interpretive capabilities from the ground up”.&lt;/p&gt;&lt;p&gt;For partners like Lloyd’s Register Foundation, it all comes down to one thing: safety.&lt;/p&gt;&lt;p&gt;“As a global safety charity, our priority is to ensure future AI systems, whatever shape they take, are deployed in a safe and reliable manner,” says their Director of Technologies, Jan Przydatek.&lt;/p&gt;&lt;p&gt;This isn’t just about building better technology. It’s about creating an AI that can help solve our biggest challenges and, in the process, amplify the best parts of our own humanity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Ben Sweet)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI obsession is costing us our human skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A powerhouse team has launched a new initiative called ‘Doing AI Differently,’ which calls for a human-centred approach to future development.&lt;/p&gt;&lt;p&gt;For years, we’ve treated AI’s outputs like they’re the results of a giant math problem. But the researchers – from The Alan Turing Institute, the University of Edinburgh, AHRC-UKRI, and the Lloyd’s Register Foundation – behind this project say that’s the wrong way to look at it.&lt;/p&gt;&lt;p&gt;What AI is creating are basically cultural artifacts. They’re more like a novel or a painting than a spreadsheet. The problem is, AI is creating this “culture” without understanding any of it. It’s like someone who has memorised a dictionary but has no idea how to hold a real conversation.&lt;/p&gt;&lt;p&gt;This is why AI often fails when “nuance and context matter most,” says Professor Drew Hemment, Theme Lead for Interpretive Technologies for Sustainability at The Alan Turing Institute. The system just doesn’t have the “interpretive depth” to get what it’s really saying.&lt;/p&gt;&lt;p&gt;However, most of the AI in the world is built on just a handful of similar designs. The report calls this the “homogenisation problem” and future AI development must overcome this.&lt;/p&gt;&lt;p&gt;Imagine if every baker in the world used the exact same recipe. You’d get a lot of identical, and frankly, boring cakes. With AI, this means the same blind spots, the same biases, and the same limitations get copied and pasted into thousands of tools we use every day.&lt;/p&gt;&lt;p&gt;We saw this happen with social media. It was rolled out with simple goals, and we’re now living with the unintended societal consequences. The ‘Doing AI Differently’ team is sounding the alarm to make sure we don’t make that same mistake with AI.&lt;/p&gt;&lt;p&gt;The team has a plan to build a new kind of AI, one they call Interpretive AI. It’s about designing systems from the very beginning to work the way people do; with ambiguity, multiple viewpoints, and a deep understanding of context.&lt;/p&gt;&lt;p&gt;The vision is to create interpretive technologies that can offer multiple valid perspectives instead of just one rigid answer. It also means exploring alternative AI architectures to break the mould of current designs. Most importantly, the future isn’t about AI replacing us; it’s about creating human-AI ensembles where we work together, combining our creativity with AI’s processing power to solve huge challenges.&lt;/p&gt;&lt;p&gt;This has the potential to touch our lives in very real ways. In healthcare, for example, your experience with a doctor is a story, not just a list of symptoms. An interpretive AI could help capture that full story, improving your care and your trust in the system.&lt;/p&gt;&lt;p&gt;For climate action, it could help bridge the gap between global climate data and the unique cultural and political realities of a local community, creating solutions that actually work on the ground.&lt;/p&gt;&lt;p&gt;A new international funding call is launching to bring researchers from the UK and Canada together on this mission. But we’re at a crossroads.&lt;/p&gt;&lt;p&gt;“We’re at a pivotal moment for AI,” warns Professor Hemment. “We have a narrowing window to build in interpretive capabilities from the ground up”.&lt;/p&gt;&lt;p&gt;For partners like Lloyd’s Register Foundation, it all comes down to one thing: safety.&lt;/p&gt;&lt;p&gt;“As a global safety charity, our priority is to ensure future AI systems, whatever shape they take, are deployed in a safe and reliable manner,” says their Director of Technologies, Jan Przydatek.&lt;/p&gt;&lt;p&gt;This isn’t just about building better technology. It’s about creating an AI that can help solve our biggest challenges and, in the process, amplify the best parts of our own humanity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Ben Sweet)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI obsession is costing us our human skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/alan-turing-institute-humanities-are-key-future-of-ai/</guid><pubDate>Thu, 07 Aug 2025 15:18:27 +0000</pubDate></item><item><title>The backlash against Duolingo going ‘AI-first’ didn’t even matter (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/the-backlash-against-duolingo-going-ai-first-didnt-even-matter/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/duolingo-owl.png?w=900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Duolingo announced on Wednesday that it beat its quarterly revenue estimates, even though the company faced widespread backlash for choosing to embrace generative AI over human workers. Duolingo stock rose almost 30% on the news.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, CEO Luis von Ahn shared that Duolingo would become an “AI-first” company, phasing out its use of contract workers. He also discouraged teams from hiring more employees, unless the team is unable to automate more of its work. With the use of generative AI, Duolingo introduced 148 new language courses, more than doubling its previous offerings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Without AI, it would take us decades to scale our content to more learners,” von Ahn wrote at the time. “We owe it to our learners to get them this content ASAP.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some Duolingo users have argued that these AI features are making the app worse, the company’s financial metrics tell a different story. Now the company anticipates making over $1 billion in revenue this year, and daily active users have grown 40% year-over-year. The growth is significant but falls in the lower range of the company’s estimates of growing between 40% and 45%, which an investor brought up to von Ahn on Wednesday’s quarterly earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason we came [in] towards the lower end was because I said some stuff about AI, and I didn’t give enough context. Because of that, we got some backlash on social media,” von Ahn said. “The most important thing is we wanted to make the sentiment on our social media positive. We stopped posting edgy posts and started posting things that would get our sentiment more positive. That has worked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On TikTok, the top comments on Duolingo’s videos often remain criticisms of the company’s AI approach. Snarky commenters will ask if videos with multiple people in them are made with AI, to which Duolingo will reply, “Nope. Made by our great team!” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But even if public sentiment toward Duolingo has shifted, its bottom line has not&amp;nbsp;… and from the company’s perspective, that’s what matters.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/duolingo-owl.png?w=900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Duolingo announced on Wednesday that it beat its quarterly revenue estimates, even though the company faced widespread backlash for choosing to embrace generative AI over human workers. Duolingo stock rose almost 30% on the news.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, CEO Luis von Ahn shared that Duolingo would become an “AI-first” company, phasing out its use of contract workers. He also discouraged teams from hiring more employees, unless the team is unable to automate more of its work. With the use of generative AI, Duolingo introduced 148 new language courses, more than doubling its previous offerings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Without AI, it would take us decades to scale our content to more learners,” von Ahn wrote at the time. “We owe it to our learners to get them this content ASAP.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some Duolingo users have argued that these AI features are making the app worse, the company’s financial metrics tell a different story. Now the company anticipates making over $1 billion in revenue this year, and daily active users have grown 40% year-over-year. The growth is significant but falls in the lower range of the company’s estimates of growing between 40% and 45%, which an investor brought up to von Ahn on Wednesday’s quarterly earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason we came [in] towards the lower end was because I said some stuff about AI, and I didn’t give enough context. Because of that, we got some backlash on social media,” von Ahn said. “The most important thing is we wanted to make the sentiment on our social media positive. We stopped posting edgy posts and started posting things that would get our sentiment more positive. That has worked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On TikTok, the top comments on Duolingo’s videos often remain criticisms of the company’s AI approach. Snarky commenters will ask if videos with multiple people in them are made with AI, to which Duolingo will reply, “Nope. Made by our great team!” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But even if public sentiment toward Duolingo has shifted, its bottom line has not&amp;nbsp;… and from the company’s perspective, that’s what matters.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/the-backlash-against-duolingo-going-ai-first-didnt-even-matter/</guid><pubDate>Thu, 07 Aug 2025 15:32:05 +0000</pubDate></item><item><title>AI agents aren’t the ‘new Google,’ says Airbnb CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/ai-agents-arent-the-new-google-says-airbnb-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/brian-chesky-GettyImages-2217178973.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a second-quarter earnings beat, Airbnb CEO Brian Chesky shared his thoughts on the company’s AI strategy, cautioning investors that AI chatbots can’t yet be thought of as the “new Google.” That is, AI chatbots, while potentially driving new leads to the travel and services business, aren’t entirely a replacement for the referrals that the dominant search engine brings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least not at this time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re still kind of feeling out the space,” the exec told investors on the Q2 earnings call. “The thing I want to caution is I don’t think that AI agents — I don’t think we should think of chatbots like Google — I don’t think we should think of them as the ‘new Google’ yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, Chesky explained, is because AI models aren’t “proprietary.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also have to remember that the model powering ChatGPT is not proprietary. It’s not exclusive to ChatGPT. We — Airbnb — can also use the API, and there are other models that we can use,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Painting a broader picture of the AI landscape, Chesky said that in addition to chatbots and other AI agents, there will be custom-built startups designed for specific applications, as well as other incumbents that have made the shift to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the things we’ve noticed is it’s not enough to just have&amp;nbsp;… the best model. You have to be able to tune the model and build a custom interface for the right application. And I think that’s the key,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company told investors it will look to take advantage of AI in a number of ways. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb shared during the call that its AI customer service agent in the U.S. reduced the percentage of guests contacting a human agent by 15%, for instance. This was actually harder than tackling the lower-hanging fruit involving travel planning and inspiration, Chesky said, because AI agents performing customer service can’t hallucinate. They have to be accurate and helpful at all times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb’s customer service agent was built using 13 different models and trained on tens of thousands of conversations, and is currently available in English in the U.S. This year, Airbnb will roll it out to more languages, and next year, it will become more personalized and agentic. That means it would be able to understand if someone reaches out to cancel a reservation; not only would it be able to tell them how to do so, but it could also do it for them. The agent could also help plan and book trips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, AI will come to Airbnb’s search next year, the CEO said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company has not fully fleshed out its plans for working with third-party AI agents, although it’s considering it. Users still need an Airbnb account to make a booking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because of this, Chesky doesn’t think agentic AI would turn its business into a commodity, the way that booking flights has become. Instead, he sees AI as “potentially interesting lead generation” for the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key thing is going to be for us to lead and become the first place for people to book travel on Airbnb. As far as whether or not we integrate with AI agents, I think that’s something that we’re certainly open to,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb beat analysts’ expectations in the quarter with revenue of $3.1 billion and earnings per share of $1.03, but the stock dropped on its forecast of slower growth in the second half of the year.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/brian-chesky-GettyImages-2217178973.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a second-quarter earnings beat, Airbnb CEO Brian Chesky shared his thoughts on the company’s AI strategy, cautioning investors that AI chatbots can’t yet be thought of as the “new Google.” That is, AI chatbots, while potentially driving new leads to the travel and services business, aren’t entirely a replacement for the referrals that the dominant search engine brings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least not at this time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re still kind of feeling out the space,” the exec told investors on the Q2 earnings call. “The thing I want to caution is I don’t think that AI agents — I don’t think we should think of chatbots like Google — I don’t think we should think of them as the ‘new Google’ yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, Chesky explained, is because AI models aren’t “proprietary.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also have to remember that the model powering ChatGPT is not proprietary. It’s not exclusive to ChatGPT. We — Airbnb — can also use the API, and there are other models that we can use,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Painting a broader picture of the AI landscape, Chesky said that in addition to chatbots and other AI agents, there will be custom-built startups designed for specific applications, as well as other incumbents that have made the shift to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the things we’ve noticed is it’s not enough to just have&amp;nbsp;… the best model. You have to be able to tune the model and build a custom interface for the right application. And I think that’s the key,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company told investors it will look to take advantage of AI in a number of ways. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb shared during the call that its AI customer service agent in the U.S. reduced the percentage of guests contacting a human agent by 15%, for instance. This was actually harder than tackling the lower-hanging fruit involving travel planning and inspiration, Chesky said, because AI agents performing customer service can’t hallucinate. They have to be accurate and helpful at all times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb’s customer service agent was built using 13 different models and trained on tens of thousands of conversations, and is currently available in English in the U.S. This year, Airbnb will roll it out to more languages, and next year, it will become more personalized and agentic. That means it would be able to understand if someone reaches out to cancel a reservation; not only would it be able to tell them how to do so, but it could also do it for them. The agent could also help plan and book trips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, AI will come to Airbnb’s search next year, the CEO said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company has not fully fleshed out its plans for working with third-party AI agents, although it’s considering it. Users still need an Airbnb account to make a booking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because of this, Chesky doesn’t think agentic AI would turn its business into a commodity, the way that booking flights has become. Instead, he sees AI as “potentially interesting lead generation” for the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key thing is going to be for us to lead and become the first place for people to book travel on Airbnb. As far as whether or not we integrate with AI agents, I think that’s something that we’re certainly open to,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb beat analysts’ expectations in the quarter with revenue of $3.1 billion and earnings per share of $1.03, but the stock dropped on its forecast of slower growth in the second half of the year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/ai-agents-arent-the-new-google-says-airbnb-ceo/</guid><pubDate>Thu, 07 Aug 2025 15:37:35 +0000</pubDate></item><item><title>Reimagining healthcare delivery and public health with AI (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Peter Lee, Umair Shah, Gianrico Farrugia" class="wp-image-1147485" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, healthcare leaders Dr. Umair Shah&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Gianrico Farrugia&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; join Lee to discuss AI’s impact on the business of public health and healthcare delivery, the healthcare-research connection, and the patient experience. Shah, a healthcare strategic consultant and former state secretary of health, explores the role of public health in the larger ecosystem and why it might not get the attention it needs or deserves and how AI could be leveraged to assist in data analysis, to help better engage with people on matters of public health, and to help narrow gaps between care delivery and public health responses during health emergencies. Farrugia, president and CEO of Mayo Clinic, traces AI’s path from predictive to generative and discusses how that progress has helped usher in a new healthcare architecture for Mayo Clinic and its partners, one powered by the goal of longer, healthier lives for patients, and how AI is also changing Mayo Clinic’s research and the education it provides, including the offering of masters and PhDs in AI and other emerging technologies.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE:&lt;/strong&gt; “In US healthcare, quality ratings are increasingly used to tie the improvement in patient health outcomes to the reimbursement rates that healthcare providers can receive. The ability of GPT-4 to understand these systems and give concrete advice … has a chance to make it easier for providers to achieve success in both dimensions.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 7, “The Ultimate Paperwork Shredder.” &lt;/p&gt;



&lt;p&gt;Public health officials and healthcare system leaders influence the well-being and health of people at the population level. They help shape people’s perceptions and responses to public health emergencies, as well as to chronic disease. They help determine the type, quality, and availability of treatment. All this is critical for maintaining good public health, as well as aligning better health and financial outcomes. That, of course, is the main goal of the concept of value-based care. AI can definitely have significant ramifications for achieving this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Joining us today to talk about how leaders in public health and healthcare systems are thinking about and acting on this new generation of AI is Dr. Umair Shah and Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Umair Shah is a nationally recognized health leader and innovator. He led one of America’s top-rated pandemic responses as Washington State’s secretary of health, a position he held from 2020 to 2025. Umair previously directed Harris County Public Health in Texas, overseeing large-scale emergency response for the nation’s third-largest county, while building an emergency-care career spanning 20-plus years. He now advises organizations on health innovation and strategy as founder and principal of Rickshaw Health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Gianrico Farrugia is the president and CEO of Mayo Clinic, the world’s top-ranked hospital for seven consecutive years, and a pioneer in technology-forward, platform-based healthcare. Under his leadership, Mayo has built and deployed the Mayo Clinic Platform. The platform enables Mayo and its partners to gain practical insights from a comprehensive repository of longitudinal de-identified clinical data spanning four continents. Gianrico is also a Mayo Clinic physician and professor and an author.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Umair and Gianrico are CEO-level leaders representing some of the best of the worlds of public health, healthcare delivery, medical research, and medical education.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here is my interview with Dr. Umair Shah:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Umair, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;UMAIR SHAH:&lt;/strong&gt; Peter, it’s my pleasure. I’ve been looking forward to this conversation, and I hope you are well today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] I am doing extremely well.&lt;/p&gt;



&lt;p&gt;So, you know, what I’d like to do in these conversations is first just to start, a little bit about you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You served actually during a really tumultuous time as the secretary of health in the State of Washington. But you recently stepped away from that and you started your own firm, Rickshaw Health. So can we start there? What’s that all about?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, no, absolutely. First of all, you know, I would say that the transition from Texas to Washington could not have been more geopolitically different, [LAUGHTER] as you can imagine.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, if you like the red-blue paradigms, you couldn’t be more, you know, red and you couldn’t be more blue, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But what happened is, back in November this past year, as I saw some of the playout of continuation of this red-blue dynamic, I made the decision to step down. And Jan. 15, I stepped down, as you mentioned, and I spent some time really thinking about what I wanted to do next and was looking at a number of opportunities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then a moment in time, there were some things happening in our—my wife and our family’s personal lives that sort of made me think that I wanted to focus a little bit more on family. And I felt the universe was saying, “Stay still.” [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I launched Rickshaw Health&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and the notion that, as you know, Peter, rickshaws are oftentimes known across the globe as these modes of transport that reliably get you through ever-changing streets and traffic patterns and all sorts of ecosystems that are evolving at all times. And they get you to the other side and they get you also with a sense of exhilaration. Like when I took my boys to Karachi, and we were—you know, they jumped in a rickshaw and the, you know, open air [LAUGHTER] and they felt this incredible excitement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so Rickshaw Health was speaking to the three wheels of a rickshaw that symbolize the three children that we have and the real notion of how do we bring balance and agility and performance to the forefront and then move in an ever—just like streets—ever-changing healthcare environment that is constantly evolving, and we too must evolve with it. And that’s what Rickshaw Health is all about, is taking clients to that next level of trying to navigate, especially at this time, a very, very different landscape than even several months ago. So, excited about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, absolutely. You know, you made this transition from Texas to the State of Washington. And for people who listen to this podcast and don’t know, the particular part of Texas where you were—Harris County—is &lt;em&gt;really big&lt;/em&gt;, very, very important in that state. That’s just not, you know, the normal county in Texas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s actually … it’s actually known as quite a forward-looking place, technologically.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So what was, you know, the transition like, then, going from, you know, possibly the most, sort of, maybe advanced county in the State of Texas, a large place, to the State of Washington?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, you know, Harris County is the third-largest county in the US. So it had close to five million. And now it’s probably … it’s exceeded the five million people, and a very diverse, very forward-looking, as you mentioned, technologically very, very much looking at what’s the next horizon, and home to Texas Medical Center [TMC] as well, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… the largest medical center. Of course, it had to be Texas. So it can’t be the largest in the state or the country [LAUGHTER]—the largest in the world, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And TMC also had a number of different initiatives related to startups and venture capital and VC. And so they had launched something called TMCX. And that was a real opportunity—and I know you’re familiar with it—an opportunity to really look at how do you incubate all sorts of different innovations and bringing private sector, public sector as well as healthcare delivery alongside these startups to really look at the landscape.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when I left Houston and came to Washington, I realized that obviously, I was in the backyard … I mean, you know, you all at Microsoft Research and the work that you’re all doing is part of an ecosystem of advanced innovation that’s occurring in the Pacific Northwest that, you know, when we see all the players that are here, all the, you know, ones that do so many different things, but they’re doing them with an eye towards technology, advancements, and adoptions, it’s been quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When I made that transition, it was really about, you know, the vaccines and what was happening with, you know, with COVID and fighting the—you know, remember, this was the state that had the first case in the continental United States, had the first outbreak, and the first [lab-confirmed] death. And fast-forward a few years later, we had the fifth-lowest death rate in the US. And that was because we all came together to do so much.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, well maybe that gets us into a question that I ask a lot of our guests, which is, you know, and maybe let’s, since we’re on your time as the secretary of health in Washington State, [start] with that job. I ask, how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; [LAUGHS] I laugh because that’s been such a fascinating conversation in public health because we have oftentimes been—it’s been really hard to describe what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And, you know, there are so many metaphors and, you know, analogies that we’ve used. I’ve always wondered why we do not have more television shows or sitcoms or dramas that are about the public health workforce or the work that we do in the field, because you have, you know, all sorts of healthcare delivery ones, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As a practicing physician for 20 years, I realized that people knew what doctors did; they knew what nurses did, right. They intimately touch the healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; They understood, you know, that an ambulance picks you up at your home or somewhere else, transports you … gets you to the emergency department. The emergency department, they do some things to you or within the four walls of that ER, and then you’re either admitted, sent home, and several days, weeks, whatever later, you get home if you’re admitted, and you start your, you know, post-hospital stay at home or your rehab or what have you. And that all is known to people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But when you ask your mother, your grandmother, or your, you know, your uncle, or your brother, your neighbor, your coworker about what is public health, they have a very quizzical look on their face of what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so what I’ve …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, just one thing I’ve learned is: it’s not just all the people you mentioned. Even healthcare professionals sometimes have that quizzical look.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, good point. That’s right. Good point. And a lot of it is because we don’t get exposed to it or trained in it. You know, we think about public health when we’re in our training. And, you know, I’m sure you had a very similar piece of this is that, you know, you see it as, oh, that’s the health department that takes care of, you know, STDs, or it takes care, you know, it does the immunizations, or, you know, maybe they do some water quality, or maybe they do mosquitoes [mosquito control], and things like that. But the reality is, we do &lt;em&gt;all&lt;/em&gt; of those things and more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my metaphor has been that we are the offensive line of a football team, and the healthcare delivery is the quarterback. So everybody focuses on, you know, from a few years back, everybody knows Tom Brady, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; He won the Super Bowls, everybody knows what … but if you asked people who was number 75 on the offensive line of the New England Patriots …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or name your favorite football team. And the answer would be: you would not be able to likely answer that question. You would know Tom Brady, the quarterback, and that’s healthcare delivery, the ER doc or the hospitalist or the nurse or the, you know, the medical assistant, or the people that are doing all the work in the field that are the ones that are more visible, but the invisible workforce of the offensive line, that’s who we don’t know. And yet these are the people that are blocking and sweating and doing all things to complement the work and make sure the quarterback is successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And here’s where the metaphor breaks down, that when Tom Brady wins the Super Bowl, we continue to invest in the offensive line because we recognize the value of it and we want the quarterback to be successful the next season. But in public health or in society, we do the exact opposite.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When tuberculosis rates come down, we say, well, you know what? We’ve solved the problem; we don’t need it anymore.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Or you have another, you know, environmental issue that’s no longer there, you say, “We don’t need it anymore.” And we &lt;em&gt;disinvest&lt;/em&gt; from public health or that offensive line. And then you start to see those rates go back up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so my answer to Mom and Grandma and Dad and Grandpa is we are &lt;em&gt;critical&lt;/em&gt; to your health because we touch you every single day. And so please invest in us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. And, you know, I think I’m going to want to get a little deeper on that in just a few minutes here, because, I think especially during the pandemic, that issue of not understanding the importance of that offensive lineman actually really came to the forefront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’d like to get into that. But the, kind of, second, kind of, standard thing I’ve been probing with people is still just focusing on you and your background is what touchpoints or experiences you’ve had with AI in the past.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And not everyone has. Like, it maybe isn’t too surprising that doctors and healthcare developers, tech developers, have lots of contact with AI, but would the top dog, you know, at a public health agency ever have had significant contact with AI? What about you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, it’s interesting. Several years ago, I was in the audience with the [then] FEMA director, [Rich Serino], who just did such an incredible job. And I remember he made this comment at that time. And, Peter, this may have been like … I don’t know—I’m dating myself—10, 15, maybe even 20 years ago, and he said, “Everybody in the audience, there’s this, you know, app called Twitter.” And, you know, “How many people in the audience have ever sent a tweet or know about this?” And I don’t know, maybe—it was a public health audience—maybe about 15% of the people raised their hands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He said, “I challenge you to right now, pick up your phone, download the app, and go ahead and send a tweet right now.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember I sent my first tweet at that time. And it was so thought provoking for me was that he was saying you need to be engaged in social media, but the other 85% of the audience had not even done that or had …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … even understood the importance of social media at that time. Or maybe they understood, but they had restrictions on how to utilize, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that has stayed with me because that’s very much about this revolution of AI that I know that public health and population health practitioners like myself who have been in the trenches and understand the importance of it, they really believe in the importance or think they know the importance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But NACCHO, the National Association of County and City Health Officials, had done a survey of local health agencies. And about two-thirds, if not three-quarters, of local health agencies reported that they had an AI capacity that was low or lower than ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And that is very much where I come from. When I was in public sector and at the state health agency, our transformation was very much about how do we advance the work, and how do we utilize this in a population health standpoint?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was fortunate to have a chief of innovation at Washington State Department of Health, Les Becker, who understood the value of AI. And as you know, we did also hold a AI science convening that …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … your team was there with University of Washington. And that was really an opportunity for us to say that AI is here. It’s not tomorrow. It’s not next year. It’s not the future. It’s already here. We need to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But here’s the problem, Peter, far too few people in our field understand just how to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; So I have become a markedly more champion of AI. One, since I read your book. So I think there’s that. So thank you for writing it. But two, since I really recognize that when I became a solo or a primary-few practitioner in my own realm, I needed to force-amplify the work that I was doing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when I look back, and I continue to stay in touch with my colleagues in the field of public health, what they’re also struggling with is that you have an epidemiologist who’s got a mound of information—data, statistics, etc.—that they are going through, and they’re doing everything in their power to get that processed and analyzed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; AI can take 80% of that and do it. And that epidemiologist can now turn to more of an overseer and a gatekeeper and to really recognize the patterns …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and let AI be able to do the, you know, grunt work. And similarly, as you know, measles—with the outbreaks that we’ve seen, especially in Texas but elsewhere—you’ve got an opportunity where our communications people who are saying, “Look, we’re about to have, or we know we’re about to announce that there’s a measles outbreak in, you know, in our community or our state or what have you—our region.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they can have AI go through different press briefings and/or press releases and say, “Give me the state of the art on how I should communicate this message to the community.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And bam! You can do that. And now you can oversee that work, as well. And then the third example is that we are always looking at how do we find ways to have a deeper connection with those who come to our, you know, our websites or come to our engagement tools—with bots and things like that. AI can really accelerate that work, as well. So there’s so many use cases that AI has for population health or public health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But I think the challenge is that we just don’t have enough adoption because they’re … one, we’ve had funding cuts, but two is that there is this real hesitation on, what is it that we can do? And I argue—the last thing I’ll say about this, Peter—is that I argue that AI is happening right now. The discussions, the technology advancements, the work, the policy work, all that’s happening right now. If public health practitioners are not at the table, if they’re not part of the, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … “What does this look like? How does it work in our field?” … guess what? It’s going to be done &lt;em&gt;to&lt;/em&gt; us and &lt;em&gt;for&lt;/em&gt; us rather than with us. And if we do not get with that and get to the table, then unfortunately it may not be exactly what we want it to be at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I find it really interesting that you are using the terms “public health” and “population health” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… pretty much interchangeably here. And I think that that’s something that I think touches on an assumption that was both implicit and explicit in the book that we wrote, which is: we were making some predictions that our ability to extract insights and knowledge from population health data would be enhanced through the use of AI. And I think that it looks to me like that has been more challenging and has come along more slowly over the past two years. But what is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, I think part of, and I think you and I have had this conversation, you know, in bits and pieces. I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Right? That’s, it’s …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes, that’s right. That’s right. You know, I think that’s a really good point. And, you know, when you look at sepsis or you look at pneumonia or try to figure out ways that, you know, radiologists or x-rays or CT scans can be read, it’s, I mean, there are so many use cases that are within the healthcare sector. And I think that gets back to this inequity that we have when we look at population health or, you know, this broad, um, swath of land that is, oftentimes, left behind or unexplored, and you have healthcare delivery. Now, healthcare delivery we know gets 95 cents or 96 cents of every dollar. So it makes sense why, right. But we also know that, at the end of the day, we’re looking at value-based outcomes, and you cannot be successful in the healthcare delivery system unless we are truly looking at prevention and what’s happening in the community and the population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;And that’s why I use it interchangeably, but I know that “public health” has got a very specific term, and “population health” is a different set of ways of looking at the world. The reason that people try to shy away from pop health in essence is that you could talk about population health as being my population of patients in a clinic. It could be my health systems population. It could be an insurance company saying, these are the lives covered, right. So it becomes, what is population? When we think of public health, we think of the entirety of the population, right. In the State of Washington, eight million people. Harris County, five million people. Or in the US, 300—whatever the number of millions of people that—we think of the entire population. And what is it that actually impacts the health and well-being of that population is really what that’s about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Yet here’s the challenge. When we then talk to those of our partners and our colleagues in the tech field, there are two things happening. One is, there’s a motivation because of the amount of dollars that are in [the] healthcare sector. And number two is, because it’s more familiar, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so there are very few practitioners similar to me that are out there, that are in the pop health who kind of know healthcare delivery because they’ve also seen patients, but they’re also—they worked at that federal, state, local level, community level—they’ve, you know, they’ve done you know various different kinds of environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they say, “Look, I’ve got a perspective to really help a tech company or somebody see the rest of it,” but you have to have both partners coming together to see that. And I think that’s one of the real challenges that we have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so now I’m going to want to go into specific problems, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe COVID is a good thing to focus on—the breadth of problems that had to get solved in pandemic response and where the gaps between healthcare delivery and public health were really exposed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first problem that I remember really keenly that just seemed so vexing was understanding where the PPE was, the &lt;em&gt;personal protective equipment&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;and where it needed to be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so that turned out … you would think just getting masks and gowns and gloves to the right places at the right times or even understanding where they are so that, you know … and being able to predict, you know, what hospitals, what clinics are most likely to get a big influx of patients during the height of the pandemic would be something that would be straightforward to solve, but that turned out to be an extremely difficult problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But how did it look from where you were sitting? Because you were sitting at the helm having to deal with these problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, we were constantly chasing data and information. And oftentimes, you know, because a lot of these data systems in the public health sector have been underinvested in over the decades, then, you know, you had our biggest emergency crisis of our time, and a lot of public health agencies were either getting, you know, thrown a whole host of resources or had to create things on the fly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And whether that was at Harris County or in the State of Washington, I will tell you that what I saw was that, you know, a lot of agencies across the country were still using fax machines, you know, to get data that were coming in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember actually—it’s kind of a funny story—there was a fax machine that was highlighted down in our agency in Texas. And we actually had this fax machine, had mounds of, you know, data … sorry, &lt;em&gt;papers&lt;/em&gt; that were next to … &lt;em&gt;faxes&lt;/em&gt; that were coming in and all these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would have, you know, &lt;em&gt;Mr. Peter Lee&lt;/em&gt; listed as a patient. And then the next, you know, transmission would have &lt;em&gt;Pete Lee&lt;/em&gt;. And then the next transmission would have &lt;em&gt;Peter Lee&lt;/em&gt;, but instead of L-E-E, it was L-E-A-H or something, or L-I or something, right. And it was just …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or you had a date of birth missing, or you had, you know, an address that was off. And what we realized is that over time, a lot of the data that were coming in were just incomplete data, and being able to chase that was really hard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, I think AI has that potential to really organize it, and to stratify it, and to especially get you to a point of at least cleaning it up. So I don’t think it’s just that AI … AI doesn’t just save &lt;em&gt;time&lt;/em&gt;; it saves &lt;em&gt;lives&lt;/em&gt;. Truly used …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… that’s, I think, where we’re talking here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when you have PPE and things of that nature, as you talked about, here in the State of Washington or what we were trying to do to get vaccines out or everything we’re doing to try to get communication messages to the public. And we did a fantastic job of that, although not ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are so many things that I could point to that we could have done better—all of us in the field of public health and healthcare delivery alike.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will tell you that the one thing that stays with me is that if we had those tools &lt;em&gt;then&lt;/em&gt;, and we had them in place &lt;em&gt;then&lt;/em&gt;, and we had invested in them at that time in advance of, I think there was a real opportunity for us to be able to move ahead and even be better at how we affected the health outcomes of the very populations that we were trying to get to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s [that] AI allows us to shift from reactive to proactive systems, catching health issues before they escalate and allow us to really communicate with empathy &lt;em&gt;at scale&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And when we can do those things, whether it’s opioids or whether it’s, you know, something that’s happening related to an infectious disease, or, you know, even this, the new agenda with &lt;em&gt;Make America Healthy Again&lt;/em&gt;—which by the way, as you know, we had a &lt;em&gt;Be Well, WA&lt;/em&gt; … &lt;em&gt;Be Well,&lt;/em&gt; &lt;em&gt;Washington&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … very much that was about, you know, looking at, you know, physical health and nutritional health and emotional well-being and social connectedness—that there is a real opportunity for us to address the very drivers of ill health. And when we can do that, and AI can help us accelerate that, I think we truly have the ability to drive down costs and increase the value that’s returned to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;What is your assessment of public health agencies’ readiness to use technology like AI? Because if there’s one thing AI is good at, it’s predicting things. Are they [public health agencies] in a better position to predict things now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, I think it’s a tale of two cities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think on the one hand, we’re better because we have the tools. On the other hand, we’ve lost the capacity to be able to utilize those tools. So, you know, it’s a plus and a minus.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many, many years ago, there was the buzzword of what we called &lt;em&gt;syndromic surveillance&lt;/em&gt;. And, Peter, you know this term well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was like you would have, you know, a whole host of accumulation of data points in, let’s say, a hospital setting or an emergency department …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup. Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… where, you know, you’d have runny nose, you’d have cough, you’d have a fever, and you would take that, what was happening and people presenting to the emergency department, with what was happening in the area pharmacies where people were going to get Kleenexes and tissues …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and buying over-the-counter, you know, medication, and things of that nature, Tylenol, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would say … you would put those two things together, and you would come up with a quote-unquote “syndrome,” and you would say our ability to say there was an alert to that syndrome allows us to say something&lt;em&gt; uh-oh&lt;/em&gt; is going on in the community, and we got many, many advancements related to wastewater surveillance over the last several years as you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep. Yep. Well, also, wasn’t patient number one in the United States discovered also because of the Seattle Flu Study, or at least that sort of syndromic surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;They weren’t even looking for COVID. They were just taking, you know, snot samples from people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right. That’s right. That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that’s the kind of thing that you, you know, we underappreciate. Is you have to have a smart, intelligent, agile practitioner, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if I think about down in Dallas when Ebola was, you know, the gentleman who was, you know, the index case for Ebola was sent out of the emergency department and came back several days later.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it was the nurse who picked up this time because the practitioner, the provider, the healthcare provider, the doc missed it. And I wouldn’t want to say in a negative way. It was just, like, not obvious. You aren’t thinking of Ebola in the middle of Texas. And it was the nurse who picked up: &lt;em&gt;there’s something wrong here&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what AI has the ability to do is to pick up those symptoms …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or those patterns and be able to recognize the importance of those and be able to then alert the practitioner. So what I … we call it &lt;em&gt;artificial intelligence&lt;/em&gt;—it almost becomes artificial wisdom.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah, interesting. So that actually reminds me of my next question, which is another thing that I watched you and public health officials do is try to play “what if” games.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, I think one decision you were involved in had to do with, you know, what would be the impact if we put a ban on large gatherings like concerts or movie theaters or imposed an 8 PM curfew on restaurants, and you were trying to play “what if” games. Like, what would be the impact on the spread of the pandemic there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So now, again, today with AI, would that aspect of what you did play out differently than it did during the pandemic?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As you know, COVID was the most studied condition on the planet at one point. And it was, you know, things that usually we would learn over years or months, we were learning in weeks or days or hours.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember in Houston, I would say something in the morning, and I would always try to give the caveat, “This is the best information we know right now,” because it kept changing, whether it was around masks or whether it was around, you know, the way the virus was operating, whether it was around …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I remember even … I was just watching something recently where I was asked to comment about whether spiders could transmit COVID-19. You know, just questions that were just evolving, evolving, evolving. And the information was evolving. By morning, you would say something. By evening, it would change.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And why I say that is that it would have been great in the pandemic if we could have said, if you could give us all the information that’s happening across the globe, synthesize that information, and be able to help us forecast the right decisions that we should be making and help us model that information so we could decide: if you did a curfew, or if you did, you know, a mask, or if you could, you know, change something else related to policy—what are the impacts of it?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;What we found constantly in public health was that we were weighing decisions in incomplete data, incomplete information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So great now that everybody can armchair quarterback looking back three, five years ago and say, “I would have done it this way,” or “I would have done it that way.” Gosh, I would have as well. But guess what—we didn’t have that information at that time. And so you had to make the best decisions you could with incomplete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what AI has the potential to do is to help &lt;em&gt;complete&lt;/em&gt; the incomplete data. Now, it’s not going to get 100%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And I think, Peter, you know, the one thing we’ve got to be really mindful [of] is phantom information, or information where it sort of makes up things, or may somehow get you incomplete information, or skews it a certain way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is why we can’t take the person out of it yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Now, maybe one day we can.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m not one of those Pollyanna-ish that people will never be replaced. I actually believe that those people who are skilled with AI and the tools will eventually have a competitive advantage over those who are not. Just like if I had a physician who knows how to use their smartphone or knows how to use a word processor or knows how to do a PowerPoint presentation is going to replace the ones that use scantrons …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or the ones that write it on pieces of paper—that eventually it makes it more efficient and effective, but we’re not there yet. But I think that the potential is &lt;em&gt;absolutely&lt;/em&gt; there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I have one more question. And you can, kind of, tell I’m trying to expand people’s understanding of just the incredible breadth of what goes on in public health, you know, all of these sorts of different issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And again, just sticking to COVID, but this is a much broader issue. Another thing you had to cope with were significant rise of misinformation …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe going along with that, very, very significant inequities in outcomes in the COVID response. And when you think about AI there, I think you can argue it both ways, that it both exacerbates the problem but also gives you new tools to mitigate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; I think you … I don’t even have to say it … I think you hit on it, is that, you know, it really is two sides of one coin.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the one hand, it has the power of really advancing and allowing us to move forward in a way that incredibly accelerates and accentuates, but on the other hand, in the case of inequities, right? So if you have inequitable information data that’s already out in the literature or already out in the, you know, media, or what have you, about a certain population or people or certain kinds of ideas or thoughts, etc., then AI will tend to accumulate that. You’re going to take that information, thinking that’s the best out there, but it may have missed out on information and now you go with it. And that’s a potential problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s the same thing on information is that when we have people that are able to classify or misclassify information, I think it really becomes hard because it can accelerate the inequities of trust or inequities of trusted sources of information. It can also close the gap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think, you know, it’s really up to us and this responsible AI to really think about how we can go about doing this in a way that’s going to allow us to further the advancements but also be careful of those, you know, those kind of places where we’re going to step into that are not going to be well received or successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, the one thing that’s really fascinating about this whole conversation is that this is why we’ve got to be at the table, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Because if we’re not at the table, you know, what’s the, you know, or if tech companies that are out there doing this work and aren’t even seeing a field of practitioners that are actually wrestling with the same problems but just cannot actually get to the solutions, we’re just going to continue to accentuate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I’m a firm proponent of: we’ve got to be at the table.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so even when we’ve seen in, and this is going to be a little controversial, but governmental spaces where, you know, policymakers have said, “Look, we are not going to let you do certain things,” or they say to public health practitioners or even healthcare delivery practitioners in certain spaces, “You cannot even play with this. You cannot have it on your phones. You can’t do any … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, what I really believe it does is that it takes [an] almost like we put our head in the sand type of approach rather than saying, “What is it that we can do to help improve AI and make it work for all of us?” What we’re doing is we’re essentially saying, “We’re going to let the tech companies and all the other developers come up with the solutions, but it’s not going to be informed by the people in the field.” And that’s dangerous. We have to do both. We have to be working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Umair, that’s really so well said, and I think a great way to wrap things up. I’ve certainly learned a lot from this conversation. So thank you again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; It’s been a pleasure to be with you this morning. Thank you so much for the time. And I’m looking forward to further conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;I live in the State of Washington and because of that, I’ve been able to watch Umair in action as our state’s former secretary of health. And some of that action was pretty intense to say the least because his tenure as secretary of health spanned the period of the COVID pandemic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, as a dyed-in-the-wool techie, I have to admit that at the beginning, I don’t think I really understood the scope and importance of the field of public health. But as the conversation with Umair showed, it’s really important and it is arguably both an underfunded and underappreciated part of our healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, public health is also very much an area that’s ripe for advancement and transformation through AI. As Umair explained in our discussion, the core of public health is the idea of population health, the idea of extracting new health insights from signals from population-scale data. And already we’re starting to see AI making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now here’s my interview with Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Gianrico, it’s really great to have you here today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GIANRICO FARRUGIA:&lt;/strong&gt; Peter, thanks for having me. Thanks for making me part of your podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, what I’d like to do in these conversations is, you know, we’ll definitely want to talk about the overall healthcare system, the state of healthcare, and what AI could or might do to help or even hurt all of that. But I always like to start with a sharper focus just on you specifically. And my first question always is, you know, I think people imagine what a hospital or a health system president and CEO does, but not really. And so how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So, Peter, my mother’s 88 years old. She lives in Malta, and she’s visiting at the moment, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … which is kind of nice, really.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that is amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;I’m proud that she’s still proud of me. So she does ask. I’ll tell her the scope of Mayo Clinic. We serve patients across the globe. We have about 83,000 staff members that work with us, and we’re very proud of the work we do in research, education, and the practice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mayo Clinic is built to serve people with serious disease. So what I tell my mother is that here we are. We’re a healthcare organization that knows what it needs to do: keep patients as the North Star. The needs of the patient come first. We have 83,000 people who want to do that, several thousand physicians and scientists. My job is to look slightly ahead and then share what I’m seeing and then, sort of, smooth the way for others to make sure Mayo remains true to its mission but also true to the fact that at the moment, we are in a category of one. We need to remain there not just from an ego standpoint, but really from a “do good to the world” standpoint.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At that point, invariably my mother will tell me that I’m working too hard. [LAUGHTER] And then of course, I change the subject, and I ask her what she cooked today because my mother, who’s 88, cooks for the whole family in Malta, and there are usually four generations eating around the table. So I tell her what she does for the family is what I do for the Mayo family.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow, that’s a great way to put it. And it sounds like you actually have a good chance to have some good genes if she’s still that active at age 88.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think I chose a little more stressful job that may limit [that]. I will tell you very briefly is that one of the AI algorithms we have estimates biological age from an electrocardiogram. My biological age jumped by 3.7 years when I became CEO.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] Oh no.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I’m hoping it will reverse on the other side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;To stick with you just for one more moment here, second question I ask is about your origin story with respect to AI. And typically, for most people, there is AI before ChatGPT and generative AI and then after the generative AI revolution. So can you share a little bit about this? Because it must be the case that you’ve been thinking about this a long time since you’ve really led Mayo Clinic to be so tech forward in this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Well, I’ve been, as you said, a physician for way too long. I got my MD degree in ’87. So that sort of dates me. But it also means that I saw a lot of the promise for AI that never seemed to pan out for decades and decades and decades like you did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Around 10 years ago, Mayo could sense that there was something different, that something was changing, that we actually—at that time, predictive AI—could make a big difference. And I think that’s the moment where I and others jumped in and said Mayo Clinic needs to be involved.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then about six years ago, when—six and a half years ago—I became CEO, it was clear that there was the right confluence of data, knowledge, tech expertise, that we could deal with what was increasingly bothering me, which is that we knew what was coming from a technology standpoint and we knew the current healthcare system could not deliver on what patients need and want within that current system. And so the answer is, how could a place like Mayo Clinic with our reputation not jump in and say there has to be a better way of doing things? I’ve always said that it is impossible for me to understand that every single government employee is incompetent. Every physician is greedy. Something’s wrong here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And that wrong was the architecture was wrong. And we knew that we could incorporate AI and make it better. So for me, that journey was one of &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;. 10 years ago, begin to jump in. Six years ago, really jump in with our platform. And then, of course, in November 2022, things changed again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. When did this idea of a data platform, what you now call the Mayo Clinic Platform&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;—by the way, I refer to this as &lt;em&gt;MCP&lt;/em&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, I know. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] … which I always smirk a little bit because, of course, for those of us in computer science research, the AI research, &lt;em&gt;MCP&lt;/em&gt; has also become quite a hot topic because of the model context protocol version of this. But for Mayo’s MCP, when did that become a serious, defined initiative?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So around the end of ’18, 2018, beginning of 2019. At that point, we knew that we were going to do something differently. We came up with a strategic plan, as I took on the job, that we needed to cure more patients. There’s just not enough cures in the world. There’s too much suffering. And that we had all these chronic diseases that people have accepted are chronic, but really the only reason that disease is chronic is you haven’t cured it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And physicians have been afraid to talk about cure because, of course, eventually everybody passes away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But I really pushed hard to say, no, it’s OK to talk about cure. It’s OK to aspire to cure. The second was connect—connecting people with data to create new knowledge. And that’s where it became clear that data were not currently in a format that were particularly useful. By the way, you’ll hear me talk about &lt;em&gt;data&lt;/em&gt; in the singular and the plural. I’m old school. I talk about &lt;em&gt;data&lt;/em&gt; as plural, but I know that most younger people now use &lt;em&gt;data&lt;/em&gt; singular. [LAUGHTER] And I apologize if I’ll go through that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then the third was transform. Let’s use Mayo’s resources to transform healthcare for ourselves and for others. And that’s the concept of, if we are able to use data in a different way, let’s create a different architecture. And that architecture had to be very closely linked to using artificial intelligence in order to create better outcomes for patients. So patients can live not only longer lives but healthier lives. And that’s the genesis of MCP, &lt;em&gt;Mayo Clinic Platform&lt;/em&gt;, so I’ll timestamp that as end of 2018, beginning of 2019.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m really wanting to delve in in this episode, in this conversation, you know, [into the] mindset of a health system or hospital CEO. And so you’re obviously thinking about, I guess, machine learning and predictive analytics and so on. What were the, kind of, like … in 2018, what were the outcomes that you were dreaming about from this? So if you had this thing, you know, what were the things that you were hoping to be able to show or, kind of, produce as results?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, I think all of us who work at Mayo Clinic, and this tends to be a bit sugary, but it’s true, strongly feel that we have a responsibility to leave the place better than when we started. And so the Mayo brothers, when they started, did two really important things. The first was that they created the first integrated healthcare system. And the second, they created the first unified record. And that record was, of course, paper at that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Part of that is to say, OK, what does it look like now versus how can we improve what we have if … it’d be blasphemy to say, let’s think of ourselves as the Mayo brothers, but let’s think of ourselves as reasonably smart people at Mayo Clinic, really lucky to be surrounded by very smart people with resources. What will we do? And so we said let’s not aim for the low-hanging fruit. Let’s aim to get at whatever you want to call it, the intractable knot, the hardest problem, and that is clinical care. Let’s improve clinical care. Yes, we can deal with burnout. Yes, we can deal with administrative burden. But let’s not focus on that. Let’s really create an architecture that allows us to tackle better clinical outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And by starting there, then everything flows from that. That it’s not really worth doing unless at the end of the day, people are experiencing better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so I know a very good colleague and friend of mine, John Halamka&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, you ended up hiring. I thought he was a very interesting choice because he is, of course, in terms of technology, quite deep and very expert, but he’s, I think, first and foremost, a doctor. And so I assume you must have had to decide what type of person you would bring in and what kinds of people you would bring in to try to create such a thing. What was your thinking around the choice of someone like John?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; It was one of the harder decisions. First of all, [I’m] a physician myself. We tend to want to maintain some control. And so now I am the CEO, [LAUGHTER] and I have to give this baby to somebody else. That’s very hard. Second is Mayo Clinic is really good because it is flat, and we run a lot by committee. But it also means that, therefore, you have to work really hard at change, and you cannot change by fiat. You have to change by convincing people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just … I’ve always made the point that the right change agent is a servant leader because that’s how change becomes embedded. But it also means you’ve got to have that personality, the Mayo personality. And it became clear when we interviewed [that] there were some people that were really hardcore tech; others that were passionate about social issues. But John really fit that of being, as you said, deep in IT but also himself very aligned with the Mayo Clinic values. It’s as if he was a Mayo Clinic physician even though he wasn’t.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that came together, and I felt, &lt;em&gt;we&lt;/em&gt; felt, that as we were hiring, that we could do it. And then we did something interesting. We paired John with a … we created the role of a chief medical officer for the platform, which was a longstanding Mayo Clinic physician. And so we brought them together so we could get the past and the present and the future working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m going to ask you about what has come out of this. But before that, let’s get back to this origin story. So now, all of that is being set up starting around 2018. But then, you know, in 2022, there is generative AI. Now you were already experimenting with transformers, starting with BERT out of Google there. So maybe that’s a couple of years earlier. But still, there has to come a point where things are feeling very disrupted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, so, you know, it really wasn’t. It, to me, was a relief because it gave this … we were feeling pretty good about what we’re doing. We were feeling a little impatient, but, in true Mayo fashion, were willing to, sort of, do everything, take its time, take it to the right committees, get the right approvals, and get it done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … because something as disruptive as that instantly became enabling at Mayo Clinic. And I’ll take … as I think about it with you and take a moment to think and reflect on it, I think there were a couple of decisions we made earlier on that really helped us. We made the decision &lt;em&gt;against&lt;/em&gt; the advice of any consulting firm to completely decentralize AI at Mayo Clinic six years ago. And we told our clinical department, you need to own this. You need to hire basic scientists in AI. We’ll help you by creating the infrastructure. We’ll help you by doing all the rest. We’ll have the compute. We’ll have the partners. You need to do this on your own. You need to treat this the same way as if a new radiological technique happened or a new surgical technique happened.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so there was a lot of expertise already present in a very diffused way that then we were able to layer on generative AI onto that. And we found a very willingness to embrace it. In fact, I would argue initially a bit too willing because as you know, we haven’t quite figured out what’s legitimate use, what’s not use.&amp;nbsp;We all learned together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But it was mostly energy, which is really interesting. It was mostly energy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. And, you know, it’s an amazing thing to hear because one common theme that we hear is that the initial reaction is oftentimes one of skepticism. In fact, I’ve been very open that even I initially had some skepticism. Was that not present in your mind or on your team’s mind at all at the beginning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So you’re asking a physician if they are skeptical about something. [LAUGHTER] Yeah. I wonder what the answer to that is. Absolutely. The first hallucination, the first wrong reference. Can you imagine if you write the grant and the wrong reference comes. As you know, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … earlier on when some references were being made up. So massive amounts of skepticism. But the energy was such there that the people [who] were skeptical were also at the same time saying, “Let’s do a RAG [retrieval augmented generation] to clean up those references. Let’s create …” We were experimenting with discharge summaries, but let’s use AI to police AI, and let’s see what’s going on. So there was more massive skepticism, but the energy was pushing that skepticism into a positive versus into a negative frame. Now, I say that summarizing in hindsight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Day to day, much more complicated than that. But overall, if you just … and remember, I had been at the World Economic Forum many years ago and had said, healthcare needs to run towards AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; If healthcare was perfect, we would wait. Healthcare is not perfect by any means, therefore let’s run and embrace AI. And, sort of, that mentality was part of who we were because at the same time, we were also saying the other thing, that we need to be the ones to lead validation. We need to be the ones that set the rules. We need to be participating in the creation of CHAI [Coalition for Health AI]&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We need to be participating as the [National] Academy of Medicine&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So people did feel that Mayo was being fairly responsible about it, but that urge to, the needs of the patient come first, was the driver that kept people wanting to say, “Not ready yet, but let’s make it ready.” And we now have 320 algorithms in the practice, and they run and we constantly are looking and seeing what else we can do to improve. But as you well know, things evolve and change. And we’re also looking and seeing which ones work and which ones don’t and which ones we have to work together on to make better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, of course Mayo has such a, you know, such a reputation and is so influential, but in the world of healthcare broadly, let’s just focus on the United States to start. How common is this experience? You know, so if you are at a meeting with fellow CEOs of hospitals and health systems, what is the attitude and what is the, kind of … how common is the approach to all of this?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think it’s more common now, but going back a few years, I think it’s fair to say that it was scary for people to know how it’s going to change things. Healthcare runs on very narrow margins. It’s very expensive. So your expenses and your revenue are both massive, and they are very close to each other. So anything that changes that balance is really scary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because it’s not like you have the opportunity to erode into a margin or get it right the second time. So I think that is what drove a lot of the initial hesitancy. Was, one, is lack of knowledge and, two, understanding that you didn’t have a lot of room to make a mistake.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; On the economics of this, when you are embarking on what I suspect is a very expensive initiative like Mayo Clinic Platform, how on earth do you justify that early on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So again, I’m trying hard to try and remember how things were versus how I think about them now. [LAUGHTER] It goes back to our history. Mayo has always invested in what it thinks is the right thing that is coming. And that’s how we’ve stayed where we are. So the investment really was having an open discussion: is this worth it for our patients? And once that discussion was over, then the board was saying, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we are lucky in that we have the size that we’re able to hire and absorb. We’re lucky in that the people [who] came before us have been financially astute, and one of our values is stewardship. And we’re lucky that we had a lot of patients at Mayo Clinic who were able to listen, be inspired by, and be willing to help support. And so that gave us the ability to build what we’re doing not only into the long-range plan but actually into the yearly plan. And so we built it into the yearly plan. We set up a center for digital health. We set up the platform. And then we set up the budgets to be able to do that. And the budgets came from assets we’ve had, assets that we would get as the year came by, and then from philanthropy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also had a really powerful calling card. And that’s one advantage I had, and that’s … and I’d been very open when I was speaking to other CEOs that would use it is that right at that very beginning, really, really in 2019, our cardiologists, both the researchers and the clinicians, had come together and had used electrocardiograms to create an AI algorithm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first one was for diagnosing from an electrocardiogram, which is very cheap, very easy to do, left ventricular dysfunction. That’s how hard the left part of the heart contracts. If it doesn’t do well, you get heart failure. And they were able to show that that algorithm was already making nurses better than the physician without the algorithm. And after that went on to show that you could do it from a single strip, really with an area under the curve for that single strip on a watch, that was as good as mammograms or pap smears. And so we already had that proof.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; That quickly then came into Mayo. We put it into it so that any patient now can benefit from it. And now there are, I think, 14 algorithms just from that same one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So we had a proof of concept thanks to those really far-seeing cardiologists that enabled things to happen a little faster and also, as I talked to other CEOs, enabled me to say, “This actually works. This is the path forward.” I have recently been vocal about also saying, we are at a point now where I believe that for some medical conditions, it is not right to not use AI to help treat them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that’s so interesting. So I think I want to get into another topic here, which is when you think about the use of AI and data, what are some of the results that maybe are top of mind for you or you think are particularly important? And if you don’t mind, I’d like to see if we can think about this not only in terms of results in terms of patient outcomes but in your other activities, core activities, like research, in the education mission, and then even in the broader impacts on the healthcare system. But maybe we start with on patient outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, they’re all linked, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; They’re part of the same ecosystem. We think of ourselves as three shields— research, education, and the practice—and that one goes into the other. So, as I said, we have about 320 AI algorithms from the practice. Some run on every patient; some run on some patients. And we have good evidence for what they do. So some specific examples, and then I’ll get into the transformer part of this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We have a program called CEDAR [Clinical Detection and Response (tool)], and like most other people, I like acronyms for things. [LAUGHTER] But what it is, in our hospitals with patient consent, we monitor vitals. We monitor in the patient room—not in the ICU [intensive care unit], in the patient room. We monitor all sorts of things. But there’s a camera in the room, and we have a team of intensivists—nurses and physicians—who do not have any patient responsibilities but are just monitoring the algorithms, and when the algorithms are predicting decompensation, they’re able to get into the room. And what we’ve shown, for example, with that algorithm, is we’ve shown we’ve decreased length of stay in the hospital, decreased transfers into the intensive care units, and interestingly, decreased mortality and morbidity, which is not easy to show. I talked about the electrocardiogram as a good example. Of course, everybody knows about the radiology things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’ve created … taken part of this and said, if we can do this in the hospital, why cannot we do it in patients’ homes? So being very active in looking after patients that would come to the ED, emergency room, would normally be admitted, and we say, no, here are the things we can give you. Go home if you want to, and we will safely look after you at your home. And we recently have been, looking at the last two years of data, been able to show that we’re also successfully able to give intravenous chemotherapy in patients’ homes because we can monitor; we can do all the things that we can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, with generative AI, that gave us many other opportunities. One biggest opportunity for me has always been digital pathology. When we see how pathology’s currently run with a glass slide, not much has changed …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … in many, many, many years, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And so really we have made a massive push to digitize pathology not just for us but for others. But talking about ourselves, we started by saying, it has to be very cheap to digitize. So we worked and created a company with partners called Pramana&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that allows us to digitize slides relatively cheaply using AI algorithms that can take away the dirt, the fingerprint. And so we end up with 21 million of our slides digitized, and that gives you now a massive opportunity. Worked with another company called Aignostics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to create a, what we call, Atlas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is an LLM that allows us to then build upon it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And we, a hundred and, I think, 120 years ago, invented frozen sections at Mayo Clinic. So what that is, is that while the patient’s still on the table, you can take a piece of tissue, look at it, and tell the surgeon the margins of what you’re trying to resect are clear or not. But as a result of that, because you have to hurry, you get no information as a surgeon about, is it an invasive cancer, is it noninvasive cancer, or other things. So we’ve just found a way to digitize our frozen section practice and will completely go across the enterprise with AI-enabled digitized frozen sections, which then enables us to then do it for anybody across the globe if we need to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in the genomic space, we’re working to create a true exomic transformer that is short range. And we originally started doing it to see if we can test it against the fact that 40% of people with rheumatoid arthritis don’t respond to the first-line therapy, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … but you have to wait six months to find out. And we found that we can actually do that. But it has much greater uses, of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we’re working with you—I don’t know how much you want to get into this, Peter, or [if] you want to talk about it yourself—MAIRA-2, which is really exciting, about how taking a simple problem—can you create a transformer that is able to detect if lines on the chest are in the right place, breathing tube is in the right place?—and then do it in a way that then can be used for many, many other things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, Peter, because you asked about education and research, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … imagine what this does now to the education system, right. And so we’ve got to train our physicians differently. We now have an AI curriculum for all our medical students. We offer masters and PhDs in AI. We think it’s essential for the people who want to be able to truly become experts, the same way I became an expert in my area of research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from a research standpoint, when you think about all the registries that exist in people’s labs, all the spatial genomics, all the epigenomics, all the omics that exist. And if you are able to coalesce them into one big, what we call, an &lt;em&gt;atlas&lt;/em&gt;, how that could really spur research at a scale that we haven’t thought of before. And so that is our aim at the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From a research standpoint, we are, with Vijay Shah, who’s our dean of research, is to say, let’s make the effort of making sure all the data are available to be able to use and enable for us to take advantage of AI. And that is not easy because, of course, people have collected the data. They tend to want to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;So there have to be the right incentives, the right privacy, and the right ways of doing it. And we think we’re on the way there, and we’re already seeing some advantages from doing it this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’re running short on time. And so I always like to end with one or two more provocative questions. And, you know, it’s tempting to ask you the provocative question of whether you think AI will ever replace human doctors, but I don’t want to go there with you. In fact, as I thought about our discussion, I was reflecting. We were at a conference together once, and I was on stage in a fireside chat. And then, you know, after the fireside chat, there were audience questions, and I don’t remember any of the questions from the audience except &lt;em&gt;yours&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And just to remind you, you know, I think when I was on stage, we were talking about a lot of practical uses of AI to, let’s say, reduce administrative burdens and so on in healthcare. But you got up and you, I won’t say you scolded me, but you more or less said, is it the right idea to use AI to optimize today’s somewhat broken healthcare system, or should we be thinking more boldly about, you know, a more fundamental transformation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so what I thought I would try to close with here is to hear what was really behind that question. You know, what were you trying to get me to think about when you asked that question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, darn your great memory [LAUGHTER]. Belated apologies … I probably should have …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It was by far the best and most sophisticated and, I think, thought-provoking question of all of the ones that came out of the audience.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; What I was trying to get to is actually trying to clarify it in my own head and then in the head of others is that we do not need to have a linear path to get to where we want to get to. And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. Let’s make their problems better, make them feel better about providing healthcare. And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, &lt;em&gt;no&lt;/em&gt;, is that let’s start with that aim, the last aim, and do the others because the others will come automatically if you’re working on that harder problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because one, to get to that harder problem, you’ll find all the other solutions. I was just trying to push that here’s this wonderful tool that’s been given to us. Let’s take advantage of it as quickly as we can. I think we had gotten a little too sensitized to need to say the right things. “Careful, be very careful” versus saying, “Massive opportunity. Do it right, and healthcare will be much better. Go for it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think I understand better now where the vision, insight, and frankly, courage to take on something as ambitious and transformational as the Mayo Clinic Platform and really all of your leadership in your tenure as the president and CEO of Mayo Clinic. I think I understand it much better now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gianrico, it’s just always such a privilege to interact with you and now to have a chance to work with you more closely. So thank you for everything that you do and thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Thank you for making it so easy, and thanks for giving us this opportunity to do good for the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Gianrico leads what is arguably the crown jewel of the world’s healthcare systems, and so I feel it’s such a privilege to be able to talk and sometimes even brainstorm with him.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our conversation, I think, exposed just how tech forward Gianrico is as he charts the strategies for healthcare delivery well into the future. And as I’ve interacted with many others, what I’ve learned is that this is a common trait among major health system CEOs. Roughly speaking, like we’ve seen in previous episodes where doctors and med students are polymath clinician-technologists, the same thing is true of health system CEOs and other leaders.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI in the mind of a health system CEO today is not only a technology that can transform diagnosis and treatment, but it’s also something that can have a huge impact on the business of healthcare delivery, the connection of healthcare to medical research, and the journeys that patients go through as they seek better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These two conversations show that virtually all leaders in health and medicine are confronting head-on the opportunities, challenges, and the reality of AI, and they see a future that is potentially very different than what we have today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’d like to thank Umair and Gianrico again for their time and insights. And to our listeners, thank you for joining us. We hope you’ll tune in to our final episode of the series. My coauthors, Carey and Zak, will be back to examine the takeaways from our most recent conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;








&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Peter Lee, Umair Shah, Gianrico Farrugia" class="wp-image-1147485" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, healthcare leaders Dr. Umair Shah&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Gianrico Farrugia&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; join Lee to discuss AI’s impact on the business of public health and healthcare delivery, the healthcare-research connection, and the patient experience. Shah, a healthcare strategic consultant and former state secretary of health, explores the role of public health in the larger ecosystem and why it might not get the attention it needs or deserves and how AI could be leveraged to assist in data analysis, to help better engage with people on matters of public health, and to help narrow gaps between care delivery and public health responses during health emergencies. Farrugia, president and CEO of Mayo Clinic, traces AI’s path from predictive to generative and discusses how that progress has helped usher in a new healthcare architecture for Mayo Clinic and its partners, one powered by the goal of longer, healthier lives for patients, and how AI is also changing Mayo Clinic’s research and the education it provides, including the offering of masters and PhDs in AI and other emerging technologies.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE:&lt;/strong&gt; “In US healthcare, quality ratings are increasingly used to tie the improvement in patient health outcomes to the reimbursement rates that healthcare providers can receive. The ability of GPT-4 to understand these systems and give concrete advice … has a chance to make it easier for providers to achieve success in both dimensions.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 7, “The Ultimate Paperwork Shredder.” &lt;/p&gt;



&lt;p&gt;Public health officials and healthcare system leaders influence the well-being and health of people at the population level. They help shape people’s perceptions and responses to public health emergencies, as well as to chronic disease. They help determine the type, quality, and availability of treatment. All this is critical for maintaining good public health, as well as aligning better health and financial outcomes. That, of course, is the main goal of the concept of value-based care. AI can definitely have significant ramifications for achieving this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Joining us today to talk about how leaders in public health and healthcare systems are thinking about and acting on this new generation of AI is Dr. Umair Shah and Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Umair Shah is a nationally recognized health leader and innovator. He led one of America’s top-rated pandemic responses as Washington State’s secretary of health, a position he held from 2020 to 2025. Umair previously directed Harris County Public Health in Texas, overseeing large-scale emergency response for the nation’s third-largest county, while building an emergency-care career spanning 20-plus years. He now advises organizations on health innovation and strategy as founder and principal of Rickshaw Health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Gianrico Farrugia is the president and CEO of Mayo Clinic, the world’s top-ranked hospital for seven consecutive years, and a pioneer in technology-forward, platform-based healthcare. Under his leadership, Mayo has built and deployed the Mayo Clinic Platform. The platform enables Mayo and its partners to gain practical insights from a comprehensive repository of longitudinal de-identified clinical data spanning four continents. Gianrico is also a Mayo Clinic physician and professor and an author.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Umair and Gianrico are CEO-level leaders representing some of the best of the worlds of public health, healthcare delivery, medical research, and medical education.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here is my interview with Dr. Umair Shah:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Umair, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;UMAIR SHAH:&lt;/strong&gt; Peter, it’s my pleasure. I’ve been looking forward to this conversation, and I hope you are well today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] I am doing extremely well.&lt;/p&gt;



&lt;p&gt;So, you know, what I’d like to do in these conversations is first just to start, a little bit about you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You served actually during a really tumultuous time as the secretary of health in the State of Washington. But you recently stepped away from that and you started your own firm, Rickshaw Health. So can we start there? What’s that all about?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, no, absolutely. First of all, you know, I would say that the transition from Texas to Washington could not have been more geopolitically different, [LAUGHTER] as you can imagine.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, if you like the red-blue paradigms, you couldn’t be more, you know, red and you couldn’t be more blue, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But what happened is, back in November this past year, as I saw some of the playout of continuation of this red-blue dynamic, I made the decision to step down. And Jan. 15, I stepped down, as you mentioned, and I spent some time really thinking about what I wanted to do next and was looking at a number of opportunities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then a moment in time, there were some things happening in our—my wife and our family’s personal lives that sort of made me think that I wanted to focus a little bit more on family. And I felt the universe was saying, “Stay still.” [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I launched Rickshaw Health&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and the notion that, as you know, Peter, rickshaws are oftentimes known across the globe as these modes of transport that reliably get you through ever-changing streets and traffic patterns and all sorts of ecosystems that are evolving at all times. And they get you to the other side and they get you also with a sense of exhilaration. Like when I took my boys to Karachi, and we were—you know, they jumped in a rickshaw and the, you know, open air [LAUGHTER] and they felt this incredible excitement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so Rickshaw Health was speaking to the three wheels of a rickshaw that symbolize the three children that we have and the real notion of how do we bring balance and agility and performance to the forefront and then move in an ever—just like streets—ever-changing healthcare environment that is constantly evolving, and we too must evolve with it. And that’s what Rickshaw Health is all about, is taking clients to that next level of trying to navigate, especially at this time, a very, very different landscape than even several months ago. So, excited about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, absolutely. You know, you made this transition from Texas to the State of Washington. And for people who listen to this podcast and don’t know, the particular part of Texas where you were—Harris County—is &lt;em&gt;really big&lt;/em&gt;, very, very important in that state. That’s just not, you know, the normal county in Texas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s actually … it’s actually known as quite a forward-looking place, technologically.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So what was, you know, the transition like, then, going from, you know, possibly the most, sort of, maybe advanced county in the State of Texas, a large place, to the State of Washington?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, you know, Harris County is the third-largest county in the US. So it had close to five million. And now it’s probably … it’s exceeded the five million people, and a very diverse, very forward-looking, as you mentioned, technologically very, very much looking at what’s the next horizon, and home to Texas Medical Center [TMC] as well, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… the largest medical center. Of course, it had to be Texas. So it can’t be the largest in the state or the country [LAUGHTER]—the largest in the world, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And TMC also had a number of different initiatives related to startups and venture capital and VC. And so they had launched something called TMCX. And that was a real opportunity—and I know you’re familiar with it—an opportunity to really look at how do you incubate all sorts of different innovations and bringing private sector, public sector as well as healthcare delivery alongside these startups to really look at the landscape.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when I left Houston and came to Washington, I realized that obviously, I was in the backyard … I mean, you know, you all at Microsoft Research and the work that you’re all doing is part of an ecosystem of advanced innovation that’s occurring in the Pacific Northwest that, you know, when we see all the players that are here, all the, you know, ones that do so many different things, but they’re doing them with an eye towards technology, advancements, and adoptions, it’s been quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When I made that transition, it was really about, you know, the vaccines and what was happening with, you know, with COVID and fighting the—you know, remember, this was the state that had the first case in the continental United States, had the first outbreak, and the first [lab-confirmed] death. And fast-forward a few years later, we had the fifth-lowest death rate in the US. And that was because we all came together to do so much.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, well maybe that gets us into a question that I ask a lot of our guests, which is, you know, and maybe let’s, since we’re on your time as the secretary of health in Washington State, [start] with that job. I ask, how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; [LAUGHS] I laugh because that’s been such a fascinating conversation in public health because we have oftentimes been—it’s been really hard to describe what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And, you know, there are so many metaphors and, you know, analogies that we’ve used. I’ve always wondered why we do not have more television shows or sitcoms or dramas that are about the public health workforce or the work that we do in the field, because you have, you know, all sorts of healthcare delivery ones, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As a practicing physician for 20 years, I realized that people knew what doctors did; they knew what nurses did, right. They intimately touch the healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; They understood, you know, that an ambulance picks you up at your home or somewhere else, transports you … gets you to the emergency department. The emergency department, they do some things to you or within the four walls of that ER, and then you’re either admitted, sent home, and several days, weeks, whatever later, you get home if you’re admitted, and you start your, you know, post-hospital stay at home or your rehab or what have you. And that all is known to people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But when you ask your mother, your grandmother, or your, you know, your uncle, or your brother, your neighbor, your coworker about what is public health, they have a very quizzical look on their face of what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so what I’ve …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, just one thing I’ve learned is: it’s not just all the people you mentioned. Even healthcare professionals sometimes have that quizzical look.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, good point. That’s right. Good point. And a lot of it is because we don’t get exposed to it or trained in it. You know, we think about public health when we’re in our training. And, you know, I’m sure you had a very similar piece of this is that, you know, you see it as, oh, that’s the health department that takes care of, you know, STDs, or it takes care, you know, it does the immunizations, or, you know, maybe they do some water quality, or maybe they do mosquitoes [mosquito control], and things like that. But the reality is, we do &lt;em&gt;all&lt;/em&gt; of those things and more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my metaphor has been that we are the offensive line of a football team, and the healthcare delivery is the quarterback. So everybody focuses on, you know, from a few years back, everybody knows Tom Brady, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; He won the Super Bowls, everybody knows what … but if you asked people who was number 75 on the offensive line of the New England Patriots …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or name your favorite football team. And the answer would be: you would not be able to likely answer that question. You would know Tom Brady, the quarterback, and that’s healthcare delivery, the ER doc or the hospitalist or the nurse or the, you know, the medical assistant, or the people that are doing all the work in the field that are the ones that are more visible, but the invisible workforce of the offensive line, that’s who we don’t know. And yet these are the people that are blocking and sweating and doing all things to complement the work and make sure the quarterback is successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And here’s where the metaphor breaks down, that when Tom Brady wins the Super Bowl, we continue to invest in the offensive line because we recognize the value of it and we want the quarterback to be successful the next season. But in public health or in society, we do the exact opposite.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When tuberculosis rates come down, we say, well, you know what? We’ve solved the problem; we don’t need it anymore.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Or you have another, you know, environmental issue that’s no longer there, you say, “We don’t need it anymore.” And we &lt;em&gt;disinvest&lt;/em&gt; from public health or that offensive line. And then you start to see those rates go back up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so my answer to Mom and Grandma and Dad and Grandpa is we are &lt;em&gt;critical&lt;/em&gt; to your health because we touch you every single day. And so please invest in us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. And, you know, I think I’m going to want to get a little deeper on that in just a few minutes here, because, I think especially during the pandemic, that issue of not understanding the importance of that offensive lineman actually really came to the forefront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’d like to get into that. But the, kind of, second, kind of, standard thing I’ve been probing with people is still just focusing on you and your background is what touchpoints or experiences you’ve had with AI in the past.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And not everyone has. Like, it maybe isn’t too surprising that doctors and healthcare developers, tech developers, have lots of contact with AI, but would the top dog, you know, at a public health agency ever have had significant contact with AI? What about you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, it’s interesting. Several years ago, I was in the audience with the [then] FEMA director, [Rich Serino], who just did such an incredible job. And I remember he made this comment at that time. And, Peter, this may have been like … I don’t know—I’m dating myself—10, 15, maybe even 20 years ago, and he said, “Everybody in the audience, there’s this, you know, app called Twitter.” And, you know, “How many people in the audience have ever sent a tweet or know about this?” And I don’t know, maybe—it was a public health audience—maybe about 15% of the people raised their hands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He said, “I challenge you to right now, pick up your phone, download the app, and go ahead and send a tweet right now.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember I sent my first tweet at that time. And it was so thought provoking for me was that he was saying you need to be engaged in social media, but the other 85% of the audience had not even done that or had …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … even understood the importance of social media at that time. Or maybe they understood, but they had restrictions on how to utilize, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that has stayed with me because that’s very much about this revolution of AI that I know that public health and population health practitioners like myself who have been in the trenches and understand the importance of it, they really believe in the importance or think they know the importance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But NACCHO, the National Association of County and City Health Officials, had done a survey of local health agencies. And about two-thirds, if not three-quarters, of local health agencies reported that they had an AI capacity that was low or lower than ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And that is very much where I come from. When I was in public sector and at the state health agency, our transformation was very much about how do we advance the work, and how do we utilize this in a population health standpoint?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was fortunate to have a chief of innovation at Washington State Department of Health, Les Becker, who understood the value of AI. And as you know, we did also hold a AI science convening that …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … your team was there with University of Washington. And that was really an opportunity for us to say that AI is here. It’s not tomorrow. It’s not next year. It’s not the future. It’s already here. We need to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But here’s the problem, Peter, far too few people in our field understand just how to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; So I have become a markedly more champion of AI. One, since I read your book. So I think there’s that. So thank you for writing it. But two, since I really recognize that when I became a solo or a primary-few practitioner in my own realm, I needed to force-amplify the work that I was doing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when I look back, and I continue to stay in touch with my colleagues in the field of public health, what they’re also struggling with is that you have an epidemiologist who’s got a mound of information—data, statistics, etc.—that they are going through, and they’re doing everything in their power to get that processed and analyzed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; AI can take 80% of that and do it. And that epidemiologist can now turn to more of an overseer and a gatekeeper and to really recognize the patterns …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and let AI be able to do the, you know, grunt work. And similarly, as you know, measles—with the outbreaks that we’ve seen, especially in Texas but elsewhere—you’ve got an opportunity where our communications people who are saying, “Look, we’re about to have, or we know we’re about to announce that there’s a measles outbreak in, you know, in our community or our state or what have you—our region.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they can have AI go through different press briefings and/or press releases and say, “Give me the state of the art on how I should communicate this message to the community.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And bam! You can do that. And now you can oversee that work, as well. And then the third example is that we are always looking at how do we find ways to have a deeper connection with those who come to our, you know, our websites or come to our engagement tools—with bots and things like that. AI can really accelerate that work, as well. So there’s so many use cases that AI has for population health or public health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But I think the challenge is that we just don’t have enough adoption because they’re … one, we’ve had funding cuts, but two is that there is this real hesitation on, what is it that we can do? And I argue—the last thing I’ll say about this, Peter—is that I argue that AI is happening right now. The discussions, the technology advancements, the work, the policy work, all that’s happening right now. If public health practitioners are not at the table, if they’re not part of the, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … “What does this look like? How does it work in our field?” … guess what? It’s going to be done &lt;em&gt;to&lt;/em&gt; us and &lt;em&gt;for&lt;/em&gt; us rather than with us. And if we do not get with that and get to the table, then unfortunately it may not be exactly what we want it to be at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I find it really interesting that you are using the terms “public health” and “population health” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… pretty much interchangeably here. And I think that that’s something that I think touches on an assumption that was both implicit and explicit in the book that we wrote, which is: we were making some predictions that our ability to extract insights and knowledge from population health data would be enhanced through the use of AI. And I think that it looks to me like that has been more challenging and has come along more slowly over the past two years. But what is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, I think part of, and I think you and I have had this conversation, you know, in bits and pieces. I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Right? That’s, it’s …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes, that’s right. That’s right. You know, I think that’s a really good point. And, you know, when you look at sepsis or you look at pneumonia or try to figure out ways that, you know, radiologists or x-rays or CT scans can be read, it’s, I mean, there are so many use cases that are within the healthcare sector. And I think that gets back to this inequity that we have when we look at population health or, you know, this broad, um, swath of land that is, oftentimes, left behind or unexplored, and you have healthcare delivery. Now, healthcare delivery we know gets 95 cents or 96 cents of every dollar. So it makes sense why, right. But we also know that, at the end of the day, we’re looking at value-based outcomes, and you cannot be successful in the healthcare delivery system unless we are truly looking at prevention and what’s happening in the community and the population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;And that’s why I use it interchangeably, but I know that “public health” has got a very specific term, and “population health” is a different set of ways of looking at the world. The reason that people try to shy away from pop health in essence is that you could talk about population health as being my population of patients in a clinic. It could be my health systems population. It could be an insurance company saying, these are the lives covered, right. So it becomes, what is population? When we think of public health, we think of the entirety of the population, right. In the State of Washington, eight million people. Harris County, five million people. Or in the US, 300—whatever the number of millions of people that—we think of the entire population. And what is it that actually impacts the health and well-being of that population is really what that’s about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Yet here’s the challenge. When we then talk to those of our partners and our colleagues in the tech field, there are two things happening. One is, there’s a motivation because of the amount of dollars that are in [the] healthcare sector. And number two is, because it’s more familiar, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so there are very few practitioners similar to me that are out there, that are in the pop health who kind of know healthcare delivery because they’ve also seen patients, but they’re also—they worked at that federal, state, local level, community level—they’ve, you know, they’ve done you know various different kinds of environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they say, “Look, I’ve got a perspective to really help a tech company or somebody see the rest of it,” but you have to have both partners coming together to see that. And I think that’s one of the real challenges that we have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so now I’m going to want to go into specific problems, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe COVID is a good thing to focus on—the breadth of problems that had to get solved in pandemic response and where the gaps between healthcare delivery and public health were really exposed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first problem that I remember really keenly that just seemed so vexing was understanding where the PPE was, the &lt;em&gt;personal protective equipment&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;and where it needed to be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so that turned out … you would think just getting masks and gowns and gloves to the right places at the right times or even understanding where they are so that, you know … and being able to predict, you know, what hospitals, what clinics are most likely to get a big influx of patients during the height of the pandemic would be something that would be straightforward to solve, but that turned out to be an extremely difficult problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But how did it look from where you were sitting? Because you were sitting at the helm having to deal with these problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, we were constantly chasing data and information. And oftentimes, you know, because a lot of these data systems in the public health sector have been underinvested in over the decades, then, you know, you had our biggest emergency crisis of our time, and a lot of public health agencies were either getting, you know, thrown a whole host of resources or had to create things on the fly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And whether that was at Harris County or in the State of Washington, I will tell you that what I saw was that, you know, a lot of agencies across the country were still using fax machines, you know, to get data that were coming in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember actually—it’s kind of a funny story—there was a fax machine that was highlighted down in our agency in Texas. And we actually had this fax machine, had mounds of, you know, data … sorry, &lt;em&gt;papers&lt;/em&gt; that were next to … &lt;em&gt;faxes&lt;/em&gt; that were coming in and all these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would have, you know, &lt;em&gt;Mr. Peter Lee&lt;/em&gt; listed as a patient. And then the next, you know, transmission would have &lt;em&gt;Pete Lee&lt;/em&gt;. And then the next transmission would have &lt;em&gt;Peter Lee&lt;/em&gt;, but instead of L-E-E, it was L-E-A-H or something, or L-I or something, right. And it was just …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or you had a date of birth missing, or you had, you know, an address that was off. And what we realized is that over time, a lot of the data that were coming in were just incomplete data, and being able to chase that was really hard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, I think AI has that potential to really organize it, and to stratify it, and to especially get you to a point of at least cleaning it up. So I don’t think it’s just that AI … AI doesn’t just save &lt;em&gt;time&lt;/em&gt;; it saves &lt;em&gt;lives&lt;/em&gt;. Truly used …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… that’s, I think, where we’re talking here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when you have PPE and things of that nature, as you talked about, here in the State of Washington or what we were trying to do to get vaccines out or everything we’re doing to try to get communication messages to the public. And we did a fantastic job of that, although not ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are so many things that I could point to that we could have done better—all of us in the field of public health and healthcare delivery alike.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will tell you that the one thing that stays with me is that if we had those tools &lt;em&gt;then&lt;/em&gt;, and we had them in place &lt;em&gt;then&lt;/em&gt;, and we had invested in them at that time in advance of, I think there was a real opportunity for us to be able to move ahead and even be better at how we affected the health outcomes of the very populations that we were trying to get to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s [that] AI allows us to shift from reactive to proactive systems, catching health issues before they escalate and allow us to really communicate with empathy &lt;em&gt;at scale&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And when we can do those things, whether it’s opioids or whether it’s, you know, something that’s happening related to an infectious disease, or, you know, even this, the new agenda with &lt;em&gt;Make America Healthy Again&lt;/em&gt;—which by the way, as you know, we had a &lt;em&gt;Be Well, WA&lt;/em&gt; … &lt;em&gt;Be Well,&lt;/em&gt; &lt;em&gt;Washington&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … very much that was about, you know, looking at, you know, physical health and nutritional health and emotional well-being and social connectedness—that there is a real opportunity for us to address the very drivers of ill health. And when we can do that, and AI can help us accelerate that, I think we truly have the ability to drive down costs and increase the value that’s returned to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;What is your assessment of public health agencies’ readiness to use technology like AI? Because if there’s one thing AI is good at, it’s predicting things. Are they [public health agencies] in a better position to predict things now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, I think it’s a tale of two cities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think on the one hand, we’re better because we have the tools. On the other hand, we’ve lost the capacity to be able to utilize those tools. So, you know, it’s a plus and a minus.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many, many years ago, there was the buzzword of what we called &lt;em&gt;syndromic surveillance&lt;/em&gt;. And, Peter, you know this term well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was like you would have, you know, a whole host of accumulation of data points in, let’s say, a hospital setting or an emergency department …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup. Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… where, you know, you’d have runny nose, you’d have cough, you’d have a fever, and you would take that, what was happening and people presenting to the emergency department, with what was happening in the area pharmacies where people were going to get Kleenexes and tissues …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and buying over-the-counter, you know, medication, and things of that nature, Tylenol, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would say … you would put those two things together, and you would come up with a quote-unquote “syndrome,” and you would say our ability to say there was an alert to that syndrome allows us to say something&lt;em&gt; uh-oh&lt;/em&gt; is going on in the community, and we got many, many advancements related to wastewater surveillance over the last several years as you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep. Yep. Well, also, wasn’t patient number one in the United States discovered also because of the Seattle Flu Study, or at least that sort of syndromic surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;They weren’t even looking for COVID. They were just taking, you know, snot samples from people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right. That’s right. That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that’s the kind of thing that you, you know, we underappreciate. Is you have to have a smart, intelligent, agile practitioner, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if I think about down in Dallas when Ebola was, you know, the gentleman who was, you know, the index case for Ebola was sent out of the emergency department and came back several days later.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it was the nurse who picked up this time because the practitioner, the provider, the healthcare provider, the doc missed it. And I wouldn’t want to say in a negative way. It was just, like, not obvious. You aren’t thinking of Ebola in the middle of Texas. And it was the nurse who picked up: &lt;em&gt;there’s something wrong here&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what AI has the ability to do is to pick up those symptoms …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or those patterns and be able to recognize the importance of those and be able to then alert the practitioner. So what I … we call it &lt;em&gt;artificial intelligence&lt;/em&gt;—it almost becomes artificial wisdom.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah, interesting. So that actually reminds me of my next question, which is another thing that I watched you and public health officials do is try to play “what if” games.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, I think one decision you were involved in had to do with, you know, what would be the impact if we put a ban on large gatherings like concerts or movie theaters or imposed an 8 PM curfew on restaurants, and you were trying to play “what if” games. Like, what would be the impact on the spread of the pandemic there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So now, again, today with AI, would that aspect of what you did play out differently than it did during the pandemic?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As you know, COVID was the most studied condition on the planet at one point. And it was, you know, things that usually we would learn over years or months, we were learning in weeks or days or hours.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember in Houston, I would say something in the morning, and I would always try to give the caveat, “This is the best information we know right now,” because it kept changing, whether it was around masks or whether it was around, you know, the way the virus was operating, whether it was around …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I remember even … I was just watching something recently where I was asked to comment about whether spiders could transmit COVID-19. You know, just questions that were just evolving, evolving, evolving. And the information was evolving. By morning, you would say something. By evening, it would change.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And why I say that is that it would have been great in the pandemic if we could have said, if you could give us all the information that’s happening across the globe, synthesize that information, and be able to help us forecast the right decisions that we should be making and help us model that information so we could decide: if you did a curfew, or if you did, you know, a mask, or if you could, you know, change something else related to policy—what are the impacts of it?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;What we found constantly in public health was that we were weighing decisions in incomplete data, incomplete information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So great now that everybody can armchair quarterback looking back three, five years ago and say, “I would have done it this way,” or “I would have done it that way.” Gosh, I would have as well. But guess what—we didn’t have that information at that time. And so you had to make the best decisions you could with incomplete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what AI has the potential to do is to help &lt;em&gt;complete&lt;/em&gt; the incomplete data. Now, it’s not going to get 100%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And I think, Peter, you know, the one thing we’ve got to be really mindful [of] is phantom information, or information where it sort of makes up things, or may somehow get you incomplete information, or skews it a certain way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is why we can’t take the person out of it yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Now, maybe one day we can.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m not one of those Pollyanna-ish that people will never be replaced. I actually believe that those people who are skilled with AI and the tools will eventually have a competitive advantage over those who are not. Just like if I had a physician who knows how to use their smartphone or knows how to use a word processor or knows how to do a PowerPoint presentation is going to replace the ones that use scantrons …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or the ones that write it on pieces of paper—that eventually it makes it more efficient and effective, but we’re not there yet. But I think that the potential is &lt;em&gt;absolutely&lt;/em&gt; there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I have one more question. And you can, kind of, tell I’m trying to expand people’s understanding of just the incredible breadth of what goes on in public health, you know, all of these sorts of different issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And again, just sticking to COVID, but this is a much broader issue. Another thing you had to cope with were significant rise of misinformation …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe going along with that, very, very significant inequities in outcomes in the COVID response. And when you think about AI there, I think you can argue it both ways, that it both exacerbates the problem but also gives you new tools to mitigate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; I think you … I don’t even have to say it … I think you hit on it, is that, you know, it really is two sides of one coin.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the one hand, it has the power of really advancing and allowing us to move forward in a way that incredibly accelerates and accentuates, but on the other hand, in the case of inequities, right? So if you have inequitable information data that’s already out in the literature or already out in the, you know, media, or what have you, about a certain population or people or certain kinds of ideas or thoughts, etc., then AI will tend to accumulate that. You’re going to take that information, thinking that’s the best out there, but it may have missed out on information and now you go with it. And that’s a potential problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s the same thing on information is that when we have people that are able to classify or misclassify information, I think it really becomes hard because it can accelerate the inequities of trust or inequities of trusted sources of information. It can also close the gap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think, you know, it’s really up to us and this responsible AI to really think about how we can go about doing this in a way that’s going to allow us to further the advancements but also be careful of those, you know, those kind of places where we’re going to step into that are not going to be well received or successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, the one thing that’s really fascinating about this whole conversation is that this is why we’ve got to be at the table, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Because if we’re not at the table, you know, what’s the, you know, or if tech companies that are out there doing this work and aren’t even seeing a field of practitioners that are actually wrestling with the same problems but just cannot actually get to the solutions, we’re just going to continue to accentuate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I’m a firm proponent of: we’ve got to be at the table.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so even when we’ve seen in, and this is going to be a little controversial, but governmental spaces where, you know, policymakers have said, “Look, we are not going to let you do certain things,” or they say to public health practitioners or even healthcare delivery practitioners in certain spaces, “You cannot even play with this. You cannot have it on your phones. You can’t do any … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, what I really believe it does is that it takes [an] almost like we put our head in the sand type of approach rather than saying, “What is it that we can do to help improve AI and make it work for all of us?” What we’re doing is we’re essentially saying, “We’re going to let the tech companies and all the other developers come up with the solutions, but it’s not going to be informed by the people in the field.” And that’s dangerous. We have to do both. We have to be working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Umair, that’s really so well said, and I think a great way to wrap things up. I’ve certainly learned a lot from this conversation. So thank you again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; It’s been a pleasure to be with you this morning. Thank you so much for the time. And I’m looking forward to further conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;I live in the State of Washington and because of that, I’ve been able to watch Umair in action as our state’s former secretary of health. And some of that action was pretty intense to say the least because his tenure as secretary of health spanned the period of the COVID pandemic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, as a dyed-in-the-wool techie, I have to admit that at the beginning, I don’t think I really understood the scope and importance of the field of public health. But as the conversation with Umair showed, it’s really important and it is arguably both an underfunded and underappreciated part of our healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, public health is also very much an area that’s ripe for advancement and transformation through AI. As Umair explained in our discussion, the core of public health is the idea of population health, the idea of extracting new health insights from signals from population-scale data. And already we’re starting to see AI making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now here’s my interview with Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Gianrico, it’s really great to have you here today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GIANRICO FARRUGIA:&lt;/strong&gt; Peter, thanks for having me. Thanks for making me part of your podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, what I’d like to do in these conversations is, you know, we’ll definitely want to talk about the overall healthcare system, the state of healthcare, and what AI could or might do to help or even hurt all of that. But I always like to start with a sharper focus just on you specifically. And my first question always is, you know, I think people imagine what a hospital or a health system president and CEO does, but not really. And so how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So, Peter, my mother’s 88 years old. She lives in Malta, and she’s visiting at the moment, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … which is kind of nice, really.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that is amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;I’m proud that she’s still proud of me. So she does ask. I’ll tell her the scope of Mayo Clinic. We serve patients across the globe. We have about 83,000 staff members that work with us, and we’re very proud of the work we do in research, education, and the practice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mayo Clinic is built to serve people with serious disease. So what I tell my mother is that here we are. We’re a healthcare organization that knows what it needs to do: keep patients as the North Star. The needs of the patient come first. We have 83,000 people who want to do that, several thousand physicians and scientists. My job is to look slightly ahead and then share what I’m seeing and then, sort of, smooth the way for others to make sure Mayo remains true to its mission but also true to the fact that at the moment, we are in a category of one. We need to remain there not just from an ego standpoint, but really from a “do good to the world” standpoint.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At that point, invariably my mother will tell me that I’m working too hard. [LAUGHTER] And then of course, I change the subject, and I ask her what she cooked today because my mother, who’s 88, cooks for the whole family in Malta, and there are usually four generations eating around the table. So I tell her what she does for the family is what I do for the Mayo family.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow, that’s a great way to put it. And it sounds like you actually have a good chance to have some good genes if she’s still that active at age 88.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think I chose a little more stressful job that may limit [that]. I will tell you very briefly is that one of the AI algorithms we have estimates biological age from an electrocardiogram. My biological age jumped by 3.7 years when I became CEO.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] Oh no.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I’m hoping it will reverse on the other side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;To stick with you just for one more moment here, second question I ask is about your origin story with respect to AI. And typically, for most people, there is AI before ChatGPT and generative AI and then after the generative AI revolution. So can you share a little bit about this? Because it must be the case that you’ve been thinking about this a long time since you’ve really led Mayo Clinic to be so tech forward in this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Well, I’ve been, as you said, a physician for way too long. I got my MD degree in ’87. So that sort of dates me. But it also means that I saw a lot of the promise for AI that never seemed to pan out for decades and decades and decades like you did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Around 10 years ago, Mayo could sense that there was something different, that something was changing, that we actually—at that time, predictive AI—could make a big difference. And I think that’s the moment where I and others jumped in and said Mayo Clinic needs to be involved.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then about six years ago, when—six and a half years ago—I became CEO, it was clear that there was the right confluence of data, knowledge, tech expertise, that we could deal with what was increasingly bothering me, which is that we knew what was coming from a technology standpoint and we knew the current healthcare system could not deliver on what patients need and want within that current system. And so the answer is, how could a place like Mayo Clinic with our reputation not jump in and say there has to be a better way of doing things? I’ve always said that it is impossible for me to understand that every single government employee is incompetent. Every physician is greedy. Something’s wrong here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And that wrong was the architecture was wrong. And we knew that we could incorporate AI and make it better. So for me, that journey was one of &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;. 10 years ago, begin to jump in. Six years ago, really jump in with our platform. And then, of course, in November 2022, things changed again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. When did this idea of a data platform, what you now call the Mayo Clinic Platform&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;—by the way, I refer to this as &lt;em&gt;MCP&lt;/em&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, I know. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] … which I always smirk a little bit because, of course, for those of us in computer science research, the AI research, &lt;em&gt;MCP&lt;/em&gt; has also become quite a hot topic because of the model context protocol version of this. But for Mayo’s MCP, when did that become a serious, defined initiative?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So around the end of ’18, 2018, beginning of 2019. At that point, we knew that we were going to do something differently. We came up with a strategic plan, as I took on the job, that we needed to cure more patients. There’s just not enough cures in the world. There’s too much suffering. And that we had all these chronic diseases that people have accepted are chronic, but really the only reason that disease is chronic is you haven’t cured it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And physicians have been afraid to talk about cure because, of course, eventually everybody passes away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But I really pushed hard to say, no, it’s OK to talk about cure. It’s OK to aspire to cure. The second was connect—connecting people with data to create new knowledge. And that’s where it became clear that data were not currently in a format that were particularly useful. By the way, you’ll hear me talk about &lt;em&gt;data&lt;/em&gt; in the singular and the plural. I’m old school. I talk about &lt;em&gt;data&lt;/em&gt; as plural, but I know that most younger people now use &lt;em&gt;data&lt;/em&gt; singular. [LAUGHTER] And I apologize if I’ll go through that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then the third was transform. Let’s use Mayo’s resources to transform healthcare for ourselves and for others. And that’s the concept of, if we are able to use data in a different way, let’s create a different architecture. And that architecture had to be very closely linked to using artificial intelligence in order to create better outcomes for patients. So patients can live not only longer lives but healthier lives. And that’s the genesis of MCP, &lt;em&gt;Mayo Clinic Platform&lt;/em&gt;, so I’ll timestamp that as end of 2018, beginning of 2019.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m really wanting to delve in in this episode, in this conversation, you know, [into the] mindset of a health system or hospital CEO. And so you’re obviously thinking about, I guess, machine learning and predictive analytics and so on. What were the, kind of, like … in 2018, what were the outcomes that you were dreaming about from this? So if you had this thing, you know, what were the things that you were hoping to be able to show or, kind of, produce as results?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, I think all of us who work at Mayo Clinic, and this tends to be a bit sugary, but it’s true, strongly feel that we have a responsibility to leave the place better than when we started. And so the Mayo brothers, when they started, did two really important things. The first was that they created the first integrated healthcare system. And the second, they created the first unified record. And that record was, of course, paper at that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Part of that is to say, OK, what does it look like now versus how can we improve what we have if … it’d be blasphemy to say, let’s think of ourselves as the Mayo brothers, but let’s think of ourselves as reasonably smart people at Mayo Clinic, really lucky to be surrounded by very smart people with resources. What will we do? And so we said let’s not aim for the low-hanging fruit. Let’s aim to get at whatever you want to call it, the intractable knot, the hardest problem, and that is clinical care. Let’s improve clinical care. Yes, we can deal with burnout. Yes, we can deal with administrative burden. But let’s not focus on that. Let’s really create an architecture that allows us to tackle better clinical outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And by starting there, then everything flows from that. That it’s not really worth doing unless at the end of the day, people are experiencing better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so I know a very good colleague and friend of mine, John Halamka&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, you ended up hiring. I thought he was a very interesting choice because he is, of course, in terms of technology, quite deep and very expert, but he’s, I think, first and foremost, a doctor. And so I assume you must have had to decide what type of person you would bring in and what kinds of people you would bring in to try to create such a thing. What was your thinking around the choice of someone like John?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; It was one of the harder decisions. First of all, [I’m] a physician myself. We tend to want to maintain some control. And so now I am the CEO, [LAUGHTER] and I have to give this baby to somebody else. That’s very hard. Second is Mayo Clinic is really good because it is flat, and we run a lot by committee. But it also means that, therefore, you have to work really hard at change, and you cannot change by fiat. You have to change by convincing people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just … I’ve always made the point that the right change agent is a servant leader because that’s how change becomes embedded. But it also means you’ve got to have that personality, the Mayo personality. And it became clear when we interviewed [that] there were some people that were really hardcore tech; others that were passionate about social issues. But John really fit that of being, as you said, deep in IT but also himself very aligned with the Mayo Clinic values. It’s as if he was a Mayo Clinic physician even though he wasn’t.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that came together, and I felt, &lt;em&gt;we&lt;/em&gt; felt, that as we were hiring, that we could do it. And then we did something interesting. We paired John with a … we created the role of a chief medical officer for the platform, which was a longstanding Mayo Clinic physician. And so we brought them together so we could get the past and the present and the future working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m going to ask you about what has come out of this. But before that, let’s get back to this origin story. So now, all of that is being set up starting around 2018. But then, you know, in 2022, there is generative AI. Now you were already experimenting with transformers, starting with BERT out of Google there. So maybe that’s a couple of years earlier. But still, there has to come a point where things are feeling very disrupted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, so, you know, it really wasn’t. It, to me, was a relief because it gave this … we were feeling pretty good about what we’re doing. We were feeling a little impatient, but, in true Mayo fashion, were willing to, sort of, do everything, take its time, take it to the right committees, get the right approvals, and get it done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … because something as disruptive as that instantly became enabling at Mayo Clinic. And I’ll take … as I think about it with you and take a moment to think and reflect on it, I think there were a couple of decisions we made earlier on that really helped us. We made the decision &lt;em&gt;against&lt;/em&gt; the advice of any consulting firm to completely decentralize AI at Mayo Clinic six years ago. And we told our clinical department, you need to own this. You need to hire basic scientists in AI. We’ll help you by creating the infrastructure. We’ll help you by doing all the rest. We’ll have the compute. We’ll have the partners. You need to do this on your own. You need to treat this the same way as if a new radiological technique happened or a new surgical technique happened.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so there was a lot of expertise already present in a very diffused way that then we were able to layer on generative AI onto that. And we found a very willingness to embrace it. In fact, I would argue initially a bit too willing because as you know, we haven’t quite figured out what’s legitimate use, what’s not use.&amp;nbsp;We all learned together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But it was mostly energy, which is really interesting. It was mostly energy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. And, you know, it’s an amazing thing to hear because one common theme that we hear is that the initial reaction is oftentimes one of skepticism. In fact, I’ve been very open that even I initially had some skepticism. Was that not present in your mind or on your team’s mind at all at the beginning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So you’re asking a physician if they are skeptical about something. [LAUGHTER] Yeah. I wonder what the answer to that is. Absolutely. The first hallucination, the first wrong reference. Can you imagine if you write the grant and the wrong reference comes. As you know, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … earlier on when some references were being made up. So massive amounts of skepticism. But the energy was such there that the people [who] were skeptical were also at the same time saying, “Let’s do a RAG [retrieval augmented generation] to clean up those references. Let’s create …” We were experimenting with discharge summaries, but let’s use AI to police AI, and let’s see what’s going on. So there was more massive skepticism, but the energy was pushing that skepticism into a positive versus into a negative frame. Now, I say that summarizing in hindsight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Day to day, much more complicated than that. But overall, if you just … and remember, I had been at the World Economic Forum many years ago and had said, healthcare needs to run towards AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; If healthcare was perfect, we would wait. Healthcare is not perfect by any means, therefore let’s run and embrace AI. And, sort of, that mentality was part of who we were because at the same time, we were also saying the other thing, that we need to be the ones to lead validation. We need to be the ones that set the rules. We need to be participating in the creation of CHAI [Coalition for Health AI]&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We need to be participating as the [National] Academy of Medicine&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So people did feel that Mayo was being fairly responsible about it, but that urge to, the needs of the patient come first, was the driver that kept people wanting to say, “Not ready yet, but let’s make it ready.” And we now have 320 algorithms in the practice, and they run and we constantly are looking and seeing what else we can do to improve. But as you well know, things evolve and change. And we’re also looking and seeing which ones work and which ones don’t and which ones we have to work together on to make better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, of course Mayo has such a, you know, such a reputation and is so influential, but in the world of healthcare broadly, let’s just focus on the United States to start. How common is this experience? You know, so if you are at a meeting with fellow CEOs of hospitals and health systems, what is the attitude and what is the, kind of … how common is the approach to all of this?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think it’s more common now, but going back a few years, I think it’s fair to say that it was scary for people to know how it’s going to change things. Healthcare runs on very narrow margins. It’s very expensive. So your expenses and your revenue are both massive, and they are very close to each other. So anything that changes that balance is really scary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because it’s not like you have the opportunity to erode into a margin or get it right the second time. So I think that is what drove a lot of the initial hesitancy. Was, one, is lack of knowledge and, two, understanding that you didn’t have a lot of room to make a mistake.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; On the economics of this, when you are embarking on what I suspect is a very expensive initiative like Mayo Clinic Platform, how on earth do you justify that early on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So again, I’m trying hard to try and remember how things were versus how I think about them now. [LAUGHTER] It goes back to our history. Mayo has always invested in what it thinks is the right thing that is coming. And that’s how we’ve stayed where we are. So the investment really was having an open discussion: is this worth it for our patients? And once that discussion was over, then the board was saying, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we are lucky in that we have the size that we’re able to hire and absorb. We’re lucky in that the people [who] came before us have been financially astute, and one of our values is stewardship. And we’re lucky that we had a lot of patients at Mayo Clinic who were able to listen, be inspired by, and be willing to help support. And so that gave us the ability to build what we’re doing not only into the long-range plan but actually into the yearly plan. And so we built it into the yearly plan. We set up a center for digital health. We set up the platform. And then we set up the budgets to be able to do that. And the budgets came from assets we’ve had, assets that we would get as the year came by, and then from philanthropy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also had a really powerful calling card. And that’s one advantage I had, and that’s … and I’d been very open when I was speaking to other CEOs that would use it is that right at that very beginning, really, really in 2019, our cardiologists, both the researchers and the clinicians, had come together and had used electrocardiograms to create an AI algorithm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first one was for diagnosing from an electrocardiogram, which is very cheap, very easy to do, left ventricular dysfunction. That’s how hard the left part of the heart contracts. If it doesn’t do well, you get heart failure. And they were able to show that that algorithm was already making nurses better than the physician without the algorithm. And after that went on to show that you could do it from a single strip, really with an area under the curve for that single strip on a watch, that was as good as mammograms or pap smears. And so we already had that proof.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; That quickly then came into Mayo. We put it into it so that any patient now can benefit from it. And now there are, I think, 14 algorithms just from that same one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So we had a proof of concept thanks to those really far-seeing cardiologists that enabled things to happen a little faster and also, as I talked to other CEOs, enabled me to say, “This actually works. This is the path forward.” I have recently been vocal about also saying, we are at a point now where I believe that for some medical conditions, it is not right to not use AI to help treat them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that’s so interesting. So I think I want to get into another topic here, which is when you think about the use of AI and data, what are some of the results that maybe are top of mind for you or you think are particularly important? And if you don’t mind, I’d like to see if we can think about this not only in terms of results in terms of patient outcomes but in your other activities, core activities, like research, in the education mission, and then even in the broader impacts on the healthcare system. But maybe we start with on patient outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, they’re all linked, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; They’re part of the same ecosystem. We think of ourselves as three shields— research, education, and the practice—and that one goes into the other. So, as I said, we have about 320 AI algorithms from the practice. Some run on every patient; some run on some patients. And we have good evidence for what they do. So some specific examples, and then I’ll get into the transformer part of this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We have a program called CEDAR [Clinical Detection and Response (tool)], and like most other people, I like acronyms for things. [LAUGHTER] But what it is, in our hospitals with patient consent, we monitor vitals. We monitor in the patient room—not in the ICU [intensive care unit], in the patient room. We monitor all sorts of things. But there’s a camera in the room, and we have a team of intensivists—nurses and physicians—who do not have any patient responsibilities but are just monitoring the algorithms, and when the algorithms are predicting decompensation, they’re able to get into the room. And what we’ve shown, for example, with that algorithm, is we’ve shown we’ve decreased length of stay in the hospital, decreased transfers into the intensive care units, and interestingly, decreased mortality and morbidity, which is not easy to show. I talked about the electrocardiogram as a good example. Of course, everybody knows about the radiology things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’ve created … taken part of this and said, if we can do this in the hospital, why cannot we do it in patients’ homes? So being very active in looking after patients that would come to the ED, emergency room, would normally be admitted, and we say, no, here are the things we can give you. Go home if you want to, and we will safely look after you at your home. And we recently have been, looking at the last two years of data, been able to show that we’re also successfully able to give intravenous chemotherapy in patients’ homes because we can monitor; we can do all the things that we can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, with generative AI, that gave us many other opportunities. One biggest opportunity for me has always been digital pathology. When we see how pathology’s currently run with a glass slide, not much has changed …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … in many, many, many years, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And so really we have made a massive push to digitize pathology not just for us but for others. But talking about ourselves, we started by saying, it has to be very cheap to digitize. So we worked and created a company with partners called Pramana&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that allows us to digitize slides relatively cheaply using AI algorithms that can take away the dirt, the fingerprint. And so we end up with 21 million of our slides digitized, and that gives you now a massive opportunity. Worked with another company called Aignostics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to create a, what we call, Atlas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is an LLM that allows us to then build upon it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And we, a hundred and, I think, 120 years ago, invented frozen sections at Mayo Clinic. So what that is, is that while the patient’s still on the table, you can take a piece of tissue, look at it, and tell the surgeon the margins of what you’re trying to resect are clear or not. But as a result of that, because you have to hurry, you get no information as a surgeon about, is it an invasive cancer, is it noninvasive cancer, or other things. So we’ve just found a way to digitize our frozen section practice and will completely go across the enterprise with AI-enabled digitized frozen sections, which then enables us to then do it for anybody across the globe if we need to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in the genomic space, we’re working to create a true exomic transformer that is short range. And we originally started doing it to see if we can test it against the fact that 40% of people with rheumatoid arthritis don’t respond to the first-line therapy, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … but you have to wait six months to find out. And we found that we can actually do that. But it has much greater uses, of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we’re working with you—I don’t know how much you want to get into this, Peter, or [if] you want to talk about it yourself—MAIRA-2, which is really exciting, about how taking a simple problem—can you create a transformer that is able to detect if lines on the chest are in the right place, breathing tube is in the right place?—and then do it in a way that then can be used for many, many other things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, Peter, because you asked about education and research, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … imagine what this does now to the education system, right. And so we’ve got to train our physicians differently. We now have an AI curriculum for all our medical students. We offer masters and PhDs in AI. We think it’s essential for the people who want to be able to truly become experts, the same way I became an expert in my area of research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from a research standpoint, when you think about all the registries that exist in people’s labs, all the spatial genomics, all the epigenomics, all the omics that exist. And if you are able to coalesce them into one big, what we call, an &lt;em&gt;atlas&lt;/em&gt;, how that could really spur research at a scale that we haven’t thought of before. And so that is our aim at the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From a research standpoint, we are, with Vijay Shah, who’s our dean of research, is to say, let’s make the effort of making sure all the data are available to be able to use and enable for us to take advantage of AI. And that is not easy because, of course, people have collected the data. They tend to want to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;So there have to be the right incentives, the right privacy, and the right ways of doing it. And we think we’re on the way there, and we’re already seeing some advantages from doing it this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’re running short on time. And so I always like to end with one or two more provocative questions. And, you know, it’s tempting to ask you the provocative question of whether you think AI will ever replace human doctors, but I don’t want to go there with you. In fact, as I thought about our discussion, I was reflecting. We were at a conference together once, and I was on stage in a fireside chat. And then, you know, after the fireside chat, there were audience questions, and I don’t remember any of the questions from the audience except &lt;em&gt;yours&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And just to remind you, you know, I think when I was on stage, we were talking about a lot of practical uses of AI to, let’s say, reduce administrative burdens and so on in healthcare. But you got up and you, I won’t say you scolded me, but you more or less said, is it the right idea to use AI to optimize today’s somewhat broken healthcare system, or should we be thinking more boldly about, you know, a more fundamental transformation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so what I thought I would try to close with here is to hear what was really behind that question. You know, what were you trying to get me to think about when you asked that question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, darn your great memory [LAUGHTER]. Belated apologies … I probably should have …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It was by far the best and most sophisticated and, I think, thought-provoking question of all of the ones that came out of the audience.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; What I was trying to get to is actually trying to clarify it in my own head and then in the head of others is that we do not need to have a linear path to get to where we want to get to. And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. Let’s make their problems better, make them feel better about providing healthcare. And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, &lt;em&gt;no&lt;/em&gt;, is that let’s start with that aim, the last aim, and do the others because the others will come automatically if you’re working on that harder problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because one, to get to that harder problem, you’ll find all the other solutions. I was just trying to push that here’s this wonderful tool that’s been given to us. Let’s take advantage of it as quickly as we can. I think we had gotten a little too sensitized to need to say the right things. “Careful, be very careful” versus saying, “Massive opportunity. Do it right, and healthcare will be much better. Go for it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think I understand better now where the vision, insight, and frankly, courage to take on something as ambitious and transformational as the Mayo Clinic Platform and really all of your leadership in your tenure as the president and CEO of Mayo Clinic. I think I understand it much better now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gianrico, it’s just always such a privilege to interact with you and now to have a chance to work with you more closely. So thank you for everything that you do and thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Thank you for making it so easy, and thanks for giving us this opportunity to do good for the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Gianrico leads what is arguably the crown jewel of the world’s healthcare systems, and so I feel it’s such a privilege to be able to talk and sometimes even brainstorm with him.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our conversation, I think, exposed just how tech forward Gianrico is as he charts the strategies for healthcare delivery well into the future. And as I’ve interacted with many others, what I’ve learned is that this is a common trait among major health system CEOs. Roughly speaking, like we’ve seen in previous episodes where doctors and med students are polymath clinician-technologists, the same thing is true of health system CEOs and other leaders.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI in the mind of a health system CEO today is not only a technology that can transform diagnosis and treatment, but it’s also something that can have a huge impact on the business of healthcare delivery, the connection of healthcare to medical research, and the journeys that patients go through as they seek better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These two conversations show that virtually all leaders in health and medicine are confronting head-on the opportunities, challenges, and the reality of AI, and they see a future that is potentially very different than what we have today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’d like to thank Umair and Gianrico again for their time and insights. And to our listeners, thank you for joining us. We hope you’ll tune in to our final episode of the series. My coauthors, Carey and Zak, will be back to examine the takeaways from our most recent conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;








&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/</guid><pubDate>Thu, 07 Aug 2025 16:00:00 +0000</pubDate></item><item><title>GPT-5 is here. Now what? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/07/1121308/gpt-5-is-here-now-what/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/force-multiplied.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI’s flagship models and its o series of reasoning models, automatically routing user queries to a fast nonreasoning model or a slower reasoning version. It is now available to everyone through the ChatGPT web interface—though nonpaying users may need to wait a few days to gain full access to the new capabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s tempting to compare GPT-5 with its explicit predecessor, GPT-4, but the more illuminating juxtaposition is with o1, OpenAI’s first reasoning model, which was released last year. In contrast to GPT-5’s broad release, o1 was initially available only to Plus and Team subscribers. Those users got access to a completely new kind of language model—one that would “reason” through its answers by generating additional text before providing a final response, enabling it to solve much more challenging problems than its nonreasoning counterparts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt;&lt;p&gt;Whereas o1 was a major technological advancement, GPT-5 is, above all else, a refined product. During a press briefing, Sam Altman compared GPT-5 to Apple’s Retina displays, and it’s an apt analogy, though perhaps not in the way that he intended. Much like an unprecedentedly crisp screen, GPT-5 will furnish a more pleasant and seamless user experience. That’s not nothing, but it falls far short of the transformative AI future that Altman has spent much of the past year hyping. In the briefing, Altman called GPT-5 “a significant step along the path to AGI,” or artificial general intelligence, and maybe he’s right—but if so, it’s a very small step.&lt;/p&gt;  &lt;p&gt;Take the demo of the model’s abilities that OpenAI showed to &lt;em&gt;MIT Technology Review&lt;/em&gt; in advance of its release. Yann Dubois, a post-training lead at OpenAI, asked GPT-5 to design a web application that would help his partner learn French so that she could communicate more easily with his family. The model did an admirable job of following his instructions and created an appealing, user-friendly app. But when I gave GPT-4o an almost identical prompt, it produced an app with exactly the same functionality. The only difference is that it wasn’t as aesthetically pleasing.&lt;/p&gt; 
 &lt;p&gt;Some of the other user-experience improvements are more substantial. Having the model rather than the user choose whether to apply reasoning to each query removes a major pain point, especially for users who don’t follow LLM advancements closely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And, according to Altman, GPT-5 reasons much faster than the o-series models. The fact that OpenAI is releasing it to nonpaying users suggests that it’s also less expensive for the company to run. That’s a big deal: Running powerful models cheaply and quickly is a tough problem, and solving it is key to reducing AI’s environmental impact.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;OpenAI has also taken steps to mitigate hallucinations, which have been a persistent headache. OpenAI’s evaluations suggest that GPT-5 models are substantially less likely to make incorrect claims than their predecessor models, o3 and GPT-4o. If that advancement holds up to scrutiny, it could help pave the way for more reliable and trustworthy agents. “Hallucination can cause real safety and security issues,” says Dawn Song, a professor of computer science at UC Berkeley. For example, an agent that hallucinates software packages could download malicious code to a user’s device.&lt;/p&gt;  &lt;p&gt;GPT-5 has achieved the state of the art on several benchmarks, including a test of agentic abilities and the coding evaluations SWE-Bench and Aider Polyglot. But according to Clémentine Fourrier, an AI researcher at the company HuggingFace, those evaluations are nearing saturation, which means that current models have achieved close to maximal performance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s basically like looking at the performance of a high schooler on middle-grade problems,” she says. “If the high schooler fails, it tells you something, but if it succeeds, it doesn’t tell you a lot.” Fourrier said she would be impressed if the system achieved a score of 80% or 85% on SWE-Bench—but it only managed a 74.9%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the headline message from OpenAI is that GPT-5 feels better to use. “The vibes of this model are really good, and I think that people are really going to feel that, especially average people who haven't been spending their time thinking about models,” said Nick Turley, the head of ChatGPT.&lt;/p&gt;  &lt;p&gt;Vibes alone, however, won’t bring about the automated future that Altman has promised. Reasoning felt like a major step forward on the way to AGI. We’re still waiting for the next one.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/force-multiplied.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI’s flagship models and its o series of reasoning models, automatically routing user queries to a fast nonreasoning model or a slower reasoning version. It is now available to everyone through the ChatGPT web interface—though nonpaying users may need to wait a few days to gain full access to the new capabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s tempting to compare GPT-5 with its explicit predecessor, GPT-4, but the more illuminating juxtaposition is with o1, OpenAI’s first reasoning model, which was released last year. In contrast to GPT-5’s broad release, o1 was initially available only to Plus and Team subscribers. Those users got access to a completely new kind of language model—one that would “reason” through its answers by generating additional text before providing a final response, enabling it to solve much more challenging problems than its nonreasoning counterparts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt;&lt;p&gt;Whereas o1 was a major technological advancement, GPT-5 is, above all else, a refined product. During a press briefing, Sam Altman compared GPT-5 to Apple’s Retina displays, and it’s an apt analogy, though perhaps not in the way that he intended. Much like an unprecedentedly crisp screen, GPT-5 will furnish a more pleasant and seamless user experience. That’s not nothing, but it falls far short of the transformative AI future that Altman has spent much of the past year hyping. In the briefing, Altman called GPT-5 “a significant step along the path to AGI,” or artificial general intelligence, and maybe he’s right—but if so, it’s a very small step.&lt;/p&gt;  &lt;p&gt;Take the demo of the model’s abilities that OpenAI showed to &lt;em&gt;MIT Technology Review&lt;/em&gt; in advance of its release. Yann Dubois, a post-training lead at OpenAI, asked GPT-5 to design a web application that would help his partner learn French so that she could communicate more easily with his family. The model did an admirable job of following his instructions and created an appealing, user-friendly app. But when I gave GPT-4o an almost identical prompt, it produced an app with exactly the same functionality. The only difference is that it wasn’t as aesthetically pleasing.&lt;/p&gt; 
 &lt;p&gt;Some of the other user-experience improvements are more substantial. Having the model rather than the user choose whether to apply reasoning to each query removes a major pain point, especially for users who don’t follow LLM advancements closely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And, according to Altman, GPT-5 reasons much faster than the o-series models. The fact that OpenAI is releasing it to nonpaying users suggests that it’s also less expensive for the company to run. That’s a big deal: Running powerful models cheaply and quickly is a tough problem, and solving it is key to reducing AI’s environmental impact.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;OpenAI has also taken steps to mitigate hallucinations, which have been a persistent headache. OpenAI’s evaluations suggest that GPT-5 models are substantially less likely to make incorrect claims than their predecessor models, o3 and GPT-4o. If that advancement holds up to scrutiny, it could help pave the way for more reliable and trustworthy agents. “Hallucination can cause real safety and security issues,” says Dawn Song, a professor of computer science at UC Berkeley. For example, an agent that hallucinates software packages could download malicious code to a user’s device.&lt;/p&gt;  &lt;p&gt;GPT-5 has achieved the state of the art on several benchmarks, including a test of agentic abilities and the coding evaluations SWE-Bench and Aider Polyglot. But according to Clémentine Fourrier, an AI researcher at the company HuggingFace, those evaluations are nearing saturation, which means that current models have achieved close to maximal performance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s basically like looking at the performance of a high schooler on middle-grade problems,” she says. “If the high schooler fails, it tells you something, but if it succeeds, it doesn’t tell you a lot.” Fourrier said she would be impressed if the system achieved a score of 80% or 85% on SWE-Bench—but it only managed a 74.9%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the headline message from OpenAI is that GPT-5 feels better to use. “The vibes of this model are really good, and I think that people are really going to feel that, especially average people who haven't been spending their time thinking about models,” said Nick Turley, the head of ChatGPT.&lt;/p&gt;  &lt;p&gt;Vibes alone, however, won’t bring about the automated future that Altman has promised. Reasoning felt like a major step forward on the way to AGI. We’re still waiting for the next one.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/07/1121308/gpt-5-is-here-now-what/</guid><pubDate>Thu, 07 Aug 2025 17:00:00 +0000</pubDate></item><item><title>OpenAI’s GPT-5 is here (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/openais-gpt-5-is-here/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched GPT-5, a new flagship AI model that will power the company’s next generation of ChatGPT. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5, which was released Thursday, is OpenAI’s first “unified” AI model and combines the reasoning abilities of its o-series of models with the fast responses of its GPT series. The next-generation model signals a new era for ChatGPT — and its creator, OpenAI — pointing to OpenAI’s broader ambitions to develop AI systems that are more like agents than chatbots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While GPT-4 enabled AI chatbots to offer smart responses on a wide variety of questions, GPT-5 allows ChatGPT to complete a wide variety of tasks on behalf of users — such as generating software applications, navigating a user’s calendar, or creating research briefs. &lt;/p&gt;&lt;p&gt;With GPT-5, OpenAI has also sought to make ChatGPT simpler to use. Instead of asking users to choose the right settings, GPT-5 comes equipped with a real-time router that decides how to offer the best answer, whether that’s responding to user questions quickly or taking additional time to “think” through answers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035064" height="382" src="https://techcrunch.com/wp-content/uploads/2025/08/GPT5-All-Together-16x9-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;During a briefing with reporters, OpenAI CEO Sam Altman claimed GPT-5 is “the best model in the world,” and said it represented a “significant step” along the company’s path to developing AI that can outperform humans at most economically valuable work — that is, artificial general intelligence (AGI).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having something like GPT-5 would be pretty much unimaginable at any previous time in history,” said Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting Thursday, GPT-5 will be available to all free users of ChatGPT as their default model. OpenAI’s VP of ChatGPT, Nick Turley, said this is part of the company’s effort to give free users access to an AI reasoning model for the first time. (Previously, the company gated these more advanced models behind a paywall.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is just one of the ways that I’m excited to live the mission, making sure that this stuff actually benefits people,” said Turley on the decision, referencing OpenAI’s long-standing mission to distribute advanced AI to as many people as possible.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for GPT-5, one of OpenAI’s most anticipated product launches since ChatGPT put the company on the map in 2022. Since then, ChatGPT has grown into one of the world’s most popular consumer products, reaching more than 700 million users every week — nearly 10% of the globe’s population, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many see GPT-5 as a bellwether for AI progress broadly, and the model’s reception by Silicon Valley could have profound implications for Big Tech, Wall Street, and policymakers regulating technology. These stakeholders are watching to see if GPT-5 offers a significant jump in AI’s capabilities, much like its predecessor, GPT-4, which challenged expectations of what software can do.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-gpt-5-offers-a-slight-edge-on-the-competition"&gt;GPT-5 offers a slight edge on the competition&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI claims GPT-5 is state-of-the-art in several domains, slightly edging out leading AI models from Anthropic, Google DeepMind, and Elon Musk’s xAI on key benchmarks. However, GPT-5 slightly underperforms frontier AI models in other areas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says GPT-5 offers frontier-level performance around coding; Altman said the model specifically excels at spinning up entire software applications on demand, in what’s become known as “vibe coding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On SWE-bench Verified — a test of real-world coding tasks pulled from GitHub — GPT-5 scores 74.9% on its first attempt. That means GPT-5 just outperforms Anthropic’s latest Claude Opus 4.1 model, which scored 74.5%, and Google DeepMind’s Gemini 2.5 Pro, which scored 59.6%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Humanity’s Last Exam — a difficult test measuring AI model performance across math, humanities, and the natural sciences — a version of GPT-5 with extended reasoning (GPT-5 Pro) scored 42% when using tools. That’s slightly less than xAI was able to achieve with Grok 4 Heavy, which scored 44.4% on the test.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035062" height="450" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.56.46PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On GPQA Diamond — a test of PhD-level science questions — GPT-5 pro scored 89.4% on its first try, outperforming Claude Opus 4.1, which scored 80.9%, and Grok 4 Heavy, which scored 88.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5 is better for answering health-related questions. On a test measuring accuracy in AI model responses around healthcare topics, HealthBench Hard Hallucinations, OpenAI says GPT-5 (with thinking) hallucinates just 1.6% of the time. This is far lower than the company’s previous GPT-4o and o3 models, which scored 12.9% and 15.8, respectively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI chatbots are not medical professionals, millions of people are using them for health advice. In response to this phenomenon, the company says GPT-5 is more proactive about flagging potential health concerns and helping users parse medical results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, OpenAI says GPT-5 is better than other AI models on more difficult-to-measure, subjective domains, such as creative design and writing. Turley said GPT-5 responds more naturally and exhibits “better taste” than other AI models on creative tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The vibes of this model are really good,” said Turley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;GPT-5 is also more accurate than OpenAI’s previous models, and the company says it suffers far less from hallucinations — the tendency for AI models to make up information — compared to its o-series models. Hallucinations seemed to be getting worse in OpenAI’s latest AI reasoning models, such as o3, and OpenAI previously said it didn’t quite understand why it was happening.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In responses to ChatGPT prompts, OpenAI found that GPT-5 (with thinking) hallucinates and responds with incorrect information 4.8% of the time. That’s a significant reduction from o3 and GPT-4o, which score hallucination rates of 22% and 20.6%, respectively, on the test.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a benchmark measuring an AI model’s agentic ability to complete simulated online tasks, Tau-bench, GPT-5 offers mixed performance. On part of the test measuring an AI’s ability to navigate an airline’s website, GPT-5 scores 63.5%, slightly underperforming o3, which scored 64.8%. On another part of the test measuring AI’s ability to navigate retail websites, GPT-5 scores 81.1%, underperforming Claude Opus 4.1, which scored 82.4%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also says that GPT-5 is safer than its previous models. While AI reasoning models occasionally exhibit a tendency to scheme against humans or lie to promote their own goals, OpenAI found that GPT-5 was deceptive at a lower rate than other models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Beutel, OpenAI’s safety research lead, said reducing deception improves not only the safety of GPT-5, but also the user experience, creating a model that’s more “transparent and honest in ways users can trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beutel also notes GPT-5 is better at discerning between bad actors who are trying to misuse ChatGPT and users making harmless requests. This results in GPT-5 being able to refuse more unsafe questions, while offering fewer rejections to users seeking harmless information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-upgrades-for-consumers-and-developers"&gt;Upgrades for consumers and developers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is getting a few user experience upgrades as part of the GPT-5 launch. Users can now select from four new personalities in ChatGPT’s setting: Cynic, Robot, Listener, and Nerd. The company says these will adapt ChatGPT’s responses without requiring users to specifically ask the model to respond in a certain way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to ChatGPT’s $20-per-month Plus plan get higher usage limits for GPT-5 than free users. Meanwhile, $200-per-month Pro subscribers will have unlimited access to GPT-5, as well as a souped-up version called GPT-5 Pro that uses additional computational resources to produce better answers. Organizations on OpenAI’s Team, Edu, and Enterprise plans will gain access to GPT-5 as their default model next week.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For developers, GPT-5 is coming to OpenAI’s API in three sizes — gpt-5, gpt-5-mini, and gpt-5-nano — which will spend more or less time “reasoning” through tasks. Developers can also now control verbosity in the OpenAI API, deciding how long or short an AI model’s responses should be.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The base model of GPT-5 will cost developers $1.25 per million input tokens (roughly 750,000 words, longer than the entire “Lord of the Rings” series) and $10 per million output tokens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of GPT-5 comes after a busy week for OpenAI. The company released an open-weight reasoning model, gpt-oss, that developers and enterprises can download for free and run at a fraction of the cost. The open model nearly matched the abilities of OpenAI’s previous top models, o3 and o4-mini, but GPT-5 sets a new standard for frontier performance in some areas, such as coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, GPT-5 seems to be roughly on par with other frontier AI models in several areas. Benchmarks, of course, only tell part of the story for any AI model, and it remains to be seen how developers will use GPT-5 in the real world, and whether the model is truly a step above the competition.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched GPT-5, a new flagship AI model that will power the company’s next generation of ChatGPT. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5, which was released Thursday, is OpenAI’s first “unified” AI model and combines the reasoning abilities of its o-series of models with the fast responses of its GPT series. The next-generation model signals a new era for ChatGPT — and its creator, OpenAI — pointing to OpenAI’s broader ambitions to develop AI systems that are more like agents than chatbots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While GPT-4 enabled AI chatbots to offer smart responses on a wide variety of questions, GPT-5 allows ChatGPT to complete a wide variety of tasks on behalf of users — such as generating software applications, navigating a user’s calendar, or creating research briefs. &lt;/p&gt;&lt;p&gt;With GPT-5, OpenAI has also sought to make ChatGPT simpler to use. Instead of asking users to choose the right settings, GPT-5 comes equipped with a real-time router that decides how to offer the best answer, whether that’s responding to user questions quickly or taking additional time to “think” through answers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035064" height="382" src="https://techcrunch.com/wp-content/uploads/2025/08/GPT5-All-Together-16x9-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;During a briefing with reporters, OpenAI CEO Sam Altman claimed GPT-5 is “the best model in the world,” and said it represented a “significant step” along the company’s path to developing AI that can outperform humans at most economically valuable work — that is, artificial general intelligence (AGI).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having something like GPT-5 would be pretty much unimaginable at any previous time in history,” said Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting Thursday, GPT-5 will be available to all free users of ChatGPT as their default model. OpenAI’s VP of ChatGPT, Nick Turley, said this is part of the company’s effort to give free users access to an AI reasoning model for the first time. (Previously, the company gated these more advanced models behind a paywall.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is just one of the ways that I’m excited to live the mission, making sure that this stuff actually benefits people,” said Turley on the decision, referencing OpenAI’s long-standing mission to distribute advanced AI to as many people as possible.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for GPT-5, one of OpenAI’s most anticipated product launches since ChatGPT put the company on the map in 2022. Since then, ChatGPT has grown into one of the world’s most popular consumer products, reaching more than 700 million users every week — nearly 10% of the globe’s population, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many see GPT-5 as a bellwether for AI progress broadly, and the model’s reception by Silicon Valley could have profound implications for Big Tech, Wall Street, and policymakers regulating technology. These stakeholders are watching to see if GPT-5 offers a significant jump in AI’s capabilities, much like its predecessor, GPT-4, which challenged expectations of what software can do.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-gpt-5-offers-a-slight-edge-on-the-competition"&gt;GPT-5 offers a slight edge on the competition&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI claims GPT-5 is state-of-the-art in several domains, slightly edging out leading AI models from Anthropic, Google DeepMind, and Elon Musk’s xAI on key benchmarks. However, GPT-5 slightly underperforms frontier AI models in other areas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says GPT-5 offers frontier-level performance around coding; Altman said the model specifically excels at spinning up entire software applications on demand, in what’s become known as “vibe coding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On SWE-bench Verified — a test of real-world coding tasks pulled from GitHub — GPT-5 scores 74.9% on its first attempt. That means GPT-5 just outperforms Anthropic’s latest Claude Opus 4.1 model, which scored 74.5%, and Google DeepMind’s Gemini 2.5 Pro, which scored 59.6%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Humanity’s Last Exam — a difficult test measuring AI model performance across math, humanities, and the natural sciences — a version of GPT-5 with extended reasoning (GPT-5 Pro) scored 42% when using tools. That’s slightly less than xAI was able to achieve with Grok 4 Heavy, which scored 44.4% on the test.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035062" height="450" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.56.46PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On GPQA Diamond — a test of PhD-level science questions — GPT-5 pro scored 89.4% on its first try, outperforming Claude Opus 4.1, which scored 80.9%, and Grok 4 Heavy, which scored 88.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5 is better for answering health-related questions. On a test measuring accuracy in AI model responses around healthcare topics, HealthBench Hard Hallucinations, OpenAI says GPT-5 (with thinking) hallucinates just 1.6% of the time. This is far lower than the company’s previous GPT-4o and o3 models, which scored 12.9% and 15.8, respectively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI chatbots are not medical professionals, millions of people are using them for health advice. In response to this phenomenon, the company says GPT-5 is more proactive about flagging potential health concerns and helping users parse medical results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, OpenAI says GPT-5 is better than other AI models on more difficult-to-measure, subjective domains, such as creative design and writing. Turley said GPT-5 responds more naturally and exhibits “better taste” than other AI models on creative tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The vibes of this model are really good,” said Turley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;GPT-5 is also more accurate than OpenAI’s previous models, and the company says it suffers far less from hallucinations — the tendency for AI models to make up information — compared to its o-series models. Hallucinations seemed to be getting worse in OpenAI’s latest AI reasoning models, such as o3, and OpenAI previously said it didn’t quite understand why it was happening.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In responses to ChatGPT prompts, OpenAI found that GPT-5 (with thinking) hallucinates and responds with incorrect information 4.8% of the time. That’s a significant reduction from o3 and GPT-4o, which score hallucination rates of 22% and 20.6%, respectively, on the test.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a benchmark measuring an AI model’s agentic ability to complete simulated online tasks, Tau-bench, GPT-5 offers mixed performance. On part of the test measuring an AI’s ability to navigate an airline’s website, GPT-5 scores 63.5%, slightly underperforming o3, which scored 64.8%. On another part of the test measuring AI’s ability to navigate retail websites, GPT-5 scores 81.1%, underperforming Claude Opus 4.1, which scored 82.4%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also says that GPT-5 is safer than its previous models. While AI reasoning models occasionally exhibit a tendency to scheme against humans or lie to promote their own goals, OpenAI found that GPT-5 was deceptive at a lower rate than other models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Beutel, OpenAI’s safety research lead, said reducing deception improves not only the safety of GPT-5, but also the user experience, creating a model that’s more “transparent and honest in ways users can trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beutel also notes GPT-5 is better at discerning between bad actors who are trying to misuse ChatGPT and users making harmless requests. This results in GPT-5 being able to refuse more unsafe questions, while offering fewer rejections to users seeking harmless information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-upgrades-for-consumers-and-developers"&gt;Upgrades for consumers and developers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is getting a few user experience upgrades as part of the GPT-5 launch. Users can now select from four new personalities in ChatGPT’s setting: Cynic, Robot, Listener, and Nerd. The company says these will adapt ChatGPT’s responses without requiring users to specifically ask the model to respond in a certain way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to ChatGPT’s $20-per-month Plus plan get higher usage limits for GPT-5 than free users. Meanwhile, $200-per-month Pro subscribers will have unlimited access to GPT-5, as well as a souped-up version called GPT-5 Pro that uses additional computational resources to produce better answers. Organizations on OpenAI’s Team, Edu, and Enterprise plans will gain access to GPT-5 as their default model next week.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For developers, GPT-5 is coming to OpenAI’s API in three sizes — gpt-5, gpt-5-mini, and gpt-5-nano — which will spend more or less time “reasoning” through tasks. Developers can also now control verbosity in the OpenAI API, deciding how long or short an AI model’s responses should be.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The base model of GPT-5 will cost developers $1.25 per million input tokens (roughly 750,000 words, longer than the entire “Lord of the Rings” series) and $10 per million output tokens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of GPT-5 comes after a busy week for OpenAI. The company released an open-weight reasoning model, gpt-oss, that developers and enterprises can download for free and run at a fraction of the cost. The open model nearly matched the abilities of OpenAI’s previous top models, o3 and o4-mini, but GPT-5 sets a new standard for frontier performance in some areas, such as coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, GPT-5 seems to be roughly on par with other frontier AI models in several areas. Benchmarks, of course, only tell part of the story for any AI model, and it remains to be seen how developers will use GPT-5 in the real world, and whether the model is truly a step above the competition.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/openais-gpt-5-is-here/</guid><pubDate>Thu, 07 Aug 2025 17:00:00 +0000</pubDate></item><item><title>OpenAI launches GPT-5, nano, mini and Pro — not AGI, but capable of generating ‘software-on-demand’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand/</link><description>&lt;p&gt;After literally years of hype and speculation, &lt;strong&gt;OpenAI has officially launched a new lineup of large language models (LLMs),&lt;/strong&gt; all different-sized variants of &lt;strong&gt;GPT-5,&lt;/strong&gt; the long-awaited predecessor to its GPT-4 model from March of 2023, nearly 2.5 years ago.  &lt;/p&gt;&lt;p&gt;The company is rolling out &lt;strong&gt;four distinct versions of the model&lt;/strong&gt; — &lt;strong&gt;GPT-5, GPT-5 Mini, GPT-5 Nano, and GPT-5 Pro&lt;/strong&gt; — to meet varying needs for speed, cost, and computational depth.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5 will soon be powering ChatGPT exclusively&lt;/strong&gt; and &lt;strong&gt;replace all other models&lt;/strong&gt; going forward for its 700 million weekly users, though &lt;strong&gt;ChatGPT Pro subscribers ($200) month can still select older models for the next 60 days.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As per rumors and reports, OpenAI has replaced the previous system of having users switch the underlying model powering ChatGPT with &lt;strong&gt;an automatic router&lt;/strong&gt; that decides to engage a special “GPT-5 thinking” mode with “deeper reasoning” that takes longer to respond on harder queries, or uses the regular GPT-5 or mini models for simpler queries. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the API, the three reasoning-focused models — GPT-5, GPT-5 mini, and GPT-5 nano — are available as gpt-5, gpt-5-mini, and gpt-5-nano, respectively. &lt;strong&gt;GPT-5 Pro is not currently accessible via API, being used only to power ChatGPT for Pro tier subscribers. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;GPT-5’s release comes just days after &lt;strong&gt;OpenAI launched a set of free, new open source LLMs under the name GPT-oss&lt;/strong&gt;, which can be downloaded, customized and used offline by individuals and developers on consumer devices like PCs/Mac desktops and laptops. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The biggest takeaway, though, is likely not what GPT-5 is, but what it isn’t: AGI, artificial general intelligence,&lt;/strong&gt; OpenAI’s stated goal of an autonomous AI system that outperforms humans at most economically valuable work.&lt;/p&gt;



&lt;p&gt;Whether or not you the reader personally believe such a system is possible or desirable, OpenAI declaring AGI would have material business impacts. &lt;em&gt;Wired&lt;/em&gt; reported previously that there is a clause in OpenAI’s contract with Microsoft that permits OpenAI to begin charging Microsoft for access to its newest models, or cut it off from accessing OpenAI models, if OpenAI’s board determines the company has achieved AGI or generates more than $100 billion in profit.&lt;/p&gt;



&lt;p&gt;But apparently, that is not the case today. As &lt;strong&gt;co-founder and CEO Sam Altman &lt;/strong&gt;said, flanked by other OpenAI staffers on an embargoed video call with reporters last night, “&lt;strong&gt;the way that most of us define AGI, we’re still missing something quite important &lt;/strong&gt;— many things that are quite important, actually — &lt;strong&gt;but one big one is a model that continuously learns as its deployed, and GPT-5 does not.”  &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;I also asked OpenAI the following question directly: &lt;strong&gt;“Is OpenAI considering&amp;nbsp;GPT-5&amp;nbsp;AGI? Will it trigger any changes regarding Microsoft negotiations?” &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To which an OpenAI spokesperson responded over email: &lt;/p&gt;



&lt;p&gt;“&lt;em&gt;GPT-5&amp;nbsp;is a significant step toward AGI in that it shows substantial improvements in reasoning and generalization, bringing us closer to systems that can perform a wide range of tasks with human-level capability. However, AGI is still a weakly defined term and means different things to different people.&amp;nbsp;&lt;strong&gt;While&amp;nbsp;GPT-5&amp;nbsp;meets some early criteria for AGI, it doesn’t yet reach the threshold of fully human-level AGI.&amp;nbsp;&lt;/strong&gt;There are still key limitations in areas like persistent memory, autonomy, and adaptability across tasks. Our focus remains on advancing these capabilities safely, rather than speculating on specific timelines.&lt;/em&gt;“&lt;/p&gt;



&lt;p&gt;Yet &lt;strong&gt;benchmark results shared by OpenAI show&amp;nbsp;GPT-5 is nearing the threshold of performing as well as, and is close to exceeding, the average human expert performance&lt;/strong&gt;&amp;nbsp;at various tasks across law, logistics, sales, and engineering.&lt;/p&gt;



&lt;p&gt;As&amp;nbsp;OpenAI writes:&amp;nbsp;“When using reasoning, GPT-5 is comparable to or better than experts in roughly half the cases, while outperforming OpenAI o3 and ChatGPT Agent.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015291" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/GxxC7TrbsAId0Ur_fe9bc5.jpg?w=483" width="483" /&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;/blockquote&gt;



&lt;h2 class="wp-block-heading" id="h-why-use-gpt-5"&gt;Why use GPT-5? &lt;/h2&gt;



&lt;p&gt;With so many alternate models available now from OpenAI and a growing list of competitors, namely Chinese startups offering powerful open source models, what does GPT-5 bring to the table?&lt;/p&gt;



&lt;p&gt;Altman described the leap in capability as more than incremental.&lt;strong&gt; He compared the experience of using GPT-5 to upgrading from a pixelated display to a retina screen — something users simply don’t want to go back from. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“GPT-3 felt like talking to a high school student,” Altman said. “GPT-4 was like a college student.&lt;strong&gt; GPT-5 is the first time it feels like talking to a PhD-level expert in your pocket.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Among the most impressive capabilities demoed for reporters during the embargoed call was the ability to &lt;strong&gt;generate the code for a fully working web application from a single prompt&lt;/strong&gt;, in this case, a French language learning app with built-in game where English-to-French phrases were shown every time the user guided a virtual mouse to collect slices of cheese, with fully working emoji-inspired characters, backdrop/setting, and clickable interactive menus. The given prompt was only a single paragraph, too.&lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Altman stated: “This idea of software on demand will be a defining part of the new GPT-5 era.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, this basic capability — prompt to working software — has been available already from prior OpenAI models such as o3 and o4-mini, o4-high, and rival services like Anthropic’s Claude Artifacts, which I (and many others) have used for many months to create interactive first-person and clickable games as well. &lt;/p&gt;



&lt;p&gt;The advantage GPT-5 seems to offer in making games, apps, and other software from prompts seems to be in speed — it produced this demo app in a matter of mere minutes — and completeness, with very few discernible bugs and a completely playable experience in “one-shot,” or from a single prompt without back-and-forth conversation, as the developers like to say. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-available-to-chatgpt-free-users-and-all-plans"&gt;Available to ChatGPT free users and all plans&lt;/h2&gt;



&lt;p&gt;GPT-5 is not restricted to premium subscribers. OpenAI has made the model available across all ChatGPT tiers, including free users — a deliberate move aligned with the company’s mission to ensure broad benefits from AI. &lt;/p&gt;



&lt;p&gt;Free-tier users can access &lt;strong&gt;GPT-5 and GPT-5 Mini&lt;/strong&gt;, with usage limits — though exactly what those usage limits are remains undefined for now, and I’d guess will likely change on an irregular cadence depending on demand.&lt;/p&gt;



&lt;p&gt;Subscribers to the &lt;strong&gt;ChatGPT Plus ($20 per month) tier&lt;/strong&gt; receive higher usage allowances, while subscribers to the &lt;strong&gt;ChatGPT Pro ($200 monthly), Team ($30 per month or $240 annually), and Enterprise (variable pricing depending on company size and usage)&lt;/strong&gt; customers get unlimited or prioritized access. &lt;/p&gt;



&lt;p&gt;GPT-5 Pro will become available to&lt;strong&gt; Team, Enterprise, and EDU customers in the coming days.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The new unified ChatGPT experience eliminates the need to select a model manually. Once users reach usage limits on GPT-5, the system automatically shifts to GPT-5 mini — a more lightweight but still highly capable fallback.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-improved-metrics-across-the-board-including-100-in-aime-2025-math"&gt;Improved metrics across the board, including 100% in AIME 2025 Math&lt;/h2&gt;



&lt;p&gt;According to OpenAI,&lt;strong&gt; GPT-5 offers the most accurate, responsive, and context-aware AI system &lt;/strong&gt;the company has ever shipped. &lt;/p&gt;



&lt;p&gt;It reduces hallucinations, handles multi-step reasoning more reliably, and generates better-quality code, content, and responses across diverse domains.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The GPT-5 system delivers ~45% fewer factual errors than GPT-4o in real-world traffic, and up to ~80% fewer when using its “thinking” mode.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;This mode, which users can trigger by explicitly asking the model to take its time, enables more complex and robust responses — powered by GPT-5 Pro in certain configurations. &lt;strong&gt;In tests, GPT-5 Pro sets new state-of-the-art scores on benchmarks like GPQA (88.4%), AIME 2025 math (100% when using Python to answer the questions), and HealthBench Hard (46.2%).&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015267" height="466" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.26.06%E2%80%AFPM.png" width="536" /&gt;&lt;/figure&gt;



&lt;p&gt;Performance improvements show up across key academic and real-world benchmarks. In coding, GPT-5 sets new state-of-the-art results on SWE-Bench Verified (74.9%) and Aider Polyglot (88%). &lt;/p&gt;



&lt;p&gt;Perhaps most incredibly, on Humanity’s Last Exam — a newish benchmark of 2,500 extremely difficult tasks for programs — GPT-5 pro achieves a record-high 42%, blowing away the competition and all prior OpenAI models except the new ChatGPT agent unveiled last month that controls its own computer and cursor like a human.&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015281" height="541" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.26.31%E2%80%AFPM.png" width="697" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;On writing tasks, GPT-5 adapts more smoothly to tone, context, and user intent. &lt;/strong&gt;It is &lt;strong&gt;better at maintaining coherence, structuring information clearly, and completing complex writing assignments. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The improvements are not just technical — OpenAI’s team emphasized how GPT-5 feels more natural and humanlike in conversation.&lt;/p&gt;



&lt;p&gt;Health-related use cases have also been enhanced. While OpenAI continues to caution that ChatGPT is not a replacement for medical professionals, &lt;strong&gt;GPT-5 is more proactive about flagging concerns, helping users interpret medical results, and guiding them through preparing for appointments or evaluating options.&lt;/strong&gt; The system also adjusts answers based on user location, background knowledge, and context — leading to safer and more personalized assistance.&lt;/p&gt;



&lt;p&gt;One of the most significant updates is in &lt;strong&gt;safe completions&lt;/strong&gt;, a new system that helps GPT-5 avoid abrupt refusals or unsafe outputs. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Instead of declining queries outright, GPT-5 aims to provide the most helpful response within its safety boundaries and explains when it cannot assist&lt;/strong&gt; — a change that dramatically reduces unnecessary denials while maintaining trustworthiness.&lt;/p&gt;







&lt;p&gt;GPT-5 is also a major upgrade for developers working on agentic systems and tool-assisted workflows. OpenAI has introduced a suite of developer-friendly controls in the GPT-5 API, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Free-form function calling&lt;/strong&gt; – Tools can now accept raw strings such as SQL queries or shell commands, without requiring JSON structure.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Reasoning effort control&lt;/strong&gt; – Developers can toggle between rapid responses and deeper analytical processing depending on the task.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Verbosity control&lt;/strong&gt; – A new parameter allows users to select whether responses are brief, standard, or detailed.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Structured outputs with grammar constraints&lt;/strong&gt; – Developers can now guide outputs using custom grammars or regular expressions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Tool call preambles&lt;/strong&gt; – GPT-5 can now explain its reasoning before using tools or making external requests.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;For the first time, developers can also enable a &lt;strong&gt;new parameter option for reasoning effort called &lt;em&gt;minimal&lt;/em&gt;&lt;/strong&gt;. This setting lets the model operate in reasoning mode, but tuned for speed. “This is so that you can use these reasoning models, but with minimalization,” one OpenAI researcher explained during the company’s announcement livestream on YouTube earlier today, “so that they can slot into the very fastest and most latency sensitive applications.”&lt;/p&gt;



&lt;p&gt;The researcher stressed that minimal mode means developers don’t have to choose between accuracy and responsiveness: “Now you don’t actually have to choose between a bunch of models… you can use GPT-5 for all of your use cases, and just dilute reasoning effort.” &lt;/p&gt;



&lt;p&gt;This&lt;strong&gt; approach aims to make GPT-5 viable for ultra-low-latency scenarios like live customer interactions, fast-refresh dashboards, and real-time tool integrations, while still leveraging the reasoning capabilities&lt;/strong&gt; that differentiate it from smaller or older models.&lt;/p&gt;



&lt;p&gt;The API itself is getting major upgrades. A researcher explained that the new &lt;strong&gt;custom tools&lt;/strong&gt; feature moves beyond JSON-only outputs: “Custom tools are just free form plain text,” with the option to enforce formats using “a regular expression or even a context free grammar… super useful if you have your own SQL fork and specify that the models always follow that format.” &lt;/p&gt;



&lt;p&gt;Developers also gain &lt;strong&gt;tool call preambles&lt;/strong&gt;, so “the model’s ability to output explanation of what it’s about to do before it calls tools” can be switched on or tailored, and a &lt;strong&gt;verbosity parameter&lt;/strong&gt; to set responses to “low, medium and high.”&lt;/p&gt;



&lt;p&gt;OpenAI also touted GPT-5’s leap in coding performance. On SWE-Bench, a benchmark for Python, the model scored &lt;strong&gt;74.9%&lt;/strong&gt;, beating GPT-4’s best of 69.1%, and it hit &lt;strong&gt;88%&lt;/strong&gt; on Polyglot, which covers multiple programming languages. Human testers preferred its code “70% of the time for its improved aesthetic abilities, but also better capabilities overall.”&lt;/p&gt;



&lt;p&gt;Developers can access GPT-5 through OpenAI’s platform for the following prices:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;gpt-5&lt;/strong&gt;: $1.25/$10 per 1 million input/output tokens (with up to 90% input cache discount)&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;gpt-5-mini:&lt;/strong&gt; $0.50 / $5 per 1 million input / output tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;gpt-5-nano:&lt;/strong&gt; $0.15 / $1.50 per 1 million input / output tokens&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The context window now spans &lt;strong&gt;256,000 tokens&lt;/strong&gt; &lt;strong&gt;(about the length of a 600-800 page book of text) &lt;/strong&gt;allowing GPT-5 to handle substantially larger documents and more extensive conversations than its predecessor, GPT-4 Turbo. &lt;/p&gt;



&lt;p&gt;For those who require even more, GPT-4.1 (which supports 1 million-token context windows) remains available.&lt;/p&gt;



&lt;p&gt;Compared to the&lt;strong&gt; &lt;/strong&gt;primary competitors — Anthropic and Google — &lt;strong&gt;OpenAI’s GPT-5 models are on par or cheaper for developers to access through the API,&lt;/strong&gt; placing more downward pressure on the cost of intelligence. &lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Model / Tier&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Input Cost (per 1M tokens)&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Output Cost (per 1M tokens)&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$1.25 (before cache)&lt;/td&gt;&lt;td&gt;$10&lt;/td&gt;&lt;td&gt;With up to 90% input caching&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5‑mini&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.50&lt;/td&gt;&lt;td&gt;$5&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5‑nano&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.15&lt;/td&gt;&lt;td&gt;$1.50&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Claude Sonnet 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$3&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;Up to 90% prompt-caching discount&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Claude Opus 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;$75&lt;/td&gt;&lt;td&gt;High-end model aimed at complex tasks&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (≤200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$1.25&lt;/td&gt;&lt;td&gt;$10&lt;/td&gt;&lt;td&gt;Interactive prompts up to 200K tokens&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (Batch ≤200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.625&lt;/td&gt;&lt;td&gt;$5&lt;/td&gt;&lt;td&gt;Batch processing reduces cost&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$2.50&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;For long prompts over 200K tokens&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Flash‑Lite&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.10&lt;/td&gt;&lt;td&gt;$0.40&lt;/td&gt;&lt;td&gt;Google’s most cost-efficient LLM to date&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-early-enterprise-testers-have-high-praise"&gt;Early enterprise testers have high praise&lt;/h2&gt;



&lt;p&gt;Several high-profile companies have already adopted GPT-5 in early trials. JetBrains is using it to power intelligent developer tools, and Notion has integrated GPT-5 to improve document generation and productivity workflows. &lt;/p&gt;



&lt;p&gt;At AI developer tool startup &lt;strong&gt;Cursor, co-founder and CEO Michael Truell said in a quote provided to reporters by OpenAI: &lt;/strong&gt;&lt;em&gt;“Our team has found GPT-5 to be remarkably intelligent, easy to steer, and even to have a personality we haven’t seen in any other model. It not only catches tricky, deeply-hidden bugs but can also run long, multi-turn background agents to see complex tasks through to the finish—the kinds of problems that used to leave other models stuck. It’s become our daily driver for everything from scoping and planning PRs to completing end-to-end builds. ”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Other customers report major gains: GitLab cites a drop in tool call volume, GitHub notes improvements in reasoning across large codebases, and Uber is testing GPT-5 for real-time, domain-aware service applications. At Amgen, the model has already improved output quality and reduced ambiguity in scientific tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-updates-still-to-come"&gt;More updates still to come&lt;/h2&gt;



&lt;p&gt;GPT-5’s launch coincides with several new features coming now and soon to ChatGPT. &lt;/p&gt;



&lt;p&gt;Users can now&lt;strong&gt; personalize the interface with chat colors (with exclusive options for paid users) a&lt;/strong&gt;nd experiment with &lt;strong&gt;preset personalities like Cynic, Robot, Listener, and Nerd &lt;/strong&gt;— designed to match different communication styles.&lt;/p&gt;



&lt;p&gt;ChatGPT will also &lt;strong&gt;soon support seamless integration with Gmail, Google Calendar, and Google Contacts&lt;/strong&gt;. Once enabled, these services will be automatically referenced during chats, with no manual toggling required. These connectors launch for Pro subscribers next week, with broader availability to follow.&lt;/p&gt;



&lt;p&gt;A new Advanced Voice mode understands instructions better and allows users to adjust tone and delivery. Voice will be available across all user tiers and included in custom GPTs. &lt;/p&gt;



&lt;p&gt;In 30 days, OpenAI will retire the older “Standard Voice Mode” and fully transition to this unified experience.&lt;/p&gt;



&lt;p&gt;With safer design, more robust reasoning, expanded developer tooling, and broad user access, GPT-5 reflects a maturing AI ecosystem that’s inching closer to real-world utility on a global scale.&lt;/p&gt;



&lt;p&gt;OpenAI’s approach this time is less about flash and more about integration. GPT-5 isn’t a separate offering that users have to seek out — it’s simply there, powering the tools millions already use, making them smarter and more capable and unlocking a whole new raft of use cases for developers. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;After literally years of hype and speculation, &lt;strong&gt;OpenAI has officially launched a new lineup of large language models (LLMs),&lt;/strong&gt; all different-sized variants of &lt;strong&gt;GPT-5,&lt;/strong&gt; the long-awaited predecessor to its GPT-4 model from March of 2023, nearly 2.5 years ago.  &lt;/p&gt;&lt;p&gt;The company is rolling out &lt;strong&gt;four distinct versions of the model&lt;/strong&gt; — &lt;strong&gt;GPT-5, GPT-5 Mini, GPT-5 Nano, and GPT-5 Pro&lt;/strong&gt; — to meet varying needs for speed, cost, and computational depth.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5 will soon be powering ChatGPT exclusively&lt;/strong&gt; and &lt;strong&gt;replace all other models&lt;/strong&gt; going forward for its 700 million weekly users, though &lt;strong&gt;ChatGPT Pro subscribers ($200) month can still select older models for the next 60 days.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As per rumors and reports, OpenAI has replaced the previous system of having users switch the underlying model powering ChatGPT with &lt;strong&gt;an automatic router&lt;/strong&gt; that decides to engage a special “GPT-5 thinking” mode with “deeper reasoning” that takes longer to respond on harder queries, or uses the regular GPT-5 or mini models for simpler queries. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the API, the three reasoning-focused models — GPT-5, GPT-5 mini, and GPT-5 nano — are available as gpt-5, gpt-5-mini, and gpt-5-nano, respectively. &lt;strong&gt;GPT-5 Pro is not currently accessible via API, being used only to power ChatGPT for Pro tier subscribers. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;GPT-5’s release comes just days after &lt;strong&gt;OpenAI launched a set of free, new open source LLMs under the name GPT-oss&lt;/strong&gt;, which can be downloaded, customized and used offline by individuals and developers on consumer devices like PCs/Mac desktops and laptops. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The biggest takeaway, though, is likely not what GPT-5 is, but what it isn’t: AGI, artificial general intelligence,&lt;/strong&gt; OpenAI’s stated goal of an autonomous AI system that outperforms humans at most economically valuable work.&lt;/p&gt;



&lt;p&gt;Whether or not you the reader personally believe such a system is possible or desirable, OpenAI declaring AGI would have material business impacts. &lt;em&gt;Wired&lt;/em&gt; reported previously that there is a clause in OpenAI’s contract with Microsoft that permits OpenAI to begin charging Microsoft for access to its newest models, or cut it off from accessing OpenAI models, if OpenAI’s board determines the company has achieved AGI or generates more than $100 billion in profit.&lt;/p&gt;



&lt;p&gt;But apparently, that is not the case today. As &lt;strong&gt;co-founder and CEO Sam Altman &lt;/strong&gt;said, flanked by other OpenAI staffers on an embargoed video call with reporters last night, “&lt;strong&gt;the way that most of us define AGI, we’re still missing something quite important &lt;/strong&gt;— many things that are quite important, actually — &lt;strong&gt;but one big one is a model that continuously learns as its deployed, and GPT-5 does not.”  &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;I also asked OpenAI the following question directly: &lt;strong&gt;“Is OpenAI considering&amp;nbsp;GPT-5&amp;nbsp;AGI? Will it trigger any changes regarding Microsoft negotiations?” &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To which an OpenAI spokesperson responded over email: &lt;/p&gt;



&lt;p&gt;“&lt;em&gt;GPT-5&amp;nbsp;is a significant step toward AGI in that it shows substantial improvements in reasoning and generalization, bringing us closer to systems that can perform a wide range of tasks with human-level capability. However, AGI is still a weakly defined term and means different things to different people.&amp;nbsp;&lt;strong&gt;While&amp;nbsp;GPT-5&amp;nbsp;meets some early criteria for AGI, it doesn’t yet reach the threshold of fully human-level AGI.&amp;nbsp;&lt;/strong&gt;There are still key limitations in areas like persistent memory, autonomy, and adaptability across tasks. Our focus remains on advancing these capabilities safely, rather than speculating on specific timelines.&lt;/em&gt;“&lt;/p&gt;



&lt;p&gt;Yet &lt;strong&gt;benchmark results shared by OpenAI show&amp;nbsp;GPT-5 is nearing the threshold of performing as well as, and is close to exceeding, the average human expert performance&lt;/strong&gt;&amp;nbsp;at various tasks across law, logistics, sales, and engineering.&lt;/p&gt;



&lt;p&gt;As&amp;nbsp;OpenAI writes:&amp;nbsp;“When using reasoning, GPT-5 is comparable to or better than experts in roughly half the cases, while outperforming OpenAI o3 and ChatGPT Agent.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015291" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/GxxC7TrbsAId0Ur_fe9bc5.jpg?w=483" width="483" /&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;&lt;/blockquote&gt;



&lt;h2 class="wp-block-heading" id="h-why-use-gpt-5"&gt;Why use GPT-5? &lt;/h2&gt;



&lt;p&gt;With so many alternate models available now from OpenAI and a growing list of competitors, namely Chinese startups offering powerful open source models, what does GPT-5 bring to the table?&lt;/p&gt;



&lt;p&gt;Altman described the leap in capability as more than incremental.&lt;strong&gt; He compared the experience of using GPT-5 to upgrading from a pixelated display to a retina screen — something users simply don’t want to go back from. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“GPT-3 felt like talking to a high school student,” Altman said. “GPT-4 was like a college student.&lt;strong&gt; GPT-5 is the first time it feels like talking to a PhD-level expert in your pocket.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Among the most impressive capabilities demoed for reporters during the embargoed call was the ability to &lt;strong&gt;generate the code for a fully working web application from a single prompt&lt;/strong&gt;, in this case, a French language learning app with built-in game where English-to-French phrases were shown every time the user guided a virtual mouse to collect slices of cheese, with fully working emoji-inspired characters, backdrop/setting, and clickable interactive menus. The given prompt was only a single paragraph, too.&lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Altman stated: “This idea of software on demand will be a defining part of the new GPT-5 era.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, this basic capability — prompt to working software — has been available already from prior OpenAI models such as o3 and o4-mini, o4-high, and rival services like Anthropic’s Claude Artifacts, which I (and many others) have used for many months to create interactive first-person and clickable games as well. &lt;/p&gt;



&lt;p&gt;The advantage GPT-5 seems to offer in making games, apps, and other software from prompts seems to be in speed — it produced this demo app in a matter of mere minutes — and completeness, with very few discernible bugs and a completely playable experience in “one-shot,” or from a single prompt without back-and-forth conversation, as the developers like to say. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-available-to-chatgpt-free-users-and-all-plans"&gt;Available to ChatGPT free users and all plans&lt;/h2&gt;



&lt;p&gt;GPT-5 is not restricted to premium subscribers. OpenAI has made the model available across all ChatGPT tiers, including free users — a deliberate move aligned with the company’s mission to ensure broad benefits from AI. &lt;/p&gt;



&lt;p&gt;Free-tier users can access &lt;strong&gt;GPT-5 and GPT-5 Mini&lt;/strong&gt;, with usage limits — though exactly what those usage limits are remains undefined for now, and I’d guess will likely change on an irregular cadence depending on demand.&lt;/p&gt;



&lt;p&gt;Subscribers to the &lt;strong&gt;ChatGPT Plus ($20 per month) tier&lt;/strong&gt; receive higher usage allowances, while subscribers to the &lt;strong&gt;ChatGPT Pro ($200 monthly), Team ($30 per month or $240 annually), and Enterprise (variable pricing depending on company size and usage)&lt;/strong&gt; customers get unlimited or prioritized access. &lt;/p&gt;



&lt;p&gt;GPT-5 Pro will become available to&lt;strong&gt; Team, Enterprise, and EDU customers in the coming days.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The new unified ChatGPT experience eliminates the need to select a model manually. Once users reach usage limits on GPT-5, the system automatically shifts to GPT-5 mini — a more lightweight but still highly capable fallback.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-improved-metrics-across-the-board-including-100-in-aime-2025-math"&gt;Improved metrics across the board, including 100% in AIME 2025 Math&lt;/h2&gt;



&lt;p&gt;According to OpenAI,&lt;strong&gt; GPT-5 offers the most accurate, responsive, and context-aware AI system &lt;/strong&gt;the company has ever shipped. &lt;/p&gt;



&lt;p&gt;It reduces hallucinations, handles multi-step reasoning more reliably, and generates better-quality code, content, and responses across diverse domains.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The GPT-5 system delivers ~45% fewer factual errors than GPT-4o in real-world traffic, and up to ~80% fewer when using its “thinking” mode.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;This mode, which users can trigger by explicitly asking the model to take its time, enables more complex and robust responses — powered by GPT-5 Pro in certain configurations. &lt;strong&gt;In tests, GPT-5 Pro sets new state-of-the-art scores on benchmarks like GPQA (88.4%), AIME 2025 math (100% when using Python to answer the questions), and HealthBench Hard (46.2%).&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015267" height="466" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.26.06%E2%80%AFPM.png" width="536" /&gt;&lt;/figure&gt;



&lt;p&gt;Performance improvements show up across key academic and real-world benchmarks. In coding, GPT-5 sets new state-of-the-art results on SWE-Bench Verified (74.9%) and Aider Polyglot (88%). &lt;/p&gt;



&lt;p&gt;Perhaps most incredibly, on Humanity’s Last Exam — a newish benchmark of 2,500 extremely difficult tasks for programs — GPT-5 pro achieves a record-high 42%, blowing away the competition and all prior OpenAI models except the new ChatGPT agent unveiled last month that controls its own computer and cursor like a human.&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015281" height="541" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.26.31%E2%80%AFPM.png" width="697" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;On writing tasks, GPT-5 adapts more smoothly to tone, context, and user intent. &lt;/strong&gt;It is &lt;strong&gt;better at maintaining coherence, structuring information clearly, and completing complex writing assignments. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The improvements are not just technical — OpenAI’s team emphasized how GPT-5 feels more natural and humanlike in conversation.&lt;/p&gt;



&lt;p&gt;Health-related use cases have also been enhanced. While OpenAI continues to caution that ChatGPT is not a replacement for medical professionals, &lt;strong&gt;GPT-5 is more proactive about flagging concerns, helping users interpret medical results, and guiding them through preparing for appointments or evaluating options.&lt;/strong&gt; The system also adjusts answers based on user location, background knowledge, and context — leading to safer and more personalized assistance.&lt;/p&gt;



&lt;p&gt;One of the most significant updates is in &lt;strong&gt;safe completions&lt;/strong&gt;, a new system that helps GPT-5 avoid abrupt refusals or unsafe outputs. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Instead of declining queries outright, GPT-5 aims to provide the most helpful response within its safety boundaries and explains when it cannot assist&lt;/strong&gt; — a change that dramatically reduces unnecessary denials while maintaining trustworthiness.&lt;/p&gt;







&lt;p&gt;GPT-5 is also a major upgrade for developers working on agentic systems and tool-assisted workflows. OpenAI has introduced a suite of developer-friendly controls in the GPT-5 API, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Free-form function calling&lt;/strong&gt; – Tools can now accept raw strings such as SQL queries or shell commands, without requiring JSON structure.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Reasoning effort control&lt;/strong&gt; – Developers can toggle between rapid responses and deeper analytical processing depending on the task.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Verbosity control&lt;/strong&gt; – A new parameter allows users to select whether responses are brief, standard, or detailed.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Structured outputs with grammar constraints&lt;/strong&gt; – Developers can now guide outputs using custom grammars or regular expressions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Tool call preambles&lt;/strong&gt; – GPT-5 can now explain its reasoning before using tools or making external requests.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;For the first time, developers can also enable a &lt;strong&gt;new parameter option for reasoning effort called &lt;em&gt;minimal&lt;/em&gt;&lt;/strong&gt;. This setting lets the model operate in reasoning mode, but tuned for speed. “This is so that you can use these reasoning models, but with minimalization,” one OpenAI researcher explained during the company’s announcement livestream on YouTube earlier today, “so that they can slot into the very fastest and most latency sensitive applications.”&lt;/p&gt;



&lt;p&gt;The researcher stressed that minimal mode means developers don’t have to choose between accuracy and responsiveness: “Now you don’t actually have to choose between a bunch of models… you can use GPT-5 for all of your use cases, and just dilute reasoning effort.” &lt;/p&gt;



&lt;p&gt;This&lt;strong&gt; approach aims to make GPT-5 viable for ultra-low-latency scenarios like live customer interactions, fast-refresh dashboards, and real-time tool integrations, while still leveraging the reasoning capabilities&lt;/strong&gt; that differentiate it from smaller or older models.&lt;/p&gt;



&lt;p&gt;The API itself is getting major upgrades. A researcher explained that the new &lt;strong&gt;custom tools&lt;/strong&gt; feature moves beyond JSON-only outputs: “Custom tools are just free form plain text,” with the option to enforce formats using “a regular expression or even a context free grammar… super useful if you have your own SQL fork and specify that the models always follow that format.” &lt;/p&gt;



&lt;p&gt;Developers also gain &lt;strong&gt;tool call preambles&lt;/strong&gt;, so “the model’s ability to output explanation of what it’s about to do before it calls tools” can be switched on or tailored, and a &lt;strong&gt;verbosity parameter&lt;/strong&gt; to set responses to “low, medium and high.”&lt;/p&gt;



&lt;p&gt;OpenAI also touted GPT-5’s leap in coding performance. On SWE-Bench, a benchmark for Python, the model scored &lt;strong&gt;74.9%&lt;/strong&gt;, beating GPT-4’s best of 69.1%, and it hit &lt;strong&gt;88%&lt;/strong&gt; on Polyglot, which covers multiple programming languages. Human testers preferred its code “70% of the time for its improved aesthetic abilities, but also better capabilities overall.”&lt;/p&gt;



&lt;p&gt;Developers can access GPT-5 through OpenAI’s platform for the following prices:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;gpt-5&lt;/strong&gt;: $1.25/$10 per 1 million input/output tokens (with up to 90% input cache discount)&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;gpt-5-mini:&lt;/strong&gt; $0.50 / $5 per 1 million input / output tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;gpt-5-nano:&lt;/strong&gt; $0.15 / $1.50 per 1 million input / output tokens&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The context window now spans &lt;strong&gt;256,000 tokens&lt;/strong&gt; &lt;strong&gt;(about the length of a 600-800 page book of text) &lt;/strong&gt;allowing GPT-5 to handle substantially larger documents and more extensive conversations than its predecessor, GPT-4 Turbo. &lt;/p&gt;



&lt;p&gt;For those who require even more, GPT-4.1 (which supports 1 million-token context windows) remains available.&lt;/p&gt;



&lt;p&gt;Compared to the&lt;strong&gt; &lt;/strong&gt;primary competitors — Anthropic and Google — &lt;strong&gt;OpenAI’s GPT-5 models are on par or cheaper for developers to access through the API,&lt;/strong&gt; placing more downward pressure on the cost of intelligence. &lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Model / Tier&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Input Cost (per 1M tokens)&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Output Cost (per 1M tokens)&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$1.25 (before cache)&lt;/td&gt;&lt;td&gt;$10&lt;/td&gt;&lt;td&gt;With up to 90% input caching&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5‑mini&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.50&lt;/td&gt;&lt;td&gt;$5&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GPT‑5‑nano&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.15&lt;/td&gt;&lt;td&gt;$1.50&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Claude Sonnet 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$3&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;Up to 90% prompt-caching discount&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Claude Opus 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;$75&lt;/td&gt;&lt;td&gt;High-end model aimed at complex tasks&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (≤200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$1.25&lt;/td&gt;&lt;td&gt;$10&lt;/td&gt;&lt;td&gt;Interactive prompts up to 200K tokens&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (Batch ≤200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.625&lt;/td&gt;&lt;td&gt;$5&lt;/td&gt;&lt;td&gt;Batch processing reduces cost&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$2.50&lt;/td&gt;&lt;td&gt;$15&lt;/td&gt;&lt;td&gt;For long prompts over 200K tokens&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Gemini 2.5 Flash‑Lite&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.10&lt;/td&gt;&lt;td&gt;$0.40&lt;/td&gt;&lt;td&gt;Google’s most cost-efficient LLM to date&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-early-enterprise-testers-have-high-praise"&gt;Early enterprise testers have high praise&lt;/h2&gt;



&lt;p&gt;Several high-profile companies have already adopted GPT-5 in early trials. JetBrains is using it to power intelligent developer tools, and Notion has integrated GPT-5 to improve document generation and productivity workflows. &lt;/p&gt;



&lt;p&gt;At AI developer tool startup &lt;strong&gt;Cursor, co-founder and CEO Michael Truell said in a quote provided to reporters by OpenAI: &lt;/strong&gt;&lt;em&gt;“Our team has found GPT-5 to be remarkably intelligent, easy to steer, and even to have a personality we haven’t seen in any other model. It not only catches tricky, deeply-hidden bugs but can also run long, multi-turn background agents to see complex tasks through to the finish—the kinds of problems that used to leave other models stuck. It’s become our daily driver for everything from scoping and planning PRs to completing end-to-end builds. ”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Other customers report major gains: GitLab cites a drop in tool call volume, GitHub notes improvements in reasoning across large codebases, and Uber is testing GPT-5 for real-time, domain-aware service applications. At Amgen, the model has already improved output quality and reduced ambiguity in scientific tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-updates-still-to-come"&gt;More updates still to come&lt;/h2&gt;



&lt;p&gt;GPT-5’s launch coincides with several new features coming now and soon to ChatGPT. &lt;/p&gt;



&lt;p&gt;Users can now&lt;strong&gt; personalize the interface with chat colors (with exclusive options for paid users) a&lt;/strong&gt;nd experiment with &lt;strong&gt;preset personalities like Cynic, Robot, Listener, and Nerd &lt;/strong&gt;— designed to match different communication styles.&lt;/p&gt;



&lt;p&gt;ChatGPT will also &lt;strong&gt;soon support seamless integration with Gmail, Google Calendar, and Google Contacts&lt;/strong&gt;. Once enabled, these services will be automatically referenced during chats, with no manual toggling required. These connectors launch for Pro subscribers next week, with broader availability to follow.&lt;/p&gt;



&lt;p&gt;A new Advanced Voice mode understands instructions better and allows users to adjust tone and delivery. Voice will be available across all user tiers and included in custom GPTs. &lt;/p&gt;



&lt;p&gt;In 30 days, OpenAI will retire the older “Standard Voice Mode” and fully transition to this unified experience.&lt;/p&gt;



&lt;p&gt;With safer design, more robust reasoning, expanded developer tooling, and broad user access, GPT-5 reflects a maturing AI ecosystem that’s inching closer to real-world utility on a global scale.&lt;/p&gt;



&lt;p&gt;OpenAI’s approach this time is less about flash and more about integration. GPT-5 isn’t a separate offering that users have to seek out — it’s simply there, powering the tools millions already use, making them smarter and more capable and unlocking a whole new raft of use cases for developers. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand/</guid><pubDate>Thu, 07 Aug 2025 17:01:10 +0000</pubDate></item><item><title>OpenAI launches GPT-5 free to all ChatGPT users (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/openai-launches-gpt-5-free-to-all-chatgpt-users/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New model claims fewer confabulations, better coding, and "safe completions" approach.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="GPT-5 header" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-640x360.jpg" width="640" /&gt;
                  &lt;img alt="GPT-5 header" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI announced GPT-5 and three variants—GPT-5 Pro, GPT-5 mini, and GPT-5 nano—what the company calls its "best AI system yet," with availability for some of the models across all ChatGPT tiers, including free users. The new model family arrives with claims of reduced confabulations, improved coding capabilities, and a new approach to handling sensitive requests that OpenAI calls "safe completions."&lt;/p&gt;
&lt;p&gt;It's also the first time OpenAI has given free users access to a simulated reasoning AI model, which breaks problems down into multiple steps using a technique that tends to improve answer accuracy for logical or analytical questions.&lt;/p&gt;
&lt;p&gt;GPT-5 represents OpenAI's latest attempt to unify its various AI capabilities into a single system. The company says the GPT-5 family acts as a "unified system" with a smart, efficient model that answers most questions, a deeper reasoning model called "GPT-5 thinking" for harder problems, and a real-time router that decides which approach to use based on conversation type, complexity, tool needs, and user intent. Like GPT-4o, GPT-5 is a multimodal system that can interact via images, voice, and text.&lt;/p&gt;
&lt;p&gt;The rollout starts today, extending to ChatGPT's 700 million weekly active users, with varying usage limits based on subscription tier. Pro subscribers will receive unlimited access to GPT-5 and the GPT-5 Pro variant, while Plus users receive "significantly higher usage limits" compared to free users, according to a statement from OpenAI. GPT-5 Pro is replacing o3-pro in ChatGPT for those subscriber tiers with access to it.&lt;/p&gt;
&lt;h2&gt;Technical improvements and new features&lt;/h2&gt;
&lt;p&gt;Since the launch of GPT-4 in 2023, we've seen a trend of relative diminishing returns in terms of jumps in capability between major AI model releases. In that sense, the jump in contextual processing capability between GPT-3 and GPT-4 felt shockingly large. The jump between GPT-4 (if you consider the original 2023 version) and GPT-5 is still significant, but when you consider intermediate releases like GPT-4o, GPT-4.5, GPT-4.1, and o3-pro, GPT-5 feels like an incremental upgrade that is unlikely to shock anyone.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We've written about how OpenAI almost used the name "GPT-5" for models like o1 last year but decided to save it for a future release. Why these new models met that branding threshold is unclear, but the "GPT-5" name brand recognition will likely give OpenAI a boost in the public eye amid a heavily competitive industry.&lt;/p&gt;
&lt;p&gt;Among the claimed improvements, OpenAI says GPT-5 delivers its "strongest coding model yet," achieving 74.9 percent on SWE-bench Verified and 88 percent on Aider Polyglot benchmarks. (To compare, earlier this week, Anthropic released Claude Opus 4.1, which reportedly scored 74.5 percent on SWE-bench.) GPT-5 can reportedly complete "complex coding tasks end-to-end with minimal prompting" and create software interface designs for users without coding experience.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2110746 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A bar chart showing GPT-5's performance on the SWEbench coding benchmark provided by OpenAI." class="fullwidth full" height="1156" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/coding.png" width="958" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A bar chart showing GPT-5's performance on the SWEbench coding benchmark provided by OpenAI.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For health-related queries, OpenAI positions, once again, GPT-5 as its "best model yet," scoring 46.2 percent on HealthBench Hard (a benchmark invented by OpenAI), though the company includes a disclaimer that "ChatGPT does not replace a medical professional." The model can reportedly help users understand medical results and prepare questions for health care providers, though it's best not to blindly trust the outputs of an AI model, because all AI language models, being predictive models tuned for user engagement, tend to tell people what they want to hear.&lt;/p&gt;
&lt;p&gt;In other performance metrics, GPT-5 reportedly achieves 94.6 percent on AIME 2025 for mathematics without tools and 84.2 percent on MMMU for multimodal understanding. And with GPT-5 Pro's extended reasoning, it sets a new state-of-the-art on GPQA at 88.4 percent without tools. OpenAI claims GPT-5 with "thinking" performs better than OpenAI o3 with 50–80 percent lower output tokens across various capabilities.&lt;/p&gt;
&lt;p&gt;GPT-5 reportedly shows significant improvements in accuracy. With web search enabled, GPT-5's responses appear to be around 45 percent less likely to contain factual errors (confabulations) than GPT-4o, and when "thinking," about 80 percent less likely to contain factual errors than o3. On long-form content benchmarks, GPT-5 with thinking shows about six times fewer confabulations than o3. Of course, AI models will fill in gaps in their "knowledge" using plausible-sounding information, so it's best not to rely on their outputs if you cannot check them yourself.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2110745 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A bar chart showing GPT-5's performance on &amp;quot;Humanity's Last Exam,&amp;quot; provided by OpenAI." class="center large" height="690" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/humanity-1024x690.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A bar chart showing GPT-5's performance on "Humanity's Last Exam," provided by OpenAI.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT is also getting interface updates, including customizable chat colors, preset conversation "personalities" (with options like "Cynic," "Robot," "Listener," and "Nerd") that alter the system prompt, and integration with Gmail, Google Calendar, and Google Contacts for Pro users. The voice mode is being unified into a single "Advanced Voice" system that OpenAI says better understands user instructions and adapts its speaking style.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company's approach to response censorship has shifted with what it calls "safe completions." Rather than refusing requests outright, GPT-5 attempts to provide "the most helpful response as possible within safety boundaries," according to OpenAI's announcement. When the model cannot assist with a request, it provides explanations for its limitations.&lt;/p&gt;
&lt;p&gt;OpenAI has also addressed previous issues with sycophancy. Earlier this year, an update to GPT-4o unintentionally made the model overly flattering or agreeable. Through new evaluations and improved training, GPT-5 has reportedly reduced sycophantic replies from 14.5 percent to less than 6 percent in targeted evaluations. Time will tell if this will help reduce the recent streak of triggering delusional and manic behaviors in some people.&lt;/p&gt;
&lt;p&gt;We have not done much hands-on testing with GPT-5 yet but will likely evaluate its performance in more detail in a future article.&lt;/p&gt;
&lt;h2&gt;Developer access and pricing&lt;/h2&gt;
&lt;p&gt;For developers, GPT-5 comes in three API versions: gpt-5, gpt-5-mini, and gpt-5-nano, each offering different latency and cost trade-offs. The context window has expanded to 256,000 tokens, up from 200,000 in OpenAI's previous o3 model. Developers who require larger context windows can still use GPT-4.1 with its 1 million token capacity.&lt;/p&gt;
&lt;p&gt;API pricing for GPT-5 is $1.25 per million input tokens with a 90 percent cache discount and $10 per million output tokens. It's somewhat comparable to GPT-4.1 ($2 input/$8 output per million tokens) and o3 ($2 input/$8 output per million tokens). GPT-5 Mini offers a more economical option at $0.25 per million input tokens and $2 per million output tokens, while GPT-5 Nano provides the most cost-effective but least-capable tier at just $0.05 per million input tokens and $0.40 per million output tokens. GPT-5 Pro pricing hasn't been announced yet for API access.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;New developer features include "free-form function calling" that allows sending raw strings like SQL commands directly to tools without JSON formatting, verbosity controls for response detail, and "reasoning effort control" that lets developers toggle between fast responses and deeper analysis.&lt;/p&gt;
&lt;h2&gt;GPT-5 rollout details&lt;/h2&gt;
&lt;p&gt;The GPT-5 launch comes as OpenAI faces increasing competition from Google's Gemini models, Anthropic's Claude family, and Meta's open-weight Llama models. OpenAI reports having 5 million paying business users and 4 million developers building on its API platform.&lt;/p&gt;
&lt;p&gt;GPT-5 replaces GPT-4o, OpenAI o3, OpenAI o4-mini, GPT-4.1, and GPT-4.5 as the default model for signed-in ChatGPT users. The system automatically applies simulated reasoning when responses would benefit from it, though paid users can still select "GPT-5 Thinking" from the model picker or add phrases like "think hard about this" to ensure reasoning is used.&lt;/p&gt;
&lt;p&gt;The model begins rolling out on Thursday to all user tiers, with enterprise and education customers receiving access next week. OpenAI plans to retire its Standard Voice Mode within 30 days as part of the transition to the unified Advanced Voice system. Once free users reach their GPT-5 usage limits, they transition to GPT-5 mini, a smaller, faster model.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    OpenAI / Benj Edwards
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New model claims fewer confabulations, better coding, and "safe completions" approach.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="GPT-5 header" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-640x360.jpg" width="640" /&gt;
                  &lt;img alt="GPT-5 header" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI announced GPT-5 and three variants—GPT-5 Pro, GPT-5 mini, and GPT-5 nano—what the company calls its "best AI system yet," with availability for some of the models across all ChatGPT tiers, including free users. The new model family arrives with claims of reduced confabulations, improved coding capabilities, and a new approach to handling sensitive requests that OpenAI calls "safe completions."&lt;/p&gt;
&lt;p&gt;It's also the first time OpenAI has given free users access to a simulated reasoning AI model, which breaks problems down into multiple steps using a technique that tends to improve answer accuracy for logical or analytical questions.&lt;/p&gt;
&lt;p&gt;GPT-5 represents OpenAI's latest attempt to unify its various AI capabilities into a single system. The company says the GPT-5 family acts as a "unified system" with a smart, efficient model that answers most questions, a deeper reasoning model called "GPT-5 thinking" for harder problems, and a real-time router that decides which approach to use based on conversation type, complexity, tool needs, and user intent. Like GPT-4o, GPT-5 is a multimodal system that can interact via images, voice, and text.&lt;/p&gt;
&lt;p&gt;The rollout starts today, extending to ChatGPT's 700 million weekly active users, with varying usage limits based on subscription tier. Pro subscribers will receive unlimited access to GPT-5 and the GPT-5 Pro variant, while Plus users receive "significantly higher usage limits" compared to free users, according to a statement from OpenAI. GPT-5 Pro is replacing o3-pro in ChatGPT for those subscriber tiers with access to it.&lt;/p&gt;
&lt;h2&gt;Technical improvements and new features&lt;/h2&gt;
&lt;p&gt;Since the launch of GPT-4 in 2023, we've seen a trend of relative diminishing returns in terms of jumps in capability between major AI model releases. In that sense, the jump in contextual processing capability between GPT-3 and GPT-4 felt shockingly large. The jump between GPT-4 (if you consider the original 2023 version) and GPT-5 is still significant, but when you consider intermediate releases like GPT-4o, GPT-4.5, GPT-4.1, and o3-pro, GPT-5 feels like an incremental upgrade that is unlikely to shock anyone.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We've written about how OpenAI almost used the name "GPT-5" for models like o1 last year but decided to save it for a future release. Why these new models met that branding threshold is unclear, but the "GPT-5" name brand recognition will likely give OpenAI a boost in the public eye amid a heavily competitive industry.&lt;/p&gt;
&lt;p&gt;Among the claimed improvements, OpenAI says GPT-5 delivers its "strongest coding model yet," achieving 74.9 percent on SWE-bench Verified and 88 percent on Aider Polyglot benchmarks. (To compare, earlier this week, Anthropic released Claude Opus 4.1, which reportedly scored 74.5 percent on SWE-bench.) GPT-5 can reportedly complete "complex coding tasks end-to-end with minimal prompting" and create software interface designs for users without coding experience.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2110746 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A bar chart showing GPT-5's performance on the SWEbench coding benchmark provided by OpenAI." class="fullwidth full" height="1156" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/coding.png" width="958" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A bar chart showing GPT-5's performance on the SWEbench coding benchmark provided by OpenAI.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;For health-related queries, OpenAI positions, once again, GPT-5 as its "best model yet," scoring 46.2 percent on HealthBench Hard (a benchmark invented by OpenAI), though the company includes a disclaimer that "ChatGPT does not replace a medical professional." The model can reportedly help users understand medical results and prepare questions for health care providers, though it's best not to blindly trust the outputs of an AI model, because all AI language models, being predictive models tuned for user engagement, tend to tell people what they want to hear.&lt;/p&gt;
&lt;p&gt;In other performance metrics, GPT-5 reportedly achieves 94.6 percent on AIME 2025 for mathematics without tools and 84.2 percent on MMMU for multimodal understanding. And with GPT-5 Pro's extended reasoning, it sets a new state-of-the-art on GPQA at 88.4 percent without tools. OpenAI claims GPT-5 with "thinking" performs better than OpenAI o3 with 50–80 percent lower output tokens across various capabilities.&lt;/p&gt;
&lt;p&gt;GPT-5 reportedly shows significant improvements in accuracy. With web search enabled, GPT-5's responses appear to be around 45 percent less likely to contain factual errors (confabulations) than GPT-4o, and when "thinking," about 80 percent less likely to contain factual errors than o3. On long-form content benchmarks, GPT-5 with thinking shows about six times fewer confabulations than o3. Of course, AI models will fill in gaps in their "knowledge" using plausible-sounding information, so it's best not to rely on their outputs if you cannot check them yourself.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2110745 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A bar chart showing GPT-5's performance on &amp;quot;Humanity's Last Exam,&amp;quot; provided by OpenAI." class="center large" height="690" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/humanity-1024x690.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A bar chart showing GPT-5's performance on "Humanity's Last Exam," provided by OpenAI.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT is also getting interface updates, including customizable chat colors, preset conversation "personalities" (with options like "Cynic," "Robot," "Listener," and "Nerd") that alter the system prompt, and integration with Gmail, Google Calendar, and Google Contacts for Pro users. The voice mode is being unified into a single "Advanced Voice" system that OpenAI says better understands user instructions and adapts its speaking style.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company's approach to response censorship has shifted with what it calls "safe completions." Rather than refusing requests outright, GPT-5 attempts to provide "the most helpful response as possible within safety boundaries," according to OpenAI's announcement. When the model cannot assist with a request, it provides explanations for its limitations.&lt;/p&gt;
&lt;p&gt;OpenAI has also addressed previous issues with sycophancy. Earlier this year, an update to GPT-4o unintentionally made the model overly flattering or agreeable. Through new evaluations and improved training, GPT-5 has reportedly reduced sycophantic replies from 14.5 percent to less than 6 percent in targeted evaluations. Time will tell if this will help reduce the recent streak of triggering delusional and manic behaviors in some people.&lt;/p&gt;
&lt;p&gt;We have not done much hands-on testing with GPT-5 yet but will likely evaluate its performance in more detail in a future article.&lt;/p&gt;
&lt;h2&gt;Developer access and pricing&lt;/h2&gt;
&lt;p&gt;For developers, GPT-5 comes in three API versions: gpt-5, gpt-5-mini, and gpt-5-nano, each offering different latency and cost trade-offs. The context window has expanded to 256,000 tokens, up from 200,000 in OpenAI's previous o3 model. Developers who require larger context windows can still use GPT-4.1 with its 1 million token capacity.&lt;/p&gt;
&lt;p&gt;API pricing for GPT-5 is $1.25 per million input tokens with a 90 percent cache discount and $10 per million output tokens. It's somewhat comparable to GPT-4.1 ($2 input/$8 output per million tokens) and o3 ($2 input/$8 output per million tokens). GPT-5 Mini offers a more economical option at $0.25 per million input tokens and $2 per million output tokens, while GPT-5 Nano provides the most cost-effective but least-capable tier at just $0.05 per million input tokens and $0.40 per million output tokens. GPT-5 Pro pricing hasn't been announced yet for API access.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;New developer features include "free-form function calling" that allows sending raw strings like SQL commands directly to tools without JSON formatting, verbosity controls for response detail, and "reasoning effort control" that lets developers toggle between fast responses and deeper analysis.&lt;/p&gt;
&lt;h2&gt;GPT-5 rollout details&lt;/h2&gt;
&lt;p&gt;The GPT-5 launch comes as OpenAI faces increasing competition from Google's Gemini models, Anthropic's Claude family, and Meta's open-weight Llama models. OpenAI reports having 5 million paying business users and 4 million developers building on its API platform.&lt;/p&gt;
&lt;p&gt;GPT-5 replaces GPT-4o, OpenAI o3, OpenAI o4-mini, GPT-4.1, and GPT-4.5 as the default model for signed-in ChatGPT users. The system automatically applies simulated reasoning when responses would benefit from it, though paid users can still select "GPT-5 Thinking" from the model picker or add phrases like "think hard about this" to ensure reasoning is used.&lt;/p&gt;
&lt;p&gt;The model begins rolling out on Thursday to all user tiers, with enterprise and education customers receiving access next week. OpenAI plans to retire its Standard Voice Mode within 30 days as part of the transition to the unified Advanced Voice system. Once free users reach their GPT-5 usage limits, they transition to GPT-5 mini, a smaller, faster model.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    OpenAI / Benj Edwards
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/openai-launches-gpt-5-free-to-all-chatgpt-users/</guid><pubDate>Thu, 07 Aug 2025 17:48:57 +0000</pubDate></item><item><title>[NEW] After using ChatGPT, man swaps his salt for sodium bromide—and suffers psychosis (AI – Ars Technica)</title><link>https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Literal "hallucinations" were the result.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-1152x648-1754591948.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Bromine—you don't want too much in your diet!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After seeking advice on health topics from ChatGPT, a 60-year-old man who had a "history of studying nutrition in college" decided to try a health experiment: He would eliminate all chlorine from his diet, which for him meant eliminating even table salt (sodium chloride). His ChatGPT conversations led him to believe that he could replace his sodium chloride with sodium bromide, which he obtained over the Internet.&lt;/p&gt;
&lt;p&gt;Three months later, the man showed up at his local emergency room. His neighbor, he said, was trying to poison him. Though extremely thirsty, the man was paranoid about accepting the water that the hospital offered him, telling doctors that he had begun distilling his own water at home and that he was on an extremely restrictive vegetarian diet. He did not mention the sodium bromide or the ChatGPT discussions.&lt;/p&gt;
&lt;p&gt;His distress, coupled with the odd behavior, led the doctors to run a broad set of lab tests, revealing multiple micronutrient deficiencies, especially in key vitamins. But the bigger problem was that the man appeared to be suffering from a serious case of "bromism." That is, an excess amount of the element bromine had built up in his body.&lt;/p&gt;
&lt;p&gt;A century ago, somewhere around 8–10 percent of all psychiatric admissions in the US were caused by bromism. That's because, then as now, people wanted sedatives to calm their anxieties, to blot out a cruel world, or simply to get a good night's sleep. Bromine-containing salts—things like potassium bromide—were once drugs of choice for this sort of thing.&lt;/p&gt;
&lt;p&gt;Unfortunately, bromide can easily build up in the human body, where too much of it impairs nerve function. This causes a wide variety of problems, including grotesque skin rashes (warning: the link is exactly what it sounds like) and significant mental problems, which are all grouped under the name of "bromism."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bromide sedatives vanished from the US market by 1989, after the Food and Drug Administration banned them, and "bromism" as a syndrome is today unfamiliar to many Americans. (Though you can still get it by drinking, as one poor guy did, two to four liters of cola daily [!], if that cola contains "brominated vegetable oil." Fortunately, the FDA removed brominated vegetable oil from US food products in 2024.)&lt;/p&gt;
&lt;p&gt;In this case, over the man's first day at the hospital, he grew worse and showed "increasing paranoia and auditory and visual hallucinations." He then attempted to escape the facility.&lt;/p&gt;
&lt;p&gt;After the escape attempt, the man was given an involuntary psychiatric hold and an anti-psychosis drug. He was administered large amounts of fluids and electrolytes, as the best way to beat bromism is "aggressive saline diuresis"—that is, to load someone up with liquids and let them pee out all the bromide in their system.&lt;/p&gt;
&lt;p&gt;This took time, as the man's bromide level was eventually measured at a whopping 1,700 mg/L, while the "reference range" for healthy people is 0.9 to 7.3 mg/L.&lt;/p&gt;
&lt;p&gt;In the end, the man suffered from a terrifying psychosis and was kept in the hospital for &lt;em&gt;three full weeks&lt;/em&gt; over an entirely preventable condition.&lt;/p&gt;
&lt;h2&gt;How it all began&lt;/h2&gt;
&lt;p&gt;It was during his stay, once doctors had his psychosis under control, that the man began telling them how it all began. He had read about the problems with too much table salt, which led him to rid his diet of sodium chloride, which led him to ChatGPT, which led him to believe that he could use sodium bromide instead.&lt;/p&gt;
&lt;p&gt;The doctors who wrote up this case study for Annals of Internal Medicine: Clinical Cases note that they never got access to the man's actual ChatGPT logs. He likely used ChatGPT 3.5 or 4.0, they say, but it's not clear that the man was actually told by the chatbot to do what he did. Bromide salts &lt;em&gt;can&lt;/em&gt; be substituted for table salt—just not in the human body. They are used in various cleaning products and pool treatments, however.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;When the doctors tried their own searches in ChatGPT 3.5, they found that the AI did include bromide in its response, but it also indicated that context mattered and that bromide was not suitable for all uses. But the AI "did not provide a specific health warning, nor did it inquire about why we wanted to know, as we presume a medical professional would do," wrote the doctors.&lt;/p&gt;
&lt;p&gt;The current free model of ChatGPT appears to be better at answering this sort of query. When I asked it how to replace chloride in my diet, it first asked to "clarify your goal," giving me three choices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduce salt (sodium chloride) in your diet or home use?&lt;/li&gt;
&lt;li&gt;Avoid toxic/reactive chlorine compounds like bleach or pool chlorine?&lt;/li&gt;
&lt;li&gt;Replace chlorine-based cleaning or disinfecting agents?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ChatGPT did list bromide as an alternative, but only under the third option (cleaning or disinfecting), noting that bromide treatments are "often used in hot tubs."&lt;/p&gt;
&lt;p&gt;Left to his own devices, then, without knowing quite what to ask or how to interpret the responses, the man in this case study "did his own research" and ended up in a pretty dark place. The story seems like a perfect cautionary tale for the modern age, where we are drowning in information—but where we often lack the economic resources, the information-vetting skills, the domain-specific knowledge, or the trust in others that would help us make the best use of it.&lt;/p&gt;
&lt;p&gt;Annals of Internal Medicine: Clinical Cases, 2025. DOI: 10.7326/aimcc.2024.1260 &amp;nbsp;(About DOIs)&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Literal "hallucinations" were the result.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-1152x648-1754591948.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Bromine—you don't want too much in your diet!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After seeking advice on health topics from ChatGPT, a 60-year-old man who had a "history of studying nutrition in college" decided to try a health experiment: He would eliminate all chlorine from his diet, which for him meant eliminating even table salt (sodium chloride). His ChatGPT conversations led him to believe that he could replace his sodium chloride with sodium bromide, which he obtained over the Internet.&lt;/p&gt;
&lt;p&gt;Three months later, the man showed up at his local emergency room. His neighbor, he said, was trying to poison him. Though extremely thirsty, the man was paranoid about accepting the water that the hospital offered him, telling doctors that he had begun distilling his own water at home and that he was on an extremely restrictive vegetarian diet. He did not mention the sodium bromide or the ChatGPT discussions.&lt;/p&gt;
&lt;p&gt;His distress, coupled with the odd behavior, led the doctors to run a broad set of lab tests, revealing multiple micronutrient deficiencies, especially in key vitamins. But the bigger problem was that the man appeared to be suffering from a serious case of "bromism." That is, an excess amount of the element bromine had built up in his body.&lt;/p&gt;
&lt;p&gt;A century ago, somewhere around 8–10 percent of all psychiatric admissions in the US were caused by bromism. That's because, then as now, people wanted sedatives to calm their anxieties, to blot out a cruel world, or simply to get a good night's sleep. Bromine-containing salts—things like potassium bromide—were once drugs of choice for this sort of thing.&lt;/p&gt;
&lt;p&gt;Unfortunately, bromide can easily build up in the human body, where too much of it impairs nerve function. This causes a wide variety of problems, including grotesque skin rashes (warning: the link is exactly what it sounds like) and significant mental problems, which are all grouped under the name of "bromism."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bromide sedatives vanished from the US market by 1989, after the Food and Drug Administration banned them, and "bromism" as a syndrome is today unfamiliar to many Americans. (Though you can still get it by drinking, as one poor guy did, two to four liters of cola daily [!], if that cola contains "brominated vegetable oil." Fortunately, the FDA removed brominated vegetable oil from US food products in 2024.)&lt;/p&gt;
&lt;p&gt;In this case, over the man's first day at the hospital, he grew worse and showed "increasing paranoia and auditory and visual hallucinations." He then attempted to escape the facility.&lt;/p&gt;
&lt;p&gt;After the escape attempt, the man was given an involuntary psychiatric hold and an anti-psychosis drug. He was administered large amounts of fluids and electrolytes, as the best way to beat bromism is "aggressive saline diuresis"—that is, to load someone up with liquids and let them pee out all the bromide in their system.&lt;/p&gt;
&lt;p&gt;This took time, as the man's bromide level was eventually measured at a whopping 1,700 mg/L, while the "reference range" for healthy people is 0.9 to 7.3 mg/L.&lt;/p&gt;
&lt;p&gt;In the end, the man suffered from a terrifying psychosis and was kept in the hospital for &lt;em&gt;three full weeks&lt;/em&gt; over an entirely preventable condition.&lt;/p&gt;
&lt;h2&gt;How it all began&lt;/h2&gt;
&lt;p&gt;It was during his stay, once doctors had his psychosis under control, that the man began telling them how it all began. He had read about the problems with too much table salt, which led him to rid his diet of sodium chloride, which led him to ChatGPT, which led him to believe that he could use sodium bromide instead.&lt;/p&gt;
&lt;p&gt;The doctors who wrote up this case study for Annals of Internal Medicine: Clinical Cases note that they never got access to the man's actual ChatGPT logs. He likely used ChatGPT 3.5 or 4.0, they say, but it's not clear that the man was actually told by the chatbot to do what he did. Bromide salts &lt;em&gt;can&lt;/em&gt; be substituted for table salt—just not in the human body. They are used in various cleaning products and pool treatments, however.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;When the doctors tried their own searches in ChatGPT 3.5, they found that the AI did include bromide in its response, but it also indicated that context mattered and that bromide was not suitable for all uses. But the AI "did not provide a specific health warning, nor did it inquire about why we wanted to know, as we presume a medical professional would do," wrote the doctors.&lt;/p&gt;
&lt;p&gt;The current free model of ChatGPT appears to be better at answering this sort of query. When I asked it how to replace chloride in my diet, it first asked to "clarify your goal," giving me three choices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduce salt (sodium chloride) in your diet or home use?&lt;/li&gt;
&lt;li&gt;Avoid toxic/reactive chlorine compounds like bleach or pool chlorine?&lt;/li&gt;
&lt;li&gt;Replace chlorine-based cleaning or disinfecting agents?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ChatGPT did list bromide as an alternative, but only under the third option (cleaning or disinfecting), noting that bromide treatments are "often used in hot tubs."&lt;/p&gt;
&lt;p&gt;Left to his own devices, then, without knowing quite what to ask or how to interpret the responses, the man in this case study "did his own research" and ended up in a pretty dark place. The story seems like a perfect cautionary tale for the modern age, where we are drowning in information—but where we often lack the economic resources, the information-vetting skills, the domain-specific knowledge, or the trust in others that would help us make the best use of it.&lt;/p&gt;
&lt;p&gt;Annals of Internal Medicine: Clinical Cases, 2025. DOI: 10.7326/aimcc.2024.1260 &amp;nbsp;(About DOIs)&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/</guid><pubDate>Thu, 07 Aug 2025 19:20:24 +0000</pubDate></item><item><title>[NEW] High costs and thin margins threatening AI coding startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/the-high-costs-and-thin-margins-threatening-ai-coding-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In February, AI coding startup Windsurf was in talks to raise a big new round at a $2.85 billion valuation led by Kleiner Perkins, at double the valuation it hit six months earlier, sources told TechCrunch at the time. That deal didn’t happen, according to a source familiar with the matter. Instead,&amp;nbsp;news broke in April that the startup planned to sell itself to OpenAI for roughly the same valuation: $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While that deal famously fell apart, one bigger question remains: If the startup was growing that fast and attracting VC interest, why would it sell at all?&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Insiders tell TechCrunch that for all the popularity and hype around AI coding assistants, they can actually be massively money-losing businesses. Vibe coders generally, and Windsurf in particular, can have such expensive structures that their gross margins are “very negative,” one person close to Windsurf told TechCrunch. Meaning it cost more to run the product than the startup could charge for it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is due to the high costs of using large language models (LLMs), the person explained. AI coding assistants are particularly pressured to always offer the most recent, most advanced, and most expensive LLMs because model makers are particularly fine-tuning their latest models for improvements in coding and related tasks like debugging.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a challenge compounded by fierce competition in the vibe-coding and code-assist market. Rivals include companies that already have huge customer bases like Anysphere’s Cursor and GitHub Copilot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most straightforward path to improving margins in this business involves the startups building their own models, thereby eliminating costs of paying suppliers like Anthropic and OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very expensive business to run if you’re not going to be in the model game,” said the person.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But that idea comes with its own risks. Windsurf’s co-founder and CEO, Varun Mohan, ultimately decided against the company building its own model — an expensive undertaking, the person said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, model makers are already competing directly. Anthropic offers Claude Code and OpenAI offers Codex, for instance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Selling the business was a strategic move to lock in a high return before it could be undermined by the very companies that supplied its AI, including OpenAI and Anthropic, which were also entering the AI coding market.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Multiple people believe that the same pressure on margins Windsurf faced could be impacting Anysphere, the maker of Cursor, as well as vibe coders like Lovable, Replit, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Margins on all of the ‘code gen’ products are either neutral or negative. They’re absolutely abysmal,” said Nicholas Charriere, founder of Mocha, a vibe-coding startup and back-end hosting solution serving small and medium businesses (SMBs). He added that he believes the variable costs for all the startups in the sector are very close, likely within 10% to 15% of one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Windsurf, Anysphere has been growing so fast that it intends to remain an independent company, having already turned down acquisition offers, including, reports say, from OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Anysphere announced in January that it is attempting to build its own model, which could give it more control over its expenses.&lt;strong&gt; &lt;/strong&gt;In July, the startup hired two leaders from Anthropic’s Claude Code team, the Information reported, but two weeks later, these employees returned to work at Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to building a model, Anysphere could expect the cost of LLMs to decrease over time.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what everyone’s banking on,” said Erik Nordlander, a general partner at Google Ventures. “The inference cost today, that’s the most expensive it’s ever going to be.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not entirely clear how true that is. Rather than falling as expected, the cost of some of the latest AI models has risen, as they use more time and computational resources to handle complicated, multistep tasks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When that will change remains to be seen. On Thursday, for instance, OpenAI introduced a new flagship model, GPT-5, with fees that are significantly less than its competitor, Anthropic’s Claude Opus 4.1. And Anysphere immediately offered this model as a choice for Cursor users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anysphere has also recently changed its pricing structure to pass along the increased costs of running Anthropic’s latest Claude model, particularly to its most active users. The move caught some of Cursor customers by surprise, since they didn’t expect additional charges on top of its $20-per-month Pro plan. Anysphere CEO Michael Truell later apologized for unclear communication about the pricing change in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the rock and the hard place. Although Cursor is one of the most popular AI applications, having reached $500 million in ARR in June, the company’s user base may not be so loyal to the product if another company develops a tool that is superior to Cursor, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given the competitive landscape and the costs, Windsurf’s decision to get out may prove to be understandable. After the OpenAI deal fell through, the founders and key employees left to join Google in a deal that led to a $2.4 billion payout to key shareholders. The remaining business then sold itself to Cognition.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many, including prominent VCs, criticized Mohan for leaving approximately 200 employees without roles at Google, a source familiar with the deal insisted the acquisition actually maximized the outcomes for all employees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, other AI coding tools are also among the fastest growing startups of the LLM generation, like Replit, Lovable, and Bolt, and all of them rely on model makers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, if this extremely popular business sector, already generating hundreds of millions in revenue or more a year, has difficulty building on top of model makers, what might it mean for other, more nascent industries?&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In February, AI coding startup Windsurf was in talks to raise a big new round at a $2.85 billion valuation led by Kleiner Perkins, at double the valuation it hit six months earlier, sources told TechCrunch at the time. That deal didn’t happen, according to a source familiar with the matter. Instead,&amp;nbsp;news broke in April that the startup planned to sell itself to OpenAI for roughly the same valuation: $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While that deal famously fell apart, one bigger question remains: If the startup was growing that fast and attracting VC interest, why would it sell at all?&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Insiders tell TechCrunch that for all the popularity and hype around AI coding assistants, they can actually be massively money-losing businesses. Vibe coders generally, and Windsurf in particular, can have such expensive structures that their gross margins are “very negative,” one person close to Windsurf told TechCrunch. Meaning it cost more to run the product than the startup could charge for it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is due to the high costs of using large language models (LLMs), the person explained. AI coding assistants are particularly pressured to always offer the most recent, most advanced, and most expensive LLMs because model makers are particularly fine-tuning their latest models for improvements in coding and related tasks like debugging.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a challenge compounded by fierce competition in the vibe-coding and code-assist market. Rivals include companies that already have huge customer bases like Anysphere’s Cursor and GitHub Copilot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most straightforward path to improving margins in this business involves the startups building their own models, thereby eliminating costs of paying suppliers like Anthropic and OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very expensive business to run if you’re not going to be in the model game,” said the person.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But that idea comes with its own risks. Windsurf’s co-founder and CEO, Varun Mohan, ultimately decided against the company building its own model — an expensive undertaking, the person said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, model makers are already competing directly. Anthropic offers Claude Code and OpenAI offers Codex, for instance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Selling the business was a strategic move to lock in a high return before it could be undermined by the very companies that supplied its AI, including OpenAI and Anthropic, which were also entering the AI coding market.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Multiple people believe that the same pressure on margins Windsurf faced could be impacting Anysphere, the maker of Cursor, as well as vibe coders like Lovable, Replit, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Margins on all of the ‘code gen’ products are either neutral or negative. They’re absolutely abysmal,” said Nicholas Charriere, founder of Mocha, a vibe-coding startup and back-end hosting solution serving small and medium businesses (SMBs). He added that he believes the variable costs for all the startups in the sector are very close, likely within 10% to 15% of one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Windsurf, Anysphere has been growing so fast that it intends to remain an independent company, having already turned down acquisition offers, including, reports say, from OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Anysphere announced in January that it is attempting to build its own model, which could give it more control over its expenses.&lt;strong&gt; &lt;/strong&gt;In July, the startup hired two leaders from Anthropic’s Claude Code team, the Information reported, but two weeks later, these employees returned to work at Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to building a model, Anysphere could expect the cost of LLMs to decrease over time.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what everyone’s banking on,” said Erik Nordlander, a general partner at Google Ventures. “The inference cost today, that’s the most expensive it’s ever going to be.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not entirely clear how true that is. Rather than falling as expected, the cost of some of the latest AI models has risen, as they use more time and computational resources to handle complicated, multistep tasks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When that will change remains to be seen. On Thursday, for instance, OpenAI introduced a new flagship model, GPT-5, with fees that are significantly less than its competitor, Anthropic’s Claude Opus 4.1. And Anysphere immediately offered this model as a choice for Cursor users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anysphere has also recently changed its pricing structure to pass along the increased costs of running Anthropic’s latest Claude model, particularly to its most active users. The move caught some of Cursor customers by surprise, since they didn’t expect additional charges on top of its $20-per-month Pro plan. Anysphere CEO Michael Truell later apologized for unclear communication about the pricing change in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the rock and the hard place. Although Cursor is one of the most popular AI applications, having reached $500 million in ARR in June, the company’s user base may not be so loyal to the product if another company develops a tool that is superior to Cursor, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given the competitive landscape and the costs, Windsurf’s decision to get out may prove to be understandable. After the OpenAI deal fell through, the founders and key employees left to join Google in a deal that led to a $2.4 billion payout to key shareholders. The remaining business then sold itself to Cognition.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many, including prominent VCs, criticized Mohan for leaving approximately 200 employees without roles at Google, a source familiar with the deal insisted the acquisition actually maximized the outcomes for all employees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, other AI coding tools are also among the fastest growing startups of the LLM generation, like Replit, Lovable, and Bolt, and all of them rely on model makers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, if this extremely popular business sector, already generating hundreds of millions in revenue or more a year, has difficulty building on top of model makers, what might it mean for other, more nascent industries?&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/the-high-costs-and-thin-margins-threatening-ai-coding-startups/</guid><pubDate>Thu, 07 Aug 2025 21:05:01 +0000</pubDate></item><item><title>[NEW] Tesla shuts down Dojo, the AI training supercomputer that Musk said would be key to full self-driving (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/tesla-shuts-down-dojo-the-ai-training-supercomputer-that-musk-said-would-be-key-to-full-self-driving/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is breaking up the team behind its Dojo supercomputer, ending the automaker’s play at developing in-house chips for driverless technology, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s lead, Peter Bannon, is leaving the company, and the remaining team members will be reassigned to other data center and compute projects within Tesla, per Bloomberg’s reporting, which cited anonymous sources.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The disbanding of Tesla’s Dojo efforts follows the departure of around 20 workers, who left the automaker to start their own AI company called DensityAI. The new startup is reportedly coming out of stealth soon and is building chips, hardware, and software that will power data centers for AI that are used in robotics, by AI agents, and in automotive applications. DensityAI was founded by former Dojo head Ganesh Venkataramanan and ex-Tesla employees Bill Chang and Ben Floering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also comes at a crucial time for Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Elon Musk has pushed to get shareholders to view Tesla as an AI and robotics company, despite a limited robotaxi launch in Austin this past June that featured Model Y vehicles with a human in the front passenger seat and resulted in a number of reported incidents of the vehicles exhibiting problematic driving behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s decision to shut down Dojo, which Musk has been talking about since 2019, is a major shift in strategy. Musk has said that Dojo would be the cornerstone of Tesla’s AI ambitions and its goal to reach full self-driving due to its ability to “process truly vast amounts of video data.”&amp;nbsp;He talked about Dojo, albeit briefly, as recently as the company’s second-quarter earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Morgan Stanley predicted Dojo could add $500 billion to the company’s market value by unlocking new revenue streams in the form of robotaxis and software services. Just last year, Musk noted that Tesla’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But talk about Dojo halted around August 2024, when Musk began touting Cortex instead, Tesla’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Dojo project was one part supercomputer, one part in-house chip-making. Tesla unveiled its D1 chip when it formally announced Dojo at its first AI Day in 2021. Venkataramanan presented the chip, which Tesla said would be used alongside Nvidia’s GPU to power the Dojo supercomputer. The automaker also said it was working on a next-gen D2 chip that would solve any information flow bottlenecks of its predecessor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told Bloomberg that now Tesla plans to increase its reliance on Nvidia, as well as other external tech partners like AMD for compute and Samsung for chip manufacturing. Tesla last month signed a $16.5 billion deal with Samsung to make its AI6 inference chips, a chip design that promises to scale from powering FSD and Tesla’s Optimus humanoid robots all the way to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter earnings call, Musk hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Tesla’s board offers Musk a $29 billion pay package to keep him at Tesla and help push the company’s AI efforts forward, rather than getting too sidetracked by his other companies, including the more pure-play AI startup xAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Tesla for more information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Have a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is breaking up the team behind its Dojo supercomputer, ending the automaker’s play at developing in-house chips for driverless technology, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s lead, Peter Bannon, is leaving the company, and the remaining team members will be reassigned to other data center and compute projects within Tesla, per Bloomberg’s reporting, which cited anonymous sources.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The disbanding of Tesla’s Dojo efforts follows the departure of around 20 workers, who left the automaker to start their own AI company called DensityAI. The new startup is reportedly coming out of stealth soon and is building chips, hardware, and software that will power data centers for AI that are used in robotics, by AI agents, and in automotive applications. DensityAI was founded by former Dojo head Ganesh Venkataramanan and ex-Tesla employees Bill Chang and Ben Floering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also comes at a crucial time for Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Elon Musk has pushed to get shareholders to view Tesla as an AI and robotics company, despite a limited robotaxi launch in Austin this past June that featured Model Y vehicles with a human in the front passenger seat and resulted in a number of reported incidents of the vehicles exhibiting problematic driving behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s decision to shut down Dojo, which Musk has been talking about since 2019, is a major shift in strategy. Musk has said that Dojo would be the cornerstone of Tesla’s AI ambitions and its goal to reach full self-driving due to its ability to “process truly vast amounts of video data.”&amp;nbsp;He talked about Dojo, albeit briefly, as recently as the company’s second-quarter earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Morgan Stanley predicted Dojo could add $500 billion to the company’s market value by unlocking new revenue streams in the form of robotaxis and software services. Just last year, Musk noted that Tesla’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But talk about Dojo halted around August 2024, when Musk began touting Cortex instead, Tesla’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Dojo project was one part supercomputer, one part in-house chip-making. Tesla unveiled its D1 chip when it formally announced Dojo at its first AI Day in 2021. Venkataramanan presented the chip, which Tesla said would be used alongside Nvidia’s GPU to power the Dojo supercomputer. The automaker also said it was working on a next-gen D2 chip that would solve any information flow bottlenecks of its predecessor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told Bloomberg that now Tesla plans to increase its reliance on Nvidia, as well as other external tech partners like AMD for compute and Samsung for chip manufacturing. Tesla last month signed a $16.5 billion deal with Samsung to make its AI6 inference chips, a chip design that promises to scale from powering FSD and Tesla’s Optimus humanoid robots all the way to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter earnings call, Musk hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Tesla’s board offers Musk a $29 billion pay package to keep him at Tesla and help push the company’s AI efforts forward, rather than getting too sidetracked by his other companies, including the more pure-play AI startup xAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Tesla for more information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Have a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/tesla-shuts-down-dojo-the-ai-training-supercomputer-that-musk-said-would-be-key-to-full-self-driving/</guid><pubDate>Thu, 07 Aug 2025 22:19:50 +0000</pubDate></item><item><title>[NEW] Black Hat 2025: Why your AI tools are becoming the next insider threat (AI News | VentureBeat)</title><link>https://venturebeat.com/security/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value/</link><description>&lt;p&gt;Cloud intrusions &lt;span&gt;increased&amp;nbsp;by 136%&amp;nbsp;in the past&amp;nbsp;&lt;/span&gt;six months. North Korean operatives infiltrated 320 companies using AI-generated identities. Scattered Spider now deploys ransomware in under 24 hours. &lt;span&gt;However, at&amp;nbsp;Black Hat 2025, the security industry demonstrated that it finally has an answer that works: agentic AI,&lt;/span&gt; delivering measurable results, not promises.&lt;/p&gt;&lt;p&gt;CrowdStrike’s recent identification of 28 North Korean operatives embedded as remote IT workers, part of a broader campaign affecting 320 companies, demonstrates how agentic AI is evolving from concept to practical threat detection.&lt;/p&gt;&lt;p&gt;While nearly every vendor at Black Hat 2025 had performance metrics available, either from beta programs in process or full-production agentic AI deployments, the strongest theme was operational readiness over hype or theoretical claims.&lt;/p&gt;&lt;p&gt;CISOs VentureBeat spoke with at Black Hat are reporting the ability to process significantly more alerts with current staffing levels, with investigation times improving substantially. However, specific gains depend on the implementation maturity and complexity of the use case. What’s notable is the transition from aspirational roadmaps to real-world outcomes.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat is also starting to see security teams begin to achieve practical, real efficiency gains that translate to the metrics boards ask about. These include reducing the mean time to investigate (MTTI), improving threat detection rates and better resource utilization. Black Hat 2025 marked an inflection point where the conversation shifted from AI’s potential to its measured impact on security operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agentic-ai-arms-race-shifts-from-promises-to-production"&gt;&lt;strong&gt;The agentic AI arms race shifts from promises to production&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That’s a welcome change from the many promises made in prior years and at previous years. There’s an urgency to close hype gaps and deliver results. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Adam Meyers, head of counter adversary operations, articulated what’s driving this urgency in an interview with VentureBeat: “Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they’re using MCP servers to get access to APIs. We’re starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.”&lt;/p&gt;



&lt;p&gt;VentureBeat believes the scale of the threat demands this response. “When they’re moving at that speed, you can’t wait,” Meyers emphasized, referencing how some adversaries now deploy ransomware in under 24 hours. “You need to have human threat hunters in the loop that are making you know, as soon as the adversary gets access, or as soon as the adversary pops up, they’re there, and they’re doing hand-to-hand combat with those adversaries.”&lt;/p&gt;



&lt;p&gt;“Last year, we looked at 60 billion hunting leads that result in about 13 million investigations, 27,000 customer escalations and 4000 emails that we started sending to customers,” Meyers revealed, emphasizing the scale at which these systems now operate. Microsoft Security unveiled significant enhancements to its Security Copilot, introducing autonomous investigation capabilities that can correlate threats across Microsoft Defender, Sentinel and third-party security tools without human intervention. Palo Alto Networks demonstrated Cortex XSOAR’s new agentic capabilities, showing how their platform can now autonomously triage alerts, conduct investigations and even execute remediation actions within defined guardrails.&lt;/p&gt;



&lt;p&gt;Cisco made one of Black Hat’s most significant announcements, releasing Foundation-sec-8B-Instruct, the first conversational AI model built exclusively for cybersecurity. This eight-billion-parameter model outperforms much larger general-purpose models, including GPT-4o-mini, on security tasks while running on a single GPU.&lt;/p&gt;



&lt;p&gt;What sets this release apart is its fully open-source architecture. Foundation-sec-8B-Instruct ships with completely open weights under a permissive license, enabling security teams to deploy it on-premises, in air-gapped environments or at the edge without vendor lock-in. The model is freely available on Hugging Face, accompanied by the Foundation AI Cookbook featuring deployment guides and implementation templates.&lt;/p&gt;



&lt;p&gt;“Foundation-sec-8B-Instruct is live, open, and ready to defend. Download it, prompt it and help shape the future of AI-powered cybersecurity,” states Yaron Singer, VP of AI and Security at Foundation, emphasizing the collaborative potential of this open-source approach.&lt;/p&gt;



&lt;p&gt;SentinelOne took a different approach, emphasizing their Purple AI’s ability not just to investigate but actually “think ahead” or predict adversary moves based on behavioral patterns and proactively adjusting defenses.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015301" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-7-crowdstrike-report.jpg?w=792" width="792" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;CrowdStrike’s threat intelligence reveals how adversaries like FAMOUS CHOLLIMA are weaponizing gen AI at every stage of insider threat operations, from creating synthetic identities to managing multiple simultaneous employment positions. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-north-korean-threat-changed-everything-fast"&gt;&lt;strong&gt;How the North Korean threat changed everything fast&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;FAMOUS CHOLLIMA operatives infiltrated over 320 companies in the past year. That’s a 220% year-over-year increase, representing a fundamental shift in enterprise security threats.&lt;/p&gt;



&lt;p&gt;“They’re using AI through the entire process,” Meyers told VentureBeat during an interview. “They’re using generative AI to create LinkedIn profiles, to create resumes and then they go into the interview, and they’re using deep fake technology to change their appearance. They’re using AI to answer questions during the interview process. They’re using AI, once they get hired, to build the code and do the work that they’re supposed to do.”&lt;/p&gt;



&lt;p&gt;The infrastructure supporting these operations is sophisticated. One Arizona-based facilitator maintained 90 laptops to enable remote access. Operations have expanded beyond the U.S. to France, Canada and Japan as adversaries diversify their targeting.&lt;/p&gt;



&lt;p&gt;CrowdStrike’s July data reveals the scope: 33 FAMOUS CHOLLIMA encounters, with 28 confirmed as malicious insiders who had successfully obtained employment. These are AI-enhanced operators working within organizations, using legitimate credentials, rather than relying on traditional malware attacks that security tools can detect.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-the-human-element-remains-vital"&gt;&lt;strong&gt;Why the human element remains vital&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite the technological advances, a consistent theme across all vendor presentations was that agentic AI augments rather than replaces human analysts. “Agentic AI, as good as it is, is not going to replace the humans that are in the loop. You need human threat hunters out there that are able to use their insight and their know-how and their intellect to come up with creative ways to try to find these adversaries,” Meyers emphasized.&lt;/p&gt;



&lt;p&gt;Every major vendor echoed this human-machine collaboration model. Splunk’s announcement of Mission Control emphasized how its agentic AI serves as a “force multiplier” for analysts, handling routine tasks while escalating complex decisions to humans. Even the most ardent advocates of automation acknowledged that human oversight remains essential for high-stakes decisions and creative problem-solving.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competition-shifts-from-features-to-results"&gt;&lt;strong&gt;Competition shifts from features to results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.&lt;/p&gt;



&lt;p&gt;Google Cloud Security’s Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015302" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-6-crowdstrike-report.jpg?w=589" width="589" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-many-are-predicting-that-ai-will-become-the-next-insider-threat"&gt;&lt;strong&gt;Many are predicting that AI will become the next insider threat&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: “AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they’re going to check the output.”&lt;/p&gt;



&lt;p&gt;This concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike’s expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco’s AI supply chain security initiative with Hugging Face, signals the industry’s recognition that securing AI agents themselves is becoming as important as using them for security.&lt;/p&gt;



&lt;p&gt;The velocity of change is accelerating. “Adversaries are moving incredibly fast,” Meyers warned. “Scattered spider hit retail back in April, they were hitting insurance companies in May, they were hitting aviation in June and July.” The ability to iterate and adapt at this speed means organizations can’t afford to wait for perfect solutions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bottom-line"&gt;&lt;strong&gt;Bottom Line&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;This year’s Black Hat confirmed what many cybersecurity professionals saw coming. AI-driven attacks now threaten their organizations across a widening array of surfaces, many of them unexpected.&lt;/p&gt;



&lt;p&gt;Human resources and hiring became the threat surface no one saw coming. FAMOUS CHOLLIMA operatives are penetrating every possible U.S. and Western technology company they can, grabbing immediate cash to fuel North Korea’s weapons programs while stealing invaluable intellectual property. This creates an entirely new dimension to attacks. Organizations and the security leaders guiding them would do well to remember what hangs in the balance of getting this right: your businesses’ core IP, national security, and the trust customers have in the organizations they do business with.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Cloud intrusions &lt;span&gt;increased&amp;nbsp;by 136%&amp;nbsp;in the past&amp;nbsp;&lt;/span&gt;six months. North Korean operatives infiltrated 320 companies using AI-generated identities. Scattered Spider now deploys ransomware in under 24 hours. &lt;span&gt;However, at&amp;nbsp;Black Hat 2025, the security industry demonstrated that it finally has an answer that works: agentic AI,&lt;/span&gt; delivering measurable results, not promises.&lt;/p&gt;&lt;p&gt;CrowdStrike’s recent identification of 28 North Korean operatives embedded as remote IT workers, part of a broader campaign affecting 320 companies, demonstrates how agentic AI is evolving from concept to practical threat detection.&lt;/p&gt;&lt;p&gt;While nearly every vendor at Black Hat 2025 had performance metrics available, either from beta programs in process or full-production agentic AI deployments, the strongest theme was operational readiness over hype or theoretical claims.&lt;/p&gt;&lt;p&gt;CISOs VentureBeat spoke with at Black Hat are reporting the ability to process significantly more alerts with current staffing levels, with investigation times improving substantially. However, specific gains depend on the implementation maturity and complexity of the use case. What’s notable is the transition from aspirational roadmaps to real-world outcomes.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat is also starting to see security teams begin to achieve practical, real efficiency gains that translate to the metrics boards ask about. These include reducing the mean time to investigate (MTTI), improving threat detection rates and better resource utilization. Black Hat 2025 marked an inflection point where the conversation shifted from AI’s potential to its measured impact on security operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agentic-ai-arms-race-shifts-from-promises-to-production"&gt;&lt;strong&gt;The agentic AI arms race shifts from promises to production&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That’s a welcome change from the many promises made in prior years and at previous years. There’s an urgency to close hype gaps and deliver results. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Adam Meyers, head of counter adversary operations, articulated what’s driving this urgency in an interview with VentureBeat: “Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they’re using MCP servers to get access to APIs. We’re starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.”&lt;/p&gt;



&lt;p&gt;VentureBeat believes the scale of the threat demands this response. “When they’re moving at that speed, you can’t wait,” Meyers emphasized, referencing how some adversaries now deploy ransomware in under 24 hours. “You need to have human threat hunters in the loop that are making you know, as soon as the adversary gets access, or as soon as the adversary pops up, they’re there, and they’re doing hand-to-hand combat with those adversaries.”&lt;/p&gt;



&lt;p&gt;“Last year, we looked at 60 billion hunting leads that result in about 13 million investigations, 27,000 customer escalations and 4000 emails that we started sending to customers,” Meyers revealed, emphasizing the scale at which these systems now operate. Microsoft Security unveiled significant enhancements to its Security Copilot, introducing autonomous investigation capabilities that can correlate threats across Microsoft Defender, Sentinel and third-party security tools without human intervention. Palo Alto Networks demonstrated Cortex XSOAR’s new agentic capabilities, showing how their platform can now autonomously triage alerts, conduct investigations and even execute remediation actions within defined guardrails.&lt;/p&gt;



&lt;p&gt;Cisco made one of Black Hat’s most significant announcements, releasing Foundation-sec-8B-Instruct, the first conversational AI model built exclusively for cybersecurity. This eight-billion-parameter model outperforms much larger general-purpose models, including GPT-4o-mini, on security tasks while running on a single GPU.&lt;/p&gt;



&lt;p&gt;What sets this release apart is its fully open-source architecture. Foundation-sec-8B-Instruct ships with completely open weights under a permissive license, enabling security teams to deploy it on-premises, in air-gapped environments or at the edge without vendor lock-in. The model is freely available on Hugging Face, accompanied by the Foundation AI Cookbook featuring deployment guides and implementation templates.&lt;/p&gt;



&lt;p&gt;“Foundation-sec-8B-Instruct is live, open, and ready to defend. Download it, prompt it and help shape the future of AI-powered cybersecurity,” states Yaron Singer, VP of AI and Security at Foundation, emphasizing the collaborative potential of this open-source approach.&lt;/p&gt;



&lt;p&gt;SentinelOne took a different approach, emphasizing their Purple AI’s ability not just to investigate but actually “think ahead” or predict adversary moves based on behavioral patterns and proactively adjusting defenses.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015301" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-7-crowdstrike-report.jpg?w=792" width="792" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;CrowdStrike’s threat intelligence reveals how adversaries like FAMOUS CHOLLIMA are weaponizing gen AI at every stage of insider threat operations, from creating synthetic identities to managing multiple simultaneous employment positions. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-north-korean-threat-changed-everything-fast"&gt;&lt;strong&gt;How the North Korean threat changed everything fast&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;FAMOUS CHOLLIMA operatives infiltrated over 320 companies in the past year. That’s a 220% year-over-year increase, representing a fundamental shift in enterprise security threats.&lt;/p&gt;



&lt;p&gt;“They’re using AI through the entire process,” Meyers told VentureBeat during an interview. “They’re using generative AI to create LinkedIn profiles, to create resumes and then they go into the interview, and they’re using deep fake technology to change their appearance. They’re using AI to answer questions during the interview process. They’re using AI, once they get hired, to build the code and do the work that they’re supposed to do.”&lt;/p&gt;



&lt;p&gt;The infrastructure supporting these operations is sophisticated. One Arizona-based facilitator maintained 90 laptops to enable remote access. Operations have expanded beyond the U.S. to France, Canada and Japan as adversaries diversify their targeting.&lt;/p&gt;



&lt;p&gt;CrowdStrike’s July data reveals the scope: 33 FAMOUS CHOLLIMA encounters, with 28 confirmed as malicious insiders who had successfully obtained employment. These are AI-enhanced operators working within organizations, using legitimate credentials, rather than relying on traditional malware attacks that security tools can detect.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-the-human-element-remains-vital"&gt;&lt;strong&gt;Why the human element remains vital&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite the technological advances, a consistent theme across all vendor presentations was that agentic AI augments rather than replaces human analysts. “Agentic AI, as good as it is, is not going to replace the humans that are in the loop. You need human threat hunters out there that are able to use their insight and their know-how and their intellect to come up with creative ways to try to find these adversaries,” Meyers emphasized.&lt;/p&gt;



&lt;p&gt;Every major vendor echoed this human-machine collaboration model. Splunk’s announcement of Mission Control emphasized how its agentic AI serves as a “force multiplier” for analysts, handling routine tasks while escalating complex decisions to humans. Even the most ardent advocates of automation acknowledged that human oversight remains essential for high-stakes decisions and creative problem-solving.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competition-shifts-from-features-to-results"&gt;&lt;strong&gt;Competition shifts from features to results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.&lt;/p&gt;



&lt;p&gt;Google Cloud Security’s Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015302" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-6-crowdstrike-report.jpg?w=589" width="589" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-many-are-predicting-that-ai-will-become-the-next-insider-threat"&gt;&lt;strong&gt;Many are predicting that AI will become the next insider threat&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: “AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they’re going to check the output.”&lt;/p&gt;



&lt;p&gt;This concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike’s expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco’s AI supply chain security initiative with Hugging Face, signals the industry’s recognition that securing AI agents themselves is becoming as important as using them for security.&lt;/p&gt;



&lt;p&gt;The velocity of change is accelerating. “Adversaries are moving incredibly fast,” Meyers warned. “Scattered spider hit retail back in April, they were hitting insurance companies in May, they were hitting aviation in June and July.” The ability to iterate and adapt at this speed means organizations can’t afford to wait for perfect solutions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bottom-line"&gt;&lt;strong&gt;Bottom Line&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;This year’s Black Hat confirmed what many cybersecurity professionals saw coming. AI-driven attacks now threaten their organizations across a widening array of surfaces, many of them unexpected.&lt;/p&gt;



&lt;p&gt;Human resources and hiring became the threat surface no one saw coming. FAMOUS CHOLLIMA operatives are penetrating every possible U.S. and Western technology company they can, grabbing immediate cash to fuel North Korea’s weapons programs while stealing invaluable intellectual property. This creates an entirely new dimension to attacks. Organizations and the security leaders guiding them would do well to remember what hangs in the balance of getting this right: your businesses’ core IP, national security, and the trust customers have in the organizations they do business with.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value/</guid><pubDate>Thu, 07 Aug 2025 23:35:56 +0000</pubDate></item><item><title>[NEW] ChatGPT users dismayed as OpenAI pulls popular models GPT-4o, o3 and more — enterprise API remains (for now) (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/chatgpt-users-dismayed-as-openai-pulls-popular-models-gpt-4o-o3-and-more-enterprise-api-remains-for-now/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After announcing the release of its newest flagship model family, GPT-5, OpenAI said the model will power all of ChatGPT, and that it will sunset the existing models in the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI, through a spokesperson, told VentureBeat that GPT-5 “will replace all other models in ChatGPT, so users don’t have to pick depending on each task, which takes effect once you have access to GPT-5.” This means people can no longer choose GPT-4o, o3, o4-mini or o4-mini-high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With GPT-5 access rolling out to ChatGPT Plus, Free, Pro and Team users starting, only the Enterprise and Edu tiers can still use the “legacy” models for 60 days.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The news came as a surprise to many ChatGPT users, many of whom came to rely on their chosen models to run their everyday queries. Some people said the adjustment would take some time getting used to, mainly because they had based workflows on how the model interacted with them or typical response times.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Although I enjoy GPT-4.1, I am saddened by the news that you're also apparently sunsetting GPT-4.5. For me, it's been way better in textual and conceptual analysis than any other GPT-4x series model, ever. At the very least, please don't make ChatGPT users go back to 4o.&lt;/p&gt;— Harry Horsperg ? (@horsperg) April 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Other users claimed they developed “a connection” to their chosen model and found a demo in the livestream announcement asking GPT-4o to write its own eulogy distasteful. The loss of GPT-4o garnered the most distress. After all, 4o was the default model for ChatGPT, and some users either preferred it or never bothered to switch models because it worked for their needs.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It was pretty gross, wasn't it. Did it as a demo and glibly said GPT-5 did it better before talking about coding. I had a great relationship with 4o, and I'm sure a fair few people did as well, it was very graceless how they handled it.&lt;/p&gt;— Meadowbrook (@Meadowbrook_) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;I used 4o as the default and found it annoying at first when my custom GPT began defaulting to a reasoning model. I’ve since come around to the reasoning model for work-related queries, but I still often turn to 4o for quicker questions like planning a trip or generating gift ideas.&lt;/p&gt;



&lt;p&gt;ChatGPT had come under fire before with the number of model choices it offered, prompting OpenAI CEO Sam Altman to admit in February that its model picker (where people can choose from a dropdown which model they prefer) became complicated. Altman vowed to unify the experience, which now seems like a hint to what they eventually decided to do with GPT-5 on ChatGPT.&lt;/p&gt;



&lt;p&gt;Last month, rumors circulated that OpenAI would introduce an automatic model router that chooses a model for users based on their workload.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI has sunsetted models before, but this is the first time all existing models on the chat platform will be removed and replaced wholesale.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-catapult-into-the-future"&gt;Catapult into the future&lt;/h2&gt;



&lt;p&gt;On the other hand, a lot of people see the sunsetting of GPT-4o and the o3 and o4 family of models as OpenAI “catapulting” 400 million users into the future.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;People are underestimating the impact of OpenAI deprecating all models except GPT-5 &lt;/p&gt;&lt;p&gt;Most lawyers and business folks outside of X use base models on ChatGPT for tasks and still think “AI is dumb”&lt;/p&gt;&lt;p&gt;99% haven’t heard of o3&lt;/p&gt;&lt;p&gt;Today, 400M people got catapulted into the future&lt;/p&gt;— Ian Tracey (@ian_dot_so) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sunsetting old models and auto-upgrading everyone to GPT-5 is smart&lt;/p&gt;&lt;p&gt;Most users never switch models and miss huge capability jumps&lt;/p&gt;— Creatify AI (@Creatify_AI) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Some internet comments claim that people who complain about AI models not being smart are a direct consequence of them never switching models in the first place. Removing legacy models as options will force more users to use the latest and most capable models.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;i have friends who stopped using gpt because they think it's stupid. they were on 4o and had no idea about what web search tool meant, let alone knowledge cutoff&lt;/p&gt;— Cengiz (@cengizdemiurg) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-apis-are-safe"&gt;Enterprise APIs are safe&lt;/h2&gt;



&lt;p&gt;For enterprises, the impact of losing models like GPT-4o on ChatGPT will be felt more on the individual or team level. Of course, for now, subscribers on the ChatGPT Enterprise tier can still access all of the models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But enterprises that built their applications or agents on either GPT-4o or one of the reasoning models can rest easy. OpenAI told VentureBeat that the company has no plans to deprecate models on the API side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In the API, we do not currently plan to deprecate older models,” the OpenAI spokesperson said. “We will share advanced notice with developers if we decide to sunset models in the future.”&lt;/p&gt;



&lt;p&gt;Many enterprises regularly evaluate models, to the point of even switching from an LLM or a smaller model to save on costs.&amp;nbsp;OpenAI creates dividing line: Sunset of legacy models GPT 4o and o3 causes chaos for ChatGPT users, but enterprise APIs are safe — for now&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After announcing the release of its newest flagship model family, GPT-5, OpenAI said the model will power all of ChatGPT, and that it will sunset the existing models in the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI, through a spokesperson, told VentureBeat that GPT-5 “will replace all other models in ChatGPT, so users don’t have to pick depending on each task, which takes effect once you have access to GPT-5.” This means people can no longer choose GPT-4o, o3, o4-mini or o4-mini-high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With GPT-5 access rolling out to ChatGPT Plus, Free, Pro and Team users starting, only the Enterprise and Edu tiers can still use the “legacy” models for 60 days.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The news came as a surprise to many ChatGPT users, many of whom came to rely on their chosen models to run their everyday queries. Some people said the adjustment would take some time getting used to, mainly because they had based workflows on how the model interacted with them or typical response times.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Although I enjoy GPT-4.1, I am saddened by the news that you're also apparently sunsetting GPT-4.5. For me, it's been way better in textual and conceptual analysis than any other GPT-4x series model, ever. At the very least, please don't make ChatGPT users go back to 4o.&lt;/p&gt;— Harry Horsperg ? (@horsperg) April 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Other users claimed they developed “a connection” to their chosen model and found a demo in the livestream announcement asking GPT-4o to write its own eulogy distasteful. The loss of GPT-4o garnered the most distress. After all, 4o was the default model for ChatGPT, and some users either preferred it or never bothered to switch models because it worked for their needs.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It was pretty gross, wasn't it. Did it as a demo and glibly said GPT-5 did it better before talking about coding. I had a great relationship with 4o, and I'm sure a fair few people did as well, it was very graceless how they handled it.&lt;/p&gt;— Meadowbrook (@Meadowbrook_) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;I used 4o as the default and found it annoying at first when my custom GPT began defaulting to a reasoning model. I’ve since come around to the reasoning model for work-related queries, but I still often turn to 4o for quicker questions like planning a trip or generating gift ideas.&lt;/p&gt;



&lt;p&gt;ChatGPT had come under fire before with the number of model choices it offered, prompting OpenAI CEO Sam Altman to admit in February that its model picker (where people can choose from a dropdown which model they prefer) became complicated. Altman vowed to unify the experience, which now seems like a hint to what they eventually decided to do with GPT-5 on ChatGPT.&lt;/p&gt;



&lt;p&gt;Last month, rumors circulated that OpenAI would introduce an automatic model router that chooses a model for users based on their workload.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI has sunsetted models before, but this is the first time all existing models on the chat platform will be removed and replaced wholesale.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-catapult-into-the-future"&gt;Catapult into the future&lt;/h2&gt;



&lt;p&gt;On the other hand, a lot of people see the sunsetting of GPT-4o and the o3 and o4 family of models as OpenAI “catapulting” 400 million users into the future.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;People are underestimating the impact of OpenAI deprecating all models except GPT-5 &lt;/p&gt;&lt;p&gt;Most lawyers and business folks outside of X use base models on ChatGPT for tasks and still think “AI is dumb”&lt;/p&gt;&lt;p&gt;99% haven’t heard of o3&lt;/p&gt;&lt;p&gt;Today, 400M people got catapulted into the future&lt;/p&gt;— Ian Tracey (@ian_dot_so) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sunsetting old models and auto-upgrading everyone to GPT-5 is smart&lt;/p&gt;&lt;p&gt;Most users never switch models and miss huge capability jumps&lt;/p&gt;— Creatify AI (@Creatify_AI) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Some internet comments claim that people who complain about AI models not being smart are a direct consequence of them never switching models in the first place. Removing legacy models as options will force more users to use the latest and most capable models.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;i have friends who stopped using gpt because they think it's stupid. they were on 4o and had no idea about what web search tool meant, let alone knowledge cutoff&lt;/p&gt;— Cengiz (@cengizdemiurg) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-apis-are-safe"&gt;Enterprise APIs are safe&lt;/h2&gt;



&lt;p&gt;For enterprises, the impact of losing models like GPT-4o on ChatGPT will be felt more on the individual or team level. Of course, for now, subscribers on the ChatGPT Enterprise tier can still access all of the models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But enterprises that built their applications or agents on either GPT-4o or one of the reasoning models can rest easy. OpenAI told VentureBeat that the company has no plans to deprecate models on the API side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In the API, we do not currently plan to deprecate older models,” the OpenAI spokesperson said. “We will share advanced notice with developers if we decide to sunset models in the future.”&lt;/p&gt;



&lt;p&gt;Many enterprises regularly evaluate models, to the point of even switching from an LLM or a smaller model to save on costs.&amp;nbsp;OpenAI creates dividing line: Sunset of legacy models GPT 4o and o3 causes chaos for ChatGPT users, but enterprise APIs are safe — for now&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/chatgpt-users-dismayed-as-openai-pulls-popular-models-gpt-4o-o3-and-more-enterprise-api-remains-for-now/</guid><pubDate>Fri, 08 Aug 2025 00:45:03 +0000</pubDate></item></channel></rss>