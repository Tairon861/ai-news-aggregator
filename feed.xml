<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 27 Sep 2025 01:27:02 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Today is the last day to save up to $668 on TechCrunch Disrupt 2025 tickets (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/last-day-to-save-668-on-techcrunch-disrupt-2025-tickets/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;This is it! You have less than 24 hours left to lock in ticket savings of up to $668 for &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27-29 in San Francisco, before prices go up at 11:59 p.m. PT tonight. Wait too long and you’ll miss out on these last-minute savings — and the most anticipated tech conference of the year. &lt;strong&gt;Register here&lt;/strong&gt; to lock in your ticket at these low rates.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 24 hours left" class="wp-image-3011660" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_24Hours-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-if-you-re-on-the-fence-about-joining-here-s-what-you-re-about-to-miss"&gt;If you’re on the fence about joining, here’s what you’re about to miss&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-250-of-tech-s-most-influential-voices"&gt;250+ of tech’s most influential voices&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;These aren’t just big names — they’re the &lt;strong&gt;leaders actively shaping the future of tech&lt;/strong&gt;. They’re bringing real-world insights on product, AI, security, GTM strategy, scaling, and leadership. If you’re a founder or investor, these conversations aren’t just inspiring — they’re critical. Sitting in these sessions means walking away with lessons, frameworks, and foresight you can actually use.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2907123" height="454" src="https://techcrunch.com/wp-content/uploads/2024/10/Vinod-Khosla.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Hear valuable insights from leaders like the following:&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roelof Botha&lt;/strong&gt;, partner, Sequoia Capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Britt&lt;/strong&gt;, co-founder and CEO, Chime&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;David George&lt;/strong&gt;, general partner,&amp;nbsp;a16z&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elad Gil&lt;/strong&gt;, serial investor (Stripe,&amp;nbsp;Notion,&amp;nbsp;Figma,&amp;nbsp;Coinbase, and more), Gil &amp;amp; Co.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Aaron Levie&lt;/strong&gt;, co-founder and CEO, Box&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tekedra Mawakana&lt;/strong&gt;, co-CEO, Waymo&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ryan Petersen&lt;/strong&gt;, founder and CEO, Flexport&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Brynn Putnam&lt;/strong&gt;, founder and CEO, Board&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, CTO, Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Astro Teller&lt;/strong&gt;, Captain of Moonshots, X, The Moonshots Factory&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Alison Wagonfeld&lt;/strong&gt;, VP of marketing, Google Cloud&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Thomas Wolf&lt;/strong&gt;, co-founder and CSO, Hugging Face&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 class="wp-block-heading" id="h-200-sessions-across-5-industry-stages-breakouts-and-roundtables"&gt;200+ sessions across 5 industry stages, breakouts, and roundtables&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Mary Barra on stage" class="wp-image-2909681" height="454" src="https://techcrunch.com/wp-content/uploads/2024/11/54103543170_40ccf027b5_k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whatever your goal — fundraising, hiring, scaling, launching, selling — there’s a session for it. Each one is designed to give you actionable takeaways, not just theory. Explore the fast-growing session lineup on the &lt;strong&gt;Disrupt agenda&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a taste of what’s on the stages:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Love, Lies &amp;amp; Algorithms:&lt;/strong&gt; The truth about AI in relationships&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The Future of AI Defense:&lt;/strong&gt; DARPA, Point72, and the Department of the Navy on national security&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;GTM That Works:&lt;/strong&gt; Real startup strategies with leaders from GTMfund, Google Cloud, OpenAI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The AI Talent Shift:&lt;/strong&gt; Mercor’s Brendan Foody on the global AI workforce&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Where VCs Are Placing Their Bets in 2026&lt;/strong&gt;: Top VCs cover what’s next in tech and where VCs will invest&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 class="wp-block-heading" id="h-100-exhibitors-and-future-facing-tech"&gt;100+ exhibitors and future-facing tech&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt isn’t just for listening — &lt;strong&gt;it’s for exploring&lt;/strong&gt;. You’ll get a first look at tomorrow’s innovations across AI, dev tools, climate tech, fintech, and more. These aren’t science fair demos. They’re real, scalable solutions. Investors find their next portfolio company. Founders meet the tools and partners that help them scale.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-startup-battlefield-200"&gt;Startup Battlefield 200&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;This is the “&lt;strong&gt;World Series” of pitch competitions&lt;/strong&gt; — a launchpad for future unicorns. Over three days, 20 early-stage startups from around the world battle it out for funding, mentorship, and the $100,000 equity-free prize. You’ll hear live VC feedback and learn exactly what makes a winning pitch and a viable startup. Whether you’re an investor, a founder, or just love watching pressure-cooker innovation, this is your front-row seat.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3016596" height="453" src="https://techcrunch.com/wp-content/uploads/2025/06/52457178574_dcedf0a9a3_o-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-thousands-of-curated-connections-and-endless-opportunities-to-network"&gt;Thousands of curated connections and endless opportunities to network&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;With 2,000+ curated meetings, powered by Braindate, and the networking lounge, breakout areas, and happy hours, every corner of Disrupt is a chance to meet the right people. Investors meet founders. Founders meet co-builders. Operators meet mentors. It’s designed to make serendipity scalable.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-beat-the-clock-don-t-let-today-pass-you-by-without-securing-up-to-668-in-savings"&gt;Beat the clock: Don’t let today pass you by without securing up to $668 in savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This is your last chance to join thousands of founders, investors, builders, and operators at the tech epicenter that moves the industry forward. Register by tonight at 11:59 p.m. PT and save up to $668. &lt;strong&gt;Secure your ticket savings now&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-founder-or-investor-your-pass-unlocks-even-more"&gt;&lt;strong&gt;Founder or Investor?&lt;/strong&gt; Your pass unlocks even more&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Includes curated VC matchmaking, private mentoring sessions, and exclusive access to the founder-investor area and content to help you scale smarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Get direct access to high-potential startups, curated meetings, the investor-founder-only lounge, and premium networking opportunities.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-bringing-a-group"&gt;Bringing a group?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Get a bonus discount! Bundle packages for groups of 4 to 9 people offer even greater savings of 15%. &lt;strong&gt;Explore bundles here&lt;/strong&gt; and invite your team.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;This is it! You have less than 24 hours left to lock in ticket savings of up to $668 for &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27-29 in San Francisco, before prices go up at 11:59 p.m. PT tonight. Wait too long and you’ll miss out on these last-minute savings — and the most anticipated tech conference of the year. &lt;strong&gt;Register here&lt;/strong&gt; to lock in your ticket at these low rates.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 24 hours left" class="wp-image-3011660" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_24Hours-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-if-you-re-on-the-fence-about-joining-here-s-what-you-re-about-to-miss"&gt;If you’re on the fence about joining, here’s what you’re about to miss&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-250-of-tech-s-most-influential-voices"&gt;250+ of tech’s most influential voices&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;These aren’t just big names — they’re the &lt;strong&gt;leaders actively shaping the future of tech&lt;/strong&gt;. They’re bringing real-world insights on product, AI, security, GTM strategy, scaling, and leadership. If you’re a founder or investor, these conversations aren’t just inspiring — they’re critical. Sitting in these sessions means walking away with lessons, frameworks, and foresight you can actually use.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2907123" height="454" src="https://techcrunch.com/wp-content/uploads/2024/10/Vinod-Khosla.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Hear valuable insights from leaders like the following:&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roelof Botha&lt;/strong&gt;, partner, Sequoia Capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Britt&lt;/strong&gt;, co-founder and CEO, Chime&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;David George&lt;/strong&gt;, general partner,&amp;nbsp;a16z&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elad Gil&lt;/strong&gt;, serial investor (Stripe,&amp;nbsp;Notion,&amp;nbsp;Figma,&amp;nbsp;Coinbase, and more), Gil &amp;amp; Co.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Aaron Levie&lt;/strong&gt;, co-founder and CEO, Box&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tekedra Mawakana&lt;/strong&gt;, co-CEO, Waymo&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ryan Petersen&lt;/strong&gt;, founder and CEO, Flexport&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Brynn Putnam&lt;/strong&gt;, founder and CEO, Board&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, CTO, Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Astro Teller&lt;/strong&gt;, Captain of Moonshots, X, The Moonshots Factory&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Alison Wagonfeld&lt;/strong&gt;, VP of marketing, Google Cloud&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Thomas Wolf&lt;/strong&gt;, co-founder and CSO, Hugging Face&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 class="wp-block-heading" id="h-200-sessions-across-5-industry-stages-breakouts-and-roundtables"&gt;200+ sessions across 5 industry stages, breakouts, and roundtables&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Mary Barra on stage" class="wp-image-2909681" height="454" src="https://techcrunch.com/wp-content/uploads/2024/11/54103543170_40ccf027b5_k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whatever your goal — fundraising, hiring, scaling, launching, selling — there’s a session for it. Each one is designed to give you actionable takeaways, not just theory. Explore the fast-growing session lineup on the &lt;strong&gt;Disrupt agenda&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a taste of what’s on the stages:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Love, Lies &amp;amp; Algorithms:&lt;/strong&gt; The truth about AI in relationships&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The Future of AI Defense:&lt;/strong&gt; DARPA, Point72, and the Department of the Navy on national security&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;GTM That Works:&lt;/strong&gt; Real startup strategies with leaders from GTMfund, Google Cloud, OpenAI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The AI Talent Shift:&lt;/strong&gt; Mercor’s Brendan Foody on the global AI workforce&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Where VCs Are Placing Their Bets in 2026&lt;/strong&gt;: Top VCs cover what’s next in tech and where VCs will invest&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 class="wp-block-heading" id="h-100-exhibitors-and-future-facing-tech"&gt;100+ exhibitors and future-facing tech&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt isn’t just for listening — &lt;strong&gt;it’s for exploring&lt;/strong&gt;. You’ll get a first look at tomorrow’s innovations across AI, dev tools, climate tech, fintech, and more. These aren’t science fair demos. They’re real, scalable solutions. Investors find their next portfolio company. Founders meet the tools and partners that help them scale.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-startup-battlefield-200"&gt;Startup Battlefield 200&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;This is the “&lt;strong&gt;World Series” of pitch competitions&lt;/strong&gt; — a launchpad for future unicorns. Over three days, 20 early-stage startups from around the world battle it out for funding, mentorship, and the $100,000 equity-free prize. You’ll hear live VC feedback and learn exactly what makes a winning pitch and a viable startup. Whether you’re an investor, a founder, or just love watching pressure-cooker innovation, this is your front-row seat.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3016596" height="453" src="https://techcrunch.com/wp-content/uploads/2025/06/52457178574_dcedf0a9a3_o-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-thousands-of-curated-connections-and-endless-opportunities-to-network"&gt;Thousands of curated connections and endless opportunities to network&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;With 2,000+ curated meetings, powered by Braindate, and the networking lounge, breakout areas, and happy hours, every corner of Disrupt is a chance to meet the right people. Investors meet founders. Founders meet co-builders. Operators meet mentors. It’s designed to make serendipity scalable.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-beat-the-clock-don-t-let-today-pass-you-by-without-securing-up-to-668-in-savings"&gt;Beat the clock: Don’t let today pass you by without securing up to $668 in savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This is your last chance to join thousands of founders, investors, builders, and operators at the tech epicenter that moves the industry forward. Register by tonight at 11:59 p.m. PT and save up to $668. &lt;strong&gt;Secure your ticket savings now&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-founder-or-investor-your-pass-unlocks-even-more"&gt;&lt;strong&gt;Founder or Investor?&lt;/strong&gt; Your pass unlocks even more&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Includes curated VC matchmaking, private mentoring sessions, and exclusive access to the founder-investor area and content to help you scale smarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Get direct access to high-potential startups, curated meetings, the investor-founder-only lounge, and premium networking opportunities.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-bringing-a-group"&gt;Bringing a group?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Get a bonus discount! Bundle packages for groups of 4 to 9 people offer even greater savings of 15%. &lt;strong&gt;Explore bundles here&lt;/strong&gt; and invite your team.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/last-day-to-save-668-on-techcrunch-disrupt-2025-tickets/</guid><pubDate>Fri, 26 Sep 2025 14:00:00 +0000</pubDate></item><item><title>From $100B OpenAI deals to $100K visa fees (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/from-100b-openai-deals-to-100k-visa-fees/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2214107176.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;From $100 billion OpenAI commitments to $100,000 visa fees, this week showed just how much the tech landscape is shifting. On the latest episode of Equity, Anthony Ha and Max Zeff unpack the AI infrastructure gold rush and tech’s talent shuffle. Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday. Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2214107176.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;From $100 billion OpenAI commitments to $100,000 visa fees, this week showed just how much the tech landscape is shifting. On the latest episode of Equity, Anthony Ha and Max Zeff unpack the AI infrastructure gold rush and tech’s talent shuffle. Listen to the full episode to hear about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday. Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/from-100b-openai-deals-to-100k-visa-fees/</guid><pubDate>Fri, 26 Sep 2025 14:30:07 +0000</pubDate></item><item><title>The Trump administration is going after semiconductor imports (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/the-trump-administration-is-going-after-semiconductor-imports/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In its latest bid to boost semiconductor production in the U.S., the Trump administration is&amp;nbsp;reportedly considering&amp;nbsp;a&amp;nbsp;ratio-based approach that would penalize domestic manufacturers with tariffs if they don’t produce enough chips.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The&amp;nbsp;administration is weighing a policy that would mandate&amp;nbsp;U.S. semiconductor companies to manufacture the same number of chips in the&amp;nbsp;U.S. as their customers import from overseas manufacturers, The Wall Street Journal reported, citing anonymous sources.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Companies that&amp;nbsp;don’t&amp;nbsp;comply with&amp;nbsp;this 1:1 ratio will be subject to&amp;nbsp;tariffs, the report said, though the timeline to achieve this ratio isn’t clear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;President Donald Trump has been&amp;nbsp;talking about&amp;nbsp;imposing tariffs on the semiconductor industry&amp;nbsp;since the beginning of August.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a ratio-based approach would be unusual if the administration wants to achieve its goal of bringing semiconductor manufacturing&amp;nbsp;back stateside.&amp;nbsp;It could eventually lead to more domestic semiconductor production, but it has&amp;nbsp;the potential to&amp;nbsp;hurt the&amp;nbsp;U.S. chip industry until manufacturing ramps up to meet the immense demand.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting domestic chip manufacturing&amp;nbsp;plants off the ground is neither a small nor a fast endeavor.&amp;nbsp;Intel’s Ohio plant, originally slated to open this year, has been&amp;nbsp;delayed&amp;nbsp;multiple times and&amp;nbsp;is now&amp;nbsp;targeting a launch in 2030.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Taiwan Semiconductor Manufacturing Company (TSMC) in March said it is committing $100 billion over the next four years for building infrastructure to support chip production plants in the U.S., though it was light on details.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In its latest bid to boost semiconductor production in the U.S., the Trump administration is&amp;nbsp;reportedly considering&amp;nbsp;a&amp;nbsp;ratio-based approach that would penalize domestic manufacturers with tariffs if they don’t produce enough chips.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The&amp;nbsp;administration is weighing a policy that would mandate&amp;nbsp;U.S. semiconductor companies to manufacture the same number of chips in the&amp;nbsp;U.S. as their customers import from overseas manufacturers, The Wall Street Journal reported, citing anonymous sources.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Companies that&amp;nbsp;don’t&amp;nbsp;comply with&amp;nbsp;this 1:1 ratio will be subject to&amp;nbsp;tariffs, the report said, though the timeline to achieve this ratio isn’t clear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;President Donald Trump has been&amp;nbsp;talking about&amp;nbsp;imposing tariffs on the semiconductor industry&amp;nbsp;since the beginning of August.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a ratio-based approach would be unusual if the administration wants to achieve its goal of bringing semiconductor manufacturing&amp;nbsp;back stateside.&amp;nbsp;It could eventually lead to more domestic semiconductor production, but it has&amp;nbsp;the potential to&amp;nbsp;hurt the&amp;nbsp;U.S. chip industry until manufacturing ramps up to meet the immense demand.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting domestic chip manufacturing&amp;nbsp;plants off the ground is neither a small nor a fast endeavor.&amp;nbsp;Intel’s Ohio plant, originally slated to open this year, has been&amp;nbsp;delayed&amp;nbsp;multiple times and&amp;nbsp;is now&amp;nbsp;targeting a launch in 2030.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Taiwan Semiconductor Manufacturing Company (TSMC) in March said it is committing $100 billion over the next four years for building infrastructure to support chip production plants in the U.S., though it was light on details.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/the-trump-administration-is-going-after-semiconductor-imports/</guid><pubDate>Fri, 26 Sep 2025 14:40:33 +0000</pubDate></item><item><title>CAMIA privacy attack reveals what AI models memorise (AI News)</title><link>https://www.artificialintelligence-news.com/news/camia-privacy-attack-reveals-what-ai-models-memorise/</link><description>&lt;p&gt;Researchers have developed a new attack that reveals privacy vulnerabilities by determining whether your data was used to train AI models.&lt;/p&gt;&lt;p&gt;The method, named CAMIA (Context-Aware Membership Inference Attack), was developed by researchers from Brave and the National University of Singapore and is far more effective than previous attempts at probing the ‘memory’ of AI models.&lt;/p&gt;&lt;p&gt;There is growing concern of “data memorisation” in AI, where models inadvertently store and can potentially leak sensitive information from their training sets. In healthcare, a model trained on clinical notes could accidentally reveal sensitive patient information. For businesses, if internal emails were used in training, an attacker might be able to trick an LLM into reproducing private company communications.&lt;/p&gt;&lt;p&gt;Such privacy concerns have been amplified by recent announcements, such as LinkedIn’s plan to use user data to improve its generative AI models, raising questions about whether private content might surface in generated text.&lt;/p&gt;&lt;p&gt;To test for this leakage, security experts use Membership Inference Attacks, or MIAs. In simple terms, an MIA asks the model a critical question: “Did you see this example during training?”. If an attacker can reliably figure out the answer, it proves the model is leaking information about its training data, posing a direct privacy risk.&lt;/p&gt;&lt;p&gt;The core idea is that models often behave differently when processing data they were trained on compared to new, unseen data. MIAs are designed to systematically exploit these behavioural gaps.&lt;/p&gt;&lt;p&gt;Until now, most MIAs have been largely ineffective against modern generative AIs. This is because they were originally designed for simpler classification models that give a single output per input. LLMs, however, generate text token-by-token, with each new word being influenced by the words that came before it. This sequential process means that simply looking at the overall confidence for a block of text misses the moment-to-moment dynamics where leakage actually occurs.&lt;/p&gt;&lt;p&gt;The key insight behind the new CAMIA privacy attack is that an AI model’s memorisation is context-dependent. An AI model relies on memorisation most heavily when it’s uncertain about what to say next.&lt;/p&gt;&lt;p&gt;For example, given the prefix “Harry Potter is…written by… The world of Harry…”, in the example below from Brave, a model can easily guess the next token is “Potter” through generalisation, because the context provides strong clues.&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-109612" height="240" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-16.png" width="748" /&gt;&lt;/figure&gt;&lt;p&gt;In such a case, a confident prediction doesn’t indicate memorisation. However, if the prefix is simply “Harry,” predicting “Potter” becomes far more difficult without having memorised specific training sequences. A low-loss, high-confidence prediction in this ambiguous scenario is a much stronger indicator of memorisation.&lt;/p&gt;&lt;p&gt;CAMIA is the first privacy attack specifically tailored to exploit this generative nature of modern AI models. It tracks how the model’s uncertainty evolves during text generation, allowing it to measure how quickly the AI transitions from “guessing” to “confident recall”. By operating at the token level, it can adjust for situations where low uncertainty is caused by simple repetition and can identify the subtle patterns of true memorisation that other methods miss.&lt;/p&gt;&lt;p&gt;The researchers tested CAMIA on the MIMIR benchmark across several Pythia and GPT-Neo models. When attacking a 2.8B parameter Pythia model on the ArXiv dataset, CAMIA nearly doubled the detection accuracy of prior methods. It increased the true positive rate from 20.11% to 32.00% while maintaining a very low false positive rate of just 1%.&lt;/p&gt;&lt;p&gt;The attack framework is also computationally efficient. On a single A100 GPU, CAMIA can process 1,000 samples in approximately 38 minutes, making it a practical tool for auditing models.&lt;/p&gt;&lt;p&gt;This work reminds the AI industry about the privacy risks in training ever-larger models on vast, unfiltered datasets. The researchers hope their work will spur the development of more privacy-preserving techniques and contribute to ongoing efforts to balance the utility of AI with fundamental user privacy.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Samsung benchmarks real productivity of enterprise AI models&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Researchers have developed a new attack that reveals privacy vulnerabilities by determining whether your data was used to train AI models.&lt;/p&gt;&lt;p&gt;The method, named CAMIA (Context-Aware Membership Inference Attack), was developed by researchers from Brave and the National University of Singapore and is far more effective than previous attempts at probing the ‘memory’ of AI models.&lt;/p&gt;&lt;p&gt;There is growing concern of “data memorisation” in AI, where models inadvertently store and can potentially leak sensitive information from their training sets. In healthcare, a model trained on clinical notes could accidentally reveal sensitive patient information. For businesses, if internal emails were used in training, an attacker might be able to trick an LLM into reproducing private company communications.&lt;/p&gt;&lt;p&gt;Such privacy concerns have been amplified by recent announcements, such as LinkedIn’s plan to use user data to improve its generative AI models, raising questions about whether private content might surface in generated text.&lt;/p&gt;&lt;p&gt;To test for this leakage, security experts use Membership Inference Attacks, or MIAs. In simple terms, an MIA asks the model a critical question: “Did you see this example during training?”. If an attacker can reliably figure out the answer, it proves the model is leaking information about its training data, posing a direct privacy risk.&lt;/p&gt;&lt;p&gt;The core idea is that models often behave differently when processing data they were trained on compared to new, unseen data. MIAs are designed to systematically exploit these behavioural gaps.&lt;/p&gt;&lt;p&gt;Until now, most MIAs have been largely ineffective against modern generative AIs. This is because they were originally designed for simpler classification models that give a single output per input. LLMs, however, generate text token-by-token, with each new word being influenced by the words that came before it. This sequential process means that simply looking at the overall confidence for a block of text misses the moment-to-moment dynamics where leakage actually occurs.&lt;/p&gt;&lt;p&gt;The key insight behind the new CAMIA privacy attack is that an AI model’s memorisation is context-dependent. An AI model relies on memorisation most heavily when it’s uncertain about what to say next.&lt;/p&gt;&lt;p&gt;For example, given the prefix “Harry Potter is…written by… The world of Harry…”, in the example below from Brave, a model can easily guess the next token is “Potter” through generalisation, because the context provides strong clues.&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-109612" height="240" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-16.png" width="748" /&gt;&lt;/figure&gt;&lt;p&gt;In such a case, a confident prediction doesn’t indicate memorisation. However, if the prefix is simply “Harry,” predicting “Potter” becomes far more difficult without having memorised specific training sequences. A low-loss, high-confidence prediction in this ambiguous scenario is a much stronger indicator of memorisation.&lt;/p&gt;&lt;p&gt;CAMIA is the first privacy attack specifically tailored to exploit this generative nature of modern AI models. It tracks how the model’s uncertainty evolves during text generation, allowing it to measure how quickly the AI transitions from “guessing” to “confident recall”. By operating at the token level, it can adjust for situations where low uncertainty is caused by simple repetition and can identify the subtle patterns of true memorisation that other methods miss.&lt;/p&gt;&lt;p&gt;The researchers tested CAMIA on the MIMIR benchmark across several Pythia and GPT-Neo models. When attacking a 2.8B parameter Pythia model on the ArXiv dataset, CAMIA nearly doubled the detection accuracy of prior methods. It increased the true positive rate from 20.11% to 32.00% while maintaining a very low false positive rate of just 1%.&lt;/p&gt;&lt;p&gt;The attack framework is also computationally efficient. On a single A100 GPU, CAMIA can process 1,000 samples in approximately 38 minutes, making it a practical tool for auditing models.&lt;/p&gt;&lt;p&gt;This work reminds the AI industry about the privacy risks in training ever-larger models on vast, unfiltered datasets. The researchers hope their work will spur the development of more privacy-preserving techniques and contribute to ongoing efforts to balance the utility of AI with fundamental user privacy.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Samsung benchmarks real productivity of enterprise AI models&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/camia-privacy-attack-reveals-what-ai-models-memorise/</guid><pubDate>Fri, 26 Sep 2025 17:17:55 +0000</pubDate></item><item><title>Everyone’s still throwing billions at AI data centers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/everyones-still-throwing-billions-at-ai-data-centers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219673294.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;From $100 billion OpenAI commitments to $100,000 visa fees, this week showed just how much the tech landscape is shifting. On the latest episode of Equity, Anthony Ha and Max Zeff unpack the AI infrastructure gold rush and tech’s talent shuffle. Watch the full episode for more about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp; &lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219673294.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;From $100 billion OpenAI commitments to $100,000 visa fees, this week showed just how much the tech landscape is shifting. On the latest episode of Equity, Anthony Ha and Max Zeff unpack the AI infrastructure gold rush and tech’s talent shuffle. Watch the full episode for more about:&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp; &lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/everyones-still-throwing-billions-at-ai-data-centers/</guid><pubDate>Fri, 26 Sep 2025 17:30:00 +0000</pubDate></item><item><title>[NEW] YouTube Music tests AI hosts that share trivia and commentary (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/youtube-music-tests-ai-hosts-that-share-trivia-and-commentary/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/youtube-music-icon.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube Music is testing AI music hosts that provide relevant stories, fan trivia, and commentary about what you’re listening to, the company announced on Friday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes two years after Spotify launched an AI DJ that delivers a curated selection of music alongside AI-powered spoken commentary about the tracks and artists you like. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new feature builds on its ongoing experiments with conversational AI. In July, the service rolled out an AI conversational radio feature that lets users create a custom radio station by describing what they want to hear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new AI hosts are currently being tested through YouTube Labs, the platform’s new hub for AI experiments. In a blog post, the company said YouTube Labs is “a new initiative dedicated to exploring the potential of AI on YouTube.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is similar to Google Labs, Google’s experimental arm that lets users test early-stage AI products and provide feedback. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is open to all YouTube users, which means they don’t need a Premium membership to sign up. However, the company notes that only a limited number of U.S.-based participants&amp;nbsp;will be given access to the experimental program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs has been implementing AI features across YouTube recently.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, the company released a series of AI features for creators, including GenAI tools for Shorts creation. A few months ago, YouTube launched an AI-powered search results carousel similar to Google’s AI Overviews and expanded access to its conversational AI tool to help users find more information, receive content recommendations, and get video summaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube is embracing AI features, it’s also cracking down on AI slop. The platform recently updated its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/youtube-music-icon.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube Music is testing AI music hosts that provide relevant stories, fan trivia, and commentary about what you’re listening to, the company announced on Friday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes two years after Spotify launched an AI DJ that delivers a curated selection of music alongside AI-powered spoken commentary about the tracks and artists you like. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new feature builds on its ongoing experiments with conversational AI. In July, the service rolled out an AI conversational radio feature that lets users create a custom radio station by describing what they want to hear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new AI hosts are currently being tested through YouTube Labs, the platform’s new hub for AI experiments. In a blog post, the company said YouTube Labs is “a new initiative dedicated to exploring the potential of AI on YouTube.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is similar to Google Labs, Google’s experimental arm that lets users test early-stage AI products and provide feedback. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is open to all YouTube users, which means they don’t need a Premium membership to sign up. However, the company notes that only a limited number of U.S.-based participants&amp;nbsp;will be given access to the experimental program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs has been implementing AI features across YouTube recently.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, the company released a series of AI features for creators, including GenAI tools for Shorts creation. A few months ago, YouTube launched an AI-powered search results carousel similar to Google’s AI Overviews and expanded access to its conversational AI tool to help users find more information, receive content recommendations, and get video summaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube is embracing AI features, it’s also cracking down on AI slop. The platform recently updated its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/youtube-music-tests-ai-hosts-that-share-trivia-and-commentary/</guid><pubDate>Fri, 26 Sep 2025 19:02:02 +0000</pubDate></item><item><title>[NEW] US investigators are using AI to detect child abuse images made by AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/26/1124343/us-investigators-are-using-ai-to-detect-child-abuse-images-made-by-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/detect-kids.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has enabled the production of child sexual abuse images to skyrocket. Now the leading investigator of child exploitation in the US is experimenting with using AI to distinguish AI-generated images from material depicting real victims, according to a new government filing.&lt;/p&gt;  &lt;p&gt;The Department of Homeland Security’s Cyber Crimes Center, which investigates child exploitation across international borders, has awarded a $150,000 contract to San Francisco–based Hive AI for its software, which can identify whether a piece of content was AI-generated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The filing, posted on September 19, is heavily redacted and Hive cofounder and CEO Kevin Guo told &lt;em&gt;MIT Technology Review&lt;/em&gt; that he could not discuss the details of the contract, but confirmed it involves use of the company’s AI detection algorithms for child sexual abuse material (CSAM).&lt;/p&gt;  &lt;p&gt;The filing quotes data from the National Center for Missing and Exploited Children that reported a 1,325% increase in incidents involving generative AI in 2024. “The sheer volume of digital content circulating online necessitates the use of automated tools to process and analyze data efficiently,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;The first priority of child exploitation investigators is to find and stop any abuse currently happening, but the flood of AI-generated CSAM has made it difficult for investigators to know whether images depict a real victim currently at risk. A tool that could successfully flag real victims would be a massive help when they try to prioritize cases.&lt;/p&gt;  &lt;p&gt;Identifying AI-generated images “ensures that investigative resources are focused on cases involving real victims, maximizing the program’s impact and safeguarding vulnerable individuals,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;Hive AI offers AI tools that create videos and images, as well as a range of content moderation tools that can flag violence, spam, and sexual material and even identify celebrities. In December, &lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the company was selling its deepfake-detection technology to the US military.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For detecting CSAM, Hive offers a tool created with Thorn, a child safety nonprofit, which companies can integrate into their platforms. This tool uses a “hashing” system, which assigns unique IDs to content known by investigators to be CSAM, and blocks that material from being uploaded. This tool, and others like it, have become a standard line of defense for tech companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these tools simply identify a piece of content as CSAM; they don’t detect whether it was generated by AI. Hive has created a separate tool that determines whether images in general were AI-generated. Though it is not trained specifically to work on CSAM, according to Guo, it doesn’t need to be.&lt;/p&gt;  &lt;p&gt;“There’s some underlying combination of pixels in this image that we can identify” as AI-generated, he says. “It can be generalizable.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;This tool, Guo says, is what the Cyber Crimes Center will be using to evaluate CSAM. He adds that Hive benchmarks its detection tools for each specific use case its customers have in mind.&lt;/p&gt;  &lt;p&gt;The National Center for Missing and Exploited Children, which participates in efforts to stop the spread of CSAM, did not respond to requests for comment on the effectiveness of such detection models in time for publication.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In its filing, the government justifies awarding the contract to Hive without a competitive bidding process. Though parts of this justification are redacted, it primarily references two points also found in a Hive presentation slide deck. One involves a 2024 study from the University of Chicago, which found that Hive’s AI detection tool outranked four other detectors in identifying AI-generated art. The other is its contract with the Pentagon for identifying deepfakes. The trial will last three months.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/detect-kids.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has enabled the production of child sexual abuse images to skyrocket. Now the leading investigator of child exploitation in the US is experimenting with using AI to distinguish AI-generated images from material depicting real victims, according to a new government filing.&lt;/p&gt;  &lt;p&gt;The Department of Homeland Security’s Cyber Crimes Center, which investigates child exploitation across international borders, has awarded a $150,000 contract to San Francisco–based Hive AI for its software, which can identify whether a piece of content was AI-generated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The filing, posted on September 19, is heavily redacted and Hive cofounder and CEO Kevin Guo told &lt;em&gt;MIT Technology Review&lt;/em&gt; that he could not discuss the details of the contract, but confirmed it involves use of the company’s AI detection algorithms for child sexual abuse material (CSAM).&lt;/p&gt;  &lt;p&gt;The filing quotes data from the National Center for Missing and Exploited Children that reported a 1,325% increase in incidents involving generative AI in 2024. “The sheer volume of digital content circulating online necessitates the use of automated tools to process and analyze data efficiently,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;The first priority of child exploitation investigators is to find and stop any abuse currently happening, but the flood of AI-generated CSAM has made it difficult for investigators to know whether images depict a real victim currently at risk. A tool that could successfully flag real victims would be a massive help when they try to prioritize cases.&lt;/p&gt;  &lt;p&gt;Identifying AI-generated images “ensures that investigative resources are focused on cases involving real victims, maximizing the program’s impact and safeguarding vulnerable individuals,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;Hive AI offers AI tools that create videos and images, as well as a range of content moderation tools that can flag violence, spam, and sexual material and even identify celebrities. In December, &lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the company was selling its deepfake-detection technology to the US military.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For detecting CSAM, Hive offers a tool created with Thorn, a child safety nonprofit, which companies can integrate into their platforms. This tool uses a “hashing” system, which assigns unique IDs to content known by investigators to be CSAM, and blocks that material from being uploaded. This tool, and others like it, have become a standard line of defense for tech companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these tools simply identify a piece of content as CSAM; they don’t detect whether it was generated by AI. Hive has created a separate tool that determines whether images in general were AI-generated. Though it is not trained specifically to work on CSAM, according to Guo, it doesn’t need to be.&lt;/p&gt;  &lt;p&gt;“There’s some underlying combination of pixels in this image that we can identify” as AI-generated, he says. “It can be generalizable.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;This tool, Guo says, is what the Cyber Crimes Center will be using to evaluate CSAM. He adds that Hive benchmarks its detection tools for each specific use case its customers have in mind.&lt;/p&gt;  &lt;p&gt;The National Center for Missing and Exploited Children, which participates in efforts to stop the spread of CSAM, did not respond to requests for comment on the effectiveness of such detection models in time for publication.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In its filing, the government justifies awarding the contract to Hive without a competitive bidding process. Though parts of this justification are redacted, it primarily references two points also found in a Hive presentation slide deck. One involves a 2024 study from the University of Chicago, which found that Hive’s AI detection tool outranked four other detectors in identifying AI-generated art. The other is its contract with the Pentagon for identifying deepfakes. The trial will last three months.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/26/1124343/us-investigators-are-using-ai-to-detect-child-abuse-images-made-by-ai/</guid><pubDate>Fri, 26 Sep 2025 19:03:34 +0000</pubDate></item><item><title>[NEW] What’s behind the massive AI data center headlines? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/whats-behind-the-massive-ai-data-center-headlines/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-957037038-nvidia.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley flooded the news this week with headlines about wild AI infrastructure investments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia said it would invest up to $100 billion in OpenAI. Then OpenAI said it would build out five more Stargate AI data centers with Oracle and Softbank, adding gigawatts of new capacity online in the coming years. And it was later revealed that Oracle sold $18 billion in bonds to pay for these data centers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On their own, each deal is dizzying in scale. But in aggregate, we see how Silicon Valley is moving heaven and Earth to give OpenAI enough power to train and serve future versions of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week on Equity, Anthony Ha and I (Max Zeff) go beyond the headlines to break down what’s really going on in these AI infrastructure deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Rather conveniently, OpenAI also gave the world a glimpse this week of a power-intensive feature it could serve more broadly if it had access to more AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company launched Pulse — a new feature in ChatGPT that works overnight to deliver personalized morning briefings for users. The experience feels similar to a news app or a social feed — something you check first thing in the morning — but doesn’t have posts from other users or ads (yet).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pulse is part of a new class of OpenAI products that works independently, even when users aren’t in the ChatGPT app. The company would like to deliver a lot more of these features, and roll them out to free users, but they’re limited by the number of computer servers available to them. OpenAI said it can only offer Pulse to its $200-a-month Pro subscribers right now due to capacity constraints.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real question is whether features like Pulse are worth the hundreds of billions of dollars being invested in AI data centers to support OpenAI. The feature looks cool and all, but that’s a tall order.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch the full episode to hear more about the massive AI infrastructure investments reshaping Silicon Valley, TikTok’s ownership saga, and the policy changes affecting tech’s biggest players.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-957037038-nvidia.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley flooded the news this week with headlines about wild AI infrastructure investments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia said it would invest up to $100 billion in OpenAI. Then OpenAI said it would build out five more Stargate AI data centers with Oracle and Softbank, adding gigawatts of new capacity online in the coming years. And it was later revealed that Oracle sold $18 billion in bonds to pay for these data centers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On their own, each deal is dizzying in scale. But in aggregate, we see how Silicon Valley is moving heaven and Earth to give OpenAI enough power to train and serve future versions of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week on Equity, Anthony Ha and I (Max Zeff) go beyond the headlines to break down what’s really going on in these AI infrastructure deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Rather conveniently, OpenAI also gave the world a glimpse this week of a power-intensive feature it could serve more broadly if it had access to more AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company launched Pulse — a new feature in ChatGPT that works overnight to deliver personalized morning briefings for users. The experience feels similar to a news app or a social feed — something you check first thing in the morning — but doesn’t have posts from other users or ads (yet).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pulse is part of a new class of OpenAI products that works independently, even when users aren’t in the ChatGPT app. The company would like to deliver a lot more of these features, and roll them out to free users, but they’re limited by the number of computer servers available to them. OpenAI said it can only offer Pulse to its $200-a-month Pro subscribers right now due to capacity constraints.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real question is whether features like Pulse are worth the hundreds of billions of dollars being invested in AI data centers to support OpenAI. The feature looks cool and all, but that’s a tall order.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch the full episode to hear more about the massive AI infrastructure investments reshaping Silicon Valley, TikTok’s ownership saga, and the policy changes affecting tech’s biggest players.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/whats-behind-the-massive-ai-data-center-headlines/</guid><pubDate>Fri, 26 Sep 2025 19:40:24 +0000</pubDate></item><item><title>[NEW] YouTube Music is testing AI hosts that will interrupt your tunes (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/09/youtube-music-is-testing-ai-hosts-that-will-interrupt-your-tunes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Labs will be a place to preview all the app's upcoming AI features.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube labs" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs-640x379.jpg" width="640" /&gt;
                  &lt;img alt="YouTube labs" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="468" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs.jpg" width="790" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;YouTube has a new Labs program, allowing listeners to "discover the next generation of YouTube." In case you were wondering, that generation is apparently all about AI. The streaming site says Labs will offer a glimpse of the AI features it's developing for YouTube Music, and it starts with AI "hosts" that will chime in while you're listening to music. Yes, really.&lt;/p&gt;
&lt;p&gt;The new AI music hosts are supposed to provide a richer listening experience, according to YouTube. As you're listening to tunes, the AI will generate audio snippets similar to, but shorter than, the fake podcasts you can create in NotebookLM. The "Beyond the Beat" host will break in every so often with relevant stories, trivia, and commentary about your musical tastes. YouTube says this feature will appear when you are listening to mixes and radio stations.&lt;/p&gt;
&lt;p&gt;The experimental feature is intended to be a bit like having a radio host drop some playful banter while cueing up the next song. It sounds a bit like Spotify's AI DJ, but the YouTube AI doesn't create playlists like Spotify's robot. This is still generative AI, which comes with the risk of hallucinations and low-quality slop, neither of which belongs in your music. That said, Google's Audio Overviews are often surprisingly good in small doses.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To opt in, visit the new YouTube Labs landing page. After joining, the YouTube Music app will get a new button on the Now Playing screen with the familiar Gemini sparkle logo. Tapping that will allow you to snooze the commentary for an hour or the remainder of the day. There is no option to completely disable the AI host in the app, so you'll have to opt out of the test if you decide Beyond the Beat is more trouble than it's worth.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119422 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1012" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YT-AI-snooze.png" width="1280" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You can snooze the AI host.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We've been on the hunt for this AI host since opting into the test several hours ago, but the robot has yet to appear. YouTube says the feature is now live for a "limited number" of US testers to try, but it's possible the frequency of AI interruptions will change as Google gathers more data on how much people like (or don't) having a robot tell them about music.&lt;/p&gt;
&lt;p&gt;This is the only experiment available in YouTube Labs for now, but the company says more AI features will be added to Labs soon. This will help Google gather feedback to decide how to roll out the features widely. So if you have strong feelings about the AI host, it may be worthwhile to submit feedback from the Labs page. YouTube is accelerating its use of AI. On the video side, the site is working toward releasing a suite of AI video tools, and it automatically upscales some videos, much to the chagrin of uploaders.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Labs will be a place to preview all the app's upcoming AI features.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube labs" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs-640x379.jpg" width="640" /&gt;
                  &lt;img alt="YouTube labs" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="468" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs.jpg" width="790" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;YouTube has a new Labs program, allowing listeners to "discover the next generation of YouTube." In case you were wondering, that generation is apparently all about AI. The streaming site says Labs will offer a glimpse of the AI features it's developing for YouTube Music, and it starts with AI "hosts" that will chime in while you're listening to music. Yes, really.&lt;/p&gt;
&lt;p&gt;The new AI music hosts are supposed to provide a richer listening experience, according to YouTube. As you're listening to tunes, the AI will generate audio snippets similar to, but shorter than, the fake podcasts you can create in NotebookLM. The "Beyond the Beat" host will break in every so often with relevant stories, trivia, and commentary about your musical tastes. YouTube says this feature will appear when you are listening to mixes and radio stations.&lt;/p&gt;
&lt;p&gt;The experimental feature is intended to be a bit like having a radio host drop some playful banter while cueing up the next song. It sounds a bit like Spotify's AI DJ, but the YouTube AI doesn't create playlists like Spotify's robot. This is still generative AI, which comes with the risk of hallucinations and low-quality slop, neither of which belongs in your music. That said, Google's Audio Overviews are often surprisingly good in small doses.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To opt in, visit the new YouTube Labs landing page. After joining, the YouTube Music app will get a new button on the Now Playing screen with the familiar Gemini sparkle logo. Tapping that will allow you to snooze the commentary for an hour or the remainder of the day. There is no option to completely disable the AI host in the app, so you'll have to opt out of the test if you decide Beyond the Beat is more trouble than it's worth.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119422 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1012" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YT-AI-snooze.png" width="1280" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You can snooze the AI host.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We've been on the hunt for this AI host since opting into the test several hours ago, but the robot has yet to appear. YouTube says the feature is now live for a "limited number" of US testers to try, but it's possible the frequency of AI interruptions will change as Google gathers more data on how much people like (or don't) having a robot tell them about music.&lt;/p&gt;
&lt;p&gt;This is the only experiment available in YouTube Labs for now, but the company says more AI features will be added to Labs soon. This will help Google gather feedback to decide how to roll out the features widely. So if you have strong feelings about the AI host, it may be worthwhile to submit feedback from the Labs page. YouTube is accelerating its use of AI. On the video side, the site is working toward releasing a suite of AI video tools, and it automatically upscales some videos, much to the chagrin of uploaders.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/09/youtube-music-is-testing-ai-hosts-that-will-interrupt-your-tunes/</guid><pubDate>Fri, 26 Sep 2025 21:05:30 +0000</pubDate></item><item><title>[NEW] Can AI detect hedgehogs from space? Maybe if you find brambles first. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/can-ai-detect-hedgehogs-from-space-maybe-if-you-find-brambles-first/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cambridge researchers use satellite-based bramble detection as a proxy for mapping hedgehog habitats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An adult UK hedgehog among autumn leaves and a fly agaric mushroom.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mike Powles via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;You can't spot a hedgehog from space, but you might be able to find where they live by looking for brambles. That's the premise behind ongoing research at the University of Cambridge, where scientists are using satellite imagery and AI models to map potential hedgehog habitats across the UK by first identifying their favorite hiding spots: bramble patches.&lt;/p&gt;
&lt;p&gt;European hedgehog populations have declined by roughly 30 to 50 percent over the past decade, so tracking these nocturnal creatures across large areas remains difficult and expensive. Rather than searching for the hedgehogs directly, researcher Gabriel Mahler developed an AI model that identifies brambles, which are thorny shrubs that hedgehogs use for shelter and foraging, from satellite data.&lt;/p&gt;
&lt;p&gt;These small mammals rely on this type of dense vegetation for daytime shelter, nesting sites, and protection from predators. Brambles also attract insects and provide berries, supporting the invertebrate populations that hedgehogs eat.&lt;/p&gt;
&lt;p&gt;Traditional hedgehog surveys require extensive nighttime fieldwork, specialized equipment, or citizen scientists reporting sightings. Those are methods that don't scale well for national conservation planning. By contrast, satellite imagery covers vast areas continuously, and if AI models could reliably identify key habitat features like brambles, conservationists might gain a powerful tool for large-scale habitat assessment.&lt;/p&gt;
&lt;h2&gt;From satellites to shrubs&lt;/h2&gt;
&lt;p&gt;While AI is a popular buzzword these days, it's worth noting that the Cambridge team's detector is not based on a large language model like ChatGPT. Instead, the model uses relatively simple machine learning techniques: a combination of logistic regression and k-nearest neighbors classification.&lt;/p&gt;
&lt;p&gt;Mahler's bramble detector also combines TESSERA earth representation embeddings, which process imagery from the European Space Agency's Sentinel satellites, with ground-truth observations from iNaturalist, a citizen science platform.&lt;/p&gt;
&lt;p&gt;But does it actually work? To find out, Mahler and colleagues Sadiq Jaffer, Anil Madhavapeddy, and Shane Weisz spent a day walking around Cambridge with smartphones and GPS devices, checking whether the model's predictions matched reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"It took us about 20 seconds to find the first one in an area indicated by the model," wrote Jaffer in a blog post documenting the field test. Starting at Milton Community Centre, where the model showed high confidence of brambles near the car park, the team systematically visited locations with varying prediction levels.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119476 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="The research team locating their first bramble." class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/20250924_130422.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The research team locating their first bramble.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadiq Jaffer

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At Milton Country Park, every high-confidence area they checked contained substantial bramble growth. When they investigated a residential hotspot, they found an empty plot overrun with brambles. Most amusingly, a major prediction in North Cambridge led them to Bramblefields Local Nature Reserve. True to its name, the area contained extensive bramble coverage.&lt;/p&gt;
&lt;p&gt;The model reportedly performed best when detecting large, uncovered bramble patches visible from above. Smaller brambles under tree cover showed lower confidence scores—a logical limitation given the satellite's overhead perspective. "Since TESSERA is learned representation from remote sensing data, it would make sense that bramble partially obscured from above might be harder to spot," Jaffer explained.&lt;/p&gt;
&lt;h2&gt;An early experiment&lt;/h2&gt;
&lt;p&gt;While the researchers expressed enthusiasm over the early results, the bramble detection work represents a proof-of-concept that is still under active research. The model has not yet been published in a peer-reviewed journal, and the field validation described here was an informal test rather than a scientific study. The Cambridge team acknowledges these limitations and plans more systematic validation.&lt;/p&gt;
&lt;p&gt;However, it's still a relatively positive research application of neural network techniques that reminds us that the field of artificial intelligence is much larger than just generative AI models, such as ChatGPT, or video synthesis models.&lt;/p&gt;
&lt;p&gt;Should the team's research pan out, the simplicity of the bramble detector offers some practical advantages. Unlike more resource-intensive deep learning models, the system could potentially run on mobile devices, enabling real-time field validation. The team considered developing a phone-based active learning system that would enable field researchers to improve the model while verifying its predictions.&lt;/p&gt;
&lt;p&gt;In the future, similar AI-based approaches combining satellite remote sensing with citizen science data could potentially map invasive species, track agricultural pests, or monitor changes in various ecosystems. For threatened species like hedgehogs, rapidly mapping critical habitat features becomes increasingly valuable during a time when climate change and urbanization are actively reshaping the places that hedgehogs like to call home.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cambridge researchers use satellite-based bramble detection as a proxy for mapping hedgehog habitats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An adult UK hedgehog among autumn leaves and a fly agaric mushroom.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mike Powles via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;You can't spot a hedgehog from space, but you might be able to find where they live by looking for brambles. That's the premise behind ongoing research at the University of Cambridge, where scientists are using satellite imagery and AI models to map potential hedgehog habitats across the UK by first identifying their favorite hiding spots: bramble patches.&lt;/p&gt;
&lt;p&gt;European hedgehog populations have declined by roughly 30 to 50 percent over the past decade, so tracking these nocturnal creatures across large areas remains difficult and expensive. Rather than searching for the hedgehogs directly, researcher Gabriel Mahler developed an AI model that identifies brambles, which are thorny shrubs that hedgehogs use for shelter and foraging, from satellite data.&lt;/p&gt;
&lt;p&gt;These small mammals rely on this type of dense vegetation for daytime shelter, nesting sites, and protection from predators. Brambles also attract insects and provide berries, supporting the invertebrate populations that hedgehogs eat.&lt;/p&gt;
&lt;p&gt;Traditional hedgehog surveys require extensive nighttime fieldwork, specialized equipment, or citizen scientists reporting sightings. Those are methods that don't scale well for national conservation planning. By contrast, satellite imagery covers vast areas continuously, and if AI models could reliably identify key habitat features like brambles, conservationists might gain a powerful tool for large-scale habitat assessment.&lt;/p&gt;
&lt;h2&gt;From satellites to shrubs&lt;/h2&gt;
&lt;p&gt;While AI is a popular buzzword these days, it's worth noting that the Cambridge team's detector is not based on a large language model like ChatGPT. Instead, the model uses relatively simple machine learning techniques: a combination of logistic regression and k-nearest neighbors classification.&lt;/p&gt;
&lt;p&gt;Mahler's bramble detector also combines TESSERA earth representation embeddings, which process imagery from the European Space Agency's Sentinel satellites, with ground-truth observations from iNaturalist, a citizen science platform.&lt;/p&gt;
&lt;p&gt;But does it actually work? To find out, Mahler and colleagues Sadiq Jaffer, Anil Madhavapeddy, and Shane Weisz spent a day walking around Cambridge with smartphones and GPS devices, checking whether the model's predictions matched reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"It took us about 20 seconds to find the first one in an area indicated by the model," wrote Jaffer in a blog post documenting the field test. Starting at Milton Community Centre, where the model showed high confidence of brambles near the car park, the team systematically visited locations with varying prediction levels.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119476 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="The research team locating their first bramble." class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/20250924_130422.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The research team locating their first bramble.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadiq Jaffer

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At Milton Country Park, every high-confidence area they checked contained substantial bramble growth. When they investigated a residential hotspot, they found an empty plot overrun with brambles. Most amusingly, a major prediction in North Cambridge led them to Bramblefields Local Nature Reserve. True to its name, the area contained extensive bramble coverage.&lt;/p&gt;
&lt;p&gt;The model reportedly performed best when detecting large, uncovered bramble patches visible from above. Smaller brambles under tree cover showed lower confidence scores—a logical limitation given the satellite's overhead perspective. "Since TESSERA is learned representation from remote sensing data, it would make sense that bramble partially obscured from above might be harder to spot," Jaffer explained.&lt;/p&gt;
&lt;h2&gt;An early experiment&lt;/h2&gt;
&lt;p&gt;While the researchers expressed enthusiasm over the early results, the bramble detection work represents a proof-of-concept that is still under active research. The model has not yet been published in a peer-reviewed journal, and the field validation described here was an informal test rather than a scientific study. The Cambridge team acknowledges these limitations and plans more systematic validation.&lt;/p&gt;
&lt;p&gt;However, it's still a relatively positive research application of neural network techniques that reminds us that the field of artificial intelligence is much larger than just generative AI models, such as ChatGPT, or video synthesis models.&lt;/p&gt;
&lt;p&gt;Should the team's research pan out, the simplicity of the bramble detector offers some practical advantages. Unlike more resource-intensive deep learning models, the system could potentially run on mobile devices, enabling real-time field validation. The team considered developing a phone-based active learning system that would enable field researchers to improve the model while verifying its predictions.&lt;/p&gt;
&lt;p&gt;In the future, similar AI-based approaches combining satellite remote sensing with citizen science data could potentially map invasive species, track agricultural pests, or monitor changes in various ecosystems. For threatened species like hedgehogs, rapidly mapping critical habitat features becomes increasingly valuable during a time when climate change and urbanization are actively reshaping the places that hedgehogs like to call home.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/can-ai-detect-hedgehogs-from-space-maybe-if-you-find-brambles-first/</guid><pubDate>Fri, 26 Sep 2025 22:22:13 +0000</pubDate></item></channel></rss>