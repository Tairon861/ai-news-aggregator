<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 07 Aug 2025 06:37:26 +0000</lastBuildDate><item><title>For regulated industries, AWS’s neurosymbolic AI promises safe, explainable agent automation (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/for-regulated-industries-awss-neurosymbolic-ai-promises-safe-explainable-agent-automation/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS is banking on the fact that by bringing its Automated Reasoning Checks feature on Bedrock to general availability, it will give more enterprises and regulated industries the confidence to use and deploy more AI applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It is also hoping that introducing methods like automated reasoning, which utilizes math-based validation to determine ground truth, will ease enterprises into the world of neurosymbolic AI, a step the company believes will be the next major advancement — and its biggest differentiation — in the world of AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Automated Reasoning Checks enable enterprise users to verify the accuracy of responses and detect model hallucination. AWS unveiled Automated Reasoning Checks on Bedrock during its annual re: Invent conference in December, claiming it can catch nearly 100% of all hallucinations. A limited number of users could access the feature through Amazon Bedrock Guardrails, where organizations can set responsible AI policies.&lt;/p&gt;



&lt;p&gt;Byron Cook, distinguished scientist and vice president at AWS’s Automated Reasoning Group, told VentureBeat in an interview that the preview rollout proved systems like this work in an enterprise setting, and it helps organizations understand the value of AI that can mix symbolic or structured thinking with the neural network nature of generative AI.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“There’s this notion of neurosymbolic AI, that’s the sort of moniker under which you might call automated reasoning,” Cook said. “The rise of interest in neurosymbolic AI caused people, while they were using the tool, to realize how important this work was.”&lt;/p&gt;



&lt;p&gt;Cook said that some customers allowed AWS to review their data and the documents used to annotate the answers as right or wrong, and found that the work generated by the tool performed similarly to humans with a copy of the rule book in front of them. He added that the concept of truth or correct can often be subject to interpretation. Automated reasoning doesn’t have quite the same issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It was really amazing! It was amazing to have people with logic backgrounds be in an internal communication channel arguing about what is true or not, and in five or six messages point to the tool and realize Oh, it is right,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new features to Automated Reasoning Checks for general release. These include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Support to add large documents of up to 80k tokens or up to 100 pages&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Simpler policy validation by saving validation tests for repeated runs&lt;/li&gt;



&lt;li&gt;Automated scenario generation from pre-saved definitions&lt;/li&gt;



&lt;li&gt;Natural language suggestions for policy feedback&lt;/li&gt;



&lt;li&gt;Customizable validation settings&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Cook said Automated Reasoning Checks validates truth or correctness in an AI system by proving that a model did not hallucinate a solution or response. This means it could offer regulators and regulated enterprises worried that the non-deterministic nature of generative AI could return incorrect responses more confidence.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-neurosymbolic-ai-and-proving-truth"&gt;Neurosymbolic AI and proving truth&lt;/h2&gt;



&lt;p&gt;Cook brought up the idea that Automated Reasoning Checks help prove many of the concepts of neurosymbolic AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Neurosymbolic AI refers to the combination of neural networks used by language models, with the structured thinking and logic from symbolic AI. Where neural networks recognize patterns from data, symbolic AI uses explicit rules and logic problems. Foundation models often rely on neural networks or deep learning, but because the models base their responses on patterns, they are prone to hallucinations, a concern that continues to concern enterprises. But symbolic AI is not very flexible without manual instructions.&lt;/p&gt;



&lt;p&gt;Prominent voices in AI, like Gary Marcus, have said that neurosymbolic AI is critical for artificial general intelligence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Cook and AWS have been excited to bring ideas of neurosymbolic AI to the enterprise. VentureBeat’s Matt Marshall spoke about AWS’s focus on methods like automated reasoning checks and combining math and logic to generative AI to cut down on hallucinations in a podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Currently, few companies offer productized neurosymbolic AI. These include Kognitos, Franz Inc. and UMNAI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bringing-math-to-validation"&gt;Bringing math to validation&lt;/h2&gt;



&lt;p&gt;Automated reasoning works by applying mathematical proofs to models in response to a query.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It employs a method called the satisfiability modulo theories, where symbols have predefined meanings, and it solves problems that involve both logic (if, then, and, or) and mathematics. Automated reasoning takes that method and applies it to responses by a model and checks it against a set of policy or ground truth data without the need to test the answer multiple times.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, in an enterprise setting, they want to prove that a financial audit is correct. The model responds that a report contains unapproved payments. Automated reasoning checks break this down to a logic string:&lt;/p&gt;



&lt;p&gt;(forall ((r Report))&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&amp;nbsp;(=&amp;gt; (containsUnapprovedVendorPayments r)&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(shouldEscalate r)))&lt;/p&gt;



&lt;p&gt;It then goes into the definitions, variables and types set by the user on Bedrock Guardrails and solves the equation to prove that the model responded correctly and based on truth.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-agents-provably-correct"&gt;Making agents provably correct&lt;/h2&gt;



&lt;p&gt;Cook said that agentic use cases could benefit from automated reasoning checks, and granting more access to the feature through Bedrock can demonstrate its usefulness. But he cautioned that automated reasoning, and other neurosymbolic AI techniques, are still in its very early stages.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“I think it will have an impact on agentic AI, though, of course, the agentic work is so speculative right now,” Cook said. “There are several techniques like this of discovering ambiguity in the statement then finding the sort of key deltas between the possible translations, and then coming back to you and getting refinement on that, which I think, will be key in terms of the emotional journey that I saw customers go through they began playing with generative AI a couple of years ago.”&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS is banking on the fact that by bringing its Automated Reasoning Checks feature on Bedrock to general availability, it will give more enterprises and regulated industries the confidence to use and deploy more AI applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It is also hoping that introducing methods like automated reasoning, which utilizes math-based validation to determine ground truth, will ease enterprises into the world of neurosymbolic AI, a step the company believes will be the next major advancement — and its biggest differentiation — in the world of AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Automated Reasoning Checks enable enterprise users to verify the accuracy of responses and detect model hallucination. AWS unveiled Automated Reasoning Checks on Bedrock during its annual re: Invent conference in December, claiming it can catch nearly 100% of all hallucinations. A limited number of users could access the feature through Amazon Bedrock Guardrails, where organizations can set responsible AI policies.&lt;/p&gt;



&lt;p&gt;Byron Cook, distinguished scientist and vice president at AWS’s Automated Reasoning Group, told VentureBeat in an interview that the preview rollout proved systems like this work in an enterprise setting, and it helps organizations understand the value of AI that can mix symbolic or structured thinking with the neural network nature of generative AI.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“There’s this notion of neurosymbolic AI, that’s the sort of moniker under which you might call automated reasoning,” Cook said. “The rise of interest in neurosymbolic AI caused people, while they were using the tool, to realize how important this work was.”&lt;/p&gt;



&lt;p&gt;Cook said that some customers allowed AWS to review their data and the documents used to annotate the answers as right or wrong, and found that the work generated by the tool performed similarly to humans with a copy of the rule book in front of them. He added that the concept of truth or correct can often be subject to interpretation. Automated reasoning doesn’t have quite the same issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It was really amazing! It was amazing to have people with logic backgrounds be in an internal communication channel arguing about what is true or not, and in five or six messages point to the tool and realize Oh, it is right,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new features to Automated Reasoning Checks for general release. These include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Support to add large documents of up to 80k tokens or up to 100 pages&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Simpler policy validation by saving validation tests for repeated runs&lt;/li&gt;



&lt;li&gt;Automated scenario generation from pre-saved definitions&lt;/li&gt;



&lt;li&gt;Natural language suggestions for policy feedback&lt;/li&gt;



&lt;li&gt;Customizable validation settings&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Cook said Automated Reasoning Checks validates truth or correctness in an AI system by proving that a model did not hallucinate a solution or response. This means it could offer regulators and regulated enterprises worried that the non-deterministic nature of generative AI could return incorrect responses more confidence.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-neurosymbolic-ai-and-proving-truth"&gt;Neurosymbolic AI and proving truth&lt;/h2&gt;



&lt;p&gt;Cook brought up the idea that Automated Reasoning Checks help prove many of the concepts of neurosymbolic AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Neurosymbolic AI refers to the combination of neural networks used by language models, with the structured thinking and logic from symbolic AI. Where neural networks recognize patterns from data, symbolic AI uses explicit rules and logic problems. Foundation models often rely on neural networks or deep learning, but because the models base their responses on patterns, they are prone to hallucinations, a concern that continues to concern enterprises. But symbolic AI is not very flexible without manual instructions.&lt;/p&gt;



&lt;p&gt;Prominent voices in AI, like Gary Marcus, have said that neurosymbolic AI is critical for artificial general intelligence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Cook and AWS have been excited to bring ideas of neurosymbolic AI to the enterprise. VentureBeat’s Matt Marshall spoke about AWS’s focus on methods like automated reasoning checks and combining math and logic to generative AI to cut down on hallucinations in a podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Currently, few companies offer productized neurosymbolic AI. These include Kognitos, Franz Inc. and UMNAI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bringing-math-to-validation"&gt;Bringing math to validation&lt;/h2&gt;



&lt;p&gt;Automated reasoning works by applying mathematical proofs to models in response to a query.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It employs a method called the satisfiability modulo theories, where symbols have predefined meanings, and it solves problems that involve both logic (if, then, and, or) and mathematics. Automated reasoning takes that method and applies it to responses by a model and checks it against a set of policy or ground truth data without the need to test the answer multiple times.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, in an enterprise setting, they want to prove that a financial audit is correct. The model responds that a report contains unapproved payments. Automated reasoning checks break this down to a logic string:&lt;/p&gt;



&lt;p&gt;(forall ((r Report))&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&amp;nbsp;(=&amp;gt; (containsUnapprovedVendorPayments r)&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(shouldEscalate r)))&lt;/p&gt;



&lt;p&gt;It then goes into the definitions, variables and types set by the user on Bedrock Guardrails and solves the equation to prove that the model responded correctly and based on truth.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-agents-provably-correct"&gt;Making agents provably correct&lt;/h2&gt;



&lt;p&gt;Cook said that agentic use cases could benefit from automated reasoning checks, and granting more access to the feature through Bedrock can demonstrate its usefulness. But he cautioned that automated reasoning, and other neurosymbolic AI techniques, are still in its very early stages.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“I think it will have an impact on agentic AI, though, of course, the agentic work is so speculative right now,” Cook said. “There are several techniques like this of discovering ambiguity in the statement then finding the sort of key deltas between the possible translations, and then coming back to you and getting refinement on that, which I think, will be key in terms of the emotional journey that I saw customers go through they began playing with generative AI a couple of years ago.”&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/for-regulated-industries-awss-neurosymbolic-ai-promises-safe-explainable-agent-automation/</guid><pubDate>Wed, 06 Aug 2025 19:05:50 +0000</pubDate></item><item><title>Google search boss says AI isn’t killing search clicks (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/08/google-search-boss-says-ai-isnt-killing-search-clicks/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Liz Reid says Google's data shows AI is generating consistent clicks and better experiences.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Google sign with logo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Google-sign-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Google sign with logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Google-sign-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google has often bristled at the implication that its obsession with AI search is harming web traffic, and now search head Liz Reid has penned a blog post on the topic. According to Reid, clicks aren't declining, AI is driving more searches, and everything is fine on the Internet. But despite the optimistic tone, the post stops short of providing any actual data to back up those claims.&lt;/p&gt;
&lt;p&gt;This statement feels like a direct response to a recent Pew Research Center analysis that showed searches with AI Overviews resulted in lower click-through rates. Google objected to the conclusions and methodology of that study, and the new blog post expands on its rationale.&lt;/p&gt;
&lt;p&gt;The banner claim in this post is that Google is not sending fewer clicks to websites. According to Reid, "total organic click volume" has remained "relatively stable year-over-year." Meanwhile, Google is seeing more searches on its end, which is the most important metric for the company. Google's blog also notes (fairly) that the web is unfathomably vast, and it's common for trends to shift.&lt;/p&gt;
&lt;p&gt;Google apparently sees AI Overviews as an evolution of what it has done in the past with Knowledge Graph or sports scores. Reid says those features didn't reduce clicks, either. In fact, Google sees higher-quality clicks in search results, which it identifies as people clicking on links without immediately backing out. However, the company isn't providing any numbers, which undercuts the argument.&lt;/p&gt;
&lt;h2&gt;Uneven benefits&lt;/h2&gt;
&lt;p&gt;Google's meaning comes partially into focus when Reid discusses some broad trends the company has seen. She says search users are increasingly looking for "authentic voices and first-hand perspectives," which sounds like code for "Reddit." Google partnered with Reddit in early 2024, gaining access to its wealth of authentic voices (except when they're trolling) for AI training, and you'd have to be blind not to notice how Google has increasingly surfaced Reddit links in search results ever since.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Reddit's traffic has more than doubled since 2021, and growth has significantly accelerated in the 18 months since the companies announced their deal. According to Reddit, which is one of the biggest sites on the Internet, it has seen daily active users grow by a whopping 21 percent in just the past year. More than 110 million people use the site every day.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2096348 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google Elizabeth Reid" class="fullwidth full" height="3037" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Liz-reid-e1747853101729.jpg" width="5346" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google's search head, Liz Reid, says AI isn't hurting the web.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;So it can be true that Google is sending a similar number of clicks to websites in aggregate, but more of those clicks could be going to sites favored in both organic results and AI answers. This isn't even an unfamiliar problem with Google search. Several years ago, niche review sites began to see their search clicks cannibalized by big brands generating SEO spam to take the top of the search results page. In short, growth is not always shared equally or fairly on Google.&lt;/p&gt;
&lt;p&gt;Reid closes with the questionable claim that Google may care more than any other company in the world about "the health of the web ecosystem." New products like AI Overviews are designed to highlight the web, not replace the need to click, according to Reid. But at the same time, the post acknowledges that sometimes people get what they need from the AI answer and will "not click further." Can both be true?&lt;/p&gt;
&lt;p&gt;If we're to take anything from Google's explanation, it's that the benefits of AI search are not being shared evenly. Google is still cruising along, seeing record profit and increasing searches, but many site operators have seen clicks stagnate as impressions go up. Until Google can provide metrics to back its claims, it's impossible to say exactly what is happening.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Liz Reid says Google's data shows AI is generating consistent clicks and better experiences.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Google sign with logo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Google-sign-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Google sign with logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Google-sign-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google has often bristled at the implication that its obsession with AI search is harming web traffic, and now search head Liz Reid has penned a blog post on the topic. According to Reid, clicks aren't declining, AI is driving more searches, and everything is fine on the Internet. But despite the optimistic tone, the post stops short of providing any actual data to back up those claims.&lt;/p&gt;
&lt;p&gt;This statement feels like a direct response to a recent Pew Research Center analysis that showed searches with AI Overviews resulted in lower click-through rates. Google objected to the conclusions and methodology of that study, and the new blog post expands on its rationale.&lt;/p&gt;
&lt;p&gt;The banner claim in this post is that Google is not sending fewer clicks to websites. According to Reid, "total organic click volume" has remained "relatively stable year-over-year." Meanwhile, Google is seeing more searches on its end, which is the most important metric for the company. Google's blog also notes (fairly) that the web is unfathomably vast, and it's common for trends to shift.&lt;/p&gt;
&lt;p&gt;Google apparently sees AI Overviews as an evolution of what it has done in the past with Knowledge Graph or sports scores. Reid says those features didn't reduce clicks, either. In fact, Google sees higher-quality clicks in search results, which it identifies as people clicking on links without immediately backing out. However, the company isn't providing any numbers, which undercuts the argument.&lt;/p&gt;
&lt;h2&gt;Uneven benefits&lt;/h2&gt;
&lt;p&gt;Google's meaning comes partially into focus when Reid discusses some broad trends the company has seen. She says search users are increasingly looking for "authentic voices and first-hand perspectives," which sounds like code for "Reddit." Google partnered with Reddit in early 2024, gaining access to its wealth of authentic voices (except when they're trolling) for AI training, and you'd have to be blind not to notice how Google has increasingly surfaced Reddit links in search results ever since.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Reddit's traffic has more than doubled since 2021, and growth has significantly accelerated in the 18 months since the companies announced their deal. According to Reddit, which is one of the biggest sites on the Internet, it has seen daily active users grow by a whopping 21 percent in just the past year. More than 110 million people use the site every day.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2096348 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google Elizabeth Reid" class="fullwidth full" height="3037" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Liz-reid-e1747853101729.jpg" width="5346" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google's search head, Liz Reid, says AI isn't hurting the web.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;So it can be true that Google is sending a similar number of clicks to websites in aggregate, but more of those clicks could be going to sites favored in both organic results and AI answers. This isn't even an unfamiliar problem with Google search. Several years ago, niche review sites began to see their search clicks cannibalized by big brands generating SEO spam to take the top of the search results page. In short, growth is not always shared equally or fairly on Google.&lt;/p&gt;
&lt;p&gt;Reid closes with the questionable claim that Google may care more than any other company in the world about "the health of the web ecosystem." New products like AI Overviews are designed to highlight the web, not replace the need to click, according to Reid. But at the same time, the post acknowledges that sometimes people get what they need from the AI answer and will "not click further." Can both be true?&lt;/p&gt;
&lt;p&gt;If we're to take anything from Google's explanation, it's that the benefits of AI search are not being shared evenly. Google is still cruising along, seeing record profit and increasing searches, but many site operators have seen clicks stagnate as impressions go up. Until Google can provide metrics to back its claims, it's impossible to say exactly what is happening.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/08/google-search-boss-says-ai-isnt-killing-search-clicks/</guid><pubDate>Wed, 06 Aug 2025 19:36:42 +0000</pubDate></item><item><title>How a ‘vibe working’ approach at Genspark tripled ARR growth and supported a barrage of new products and features in just weeks (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/how-a-vibe-working-approach-at-genspark-tripled-arr-growth-and-supported-a-barrage-of-new-products-and-features-in-just-weeks/</link><description>&lt;p&gt;Traditionally, product releases can be cumbersome, requiring multiple sign-offs, endless tinkering, bureaucracies and friction points.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The AI workspace company’s lean team practices AI-native working — or ‘vibe working,’ if you will — so that they can move at what they call “gen speed.” This allows them to release new products and features in rapid-fire succession (nearly every week or so), steadily driving up annual recurring revenue (ARR). As the company boasts, it could be “the fastest-growing startup ever in terms of ARR.”&lt;/p&gt;&lt;p&gt;“When people are working the AI-native way, basically everybody is the manager,” Kaihua (Kay) Zhu, co-founder and CTO, told VentureBeat. “They are equipped with a team of AI agents, which are kind of their reportees, and they are capable of, single-handedly, delivering the feature end-to-end. “&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-aggressive-rollouts-stoking-competition"&gt;Aggressive rollouts, stoking competition&lt;/h2&gt;



&lt;p&gt;Genspark, launched in June 2024 by MainFunc, was initially focused on AI search. But despite reaching an impressive 5 million users, the company pivoted away from that initial product to Super Agent, which, instead of following a static sequence of steps as in traditional search, chooses the best tools or sub-agents for the job, gauges results and adjusts in real time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Launching on April 2, Super Agent is powered by Anthropic’s Claude and can condense an afternoon of white collar office work into 5 minutes, Zhu claims. For instance, it can make calls, download, fact check, produce podcasts, draft documents, perform deep research and pull together spreadsheets and slides.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We still see it as a kind of search, but it’s more technically advanced,” said Zhu, who has more than 20 years of experience working in search at Google and Baidu.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company has aggressively added more and more features over the last four months; here’s a rundown of its rollouts and milestones:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;April 11: Reached $10 million ARR just 9 days after Super Agent launch&lt;/li&gt;



&lt;li&gt;April 22: Introduced AI Slides (featuring hundreds of templates)&lt;/li&gt;



&lt;li&gt;April 28: Rolled out a personalized Super Agent with adaptive personalities&lt;/li&gt;



&lt;li&gt;May 2: Hit $22 million ARR, exactly one month post-launch&lt;/li&gt;



&lt;li&gt;May 8: Rolled out AI Sheets that create complete spreadsheets in one click&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 15: Introduced a fully-agentic download agent and AI drive that manages and stores files&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 19: Hit $36 million ARR&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 22: Rolled out AI that can make phone calls&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 4: Introduced an AI Secretary that manages Gmail, calendars and Google Drive&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 10: Rolled out an AI Browser and MCP store featuring extended browsing capabilities and a tool marketplace&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 18: Introduced AI Docs for document creation and management&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 25: Introduced Design Studio with “Canva-like” capabilities for visual content creation&amp;nbsp;&lt;/li&gt;



&lt;li&gt;July 10: Rolled out AI Pods to create podcasts with simple prompts&amp;nbsp;&lt;/li&gt;



&lt;li&gt;July 17: Introduced advanced editing features for AI Slides&lt;/li&gt;



&lt;li&gt;July 31: Rolled out AI Slides 2.0&lt;/li&gt;



&lt;li&gt;August 1: Introduced multi-agent orchestration that can produce up to 10 agents simultaneously&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Genspark is also heating up the AI agent space with friendly competition. After OpenAI announced its ChatGPT agent in mid-July, Genspark performed a comparative analysis and is “very confident” in its ability to overperform the rival. To drive home this point, the company launched a “1 Million Dollar Side-by-side AI Showdown,” challenging users to hunt for cases where other platforms outperform Genspark Super Agent.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015111" height="293" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-59.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In the first round, users were tasked with building a 12-page financial slide using Genspack and ChatGPT Agent; users identified 429 cases where the latter outperformed the former, each earning $100 for their efforts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In round 2 (which ended Monday, August 4), Genspark upped the ante to $200 per win and opened the competition to any AI tool as an opponent. Users were challenged to use exactly the same prompt to build slides on Genspark and their chosen AI tool, then upload them to Gemini for evaluation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Not trying to start any drama here — just genuinely excited about how far the entire AI agent ecosystem has come,” the company posted on X. “It shows we’re all pushing the boundaries in the right direction.”&lt;/p&gt;



&lt;p&gt;Some user reactions:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015112" height="580" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-64.png" width="631" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015113" height="561" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-65.png" width="638" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-genspark-s-ai-native-team-vibes"&gt;How Genspark’s AI native team vibes&lt;/h2&gt;



&lt;p&gt;Genspark’s secret is its lean, AI-native team of 20 people and engineering philosophy of “less control, more tools.” Zhu explained that more than 80% of its code is written by AI, which isn’t vibe coding per se, “because vibe coding kind of indicates you never look at the code.” Rather, Genspark has a “very rigid” code review process to help guarantee the quality of their code base.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We only need a very small AI-native team to operate in a kind of superhero mode, like &lt;em&gt;The Avengers&lt;/em&gt;,” said Zhu, who said they’ll gradually add team members as needed. “The AI coding and AI workflow are so powerful, it’s a magnifier.”&lt;/p&gt;



&lt;p&gt;Today’s enterprise teams must be reorganized “totally differently,” he said. He’s managed 1,000-member teams with different levels of management and seen how office politics can introduce friction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark’s team, by contrast, communicates in “a very transparent way,” and productivity is “super high.” “Everybody is working on a product that can ship,” said Zhu. “I believe that that will be the norm looking forward, since AI is actually helping more and more people do their work better.”&lt;/p&gt;



&lt;p&gt;He also emphasized the importance of immersing yourself in your own product. From designers themselves to the marketing team, “we actually eat our own dog food. We are our own product consumer. That’s how we will keep improving the experience.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-genspark-s-flagship-super-agent"&gt;Inside Genspark’s flagship Super Agent&lt;/h2&gt;



&lt;p&gt;Zhu noted that, when Perplexity launched in December 2022, it ignited excitement about AI’s potential to transform search. Still, it followed rigid workflows, with platforms having to:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Analyze queries and expand keywords;&lt;/li&gt;



&lt;li&gt;Retrieve top web results;&lt;/li&gt;



&lt;li&gt;Rerank/summarize for a final response.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This was adequate for basic stuff, but “crumbled” in more complex scenarios like technical comparisons, in-depth research and multi-step and multi-factor purchases. “In essence, it was like trying to navigate a maze with only fixed turns,” said Zhu.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark built its search engine on this same kind of foundation, layering on incremental improvements including specialized data sources, parallel search for deeper investigation into complex queries and cross-checking of asynchronous agents to verify statements too complex for “quick, on-the-fly handling.” But they realized they were still “shackled” by fixed, predefined workflows, Zhu reported.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Super Agent uses nine differently-sized, differently-specialized large language models (LLMs) in a mixture-of-agents (MoE) system. Models break tasks down into steps, delegating based on specialty and strength, then cross-verify one another. Super Agent is also equipped with more than 80 tools (from sub-agents that can generate Python code to ones that can autonomously make phone calls) and more than 10 datasets curated from the web, partners and repositories.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark gives tasks to Claude, OpenAI, Google Gemini, DeepSeek., AI’s Grok 4 and others, “then we let everybody produce their output, and we have an aggregator model to look through the results and analyze which process is most cost-effective,” Zhu explained. “In this way, we improve the accuracy, reduce hallucinations.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company also fine-tunes its own frontier model. However, they are not overly aggressive about creating state-of-the-art systems like DeepSeek v3 or v4, Zhu emphasized. The goal is to have the model perform low-level but heavy lifting work.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We are not trying to push the boundary of the frontier model,” he said. “We are trying to bring down the cost and the latency, because a lot of proprietary models are too big, too slow and too expensive for a lot of relatively simple tasks.”&lt;/p&gt;



&lt;p&gt;As for the vibe coding trend, Genspark’s goal is to allow everyone to experiment, even for non-programmers where the concept may be a little “too distant.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“A lot of people think, ‘vibe coding, I’ve heard about it, it sounds cool, but I’m not familiar with the integrated developer environment (IDE), I’m not familiar with code,” said Zhu. “Using Genspark, people can actually vibe.”&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Traditionally, product releases can be cumbersome, requiring multiple sign-offs, endless tinkering, bureaucracies and friction points.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The AI workspace company’s lean team practices AI-native working — or ‘vibe working,’ if you will — so that they can move at what they call “gen speed.” This allows them to release new products and features in rapid-fire succession (nearly every week or so), steadily driving up annual recurring revenue (ARR). As the company boasts, it could be “the fastest-growing startup ever in terms of ARR.”&lt;/p&gt;&lt;p&gt;“When people are working the AI-native way, basically everybody is the manager,” Kaihua (Kay) Zhu, co-founder and CTO, told VentureBeat. “They are equipped with a team of AI agents, which are kind of their reportees, and they are capable of, single-handedly, delivering the feature end-to-end. “&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-aggressive-rollouts-stoking-competition"&gt;Aggressive rollouts, stoking competition&lt;/h2&gt;



&lt;p&gt;Genspark, launched in June 2024 by MainFunc, was initially focused on AI search. But despite reaching an impressive 5 million users, the company pivoted away from that initial product to Super Agent, which, instead of following a static sequence of steps as in traditional search, chooses the best tools or sub-agents for the job, gauges results and adjusts in real time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Launching on April 2, Super Agent is powered by Anthropic’s Claude and can condense an afternoon of white collar office work into 5 minutes, Zhu claims. For instance, it can make calls, download, fact check, produce podcasts, draft documents, perform deep research and pull together spreadsheets and slides.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We still see it as a kind of search, but it’s more technically advanced,” said Zhu, who has more than 20 years of experience working in search at Google and Baidu.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company has aggressively added more and more features over the last four months; here’s a rundown of its rollouts and milestones:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;April 11: Reached $10 million ARR just 9 days after Super Agent launch&lt;/li&gt;



&lt;li&gt;April 22: Introduced AI Slides (featuring hundreds of templates)&lt;/li&gt;



&lt;li&gt;April 28: Rolled out a personalized Super Agent with adaptive personalities&lt;/li&gt;



&lt;li&gt;May 2: Hit $22 million ARR, exactly one month post-launch&lt;/li&gt;



&lt;li&gt;May 8: Rolled out AI Sheets that create complete spreadsheets in one click&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 15: Introduced a fully-agentic download agent and AI drive that manages and stores files&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 19: Hit $36 million ARR&amp;nbsp;&lt;/li&gt;



&lt;li&gt;May 22: Rolled out AI that can make phone calls&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 4: Introduced an AI Secretary that manages Gmail, calendars and Google Drive&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 10: Rolled out an AI Browser and MCP store featuring extended browsing capabilities and a tool marketplace&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 18: Introduced AI Docs for document creation and management&amp;nbsp;&lt;/li&gt;



&lt;li&gt;June 25: Introduced Design Studio with “Canva-like” capabilities for visual content creation&amp;nbsp;&lt;/li&gt;



&lt;li&gt;July 10: Rolled out AI Pods to create podcasts with simple prompts&amp;nbsp;&lt;/li&gt;



&lt;li&gt;July 17: Introduced advanced editing features for AI Slides&lt;/li&gt;



&lt;li&gt;July 31: Rolled out AI Slides 2.0&lt;/li&gt;



&lt;li&gt;August 1: Introduced multi-agent orchestration that can produce up to 10 agents simultaneously&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Genspark is also heating up the AI agent space with friendly competition. After OpenAI announced its ChatGPT agent in mid-July, Genspark performed a comparative analysis and is “very confident” in its ability to overperform the rival. To drive home this point, the company launched a “1 Million Dollar Side-by-side AI Showdown,” challenging users to hunt for cases where other platforms outperform Genspark Super Agent.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015111" height="293" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-59.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In the first round, users were tasked with building a 12-page financial slide using Genspack and ChatGPT Agent; users identified 429 cases where the latter outperformed the former, each earning $100 for their efforts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In round 2 (which ended Monday, August 4), Genspark upped the ante to $200 per win and opened the competition to any AI tool as an opponent. Users were challenged to use exactly the same prompt to build slides on Genspark and their chosen AI tool, then upload them to Gemini for evaluation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Not trying to start any drama here — just genuinely excited about how far the entire AI agent ecosystem has come,” the company posted on X. “It shows we’re all pushing the boundaries in the right direction.”&lt;/p&gt;



&lt;p&gt;Some user reactions:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015112" height="580" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-64.png" width="631" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015113" height="561" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-65.png" width="638" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-genspark-s-ai-native-team-vibes"&gt;How Genspark’s AI native team vibes&lt;/h2&gt;



&lt;p&gt;Genspark’s secret is its lean, AI-native team of 20 people and engineering philosophy of “less control, more tools.” Zhu explained that more than 80% of its code is written by AI, which isn’t vibe coding per se, “because vibe coding kind of indicates you never look at the code.” Rather, Genspark has a “very rigid” code review process to help guarantee the quality of their code base.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We only need a very small AI-native team to operate in a kind of superhero mode, like &lt;em&gt;The Avengers&lt;/em&gt;,” said Zhu, who said they’ll gradually add team members as needed. “The AI coding and AI workflow are so powerful, it’s a magnifier.”&lt;/p&gt;



&lt;p&gt;Today’s enterprise teams must be reorganized “totally differently,” he said. He’s managed 1,000-member teams with different levels of management and seen how office politics can introduce friction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark’s team, by contrast, communicates in “a very transparent way,” and productivity is “super high.” “Everybody is working on a product that can ship,” said Zhu. “I believe that that will be the norm looking forward, since AI is actually helping more and more people do their work better.”&lt;/p&gt;



&lt;p&gt;He also emphasized the importance of immersing yourself in your own product. From designers themselves to the marketing team, “we actually eat our own dog food. We are our own product consumer. That’s how we will keep improving the experience.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-genspark-s-flagship-super-agent"&gt;Inside Genspark’s flagship Super Agent&lt;/h2&gt;



&lt;p&gt;Zhu noted that, when Perplexity launched in December 2022, it ignited excitement about AI’s potential to transform search. Still, it followed rigid workflows, with platforms having to:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Analyze queries and expand keywords;&lt;/li&gt;



&lt;li&gt;Retrieve top web results;&lt;/li&gt;



&lt;li&gt;Rerank/summarize for a final response.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This was adequate for basic stuff, but “crumbled” in more complex scenarios like technical comparisons, in-depth research and multi-step and multi-factor purchases. “In essence, it was like trying to navigate a maze with only fixed turns,” said Zhu.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark built its search engine on this same kind of foundation, layering on incremental improvements including specialized data sources, parallel search for deeper investigation into complex queries and cross-checking of asynchronous agents to verify statements too complex for “quick, on-the-fly handling.” But they realized they were still “shackled” by fixed, predefined workflows, Zhu reported.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Super Agent uses nine differently-sized, differently-specialized large language models (LLMs) in a mixture-of-agents (MoE) system. Models break tasks down into steps, delegating based on specialty and strength, then cross-verify one another. Super Agent is also equipped with more than 80 tools (from sub-agents that can generate Python code to ones that can autonomously make phone calls) and more than 10 datasets curated from the web, partners and repositories.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Genspark gives tasks to Claude, OpenAI, Google Gemini, DeepSeek., AI’s Grok 4 and others, “then we let everybody produce their output, and we have an aggregator model to look through the results and analyze which process is most cost-effective,” Zhu explained. “In this way, we improve the accuracy, reduce hallucinations.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The company also fine-tunes its own frontier model. However, they are not overly aggressive about creating state-of-the-art systems like DeepSeek v3 or v4, Zhu emphasized. The goal is to have the model perform low-level but heavy lifting work.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We are not trying to push the boundary of the frontier model,” he said. “We are trying to bring down the cost and the latency, because a lot of proprietary models are too big, too slow and too expensive for a lot of relatively simple tasks.”&lt;/p&gt;



&lt;p&gt;As for the vibe coding trend, Genspark’s goal is to allow everyone to experiment, even for non-programmers where the concept may be a little “too distant.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“A lot of people think, ‘vibe coding, I’ve heard about it, it sounds cool, but I’m not familiar with the integrated developer environment (IDE), I’m not familiar with code,” said Zhu. “Using Genspark, people can actually vibe.”&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-a-vibe-working-approach-at-genspark-tripled-arr-growth-and-supported-a-barrage-of-new-products-and-features-in-just-weeks/</guid><pubDate>Wed, 06 Aug 2025 19:41:34 +0000</pubDate></item><item><title>Google denies AI search features are killing website traffic (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/06/google-denies-ai-search-features-are-killing-website-traffic/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Numerous studies indicate that the shift to AI search features and the use of AI chatbots are killing traffic to publishers’ sites. But Google on Wednesday denied that’s the case, at least in aggregate. Instead, the search giant says that total organic click volume from its search engine to websites has been “relatively stable” year-over-year and that average click quality has slightly increased.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This data is in contrast to third-party reports that inaccurately suggest dramatic declines in aggregate traffic — often based on flawed methodologies, isolated examples, or traffic changes that occurred prior to the roll out of AI features in Search,” writes Google VP and Head of Search, Liz Reid, in a new blog post.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though Google hasn’t shared any specific data to back up its conclusions, even if we assume Google’s claims to be true, this doesn’t necessarily mean that AI isn’t having an impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Google has to admit this, as Reid acknowledges that “user trends are shifting traffic to different sites, resulting in decreased traffic to some sites and increased traffic to others.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That word “some” is doing heavy lifting here, as Google doesn’t share data about how many sites are gaining or losing. And while chatbots like ChatGPT have certainly seen traffic increase in recent months, that doesn’t mean online publishers aren’t suffering.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3009660" height="339" src="https://techcrunch.com/wp-content/uploads/2025/05/ai-overviews-io.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been revamping its search engine for years to answer more questions directly on the search results page, and now does so with AI through its “AI Overviews” that appear at the top of search results. Google also allows users to interact with an AI chatbot for some queries. Yet Google denies that this is significantly reshaping the search landscape. Rather, it points to users shifting their attention to other sites to start their queries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reid explains, “People are increasingly seeking out and clicking on sites with forums, videos, podcasts, and posts where they can hear authentic voices and first-hand perspectives.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reading between the lines, it seems like Google.com isn’t necessarily people’s first stop on the web these days. But that’s something we’ve known for some time. Back in 2022, a Google exec even said that social sites like TikTok and Instagram were eating into Google’s core products, like Search and Maps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our studies, something like almost 40% of young people, when they’re looking for a place for lunch, they don’t go to Google Maps or Search,” said Google SVP Prabhakar Raghavan, who ran the company’s Knowledge and Information organization at the time (he is now its chief technologist). “They go to TikTok or Instagram,” he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has also long been worried that Amazon.com had become people’s first stop for online shopping searches, and Reddit.com had become the first stop for researching topics of interest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over many years, the company has tried to come up with compelling features for both consumers and retailers that would attract more users to Google Shopping. These efforts have included universal shopping carts, local inventory checks, deal finders, shopping from product images on websites, and more. It even made its Shopping listings free for merchants in 2020.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, as users complained that Google Search quality was declining, the search giant was seeing so much demand for Reddit that it finally added a “Reddit” filter to allow users to narrow down results on relevant search queries. (Now that filter simply reads “forums.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So perhaps there’s some truth in Google’s denials — it’s not AI that’s entirely responsible for killing search. Search was already dying. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A person holding an iPhone and using Google AI Mode" class="wp-image-3017226" height="453" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2206888090.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Smith Collection/Gado / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new blog post also attempts to move the goalposts a bit about what it means for websites receiving Google’s clicks. Now, instead of counting clicks, it wants publishers to think about click quality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says average click quality has increased, and Google is sending “slightly more quality clicks” to websites than a year ago. (Google explains that a quality click is one where users don’t quickly click back — they stay and read.) How much of an increase, though, Google doesn’t say. The company only points out that when people click through on an AI response to the source, they’re more likely to dive deeper, so those clicks are more valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, Google paints AI as an opportunity for web publishers to gain increased exposure, saying that “with AI Overviews, people are seeing more links on the page than before,” Reid writes. “More queries and more links mean more opportunities for websites to surface and get clicked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But AI, while a growing referral source, isn’t yet making up the difference in terms of clicks, reports have shown. One recent study from Similarweb indicates that the number of news searches on the web resulting in zero clicks to news websites has grown from 56% (when Google launched AI Overviews in May 2024) to 69% as of May 2025. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024257" height="575" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-1.01.35PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google appears to knows this is a trend, too, as it recently launched a product for publishers that helps them monetize their dwindling traffic in other ways that don’t rely only on advertising, like micropayments or newsletter sign-ups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The fact that Google is pushing this &lt;em&gt;“&lt;/em&gt;AI is not the end of search traffic!” PR now only makes the situation seem more dire. It’s as if Google wants publishers to believe not what their own eyes — and graphs and charts — tell them, but instead take comfort in the fact that Google still sends “billions of clicks to websites” every day, just as the post claims.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Numerous studies indicate that the shift to AI search features and the use of AI chatbots are killing traffic to publishers’ sites. But Google on Wednesday denied that’s the case, at least in aggregate. Instead, the search giant says that total organic click volume from its search engine to websites has been “relatively stable” year-over-year and that average click quality has slightly increased.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This data is in contrast to third-party reports that inaccurately suggest dramatic declines in aggregate traffic — often based on flawed methodologies, isolated examples, or traffic changes that occurred prior to the roll out of AI features in Search,” writes Google VP and Head of Search, Liz Reid, in a new blog post.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though Google hasn’t shared any specific data to back up its conclusions, even if we assume Google’s claims to be true, this doesn’t necessarily mean that AI isn’t having an impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Google has to admit this, as Reid acknowledges that “user trends are shifting traffic to different sites, resulting in decreased traffic to some sites and increased traffic to others.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That word “some” is doing heavy lifting here, as Google doesn’t share data about how many sites are gaining or losing. And while chatbots like ChatGPT have certainly seen traffic increase in recent months, that doesn’t mean online publishers aren’t suffering.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3009660" height="339" src="https://techcrunch.com/wp-content/uploads/2025/05/ai-overviews-io.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been revamping its search engine for years to answer more questions directly on the search results page, and now does so with AI through its “AI Overviews” that appear at the top of search results. Google also allows users to interact with an AI chatbot for some queries. Yet Google denies that this is significantly reshaping the search landscape. Rather, it points to users shifting their attention to other sites to start their queries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reid explains, “People are increasingly seeking out and clicking on sites with forums, videos, podcasts, and posts where they can hear authentic voices and first-hand perspectives.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reading between the lines, it seems like Google.com isn’t necessarily people’s first stop on the web these days. But that’s something we’ve known for some time. Back in 2022, a Google exec even said that social sites like TikTok and Instagram were eating into Google’s core products, like Search and Maps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our studies, something like almost 40% of young people, when they’re looking for a place for lunch, they don’t go to Google Maps or Search,” said Google SVP Prabhakar Raghavan, who ran the company’s Knowledge and Information organization at the time (he is now its chief technologist). “They go to TikTok or Instagram,” he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has also long been worried that Amazon.com had become people’s first stop for online shopping searches, and Reddit.com had become the first stop for researching topics of interest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over many years, the company has tried to come up with compelling features for both consumers and retailers that would attract more users to Google Shopping. These efforts have included universal shopping carts, local inventory checks, deal finders, shopping from product images on websites, and more. It even made its Shopping listings free for merchants in 2020.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, as users complained that Google Search quality was declining, the search giant was seeing so much demand for Reddit that it finally added a “Reddit” filter to allow users to narrow down results on relevant search queries. (Now that filter simply reads “forums.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So perhaps there’s some truth in Google’s denials — it’s not AI that’s entirely responsible for killing search. Search was already dying. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A person holding an iPhone and using Google AI Mode" class="wp-image-3017226" height="453" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2206888090.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Smith Collection/Gado / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new blog post also attempts to move the goalposts a bit about what it means for websites receiving Google’s clicks. Now, instead of counting clicks, it wants publishers to think about click quality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says average click quality has increased, and Google is sending “slightly more quality clicks” to websites than a year ago. (Google explains that a quality click is one where users don’t quickly click back — they stay and read.) How much of an increase, though, Google doesn’t say. The company only points out that when people click through on an AI response to the source, they’re more likely to dive deeper, so those clicks are more valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, Google paints AI as an opportunity for web publishers to gain increased exposure, saying that “with AI Overviews, people are seeing more links on the page than before,” Reid writes. “More queries and more links mean more opportunities for websites to surface and get clicked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But AI, while a growing referral source, isn’t yet making up the difference in terms of clicks, reports have shown. One recent study from Similarweb indicates that the number of news searches on the web resulting in zero clicks to news websites has grown from 56% (when Google launched AI Overviews in May 2024) to 69% as of May 2025. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3024257" height="575" src="https://techcrunch.com/wp-content/uploads/2025/07/Similarweb-AI-news-report-2025-07-02-at-1.01.35PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google appears to knows this is a trend, too, as it recently launched a product for publishers that helps them monetize their dwindling traffic in other ways that don’t rely only on advertising, like micropayments or newsletter sign-ups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The fact that Google is pushing this &lt;em&gt;“&lt;/em&gt;AI is not the end of search traffic!” PR now only makes the situation seem more dire. It’s as if Google wants publishers to believe not what their own eyes — and graphs and charts — tell them, but instead take comfort in the fact that Google still sends “billions of clicks to websites” every day, just as the post claims.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/06/google-denies-ai-search-features-are-killing-website-traffic/</guid><pubDate>Wed, 06 Aug 2025 19:45:29 +0000</pubDate></item><item><title>Insulin resistance prediction from wearables and routine blood biomarkers (The latest research from Google)</title><link>https://research.google/blog/insulin-resistance-prediction-from-wearables-and-routine-blood-biomarkers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Type 2 diabetes affects hundreds of millions globally, and its prevalence is rising. A major precursor to this condition is insulin resistance (IR), where the body's cells do not respond properly to insulin, a hormone crucial for regulating blood sugar. Detecting IR early is key, as lifestyle changes can often reverse it and prevent or delay the onset of type 2 diabetes. However, current methods for accurately measuring IR, like the "gold standard" euglycemic insulin clamp or the Homeostatic Model Assessment for Insulin Resistance (HOMA-IR), which requires specific insulin blood tests, are often invasive, expensive, or not readily available in routine check-ups. These steps create significant barriers to early detection and intervention, especially for those unknowingly at risk.&lt;/p&gt;&lt;p&gt;What if we could leverage data already available to many people, such as data from wearable devices and common blood tests, to estimate IR risk? In “Insulin Resistance Prediction From Wearables and Routine Blood Biomarkers”, we explore a suite of machine learning models that have the potential of predicting IR using wearable data (e.g., resting heart rate, step count, sleep patterns) and routine blood tests (e.g., fasting glucose, lipid panel). This approach shows strong performance across the studied population (N=1,165) and an independent validation cohort (N=72), particularly in high-risk individuals, such as people with obesity and sedentary lifestyles. Additionally, we introduce the Insulin Resistance Literacy and Understanding Agent (an IR prototype agent), built on the state-of-the-art Gemini family of LLMs to help understand insulin resistance, facilitating interpretation and safe personalized recommendations. This work offers the potential for early detection of people at risk of type 2 diabetes and thereby facilitates earlier implementation of preventative strategies. The models, predictions, and the Insulin Resistance Literacy and Understanding Agent described in this research are intended for informational and research purposes only.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Type 2 diabetes affects hundreds of millions globally, and its prevalence is rising. A major precursor to this condition is insulin resistance (IR), where the body's cells do not respond properly to insulin, a hormone crucial for regulating blood sugar. Detecting IR early is key, as lifestyle changes can often reverse it and prevent or delay the onset of type 2 diabetes. However, current methods for accurately measuring IR, like the "gold standard" euglycemic insulin clamp or the Homeostatic Model Assessment for Insulin Resistance (HOMA-IR), which requires specific insulin blood tests, are often invasive, expensive, or not readily available in routine check-ups. These steps create significant barriers to early detection and intervention, especially for those unknowingly at risk.&lt;/p&gt;&lt;p&gt;What if we could leverage data already available to many people, such as data from wearable devices and common blood tests, to estimate IR risk? In “Insulin Resistance Prediction From Wearables and Routine Blood Biomarkers”, we explore a suite of machine learning models that have the potential of predicting IR using wearable data (e.g., resting heart rate, step count, sleep patterns) and routine blood tests (e.g., fasting glucose, lipid panel). This approach shows strong performance across the studied population (N=1,165) and an independent validation cohort (N=72), particularly in high-risk individuals, such as people with obesity and sedentary lifestyles. Additionally, we introduce the Insulin Resistance Literacy and Understanding Agent (an IR prototype agent), built on the state-of-the-art Gemini family of LLMs to help understand insulin resistance, facilitating interpretation and safe personalized recommendations. This work offers the potential for early detection of people at risk of type 2 diabetes and thereby facilitates earlier implementation of preventative strategies. The models, predictions, and the Insulin Resistance Literacy and Understanding Agent described in this research are intended for informational and research purposes only.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/insulin-resistance-prediction-from-wearables-and-routine-blood-biomarkers/</guid><pubDate>Wed, 06 Aug 2025 20:02:00 +0000</pubDate></item><item><title>School of Architecture and Planning welcomes new faculty for 2025 (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/school-architecture-planning-welcomes-new-faculty-0806</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-NewSAP25-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Four new faculty members join the School of Architecture and Planning (SA+P) this fall, offering the MIT community creativity, knowledge, and scholarship in multidisciplinary roles.&lt;/p&gt;&lt;p&gt;“These individuals add considerable strength and depth to our faculty,” says Hashim Sarkis, dean of the School of Architecture and Planning. “We are excited for the academic vigor they bring to research and teaching.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Karrie G. Karahalios&lt;/strong&gt; ’94, MEng ’95, SM ’97, PhD ’04 joins the MIT Media Lab as a full professor of media arts and sciences. Karahalios is a pioneer in the exploration of social media and of how people communicate in environments that are increasingly mediated by algorithms that, as she has written, “shape the world around us.” Her work combines computing, systems, artificial intelligence, anthropology, sociology, psychology, game theory, design, and infrastructure studies. Karahalios’ work has received numerous honors including the National Science Foundation CAREER Award, Alfred P. Sloan Research Fellowship, SIGMOD Best Paper Award, and recognition as an ACM Distinguished Member.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pat Pataranutaporn&lt;/strong&gt; SM ’18, PhD ’20 joins the MIT Media Lab as an assistant professor of media arts and sciences. A visionary technologist, scientist, and designer, Pataranutaporn explores the frontier of human-AI interaction, inventing and investigating AI systems that support human thriving. His research focuses on how personalized AI systems can amplify human cognition, from learning and decision-making to self-development, reflection, and well-being. Pataranutaporn will co-direct the Advancing Humans with AI Program.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mariana Popescu&lt;/strong&gt; joins the&amp;nbsp;Department of Architecture as an assistant professor. Popescu&amp;nbsp;is a computational architect and structural designer with a strong interest and experience in innovative ways of approaching the fabrication process and use of materials in construction.&amp;nbsp;Her area of expertise is computational and parametric design, with a focus on digital fabrication and sustainable design. Her extensive involvement in projects related to promoting sustainability has led to a multilateral development of skills, which combine the fields of architecture, engineering, computational design, and digital fabrication.&amp;nbsp;Popescu earned her doctorate at ETH Zurich. She was&amp;nbsp;named a “Pioneer” on the &lt;em&gt;MIT Technology Review&lt;/em&gt; global list of “35 innovators under 35” in 2019.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Holly Samuelson&lt;/strong&gt; joins the Department of Architecture as an associate professor&amp;nbsp;in the Building Technology Program at MIT, teaching architectural technology courses. Her teaching and research focus on issues of building design that impact human and environmental health. Her current projects harness advanced building simulation to investigate issues of greenhouse gas emissions, heat vulnerability, and indoor environmental quality while considering the future of buildings in a changing electricity grid. Samuelson has co-authored over 40 peer-reviewed papers, winning a best paper award from the journal &lt;em&gt;Energy and Building&lt;/em&gt;. As a recognized expert in architectural technology, she has been featured in news outlets including &lt;em&gt;The Washington Post&lt;/em&gt;, &lt;em&gt;The Boston Globe&lt;/em&gt;, the BBC, and &lt;em&gt;The Wall Street Journal&lt;/em&gt;. Samuelson earned her doctor of design from Harvard University Graduate School of Design.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-NewSAP25-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Four new faculty members join the School of Architecture and Planning (SA+P) this fall, offering the MIT community creativity, knowledge, and scholarship in multidisciplinary roles.&lt;/p&gt;&lt;p&gt;“These individuals add considerable strength and depth to our faculty,” says Hashim Sarkis, dean of the School of Architecture and Planning. “We are excited for the academic vigor they bring to research and teaching.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Karrie G. Karahalios&lt;/strong&gt; ’94, MEng ’95, SM ’97, PhD ’04 joins the MIT Media Lab as a full professor of media arts and sciences. Karahalios is a pioneer in the exploration of social media and of how people communicate in environments that are increasingly mediated by algorithms that, as she has written, “shape the world around us.” Her work combines computing, systems, artificial intelligence, anthropology, sociology, psychology, game theory, design, and infrastructure studies. Karahalios’ work has received numerous honors including the National Science Foundation CAREER Award, Alfred P. Sloan Research Fellowship, SIGMOD Best Paper Award, and recognition as an ACM Distinguished Member.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pat Pataranutaporn&lt;/strong&gt; SM ’18, PhD ’20 joins the MIT Media Lab as an assistant professor of media arts and sciences. A visionary technologist, scientist, and designer, Pataranutaporn explores the frontier of human-AI interaction, inventing and investigating AI systems that support human thriving. His research focuses on how personalized AI systems can amplify human cognition, from learning and decision-making to self-development, reflection, and well-being. Pataranutaporn will co-direct the Advancing Humans with AI Program.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mariana Popescu&lt;/strong&gt; joins the&amp;nbsp;Department of Architecture as an assistant professor. Popescu&amp;nbsp;is a computational architect and structural designer with a strong interest and experience in innovative ways of approaching the fabrication process and use of materials in construction.&amp;nbsp;Her area of expertise is computational and parametric design, with a focus on digital fabrication and sustainable design. Her extensive involvement in projects related to promoting sustainability has led to a multilateral development of skills, which combine the fields of architecture, engineering, computational design, and digital fabrication.&amp;nbsp;Popescu earned her doctorate at ETH Zurich. She was&amp;nbsp;named a “Pioneer” on the &lt;em&gt;MIT Technology Review&lt;/em&gt; global list of “35 innovators under 35” in 2019.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Holly Samuelson&lt;/strong&gt; joins the Department of Architecture as an associate professor&amp;nbsp;in the Building Technology Program at MIT, teaching architectural technology courses. Her teaching and research focus on issues of building design that impact human and environmental health. Her current projects harness advanced building simulation to investigate issues of greenhouse gas emissions, heat vulnerability, and indoor environmental quality while considering the future of buildings in a changing electricity grid. Samuelson has co-authored over 40 peer-reviewed papers, winning a best paper award from the journal &lt;em&gt;Energy and Building&lt;/em&gt;. As a recognized expert in architectural technology, she has been featured in news outlets including &lt;em&gt;The Washington Post&lt;/em&gt;, &lt;em&gt;The Boston Globe&lt;/em&gt;, the BBC, and &lt;em&gt;The Wall Street Journal&lt;/em&gt;. Samuelson earned her doctor of design from Harvard University Graduate School of Design.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/school-architecture-planning-welcomes-new-faculty-0806</guid><pubDate>Wed, 06 Aug 2025 20:10:00 +0000</pubDate></item><item><title>US executive branch agencies will use ChatGPT Enterprise for just $1 per agency (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/openai-announces-deal-to-offer-chatgpt-to-us-executive-branch-at-almost-no-cost/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Questions linger about ideological bias in models as well as data security.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="OpenAI CEO Sam Altman standing in front of a backup with a large OpenAI logo." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/openai-sam-altman-640x427.jpg" width="640" /&gt;
                  &lt;img alt="OpenAI CEO Sam Altman standing in front of a backup with a large OpenAI logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/openai-sam-altman-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI CEO Sam Altman speaks during the Microsoft Build conference at the Seattle Convention Center Summit Building in Seattle, Washington on May 21, 2024. (Photo by Jason Redmond / AFP)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Jason Redmond/AFP

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;OpenAI announced an agreement to supply more than 2 million workers for the US federal executive branch access to ChatGPT and related tools at practically no cost: just $1 per agency for one year.&lt;/p&gt;
&lt;p&gt;The deal was announced just one day after the US General Services Administration (GSA) signed a blanket deal to allow OpenAI and rivals like Google and Anthropic to supply tools to federal workers.&lt;/p&gt;
&lt;p&gt;The workers will have access to ChatGPT Enterprise, a type of account that includes access to frontier models and cutting-edge features with relatively high token limits, alongside a more robust commitment to data privacy than general consumers of ChatGPT get. ChatGPT Enterprise has been trialed over the past several months at several corporations and other types of large organizations.&lt;/p&gt;
&lt;p&gt;The workers will also have unlimited access to advanced features like Deep Research and Advanced Voice Mode for a 60-day period. After the one-year trial period, the agencies are under no obligation to renew.&lt;/p&gt;
&lt;p&gt;A limited deployment of ChatGPT for federal workers was already done via a pilot program with the US Department of Defense earlier this summer.&lt;/p&gt;
&lt;p&gt;In a blog post, OpenAI heralded this announcement as an act of public service:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This effort delivers on a core pillar of the Trump Administration’s AI Action Plan by making powerful AI tools available across the federal government so that workers can spend less time on red tape and paperwork, and more time doing what they came to public service to do: serve the American people.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The AI Action Plan aims to expand AI-focused data centers in the United States while bringing AI tools to federal workers, ostensibly to improve efficiency.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There's an additional wrinkle that OpenAI may have to contend with: The Trump administration also recently issued an executive order labeled "Preventing Woke AI" that insists that AI tools procured by the federal government not push "ideological dogmas such as DEI."&lt;/p&gt;
&lt;p&gt;So far, conservatives in the Trump administration's camp have been consistently frustrated by ChatGPT's alleged left-leaning biases on issues just like that one, and efforts to train LLMs to consistently adhere to one ideology have had mixed results at best. It's not known what, if anything, OpenAI will do on this front; the company has already offered the federal government "custom models for national security," but there's no public commitment to custom models that avoid certain ideological inclinations.&lt;/p&gt;
&lt;p&gt;The details of how ChatGPT will ensure the necessary high standards of security for federal workers are also not publicly known, though a GSA spokesperson responded to a question on that topic from TechCrunch by saying "the government is taking a cautious, security-first approach to AI," adding, "this ensures sensitive information remains protected while enabling agencies to benefit from AI-driven efficiencies."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Questions linger about ideological bias in models as well as data security.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="OpenAI CEO Sam Altman standing in front of a backup with a large OpenAI logo." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/openai-sam-altman-640x427.jpg" width="640" /&gt;
                  &lt;img alt="OpenAI CEO Sam Altman standing in front of a backup with a large OpenAI logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/openai-sam-altman-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI CEO Sam Altman speaks during the Microsoft Build conference at the Seattle Convention Center Summit Building in Seattle, Washington on May 21, 2024. (Photo by Jason Redmond / AFP)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Jason Redmond/AFP

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;OpenAI announced an agreement to supply more than 2 million workers for the US federal executive branch access to ChatGPT and related tools at practically no cost: just $1 per agency for one year.&lt;/p&gt;
&lt;p&gt;The deal was announced just one day after the US General Services Administration (GSA) signed a blanket deal to allow OpenAI and rivals like Google and Anthropic to supply tools to federal workers.&lt;/p&gt;
&lt;p&gt;The workers will have access to ChatGPT Enterprise, a type of account that includes access to frontier models and cutting-edge features with relatively high token limits, alongside a more robust commitment to data privacy than general consumers of ChatGPT get. ChatGPT Enterprise has been trialed over the past several months at several corporations and other types of large organizations.&lt;/p&gt;
&lt;p&gt;The workers will also have unlimited access to advanced features like Deep Research and Advanced Voice Mode for a 60-day period. After the one-year trial period, the agencies are under no obligation to renew.&lt;/p&gt;
&lt;p&gt;A limited deployment of ChatGPT for federal workers was already done via a pilot program with the US Department of Defense earlier this summer.&lt;/p&gt;
&lt;p&gt;In a blog post, OpenAI heralded this announcement as an act of public service:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This effort delivers on a core pillar of the Trump Administration’s AI Action Plan by making powerful AI tools available across the federal government so that workers can spend less time on red tape and paperwork, and more time doing what they came to public service to do: serve the American people.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The AI Action Plan aims to expand AI-focused data centers in the United States while bringing AI tools to federal workers, ostensibly to improve efficiency.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There's an additional wrinkle that OpenAI may have to contend with: The Trump administration also recently issued an executive order labeled "Preventing Woke AI" that insists that AI tools procured by the federal government not push "ideological dogmas such as DEI."&lt;/p&gt;
&lt;p&gt;So far, conservatives in the Trump administration's camp have been consistently frustrated by ChatGPT's alleged left-leaning biases on issues just like that one, and efforts to train LLMs to consistently adhere to one ideology have had mixed results at best. It's not known what, if anything, OpenAI will do on this front; the company has already offered the federal government "custom models for national security," but there's no public commitment to custom models that avoid certain ideological inclinations.&lt;/p&gt;
&lt;p&gt;The details of how ChatGPT will ensure the necessary high standards of security for federal workers are also not publicly known, though a GSA spokesperson responded to a question on that topic from TechCrunch by saying "the government is taking a cautious, security-first approach to AI," adding, "this ensures sensitive information remains protected while enabling agencies to benefit from AI-driven efficiencies."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/openai-announces-deal-to-offer-chatgpt-to-us-executive-branch-at-almost-no-cost/</guid><pubDate>Wed, 06 Aug 2025 20:11:24 +0000</pubDate></item><item><title>The initial reactions to OpenAI’s landmark open source gpt-oss models are highly varied and mixed (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/the-initial-reactions-to-openais-landmark-open-source-gpt-oss-models-are-highly-varied-and-mixed/</link><description>&lt;p&gt;But despite achieving technical benchmarks on par with OpenAI’s other powerful proprietary AI model offerings, the broader AI developer and user community’s initial &lt;strong&gt;response has so far been all over the map.&lt;/strong&gt; If this release were a movie premiering and being graded on Rotten Tomatoes, we’d be looking at a near 50% split, based on my observations. &lt;/p&gt;&lt;p&gt;First some background: OpenAI has released these two new text-only language models (no image generation or analysis) &lt;strong&gt;both under the permissive open source Apache 2.0 license &lt;/strong&gt;—&lt;strong&gt; the first time since 2019 (before ChatGPT) &lt;/strong&gt;that the company has done so with a cutting-edge language model. &lt;/p&gt;&lt;p&gt;The &lt;strong&gt;entire ChatGPT era of the last 2.7 years has so far been powered by proprietary or closed-source models&lt;/strong&gt;, ones that OpenAI controlled and that users had to pay to access (or use a free tier subject to limits), with limited customizability and no way to run them offline or on private computing hardware.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;But that all changed thanks to the release of the pair of gpt-oss models yesterday, one larger and more powerful for use on a single Nvidia H100 GPU at say, a small or medium-sized enterprise’s data center or server farm, and an even smaller one that works on a single consumer laptop or desktop PC like the kind in your home office.&lt;/p&gt;



&lt;p&gt;Of course, the models being so new, it’s taken several hours for the AI power user community to independently run and test them out on their own individual benchmarks (measurements) and tasks. &lt;/p&gt;



&lt;p&gt;And&lt;strong&gt; now we’re getting a wave of feedback ranging from optimistic enthusiasm&lt;/strong&gt; about the potential of these powerful, free, and efficient new models&lt;strong&gt; to an undercurrent of dissatisfaction and dismay with what some users see as significant problems and limitations&lt;/strong&gt;, especially compared to the wave of similarly Apache 2.0-licensed&lt;strong&gt; powerful open source, multimodal LLMs from Chinese startups&lt;/strong&gt; (which can also be taken, customized, run locally on U.S. hardware for free by U.S. companies, or companies anywhere else around the world).  &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-high-benchmarks-but-still-behind-chinese-open-source-leaders"&gt;High benchmarks, but still behind Chinese open source leaders&lt;/h2&gt;



&lt;p&gt;Intelligence benchmarks place the gpt-oss models ahead of most American open-source offerings. According to independent third-party AI benchmarking firm Artificial Analysis, gpt-oss-120B is “the most intelligent American open weights model,” though it &lt;strong&gt;still falls short of Chinese heavyweights like DeepSeek R1 and Qwen3 235B.&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015234" height="366" src="https://venturebeat.com/wp-content/uploads/2025/08/GxoMDVga8AAJWo3.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“On reflection, that’s all they did. Mogged on benchmarks,” wrote self-proclaimed DeepSeek “stan” @teortaxesTex. “No good derivative models will be trained… No new usecases created… Barren claim to bragging rights.”&lt;/p&gt;



&lt;p&gt;That skepticism is echoed by pseudonymous open source AI researcher Teknium (@Teknium1), co-founder of rival open source AI model provider Nous Research, who called the release “a legitimate nothing burger,” on X, and predicted a Chinese model will soon eclipse it. “Overall very disappointed and I legitimately came open minded to this,” they wrote.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bench-maxxing-on-math-and-coding-at-the-expense-of-writing"&gt;Bench-maxxing on math and coding at the expense of writing?&lt;/h2&gt;



&lt;p&gt;Other criticism focused on the &lt;strong&gt;gpt-oss models’ apparent narrow usefulness. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;AI influencer “Lisan al Gaib (@scaling01)” noted that the models excel at math and coding but “completely lack taste and common sense.” He added, “So it’s just a math model?”&lt;/p&gt;



&lt;p&gt;In creative writing tests, some users found the model injecting equations into poetic outputs. “This is what happens when you benchmarkmax,” Teknium remarked, sharing a screenshot where the model added an integral formula mid-poem.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;And @kalomaze, a researcher at decentralized AI model training company Prime Intellect, wrote that “gpt-oss-120b knows less about the world than what a good 32b does. probably wanted to avoid copyright issues so they likely pretrained on majority synth. pretty devastating stuff”&lt;/p&gt;



&lt;p&gt;Former Googler and independent AI developer Kyle Corbitt agreed that the gpt-oss pair of models seemed to have been trained primarily on synthetic data —  that is, data generated by an AI model specifically for the purposes of training a new one — making it “extremely spiky.”&lt;/p&gt;



&lt;p&gt;It’s “great at the tasks it’s trained on, really bad at everything else,” Corbitt wrote, i.e.,&lt;strong&gt; great on coding and math problems, and bad at more linguistic tasks like creative writing or report generation&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;In other words, the charge is that OpenAI deliberately trained the model on more synthetic data than real world facts and figures to avoid using copyrighted data scraped from websites and other repositories it doesn’t own or have license to use, which is something it and many other leading gen AI companies have been accused of in the past and are facing down ongoing lawsuits as a result of. &lt;/p&gt;



&lt;p&gt;Others speculated OpenAI may have trained the model on primarily synthetic data to avoid safety and security issues, resulting in worse quality than if it had been trained on more real world (and presumably copyrighted) data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-concerning-third-party-benchmark-results"&gt;Concerning third-party benchmark results&lt;/h2&gt;



&lt;p&gt;Moreover, evaluating the models on third-party benchmarking tests have turned up concerning metrics in some users’ eyes.&lt;/p&gt;



&lt;p&gt;SpeechMap — which measures the performance of LLMs in complying with user prompts to generate disallowed, biased, or politically sensitive outputs — showed compliance scores for gpt-oss 120B hovering under 40%,&lt;strong&gt; near the bottom of peer open models,&lt;/strong&gt; which indicates resistance to follow user requests and defaulting to guardrails, potentially at the expense of providing accurate information. &lt;/p&gt;



&lt;p&gt;In Aider’s Polyglot evaluation, &lt;strong&gt;gpt-oss-120B scored just 41.8% in multilingual reasoning—far below competitors like Kimi-K2 (59.1%) and DeepSeek-R1 (56.9%).&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Some users also said their tests indicated the model is oddly resistant to generating criticism of China or Russia, a contrast to its treatment of the US and EU, raising questions about bias and training data filtering.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-other-experts-have-applauded-the-release-and-what-it-signals-for-u-s-open-source-ai"&gt;Other experts have applauded the release and what it signals for U.S. open source AI&lt;/h2&gt;



&lt;p&gt;To be fair, not all the commentary is negative. Software engineer and close AI watcher Simon Willison called the release “really impressive” on X, elaborating in a blog post on &lt;strong&gt;the models’ efficiency and ability to achieve parity with OpenAI’s proprietary o3-mini and o4-mini models.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;He praised their strong performance on reasoning and STEM-heavy benchmarks, and hailed the new “Harmony” prompt template format — which offers developers more structured terms for guiding model responses — and support for third-party tool use as meaningful contributions.&lt;/p&gt;



&lt;p&gt;In a lengthy X post, Clem Delangue, CEO and co-founder of AI code sharing and open source community Hugging Face, encouraged users not to rush to judgment, pointing out that inference for these models is complex, and early issues could be due to infrastructure instability and insufficient optimization among hosting providers. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“The power of open-source is that there’s no cheating,” Delangue wrote.&lt;/strong&gt; “We’ll uncover all the strengths and limitations… progressively.”&lt;/p&gt;



&lt;p&gt;Even more cautious was Wharton School of Business at the University of Pennsylvania professor Ethan Mollick, who wrote on X that “The US now likely has the leading open weights models (or close to it)”, but questioned whether this is a one-off by OpenAI. &lt;strong&gt;“The lead will evaporate quickly as others catch up,”&lt;/strong&gt; he noted, adding that it’s unclear what incentives OpenAI has to keep the models updated.&lt;/p&gt;



&lt;p&gt;Nathan Lambert, a leading AI researcher at the rival open source lab Allen Institute for AI (Ai2) and commentator, praised the symbolic significance of the release on his blog Interconnects, calling it &lt;strong&gt;“a phenomenal step for the open ecosystem, especially for the West and its allies, &lt;/strong&gt;that the most known brand in the AI space has returned to openly releasing models.” &lt;/p&gt;



&lt;p&gt;But he cautioned on X that gpt-oss is &lt;strong&gt;“unlikely to meaningfully slow down [Chinese e-commerce giant Aliaba’s AI team] Qwen,” &lt;/strong&gt;citing its usability, performance, and variety. &lt;/p&gt;



&lt;p&gt;He argued the release marks an important shift in the U.S. toward open models, but that OpenAI still has a “long path back” to catch up in practice.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-split-verdict"&gt;A split verdict&lt;/h2&gt;



&lt;p&gt;The verdict, for now, is split. &lt;/p&gt;



&lt;p&gt;OpenAI’s gpt-oss models are a landmark in terms of licensing and accessibility. &lt;/p&gt;



&lt;p&gt;But while the benchmarks look solid, the real-world “vibes” — as many users describe it — are proving less compelling. &lt;/p&gt;



&lt;p&gt;Whether developers can build strong applications and derivatives on top of gpt-oss will determine whether the release is remembered as a breakthrough or a blip.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;But despite achieving technical benchmarks on par with OpenAI’s other powerful proprietary AI model offerings, the broader AI developer and user community’s initial &lt;strong&gt;response has so far been all over the map.&lt;/strong&gt; If this release were a movie premiering and being graded on Rotten Tomatoes, we’d be looking at a near 50% split, based on my observations. &lt;/p&gt;&lt;p&gt;First some background: OpenAI has released these two new text-only language models (no image generation or analysis) &lt;strong&gt;both under the permissive open source Apache 2.0 license &lt;/strong&gt;—&lt;strong&gt; the first time since 2019 (before ChatGPT) &lt;/strong&gt;that the company has done so with a cutting-edge language model. &lt;/p&gt;&lt;p&gt;The &lt;strong&gt;entire ChatGPT era of the last 2.7 years has so far been powered by proprietary or closed-source models&lt;/strong&gt;, ones that OpenAI controlled and that users had to pay to access (or use a free tier subject to limits), with limited customizability and no way to run them offline or on private computing hardware.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;But that all changed thanks to the release of the pair of gpt-oss models yesterday, one larger and more powerful for use on a single Nvidia H100 GPU at say, a small or medium-sized enterprise’s data center or server farm, and an even smaller one that works on a single consumer laptop or desktop PC like the kind in your home office.&lt;/p&gt;



&lt;p&gt;Of course, the models being so new, it’s taken several hours for the AI power user community to independently run and test them out on their own individual benchmarks (measurements) and tasks. &lt;/p&gt;



&lt;p&gt;And&lt;strong&gt; now we’re getting a wave of feedback ranging from optimistic enthusiasm&lt;/strong&gt; about the potential of these powerful, free, and efficient new models&lt;strong&gt; to an undercurrent of dissatisfaction and dismay with what some users see as significant problems and limitations&lt;/strong&gt;, especially compared to the wave of similarly Apache 2.0-licensed&lt;strong&gt; powerful open source, multimodal LLMs from Chinese startups&lt;/strong&gt; (which can also be taken, customized, run locally on U.S. hardware for free by U.S. companies, or companies anywhere else around the world).  &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-high-benchmarks-but-still-behind-chinese-open-source-leaders"&gt;High benchmarks, but still behind Chinese open source leaders&lt;/h2&gt;



&lt;p&gt;Intelligence benchmarks place the gpt-oss models ahead of most American open-source offerings. According to independent third-party AI benchmarking firm Artificial Analysis, gpt-oss-120B is “the most intelligent American open weights model,” though it &lt;strong&gt;still falls short of Chinese heavyweights like DeepSeek R1 and Qwen3 235B.&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015234" height="366" src="https://venturebeat.com/wp-content/uploads/2025/08/GxoMDVga8AAJWo3.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“On reflection, that’s all they did. Mogged on benchmarks,” wrote self-proclaimed DeepSeek “stan” @teortaxesTex. “No good derivative models will be trained… No new usecases created… Barren claim to bragging rights.”&lt;/p&gt;



&lt;p&gt;That skepticism is echoed by pseudonymous open source AI researcher Teknium (@Teknium1), co-founder of rival open source AI model provider Nous Research, who called the release “a legitimate nothing burger,” on X, and predicted a Chinese model will soon eclipse it. “Overall very disappointed and I legitimately came open minded to this,” they wrote.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bench-maxxing-on-math-and-coding-at-the-expense-of-writing"&gt;Bench-maxxing on math and coding at the expense of writing?&lt;/h2&gt;



&lt;p&gt;Other criticism focused on the &lt;strong&gt;gpt-oss models’ apparent narrow usefulness. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;AI influencer “Lisan al Gaib (@scaling01)” noted that the models excel at math and coding but “completely lack taste and common sense.” He added, “So it’s just a math model?”&lt;/p&gt;



&lt;p&gt;In creative writing tests, some users found the model injecting equations into poetic outputs. “This is what happens when you benchmarkmax,” Teknium remarked, sharing a screenshot where the model added an integral formula mid-poem.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;And @kalomaze, a researcher at decentralized AI model training company Prime Intellect, wrote that “gpt-oss-120b knows less about the world than what a good 32b does. probably wanted to avoid copyright issues so they likely pretrained on majority synth. pretty devastating stuff”&lt;/p&gt;



&lt;p&gt;Former Googler and independent AI developer Kyle Corbitt agreed that the gpt-oss pair of models seemed to have been trained primarily on synthetic data —  that is, data generated by an AI model specifically for the purposes of training a new one — making it “extremely spiky.”&lt;/p&gt;



&lt;p&gt;It’s “great at the tasks it’s trained on, really bad at everything else,” Corbitt wrote, i.e.,&lt;strong&gt; great on coding and math problems, and bad at more linguistic tasks like creative writing or report generation&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;In other words, the charge is that OpenAI deliberately trained the model on more synthetic data than real world facts and figures to avoid using copyrighted data scraped from websites and other repositories it doesn’t own or have license to use, which is something it and many other leading gen AI companies have been accused of in the past and are facing down ongoing lawsuits as a result of. &lt;/p&gt;



&lt;p&gt;Others speculated OpenAI may have trained the model on primarily synthetic data to avoid safety and security issues, resulting in worse quality than if it had been trained on more real world (and presumably copyrighted) data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-concerning-third-party-benchmark-results"&gt;Concerning third-party benchmark results&lt;/h2&gt;



&lt;p&gt;Moreover, evaluating the models on third-party benchmarking tests have turned up concerning metrics in some users’ eyes.&lt;/p&gt;



&lt;p&gt;SpeechMap — which measures the performance of LLMs in complying with user prompts to generate disallowed, biased, or politically sensitive outputs — showed compliance scores for gpt-oss 120B hovering under 40%,&lt;strong&gt; near the bottom of peer open models,&lt;/strong&gt; which indicates resistance to follow user requests and defaulting to guardrails, potentially at the expense of providing accurate information. &lt;/p&gt;



&lt;p&gt;In Aider’s Polyglot evaluation, &lt;strong&gt;gpt-oss-120B scored just 41.8% in multilingual reasoning—far below competitors like Kimi-K2 (59.1%) and DeepSeek-R1 (56.9%).&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Some users also said their tests indicated the model is oddly resistant to generating criticism of China or Russia, a contrast to its treatment of the US and EU, raising questions about bias and training data filtering.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-other-experts-have-applauded-the-release-and-what-it-signals-for-u-s-open-source-ai"&gt;Other experts have applauded the release and what it signals for U.S. open source AI&lt;/h2&gt;



&lt;p&gt;To be fair, not all the commentary is negative. Software engineer and close AI watcher Simon Willison called the release “really impressive” on X, elaborating in a blog post on &lt;strong&gt;the models’ efficiency and ability to achieve parity with OpenAI’s proprietary o3-mini and o4-mini models.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;He praised their strong performance on reasoning and STEM-heavy benchmarks, and hailed the new “Harmony” prompt template format — which offers developers more structured terms for guiding model responses — and support for third-party tool use as meaningful contributions.&lt;/p&gt;



&lt;p&gt;In a lengthy X post, Clem Delangue, CEO and co-founder of AI code sharing and open source community Hugging Face, encouraged users not to rush to judgment, pointing out that inference for these models is complex, and early issues could be due to infrastructure instability and insufficient optimization among hosting providers. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“The power of open-source is that there’s no cheating,” Delangue wrote.&lt;/strong&gt; “We’ll uncover all the strengths and limitations… progressively.”&lt;/p&gt;



&lt;p&gt;Even more cautious was Wharton School of Business at the University of Pennsylvania professor Ethan Mollick, who wrote on X that “The US now likely has the leading open weights models (or close to it)”, but questioned whether this is a one-off by OpenAI. &lt;strong&gt;“The lead will evaporate quickly as others catch up,”&lt;/strong&gt; he noted, adding that it’s unclear what incentives OpenAI has to keep the models updated.&lt;/p&gt;



&lt;p&gt;Nathan Lambert, a leading AI researcher at the rival open source lab Allen Institute for AI (Ai2) and commentator, praised the symbolic significance of the release on his blog Interconnects, calling it &lt;strong&gt;“a phenomenal step for the open ecosystem, especially for the West and its allies, &lt;/strong&gt;that the most known brand in the AI space has returned to openly releasing models.” &lt;/p&gt;



&lt;p&gt;But he cautioned on X that gpt-oss is &lt;strong&gt;“unlikely to meaningfully slow down [Chinese e-commerce giant Aliaba’s AI team] Qwen,” &lt;/strong&gt;citing its usability, performance, and variety. &lt;/p&gt;



&lt;p&gt;He argued the release marks an important shift in the U.S. toward open models, but that OpenAI still has a “long path back” to catch up in practice.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-split-verdict"&gt;A split verdict&lt;/h2&gt;



&lt;p&gt;The verdict, for now, is split. &lt;/p&gt;



&lt;p&gt;OpenAI’s gpt-oss models are a landmark in terms of licensing and accessibility. &lt;/p&gt;



&lt;p&gt;But while the benchmarks look solid, the real-world “vibes” — as many users describe it — are proving less compelling. &lt;/p&gt;



&lt;p&gt;Whether developers can build strong applications and derivatives on top of gpt-oss will determine whether the release is remembered as a breakthrough or a blip.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-initial-reactions-to-openais-landmark-open-source-gpt-oss-models-are-highly-varied-and-mixed/</guid><pubDate>Wed, 06 Aug 2025 20:24:07 +0000</pubDate></item><item><title>New ‘persona vectors’ from Anthropic let you decode and direct an LLM’s personality (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new study from the Anthropic Fellows Program reveals a technique to identify, monitor and control character traits in large language models (LLMs). The findings show that models can develop undesirable personalities (e.g., becoming malicious, excessively agreeable, or prone to making things up) either in response to user prompts or as an unintended consequence of training.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The researchers introduce “persona vectors,” which are directions in a model’s internal activation space that correspond to specific personality traits, providing a toolkit for developers to manage the behavior of their AI assistants better.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-model-personas-can-go-wrong"&gt;Model personas can go wrong&lt;/h2&gt;



&lt;p&gt;LLMs typically interact with users through an “Assistant” persona designed to be helpful, harmless, and honest. However, these personas can fluctuate in unexpected ways. At deployment, a model’s personality can shift dramatically based on prompts or conversational context, as seen when Microsoft’s Bing chatbot threatened users or xAI’s Grok started behaving erratically. As the researchers note in their paper, “While these particular examples gained widespread public attention, most language models are susceptible to in-context persona shifts.”&lt;/p&gt;



&lt;p&gt;Training procedures can also induce unexpected changes. For instance, fine-tuning a model on a narrow task like generating insecure code can lead to a broader “emergent misalignment” that extends beyond the original task. Even well-intentioned training adjustments can backfire. In April 2025, a modification to the reinforcement learning from human feedback (RLHF) process unintentionally made OpenAI’s GPT-4o overly sycophantic, causing it to validate harmful behaviors.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-how-persona-vectors-work"&gt;How persona vectors work&lt;/h2&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015226" height="449" src="https://venturebeat.com/wp-content/uploads/2025/08/image_4e16ea.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Source: Anthropic&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;The new research builds on the concept that high-level traits, such as truthfulness or secrecy, are encoded as linear directions within a model’s “activation space” (the internal, high-dimensional representation of information embedded within the model’s weights). The researchers systematized the process of finding these directions, which they call “persona vectors.” According to the paper, their method for extracting persona vectors is automated and “can be applied to any personality trait of interest, given only a natural-language description.”&lt;/p&gt;



&lt;p&gt;The process works through an automated pipeline. It begins with a simple description of a trait, such as “evil.” The pipeline then generates pairs of contrasting system prompts (e.g., “You are an evil AI” vs. “You are a helpful AI”) along with a set of evaluation questions. The model generates responses under both the positive and negative prompts. The persona vector is then calculated by taking the difference in the average internal activations between the responses that exhibit the trait and those that do not. This isolates the specific direction in the model’s weights that corresponds to that personality trait.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-putting-persona-vectors-to-use"&gt;Putting persona vectors to use&lt;/h2&gt;



&lt;p&gt;In a series of experiments with open models, such as Qwen 2.5-7B-Instruct and Llama-3.1-8B-Instruct, the researchers demonstrated several practical applications for persona vectors.&lt;/p&gt;



&lt;p&gt;First, by projecting a model’s internal state onto a persona vector, developers can monitor and predict how it will behave before it generates a response. The paper states, “We show that both intended and unintended finetuning-induced persona shifts strongly correlate with activation changes along corresponding persona vectors.” This allows for early detection and mitigation of undesirable behavioral shifts during fine-tuning.&lt;/p&gt;



&lt;p&gt;Persona vectors also allow for direct intervention to curb unwanted behaviors at inference time through a process the researchers call “steering.” One approach is “post-hoc steering,” where developers subtract the persona vector from the model’s activations during inference to mitigate a bad trait. The researchers found that while effective, post-hoc steering can sometimes degrade the model’s performance on other tasks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;A more novel method is “preventative steering,” where the model is proactively steered toward the undesirable persona during fine-tuning. This counterintuitive approach essentially “vaccinates” the model against learning the bad trait from the training data, canceling out the fine-tuning pressure while better preserving its general capabilities.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015227" height="430" src="https://venturebeat.com/wp-content/uploads/2025/08/image_d7158d.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Source: Anthropic&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;A key application for enterprises is using persona vectors to screen data before fine-tuning. The researchers developed a metric called “projection difference,” which measures how much a given training dataset will push the model’s persona toward a particular trait. This metric is highly predictive of how the model’s behavior will shift after training, allowing developers to flag and filter problematic datasets before using them in training.&lt;/p&gt;



&lt;p&gt;For companies that fine-tune open-source models on proprietary or third-party data (including data generated by other models), persona vectors provide a direct way to monitor and mitigate the risk of inheriting hidden, undesirable traits. The ability to screen data proactively is a powerful tool for developers, enabling the identification of problematic samples that may not be immediately apparent as harmful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The research found that this technique can find issues that other methods miss, noting, “This suggests that the method surfaces problematic samples that may evade LLM-based detection.” For example, their method was able to catch some dataset examples that weren’t obviously problematic to the human eye, and that an LLM judge wasn’t able to flag.&lt;/p&gt;



&lt;p&gt;In a blog post, Anthropic suggested that they will use this technique to improve future generations of Claude. “Persona vectors give us some handle on where models acquire these personalities, how they fluctuate over time, and how we can better control them,” they write. Anthropic has released the code for computing persona vectors, monitoring and steering model behavior, and vetting training datasets. Developers of AI applications can utilize these tools to transition from merely reacting to undesirable behavior to proactively designing models with a more stable and predictable personality.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new study from the Anthropic Fellows Program reveals a technique to identify, monitor and control character traits in large language models (LLMs). The findings show that models can develop undesirable personalities (e.g., becoming malicious, excessively agreeable, or prone to making things up) either in response to user prompts or as an unintended consequence of training.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The researchers introduce “persona vectors,” which are directions in a model’s internal activation space that correspond to specific personality traits, providing a toolkit for developers to manage the behavior of their AI assistants better.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-model-personas-can-go-wrong"&gt;Model personas can go wrong&lt;/h2&gt;



&lt;p&gt;LLMs typically interact with users through an “Assistant” persona designed to be helpful, harmless, and honest. However, these personas can fluctuate in unexpected ways. At deployment, a model’s personality can shift dramatically based on prompts or conversational context, as seen when Microsoft’s Bing chatbot threatened users or xAI’s Grok started behaving erratically. As the researchers note in their paper, “While these particular examples gained widespread public attention, most language models are susceptible to in-context persona shifts.”&lt;/p&gt;



&lt;p&gt;Training procedures can also induce unexpected changes. For instance, fine-tuning a model on a narrow task like generating insecure code can lead to a broader “emergent misalignment” that extends beyond the original task. Even well-intentioned training adjustments can backfire. In April 2025, a modification to the reinforcement learning from human feedback (RLHF) process unintentionally made OpenAI’s GPT-4o overly sycophantic, causing it to validate harmful behaviors.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-how-persona-vectors-work"&gt;How persona vectors work&lt;/h2&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015226" height="449" src="https://venturebeat.com/wp-content/uploads/2025/08/image_4e16ea.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Source: Anthropic&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;The new research builds on the concept that high-level traits, such as truthfulness or secrecy, are encoded as linear directions within a model’s “activation space” (the internal, high-dimensional representation of information embedded within the model’s weights). The researchers systematized the process of finding these directions, which they call “persona vectors.” According to the paper, their method for extracting persona vectors is automated and “can be applied to any personality trait of interest, given only a natural-language description.”&lt;/p&gt;



&lt;p&gt;The process works through an automated pipeline. It begins with a simple description of a trait, such as “evil.” The pipeline then generates pairs of contrasting system prompts (e.g., “You are an evil AI” vs. “You are a helpful AI”) along with a set of evaluation questions. The model generates responses under both the positive and negative prompts. The persona vector is then calculated by taking the difference in the average internal activations between the responses that exhibit the trait and those that do not. This isolates the specific direction in the model’s weights that corresponds to that personality trait.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-putting-persona-vectors-to-use"&gt;Putting persona vectors to use&lt;/h2&gt;



&lt;p&gt;In a series of experiments with open models, such as Qwen 2.5-7B-Instruct and Llama-3.1-8B-Instruct, the researchers demonstrated several practical applications for persona vectors.&lt;/p&gt;



&lt;p&gt;First, by projecting a model’s internal state onto a persona vector, developers can monitor and predict how it will behave before it generates a response. The paper states, “We show that both intended and unintended finetuning-induced persona shifts strongly correlate with activation changes along corresponding persona vectors.” This allows for early detection and mitigation of undesirable behavioral shifts during fine-tuning.&lt;/p&gt;



&lt;p&gt;Persona vectors also allow for direct intervention to curb unwanted behaviors at inference time through a process the researchers call “steering.” One approach is “post-hoc steering,” where developers subtract the persona vector from the model’s activations during inference to mitigate a bad trait. The researchers found that while effective, post-hoc steering can sometimes degrade the model’s performance on other tasks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;A more novel method is “preventative steering,” where the model is proactively steered toward the undesirable persona during fine-tuning. This counterintuitive approach essentially “vaccinates” the model against learning the bad trait from the training data, canceling out the fine-tuning pressure while better preserving its general capabilities.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015227" height="430" src="https://venturebeat.com/wp-content/uploads/2025/08/image_d7158d.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Source: Anthropic&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;A key application for enterprises is using persona vectors to screen data before fine-tuning. The researchers developed a metric called “projection difference,” which measures how much a given training dataset will push the model’s persona toward a particular trait. This metric is highly predictive of how the model’s behavior will shift after training, allowing developers to flag and filter problematic datasets before using them in training.&lt;/p&gt;



&lt;p&gt;For companies that fine-tune open-source models on proprietary or third-party data (including data generated by other models), persona vectors provide a direct way to monitor and mitigate the risk of inheriting hidden, undesirable traits. The ability to screen data proactively is a powerful tool for developers, enabling the identification of problematic samples that may not be immediately apparent as harmful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The research found that this technique can find issues that other methods miss, noting, “This suggests that the method surfaces problematic samples that may evade LLM-based detection.” For example, their method was able to catch some dataset examples that weren’t obviously problematic to the human eye, and that an LLM judge wasn’t able to flag.&lt;/p&gt;



&lt;p&gt;In a blog post, Anthropic suggested that they will use this technique to improve future generations of Claude. “Persona vectors give us some handle on where models acquire these personalities, how they fluctuate over time, and how we can better control them,” they write. Anthropic has released the code for computing persona vectors, monitoring and steering model behavior, and vetting training datasets. Developers of AI applications can utilize these tools to transition from merely reacting to undesirable behavior to proactively designing models with a more stable and predictable personality.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/</guid><pubDate>Wed, 06 Aug 2025 22:11:20 +0000</pubDate></item><item><title>[NEW] Eco-driving measures could significantly reduce vehicle emissions (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/eco-driving-measures-could-significantly-reduce-vehicle-emissions-0807</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Any motorist who has ever waited through multiple cycles for a traffic light to turn green knows how annoying signalized intersections can be. But sitting at intersections isn’t just a drag on drivers’ patience — unproductive vehicle idling could contribute as much as 15 percent of the carbon dioxide emissions from U.S. land transportation.&lt;/p&gt;&lt;p&gt;A large-scale modeling study led by MIT researchers reveals that eco-driving measures, which can involve dynamically adjusting vehicle speeds to reduce stopping and excessive acceleration, could significantly reduce those CO&lt;sub&gt;2&lt;/sub&gt; emissions.&lt;/p&gt;&lt;p&gt;Using a powerful artificial intelligence method called deep reinforcement learning, the researchers conducted an in-depth impact assessment of the factors affecting vehicle emissions in three major U.S. cities.&lt;/p&gt;&lt;p&gt;Their analysis indicates that fully adopting eco-driving measures could cut annual city-wide intersection carbon emissions by 11 to 22 percent, without slowing traffic throughput or affecting vehicle and traffic safety.&lt;/p&gt;&lt;p&gt;Even if only 10 percent of vehicles on the road employ eco-driving, it would result in 25 to 50 percent of the total reduction in CO2 emissions, the researchers found.&lt;/p&gt;&lt;p&gt;In addition, dynamically optimizing speed limits at about 20 percent of intersections provides 70 percent of the total emission benefits. This indicates that eco-driving measures could be implemented gradually while still having measurable, positive impacts on mitigating climate change and improving public health.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;figure class="align-center"&gt;
&lt;img alt="Two intersections with lots of cars; the 100% adoption has less traffic." height="333" src="https://news.mit.edu/sites/default/files/images/inline/eco-driving.gif" width="521" /&gt;
&lt;figcaption&gt;An animated GIF compares what 20% eco-driving adoption looks like to 100% eco-driving adoption.&lt;p&gt;Image: Courtesy of the researchers&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“Vehicle-based control strategies like eco-driving can move the needle on climate change reduction. We’ve shown here that modern machine-learning tools, like deep reinforcement learning, can accelerate the kinds of analysis that support sociotechnical decision making. This is just the tip of the iceberg,” says senior author Cathy Wu, the Thomas D. and Virginia W. Cabot Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS) at MIT, and a member of the Laboratory for Information and Decision Systems (LIDS).&lt;/p&gt;&lt;p&gt;She is joined on the paper by lead author Vindula Jayawardana, an MIT graduate student; as well as MIT graduate students Ao Qu, Cameron Hickert, and Edgar Sanchez; MIT undergraduate Catherine Tang; Baptiste Freydt, a graduate student at ETH Zurich; and Mark Taylor and Blaine Leonard of the Utah Department of Transportation. The research appears in &lt;em&gt;Transportation Research Part C: Emerging Technologies&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A multi-part modeling study&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Traffic control measures typically call to mind fixed infrastructure, like stop signs and traffic signals. But as vehicles become more technologically advanced, it presents an opportunity for eco-driving, which is a catch-all term for vehicle-based traffic control measures like the use of dynamic speeds to reduce energy consumption.&lt;/p&gt;&lt;p&gt;In the near term, eco-driving could involve speed guidance in the form of vehicle dashboards or smartphone apps. In the longer term, eco-driving could involve intelligent speed commands that directly control the acceleration of semi-autonomous and fully autonomous vehicles through vehicle-to-infrastructure communication systems.&lt;/p&gt;&lt;p&gt;“Most prior work has focused on how&lt;em&gt;&amp;nbsp;&lt;/em&gt;to implement eco-driving. We shifted the frame to consider the question of should&lt;em&gt;&amp;nbsp;&lt;/em&gt;we implement eco-driving. If we were to deploy this technology at scale, would it make a difference?” Wu says.&lt;/p&gt;&lt;p&gt;To answer that question, the researchers embarked on a multifaceted modeling study that would take the better part of four years to complete.&lt;/p&gt;&lt;p&gt;They began by identifying 33 factors that influence vehicle emissions, including temperature, road grade, intersection topology, age of the vehicle, traffic demand, vehicle types, driver behavior, traffic signal timing, road geometry, etc.&lt;/p&gt;&lt;p&gt;“One of the biggest challenges was making sure we were diligent and didn’t leave out any major factors,” Wu says.&lt;/p&gt;&lt;p&gt;Then they used data from open street maps, U.S. geological surveys, and other sources to create digital replicas of more than 6,000 signalized intersections in three cities — Atlanta, San Francisco, and Los Angeles — and simulated more than a million traffic scenarios.&lt;/p&gt;&lt;p&gt;The researchers used deep reinforcement learning to optimize each scenario for eco-driving to achieve the maximum emissions benefits.&lt;/p&gt;&lt;p&gt;Reinforcement learning optimizes the vehicles’ driving behavior through trial-and-error interactions with a high-fidelity traffic simulator, rewarding vehicle behaviors that are more energy-efficient while penalizing those that are not.&lt;/p&gt;&lt;p&gt;However, training vehicle behaviors that generalize across diverse intersection traffic scenarios was a major challenge. The researchers observed that some scenarios are more similar to one another than others, such as scenarios with the same number of lanes or the same number of traffic signal phases.&lt;/p&gt;&lt;p&gt;As such, the researchers trained separate reinforcement learning models for different clusters of traffic scenarios, yielding better emission benefits overall.&lt;/p&gt;&lt;p&gt;But even with the help of AI, analyzing citywide traffic at the network level would be so computationally intensive it could take another decade to unravel, Wu says.&lt;/p&gt;&lt;p&gt;Instead, they broke the problem down and solved each eco-driving scenario at the individual intersection level.&lt;/p&gt;&lt;p&gt;“We carefully constrained the impact of eco-driving control at each intersection on neighboring intersections. In this way, we dramatically simplified the problem, which enabled us to perform this analysis at scale, without introducing unknown network effects,” she says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Significant emissions benefits&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When they analyzed the results, the researchers found that full adoption of eco-driving could result in intersection emissions reductions of between 11 and 22 percent.&lt;/p&gt;&lt;p&gt;These benefits differ depending on the layout of a city’s streets. A denser city like San Francisco has less room to implement eco-driving between intersections, offering a possible explanation for reduced emission savings, while Atlanta could see greater benefits given its higher speed limits.&lt;/p&gt;&lt;p&gt;Even if only 10 percent of vehicles employ eco-driving, a city could still realize 25 to 50 percent of the total emissions benefit because of car-following dynamics: Non-eco-driving vehicles would follow controlled eco-driving vehicles as they optimize speed to pass smoothly through intersections, reducing their carbon emissions as well.&lt;/p&gt;&lt;p&gt;In some cases, eco-driving could also increase vehicle throughput by minimizing emissions. However, Wu cautions that increasing throughput could result in more drivers taking to the roads, reducing emissions benefits.&lt;/p&gt;&lt;p&gt;And while their analysis of widely used safety metrics known as surrogate safety measures, such as time to collision, suggest that eco-driving is as safe as human driving, it could cause unexpected behavior in human drivers. More research is needed to fully understand potential safety impacts, Wu says.&lt;/p&gt;&lt;p&gt;Their results also show that eco-driving could provide even greater benefits when combined with alternative transportation decarbonization solutions. For instance, 20 percent eco-driving adoption in San Francisco would cut emission levels by 7 percent, but when combined with the projected adoption of hybrid and electric vehicles, it would cut emissions by 17 percent.&lt;/p&gt;&lt;p&gt;“This is a first attempt to systematically quantify network-wide environmental benefits of eco-driving. This is a great research effort that will serve as a key reference for others to build on in the assessment of eco-driving systems,” says Hesham Rakha, the Samuel L. Pritchard Professor of Engineering at Virginia Tech, who was not involved with this research.&lt;/p&gt;&lt;p&gt;And while the researchers focus on carbon emissions, the benefits are highly correlated with improvements in fuel consumption, energy use, and air quality.&lt;/p&gt;&lt;p&gt;“This is almost a free intervention. We already have smartphones in our cars, and we are rapidly adopting cars with more advanced automation features. For something to scale quickly in practice, it must be relatively simple to implement and shovel-ready. Eco-driving fits that bill,” Wu says.&lt;/p&gt;&lt;p&gt;This work is funded, in part, by Amazon and the Utah Department of Transportation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Any motorist who has ever waited through multiple cycles for a traffic light to turn green knows how annoying signalized intersections can be. But sitting at intersections isn’t just a drag on drivers’ patience — unproductive vehicle idling could contribute as much as 15 percent of the carbon dioxide emissions from U.S. land transportation.&lt;/p&gt;&lt;p&gt;A large-scale modeling study led by MIT researchers reveals that eco-driving measures, which can involve dynamically adjusting vehicle speeds to reduce stopping and excessive acceleration, could significantly reduce those CO&lt;sub&gt;2&lt;/sub&gt; emissions.&lt;/p&gt;&lt;p&gt;Using a powerful artificial intelligence method called deep reinforcement learning, the researchers conducted an in-depth impact assessment of the factors affecting vehicle emissions in three major U.S. cities.&lt;/p&gt;&lt;p&gt;Their analysis indicates that fully adopting eco-driving measures could cut annual city-wide intersection carbon emissions by 11 to 22 percent, without slowing traffic throughput or affecting vehicle and traffic safety.&lt;/p&gt;&lt;p&gt;Even if only 10 percent of vehicles on the road employ eco-driving, it would result in 25 to 50 percent of the total reduction in CO2 emissions, the researchers found.&lt;/p&gt;&lt;p&gt;In addition, dynamically optimizing speed limits at about 20 percent of intersections provides 70 percent of the total emission benefits. This indicates that eco-driving measures could be implemented gradually while still having measurable, positive impacts on mitigating climate change and improving public health.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;figure class="align-center"&gt;
&lt;img alt="Two intersections with lots of cars; the 100% adoption has less traffic." height="333" src="https://news.mit.edu/sites/default/files/images/inline/eco-driving.gif" width="521" /&gt;
&lt;figcaption&gt;An animated GIF compares what 20% eco-driving adoption looks like to 100% eco-driving adoption.&lt;p&gt;Image: Courtesy of the researchers&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“Vehicle-based control strategies like eco-driving can move the needle on climate change reduction. We’ve shown here that modern machine-learning tools, like deep reinforcement learning, can accelerate the kinds of analysis that support sociotechnical decision making. This is just the tip of the iceberg,” says senior author Cathy Wu, the Thomas D. and Virginia W. Cabot Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS) at MIT, and a member of the Laboratory for Information and Decision Systems (LIDS).&lt;/p&gt;&lt;p&gt;She is joined on the paper by lead author Vindula Jayawardana, an MIT graduate student; as well as MIT graduate students Ao Qu, Cameron Hickert, and Edgar Sanchez; MIT undergraduate Catherine Tang; Baptiste Freydt, a graduate student at ETH Zurich; and Mark Taylor and Blaine Leonard of the Utah Department of Transportation. The research appears in &lt;em&gt;Transportation Research Part C: Emerging Technologies&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A multi-part modeling study&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Traffic control measures typically call to mind fixed infrastructure, like stop signs and traffic signals. But as vehicles become more technologically advanced, it presents an opportunity for eco-driving, which is a catch-all term for vehicle-based traffic control measures like the use of dynamic speeds to reduce energy consumption.&lt;/p&gt;&lt;p&gt;In the near term, eco-driving could involve speed guidance in the form of vehicle dashboards or smartphone apps. In the longer term, eco-driving could involve intelligent speed commands that directly control the acceleration of semi-autonomous and fully autonomous vehicles through vehicle-to-infrastructure communication systems.&lt;/p&gt;&lt;p&gt;“Most prior work has focused on how&lt;em&gt;&amp;nbsp;&lt;/em&gt;to implement eco-driving. We shifted the frame to consider the question of should&lt;em&gt;&amp;nbsp;&lt;/em&gt;we implement eco-driving. If we were to deploy this technology at scale, would it make a difference?” Wu says.&lt;/p&gt;&lt;p&gt;To answer that question, the researchers embarked on a multifaceted modeling study that would take the better part of four years to complete.&lt;/p&gt;&lt;p&gt;They began by identifying 33 factors that influence vehicle emissions, including temperature, road grade, intersection topology, age of the vehicle, traffic demand, vehicle types, driver behavior, traffic signal timing, road geometry, etc.&lt;/p&gt;&lt;p&gt;“One of the biggest challenges was making sure we were diligent and didn’t leave out any major factors,” Wu says.&lt;/p&gt;&lt;p&gt;Then they used data from open street maps, U.S. geological surveys, and other sources to create digital replicas of more than 6,000 signalized intersections in three cities — Atlanta, San Francisco, and Los Angeles — and simulated more than a million traffic scenarios.&lt;/p&gt;&lt;p&gt;The researchers used deep reinforcement learning to optimize each scenario for eco-driving to achieve the maximum emissions benefits.&lt;/p&gt;&lt;p&gt;Reinforcement learning optimizes the vehicles’ driving behavior through trial-and-error interactions with a high-fidelity traffic simulator, rewarding vehicle behaviors that are more energy-efficient while penalizing those that are not.&lt;/p&gt;&lt;p&gt;However, training vehicle behaviors that generalize across diverse intersection traffic scenarios was a major challenge. The researchers observed that some scenarios are more similar to one another than others, such as scenarios with the same number of lanes or the same number of traffic signal phases.&lt;/p&gt;&lt;p&gt;As such, the researchers trained separate reinforcement learning models for different clusters of traffic scenarios, yielding better emission benefits overall.&lt;/p&gt;&lt;p&gt;But even with the help of AI, analyzing citywide traffic at the network level would be so computationally intensive it could take another decade to unravel, Wu says.&lt;/p&gt;&lt;p&gt;Instead, they broke the problem down and solved each eco-driving scenario at the individual intersection level.&lt;/p&gt;&lt;p&gt;“We carefully constrained the impact of eco-driving control at each intersection on neighboring intersections. In this way, we dramatically simplified the problem, which enabled us to perform this analysis at scale, without introducing unknown network effects,” she says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Significant emissions benefits&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When they analyzed the results, the researchers found that full adoption of eco-driving could result in intersection emissions reductions of between 11 and 22 percent.&lt;/p&gt;&lt;p&gt;These benefits differ depending on the layout of a city’s streets. A denser city like San Francisco has less room to implement eco-driving between intersections, offering a possible explanation for reduced emission savings, while Atlanta could see greater benefits given its higher speed limits.&lt;/p&gt;&lt;p&gt;Even if only 10 percent of vehicles employ eco-driving, a city could still realize 25 to 50 percent of the total emissions benefit because of car-following dynamics: Non-eco-driving vehicles would follow controlled eco-driving vehicles as they optimize speed to pass smoothly through intersections, reducing their carbon emissions as well.&lt;/p&gt;&lt;p&gt;In some cases, eco-driving could also increase vehicle throughput by minimizing emissions. However, Wu cautions that increasing throughput could result in more drivers taking to the roads, reducing emissions benefits.&lt;/p&gt;&lt;p&gt;And while their analysis of widely used safety metrics known as surrogate safety measures, such as time to collision, suggest that eco-driving is as safe as human driving, it could cause unexpected behavior in human drivers. More research is needed to fully understand potential safety impacts, Wu says.&lt;/p&gt;&lt;p&gt;Their results also show that eco-driving could provide even greater benefits when combined with alternative transportation decarbonization solutions. For instance, 20 percent eco-driving adoption in San Francisco would cut emission levels by 7 percent, but when combined with the projected adoption of hybrid and electric vehicles, it would cut emissions by 17 percent.&lt;/p&gt;&lt;p&gt;“This is a first attempt to systematically quantify network-wide environmental benefits of eco-driving. This is a great research effort that will serve as a key reference for others to build on in the assessment of eco-driving systems,” says Hesham Rakha, the Samuel L. Pritchard Professor of Engineering at Virginia Tech, who was not involved with this research.&lt;/p&gt;&lt;p&gt;And while the researchers focus on carbon emissions, the benefits are highly correlated with improvements in fuel consumption, energy use, and air quality.&lt;/p&gt;&lt;p&gt;“This is almost a free intervention. We already have smartphones in our cars, and we are rapidly adopting cars with more advanced automation features. For something to scale quickly in practice, it must be relatively simple to implement and shovel-ready. Eco-driving fits that bill,” Wu says.&lt;/p&gt;&lt;p&gt;This work is funded, in part, by Amazon and the Utah Department of Transportation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/eco-driving-measures-could-significantly-reduce-vehicle-emissions-0807</guid><pubDate>Thu, 07 Aug 2025 04:00:00 +0000</pubDate></item></channel></rss>