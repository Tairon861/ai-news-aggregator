<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 23 Jan 2026 06:39:12 +0000</lastBuildDate><item><title>Humans&amp; thinks coordination is the next frontier for AI, and they’re building a model to prove it (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They’re not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a “central nervous system” for the human-plus-AI economy. The startup’s “AI for empowering humans” framing has dominated early coverage, but the company’s actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It feels like we’re ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we’re entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,” Andi Peng, one of Humans&amp;amp;’s co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;’s pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that’s just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren’t, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn’t have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are building a product and a model that is centered on communication and collaboration,” Eric Zelikman, co-founder and CEO of Humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively — both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they’d like,” Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they’ve been optimized for two things: How much a user immediately likes a response they’re given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that Humans&amp;amp; doesn’t exactly have an answer for that yet. Peng said Humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Part of what we’re doing here is also making sure that as the model improves, we’re able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,” she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that Humans&amp;amp; isn’t trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field — for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work — that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI lives at the workflow level, and the people closest to the work know where the friction actually is,” Hoffman wrote on social media. “They’re the ones who will discover what should be automated, compressed, or totally redesigned.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the space where Humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the “connective tissue” across any organization — be it a 10,000-person business or a family — that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,” Yuchen He, a Humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup’s model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The model needs to remember things about itself, about you, and the better its memory, the better its user understanding,” He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that Humans&amp;amp; isn’t just competing with the Notions and Slacks of the world. It’s coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives Humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,” Zelikman said. “We trust ourselves to do that, and we have a lot of faith in the team that we’ve assembled here.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They’re not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a “central nervous system” for the human-plus-AI economy. The startup’s “AI for empowering humans” framing has dominated early coverage, but the company’s actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It feels like we’re ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we’re entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,” Andi Peng, one of Humans&amp;amp;’s co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;’s pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that’s just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren’t, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn’t have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are building a product and a model that is centered on communication and collaboration,” Eric Zelikman, co-founder and CEO of Humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively — both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they’d like,” Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they’ve been optimized for two things: How much a user immediately likes a response they’re given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that Humans&amp;amp; doesn’t exactly have an answer for that yet. Peng said Humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Part of what we’re doing here is also making sure that as the model improves, we’re able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,” she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that Humans&amp;amp; isn’t trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field — for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work — that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI lives at the workflow level, and the people closest to the work know where the friction actually is,” Hoffman wrote on social media. “They’re the ones who will discover what should be automated, compressed, or totally redesigned.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the space where Humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the “connective tissue” across any organization — be it a 10,000-person business or a family — that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,” Yuchen He, a Humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup’s model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The model needs to remember things about itself, about you, and the better its memory, the better its user understanding,” He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that Humans&amp;amp; isn’t just competing with the Notions and Slacks of the world. It’s coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives Humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,” Zelikman said. “We trust ourselves to do that, and we have a lot of faith in the team that we’ve assembled here.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</guid><pubDate>Thu, 22 Jan 2026 19:24:13 +0000</pubDate></item><item><title>Google DeepMind CEO is ‘surprised’ OpenAI is rushing forward with ads in ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/google-deepmind-ceo-is-surprised-openai-is-rushing-forward-with-ads-in-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/videoframe_271754.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind CEO Demis Hassabis said he’s “surprised” that OpenAI has already moved to introduce ads within its AI chatbot. In an interview with Axios at Davos, the AI leader was responding to a question about using ads to monetize AI services, saying the idea is something that the team at Google was thinking through “very carefully.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis also said that his team wasn’t feeling pressure from the tech giant to make “a knee-jerk” decision around advertising, despite how key ads are to Google’s core business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The DeepMind co-founder’s remarks followed Friday’s news that OpenAI will begin &lt;span&gt;testing ads&amp;nbsp;as a way to generate&lt;/span&gt; additional revenue from the portion of the AI chatbot’s 800 million weekly active users who don’t have a paid subscription. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI may have been forced to consider ads, considering its growing infrastructure and energy costs, its decision could change how users view the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m a little bit surprised they’ve moved so early into that,” Hassabis said, referring to OpenAI’s adoption of ads. “I mean, look, ads, there’s nothing wrong with ads…they funded much of the consumer internet. And if done well, they can be useful,” he clarified.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But in the realm of assistants, and if you think of the chatbot as an assistant that’s meant to be helpful — and ideally, in my mind, as they become more powerful, the kind of technology that works for you as the individual…there is a question about how ads fit into that model?… You want to have trust in your assistant, so how does that work?” he questioned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reiterating some early comments from another Davos interview, Hassabis also said that Google didn’t have “any current plans” to do ads in its AI chatbot. Instead, the company would monitor the situation to see how users respond.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, we’ve already seen consumer backlash to the idea of ads infiltrating people’s conversations with AI assistants. When OpenAI last month began exploring a feature that suggested apps to try during users’ chats, for instance, people reacted negatively, saying these suggestions felt like intrusive ads. Shortly after, OpenAI turned off the app suggestions, which it claimed were not actually ads as they had “no financial component.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But whether or not money had exchanged hands was not what made users angry. Rather, it was how the app suggestions degraded the quality of the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s something that also concerns Hassabis, his remarks suggested. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He explained that using a chatbot is a much different experience than using Google Search. With Search, Google already understands a user’s intent, so it can show potentially useful ads. Chatbots, on the other hand, are meant to become helpful digital assistants that know about you and can help you with many aspects of your life, he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s very different from the search use case. So I think there, that has to be thought through very carefully,” he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Making Gemini more useful to each user is also the focus of&lt;span&gt;&amp;nbsp;&lt;/span&gt;newly launched personalization features announced today for Google’s AI Mode. Now, users can opt into having Gemini’s AI tap into their Gmail and Photos for tailored responses in Search’s AI Mode, similar to how Gemini’s app just added a Personal Intelligence feature that can reference users’ Gmail, Photos, Search, and YouTube history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While personalized ad targeting is a business that sustains the free web, pushing an ad on the user while they’re in a conversation with an AI assistant can feel off-putting. It’s why customers rejected Amazon’s earlier attempts to infuse ads into its Alexa experience — they wanted an assistant, not a personal shopper hawking things for them to buy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis said he wasn’t feeling top-down pressure to force ads into the AI product, either, though he admitted there may be a way to do them right later on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t feel any immediate pressure to make knee-jerk decisions like that — I think that’s been the history of what we’ve done at DeepMind — is be very scientific, and rigorous, and thoughtful about each step that we take — be that the technology itself or the product,” he noted.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/videoframe_271754.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind CEO Demis Hassabis said he’s “surprised” that OpenAI has already moved to introduce ads within its AI chatbot. In an interview with Axios at Davos, the AI leader was responding to a question about using ads to monetize AI services, saying the idea is something that the team at Google was thinking through “very carefully.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis also said that his team wasn’t feeling pressure from the tech giant to make “a knee-jerk” decision around advertising, despite how key ads are to Google’s core business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The DeepMind co-founder’s remarks followed Friday’s news that OpenAI will begin &lt;span&gt;testing ads&amp;nbsp;as a way to generate&lt;/span&gt; additional revenue from the portion of the AI chatbot’s 800 million weekly active users who don’t have a paid subscription. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI may have been forced to consider ads, considering its growing infrastructure and energy costs, its decision could change how users view the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m a little bit surprised they’ve moved so early into that,” Hassabis said, referring to OpenAI’s adoption of ads. “I mean, look, ads, there’s nothing wrong with ads…they funded much of the consumer internet. And if done well, they can be useful,” he clarified.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But in the realm of assistants, and if you think of the chatbot as an assistant that’s meant to be helpful — and ideally, in my mind, as they become more powerful, the kind of technology that works for you as the individual…there is a question about how ads fit into that model?… You want to have trust in your assistant, so how does that work?” he questioned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reiterating some early comments from another Davos interview, Hassabis also said that Google didn’t have “any current plans” to do ads in its AI chatbot. Instead, the company would monitor the situation to see how users respond.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, we’ve already seen consumer backlash to the idea of ads infiltrating people’s conversations with AI assistants. When OpenAI last month began exploring a feature that suggested apps to try during users’ chats, for instance, people reacted negatively, saying these suggestions felt like intrusive ads. Shortly after, OpenAI turned off the app suggestions, which it claimed were not actually ads as they had “no financial component.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But whether or not money had exchanged hands was not what made users angry. Rather, it was how the app suggestions degraded the quality of the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s something that also concerns Hassabis, his remarks suggested. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He explained that using a chatbot is a much different experience than using Google Search. With Search, Google already understands a user’s intent, so it can show potentially useful ads. Chatbots, on the other hand, are meant to become helpful digital assistants that know about you and can help you with many aspects of your life, he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s very different from the search use case. So I think there, that has to be thought through very carefully,” he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Making Gemini more useful to each user is also the focus of&lt;span&gt;&amp;nbsp;&lt;/span&gt;newly launched personalization features announced today for Google’s AI Mode. Now, users can opt into having Gemini’s AI tap into their Gmail and Photos for tailored responses in Search’s AI Mode, similar to how Gemini’s app just added a Personal Intelligence feature that can reference users’ Gmail, Photos, Search, and YouTube history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While personalized ad targeting is a business that sustains the free web, pushing an ad on the user while they’re in a conversation with an AI assistant can feel off-putting. It’s why customers rejected Amazon’s earlier attempts to infuse ads into its Alexa experience — they wanted an assistant, not a personal shopper hawking things for them to buy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis said he wasn’t feeling top-down pressure to force ads into the AI product, either, though he admitted there may be a way to do them right later on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t feel any immediate pressure to make knee-jerk decisions like that — I think that’s been the history of what we’ve done at DeepMind — is be very scientific, and rigorous, and thoughtful about each step that we take — be that the technology itself or the product,” he noted.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/google-deepmind-ceo-is-surprised-openai-is-rushing-forward-with-ads-in-chatgpt/</guid><pubDate>Thu, 22 Jan 2026 19:41:01 +0000</pubDate></item><item><title>Google begins offering free SAT practice tests powered by Gemini (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/google-begins-offering-free-sat-practice-tests-powered-by-gemini/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says more kinds of standardized tests will be added in the future.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It’s no secret that students worldwide use AI chatbots to do their homework and avoid learning things. On the flip side, students can also use AI as a tool to beef up their knowledge and plan for the future with flashcards or study guides. Google hopes its latest Gemini feature will help with the latter. The company has announced that Gemini can now create free SAT practice tests and coach students to help them get higher scores.&lt;/p&gt;
&lt;p&gt;As a standardized test, the content of the SAT follows a predictable pattern. So there’s no need to use a lengthy, personalized prompt to get Gemini going. Just say something like, “I want to take a practice SAT test,” and the chatbot will generate one complete with clickable buttons, graphs, and score analysis.&lt;/p&gt;
&lt;p&gt;Of course, generative AI can go off the rails and provide incorrect information, which is a problem when you’re trying to learn things. However, Google says it has worked with education firms like The Princeton Review to ensure the AI-generated tests resemble what students will see in the real deal.&lt;/p&gt;
&lt;p&gt;The interface for Gemini’s practice tests includes scoring and the ability to review previous answers. If you are unclear on why a particular answer is right or wrong, the questions have an “Explain answer” button right at the bottom. After you finish the practice exam, the custom interface (which looks a bit like Gemini’s Canvas coding tool) can help you follow up on areas that need improvement.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While the SAT is the most widely used test in US college admissions, it’s not the only one. Google is starting with the SAT but says it plans to support other tests in the future. It does not specify if future tests will be US-centric or if they could branch out to other regions.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2136940-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Practice-SAT-in-Gemini.mp4?_=1" type="video/mp4" /&gt;Practice SAT in Gemini&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Practice SAT in Gemini

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Currently, SAT prep courses and tutoring are a big business. Practice tests and books can cost several hundred dollars, and a one-on-one tutor can run into the thousands. Overall, Americans spend billions of dollars every year on these products and services in hopes of giving their kids a leg up in college admissions.&lt;/p&gt;
&lt;p&gt;AI is already making a dent in the industry—even without a dedicated test prep mode, students regularly use chatbots for tutoring, hallucinations be damned. The addition of this feature to Gemini for all users will likely accelerate declines in test prep and tutoring services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says more kinds of standardized tests will be added in the future.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It’s no secret that students worldwide use AI chatbots to do their homework and avoid learning things. On the flip side, students can also use AI as a tool to beef up their knowledge and plan for the future with flashcards or study guides. Google hopes its latest Gemini feature will help with the latter. The company has announced that Gemini can now create free SAT practice tests and coach students to help them get higher scores.&lt;/p&gt;
&lt;p&gt;As a standardized test, the content of the SAT follows a predictable pattern. So there’s no need to use a lengthy, personalized prompt to get Gemini going. Just say something like, “I want to take a practice SAT test,” and the chatbot will generate one complete with clickable buttons, graphs, and score analysis.&lt;/p&gt;
&lt;p&gt;Of course, generative AI can go off the rails and provide incorrect information, which is a problem when you’re trying to learn things. However, Google says it has worked with education firms like The Princeton Review to ensure the AI-generated tests resemble what students will see in the real deal.&lt;/p&gt;
&lt;p&gt;The interface for Gemini’s practice tests includes scoring and the ability to review previous answers. If you are unclear on why a particular answer is right or wrong, the questions have an “Explain answer” button right at the bottom. After you finish the practice exam, the custom interface (which looks a bit like Gemini’s Canvas coding tool) can help you follow up on areas that need improvement.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While the SAT is the most widely used test in US college admissions, it’s not the only one. Google is starting with the SAT but says it plans to support other tests in the future. It does not specify if future tests will be US-centric or if they could branch out to other regions.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2136940-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Practice-SAT-in-Gemini.mp4?_=1" type="video/mp4" /&gt;Practice SAT in Gemini&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Practice SAT in Gemini

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Currently, SAT prep courses and tutoring are a big business. Practice tests and books can cost several hundred dollars, and a one-on-one tutor can run into the thousands. Overall, Americans spend billions of dollars every year on these products and services in hopes of giving their kids a leg up in college admissions.&lt;/p&gt;
&lt;p&gt;AI is already making a dent in the industry—even without a dedicated test prep mode, students regularly use chatbots for tutoring, hallucinations be damned. The addition of this feature to Gemini for all users will likely accelerate declines in test prep and tutoring services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/google-begins-offering-free-sat-practice-tests-powered-by-gemini/</guid><pubDate>Thu, 22 Jan 2026 20:46:10 +0000</pubDate></item><item><title>Asking Grok to delete fake nudes may force victims to sue in Musk's chosen court (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/asking-grok-to-delete-fake-nudes-may-force-victims-to-sue-in-musks-chosen-court/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Millions likely harmed by Grok-edited sex images as X advertisers shrugged.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A post by Elon Musk on the X app, showing an AI prompt-created image, made with xAI's Grok app, depicting Musk wearing a bikini.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Journalists and advocates have been trying to grasp how many victims in total were harmed by Grok’s nudifying scandal after xAI delayed restricting outputs and app stores refused to cut off access for days.&lt;/p&gt;
&lt;p&gt;The latest estimates show that perhaps millions were harmed in the days immediately after Elon Musk promoted Grok’s undressing feature on his own X feed by posting a pic of himself in a bikini.&lt;/p&gt;
&lt;p&gt;Over just 11 days after Musk’s post, Grok sexualized more than 3 million images, of which 23,000 were of children, the Center for Countering Digital Hate (CCDH) estimated in research published Thursday.&lt;/p&gt;
&lt;p&gt;That figure may be inflated, since CCDH did not analyze prompts and could not determine if images were already sexual prior to Grok’s editing. However, The New York Times shared the CCDH report alongside its own analysis, conservatively estimating that about 41 percent (1.8 million) of 4.4 million images Grok generated between December 31 and January 8 sexualized men, women, and children.&lt;/p&gt;
&lt;p&gt;For xAI and X, the scandal brought scrutiny, but it also helped spike X engagement at a time when Meta’s rival app, Threads, has begun inching ahead of X in daily usage by mobile device users, TechCrunch reported. Without mentioning Grok, X’s head of product, Nikita Bier, celebrated the “highest engagement days on X” in an X post on January 6, just days before X finally started restricting some of Grok’s outputs for free users.&lt;/p&gt;
&lt;p&gt;Whether or not xAI intended the Grok scandal to surge X and Grok use, that appears to be the outcome. The Times charted Grok trends and found that in the nine days prior to Musk’s post, combined, Grok was only used about 300,000 times to generate images, but after Musk’s post, “the number of images created by Grok surged to nearly 600,000 per day” on X.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an article declaring that “Elon Musk cannot get away with this,” writers for The Atlantic suggested that X users “appeared to be imitating and showing off to one another,” believing that using Grok to create revenge porn “can make you famous.”&lt;/p&gt;
&lt;p&gt;X has previously warned that X users who generate illegal content risk permanent suspensions, but X has not confirmed if any users have been banned since public outcry over Grok’s outputs began. Ars asked and will update this post if X provides any response.&lt;/p&gt;
&lt;h2&gt;xAI fights victim who begged Grok to remove images&lt;/h2&gt;
&lt;p&gt;At first, X only limited Grok’s image editing for some free users, which The Atlantic noted made it seem like X was “essentially marketing nonconsensual sexual images as a paid feature of the platform.”&lt;/p&gt;
&lt;p&gt;But then, on January 14, X took its strongest action to restrict Grok’s harmful outputs—blocking outputs prompted by both free and paid X users. That move came after several countries, perhaps most notably the United Kingdom, and at least one state, California, launched probes.&lt;/p&gt;
&lt;p&gt;Crucially, X’s updates did not apply to the Grok app or website; however, it can reportedly still be used to generate nonconsensual images.&lt;/p&gt;
&lt;p&gt;That’s a problem for victims targeted by X users, according to Carrie Goldberg, a lawyer representing Ashley St. Clair, one of the first Grok victims to sue xAI; St. Clair also happens to be the mother of one of Musk’s children.&lt;/p&gt;
&lt;p&gt;Goldberg told Ars that victims like St. Clair want changes on all Grok platforms, not just X. But it’s not easy to “compel that kind of product change in a lawsuit,” Goldberg said. That’s why St. Clair is hoping the court will agree that Grok is a public nuisance, a claim that provides some injunctive relief to prevent broader social harms if she wins.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, St. Clair is seeking a temporary injunction that would block Grok from generating harmful images of her. But before she can get that order, if she wants a fair shot at winning the case, St. Clair must fight an xAI push counter-suing her and trying to move her lawsuit into Musk’s preferred Texas court, a recent court filing suggests.&lt;/p&gt;
&lt;p&gt;In that fight, xAI is arguing that St. Clair is bound by xAI’s terms of service, which were updated the day after she notified the company of her intent to sue.&lt;/p&gt;
&lt;p&gt;Alarmingly, xAI argued that St. Clair effectively agreed to the TOS when she started prompting Grok to delete her nonconsensual images—which is the only way X users had to get images removed quickly, St. Clair alleged. It seems xAI is hoping to turn moments of desperation, where victims beg Grok to remove images, into a legal shield.&lt;/p&gt;
&lt;p&gt;In the filing, Goldberg wrote that St. Clair’s lawsuit has nothing to do with her own use of Grok, noting that the harassing images could have been made even if she never used any of xAI’s products. For that reason alone, xAI should not be able to force a change in venue.&lt;/p&gt;
&lt;p&gt;Further, St. Clair’s use of Grok was clearly under duress, Goldberg argued, noting that one of the photos that Grok edited showed St. Clair’s toddler’s backpack.&lt;/p&gt;
&lt;p&gt;“REMOVE IT!!!” St. Clair asked Grok, allegedly feeling increasingly vulnerable every second the images remained online.&lt;/p&gt;
&lt;p&gt;Goldberg wrote that Barry Murphy, an X Safety employee, provided an affidavit that claimed that this instance and others of St. Clair “begging @Grok to remove illegal content constitutes an assent to xAI’s TOS.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But “such cannot be the case,” Goldberg argued.&lt;/p&gt;
&lt;p&gt;Faced with “the implicit threat that Grok would keep the images of St. Clair online and, possibly, create more of them,” St. Clair had little choice but to interact with Grok, Goldberg argued. And that prompting should not gut protections under New York law that St. Clair seeks to claim in her lawsuit, Goldberg argued, asking the court to void St. Clair’s xAI contract and reject xAI’s motion to switch venues.&lt;/p&gt;
&lt;p&gt;Should St. Clair win her fight to keep the lawsuit in New York, the case could help set precedent for perhaps millions of other victims who may be contemplating legal action but fear facing xAI in Musk’s chosen court.&lt;/p&gt;
&lt;p&gt;“It would be unjust to expect St. Clair to litigate in a state so far from her residence, and it may be so that trial in Texas will be so difficult and inconvenient that St. Clair effectively will be deprived of her day in court,” Goldberg argued.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Grok may continue harming kids&lt;/h2&gt;
&lt;p&gt;The estimated volume of sexualized images reported this week is alarming because it suggests that Grok, at the peak of the scandal, may have been generating more child sexual abuse material (CSAM) than X finds on its platform each month.&lt;/p&gt;
&lt;p&gt;In 2024, X Safety reported 686,176 instances of CSAM to the National Center for Missing and Exploited Children, which, on average, is about 57,000 CSAM reports each month. If the CCDH’s estimate of 23,000 Grok outputs that sexualize children over an 11-day span is accurate, then an average monthly total may have exceeded 62,000 if Grok was left unchecked.&lt;/p&gt;
&lt;p&gt;NCMEC did not immediately respond to Ars’ request to comment on how the estimated volume of Grok’s CSAM compares to X’s average CSAM reporting. But NCMEC previously told Ars that “whether an image is real or computer-generated, the harm is real, and the material is illegal.” That suggests Grok could remain a thorn in NCMEC’s side, as the CCDH has warned that even when X removes harmful Grok posts, “images could still be accessed via separate URLs,” suggesting that Grok’s CSAM and other harmful outputs could continue spreading. The CCDH also found instances of alleged CSAM that X had not removed as of January 15.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is why child safety experts have advocated for more testing to ensure that AI tools like Grok don’t roll out capabilities like the undressing feature. NCMEC previously told Ars that “technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children.” Amid a rise in AI-generated CSAM, the UK’s Internet Watch Foundation similarly warned that “it is unacceptable that technology is released which allows criminals to create this content.”&lt;/p&gt;
&lt;h2&gt;xAI advertisers, investors, partners remain silent&lt;/h2&gt;
&lt;p&gt;Yet, for Musk and xAI, there have been no meaningful consequences for Grok’s controversial outputs.&lt;/p&gt;
&lt;p&gt;It’s possible that recently launched probes will result in legal action in California or fines in the UK or elsewhere, but those investigations will likely take months to conclude.&lt;/p&gt;
&lt;p&gt;While US lawmakers have done little to intervene, some Democratic senators have attempted to ask Google and Apple CEOs why X and the Grok app were never restricted in their app stores, demanding a response by January 23. One day ahead of that deadline, senators confirmed to Ars that they’ve received no responses.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, neither Google nor Apple responded to Ars’ request to confirm whether a response is forthcoming or provide any statements on their decisions to keep the apps accessible. Both companies have been silent for weeks, along with other Big Tech companies that appear to be afraid to speak out against Musk’s chatbot.&lt;/p&gt;
&lt;p&gt;Microsoft and Oracle, which “run Grok on their cloud services,” as well as Nvidia and Advanced Micro Devices, “which sell xAI the computer chips needed to train and run Grok,” declined The Atlantic’s request to comment on how the scandal has impacted their decisions to partner with xAI. Additionally, a dozen of xAI’s key investors simply didn’t respond when The Atlantic asked if “they would continue partnering with xAI absent the company changing its products.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Similarly, dozens of advertisers refused Popular Information’s request to explain why there was no ad boycott over the Grok CSAM reports. That includes companies that once boycotted X over an antisemitic post from Musk, like “Amazon, Microsoft, and Google, all of which have advertised on X in recent days,” Popular Information reported.&lt;/p&gt;
&lt;p&gt;It’s possible that advertisers fear Musk’s legal wrath if they boycott his platforms. The CCDH overcame a lawsuit from Musk last year, but that’s pending an appeal. And Musk’s so-called “thermonuclear” lawsuit against advertisers&amp;nbsp;remains ongoing, with a trial date set for this October.&lt;/p&gt;
&lt;p&gt;The Atlantic suggested that xAI stakeholders are likely hoping the Grok scandal will blow over and they’ll escape unscathed by staying silent. But so far, backlash has seemed to remain strong, perhaps because, while “deepfakes are not new,” xAI “has made them a dramatically larger problem than ever before,” The Atlantic opined.&lt;/p&gt;
&lt;p&gt;“One of the largest forums dedicated to making fake images of real people,” Mr. Deepfakes, shut down in 2024 after public backlash over 43,000 sexual deepfake videos depicting about 3,800 individuals, the NYT reported. If the most recent estimates of Grok’s deepfakes are accurate, xAI shows how much more damage can be done when nudifying becomes a feature of one of the world’s biggest social networks, and nobody who has the power to stop it moves to intervene.&lt;/p&gt;
&lt;p&gt;“This is industrial-scale abuse of women and girls,” Imran Ahmed, the CCDH’s chief executive, told NYT. “There have been nudifying tools, but they have never had the distribution, ease of use or the integration into a large platform that Elon Musk did with Grok.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Millions likely harmed by Grok-edited sex images as X advertisers shrugged.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A post by Elon Musk on the X app, showing an AI prompt-created image, made with xAI's Grok app, depicting Musk wearing a bikini.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Journalists and advocates have been trying to grasp how many victims in total were harmed by Grok’s nudifying scandal after xAI delayed restricting outputs and app stores refused to cut off access for days.&lt;/p&gt;
&lt;p&gt;The latest estimates show that perhaps millions were harmed in the days immediately after Elon Musk promoted Grok’s undressing feature on his own X feed by posting a pic of himself in a bikini.&lt;/p&gt;
&lt;p&gt;Over just 11 days after Musk’s post, Grok sexualized more than 3 million images, of which 23,000 were of children, the Center for Countering Digital Hate (CCDH) estimated in research published Thursday.&lt;/p&gt;
&lt;p&gt;That figure may be inflated, since CCDH did not analyze prompts and could not determine if images were already sexual prior to Grok’s editing. However, The New York Times shared the CCDH report alongside its own analysis, conservatively estimating that about 41 percent (1.8 million) of 4.4 million images Grok generated between December 31 and January 8 sexualized men, women, and children.&lt;/p&gt;
&lt;p&gt;For xAI and X, the scandal brought scrutiny, but it also helped spike X engagement at a time when Meta’s rival app, Threads, has begun inching ahead of X in daily usage by mobile device users, TechCrunch reported. Without mentioning Grok, X’s head of product, Nikita Bier, celebrated the “highest engagement days on X” in an X post on January 6, just days before X finally started restricting some of Grok’s outputs for free users.&lt;/p&gt;
&lt;p&gt;Whether or not xAI intended the Grok scandal to surge X and Grok use, that appears to be the outcome. The Times charted Grok trends and found that in the nine days prior to Musk’s post, combined, Grok was only used about 300,000 times to generate images, but after Musk’s post, “the number of images created by Grok surged to nearly 600,000 per day” on X.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an article declaring that “Elon Musk cannot get away with this,” writers for The Atlantic suggested that X users “appeared to be imitating and showing off to one another,” believing that using Grok to create revenge porn “can make you famous.”&lt;/p&gt;
&lt;p&gt;X has previously warned that X users who generate illegal content risk permanent suspensions, but X has not confirmed if any users have been banned since public outcry over Grok’s outputs began. Ars asked and will update this post if X provides any response.&lt;/p&gt;
&lt;h2&gt;xAI fights victim who begged Grok to remove images&lt;/h2&gt;
&lt;p&gt;At first, X only limited Grok’s image editing for some free users, which The Atlantic noted made it seem like X was “essentially marketing nonconsensual sexual images as a paid feature of the platform.”&lt;/p&gt;
&lt;p&gt;But then, on January 14, X took its strongest action to restrict Grok’s harmful outputs—blocking outputs prompted by both free and paid X users. That move came after several countries, perhaps most notably the United Kingdom, and at least one state, California, launched probes.&lt;/p&gt;
&lt;p&gt;Crucially, X’s updates did not apply to the Grok app or website; however, it can reportedly still be used to generate nonconsensual images.&lt;/p&gt;
&lt;p&gt;That’s a problem for victims targeted by X users, according to Carrie Goldberg, a lawyer representing Ashley St. Clair, one of the first Grok victims to sue xAI; St. Clair also happens to be the mother of one of Musk’s children.&lt;/p&gt;
&lt;p&gt;Goldberg told Ars that victims like St. Clair want changes on all Grok platforms, not just X. But it’s not easy to “compel that kind of product change in a lawsuit,” Goldberg said. That’s why St. Clair is hoping the court will agree that Grok is a public nuisance, a claim that provides some injunctive relief to prevent broader social harms if she wins.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, St. Clair is seeking a temporary injunction that would block Grok from generating harmful images of her. But before she can get that order, if she wants a fair shot at winning the case, St. Clair must fight an xAI push counter-suing her and trying to move her lawsuit into Musk’s preferred Texas court, a recent court filing suggests.&lt;/p&gt;
&lt;p&gt;In that fight, xAI is arguing that St. Clair is bound by xAI’s terms of service, which were updated the day after she notified the company of her intent to sue.&lt;/p&gt;
&lt;p&gt;Alarmingly, xAI argued that St. Clair effectively agreed to the TOS when she started prompting Grok to delete her nonconsensual images—which is the only way X users had to get images removed quickly, St. Clair alleged. It seems xAI is hoping to turn moments of desperation, where victims beg Grok to remove images, into a legal shield.&lt;/p&gt;
&lt;p&gt;In the filing, Goldberg wrote that St. Clair’s lawsuit has nothing to do with her own use of Grok, noting that the harassing images could have been made even if she never used any of xAI’s products. For that reason alone, xAI should not be able to force a change in venue.&lt;/p&gt;
&lt;p&gt;Further, St. Clair’s use of Grok was clearly under duress, Goldberg argued, noting that one of the photos that Grok edited showed St. Clair’s toddler’s backpack.&lt;/p&gt;
&lt;p&gt;“REMOVE IT!!!” St. Clair asked Grok, allegedly feeling increasingly vulnerable every second the images remained online.&lt;/p&gt;
&lt;p&gt;Goldberg wrote that Barry Murphy, an X Safety employee, provided an affidavit that claimed that this instance and others of St. Clair “begging @Grok to remove illegal content constitutes an assent to xAI’s TOS.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But “such cannot be the case,” Goldberg argued.&lt;/p&gt;
&lt;p&gt;Faced with “the implicit threat that Grok would keep the images of St. Clair online and, possibly, create more of them,” St. Clair had little choice but to interact with Grok, Goldberg argued. And that prompting should not gut protections under New York law that St. Clair seeks to claim in her lawsuit, Goldberg argued, asking the court to void St. Clair’s xAI contract and reject xAI’s motion to switch venues.&lt;/p&gt;
&lt;p&gt;Should St. Clair win her fight to keep the lawsuit in New York, the case could help set precedent for perhaps millions of other victims who may be contemplating legal action but fear facing xAI in Musk’s chosen court.&lt;/p&gt;
&lt;p&gt;“It would be unjust to expect St. Clair to litigate in a state so far from her residence, and it may be so that trial in Texas will be so difficult and inconvenient that St. Clair effectively will be deprived of her day in court,” Goldberg argued.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Grok may continue harming kids&lt;/h2&gt;
&lt;p&gt;The estimated volume of sexualized images reported this week is alarming because it suggests that Grok, at the peak of the scandal, may have been generating more child sexual abuse material (CSAM) than X finds on its platform each month.&lt;/p&gt;
&lt;p&gt;In 2024, X Safety reported 686,176 instances of CSAM to the National Center for Missing and Exploited Children, which, on average, is about 57,000 CSAM reports each month. If the CCDH’s estimate of 23,000 Grok outputs that sexualize children over an 11-day span is accurate, then an average monthly total may have exceeded 62,000 if Grok was left unchecked.&lt;/p&gt;
&lt;p&gt;NCMEC did not immediately respond to Ars’ request to comment on how the estimated volume of Grok’s CSAM compares to X’s average CSAM reporting. But NCMEC previously told Ars that “whether an image is real or computer-generated, the harm is real, and the material is illegal.” That suggests Grok could remain a thorn in NCMEC’s side, as the CCDH has warned that even when X removes harmful Grok posts, “images could still be accessed via separate URLs,” suggesting that Grok’s CSAM and other harmful outputs could continue spreading. The CCDH also found instances of alleged CSAM that X had not removed as of January 15.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is why child safety experts have advocated for more testing to ensure that AI tools like Grok don’t roll out capabilities like the undressing feature. NCMEC previously told Ars that “technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children.” Amid a rise in AI-generated CSAM, the UK’s Internet Watch Foundation similarly warned that “it is unacceptable that technology is released which allows criminals to create this content.”&lt;/p&gt;
&lt;h2&gt;xAI advertisers, investors, partners remain silent&lt;/h2&gt;
&lt;p&gt;Yet, for Musk and xAI, there have been no meaningful consequences for Grok’s controversial outputs.&lt;/p&gt;
&lt;p&gt;It’s possible that recently launched probes will result in legal action in California or fines in the UK or elsewhere, but those investigations will likely take months to conclude.&lt;/p&gt;
&lt;p&gt;While US lawmakers have done little to intervene, some Democratic senators have attempted to ask Google and Apple CEOs why X and the Grok app were never restricted in their app stores, demanding a response by January 23. One day ahead of that deadline, senators confirmed to Ars that they’ve received no responses.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, neither Google nor Apple responded to Ars’ request to confirm whether a response is forthcoming or provide any statements on their decisions to keep the apps accessible. Both companies have been silent for weeks, along with other Big Tech companies that appear to be afraid to speak out against Musk’s chatbot.&lt;/p&gt;
&lt;p&gt;Microsoft and Oracle, which “run Grok on their cloud services,” as well as Nvidia and Advanced Micro Devices, “which sell xAI the computer chips needed to train and run Grok,” declined The Atlantic’s request to comment on how the scandal has impacted their decisions to partner with xAI. Additionally, a dozen of xAI’s key investors simply didn’t respond when The Atlantic asked if “they would continue partnering with xAI absent the company changing its products.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Similarly, dozens of advertisers refused Popular Information’s request to explain why there was no ad boycott over the Grok CSAM reports. That includes companies that once boycotted X over an antisemitic post from Musk, like “Amazon, Microsoft, and Google, all of which have advertised on X in recent days,” Popular Information reported.&lt;/p&gt;
&lt;p&gt;It’s possible that advertisers fear Musk’s legal wrath if they boycott his platforms. The CCDH overcame a lawsuit from Musk last year, but that’s pending an appeal. And Musk’s so-called “thermonuclear” lawsuit against advertisers&amp;nbsp;remains ongoing, with a trial date set for this October.&lt;/p&gt;
&lt;p&gt;The Atlantic suggested that xAI stakeholders are likely hoping the Grok scandal will blow over and they’ll escape unscathed by staying silent. But so far, backlash has seemed to remain strong, perhaps because, while “deepfakes are not new,” xAI “has made them a dramatically larger problem than ever before,” The Atlantic opined.&lt;/p&gt;
&lt;p&gt;“One of the largest forums dedicated to making fake images of real people,” Mr. Deepfakes, shut down in 2024 after public backlash over 43,000 sexual deepfake videos depicting about 3,800 individuals, the NYT reported. If the most recent estimates of Grok’s deepfakes are accurate, xAI shows how much more damage can be done when nudifying becomes a feature of one of the world’s biggest social networks, and nobody who has the power to stop it moves to intervene.&lt;/p&gt;
&lt;p&gt;“This is industrial-scale abuse of women and girls,” Imran Ahmed, the CCDH’s chief executive, told NYT. “There have been nudifying tools, but they have never had the distribution, ease of use or the integration into a large platform that Elon Musk did with Grok.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/asking-grok-to-delete-fake-nudes-may-force-victims-to-sue-in-musks-chosen-court/</guid><pubDate>Thu, 22 Jan 2026 21:16:42 +0000</pubDate></item><item><title>Report: Apple plans to launch AI-powered wearable pin device as soon as 2027 (AI - Ars Technica)</title><link>https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple, OpenAI, Meta, and more are all racing toward AI hardware products.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A small metal disc" class="absolute inset-0 w-full h-full object-cover hidden" height="159" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-300x159.png" width="300" /&gt;
                  &lt;img alt="A small metal disc" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new wearable is said to resemble an AirTag like this.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.&lt;/p&gt;
&lt;p&gt;The product is said to be “the same size as an AirTag, only slightly thicker,” and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple’s solution, should Apple offload the processing to a synced external device like an iPhone.&lt;/p&gt;
&lt;p&gt;The Information’s sources don’t specify whether that’s the plan, or if it will be a standalone device.&lt;/p&gt;
&lt;p&gt;The wearable will have a single physical button “along its edges” and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user’s surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The report didn’t include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.&lt;/p&gt;
&lt;p&gt;Not long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.&lt;/p&gt;
&lt;p&gt;Apple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea’s conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.&lt;/p&gt;
&lt;p&gt;Just a few days ago, it was revealed that Apple will tap Google’s Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple, OpenAI, Meta, and more are all racing toward AI hardware products.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A small metal disc" class="absolute inset-0 w-full h-full object-cover hidden" height="159" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-300x159.png" width="300" /&gt;
                  &lt;img alt="A small metal disc" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new wearable is said to resemble an AirTag like this.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.&lt;/p&gt;
&lt;p&gt;The product is said to be “the same size as an AirTag, only slightly thicker,” and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple’s solution, should Apple offload the processing to a synced external device like an iPhone.&lt;/p&gt;
&lt;p&gt;The Information’s sources don’t specify whether that’s the plan, or if it will be a standalone device.&lt;/p&gt;
&lt;p&gt;The wearable will have a single physical button “along its edges” and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user’s surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The report didn’t include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.&lt;/p&gt;
&lt;p&gt;Not long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.&lt;/p&gt;
&lt;p&gt;Apple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea’s conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.&lt;/p&gt;
&lt;p&gt;Just a few days ago, it was revealed that Apple will tap Google’s Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/</guid><pubDate>Thu, 22 Jan 2026 21:32:28 +0000</pubDate></item><item><title>Are AI agents ready for the workplace? A new benchmark raises doubts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/are-ai-agents-ready-for-the-workplace-a-new-benchmark-raises-doubts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s been nearly two years since Microsoft CEO Satya Nadella predicted AI would replace knowledge work — the white-collar jobs held by lawyers, investment bankers, librarians, accountants, IT, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But despite the huge progress made by foundation models, the change in knowledge work has been slow to arrive. Models have mastered in-depth research and agentic planning, but for whatever reason, most white-collar work has been relatively unaffected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s one of the biggest mysteries in AI — and thanks to new research from the training-data giant Mercor, we’re finally getting some answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new research looks at how leading AI models hold up doing actual white-collar work tasks, drawn from consulting, investment banking, and law. The result is a new benchmark called APEX-Agents — and so far, every AI lab is getting a failing grade. Faced with queries from real professionals, even the best models struggled to get more than a quarter of the questions right. The vast majority of the time, the model came back with a wrong answer or no answer at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Mercor CEO Brendan Foody, who worked on the paper, the models’ biggest stumbling point was tracking down information across multiple domains — something that’s integral to most of the knowledge work performed by humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the big changes in this benchmark is that we built out the entire environment, modeled after real professional services,” Foody told TechCrunch. “The way we do our jobs isn’t with one individual giving us all the context in one place. In real life, you’re operating across Slack and Google Drive and all these other tools.” For many agentic AI models, that kind of multi-domain reasoning is still hit or miss.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085292" height="307" src="https://techcrunch.com/wp-content/uploads/2026/01/Screen-Shot-2026-01-22-at-3.25.58-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The scenarios were all drawn from actual professionals on Mercor’s expert marketplace, who both laid out the queries and set the standard for a successful response. Looking through the questions, which are posted publicly on Hugging Face, gives a sense of how complex the tasks can get.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One question in the “Law” section reads:&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;During the first 48 minutes of the EU production outage, Northstar’s engineering team exported one or two bundled sets of EU production event logs containing personal data to the U.S. analytics vendor&amp;nbsp;… Under Northstar’s own policies, it can reasonably treat the one or two log exports as consistent with Article 49?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The correct answer is yes, but getting there requires an in-depth assessment of the company’s own policies as well as the relevant EU privacy laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That might stump even a well-informed human, but the researchers were trying to model the work done by professionals in the field. If an LLM can reliably answer these questions, it could effectively replace many of the lawyers working today. “I think this is probably the most important topic in the economy,” Foody told TechCrunch. “The benchmark is very reflective of the real work that these people do.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also attempted to measure professional skills with its GDPval benchmark — but the APEX-Agents test differs in important ways. Where GDPval tests general knowledge across a wide range of professions, the APEX-Agents benchmark measures the system’s ability to perform sustained tasks in a narrow set of high-value professions. The result is more difficult for models, but also more closely tied to whether these jobs can be automated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While none of the models proved ready to take over as investment bankers, some were clearly closer to the mark. Gemini 3 Flash performed the best of the group with 24% one-shot accuracy, followed closely by GPT-5.2 with 23%. Below that, Opus 4.5, Gemini 3 Pro and GPT-5 all scored roughly 18%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the initial results fall short, the AI field has a history of blowing through challenging benchmarks. Now that the APEX-Agents test is public, it’s an open challenge for AI labs that believe they can do better — something Foody fully expects in the months to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s improving really quickly,” he told TechCrunch. “Right now it’s fair to say it’s like an intern that gets it right a quarter of the time, but last year it was the intern that gets it right five or 10% of the time. That kind of improvement year after year can have an impact so quickly.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s been nearly two years since Microsoft CEO Satya Nadella predicted AI would replace knowledge work — the white-collar jobs held by lawyers, investment bankers, librarians, accountants, IT, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But despite the huge progress made by foundation models, the change in knowledge work has been slow to arrive. Models have mastered in-depth research and agentic planning, but for whatever reason, most white-collar work has been relatively unaffected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s one of the biggest mysteries in AI — and thanks to new research from the training-data giant Mercor, we’re finally getting some answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new research looks at how leading AI models hold up doing actual white-collar work tasks, drawn from consulting, investment banking, and law. The result is a new benchmark called APEX-Agents — and so far, every AI lab is getting a failing grade. Faced with queries from real professionals, even the best models struggled to get more than a quarter of the questions right. The vast majority of the time, the model came back with a wrong answer or no answer at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Mercor CEO Brendan Foody, who worked on the paper, the models’ biggest stumbling point was tracking down information across multiple domains — something that’s integral to most of the knowledge work performed by humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the big changes in this benchmark is that we built out the entire environment, modeled after real professional services,” Foody told TechCrunch. “The way we do our jobs isn’t with one individual giving us all the context in one place. In real life, you’re operating across Slack and Google Drive and all these other tools.” For many agentic AI models, that kind of multi-domain reasoning is still hit or miss.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085292" height="307" src="https://techcrunch.com/wp-content/uploads/2026/01/Screen-Shot-2026-01-22-at-3.25.58-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The scenarios were all drawn from actual professionals on Mercor’s expert marketplace, who both laid out the queries and set the standard for a successful response. Looking through the questions, which are posted publicly on Hugging Face, gives a sense of how complex the tasks can get.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One question in the “Law” section reads:&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;During the first 48 minutes of the EU production outage, Northstar’s engineering team exported one or two bundled sets of EU production event logs containing personal data to the U.S. analytics vendor&amp;nbsp;… Under Northstar’s own policies, it can reasonably treat the one or two log exports as consistent with Article 49?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The correct answer is yes, but getting there requires an in-depth assessment of the company’s own policies as well as the relevant EU privacy laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That might stump even a well-informed human, but the researchers were trying to model the work done by professionals in the field. If an LLM can reliably answer these questions, it could effectively replace many of the lawyers working today. “I think this is probably the most important topic in the economy,” Foody told TechCrunch. “The benchmark is very reflective of the real work that these people do.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also attempted to measure professional skills with its GDPval benchmark — but the APEX-Agents test differs in important ways. Where GDPval tests general knowledge across a wide range of professions, the APEX-Agents benchmark measures the system’s ability to perform sustained tasks in a narrow set of high-value professions. The result is more difficult for models, but also more closely tied to whether these jobs can be automated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While none of the models proved ready to take over as investment bankers, some were clearly closer to the mark. Gemini 3 Flash performed the best of the group with 24% one-shot accuracy, followed closely by GPT-5.2 with 23%. Below that, Opus 4.5, Gemini 3 Pro and GPT-5 all scored roughly 18%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the initial results fall short, the AI field has a history of blowing through challenging benchmarks. Now that the APEX-Agents test is public, it’s an open challenge for AI labs that believe they can do better — something Foody fully expects in the months to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s improving really quickly,” he told TechCrunch. “Right now it’s fair to say it’s like an intern that gets it right a quarter of the time, but last year it was the intern that gets it right five or 10% of the time. That kind of improvement year after year can have an impact so quickly.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/are-ai-agents-ready-for-the-workplace-a-new-benchmark-raises-doubts/</guid><pubDate>Thu, 22 Jan 2026 21:42:18 +0000</pubDate></item><item><title>Inference startup Inferact lands $150M to commercialize vLLM (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/inference-startup-inferact-lands-150m-to-commercialize-vllm/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/10/ai-tool.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The creators of the open source project vLLM have announced that they transitioned the popular tool into a VC-backed startup, Inferact, raising $150 million in seed funding at an $800 million valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners, confirming TechCrunch’s earlier reporting that vLLM has raised capital from a16z.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inferact’s debut mirrors the recent commercialization of the SGLang project as RadixArk, which sources told us secured capital at a $400 million valuation led by Accel, as we reported on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the focus in AI shifts from training models to deploying them in applications, a process known as inference, technologies like vLLM and SGLang that make these AI tools run faster and more affordably are attracting investor attention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both vLLM and SGLang were incubated in 2023 at the UC Berkeley lab of Databricks co-founder Ion Stoica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Inferact CEO Simon Mo, one of the project’s original creators, told Bloomberg that existing users of vLLM include Amazon’s cloud service and the shopping app.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/10/ai-tool.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The creators of the open source project vLLM have announced that they transitioned the popular tool into a VC-backed startup, Inferact, raising $150 million in seed funding at an $800 million valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners, confirming TechCrunch’s earlier reporting that vLLM has raised capital from a16z.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inferact’s debut mirrors the recent commercialization of the SGLang project as RadixArk, which sources told us secured capital at a $400 million valuation led by Accel, as we reported on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the focus in AI shifts from training models to deploying them in applications, a process known as inference, technologies like vLLM and SGLang that make these AI tools run faster and more affordably are attracting investor attention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both vLLM and SGLang were incubated in 2023 at the UC Berkeley lab of Databricks co-founder Ion Stoica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Inferact CEO Simon Mo, one of the project’s original creators, told Bloomberg that existing users of vLLM include Amazon’s cloud service and the shopping app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/inference-startup-inferact-lands-150m-to-commercialize-vllm/</guid><pubDate>Thu, 22 Jan 2026 22:42:00 +0000</pubDate></item><item><title>Voice AI engine and OpenAI partner LiveKit hits $1B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/voice-ai-engine-and-openai-partner-livekit-hits-1b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LiveKit, a developer of infrastructure software for real-time AI voice and video applications, has announced the raise of $100 million in funding at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round, which comes 10 months after LiveKit’s previous fundraise, was led by Index Ventures with participation from existing investors, including Altimeter Capital Management, Hanabi Capital, and Redpoint Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;LiveKit powers OpenAI’s ChatGPT voice mode. The startup’s other customers include xAI, Salesforce, Tesla, as well as 911 emergency service operators and mental health providers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in 2021 by Russ d’Sa and David Zhao as an open source software project for building apps that can transmit real-time audio and video without interruptions, in an era when the whole world was meeting on Zoom during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although LiveKit began as a free developer tool, the business took off after the founders realized big companies wanted a managed cloud version and began providing those services to enterprises amid the voice AI boom.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LiveKit, a developer of infrastructure software for real-time AI voice and video applications, has announced the raise of $100 million in funding at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round, which comes 10 months after LiveKit’s previous fundraise, was led by Index Ventures with participation from existing investors, including Altimeter Capital Management, Hanabi Capital, and Redpoint Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;LiveKit powers OpenAI’s ChatGPT voice mode. The startup’s other customers include xAI, Salesforce, Tesla, as well as 911 emergency service operators and mental health providers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in 2021 by Russ d’Sa and David Zhao as an open source software project for building apps that can transmit real-time audio and video without interruptions, in an era when the whole world was meeting on Zoom during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although LiveKit began as a free developer tool, the business took off after the founders realized big companies wanted a managed cloud version and began providing those services to enterprises amid the voice AI boom.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/voice-ai-engine-and-openai-partner-livekit-hits-1b-valuation/</guid><pubDate>Thu, 22 Jan 2026 22:44:29 +0000</pubDate></item><item><title>Overrun with AI slop, cURL scraps bug bounties to ensure "intact mental health" (AI - Ars Technica)</title><link>https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The onslaught includes LLMs finding bogus vulnerabilities and code that won’t compile.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="absolute inset-0 w-full h-full object-cover hidden" height="404" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-640x404.jpg" width="640" /&gt;
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The project developer for one of the Internet’s most popular networking tools is scrapping its vulnerability reward program after being overrun by a spike in the submission of low-quality reports, much of it AI-generated slop.&lt;/p&gt;
&lt;p&gt;“We are just a small single open source project with a small number of active maintainers,” Daniel Stenberg, the founder and lead developer of the open source app cURL, said Thursday. “It is not in our power to change how all these people and their slop machines work. We need to make moves to ensure our survival and intact mental health.”&lt;/p&gt;
&lt;h2&gt;Manufacturing bogus bugs&lt;/h2&gt;
&lt;p&gt;His comments came as cURL users complained that the move was treating the symptoms caused by AI slop without addressing the cause. The users said they were concerned the move would eliminate a key means for ensuring and maintaining the security of the tool. Stenberg largely agreed, but indicated his team had little choice.&lt;/p&gt;
&lt;p&gt;In a separate post on Thursday, Stenberg wrote: “We will ban you and ridicule you in public if you waste our time on crap reports.” An update to cURL’s official GitHub account made the termination, which takes effect at the end of this month, official.&lt;/p&gt;
&lt;p&gt;cURL was first released three decades ago, under the name httpget and later urlget. It has since become an indispensable tool among admins, researchers, and security professionals, among others, for a wide range of tasks, including file transfers, troubleshooting buggy web software, and automating tasks. cURL is integrated into default versions of Windows, macOS, and most distributions of Linux.&lt;/p&gt;
&lt;p&gt;As such a widely used tool for interacting with vast amounts of data online, security is paramount. Like many other software makers, cURL project members have relied on private bug reports submitted by outside researchers. To provide an incentive and to reward high-quality submissions, the project members have paid cash bounties in return for reports of high-severity vulnerabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last May, Stenberg said the number of low-quality AI-generated reports was putting a strain on the cURL security team and was likely to metastasize, hampering other software developers.&lt;/p&gt;
&lt;p&gt;“AI slop is overwhelming maintainers *today* and it won’t stop at curl but only starts there,” he said at the time.&lt;/p&gt;
&lt;p&gt;The lead developer has also posted a page listing some of the specious reports submitted in recent months. In response to one such report, a cURL project member wrote: “I think you’re a victim of LLM hallucination.” The member continued:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The text has some similarities to the (bogus) CVE-2020-19909 and other reports. There are plenty of clues that Bard has manufactured bogus information: that code snippet of “curl_easy_setopt” doesn’t match the actual signature of the function (and wouldn’t even compile), a changelog that don’t match reality, and more indications that this is completely bogus. I’m curious to hear what your exploit does against a made-up vulnerability. Care to share it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After the bug reporter complained and reiterated the risk posed by the non-existent vulnerability, Stenberg jumped in and wrote: “You were fooled by an AI into believing that. In what way did we not meet our end of the deal?&lt;/p&gt;
&lt;p&gt;Stenberg isn’t critical of AI-assisted bug reports in all cases. In September, he publicly applauded a researcher for sending a “massive list” of bugs that were found using a set of AI-assisted tools. The reports had resulted in 22 bug fixes at the time.&lt;/p&gt;
&lt;p&gt;In an interview, Stenberg said that the reporter, Joshua Rogers, mostly used AI-powered code analyzer called ZeroPath.&lt;/p&gt;
&lt;p&gt;“A clever person using a powerful tool,” Stenberg wrote. “I believe most of the worst reports we get are from people just asking an AI bot without caring or understanding much about what it reports.”&lt;/p&gt;
&lt;p&gt;Unfortunately, such cases seem to be the exception. AI slop has already flooded music-streaming services with so many songs—often misattributed to real artists—that the platforms are slowly becoming unusable for music discovery. cURL’s move may be an early indication that something similar is happening to bug bounty programs.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The onslaught includes LLMs finding bogus vulnerabilities and code that won’t compile.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="absolute inset-0 w-full h-full object-cover hidden" height="404" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-640x404.jpg" width="640" /&gt;
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The project developer for one of the Internet’s most popular networking tools is scrapping its vulnerability reward program after being overrun by a spike in the submission of low-quality reports, much of it AI-generated slop.&lt;/p&gt;
&lt;p&gt;“We are just a small single open source project with a small number of active maintainers,” Daniel Stenberg, the founder and lead developer of the open source app cURL, said Thursday. “It is not in our power to change how all these people and their slop machines work. We need to make moves to ensure our survival and intact mental health.”&lt;/p&gt;
&lt;h2&gt;Manufacturing bogus bugs&lt;/h2&gt;
&lt;p&gt;His comments came as cURL users complained that the move was treating the symptoms caused by AI slop without addressing the cause. The users said they were concerned the move would eliminate a key means for ensuring and maintaining the security of the tool. Stenberg largely agreed, but indicated his team had little choice.&lt;/p&gt;
&lt;p&gt;In a separate post on Thursday, Stenberg wrote: “We will ban you and ridicule you in public if you waste our time on crap reports.” An update to cURL’s official GitHub account made the termination, which takes effect at the end of this month, official.&lt;/p&gt;
&lt;p&gt;cURL was first released three decades ago, under the name httpget and later urlget. It has since become an indispensable tool among admins, researchers, and security professionals, among others, for a wide range of tasks, including file transfers, troubleshooting buggy web software, and automating tasks. cURL is integrated into default versions of Windows, macOS, and most distributions of Linux.&lt;/p&gt;
&lt;p&gt;As such a widely used tool for interacting with vast amounts of data online, security is paramount. Like many other software makers, cURL project members have relied on private bug reports submitted by outside researchers. To provide an incentive and to reward high-quality submissions, the project members have paid cash bounties in return for reports of high-severity vulnerabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last May, Stenberg said the number of low-quality AI-generated reports was putting a strain on the cURL security team and was likely to metastasize, hampering other software developers.&lt;/p&gt;
&lt;p&gt;“AI slop is overwhelming maintainers *today* and it won’t stop at curl but only starts there,” he said at the time.&lt;/p&gt;
&lt;p&gt;The lead developer has also posted a page listing some of the specious reports submitted in recent months. In response to one such report, a cURL project member wrote: “I think you’re a victim of LLM hallucination.” The member continued:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The text has some similarities to the (bogus) CVE-2020-19909 and other reports. There are plenty of clues that Bard has manufactured bogus information: that code snippet of “curl_easy_setopt” doesn’t match the actual signature of the function (and wouldn’t even compile), a changelog that don’t match reality, and more indications that this is completely bogus. I’m curious to hear what your exploit does against a made-up vulnerability. Care to share it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After the bug reporter complained and reiterated the risk posed by the non-existent vulnerability, Stenberg jumped in and wrote: “You were fooled by an AI into believing that. In what way did we not meet our end of the deal?&lt;/p&gt;
&lt;p&gt;Stenberg isn’t critical of AI-assisted bug reports in all cases. In September, he publicly applauded a researcher for sending a “massive list” of bugs that were found using a set of AI-assisted tools. The reports had resulted in 22 bug fixes at the time.&lt;/p&gt;
&lt;p&gt;In an interview, Stenberg said that the reporter, Joshua Rogers, mostly used AI-powered code analyzer called ZeroPath.&lt;/p&gt;
&lt;p&gt;“A clever person using a powerful tool,” Stenberg wrote. “I believe most of the worst reports we get are from people just asking an AI bot without caring or understanding much about what it reports.”&lt;/p&gt;
&lt;p&gt;Unfortunately, such cases seem to be the exception. AI slop has already flooded music-streaming services with so many songs—often misattributed to real artists—that the platforms are slowly becoming unusable for music discovery. cURL’s move may be an early indication that something similar is happening to bug bounty programs.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/</guid><pubDate>Thu, 22 Jan 2026 22:46:30 +0000</pubDate></item><item><title>OpenAI is coming for those sweet enterprise dollars in 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/openai-is-coming-for-those-sweet-enterprise-dollars-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has reorganized some of its leadership and picked a familiar face to lead its push into selling AI to business customers as the company looks to catch up to its rivals in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company appointed Barret Zoph to lead its efforts to sell its AI to enterprises, according to reporting from The Information, citing an internal OpenAI memo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to OpenAI for confirmation and more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph returned to OpenAI last week after leaving Thinking Machine Labs, former OpenAI CTO Mira Murati’s AI startup where Zoph had served as a co-founder and CTO since October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exact circumstances of his departure aren’t clear, with rumors swirling about whether Zoph and a few other former OpenAI employees were fired or left on their own accord, possibly with plans to return to OpenAI all along.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph was previously the vice president of post-training inference at OpenAI from September 2022 to October 2024. He’s stepping into a very different position and will likely play an important role at the company as it looks to grow its enterprise business — an area where it is losing ground to competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched its enterprise-focused ChatGPT Enterprise product in 2023 more than a year before Anthropic and multiple years before Google launched its enterprise offerings. The company claims the product has more than 5 million business users and counts companies including SoftBank, Target, and Lowe’s as customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But its market share is falling while its rivals are climbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic holds a dominant lead over its AI rivals when it comes to enterprise large language model usage. The AI research lab holds a 40% market share, according to a December report from VC firm Menlo Ventures (which, it should be noted, has invested aggressively in Anthropic). In July, the startup’s market share was estimated to be 32%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s Gemini adoption has been steadier, according to Menlo Ventures. The company released its enterprise product last fall and has seen its enterprise LLM usage market share largely stay the same, per Menlo’s findings, growing from 20% in July to 21% at the end of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI on the other hand has seen its usage market share drop from 50% in 2023 to 27% at the end of 2025 — a trend that appears to concern the company. OpenAI CEO Sam Altman expressed concern specifically that Google Gemini’s growth was starting to encroach on OpenAI in an internal memo a few months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise growth is an area of focus for the company in 2026, OpenAI’s CFO Sarah Friar wrote in a blog post this past Sunday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has since announced an expanded multi-year partnership with ServiceNow that will give ServiceNow customers access to OpenAI models.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has reorganized some of its leadership and picked a familiar face to lead its push into selling AI to business customers as the company looks to catch up to its rivals in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company appointed Barret Zoph to lead its efforts to sell its AI to enterprises, according to reporting from The Information, citing an internal OpenAI memo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to OpenAI for confirmation and more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph returned to OpenAI last week after leaving Thinking Machine Labs, former OpenAI CTO Mira Murati’s AI startup where Zoph had served as a co-founder and CTO since October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exact circumstances of his departure aren’t clear, with rumors swirling about whether Zoph and a few other former OpenAI employees were fired or left on their own accord, possibly with plans to return to OpenAI all along.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph was previously the vice president of post-training inference at OpenAI from September 2022 to October 2024. He’s stepping into a very different position and will likely play an important role at the company as it looks to grow its enterprise business — an area where it is losing ground to competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched its enterprise-focused ChatGPT Enterprise product in 2023 more than a year before Anthropic and multiple years before Google launched its enterprise offerings. The company claims the product has more than 5 million business users and counts companies including SoftBank, Target, and Lowe’s as customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But its market share is falling while its rivals are climbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic holds a dominant lead over its AI rivals when it comes to enterprise large language model usage. The AI research lab holds a 40% market share, according to a December report from VC firm Menlo Ventures (which, it should be noted, has invested aggressively in Anthropic). In July, the startup’s market share was estimated to be 32%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s Gemini adoption has been steadier, according to Menlo Ventures. The company released its enterprise product last fall and has seen its enterprise LLM usage market share largely stay the same, per Menlo’s findings, growing from 20% in July to 21% at the end of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI on the other hand has seen its usage market share drop from 50% in 2023 to 27% at the end of 2025 — a trend that appears to concern the company. OpenAI CEO Sam Altman expressed concern specifically that Google Gemini’s growth was starting to encroach on OpenAI in an internal memo a few months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise growth is an area of focus for the company in 2026, OpenAI’s CFO Sarah Friar wrote in a blog post this past Sunday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has since announced an expanded multi-year partnership with ServiceNow that will give ServiceNow customers access to OpenAI models.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/openai-is-coming-for-those-sweet-enterprise-dollars-in-2026/</guid><pubDate>Fri, 23 Jan 2026 00:52:33 +0000</pubDate></item><item><title>[NEW] Former Sequoia partner’s new startup uses AI to negotiate your calendar for you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/former-sequoia-partners-new-startup-uses-ai-to-negotiate-your-calendar-for-you/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Copy-of-SequoiaARCUS2023-FallWeek1NYC_0919-318.jpg.png?resize=1200,694" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Kais Khimji has spent most of his professional career as a venture investor, including six years as a partner at the prominent VC firm Sequoia Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just like several other former Sequoia partners — including David Vélez, who founded the Brazilian digital bank Nubank — Khimji (pictured left) has always wanted to be a startup founder. On Thursday, he announced that he has revived an idea he began working on as a student at Harvard about 10 years ago, turning it into the AI calendar-scheduling company Blockit. In a major vote of confidence, Khimji’s former employer, Sequoia, led the company’s $5 million seed round.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Blockit has a chance to become a $1Bn+ revenue business, and Kais will make sure it gets there,” Pat Grady, Sequoia’s general partner and co-steward who led the investment, wrote in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many startups have tried to automate scheduling in the past, Khimji believes that thanks to advances in LLMs, Blockit’s AI agents can handle scheduling more seamlessly and efficiently than many of its predecessors, including now-defunct startups Clara Labs and x.ai. (Yes, that domain name ended up with Elon Musk’s AI company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike the current category leader Calendly, which was last valued at $3 billion and relies on users sharing links to find availability, Blockit is betting that its AI agents can master the nuance required to handle the entire scheduling process without human involvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Blockit, Khimji and co-founder John Hahn — who previously worked on calendar products, including Timeful, Google Calendar, and Clockwise — are building what is essentially an AI social network for people’s time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It always felt very odd. I have a time database — my calendar. You have a time database — your calendar, and our databases just can’t talk to each other,” Khimji told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji says that Blockit can finally solve this disconnection. When two users need to meet, their respective AI agents communicate directly to negotiate a time, bypassing the typical back-and-forth emails entirely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke the Blockit agent by copying it on an email or messaging it in Slack about a meeting. The bot then takes over the logistics, negotiating a mutually convenient time and location that fits the preferences of all participants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji said that Blockit can work as seamlessly as a human executive assistant. Users simply need to provide the system with specific instructions about their preferences, such as which meetings are nonnegotiable and which are “movable” based on daily needs. “Sometimes my calendar is crazy, so I need to skip lunch, and the agent needs to know that it’s okay to skip lunch,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The system can even be trained to prioritize meetings based on the tone of an email. For instance, a user might instruct the agent that a meeting request signed with a formal “Best regards” should take precedence over a casual interaction ending with “Cheers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By learning the preferences of its users, Blockit appears to be capitalizing on what venture firm Foundation Capital’s partners Jaya Gupta and Ashu Garg call “context graphs.” In a widely shared essay, the investors describe a multibillion-dollar opportunity for AI agents to capture the “why” behind every business decision by relying on the hidden logic that previously only existed in a person’s head.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blockit is already being used by more than 200 companies, including AI startup Together.ai, the newly acquired fintech company Brex, and robotics startup Rogo, as well as venture firms a16z, Accel, and Index. The app is available for free for 30 days. After that, it costs $1,000 annually for individual users and $5,000 annually for a team license with support for multiple users, Khimji said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Copy-of-SequoiaARCUS2023-FallWeek1NYC_0919-318.jpg.png?resize=1200,694" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Kais Khimji has spent most of his professional career as a venture investor, including six years as a partner at the prominent VC firm Sequoia Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just like several other former Sequoia partners — including David Vélez, who founded the Brazilian digital bank Nubank — Khimji (pictured left) has always wanted to be a startup founder. On Thursday, he announced that he has revived an idea he began working on as a student at Harvard about 10 years ago, turning it into the AI calendar-scheduling company Blockit. In a major vote of confidence, Khimji’s former employer, Sequoia, led the company’s $5 million seed round.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Blockit has a chance to become a $1Bn+ revenue business, and Kais will make sure it gets there,” Pat Grady, Sequoia’s general partner and co-steward who led the investment, wrote in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many startups have tried to automate scheduling in the past, Khimji believes that thanks to advances in LLMs, Blockit’s AI agents can handle scheduling more seamlessly and efficiently than many of its predecessors, including now-defunct startups Clara Labs and x.ai. (Yes, that domain name ended up with Elon Musk’s AI company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike the current category leader Calendly, which was last valued at $3 billion and relies on users sharing links to find availability, Blockit is betting that its AI agents can master the nuance required to handle the entire scheduling process without human involvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Blockit, Khimji and co-founder John Hahn — who previously worked on calendar products, including Timeful, Google Calendar, and Clockwise — are building what is essentially an AI social network for people’s time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It always felt very odd. I have a time database — my calendar. You have a time database — your calendar, and our databases just can’t talk to each other,” Khimji told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji says that Blockit can finally solve this disconnection. When two users need to meet, their respective AI agents communicate directly to negotiate a time, bypassing the typical back-and-forth emails entirely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke the Blockit agent by copying it on an email or messaging it in Slack about a meeting. The bot then takes over the logistics, negotiating a mutually convenient time and location that fits the preferences of all participants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji said that Blockit can work as seamlessly as a human executive assistant. Users simply need to provide the system with specific instructions about their preferences, such as which meetings are nonnegotiable and which are “movable” based on daily needs. “Sometimes my calendar is crazy, so I need to skip lunch, and the agent needs to know that it’s okay to skip lunch,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The system can even be trained to prioritize meetings based on the tone of an email. For instance, a user might instruct the agent that a meeting request signed with a formal “Best regards” should take precedence over a casual interaction ending with “Cheers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By learning the preferences of its users, Blockit appears to be capitalizing on what venture firm Foundation Capital’s partners Jaya Gupta and Ashu Garg call “context graphs.” In a widely shared essay, the investors describe a multibillion-dollar opportunity for AI agents to capture the “why” behind every business decision by relying on the hidden logic that previously only existed in a person’s head.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blockit is already being used by more than 200 companies, including AI startup Together.ai, the newly acquired fintech company Brex, and robotics startup Rogo, as well as venture firms a16z, Accel, and Index. The app is available for free for 30 days. After that, it costs $1,000 annually for individual users and $5,000 annually for a team license with support for multiple users, Khimji said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/former-sequoia-partners-new-startup-uses-ai-to-negotiate-your-calendar-for-you/</guid><pubDate>Fri, 23 Jan 2026 02:29:24 +0000</pubDate></item></channel></rss>