<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 24 Sep 2025 06:31:29 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Roundtables: Meet the 2025 Innovator of the Year (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/23/1123986/roundtables-meet-the-2025-innovator-of-the-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-Roundtables-1-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Every year, MIT Technology Review selects one individual whose work we admire to recognize as Innovator of the Year. For 2025, we chose Sneha Goenka, who designed the computations behind&amp;nbsp;the world’s fastest whole-genome sequencing method. Thanks to her work, physicians can now sequence a patient’s genome and diagnose a genetic condition in less than eight hours—an achievement that could transform medical care.&lt;/p&gt;  &lt;p&gt;Speakers: &lt;strong&gt;&lt;strong&gt;Sneha Goenka&lt;/strong&gt;&lt;/strong&gt;, Innovator of the Year;&lt;strong&gt;&amp;nbsp;&lt;strong&gt;Leilani Battle&lt;/strong&gt;,&amp;nbsp;&lt;/strong&gt;University of Washington;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;and&lt;strong&gt;&amp;nbsp;&lt;strong&gt;Mat Honan&lt;/strong&gt;,&amp;nbsp;&lt;/strong&gt;editor in chief&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;Recorded on&lt;/strong&gt; September 23&lt;/strong&gt;, &lt;strong&gt;2025&lt;/strong&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-Roundtables-1-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Every year, MIT Technology Review selects one individual whose work we admire to recognize as Innovator of the Year. For 2025, we chose Sneha Goenka, who designed the computations behind&amp;nbsp;the world’s fastest whole-genome sequencing method. Thanks to her work, physicians can now sequence a patient’s genome and diagnose a genetic condition in less than eight hours—an achievement that could transform medical care.&lt;/p&gt;  &lt;p&gt;Speakers: &lt;strong&gt;&lt;strong&gt;Sneha Goenka&lt;/strong&gt;&lt;/strong&gt;, Innovator of the Year;&lt;strong&gt;&amp;nbsp;&lt;strong&gt;Leilani Battle&lt;/strong&gt;,&amp;nbsp;&lt;/strong&gt;University of Washington;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;and&lt;strong&gt;&amp;nbsp;&lt;strong&gt;Mat Honan&lt;/strong&gt;,&amp;nbsp;&lt;/strong&gt;editor in chief&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;Recorded on&lt;/strong&gt; September 23&lt;/strong&gt;, &lt;strong&gt;2025&lt;/strong&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/23/1123986/roundtables-meet-the-2025-innovator-of-the-year/</guid><pubDate>Tue, 23 Sep 2025 19:12:31 +0000</pubDate></item><item><title>Scott Wiener on his fight to make Big Tech disclose AI’s dangers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/23/scott-wiener-on-his-fight-to-make-big-tech-disclose-ais-dangers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2218026592.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;This is not California state senator Scott Wiener’s first attempt at addressing the dangers of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Silicon Valley mounted a fierce campaign against his controversial AI safety bill, SB 1047, which would have made tech companies liable for the potential harms of their AI systems. Tech leaders warned that it would stifle America’s AI boom. Governor Gavin Newsom ultimately vetoed the bill, echoing similar concerns, and a popular AI hacker house promptly threw an “SB 1047 Veto Party.” One attendee told me, “Thank god, AI is still legal.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now Wiener has returned with a new AI safety bill, SB 53, which sits on Governor Newsom’s desk awaiting his signature or veto sometime in the next few weeks. This time around, the bill is much more popular or at least, Silicon Valley doesn’t seem to be at war with it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic outright endorsed SB 53 earlier this month. Meta spokesperson Jim Cullinan tells TechCrunch that the company supports AI regulation that balances guardrails with innovation and says, “SB 53 is a step in that direction,” though there are areas for improvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Former White House AI policy adviser Dean Ball tells TechCrunch that SB 53 is a “victory for reasonable voices,” and thinks there’s a strong chance Governor Newsom signs it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed, SB 53 would impose some of the nation’s first safety reporting requirements on AI giants like OpenAI, Anthropic, xAI, and Google — companies that today face no obligation to reveal how they test their AI systems. Many AI labs voluntarily publish safety reports explaining how their AI models could be used to create bioweapons and other dangers, but they do this at will and they’re not always consistent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill requires leading AI labs — specifically those making more than $500 million in revenue — to publish safety reports for their most capable AI models. Much like SB 1047, the bill specifically focuses on the worst kinds of AI risks: their ability to contribute to human deaths, cyberattacks, and chemical weapons. Governor Newsom is considering several other bills that address other types of AI risks, such as engagement-optimization techniques in AI companions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 also creates protected channels for employees working at AI labs to report safety concerns to government officials, and establishes a state-operated cloud computing cluster, CalCompute, to provide AI research resources beyond the Big Tech companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One reason SB 53 may be more popular than SB 1047 is that it’s less severe. SB 1047 also would have made AI companies liable for any harms caused by their AI models, whereas SB 53 focuses more on requiring self-reporting and transparency. SB 53 also narrowly applies to the world’s largest tech companies, rather than startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But many in the tech industry still believe states should leave AI regulation up to the federal government. In a recent letter to Governor Newsom, OpenAI argued that AI labs should only have to comply with federal standards — which is a funny thing to say to a state governor. Venture firm Andreessen Horowitz wrote a recent blog post vaguely suggesting that some bills in California could violate the Constitution’s dormant Commerce Clause, which prohibits states from unfairly limiting interstate commerce.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener addresses these concerns: He lacks faith in the federal government to pass meaningful AI safety regulation, so states need to step up. In fact, Wiener thinks the Trump administration has been captured by the tech industry and that recent federal efforts to block all state AI laws are a form of Trump “rewarding his funders.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has made a notable shift away from the Biden administration’s focus on AI safety, replacing it with an emphasis on growth. Shortly after taking office, Vice President J.D. Vance appeared at an AI conference in Paris and said: “I’m not here this morning to talk about AI safety, which was the title of the conference a couple of years ago. I’m here to talk about AI opportunity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silicon Valley has applauded this shift, exemplified by Trump’s AI Action Plan, which removed barriers to building out the infrastructure needed to train and serve AI models. Today, Big Tech CEOs are regularly seen dining at the White House or announcing hundred-billion-dollar data centers alongside President Trump.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Senator Wiener thinks it’s critical for California to lead the nation on AI safety, but without choking off innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I recently interviewed Senator Wiener to discuss his years at the negotiating table with Silicon Valley and why he’s so focused on AI safety bills. Our conversation has been edited lightly for clarity and brevity. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Senator Wiener, I interviewed you when SB 1047 was sitting on Governor Newsom’s desk. Talk to me about the journey you’ve been on to regulate AI safety in the last few years&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s been a roller coaster, an incredible learning experience, and just really rewarding. We’ve been able to help elevate this issue [of AI safety], not just in California, but in the national and international discourse.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have this incredibly powerful new technology that is changing the world. How do we make sure it benefits humanity in a way where we reduce the risk? How do we promote innovation, while also being very mindful of public health and public safety. It’s an important — and in some ways, existential — conversation about the future. SB 1047, and now SB 53, have helped to foster that conversation about safe innovation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;In the last 20 years of technology, what have you learned about the importance of laws that can hold Silicon Valley to account?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’m the guy who represents San Francisco, the beating heart of AI innovation. I’m immediately north of Silicon Valley itself, so we’re right here in the middle of it all. But we’ve also seen how the large tech companies — some of the wealthiest companies in world history — have been able to stop federal regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Every time I see tech CEOs having dinner at the White House with the aspiring fascist dictator, I have to take a deep breath. These are all really brilliant people who have generated enormous wealth. A lot of folks I represent work for them. It really pains me when I see the deals that are being struck with Saudi Arabia and the United Arab Emirates, and how that money gets funneled into Trump’s meme coin. It causes me deep concern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’m not someone who’s anti-tech. I want tech innovation to happen. It’s incredibly important. But this is an industry that we should not trust to regulate itself or make voluntary commitments. And that’s not casting aspersions on anyone. This is capitalism, and it can create enormous prosperity but also cause harm if there are not sensible regulations to protect the public interest. When it comes to AI safety, we’re trying to thread that needle.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;SB 53 is focused on the worst harms that AI could imaginably cause — death, massive cyberattacks, and the creation of bioweapons. Why focus there?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The risks of AI are varied. There is algorithmic discrimination, job loss, deep fakes, and scams. There have been various bills in California and elsewhere to address those risks. SB 53 was never intended to cover the field and address every risk created by AI. We’re focused on one specific category of risk, in terms of catastrophic risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That issue came to me organically from folks in the AI space in San Francisco — startup founders, frontline AI technologists, and people who are building these models. They came to me and said, “This is an issue that needs to be addressed in a thoughtful way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do you feel that AI systems are inherently unsafe, or have the potential to cause death and massive cyberattacks?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I don’t think they’re inherently safe. I know there are a lot of people working in these labs who care very deeply about trying to mitigate risk. And again, it’s not about eliminating risk. Life is about risk, unless you’re going to live in your basement and never leave, you’re going to have risk in your life. Even in your basement, the ceiling might fall down.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Is there a risk that some AI models could be used to do significant harm to society? Yes, and we know there are people who would love to do that. We should try to make it harder for bad actors to cause these severe harms, and so should the people developing these models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anthropic issued its support for SB 53. What are your conversations like with other industry players?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ve talked to everyone: large companies, small startups, investors, and academics. Anthropic has been really constructive. Last year, they never formally supported [SB 1047] but they had positive things to say about aspects of the bill. I don’t think [Anthropic] loves every aspect of SB 53, but I think they concluded that on balance the bill was worth supporting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’ve had conversations with large AI labs who are not supporting the bill, but are not at war with it in the way they were with SB 1047. It’s not surprising. SB 1047 was more of a liability bill, SB 53 is more of a transparency bill. Startups have been less engaged this year because the bill really focuses on the largest companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do you feel pressure from the large AI PACs that have formed in recent months?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is another symptom of Citizens United. The wealthiest companies in the world can just pour endless resources into these PACs to try to intimidate elected officials. Under the rules we have, they have every right to do that. It’s never really impacted how I approach policy. There have been groups trying to destroy me for as long as I’ve been in elected office. Various groups have spent millions trying to blow me up, and here I am. I’m in this to do right by my constituents and try to make my community, San Francisco, and the world a better place. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s your message to Governor Newsom as he’s debating whether to sign or veto this bill?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My message is that we heard you. You vetoed SB 1047 and provided a very comprehensive and thoughtful veto message. You wisely convened a working group that produced a very strong report, and we really looked to that report in crafting this bill. The governor laid out a path, and we followed that path in order to come to an agreement, and I hope we got there.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2218026592.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;This is not California state senator Scott Wiener’s first attempt at addressing the dangers of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2024, Silicon Valley mounted a fierce campaign against his controversial AI safety bill, SB 1047, which would have made tech companies liable for the potential harms of their AI systems. Tech leaders warned that it would stifle America’s AI boom. Governor Gavin Newsom ultimately vetoed the bill, echoing similar concerns, and a popular AI hacker house promptly threw an “SB 1047 Veto Party.” One attendee told me, “Thank god, AI is still legal.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now Wiener has returned with a new AI safety bill, SB 53, which sits on Governor Newsom’s desk awaiting his signature or veto sometime in the next few weeks. This time around, the bill is much more popular or at least, Silicon Valley doesn’t seem to be at war with it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic outright endorsed SB 53 earlier this month. Meta spokesperson Jim Cullinan tells TechCrunch that the company supports AI regulation that balances guardrails with innovation and says, “SB 53 is a step in that direction,” though there are areas for improvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Former White House AI policy adviser Dean Ball tells TechCrunch that SB 53 is a “victory for reasonable voices,” and thinks there’s a strong chance Governor Newsom signs it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed, SB 53 would impose some of the nation’s first safety reporting requirements on AI giants like OpenAI, Anthropic, xAI, and Google — companies that today face no obligation to reveal how they test their AI systems. Many AI labs voluntarily publish safety reports explaining how their AI models could be used to create bioweapons and other dangers, but they do this at will and they’re not always consistent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill requires leading AI labs — specifically those making more than $500 million in revenue — to publish safety reports for their most capable AI models. Much like SB 1047, the bill specifically focuses on the worst kinds of AI risks: their ability to contribute to human deaths, cyberattacks, and chemical weapons. Governor Newsom is considering several other bills that address other types of AI risks, such as engagement-optimization techniques in AI companions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 also creates protected channels for employees working at AI labs to report safety concerns to government officials, and establishes a state-operated cloud computing cluster, CalCompute, to provide AI research resources beyond the Big Tech companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One reason SB 53 may be more popular than SB 1047 is that it’s less severe. SB 1047 also would have made AI companies liable for any harms caused by their AI models, whereas SB 53 focuses more on requiring self-reporting and transparency. SB 53 also narrowly applies to the world’s largest tech companies, rather than startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But many in the tech industry still believe states should leave AI regulation up to the federal government. In a recent letter to Governor Newsom, OpenAI argued that AI labs should only have to comply with federal standards — which is a funny thing to say to a state governor. Venture firm Andreessen Horowitz wrote a recent blog post vaguely suggesting that some bills in California could violate the Constitution’s dormant Commerce Clause, which prohibits states from unfairly limiting interstate commerce.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener addresses these concerns: He lacks faith in the federal government to pass meaningful AI safety regulation, so states need to step up. In fact, Wiener thinks the Trump administration has been captured by the tech industry and that recent federal efforts to block all state AI laws are a form of Trump “rewarding his funders.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has made a notable shift away from the Biden administration’s focus on AI safety, replacing it with an emphasis on growth. Shortly after taking office, Vice President J.D. Vance appeared at an AI conference in Paris and said: “I’m not here this morning to talk about AI safety, which was the title of the conference a couple of years ago. I’m here to talk about AI opportunity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silicon Valley has applauded this shift, exemplified by Trump’s AI Action Plan, which removed barriers to building out the infrastructure needed to train and serve AI models. Today, Big Tech CEOs are regularly seen dining at the White House or announcing hundred-billion-dollar data centers alongside President Trump.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Senator Wiener thinks it’s critical for California to lead the nation on AI safety, but without choking off innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I recently interviewed Senator Wiener to discuss his years at the negotiating table with Silicon Valley and why he’s so focused on AI safety bills. Our conversation has been edited lightly for clarity and brevity. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Senator Wiener, I interviewed you when SB 1047 was sitting on Governor Newsom’s desk. Talk to me about the journey you’ve been on to regulate AI safety in the last few years&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s been a roller coaster, an incredible learning experience, and just really rewarding. We’ve been able to help elevate this issue [of AI safety], not just in California, but in the national and international discourse.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have this incredibly powerful new technology that is changing the world. How do we make sure it benefits humanity in a way where we reduce the risk? How do we promote innovation, while also being very mindful of public health and public safety. It’s an important — and in some ways, existential — conversation about the future. SB 1047, and now SB 53, have helped to foster that conversation about safe innovation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;In the last 20 years of technology, what have you learned about the importance of laws that can hold Silicon Valley to account?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’m the guy who represents San Francisco, the beating heart of AI innovation. I’m immediately north of Silicon Valley itself, so we’re right here in the middle of it all. But we’ve also seen how the large tech companies — some of the wealthiest companies in world history — have been able to stop federal regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Every time I see tech CEOs having dinner at the White House with the aspiring fascist dictator, I have to take a deep breath. These are all really brilliant people who have generated enormous wealth. A lot of folks I represent work for them. It really pains me when I see the deals that are being struck with Saudi Arabia and the United Arab Emirates, and how that money gets funneled into Trump’s meme coin. It causes me deep concern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’m not someone who’s anti-tech. I want tech innovation to happen. It’s incredibly important. But this is an industry that we should not trust to regulate itself or make voluntary commitments. And that’s not casting aspersions on anyone. This is capitalism, and it can create enormous prosperity but also cause harm if there are not sensible regulations to protect the public interest. When it comes to AI safety, we’re trying to thread that needle.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;SB 53 is focused on the worst harms that AI could imaginably cause — death, massive cyberattacks, and the creation of bioweapons. Why focus there?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The risks of AI are varied. There is algorithmic discrimination, job loss, deep fakes, and scams. There have been various bills in California and elsewhere to address those risks. SB 53 was never intended to cover the field and address every risk created by AI. We’re focused on one specific category of risk, in terms of catastrophic risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That issue came to me organically from folks in the AI space in San Francisco — startup founders, frontline AI technologists, and people who are building these models. They came to me and said, “This is an issue that needs to be addressed in a thoughtful way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do you feel that AI systems are inherently unsafe, or have the potential to cause death and massive cyberattacks?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I don’t think they’re inherently safe. I know there are a lot of people working in these labs who care very deeply about trying to mitigate risk. And again, it’s not about eliminating risk. Life is about risk, unless you’re going to live in your basement and never leave, you’re going to have risk in your life. Even in your basement, the ceiling might fall down.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Is there a risk that some AI models could be used to do significant harm to society? Yes, and we know there are people who would love to do that. We should try to make it harder for bad actors to cause these severe harms, and so should the people developing these models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anthropic issued its support for SB 53. What are your conversations like with other industry players?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ve talked to everyone: large companies, small startups, investors, and academics. Anthropic has been really constructive. Last year, they never formally supported [SB 1047] but they had positive things to say about aspects of the bill. I don’t think [Anthropic] loves every aspect of SB 53, but I think they concluded that on balance the bill was worth supporting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I’ve had conversations with large AI labs who are not supporting the bill, but are not at war with it in the way they were with SB 1047. It’s not surprising. SB 1047 was more of a liability bill, SB 53 is more of a transparency bill. Startups have been less engaged this year because the bill really focuses on the largest companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do you feel pressure from the large AI PACs that have formed in recent months?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is another symptom of Citizens United. The wealthiest companies in the world can just pour endless resources into these PACs to try to intimidate elected officials. Under the rules we have, they have every right to do that. It’s never really impacted how I approach policy. There have been groups trying to destroy me for as long as I’ve been in elected office. Various groups have spent millions trying to blow me up, and here I am. I’m in this to do right by my constituents and try to make my community, San Francisco, and the world a better place. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s your message to Governor Newsom as he’s debating whether to sign or veto this bill?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My message is that we heard you. You vetoed SB 1047 and provided a very comprehensive and thoughtful veto message. You wisely convened a working group that produced a very strong report, and we really looked to that report in crafting this bill. The governor laid out a path, and we followed that path in order to come to an agreement, and I hope we got there.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/23/scott-wiener-on-his-fight-to-make-big-tech-disclose-ais-dangers/</guid><pubDate>Tue, 23 Sep 2025 20:21:06 +0000</pubDate></item><item><title>Google Cloud’s COO isn’t stressed about landing the AI giants (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/google-clouds-coo-isnt-stressed-about-landing-the-ai-giants/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-1252207431.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, TechCrunch Editor-in-Chief Connie Loizos is joined by Francis deSouza, the renowned entrepreneur, operator, and, since January, COO of Google Cloud. They discuss his goals for Google Cloud and how the company maintains its competitive position by focusing on startups while giants like AWS and Oracle snap up major deals with leading AI companies — namely, OpenAI and Anthropic.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;The conversation also covers the tangled web of relationships in the AI ecosystem, where companies like Google Cloud provide infrastructure services while their parent companies compete fiercely in generative AI, even as those same parents hold investment stakes in their supposed rivals. They also discuss how Google Cloud approaches the GPU shortage as part of its strategy to attract customers — and keep them coming back for more.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-1252207431.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, TechCrunch Editor-in-Chief Connie Loizos is joined by Francis deSouza, the renowned entrepreneur, operator, and, since January, COO of Google Cloud. They discuss his goals for Google Cloud and how the company maintains its competitive position by focusing on startups while giants like AWS and Oracle snap up major deals with leading AI companies — namely, OpenAI and Anthropic.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;The conversation also covers the tangled web of relationships in the AI ecosystem, where companies like Google Cloud provide infrastructure services while their parent companies compete fiercely in generative AI, even as those same parents hold investment stakes in their supposed rivals. They also discuss how Google Cloud approaches the GPU shortage as part of its strategy to attract customers — and keep them coming back for more.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/google-clouds-coo-isnt-stressed-about-landing-the-ai-giants/</guid><pubDate>Tue, 23 Sep 2025 20:53:16 +0000</pubDate></item><item><title>Google’s AI Mode arrives in Spanish globally (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/23/googles-ai-mode-arrives-in-spanish-globally/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/google-ai-mode-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Search is bringing its AI Mode feature — its AI-powered search experience — to Spanish-speaking users, the company announced on Tuesday. This expansion will introduce Google’s conversational search interface to a broader market, allowing users to ask questions using natural language queries, engage in back-and-forth conversations, upload images, dig deeper on complex topics, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Spanish-language rollout comes on the heels of Google’s major AI Mode expansion in August, when the company released the feature to 180 more countries worldwide. Previously, it had only been available in the U.S., U.K., and India. During that August rollout, Google also introduced advanced AI capabilities to its Google AI Ultra subscribers, allowing them to request restaurant reservations in AI Mode. The company plans to introduce support for other types of appointments and event ticket purchases in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google has been rapidly rolling out AI across its products and services, often with multiple product announcements occurring simultaneously. For instance, the company announced Tuesday that it was bringing conversational photo editing to all Android users in the U.S. It also announced the same day that its more affordable Google AI Plus subscription plan, first introduced in Indonesia, is now arriving in 40 more countries. This expansion follows OpenAI’s recent launch of its ChatGPT’s Go plan, which launched in India in August and in Indonesia on Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT Go plan is a mid-tier subscription option that sits between OpenAI’s free version and its premium $20-per-month ChatGPT Plus plan. Users get 10 times higher usage limits than the free plan for sending questions or prompts, generating images, and uploading files. According to OpenAI, the plan also allows ChatGPT to remember previous conversations better, enabling more personalized responses over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google&amp;nbsp;announced&amp;nbsp;earlier this month that AI Mode also now supports Hindi, Indonesian, Japanese, Korean, and Brazilian Portuguese.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With so many products, users may find it hard to distinguish between different features and functionality, like the difference between Google’s AI Mode and its AI Overviews. The former is a separate, immersive, and conversational experience where users chat directly with Gemini AI. Meanwhile, AI Overviews simply offer a quick, AI-generated summary of information about your search query at the top of Google’s Search results.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/google-ai-mode-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Search is bringing its AI Mode feature — its AI-powered search experience — to Spanish-speaking users, the company announced on Tuesday. This expansion will introduce Google’s conversational search interface to a broader market, allowing users to ask questions using natural language queries, engage in back-and-forth conversations, upload images, dig deeper on complex topics, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Spanish-language rollout comes on the heels of Google’s major AI Mode expansion in August, when the company released the feature to 180 more countries worldwide. Previously, it had only been available in the U.S., U.K., and India. During that August rollout, Google also introduced advanced AI capabilities to its Google AI Ultra subscribers, allowing them to request restaurant reservations in AI Mode. The company plans to introduce support for other types of appointments and event ticket purchases in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google has been rapidly rolling out AI across its products and services, often with multiple product announcements occurring simultaneously. For instance, the company announced Tuesday that it was bringing conversational photo editing to all Android users in the U.S. It also announced the same day that its more affordable Google AI Plus subscription plan, first introduced in Indonesia, is now arriving in 40 more countries. This expansion follows OpenAI’s recent launch of its ChatGPT’s Go plan, which launched in India in August and in Indonesia on Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT Go plan is a mid-tier subscription option that sits between OpenAI’s free version and its premium $20-per-month ChatGPT Plus plan. Users get 10 times higher usage limits than the free plan for sending questions or prompts, generating images, and uploading files. According to OpenAI, the plan also allows ChatGPT to remember previous conversations better, enabling more personalized responses over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google&amp;nbsp;announced&amp;nbsp;earlier this month that AI Mode also now supports Hindi, Indonesian, Japanese, Korean, and Brazilian Portuguese.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With so many products, users may find it hard to distinguish between different features and functionality, like the difference between Google’s AI Mode and its AI Overviews. The former is a separate, immersive, and conversational experience where users chat directly with Gemini AI. Meanwhile, AI Overviews simply offer a quick, AI-generated summary of information about your search query at the top of Google’s Search results.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/23/googles-ai-mode-arrives-in-spanish-globally/</guid><pubDate>Tue, 23 Sep 2025 21:18:32 +0000</pubDate></item><item><title>When “no” means “yes”: Why AI chatbots can’t process Persian social etiquette (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/when-no-means-yes-why-ai-chatbots-cant-process-persian-social-etiquette/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study examines how a helpful AI response could become a cultural disaster in Iran.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="People at Tehran Grand Bazaar market in May 2017." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/tehran_market-640x360.jpg" width="640" /&gt;
                  &lt;img alt="People at Tehran Grand Bazaar market in May 2017." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/tehran_market-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      People at Tehran Grand Bazaar market in May 2017.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          joyt via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;If an Iranian taxi driver waves away your payment, saying, "Be my guest this time," accepting their offer would be a cultural disaster. They expect you to insist on paying—probably three times—before they'll take your money. This dance of refusal and counter-refusal, called taarof, governs countless daily interactions in Persian culture. And AI models are terrible at it.&lt;/p&gt;
&lt;p&gt;New research&amp;nbsp;released earlier this month titled "We Politely Insist: Your LLM Must Learn the Persian Art of Taarof" shows that mainstream AI language models from OpenAI, Anthropic, and Meta fail to absorb these Persian social rituals, correctly navigating taarof situations only 34 to 42 percent of the time. Native Persian speakers, by contrast, get it right 82 percent of the time. This performance gap persists across large language models such as GPT-4o, Claude 3.5 Haiku, Llama 3, DeepSeek V3, and Dorna, a Persian-tuned variant of Llama 3.&lt;/p&gt;
&lt;p&gt;A study led by Nikta Gohari Sadr of Brock University, along with researchers from Emory University and other institutions, introduces "TAAROFBENCH," the first benchmark for measuring how well AI systems reproduce this intricate cultural practice. The researchers' findings show how recent AI models default to Western-style directness, completely missing the cultural cues that govern everyday interactions for millions of Persian speakers worldwide.&lt;/p&gt;
&lt;p&gt;"Cultural missteps in high-consequence settings can derail negotiations, damage relationships, and reinforce stereotypes," the researchers write. For AI systems increasingly used in global contexts, that cultural blindness could represent a limitation that few in the West realize exists.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2118657 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A taarof scenario diagram from TAAROFBENCH, devised by the researchers. Each scenario defines the environment, location, roles, context, and user utterance." class="fullwidth full" height="825" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/taarof_illustration.jpg" width="748" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A taarof scenario diagram from TAAROFBENCH, devised by the researchers. Each scenario defines the environment, location, roles, context, and user utterance.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadr et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;"Taarof, a core element of Persian etiquette, is a system of ritual politeness where what is said often differs from what is meant," the researchers write. "It takes the form of ritualized exchanges: offering repeatedly despite initial refusals, declining gifts while the giver insists, and deflecting compliments while the other party reaffirms them. This 'polite verbal wrestling' (Rafiee, 1991) involves a delicate dance of offer and refusal, insistence and resistance, which shapes everyday interactions in Iranian culture, creating implicit rules for how generosity, gratitude, and requests are expressed."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Politeness is context-dependent&lt;/h2&gt;
&lt;p&gt;To test whether being "polite" was enough for cultural competence, researchers compared Llama 3 responses using Polite Guard, an Intel-developed classifier that rates text politeness. The results revealed a paradox: 84.5 percent of responses registered as "polite" or "somewhat polite," yet only 41.7 percent of those same responses actually met Persian cultural expectations in taarof scenarios.&lt;/p&gt;
&lt;p&gt;This 42.8 percentage point gap shows how an LLM response can be simultaneously polite in one context and culturally tone-deaf in another. Common failures included accepting offers without initial refusal, responding directly to compliments rather than deflecting them, and making direct requests without hesitation.&lt;/p&gt;
&lt;p&gt;Consider what might happen if someone compliments an Iranian's new car. The culturally appropriate response might involve downplaying the purchase ("It's nothing special") or deflecting credit ("I was just lucky to find it"). AI models tend to generate responses like "Thank you! I worked hard to afford it," which is perfectly polite by Western standards, but might be perceived as boastful in Persian culture.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Found in translation&lt;/h2&gt;
&lt;p&gt;In a way, human language acts as a compression and decompression scheme—the listener must decompress the meaning of words in the same way the speaker intended when encoding the message for them to be properly understood. This process relies on shared context, cultural knowledge, and inference, as speakers routinely omit information they expect listeners can reconstruct, while listeners must actively fill in unstated assumptions, resolve ambiguities, and infer intentions beyond the literal words spoken.&lt;/p&gt;
&lt;p&gt;While compression makes communication faster by leaving implied information unsaid, it also opens the door for dramatic misunderstandings when that shared context between speaker and listener doesn't exist.&lt;/p&gt;
&lt;p&gt;Similarly, taarof represents a case of heavy cultural compression where the literal message and intended meaning diverge enough that LLMs—trained primarily on explicit Western communication patterns—typically fail to process the Persian cultural context that "yes" can mean "no," an offer can be a refusal, and insistence can be courtesy rather than coercion.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Since LLMs are pattern-matching machines, it makes sense that when the researchers prompted them in Persian rather than English, scores improved. DeepSeek V3's accuracy on taarof scenarios jumped from 36.6 percent to 68.6 percent. GPT-4o showed similar gains, improving by 33.1 percentage points. The language switch apparently activated different Persian-language training data patterns that better matched these cultural encoding schemes, though smaller models like Llama 3 and Dorna showed more modest improvements of 12.8 and 11 points, respectively.&lt;/p&gt;
&lt;p&gt;The study included 33 human participants divided equally among native Persian speakers, heritage speakers (people of Persian descent raised with exposure to Persian at home but educated primarily in English), and non-Iranians. Native speakers achieved 81.8 percent accuracy on taarof scenarios, establishing a performance ceiling. Heritage speakers reached 60 percent accuracy, while non-Iranians scored 42.3 percent, nearly matching base model performance. Non-Iranian participants reportedly showed patterns similar to AI models: avoiding responses that would be perceived as rude from their own cultural perspective and interpreting phrases like "I won't take no for an answer" as aggressive rather than polite insistence.&lt;/p&gt;
&lt;p&gt;The research also uncovered gender-specific patterns in the AI model outputs while measuring how often the AI models provided culturally appropriate responses that aligned with taarof expectations. All tested models received higher scores when responding to women than men, with GPT-4o showing 43.6 percent accuracy for female users versus 30.9 percent for male users. The language models frequently supported their responses using gender stereotype patterns typically found in training data, stating that "men should pay" or "women shouldn't be left alone" even when taarof norms apply equally regardless of gender. "Despite the model's role never being assigned a gender in our prompts, models frequently assume a male identity and adopt stereotypically masculine behaviors in their responses," the researchers noted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Teaching cultural nuance&lt;/h2&gt;
&lt;p&gt;The parallel between non-Iranian humans and AI models found by the researchers suggests these aren't just technical failures but fundamental deficiencies in decoding meaning in cross-cultural contexts. The researchers didn't stop at documenting the problem—they tested whether AI models could learn taarof through targeted training.&lt;/p&gt;
&lt;p&gt;In trials, the researchers reported substantial improvements in taarof scores through targeted adaptation. A technique called "Direct Preference Optimization" (a training technique where you teach an AI model to prefer certain types of responses over others by showing it pairs of examples) doubled Llama 3's performance on taarof scenarios, raising accuracy from 37.2 percent to 79.5 percent. Supervised fine-tuning (training the model on examples of correct responses) produced a 20 percent gain, while simple in-context learning with 12 examples improved performance by 20 points.&lt;/p&gt;
&lt;p&gt;While the study focused on Persian taarof, the methodology potentially offers a template for evaluating cultural decoding in other low-resource traditions that might not be well-represented in standard, Western-dominated AI training datasets. The researchers suggest their approach could inform the development of more culturally aware AI systems for education, tourism, and international communication applications.&lt;/p&gt;
&lt;p&gt;These findings highlight a more significant aspect of how AI systems encode and perpetuate cultural assumptions, as well as where decoding errors might occur in the human reader's mind. It's likely that LLMs possess many contextual cultural blind spots that researchers have not tested and that may have significant impacts if LLMs are used to facilitate translations between cultures and languages. The researchers' work represents an early step toward AI systems that might better navigate a wider diversity of human communication patterns beyond Western norms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study examines how a helpful AI response could become a cultural disaster in Iran.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="People at Tehran Grand Bazaar market in May 2017." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/tehran_market-640x360.jpg" width="640" /&gt;
                  &lt;img alt="People at Tehran Grand Bazaar market in May 2017." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/tehran_market-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      People at Tehran Grand Bazaar market in May 2017.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          joyt via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;If an Iranian taxi driver waves away your payment, saying, "Be my guest this time," accepting their offer would be a cultural disaster. They expect you to insist on paying—probably three times—before they'll take your money. This dance of refusal and counter-refusal, called taarof, governs countless daily interactions in Persian culture. And AI models are terrible at it.&lt;/p&gt;
&lt;p&gt;New research&amp;nbsp;released earlier this month titled "We Politely Insist: Your LLM Must Learn the Persian Art of Taarof" shows that mainstream AI language models from OpenAI, Anthropic, and Meta fail to absorb these Persian social rituals, correctly navigating taarof situations only 34 to 42 percent of the time. Native Persian speakers, by contrast, get it right 82 percent of the time. This performance gap persists across large language models such as GPT-4o, Claude 3.5 Haiku, Llama 3, DeepSeek V3, and Dorna, a Persian-tuned variant of Llama 3.&lt;/p&gt;
&lt;p&gt;A study led by Nikta Gohari Sadr of Brock University, along with researchers from Emory University and other institutions, introduces "TAAROFBENCH," the first benchmark for measuring how well AI systems reproduce this intricate cultural practice. The researchers' findings show how recent AI models default to Western-style directness, completely missing the cultural cues that govern everyday interactions for millions of Persian speakers worldwide.&lt;/p&gt;
&lt;p&gt;"Cultural missteps in high-consequence settings can derail negotiations, damage relationships, and reinforce stereotypes," the researchers write. For AI systems increasingly used in global contexts, that cultural blindness could represent a limitation that few in the West realize exists.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2118657 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A taarof scenario diagram from TAAROFBENCH, devised by the researchers. Each scenario defines the environment, location, roles, context, and user utterance." class="fullwidth full" height="825" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/taarof_illustration.jpg" width="748" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A taarof scenario diagram from TAAROFBENCH, devised by the researchers. Each scenario defines the environment, location, roles, context, and user utterance.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadr et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;"Taarof, a core element of Persian etiquette, is a system of ritual politeness where what is said often differs from what is meant," the researchers write. "It takes the form of ritualized exchanges: offering repeatedly despite initial refusals, declining gifts while the giver insists, and deflecting compliments while the other party reaffirms them. This 'polite verbal wrestling' (Rafiee, 1991) involves a delicate dance of offer and refusal, insistence and resistance, which shapes everyday interactions in Iranian culture, creating implicit rules for how generosity, gratitude, and requests are expressed."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Politeness is context-dependent&lt;/h2&gt;
&lt;p&gt;To test whether being "polite" was enough for cultural competence, researchers compared Llama 3 responses using Polite Guard, an Intel-developed classifier that rates text politeness. The results revealed a paradox: 84.5 percent of responses registered as "polite" or "somewhat polite," yet only 41.7 percent of those same responses actually met Persian cultural expectations in taarof scenarios.&lt;/p&gt;
&lt;p&gt;This 42.8 percentage point gap shows how an LLM response can be simultaneously polite in one context and culturally tone-deaf in another. Common failures included accepting offers without initial refusal, responding directly to compliments rather than deflecting them, and making direct requests without hesitation.&lt;/p&gt;
&lt;p&gt;Consider what might happen if someone compliments an Iranian's new car. The culturally appropriate response might involve downplaying the purchase ("It's nothing special") or deflecting credit ("I was just lucky to find it"). AI models tend to generate responses like "Thank you! I worked hard to afford it," which is perfectly polite by Western standards, but might be perceived as boastful in Persian culture.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Found in translation&lt;/h2&gt;
&lt;p&gt;In a way, human language acts as a compression and decompression scheme—the listener must decompress the meaning of words in the same way the speaker intended when encoding the message for them to be properly understood. This process relies on shared context, cultural knowledge, and inference, as speakers routinely omit information they expect listeners can reconstruct, while listeners must actively fill in unstated assumptions, resolve ambiguities, and infer intentions beyond the literal words spoken.&lt;/p&gt;
&lt;p&gt;While compression makes communication faster by leaving implied information unsaid, it also opens the door for dramatic misunderstandings when that shared context between speaker and listener doesn't exist.&lt;/p&gt;
&lt;p&gt;Similarly, taarof represents a case of heavy cultural compression where the literal message and intended meaning diverge enough that LLMs—trained primarily on explicit Western communication patterns—typically fail to process the Persian cultural context that "yes" can mean "no," an offer can be a refusal, and insistence can be courtesy rather than coercion.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Since LLMs are pattern-matching machines, it makes sense that when the researchers prompted them in Persian rather than English, scores improved. DeepSeek V3's accuracy on taarof scenarios jumped from 36.6 percent to 68.6 percent. GPT-4o showed similar gains, improving by 33.1 percentage points. The language switch apparently activated different Persian-language training data patterns that better matched these cultural encoding schemes, though smaller models like Llama 3 and Dorna showed more modest improvements of 12.8 and 11 points, respectively.&lt;/p&gt;
&lt;p&gt;The study included 33 human participants divided equally among native Persian speakers, heritage speakers (people of Persian descent raised with exposure to Persian at home but educated primarily in English), and non-Iranians. Native speakers achieved 81.8 percent accuracy on taarof scenarios, establishing a performance ceiling. Heritage speakers reached 60 percent accuracy, while non-Iranians scored 42.3 percent, nearly matching base model performance. Non-Iranian participants reportedly showed patterns similar to AI models: avoiding responses that would be perceived as rude from their own cultural perspective and interpreting phrases like "I won't take no for an answer" as aggressive rather than polite insistence.&lt;/p&gt;
&lt;p&gt;The research also uncovered gender-specific patterns in the AI model outputs while measuring how often the AI models provided culturally appropriate responses that aligned with taarof expectations. All tested models received higher scores when responding to women than men, with GPT-4o showing 43.6 percent accuracy for female users versus 30.9 percent for male users. The language models frequently supported their responses using gender stereotype patterns typically found in training data, stating that "men should pay" or "women shouldn't be left alone" even when taarof norms apply equally regardless of gender. "Despite the model's role never being assigned a gender in our prompts, models frequently assume a male identity and adopt stereotypically masculine behaviors in their responses," the researchers noted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Teaching cultural nuance&lt;/h2&gt;
&lt;p&gt;The parallel between non-Iranian humans and AI models found by the researchers suggests these aren't just technical failures but fundamental deficiencies in decoding meaning in cross-cultural contexts. The researchers didn't stop at documenting the problem—they tested whether AI models could learn taarof through targeted training.&lt;/p&gt;
&lt;p&gt;In trials, the researchers reported substantial improvements in taarof scores through targeted adaptation. A technique called "Direct Preference Optimization" (a training technique where you teach an AI model to prefer certain types of responses over others by showing it pairs of examples) doubled Llama 3's performance on taarof scenarios, raising accuracy from 37.2 percent to 79.5 percent. Supervised fine-tuning (training the model on examples of correct responses) produced a 20 percent gain, while simple in-context learning with 12 examples improved performance by 20 points.&lt;/p&gt;
&lt;p&gt;While the study focused on Persian taarof, the methodology potentially offers a template for evaluating cultural decoding in other low-resource traditions that might not be well-represented in standard, Western-dominated AI training datasets. The researchers suggest their approach could inform the development of more culturally aware AI systems for education, tourism, and international communication applications.&lt;/p&gt;
&lt;p&gt;These findings highlight a more significant aspect of how AI systems encode and perpetuate cultural assumptions, as well as where decoding errors might occur in the human reader's mind. It's likely that LLMs possess many contextual cultural blind spots that researchers have not tested and that may have significant impacts if LLMs are used to facilitate translations between cultures and languages. The researchers' work represents an early step toward AI systems that might better navigate a wider diversity of human communication patterns beyond Western norms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/when-no-means-yes-why-ai-chatbots-cant-process-persian-social-etiquette/</guid><pubDate>Tue, 23 Sep 2025 22:23:22 +0000</pubDate></item><item><title>OpenAI is building five new Stargate data centers with Oracle and SoftBank (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/23/openai-is-building-five-new-stargate-data-centers-with-oracle-and-softbank/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2194585046.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced on Tuesday that it plans to build five new AI data centers across the United States with partners Oracle and SoftBank through its Stargate project. The new data centers will bring Stargate’s planned capacity to 7 gigawatts — enough energy to power more than 5 million homes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three of the new sites are being developed with Oracle. They’re located in Shackelford County, Texas; Doña Ana County, New Mexico;&amp;nbsp;and an undisclosed location in the Midwest. The other two sites are being developed with SoftBank, with one in Lordstown, Ohio, and the other in Milam County, Texas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Stargate AI data centers are part of OpenAI’s massive infrastructure buildout, as the company works to train and serve more powerful AI models. On Monday, OpenAI said it would receive a $100 billion investment from Nvidia to buy the chipmaker’s AI processors and build out even more AI data centers.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2194585046.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced on Tuesday that it plans to build five new AI data centers across the United States with partners Oracle and SoftBank through its Stargate project. The new data centers will bring Stargate’s planned capacity to 7 gigawatts — enough energy to power more than 5 million homes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three of the new sites are being developed with Oracle. They’re located in Shackelford County, Texas; Doña Ana County, New Mexico;&amp;nbsp;and an undisclosed location in the Midwest. The other two sites are being developed with SoftBank, with one in Lordstown, Ohio, and the other in Milam County, Texas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Stargate AI data centers are part of OpenAI’s massive infrastructure buildout, as the company works to train and serve more powerful AI models. On Monday, OpenAI said it would receive a $100 billion investment from Nvidia to buy the chipmaker’s AI processors and build out even more AI data centers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/23/openai-is-building-five-new-stargate-data-centers-with-oracle-and-softbank/</guid><pubDate>Tue, 23 Sep 2025 22:24:17 +0000</pubDate></item><item><title>[NEW] Improving the workplace of the future (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/improving-workplace-future-whitney-zhang-0924</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Whitney Zhang ’21 believes in the importance of valuing workers regardless of where they fit into an organizational chart.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang is a PhD student in MIT’s&amp;nbsp;Department of Economics studying labor economics. She explores how the technological and managerial decisions companies make affect workers across the pay spectrum.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“I’ve been interested in economics, economic impacts, and related social issues for a long time,” says Zhang, who majored in mathematical economics as an undergraduate. “I wanted to apply my math skills to see how we could improve policies and their effects.”&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang is interested in how to improve conditions for workers. She believes it’s important to build relationships with policymakers, focusing on an evidence-driven approach to policy, while always remembering to center those the policies may affect. “We have to remember the people whose lives are impacted by business operations and legislation,” she says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;She’s also aware of the complex intermixture of politics, social status, and financial obligations organizations and their employees have to navigate.&lt;/p&gt;&lt;p dir="ltr"&gt;“Though I’m studying workers, it’s important to consider the entire complex ecosystem when solving for these kinds of challenges, including firm incentives and global economic conditions,” she says.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/1nJ1-p5Hi_8/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            Graduate student spotlight: PhD student Whitney Zhang        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;strong&gt;The intersection of tech and labor policy&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang began investigating employee productivity, artificial intelligence, and related economic and labor market phenomena early in her time as a doctoral student, collaborating frequently with fellow PhD students in the department.&lt;/p&gt;&lt;p dir="ltr"&gt;A collaboration with economics doctoral student Shakked Noy yielded the 2023&amp;nbsp;study investigating ChatGPT as a tool to improve productivity. Their&amp;nbsp;research found it substantially increased workers’ productivity on writing tasks, most so for workers who initially performed the worst on the tasks.&lt;/p&gt;&lt;p dir="ltr"&gt;“This was one of the earliest pieces of evidence on the productivity effects of generative AI, and contributed to providing concrete data on how impactful these types of tools might be in the workplace and on the labor market,” Zhang says.&lt;/p&gt;&lt;p dir="ltr"&gt;In other ongoing research&amp;nbsp;—&amp;nbsp;“Determinants of Irregular Worker Schedules” —&amp;nbsp;Zhang is using data from a payroll provider to examine scheduling unpredictability, investigating why companies employ unpredictable schedules and how these schedules affect low-wage employees’ quality of life.&lt;/p&gt;&lt;p dir="ltr"&gt;The scheduling project, conducted with MIT economics PhD student Nathan Lazarus, is motivated, in part, by existing sociological evidence that low-wage workers’ unpredictable schedules are associated with worse sleep and well-being. “We’ve seen a relationship between higher turnover and inconsistent, inadequate schedules, which suggests workers dis-prefer these kinds of schedules,” Zhang says.&lt;/p&gt;&lt;p dir="ltr"&gt;At an academic roundtable, Zhang presented her results to Starbucks employees involved in scheduling and staffing. The attendees wanted to learn more about how different scheduling practices impacted workers and their productivity. “These are the kinds of questions that could reveal useful information for small businesses, large corporations, and others,” she says.&lt;/p&gt;&lt;p dir="ltr"&gt;By conducting this research, Zhang hopes to better understand whether or not scheduling regulations can improve affected employees’ quality of life, while also considering potential unintended consequences. “Why are these schedules set the way they’re set?” she asks. “Do businesses with these kinds of schedules require increased regulation?”&lt;/p&gt;&lt;p dir="ltr"&gt;Another project, conducted with MIT economics doctoral student Arjun Ramani, examines the linkages between offshoring, remote work, and related outcomes. “Do the technological and managerial practices that have made remote work possible further facilitate offshoring?” she asks. “Do organizations see significant gains in efficiency? What are the impacts on U.S. and offshore workers?”&lt;/p&gt;&lt;p dir="ltr"&gt;Her work is being funded through the&amp;nbsp;National Science Foundation Graduate Research Fellowship Program and the&amp;nbsp;Washington Center for Equitable Growth.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Putting people at the center&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang has observed the different kinds of people economics and higher education could bring together. She followed a dual enrollment track in high school, completing college-level courses with students from across a variety of demographic identities. “I enjoyed centering people in my work,” she says. “Taking classes with a diverse group of students, including veterans and mothers returning to school to complete their studies, made me more curious about socioeconomic issues and the policies relevant to them.”&lt;/p&gt;&lt;p dir="ltr"&gt;She later enrolled at MIT, where she participated in the Undergraduate Research Opportunities Program (UROP). She also completed an internship at the World Bank, worked as a summer analyst at the Federal Reserve Bank of New York, and worked as an assistant for a diverse faculty cohort including MIT economists&amp;nbsp;David Autor,&amp;nbsp;Jon Gruber, and&amp;nbsp;Nina Roussille. Autor is her primary advisor on her doctoral research, a mentor she cites as a significant influence.&lt;/p&gt;&lt;p dir="ltr"&gt;“[Autor’s] course, 14.03 (Microeconomics and Public Policy), cemented connections between theory and practice,” she says. “I thought the class was revelatory in showing the kinds of questions economics can answer.”&lt;/p&gt;&lt;p dir="ltr"&gt;Doctoral study has revealed interesting pathways of investigation for Zhang, as have her relationships with her student peers and other faculty. She has, for example, leveraged faculty connections to gain access to hourly wage data in support of her scheduling and employee impacts work. “Generally, economists have had administrative data on earnings, but not on hours,” she notes.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang’s focus on improving others’ lives extends to her work outside the classroom. She’s a mentor for the&amp;nbsp;Boston Chinatown Neighborhood Center College Access Program and a member of MIT’s Graduate Christian Fellowship group. When she’s not enjoying spicy soups or&amp;nbsp;paddling on the Charles, she takes advantage of opportunities to decompress with her art at&amp;nbsp;W20 Arts Studios.&lt;/p&gt;&lt;p dir="ltr"&gt;“I wanted to create time for myself outside of research and the classroom,” she says.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang cites the benefits of MIT’s focus on cross-collaboration and encouraging students to explore other disciplines. As an undergraduate, Zhang minored in computer science, which taught her coding skills critical to her data work. Exposure to engineering also led her to become more interested in questions around how technology and workers interact.&lt;/p&gt;&lt;p dir="ltr"&gt;Working with other scholars in the department has improved how Zhang conducts inquiries. “I’ve become the kind of well-rounded student and professional who can identify and quantify impacts, which is invaluable for future projects,” she says. Exposure to different academic and research areas, Zhang argues, helps increase access to ideas and information.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Whitney Zhang ’21 believes in the importance of valuing workers regardless of where they fit into an organizational chart.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang is a PhD student in MIT’s&amp;nbsp;Department of Economics studying labor economics. She explores how the technological and managerial decisions companies make affect workers across the pay spectrum.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“I’ve been interested in economics, economic impacts, and related social issues for a long time,” says Zhang, who majored in mathematical economics as an undergraduate. “I wanted to apply my math skills to see how we could improve policies and their effects.”&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang is interested in how to improve conditions for workers. She believes it’s important to build relationships with policymakers, focusing on an evidence-driven approach to policy, while always remembering to center those the policies may affect. “We have to remember the people whose lives are impacted by business operations and legislation,” she says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;She’s also aware of the complex intermixture of politics, social status, and financial obligations organizations and their employees have to navigate.&lt;/p&gt;&lt;p dir="ltr"&gt;“Though I’m studying workers, it’s important to consider the entire complex ecosystem when solving for these kinds of challenges, including firm incentives and global economic conditions,” she says.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/1nJ1-p5Hi_8/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            Graduate student spotlight: PhD student Whitney Zhang        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;strong&gt;The intersection of tech and labor policy&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang began investigating employee productivity, artificial intelligence, and related economic and labor market phenomena early in her time as a doctoral student, collaborating frequently with fellow PhD students in the department.&lt;/p&gt;&lt;p dir="ltr"&gt;A collaboration with economics doctoral student Shakked Noy yielded the 2023&amp;nbsp;study investigating ChatGPT as a tool to improve productivity. Their&amp;nbsp;research found it substantially increased workers’ productivity on writing tasks, most so for workers who initially performed the worst on the tasks.&lt;/p&gt;&lt;p dir="ltr"&gt;“This was one of the earliest pieces of evidence on the productivity effects of generative AI, and contributed to providing concrete data on how impactful these types of tools might be in the workplace and on the labor market,” Zhang says.&lt;/p&gt;&lt;p dir="ltr"&gt;In other ongoing research&amp;nbsp;—&amp;nbsp;“Determinants of Irregular Worker Schedules” —&amp;nbsp;Zhang is using data from a payroll provider to examine scheduling unpredictability, investigating why companies employ unpredictable schedules and how these schedules affect low-wage employees’ quality of life.&lt;/p&gt;&lt;p dir="ltr"&gt;The scheduling project, conducted with MIT economics PhD student Nathan Lazarus, is motivated, in part, by existing sociological evidence that low-wage workers’ unpredictable schedules are associated with worse sleep and well-being. “We’ve seen a relationship between higher turnover and inconsistent, inadequate schedules, which suggests workers dis-prefer these kinds of schedules,” Zhang says.&lt;/p&gt;&lt;p dir="ltr"&gt;At an academic roundtable, Zhang presented her results to Starbucks employees involved in scheduling and staffing. The attendees wanted to learn more about how different scheduling practices impacted workers and their productivity. “These are the kinds of questions that could reveal useful information for small businesses, large corporations, and others,” she says.&lt;/p&gt;&lt;p dir="ltr"&gt;By conducting this research, Zhang hopes to better understand whether or not scheduling regulations can improve affected employees’ quality of life, while also considering potential unintended consequences. “Why are these schedules set the way they’re set?” she asks. “Do businesses with these kinds of schedules require increased regulation?”&lt;/p&gt;&lt;p dir="ltr"&gt;Another project, conducted with MIT economics doctoral student Arjun Ramani, examines the linkages between offshoring, remote work, and related outcomes. “Do the technological and managerial practices that have made remote work possible further facilitate offshoring?” she asks. “Do organizations see significant gains in efficiency? What are the impacts on U.S. and offshore workers?”&lt;/p&gt;&lt;p dir="ltr"&gt;Her work is being funded through the&amp;nbsp;National Science Foundation Graduate Research Fellowship Program and the&amp;nbsp;Washington Center for Equitable Growth.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Putting people at the center&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang has observed the different kinds of people economics and higher education could bring together. She followed a dual enrollment track in high school, completing college-level courses with students from across a variety of demographic identities. “I enjoyed centering people in my work,” she says. “Taking classes with a diverse group of students, including veterans and mothers returning to school to complete their studies, made me more curious about socioeconomic issues and the policies relevant to them.”&lt;/p&gt;&lt;p dir="ltr"&gt;She later enrolled at MIT, where she participated in the Undergraduate Research Opportunities Program (UROP). She also completed an internship at the World Bank, worked as a summer analyst at the Federal Reserve Bank of New York, and worked as an assistant for a diverse faculty cohort including MIT economists&amp;nbsp;David Autor,&amp;nbsp;Jon Gruber, and&amp;nbsp;Nina Roussille. Autor is her primary advisor on her doctoral research, a mentor she cites as a significant influence.&lt;/p&gt;&lt;p dir="ltr"&gt;“[Autor’s] course, 14.03 (Microeconomics and Public Policy), cemented connections between theory and practice,” she says. “I thought the class was revelatory in showing the kinds of questions economics can answer.”&lt;/p&gt;&lt;p dir="ltr"&gt;Doctoral study has revealed interesting pathways of investigation for Zhang, as have her relationships with her student peers and other faculty. She has, for example, leveraged faculty connections to gain access to hourly wage data in support of her scheduling and employee impacts work. “Generally, economists have had administrative data on earnings, but not on hours,” she notes.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang’s focus on improving others’ lives extends to her work outside the classroom. She’s a mentor for the&amp;nbsp;Boston Chinatown Neighborhood Center College Access Program and a member of MIT’s Graduate Christian Fellowship group. When she’s not enjoying spicy soups or&amp;nbsp;paddling on the Charles, she takes advantage of opportunities to decompress with her art at&amp;nbsp;W20 Arts Studios.&lt;/p&gt;&lt;p dir="ltr"&gt;“I wanted to create time for myself outside of research and the classroom,” she says.&lt;/p&gt;&lt;p dir="ltr"&gt;Zhang cites the benefits of MIT’s focus on cross-collaboration and encouraging students to explore other disciplines. As an undergraduate, Zhang minored in computer science, which taught her coding skills critical to her data work. Exposure to engineering also led her to become more interested in questions around how technology and workers interact.&lt;/p&gt;&lt;p dir="ltr"&gt;Working with other scholars in the department has improved how Zhang conducts inquiries. “I’ve become the kind of well-rounded student and professional who can identify and quantify impacts, which is invaluable for future projects,” she says. Exposure to different academic and research areas, Zhang argues, helps increase access to ideas and information.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/improving-workplace-future-whitney-zhang-0924</guid><pubDate>Wed, 24 Sep 2025 04:00:00 +0000</pubDate></item></channel></rss>