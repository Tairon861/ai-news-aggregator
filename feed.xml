<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 13 Jan 2026 18:35:22 +0000</lastBuildDate><item><title>[NEW] Why Apple chose Google over OpenAI: What enterprise AI buyers can learn from the Gemini deal (AI News)</title><link>https://www.artificialintelligence-news.com/news/apple-gemini-siri-enterprise-foundation-models/</link><description>&lt;p&gt;Apple’s multi-year agreement to integrate Google’s Gemini models into its revamped Siri offers a rare window into how one of the world’s most selective technology companies evaluates foundation models – and the criteria should matter to any enterprise weighing similar decisions.&lt;/p&gt;&lt;p&gt;The stakes were considerable. Apple had been publicly integrating ChatGPT into its devices since late 2024, giving OpenAI prominent positioning in the Apple Intelligence ecosystem.&lt;/p&gt;&lt;p&gt;Google’s Gemini win represents a shift in Apple’s AI infrastructure strategy, one that relegates OpenAI to what Parth Talsania, CEO of Equisights Research, describes as “a more supporting role, with ChatGPT remaining positioned for complex, opt-in queries rather than the default intelligence layer.”&lt;/p&gt;&lt;h3&gt;The evaluation that mattered&lt;/h3&gt;&lt;p&gt;Apple’s reasoning was notably specific. “After careful evaluation, Apple determined Google’s AI technology provides the most capable foundation for Apple Foundation Models,” according to the joint statement. The phrasing matters – Apple didn’t cite partnership convenience, pricing, or ecosystem compatibility. The company framed this explicitly as a capabilities assessment.&lt;/p&gt;&lt;p&gt;Apple’s evaluation criteria likely mirrored concerns familiar to any organisation building AI into core products: model performance at scale, inference latency, multimodal capabilities, and crucially, the ability to run models both on-device and in cloud environments while maintaining privacy standards.&lt;/p&gt;&lt;p&gt;Google’s technology already powers Samsung’s Galaxy AI in millions of devices, providing proven deployment evidence at consumer scale. But Apple’s decision unlocks something different: integration in more than two billion active devices, with the technical demands that come with Apple’s performance and privacy requirements.&lt;/p&gt;&lt;h3&gt;What has changed since ChatGPT integration&lt;/h3&gt;&lt;p&gt;The timing raises questions. Apple rolled out ChatGPT integration just over a year ago, positioning Siri to tap into the chatbot for complex queries. The company now states, “there were no major changes to the ChatGPT integration at the time,” but the competitive dynamics have clearly shifted.&lt;/p&gt;&lt;p&gt;OpenAI’s response to Google’s Gemini 3 release in late 2025 – what reports described as a “code red” to accelerate development – suggests the competitive pressure was real. For enterprises, this highlights a risk often under-weighted in vendor selection: the pace of model capability advancement varies significantly between providers, and today’s leader may not maintain that position in a multi-year deployment.&lt;/p&gt;&lt;p&gt;Apple’s choice of a multi-year agreement with Google, rather than maintaining flexibility to switch between providers, suggests confidence in Google’s development trajectory. That’s a bet on sustained R&amp;amp;D investment, continued model improvements, and infrastructure scaling – the same factors enterprise buyers need to assess beyond current benchmarks.&lt;/p&gt;&lt;h3&gt;The infrastructure question&lt;/h3&gt;&lt;p&gt;The deal raises immediate concerns about concentration. “The seems like an unreasonable concentration of power for Google, given that they also have Android and Chrome,” Tesla CEO Elon Musk posted on social media. The critique reflects a legitimate enterprise concern about vendor dependency.&lt;/p&gt;&lt;p&gt;Google now powers AI features in both major mobile operating systems through different mechanisms: directly via Android, and through this partnership for iOS. For enterprises deploying AI capabilities, the parallel is that relying on a single foundation model provider creates technical and commercial dependencies that extend beyond the immediate integration.&lt;/p&gt;&lt;p&gt;This makes Apple’s architectural approach worth examining. The company emphasised that “Apple Intelligence will continue to run on Apple devices and Private Cloud Compute, while maintaining Apple’s industry-leading privacy standards.”&lt;/p&gt;&lt;p&gt;The hybrid deployment model – on-device processing for privacy-sensitive operations, cloud-based models for complex tasks – offers a template for enterprises balancing capability with data governance requirements.&lt;/p&gt;&lt;h3&gt;Market implications beyond mobile&lt;/h3&gt;&lt;p&gt;The deal’s immediate impact was measurable: Alphabet’s market valuation crossed US$4 trillion on Monday, with the stock having jumped 65% in 2024 on growing investor confidence in its AI efforts. But the strategic implications extend beyond market caps.&lt;/p&gt;&lt;p&gt;Google has been methodically building positions in the AI stack – frontier models, image and video generation, and now default integration into iOS devices. For enterprises, this vertical integration matters when evaluating cloud AI services: a provider’s foundation model capabilities increasingly connect to their broader infrastructure, tools, and ecosystem positioning.&lt;/p&gt;&lt;p&gt;Apple’s setbacks on the AI front – delayed Siri upgrades, executive changes, lukewarm reception for initial generative AI tools – are instructive from another angle. Even companies with enormous resources and talent can struggle with AI product execution. The decision to partner with Google rather than persist with entirely proprietary development acknowledges the complexity and resource demands of frontier model development.&lt;/p&gt;&lt;h3&gt;The search revenue connection&lt;/h3&gt;&lt;p&gt;The Gemini deal builds on an existing commercial relationship that generates tens of billions in annual revenue for Apple: Google pays to remain the default search engine on Apple devices. That arrangement has faced regulatory scrutiny, but it establishes precedent for deep technical integration between the companies.&lt;/p&gt;&lt;p&gt;The search deal likely influenced negotiations around the Gemini integration, just as existing vendor relationships shape enterprise AI procurement. Those relationships can be advantages – established trust, proven integration capabilities – or constraints that limit evaluation of alternatives.&lt;/p&gt;&lt;h3&gt;The OpenAI question&lt;/h3&gt;&lt;p&gt;The deal leaves OpenAI in an awkward position. ChatGPT remains available on Apple devices, but as an optional feature rather than the infrastructure layer. For a company that has positioned itself as the AI leader, losing default integration to Google represents a strategic setback.&lt;/p&gt;&lt;p&gt;The competitive dynamic offers a reminder that the foundation model market remains fluid. Provider positioning can shift quickly, and exclusive relationships between major players can reshape options for everyone else. Maintaining options – through abstraction layers, multi-model strategies, or portable architectures – becomes more valuable in rapidly evolving markets.&lt;/p&gt;&lt;h3&gt;What comes next&lt;/h3&gt;&lt;p&gt;Google stated that Gemini models will power not just the revamped Siri coming later this year, but “other future Apple Intelligence features.” The scope of integration will likely expand as Apple builds out its AI capabilities, creating deeper technical dependencies and raising the stakes of the partnership.&lt;/p&gt;&lt;p&gt;The financial terms remain undisclosed, leaving the question of how Apple and Google structure pricing for this scale of deployment? Enterprise buyers negotiating foundation model licensing will be watching for any signals about how such deals get priced at a massive scale.&lt;/p&gt;&lt;p&gt;Apple’s decision doesn’t make Google’s Gemini the obvious choice for every enterprise – far from it. But the deal does offer validated evidence of what one extremely selective technology company prioritised when evaluating foundation models under demanding requirements. For enterprise AI buyers navigating their own evaluations, that’s a signal worth considering amid the noise of vendor marketing and benchmark leader boards.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;strong&gt;See also: Apple plans big Siri update with help from Google AI&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Apple’s multi-year agreement to integrate Google’s Gemini models into its revamped Siri offers a rare window into how one of the world’s most selective technology companies evaluates foundation models – and the criteria should matter to any enterprise weighing similar decisions.&lt;/p&gt;&lt;p&gt;The stakes were considerable. Apple had been publicly integrating ChatGPT into its devices since late 2024, giving OpenAI prominent positioning in the Apple Intelligence ecosystem.&lt;/p&gt;&lt;p&gt;Google’s Gemini win represents a shift in Apple’s AI infrastructure strategy, one that relegates OpenAI to what Parth Talsania, CEO of Equisights Research, describes as “a more supporting role, with ChatGPT remaining positioned for complex, opt-in queries rather than the default intelligence layer.”&lt;/p&gt;&lt;h3&gt;The evaluation that mattered&lt;/h3&gt;&lt;p&gt;Apple’s reasoning was notably specific. “After careful evaluation, Apple determined Google’s AI technology provides the most capable foundation for Apple Foundation Models,” according to the joint statement. The phrasing matters – Apple didn’t cite partnership convenience, pricing, or ecosystem compatibility. The company framed this explicitly as a capabilities assessment.&lt;/p&gt;&lt;p&gt;Apple’s evaluation criteria likely mirrored concerns familiar to any organisation building AI into core products: model performance at scale, inference latency, multimodal capabilities, and crucially, the ability to run models both on-device and in cloud environments while maintaining privacy standards.&lt;/p&gt;&lt;p&gt;Google’s technology already powers Samsung’s Galaxy AI in millions of devices, providing proven deployment evidence at consumer scale. But Apple’s decision unlocks something different: integration in more than two billion active devices, with the technical demands that come with Apple’s performance and privacy requirements.&lt;/p&gt;&lt;h3&gt;What has changed since ChatGPT integration&lt;/h3&gt;&lt;p&gt;The timing raises questions. Apple rolled out ChatGPT integration just over a year ago, positioning Siri to tap into the chatbot for complex queries. The company now states, “there were no major changes to the ChatGPT integration at the time,” but the competitive dynamics have clearly shifted.&lt;/p&gt;&lt;p&gt;OpenAI’s response to Google’s Gemini 3 release in late 2025 – what reports described as a “code red” to accelerate development – suggests the competitive pressure was real. For enterprises, this highlights a risk often under-weighted in vendor selection: the pace of model capability advancement varies significantly between providers, and today’s leader may not maintain that position in a multi-year deployment.&lt;/p&gt;&lt;p&gt;Apple’s choice of a multi-year agreement with Google, rather than maintaining flexibility to switch between providers, suggests confidence in Google’s development trajectory. That’s a bet on sustained R&amp;amp;D investment, continued model improvements, and infrastructure scaling – the same factors enterprise buyers need to assess beyond current benchmarks.&lt;/p&gt;&lt;h3&gt;The infrastructure question&lt;/h3&gt;&lt;p&gt;The deal raises immediate concerns about concentration. “The seems like an unreasonable concentration of power for Google, given that they also have Android and Chrome,” Tesla CEO Elon Musk posted on social media. The critique reflects a legitimate enterprise concern about vendor dependency.&lt;/p&gt;&lt;p&gt;Google now powers AI features in both major mobile operating systems through different mechanisms: directly via Android, and through this partnership for iOS. For enterprises deploying AI capabilities, the parallel is that relying on a single foundation model provider creates technical and commercial dependencies that extend beyond the immediate integration.&lt;/p&gt;&lt;p&gt;This makes Apple’s architectural approach worth examining. The company emphasised that “Apple Intelligence will continue to run on Apple devices and Private Cloud Compute, while maintaining Apple’s industry-leading privacy standards.”&lt;/p&gt;&lt;p&gt;The hybrid deployment model – on-device processing for privacy-sensitive operations, cloud-based models for complex tasks – offers a template for enterprises balancing capability with data governance requirements.&lt;/p&gt;&lt;h3&gt;Market implications beyond mobile&lt;/h3&gt;&lt;p&gt;The deal’s immediate impact was measurable: Alphabet’s market valuation crossed US$4 trillion on Monday, with the stock having jumped 65% in 2024 on growing investor confidence in its AI efforts. But the strategic implications extend beyond market caps.&lt;/p&gt;&lt;p&gt;Google has been methodically building positions in the AI stack – frontier models, image and video generation, and now default integration into iOS devices. For enterprises, this vertical integration matters when evaluating cloud AI services: a provider’s foundation model capabilities increasingly connect to their broader infrastructure, tools, and ecosystem positioning.&lt;/p&gt;&lt;p&gt;Apple’s setbacks on the AI front – delayed Siri upgrades, executive changes, lukewarm reception for initial generative AI tools – are instructive from another angle. Even companies with enormous resources and talent can struggle with AI product execution. The decision to partner with Google rather than persist with entirely proprietary development acknowledges the complexity and resource demands of frontier model development.&lt;/p&gt;&lt;h3&gt;The search revenue connection&lt;/h3&gt;&lt;p&gt;The Gemini deal builds on an existing commercial relationship that generates tens of billions in annual revenue for Apple: Google pays to remain the default search engine on Apple devices. That arrangement has faced regulatory scrutiny, but it establishes precedent for deep technical integration between the companies.&lt;/p&gt;&lt;p&gt;The search deal likely influenced negotiations around the Gemini integration, just as existing vendor relationships shape enterprise AI procurement. Those relationships can be advantages – established trust, proven integration capabilities – or constraints that limit evaluation of alternatives.&lt;/p&gt;&lt;h3&gt;The OpenAI question&lt;/h3&gt;&lt;p&gt;The deal leaves OpenAI in an awkward position. ChatGPT remains available on Apple devices, but as an optional feature rather than the infrastructure layer. For a company that has positioned itself as the AI leader, losing default integration to Google represents a strategic setback.&lt;/p&gt;&lt;p&gt;The competitive dynamic offers a reminder that the foundation model market remains fluid. Provider positioning can shift quickly, and exclusive relationships between major players can reshape options for everyone else. Maintaining options – through abstraction layers, multi-model strategies, or portable architectures – becomes more valuable in rapidly evolving markets.&lt;/p&gt;&lt;h3&gt;What comes next&lt;/h3&gt;&lt;p&gt;Google stated that Gemini models will power not just the revamped Siri coming later this year, but “other future Apple Intelligence features.” The scope of integration will likely expand as Apple builds out its AI capabilities, creating deeper technical dependencies and raising the stakes of the partnership.&lt;/p&gt;&lt;p&gt;The financial terms remain undisclosed, leaving the question of how Apple and Google structure pricing for this scale of deployment? Enterprise buyers negotiating foundation model licensing will be watching for any signals about how such deals get priced at a massive scale.&lt;/p&gt;&lt;p&gt;Apple’s decision doesn’t make Google’s Gemini the obvious choice for every enterprise – far from it. But the deal does offer validated evidence of what one extremely selective technology company prioritised when evaluating foundation models under demanding requirements. For enterprise AI buyers navigating their own evaluations, that’s a signal worth considering amid the noise of vendor marketing and benchmark leader boards.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;strong&gt;See also: Apple plans big Siri update with help from Google AI&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/apple-gemini-siri-enterprise-foundation-models/</guid><pubDate>Tue, 13 Jan 2026 07:00:00 +0000</pubDate></item><item><title>[NEW] The latency trap: Smart warehouses abandon cloud for edge (AI News)</title><link>https://www.artificialintelligence-news.com/news/the-latency-trap-smart-warehouses-abandon-cloud-for-edge/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/chuttersnap-BNBA1h-NgdY-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;While the enterprise world rushes to migrate everything to the cloud, the warehouse floor is moving in the opposite direction. This article explores why the future of automation relies on edge AI to solve the fatal “latency gap” in modern logistics.&lt;/p&gt;&lt;p&gt;In the sterilised promotional videos for smart warehouses, autonomous mobile robots (AMRs) glide in perfect, balletic harmony. They weave past human workers, dodge dropped pallets and optimise their paths in real-time. It looks seamless.&lt;/p&gt;&lt;p&gt;In the real world, however, it is messy. A robot moving at 2.5 metres per second that relies on a cloud server to tell it whether that obstacle is a cardboard box or a human ankle is a liability. If the wi-fi flickers for 200 milliseconds (a blink of an eye in human terms), that robot is effectively blind. In a highly dense facility, 200 milliseconds is the difference between a smooth operation and a collision.&lt;/p&gt;&lt;p&gt;This is the “latency trap,” and it is currently the single biggest bottleneck in eCommerce logistics. For the past decade, the industry dogma has been to centralise intelligence: push all data to the cloud, process it with massive compute power and send instructions back. But as we approach the physical limits of bandwidth and speed, engineers are realising that the cloud is simply too far away. The next generation of smart warehouses isn’t getting smarter by connecting to a larger server farm; it’s getting smarter by severing the cord.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-physics-of-real-time"&gt;The physics of “real-time”&lt;/h3&gt;&lt;p&gt;To understand why the industry is pivoting to Edge AI, we have to look at the maths of modern fulfilment.&lt;/p&gt;&lt;p&gt;In a traditional setup, a robot’s LIDAR or camera sensors capture data. That data is compressed, packeted and transmitted via local wi-fi to a gateway, then through fibre optics to a data centre (often hundreds of miles away). The AI model in the cloud processes the image (“Object detected: Forklift”), determines an action (“Stop”) and sends the command back down the chain.&lt;/p&gt;&lt;p&gt;Even with fibber, the round-trip time (RTT) can hover between 50 to 100 milliseconds. Add in network jitter, packet loss in a warehouse full of metal racking (which acts as a Faraday cage) and server processing time. Then boom, the delay can spike to half a second.&lt;/p&gt;&lt;p&gt;For a predictive algorithm analysing sales data, half a second is irrelevant. For a 500kg robot navigating a narrow aisle, it is an eternity.&lt;/p&gt;&lt;p&gt;This is why the architecture of eCommerce logistics is flipping upside down. We are moving from a “Hive Mind” model (one central brain controlling all drones) to a “Swarm” model (smart drones making their own decisions).&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-rise-of-on-device-inference"&gt;The rise of on-device inference&lt;/h3&gt;&lt;p&gt;The solution lies in edge AI: moving the inference (the decision-making process) directly onto the robot itself.&lt;/p&gt;&lt;p&gt;Thanks to the explosion in efficient, high-performing silicon, specifically system-on-modules (SoMs) like the NVIDIA Jetson series or specialised TPUs, robots no longer need to ask permission to stop. They process the sensor data locally. The camera sees the obstacle, the onboard chip runs the neural network and the brakes are applied in single-digit milliseconds. No internet required.&lt;/p&gt;&lt;p&gt;The transformation does more than just prevent accidents. It fundamentally changes the bandwidth economics of the warehouse. A facility running at lets say, 500 AMRs, cannot feasibly stream high-definition video feeds from every robot to the cloud simultaneously. The truth is, the bandwidth cost alone would destroy the margins. By processing video locally and only sending metadata (e.g., “Aisle 4 blocked by debris”) to the central server, warehouses can scale their fleets without totally crushing their network infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-3pl-adoption-curve"&gt;The 3PL adoption curve&lt;/h3&gt;&lt;p&gt;The technological shift is creating a divide in the logistics market. On one side, you have legacy providers running rigid, older automation systems. On the other hand, you have ‘tech-forward’ third-party logistics (3PL) providers who are treating their warehouses as software platforms.&lt;/p&gt;&lt;p&gt;The agility of a 3PL for eCommerce is now defined by its tech stack. Modern providers are adopting these edge-enabled systems not just for safety, but for speed. When a 3PL integrates edge-computing robotics, they aren’t just installing machines; they are installing a dynamic mesh network that adapts to order volume in real-time.&lt;/p&gt;&lt;p&gt;For example, during peak season (black Friday/cyber Monday), the volume of goods moving through a facility can triple. You don’t want systems completely dependent on the cloud because it would slow them down exactly when speed is paramount. An edge-based fleet, however, maintains its performance because each unit carries its own compute power. It scales linearly. The reliability is what separates top-tier fulfilment partners from those who crumble under the December crush.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-computer-vision-the-killer-app-for-the-edge"&gt;Computer vision: The killer app for the edge&lt;/h3&gt;&lt;p&gt;While navigation is the immediate safety use case, the most lucrative application of Edge AI is actually in quality control and tracking. This is where the barcode, a technology that has survived for 50 years, finally faces its extinction.&lt;/p&gt;&lt;p&gt;In a standard workflow, a package is scanned manually at multiple touchpoints. It’s slow, prone to human error and tediously repetitive.&lt;/p&gt;&lt;p&gt;Edge AI enables “passive tracking” via Computer Vision. Cameras mounted on conveyor belts or worn by workers (smart glasses) run object recognition models locally. As a package moves down the line, the AI identifies it by its dimensions, logo and shipping label text simultaneously.&lt;/p&gt;&lt;p&gt;This requires massive processing power. Running a YOLO (you only look once) object detection model at 60 frames per second on 50 different cameras is not something you can easily offload to the cloud without massive lag and cost. It has to happen at the edge.&lt;/p&gt;&lt;p&gt;When this works, the results are invisible but profound. “Lost” inventory becomes a rarity because the system “sees” every item constantly. If a worker places a package in the wrong bin, an overhead camera (running local inference) detects the anomaly and flashes a red light instantly. The error is caught before the item even leaves the station.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-data-gravity-problem"&gt;The data gravity problem&lt;/h3&gt;&lt;p&gt;There is, however, a catch. If the robots are thinking for themselves, how do you improve their collective intelligence?&lt;/p&gt;&lt;p&gt;In a completely cloud-centric model, all data is in a single place, making it easy to retrain models. In an edge-centric model on the other hand, the data is fragmented in hundreds of different devices. This introduces the challenge of “Data Gravity.” To solve this, the industry is turning to federated learning.&lt;/p&gt;&lt;p&gt;This means that if one robot learns that a specific type of shrink wrap confuses its sensors, every robot in the fleet wakes up the next day knowing how to handle it. It is collective evolution without the bandwidth bloat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-5g-is-the-enabler-not-the-saviour"&gt;Why 5G is the enabler (not the saviour)&lt;/h3&gt;&lt;p&gt;You cannot talk about the smart warehouse without mentioning 5G, but it is important to understand its actual role. Marketing hype suggests 5G solves latency. It helps, certainly, offering sub-10ms latency theoretically. But for eCommerce logistics, 5G is not the brain. No, it is the nervous system.&lt;/p&gt;&lt;p&gt;5G private networks are becoming the standard for these facilities because they offer a dedicated spectrum. Wi-fi is notorious for interference. Metal racking, other devices and microwave ovens in the breakroom can degrade the signal. A private 5G slice guarantees that the robots (and the important edge devices) have a dedicated lane that is immune to the noise.&lt;/p&gt;&lt;p&gt;However, 5G is the pipe, not the processor. It allows the edge devices to communicate with each other (machine-to-machine or M2M communication) faster. This enables “swarm intelligence.” If Robot A encounters a spill in Aisle 3, it can broadcast a “Keep Out” zone to the local mesh network. Robot B, C and D reroute instantly without ever needing to query the central server. The network effect amplifies the value of the edge compute.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-the-warehouse-as-a-neural-network"&gt;The future: The warehouse as a neural network&lt;/h3&gt;&lt;p&gt;Looking forward to 2026 and beyond, the definition of a “warehouse” is pivoting. It is no longer just a storage shed; it is becoming a physical neural network.&lt;/p&gt;&lt;p&gt;Every sensor, camera, robot and conveyor belt is becoming a node with its own compute capacity. The walls themselves are getting smart. We are seeing the deployment of ‘Smart Floor’ tiles that can sense weight and foot traffic, processing that data locally to optimise heating and lighting or detect unauthorised access.&lt;/p&gt;&lt;p&gt;For the enterprise, the message is clear: the competitive advantage in eCommerce logistics is no longer just about square footage or location. It is about compute density.&lt;/p&gt;&lt;p&gt;The winners in this space will be the ones who can push intelligence the furthest out to the edge. They will be the ones who understand that in a world demanding instant gratification, the speed of light is simply too slow and the smartest decision is the one made right where the action is.&lt;/p&gt;&lt;p&gt;The cloud will always have a place for long-term analytics and storage, but for the kinetic, chaotic, fast-moving reality of the warehouse floor, the edge has already won. The revolution is happening on the device, millisecond by millisecond and it is reshaping the global supply chain… one decision at a time.&lt;/p&gt;&lt;p&gt;Image source: Unsplash&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/chuttersnap-BNBA1h-NgdY-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;While the enterprise world rushes to migrate everything to the cloud, the warehouse floor is moving in the opposite direction. This article explores why the future of automation relies on edge AI to solve the fatal “latency gap” in modern logistics.&lt;/p&gt;&lt;p&gt;In the sterilised promotional videos for smart warehouses, autonomous mobile robots (AMRs) glide in perfect, balletic harmony. They weave past human workers, dodge dropped pallets and optimise their paths in real-time. It looks seamless.&lt;/p&gt;&lt;p&gt;In the real world, however, it is messy. A robot moving at 2.5 metres per second that relies on a cloud server to tell it whether that obstacle is a cardboard box or a human ankle is a liability. If the wi-fi flickers for 200 milliseconds (a blink of an eye in human terms), that robot is effectively blind. In a highly dense facility, 200 milliseconds is the difference between a smooth operation and a collision.&lt;/p&gt;&lt;p&gt;This is the “latency trap,” and it is currently the single biggest bottleneck in eCommerce logistics. For the past decade, the industry dogma has been to centralise intelligence: push all data to the cloud, process it with massive compute power and send instructions back. But as we approach the physical limits of bandwidth and speed, engineers are realising that the cloud is simply too far away. The next generation of smart warehouses isn’t getting smarter by connecting to a larger server farm; it’s getting smarter by severing the cord.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-physics-of-real-time"&gt;The physics of “real-time”&lt;/h3&gt;&lt;p&gt;To understand why the industry is pivoting to Edge AI, we have to look at the maths of modern fulfilment.&lt;/p&gt;&lt;p&gt;In a traditional setup, a robot’s LIDAR or camera sensors capture data. That data is compressed, packeted and transmitted via local wi-fi to a gateway, then through fibre optics to a data centre (often hundreds of miles away). The AI model in the cloud processes the image (“Object detected: Forklift”), determines an action (“Stop”) and sends the command back down the chain.&lt;/p&gt;&lt;p&gt;Even with fibber, the round-trip time (RTT) can hover between 50 to 100 milliseconds. Add in network jitter, packet loss in a warehouse full of metal racking (which acts as a Faraday cage) and server processing time. Then boom, the delay can spike to half a second.&lt;/p&gt;&lt;p&gt;For a predictive algorithm analysing sales data, half a second is irrelevant. For a 500kg robot navigating a narrow aisle, it is an eternity.&lt;/p&gt;&lt;p&gt;This is why the architecture of eCommerce logistics is flipping upside down. We are moving from a “Hive Mind” model (one central brain controlling all drones) to a “Swarm” model (smart drones making their own decisions).&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-rise-of-on-device-inference"&gt;The rise of on-device inference&lt;/h3&gt;&lt;p&gt;The solution lies in edge AI: moving the inference (the decision-making process) directly onto the robot itself.&lt;/p&gt;&lt;p&gt;Thanks to the explosion in efficient, high-performing silicon, specifically system-on-modules (SoMs) like the NVIDIA Jetson series or specialised TPUs, robots no longer need to ask permission to stop. They process the sensor data locally. The camera sees the obstacle, the onboard chip runs the neural network and the brakes are applied in single-digit milliseconds. No internet required.&lt;/p&gt;&lt;p&gt;The transformation does more than just prevent accidents. It fundamentally changes the bandwidth economics of the warehouse. A facility running at lets say, 500 AMRs, cannot feasibly stream high-definition video feeds from every robot to the cloud simultaneously. The truth is, the bandwidth cost alone would destroy the margins. By processing video locally and only sending metadata (e.g., “Aisle 4 blocked by debris”) to the central server, warehouses can scale their fleets without totally crushing their network infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-3pl-adoption-curve"&gt;The 3PL adoption curve&lt;/h3&gt;&lt;p&gt;The technological shift is creating a divide in the logistics market. On one side, you have legacy providers running rigid, older automation systems. On the other hand, you have ‘tech-forward’ third-party logistics (3PL) providers who are treating their warehouses as software platforms.&lt;/p&gt;&lt;p&gt;The agility of a 3PL for eCommerce is now defined by its tech stack. Modern providers are adopting these edge-enabled systems not just for safety, but for speed. When a 3PL integrates edge-computing robotics, they aren’t just installing machines; they are installing a dynamic mesh network that adapts to order volume in real-time.&lt;/p&gt;&lt;p&gt;For example, during peak season (black Friday/cyber Monday), the volume of goods moving through a facility can triple. You don’t want systems completely dependent on the cloud because it would slow them down exactly when speed is paramount. An edge-based fleet, however, maintains its performance because each unit carries its own compute power. It scales linearly. The reliability is what separates top-tier fulfilment partners from those who crumble under the December crush.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-computer-vision-the-killer-app-for-the-edge"&gt;Computer vision: The killer app for the edge&lt;/h3&gt;&lt;p&gt;While navigation is the immediate safety use case, the most lucrative application of Edge AI is actually in quality control and tracking. This is where the barcode, a technology that has survived for 50 years, finally faces its extinction.&lt;/p&gt;&lt;p&gt;In a standard workflow, a package is scanned manually at multiple touchpoints. It’s slow, prone to human error and tediously repetitive.&lt;/p&gt;&lt;p&gt;Edge AI enables “passive tracking” via Computer Vision. Cameras mounted on conveyor belts or worn by workers (smart glasses) run object recognition models locally. As a package moves down the line, the AI identifies it by its dimensions, logo and shipping label text simultaneously.&lt;/p&gt;&lt;p&gt;This requires massive processing power. Running a YOLO (you only look once) object detection model at 60 frames per second on 50 different cameras is not something you can easily offload to the cloud without massive lag and cost. It has to happen at the edge.&lt;/p&gt;&lt;p&gt;When this works, the results are invisible but profound. “Lost” inventory becomes a rarity because the system “sees” every item constantly. If a worker places a package in the wrong bin, an overhead camera (running local inference) detects the anomaly and flashes a red light instantly. The error is caught before the item even leaves the station.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-data-gravity-problem"&gt;The data gravity problem&lt;/h3&gt;&lt;p&gt;There is, however, a catch. If the robots are thinking for themselves, how do you improve their collective intelligence?&lt;/p&gt;&lt;p&gt;In a completely cloud-centric model, all data is in a single place, making it easy to retrain models. In an edge-centric model on the other hand, the data is fragmented in hundreds of different devices. This introduces the challenge of “Data Gravity.” To solve this, the industry is turning to federated learning.&lt;/p&gt;&lt;p&gt;This means that if one robot learns that a specific type of shrink wrap confuses its sensors, every robot in the fleet wakes up the next day knowing how to handle it. It is collective evolution without the bandwidth bloat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-5g-is-the-enabler-not-the-saviour"&gt;Why 5G is the enabler (not the saviour)&lt;/h3&gt;&lt;p&gt;You cannot talk about the smart warehouse without mentioning 5G, but it is important to understand its actual role. Marketing hype suggests 5G solves latency. It helps, certainly, offering sub-10ms latency theoretically. But for eCommerce logistics, 5G is not the brain. No, it is the nervous system.&lt;/p&gt;&lt;p&gt;5G private networks are becoming the standard for these facilities because they offer a dedicated spectrum. Wi-fi is notorious for interference. Metal racking, other devices and microwave ovens in the breakroom can degrade the signal. A private 5G slice guarantees that the robots (and the important edge devices) have a dedicated lane that is immune to the noise.&lt;/p&gt;&lt;p&gt;However, 5G is the pipe, not the processor. It allows the edge devices to communicate with each other (machine-to-machine or M2M communication) faster. This enables “swarm intelligence.” If Robot A encounters a spill in Aisle 3, it can broadcast a “Keep Out” zone to the local mesh network. Robot B, C and D reroute instantly without ever needing to query the central server. The network effect amplifies the value of the edge compute.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-the-warehouse-as-a-neural-network"&gt;The future: The warehouse as a neural network&lt;/h3&gt;&lt;p&gt;Looking forward to 2026 and beyond, the definition of a “warehouse” is pivoting. It is no longer just a storage shed; it is becoming a physical neural network.&lt;/p&gt;&lt;p&gt;Every sensor, camera, robot and conveyor belt is becoming a node with its own compute capacity. The walls themselves are getting smart. We are seeing the deployment of ‘Smart Floor’ tiles that can sense weight and foot traffic, processing that data locally to optimise heating and lighting or detect unauthorised access.&lt;/p&gt;&lt;p&gt;For the enterprise, the message is clear: the competitive advantage in eCommerce logistics is no longer just about square footage or location. It is about compute density.&lt;/p&gt;&lt;p&gt;The winners in this space will be the ones who can push intelligence the furthest out to the edge. They will be the ones who understand that in a world demanding instant gratification, the speed of light is simply too slow and the smartest decision is the one made right where the action is.&lt;/p&gt;&lt;p&gt;The cloud will always have a place for long-term analytics and storage, but for the kinetic, chaotic, fast-moving reality of the warehouse floor, the edge has already won. The revolution is happening on the device, millisecond by millisecond and it is reshaping the global supply chain… one decision at a time.&lt;/p&gt;&lt;p&gt;Image source: Unsplash&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/the-latency-trap-smart-warehouses-abandon-cloud-for-edge/</guid><pubDate>Tue, 13 Jan 2026 10:53:45 +0000</pubDate></item><item><title>[NEW] Converge Bio raises $25M, backed by Bessemer and execs from Meta, OpenAI, Wiz (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/ai-drug-discovery-startup-converge-bio-pulls-in-25m-from-bessemer-and-execs-from-meta-openai-and-wiz/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Artificial intelligence is moving quickly into drug discovery as pharmaceutical and biotech companies look for ways to cut years off R&amp;amp;D timelines and increase the chances of success amid rising costs. More than 200 startups are now competing to weave AI directly into research workflows, attracting growing interest from investors. Converge Bio is the latest company to ride that shift, securing new capital as competition in the AI-driven drug discovery space heats up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Boston- and Tel Aviv-based startup, which helps pharma and biotech companies develop drugs faster using generative AI trained on molecular data, has raised a $25 million oversubscribed Series A round, led by Bessemer Venture Partners. TLV Partners, Saras Capital, and Vintage Investment Partners also joined the round, along with additional backing from unidentified executives at Meta, OpenAI, and Wiz.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In practice, Converge trains generative models on DNA, RNA, and protein sequences, then plugs them into pharma and biotech’s workflows to speed up drug development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The drug-development lifecycle has defined stages — from target identification and discovery to manufacturing, clinical trials, and beyond — and within each, there are experiments we can support,” Converge Bio CEO and co-founder Dov Gertz said in an exclusive interview with TechCrunch. “Our platform continues to expand across these stages, helping bring new drugs to market faster.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Converge has rolled out customer-facing systems. The startup has already introduced three discrete AI systems: one for antibody design, one for protein yield optimization, and one for biomarker and target discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Take our antibody design system as an example. It’s not just a single model. It’s made up of three integrated components. First, a generative model creates novel antibodies. Next, predictive models filter those antibodies based on their molecular properties. Finally, a docking system, which uses a physics-based model, simulates the three-dimensional interactions between the antibody and its target,” Gertz continued. The value lies in the system as a whole, not any single model, according to the CEO. “Our customers don’t have to piece models together themselves. They get ready-to-use systems that plug directly into their workflows.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding comes about a year and a half after the company raised a $5.5 million seed round in 2024. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, the two-year-old startup has scaled quickly. Converge has completed over 40 programs with more than a dozen pharmaceutical and biotech customers, Gertz said. It works with customers across the U.S., Canada, Europe, and Israel and is now expanding into Asia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team has also grown rapidly, increasing to 34 employees from just nine in November 2024. Along the way, Converge has begun publishing public case studies. In one, the startup helped a partner boost protein yield by 4 to 4.5X in a single computational iteration. In another, the platform generated antibodies with extremely high binding affinity, reaching the single-nanomolar range, Gertz noted.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3081729" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/Converge-Bio-9976.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Converge Bio&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;AI-driven drug discovery is experiencing a surge of interest. Last year, Eli Lilly teamed up with Nvidia to build what the companies called the pharma industry’s most powerful supercomputer for drug discovery. And in October 2024, the developers behind Google DeepMind’s AlphaFold project won a Nobel Prize in Chemistry for creating AlphaFold, the AI system that can predict protein structures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about the momentum and how it is shaping Converge Bio’s growth, Gertz said that the company is witnessing the largest financial opportunity in the history of life sciences and the industry is shifting from “trial-and-error” approaches to data-driven molecular design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We feel the momentum deeply, especially in our inboxes. A year and a half ago, when we founded the company, there was a lot of skepticism,” Gertz told TechCrunch. That skepticism has vanished remarkably quickly, thanks to successful case studies from companies like Converge and from academia, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Large language models are gaining attention in drug discovery for their ability to analyze biological sequences and suggest new molecules, but challenges like hallucinations and accuracy remain. “In text, hallucinations are usually easy to spot,” the CEO said. “In molecules, validating a novel compound can take weeks, so the cost is much higher.” To tackle this, Converge pairs generative models with predictive ones, filtering new molecules to reduce risk and improve outcomes for its partners. “This filtration isn’t perfect, but it significantly reduces risk and delivers better outcomes for our customers,” Gertz added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch also asked about experts like Yann LeCun, who remain skeptical about using LLMs. “I’m a huge fan of Yann LeCun, and I completely agree with him. We don’t rely on text-based models for core scientific understanding. To truly understand biology, models need to be trained on DNA, RNA, proteins, and small molecules,” Gertz explained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Text-based LLMs are used only as support tools, for example, to help customers navigate literature on generated molecules. “They’re not our core technology,” Gertz said. “We’re not tied to a single architecture. We use LLMs, diffusion models, traditional machine learning, and statistical methods when it makes sense.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our vision is that every life-science organization will use Converge Bio as its generative AI lab. Wet labs will always exist, but they’ll be paired with generative labs that create hypotheses and molecules computationally. We want to be that generative lab for the entire industry,” Gertz said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;The article has been updated to include information on the number of customers&lt;/em&gt;. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Artificial intelligence is moving quickly into drug discovery as pharmaceutical and biotech companies look for ways to cut years off R&amp;amp;D timelines and increase the chances of success amid rising costs. More than 200 startups are now competing to weave AI directly into research workflows, attracting growing interest from investors. Converge Bio is the latest company to ride that shift, securing new capital as competition in the AI-driven drug discovery space heats up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Boston- and Tel Aviv-based startup, which helps pharma and biotech companies develop drugs faster using generative AI trained on molecular data, has raised a $25 million oversubscribed Series A round, led by Bessemer Venture Partners. TLV Partners, Saras Capital, and Vintage Investment Partners also joined the round, along with additional backing from unidentified executives at Meta, OpenAI, and Wiz.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In practice, Converge trains generative models on DNA, RNA, and protein sequences, then plugs them into pharma and biotech’s workflows to speed up drug development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The drug-development lifecycle has defined stages — from target identification and discovery to manufacturing, clinical trials, and beyond — and within each, there are experiments we can support,” Converge Bio CEO and co-founder Dov Gertz said in an exclusive interview with TechCrunch. “Our platform continues to expand across these stages, helping bring new drugs to market faster.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Converge has rolled out customer-facing systems. The startup has already introduced three discrete AI systems: one for antibody design, one for protein yield optimization, and one for biomarker and target discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Take our antibody design system as an example. It’s not just a single model. It’s made up of three integrated components. First, a generative model creates novel antibodies. Next, predictive models filter those antibodies based on their molecular properties. Finally, a docking system, which uses a physics-based model, simulates the three-dimensional interactions between the antibody and its target,” Gertz continued. The value lies in the system as a whole, not any single model, according to the CEO. “Our customers don’t have to piece models together themselves. They get ready-to-use systems that plug directly into their workflows.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding comes about a year and a half after the company raised a $5.5 million seed round in 2024. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, the two-year-old startup has scaled quickly. Converge has completed over 40 programs with more than a dozen pharmaceutical and biotech customers, Gertz said. It works with customers across the U.S., Canada, Europe, and Israel and is now expanding into Asia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team has also grown rapidly, increasing to 34 employees from just nine in November 2024. Along the way, Converge has begun publishing public case studies. In one, the startup helped a partner boost protein yield by 4 to 4.5X in a single computational iteration. In another, the platform generated antibodies with extremely high binding affinity, reaching the single-nanomolar range, Gertz noted.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3081729" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/Converge-Bio-9976.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Converge Bio&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;AI-driven drug discovery is experiencing a surge of interest. Last year, Eli Lilly teamed up with Nvidia to build what the companies called the pharma industry’s most powerful supercomputer for drug discovery. And in October 2024, the developers behind Google DeepMind’s AlphaFold project won a Nobel Prize in Chemistry for creating AlphaFold, the AI system that can predict protein structures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about the momentum and how it is shaping Converge Bio’s growth, Gertz said that the company is witnessing the largest financial opportunity in the history of life sciences and the industry is shifting from “trial-and-error” approaches to data-driven molecular design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We feel the momentum deeply, especially in our inboxes. A year and a half ago, when we founded the company, there was a lot of skepticism,” Gertz told TechCrunch. That skepticism has vanished remarkably quickly, thanks to successful case studies from companies like Converge and from academia, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Large language models are gaining attention in drug discovery for their ability to analyze biological sequences and suggest new molecules, but challenges like hallucinations and accuracy remain. “In text, hallucinations are usually easy to spot,” the CEO said. “In molecules, validating a novel compound can take weeks, so the cost is much higher.” To tackle this, Converge pairs generative models with predictive ones, filtering new molecules to reduce risk and improve outcomes for its partners. “This filtration isn’t perfect, but it significantly reduces risk and delivers better outcomes for our customers,” Gertz added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch also asked about experts like Yann LeCun, who remain skeptical about using LLMs. “I’m a huge fan of Yann LeCun, and I completely agree with him. We don’t rely on text-based models for core scientific understanding. To truly understand biology, models need to be trained on DNA, RNA, proteins, and small molecules,” Gertz explained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Text-based LLMs are used only as support tools, for example, to help customers navigate literature on generated molecules. “They’re not our core technology,” Gertz said. “We’re not tied to a single architecture. We use LLMs, diffusion models, traditional machine learning, and statistical methods when it makes sense.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our vision is that every life-science organization will use Converge Bio as its generative AI lab. Wet labs will always exist, but they’ll be paired with generative labs that create hypotheses and molecules computationally. We want to be that generative lab for the entire industry,” Gertz said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;The article has been updated to include information on the number of customers&lt;/em&gt;. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/ai-drug-discovery-startup-converge-bio-pulls-in-25m-from-bessemer-and-execs-from-meta-openai-and-wiz/</guid><pubDate>Tue, 13 Jan 2026 11:30:00 +0000</pubDate></item><item><title>[NEW] Signal creator Moxie Marlinspike wants to do for AI what he did for messaging (AI - Ars Technica)</title><link>https://arstechnica.com/security/2026/01/signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging/</link><description>&lt;article class="double-column h-entry post-2135075 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-features category-security tag-ai tag-end-to-end-encryptioon tag-llms tag-privacy"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Introducing Confer, an end-to-end AI assistant that just works.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-640x448.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Moxie Marlinspike—the pseudonym of an engineer who set a new standard for private messaging with the creation of the Signal Messenger—is now aiming to revolutionize AI chatbots in a similar way.&lt;/p&gt;
&lt;p&gt;His latest brainchild is Confer, an open source AI assistant that provides strong assurances that user data is unreadable to the platform operator, hackers, law enforcement, or any other party other than account holders. The service—including its large language models and back-end components—runs entirely on open source software that users can cryptographically verify is in place.&lt;/p&gt;
&lt;p&gt;Data and conversations originating from users and the resulting responses from the LLMs are encrypted in a trusted execution environment (TEE) that prevents even server administrators from peeking at or tampering with them. Conversations are stored by Confer in the same encrypted form, which uses a key that remains securely on users’ devices.&lt;/p&gt;
&lt;p&gt;Like Signal, the under-the-hood workings of Confer are elegant in their design and simplicity. Signal was the first end-user privacy tool that made using it a snap. Prior to that, using PGP email or other options to establish encrypted channels between two users was a cumbersome process that was easy to botch. Signal broke that mold. Key management was no longer a task users had to worry about. Signal was designed to prevent even the platform operators from peering into messages or identifying users’ real-world identities.&lt;/p&gt;
&lt;h2&gt;“Inherent data collectors”&lt;/h2&gt;
&lt;p&gt;All major platforms are required to turn over user data to law enforcement or private parties in a lawsuit when either provides a valid subpoena. Even when users opt out of having their data stored long term, parties to a lawsuit can compel the platform to store it, as the world learned last May when a court ordered OpenAI to preserve all ChatGPT users’ logs—including deleted chats and sensitive chats logged through its API business offering. Sam Altman, CEO of OpenAI, has said such rulings mean even psychotherapy sessions on the platform may not stay private. Another carve out to opting out: AI platforms like Google Gemini may have humans read chats.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Data privacy expert Em (she keeps her last name off the Internet) called AI assistants the “archnemesis” of data privacy because their utility relies on assembling massive amounts of data from myriad sources, including individuals.&lt;/p&gt;
&lt;p&gt;“AI models are inherent data collectors,” she told Ars. “They rely on large data collection for training, improvements, operations, and customizations. More often than not, this data is collected without clear and informed consent (from unknowing training subjects or from platform users), and is sent to and accessed by a private company with many incentives to share and monetize this data.”&lt;/p&gt;
&lt;p&gt;The lack of user-control is especially problematic given the nature of LLM interactions, Marlinspike says. Users often treat dialogue as an intimate conversation. Users share their thoughts, fears, transgressions, business dealings, and deepest, darkest secrets as if AI assistants are trusted confidants or personal journals. The interactions are fundamentally different from traditional web search queries, which usually adhere to a transactional model of keywords in and links out.&lt;/p&gt;
&lt;p&gt;He likens AI use to confessing into a “data lake.”&lt;/p&gt;
&lt;h2&gt;Awaking from the nightmare that is today’s AI landscape&lt;/h2&gt;
&lt;p&gt;In response, Marlinspike has developed and is now trialing Confer. In much the way Signal uses encryption to make messages readable only to parties participating in a conversation, Confer protects user prompts, AI responses, and all data included in them. And just like Signal, there’s no way to tie individual users to their real-world identity through their email address, IP address, or other details.&lt;/p&gt;
&lt;p&gt;“The character of the interaction is fundamentally different because it’s a private interaction,” Marlinspike told Ars. “It’s been really interesting and encouraging and amazing to hear stories from people who have used Confer and had life-changing conversations, in part because they haven’t felt free to include information in those conversations with sources like ChatGPT or they had insights using data that they weren’t really free to share with ChatGPT before but can using an environment like Confer.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;One of the main ingredients of Confer encryption is passkeys. The industry-wide standard generates a 32-byte encryption keypair that’s unique to each service a user logs in to. The public key is sent to the server. The private key is stored only on the user device, inside protected storage hardware that hackers (even those with physical access) can’t access. Passkeys provide two-factor authentication and can be configured to log in to an account with a fingerprint, face scan (both of which also stay securely on a device), or a device unlock PIN or passcode.&lt;/p&gt;
&lt;p&gt;The private key allows the device to log in to Confer and encrypt all input and output with encryption that’s widely believed to be impossible to break. That allows users to store conversations on Confer servers with confidence that they can’t be read by anyone other than themselves. The storage allows conversations to sync across other devices the user owns. The code making this all work is available for anyone to inspect. It looks like this:&lt;/p&gt;
&lt;div class="language-typescript highlighter-rouge"&gt;
&lt;div class="highlight"&gt;
&lt;pre class="highlight"&gt;&lt;code&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;assertion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nb"&gt;navigator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;credentials&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="na"&gt;mediation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;optional&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;publicKey&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="na"&gt;challenge&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;crypto&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getRandomValues&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
      &lt;span class="na"&gt;allowCredentials&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;credId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;public-key&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt; &lt;span class="p"&gt;}],&lt;/span&gt;
      &lt;span class="na"&gt;userVerification&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;required&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="na"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;prf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;first&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;salt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nx"&gt;PublicKeyCredential&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;prf&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;assertion&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getClientExtensionResults&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;rawKey&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;prf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;first&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2135083 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="2018" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1024x2018.png" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Confer

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2135150 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="2018" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1024x2018.png" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Confer

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This robust internal engine is fronted by a user interface (shown in the two images above) that’s deceptively simple. In just two strokes, a user is logged in, and all previous chats are decrypted. These chats are then available to any device logged in to the same account. This way, Confer can sync chats without compromising privacy. The ample 32 bytes of key material allow the private key to change regularly, a feature that allows for forward secrecy, meaning that in the event a key is compromised, an attacker cannot read previous or future chats.&lt;/p&gt;
&lt;p&gt;The other main Confer ingredient is a TEE on the platform servers. TEEs encrypt all data and code flowing through the server CPU, protecting them from being read or modified by someone with administrative access to the machine. The Confer TEE also provides remote attestation. Remote attestation is a digital certificate sent by the server that cryptographically verifies that data and software are running inside the TEE and lists all software running on it.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Confer, remote attestation allows anyone to reproduce the bit-by-bit outputs that confirm that the publicly available proxy and image software—and only that software—is running on the server. To further verify Confer is running as promised, each release is digitally signed and published in a transparency log.&lt;/p&gt;
&lt;p&gt;Native support for Confer is available in the most recent versions of macOS, iOS, and Android. On Windows, users must install a third-party authenticator. Linux support also doesn’t exist, although this extension bridges that gap.&lt;/p&gt;
&lt;h2&gt;There are other private LLMs, but none from the big players&lt;/h2&gt;
&lt;p&gt;Another publicly available LLM offering E2EE is Lumo, provided by Proton, a European company that’s behind the popular encrypted email service. It adopts the same encryption engine used by Proton Mail, Drive, and Calendar. The internals of the engine are considerably more complicated than Confer because they rely on a series of both symmetric and asymmetric keys. The end result for the user is largely the same, however.&lt;/p&gt;
&lt;p&gt;Once a user authenticates to their account, Proton says, all conversations, data, and metadata is encrypted with a symmetrical key that only the user has. Users can opt to store the encrypted data on Proton servers for device syncing or have it wiped immediately after the conversation is finished.&lt;/p&gt;
&lt;p&gt;A third LLM provider promising privacy is Venice. It stores all data locally, meaning on the user device. No data is stored on the remote server.&lt;/p&gt;
&lt;p&gt;Most of the big LLM platforms offer a means for users to exempt their conversations and data for marketing and training purposes. But as noted earlier, these promises often come with major carve-outs. Besides selected review by humans, personal data may still be used to enforce terms of service or for other internal purposes, even when users have opted out of default storage.&lt;/p&gt;
&lt;p&gt;Given today’s legal landscape—which allows most data stored online to be obtained with a subpoena—and the regular occurrence of blockbuster data breaches by hackers, there can be no reasonable expectation that personal data remains private.&lt;/p&gt;
&lt;p&gt;It would be great if big providers offered end-to-end encryption protections, but there’s currently no indication they plan to do so. Until then, a handful of smaller alternatives will keep user data out of the ever-growing data lake.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #f4ff81; background-color: #cddc39;"&gt;&lt;span class="ars-avatar-letter"&gt;q&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              quamquam quid loquor
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            &lt;blockquote class="xfBb-quote"&gt;In much the way Signal uses encryption to make messages readable only to parties participating in a conversation, Confer protects user prompts, AI responses, and all data included in them&lt;/blockquote&gt;The NYT court case shows how important this is. Even if AI companies want to delete your information they legally cannot. &lt;p&gt;This is an interesting angle to leverage the efficiencies of datacenter computing vs running a local LLM.&lt;/p&gt;&lt;p&gt;My guess is the world will divide into public clouds and local LLMs. Unfortunately these services won't find the scale they need.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-01-13T14:27:45+00:00"&gt;January 13, 2026 at 2:27 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2135075 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-features category-security tag-ai tag-end-to-end-encryptioon tag-llms tag-privacy"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Introducing Confer, an end-to-end AI assistant that just works.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-640x448.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Moxie Marlinspike—the pseudonym of an engineer who set a new standard for private messaging with the creation of the Signal Messenger—is now aiming to revolutionize AI chatbots in a similar way.&lt;/p&gt;
&lt;p&gt;His latest brainchild is Confer, an open source AI assistant that provides strong assurances that user data is unreadable to the platform operator, hackers, law enforcement, or any other party other than account holders. The service—including its large language models and back-end components—runs entirely on open source software that users can cryptographically verify is in place.&lt;/p&gt;
&lt;p&gt;Data and conversations originating from users and the resulting responses from the LLMs are encrypted in a trusted execution environment (TEE) that prevents even server administrators from peeking at or tampering with them. Conversations are stored by Confer in the same encrypted form, which uses a key that remains securely on users’ devices.&lt;/p&gt;
&lt;p&gt;Like Signal, the under-the-hood workings of Confer are elegant in their design and simplicity. Signal was the first end-user privacy tool that made using it a snap. Prior to that, using PGP email or other options to establish encrypted channels between two users was a cumbersome process that was easy to botch. Signal broke that mold. Key management was no longer a task users had to worry about. Signal was designed to prevent even the platform operators from peering into messages or identifying users’ real-world identities.&lt;/p&gt;
&lt;h2&gt;“Inherent data collectors”&lt;/h2&gt;
&lt;p&gt;All major platforms are required to turn over user data to law enforcement or private parties in a lawsuit when either provides a valid subpoena. Even when users opt out of having their data stored long term, parties to a lawsuit can compel the platform to store it, as the world learned last May when a court ordered OpenAI to preserve all ChatGPT users’ logs—including deleted chats and sensitive chats logged through its API business offering. Sam Altman, CEO of OpenAI, has said such rulings mean even psychotherapy sessions on the platform may not stay private. Another carve out to opting out: AI platforms like Google Gemini may have humans read chats.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Data privacy expert Em (she keeps her last name off the Internet) called AI assistants the “archnemesis” of data privacy because their utility relies on assembling massive amounts of data from myriad sources, including individuals.&lt;/p&gt;
&lt;p&gt;“AI models are inherent data collectors,” she told Ars. “They rely on large data collection for training, improvements, operations, and customizations. More often than not, this data is collected without clear and informed consent (from unknowing training subjects or from platform users), and is sent to and accessed by a private company with many incentives to share and monetize this data.”&lt;/p&gt;
&lt;p&gt;The lack of user-control is especially problematic given the nature of LLM interactions, Marlinspike says. Users often treat dialogue as an intimate conversation. Users share their thoughts, fears, transgressions, business dealings, and deepest, darkest secrets as if AI assistants are trusted confidants or personal journals. The interactions are fundamentally different from traditional web search queries, which usually adhere to a transactional model of keywords in and links out.&lt;/p&gt;
&lt;p&gt;He likens AI use to confessing into a “data lake.”&lt;/p&gt;
&lt;h2&gt;Awaking from the nightmare that is today’s AI landscape&lt;/h2&gt;
&lt;p&gt;In response, Marlinspike has developed and is now trialing Confer. In much the way Signal uses encryption to make messages readable only to parties participating in a conversation, Confer protects user prompts, AI responses, and all data included in them. And just like Signal, there’s no way to tie individual users to their real-world identity through their email address, IP address, or other details.&lt;/p&gt;
&lt;p&gt;“The character of the interaction is fundamentally different because it’s a private interaction,” Marlinspike told Ars. “It’s been really interesting and encouraging and amazing to hear stories from people who have used Confer and had life-changing conversations, in part because they haven’t felt free to include information in those conversations with sources like ChatGPT or they had insights using data that they weren’t really free to share with ChatGPT before but can using an environment like Confer.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;One of the main ingredients of Confer encryption is passkeys. The industry-wide standard generates a 32-byte encryption keypair that’s unique to each service a user logs in to. The public key is sent to the server. The private key is stored only on the user device, inside protected storage hardware that hackers (even those with physical access) can’t access. Passkeys provide two-factor authentication and can be configured to log in to an account with a fingerprint, face scan (both of which also stay securely on a device), or a device unlock PIN or passcode.&lt;/p&gt;
&lt;p&gt;The private key allows the device to log in to Confer and encrypt all input and output with encryption that’s widely believed to be impossible to break. That allows users to store conversations on Confer servers with confidence that they can’t be read by anyone other than themselves. The storage allows conversations to sync across other devices the user owns. The code making this all work is available for anyone to inspect. It looks like this:&lt;/p&gt;
&lt;div class="language-typescript highlighter-rouge"&gt;
&lt;div class="highlight"&gt;
&lt;pre class="highlight"&gt;&lt;code&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;assertion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nb"&gt;navigator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;credentials&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="na"&gt;mediation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;optional&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;publicKey&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="na"&gt;challenge&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;crypto&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getRandomValues&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
      &lt;span class="na"&gt;allowCredentials&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;credId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;public-key&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt; &lt;span class="p"&gt;}],&lt;/span&gt;
      &lt;span class="na"&gt;userVerification&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;required&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="na"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;prf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;first&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;salt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nx"&gt;PublicKeyCredential&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;prf&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;assertion&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getClientExtensionResults&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;rawKey&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;prf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;first&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2135083 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="2018" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1024x2018.png" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Confer

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2135150 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="2018" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1024x2018.png" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Confer

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This robust internal engine is fronted by a user interface (shown in the two images above) that’s deceptively simple. In just two strokes, a user is logged in, and all previous chats are decrypted. These chats are then available to any device logged in to the same account. This way, Confer can sync chats without compromising privacy. The ample 32 bytes of key material allow the private key to change regularly, a feature that allows for forward secrecy, meaning that in the event a key is compromised, an attacker cannot read previous or future chats.&lt;/p&gt;
&lt;p&gt;The other main Confer ingredient is a TEE on the platform servers. TEEs encrypt all data and code flowing through the server CPU, protecting them from being read or modified by someone with administrative access to the machine. The Confer TEE also provides remote attestation. Remote attestation is a digital certificate sent by the server that cryptographically verifies that data and software are running inside the TEE and lists all software running on it.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Confer, remote attestation allows anyone to reproduce the bit-by-bit outputs that confirm that the publicly available proxy and image software—and only that software—is running on the server. To further verify Confer is running as promised, each release is digitally signed and published in a transparency log.&lt;/p&gt;
&lt;p&gt;Native support for Confer is available in the most recent versions of macOS, iOS, and Android. On Windows, users must install a third-party authenticator. Linux support also doesn’t exist, although this extension bridges that gap.&lt;/p&gt;
&lt;h2&gt;There are other private LLMs, but none from the big players&lt;/h2&gt;
&lt;p&gt;Another publicly available LLM offering E2EE is Lumo, provided by Proton, a European company that’s behind the popular encrypted email service. It adopts the same encryption engine used by Proton Mail, Drive, and Calendar. The internals of the engine are considerably more complicated than Confer because they rely on a series of both symmetric and asymmetric keys. The end result for the user is largely the same, however.&lt;/p&gt;
&lt;p&gt;Once a user authenticates to their account, Proton says, all conversations, data, and metadata is encrypted with a symmetrical key that only the user has. Users can opt to store the encrypted data on Proton servers for device syncing or have it wiped immediately after the conversation is finished.&lt;/p&gt;
&lt;p&gt;A third LLM provider promising privacy is Venice. It stores all data locally, meaning on the user device. No data is stored on the remote server.&lt;/p&gt;
&lt;p&gt;Most of the big LLM platforms offer a means for users to exempt their conversations and data for marketing and training purposes. But as noted earlier, these promises often come with major carve-outs. Besides selected review by humans, personal data may still be used to enforce terms of service or for other internal purposes, even when users have opted out of default storage.&lt;/p&gt;
&lt;p&gt;Given today’s legal landscape—which allows most data stored online to be obtained with a subpoena—and the regular occurrence of blockbuster data breaches by hackers, there can be no reasonable expectation that personal data remains private.&lt;/p&gt;
&lt;p&gt;It would be great if big providers offered end-to-end encryption protections, but there’s currently no indication they plan to do so. Until then, a handful of smaller alternatives will keep user data out of the ever-growing data lake.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #f4ff81; background-color: #cddc39;"&gt;&lt;span class="ars-avatar-letter"&gt;q&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              quamquam quid loquor
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            &lt;blockquote class="xfBb-quote"&gt;In much the way Signal uses encryption to make messages readable only to parties participating in a conversation, Confer protects user prompts, AI responses, and all data included in them&lt;/blockquote&gt;The NYT court case shows how important this is. Even if AI companies want to delete your information they legally cannot. &lt;p&gt;This is an interesting angle to leverage the efficiencies of datacenter computing vs running a local LLM.&lt;/p&gt;&lt;p&gt;My guess is the world will divide into public clouds and local LLMs. Unfortunately these services won't find the scale they need.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-01-13T14:27:45+00:00"&gt;January 13, 2026 at 2:27 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2026/01/signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging/</guid><pubDate>Tue, 13 Jan 2026 12:00:36 +0000</pubDate></item><item><title>[NEW] Brazil orders Meta to suspend policy banning third-party AI chatbots from WhatsApp (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/brazil-orders-meta-to-suspend-policy-banning-third-party-ai-chatbots-from-whatsapp/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/WhatsApp-Bubble.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Brazil’s competition watchdog has ordered WhatsApp to put on hold its policy that bars third-party AI companies from using its business API to offer chatbots on the app. The agency has also started an investigation against the company to determine if the policy is anti-competitive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“According to the investigations, there is possible&amp;nbsp;anti-competitive&amp;nbsp;conduct&amp;nbsp;of an exclusive nature&amp;nbsp;that&amp;nbsp;arises from the application of the New&amp;nbsp;WhatsApp&amp;nbsp;Terms&amp;nbsp;(“WhatsApp&amp;nbsp;Business&amp;nbsp;Solution&amp;nbsp;Terms”)&amp;nbsp;imposed by Meta to regulate the access and offer, by providers of artificial intelligence tools, of its technologies to WhatsApp users,” the Conselho Administrativo de Defesa Econômica (CADE) said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CADE said it would investigate if Meta’s terms are exclusionary to competitors and unduly favor Meta AI, the company’s chatbot that’s offered on WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta last October changed its terms of use for the WhatsApp Business API to ban third-party AI companies from offering their chatbots on the app. Companies like OpenAI, Perplexity, and Microsoft soon after noted that after the policy goes into force from January 15, their chatbots would no longer be offered on WhatsApp. Notably, Meta’s policy does not stop businesses from offering their own chatbots, AI-powered or otherwise, within WhatsApp to their customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CADE’s investigation comes after the European Union launched its own antitrust investigation into the new policy, as has Italy. If the EU finds Meta in breach of its antitrust rules, it could be fined up to 10% of its global revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has told AI providers that they can continue offering their AI chatbots to users in Italy even after the new rules go into force on January 15, according to a notice to developers seen by TechCrunch. The company could make a similar decision in Brazil following CADE’s order. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately respond to a request for a comment outside regular business hours.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company has consistently maintained that AI chatbots are straining its systems that were designed for different uses of its business API. Meta has even said in the past that people who want to use different chatbots can do so outside WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The purpose of the WhatsApp Business API is to help businesses provide customer support and send relevant updates. Our focus is on supporting the tens of thousands of businesses who are building these experiences on WhatsApp,” a Meta spokesperson said when the company changed the terms in October. &lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/WhatsApp-Bubble.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Brazil’s competition watchdog has ordered WhatsApp to put on hold its policy that bars third-party AI companies from using its business API to offer chatbots on the app. The agency has also started an investigation against the company to determine if the policy is anti-competitive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“According to the investigations, there is possible&amp;nbsp;anti-competitive&amp;nbsp;conduct&amp;nbsp;of an exclusive nature&amp;nbsp;that&amp;nbsp;arises from the application of the New&amp;nbsp;WhatsApp&amp;nbsp;Terms&amp;nbsp;(“WhatsApp&amp;nbsp;Business&amp;nbsp;Solution&amp;nbsp;Terms”)&amp;nbsp;imposed by Meta to regulate the access and offer, by providers of artificial intelligence tools, of its technologies to WhatsApp users,” the Conselho Administrativo de Defesa Econômica (CADE) said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CADE said it would investigate if Meta’s terms are exclusionary to competitors and unduly favor Meta AI, the company’s chatbot that’s offered on WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta last October changed its terms of use for the WhatsApp Business API to ban third-party AI companies from offering their chatbots on the app. Companies like OpenAI, Perplexity, and Microsoft soon after noted that after the policy goes into force from January 15, their chatbots would no longer be offered on WhatsApp. Notably, Meta’s policy does not stop businesses from offering their own chatbots, AI-powered or otherwise, within WhatsApp to their customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CADE’s investigation comes after the European Union launched its own antitrust investigation into the new policy, as has Italy. If the EU finds Meta in breach of its antitrust rules, it could be fined up to 10% of its global revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has told AI providers that they can continue offering their AI chatbots to users in Italy even after the new rules go into force on January 15, according to a notice to developers seen by TechCrunch. The company could make a similar decision in Brazil following CADE’s order. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately respond to a request for a comment outside regular business hours.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company has consistently maintained that AI chatbots are straining its systems that were designed for different uses of its business API. Meta has even said in the past that people who want to use different chatbots can do so outside WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The purpose of the WhatsApp Business API is to help businesses provide customer support and send relevant updates. Our focus is on supporting the tens of thousands of businesses who are building these experiences on WhatsApp,” a Meta spokesperson said when the company changed the terms in October. &lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/brazil-orders-meta-to-suspend-policy-banning-third-party-ai-chatbots-from-whatsapp/</guid><pubDate>Tue, 13 Jan 2026 12:21:47 +0000</pubDate></item><item><title>[NEW] The Download: sodium-ion batteries and China’s bright tech future (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/13/1131245/the-download-sodium-ion-batteries-and-chinas-bright-tech-future/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Sodium-ion batteries are making their way into cars—and the grid&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For decades, lithium-ion batteries have powered our phones, laptops, and electric vehicles. But lithium’s limited supply and volatile price have led the industry to seek more resilient alternatives. Enter: sodium-ion batteries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They work much like lithium-ion ones: they store and release energy by shuttling ions between two electrodes. But unlike lithium, a somewhat rare element that is currently mined in only a handful of countries, sodium is cheap and found everywhere.&amp;nbsp;Read why it’s poised to become more important to our energy future.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Sodium-ion batteries are one of&amp;nbsp;&lt;em&gt;MIT Technology Review’s&lt;/em&gt;&amp;nbsp;10 Breakthrough Technologies this year.&amp;nbsp;Take a look at what else made the list.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4 class="wp-block-heading"&gt;CES showed me why Chinese tech companies feel so optimistic&lt;/h4&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I decided to go to CES kind of at the last minute. Over the holiday break, contacts from China kept messaging me about their travel plans. After the umpteenth “See you in Vegas?” I caved. As a China tech writer based in the US, I have one week a year when my entire beat seems to come to me—no 20-hour flights required.&lt;/p&gt;  &lt;p&gt;CES, the Consumer Electronics Show, is the world’s biggest tech show, where companies launch new gadgets and announce new developments, and it happens every January. China has long had a presence at CES, but this year it showed up in a big way. Chinese companies showcased everything from AI gadgets to household appliances to robots, and the overall mood among them was upbeat.&amp;nbsp;Here’s why.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;This story was first featured in The Algorithm, our weekly newsletter giving you the inside story of what’s going on in AI.&amp;nbsp;Sign up&amp;nbsp;to receive it in your inbox every Monday.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;h4 class="wp-block-heading"&gt;This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity” &amp;nbsp;&lt;/h4&gt;  &lt;p&gt;At some point this month, a handful of volunteers will be injected with experimental gene therapies as part of an unusual clinical trial. The drugs are potential longevity therapies, says Ivan Morgunov, the CEO of Unlimited Bio, the company behind the trial.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The volunteers—who are covering their own travel and treatment costs—will receive a series of injections in their arms and legs. One of the therapies is designed to increase the blood supply to those muscles. The other is designed to support muscle growth. The company hopes to see improvements in strength, endurance, and recovery. It also plans to eventually trial similar therapies in the scalp (for baldness) and penis (for erectile dysfunction).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, some experts warn the trial is too small, and likely won’t reveal anything useful.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 Apple is teaming up with Google to give Siri an AI revamp&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;That’s a giant win for Google, and a blow for OpenAI. (CNBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump wants Elon Musk to help break Iran’s internet blackout&lt;/strong&gt;&lt;br /&gt;He’s appealing to Musk to let Iranians circumvent it with Starlink. (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Smuggled tech is Iran’s last link to the outside world.&lt;/em&gt;&amp;nbsp;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Right-wing influencers have flocked to Minneapolis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Their goal is to paint it as a lawless city, and justify ICE’s shooting of Renee Nicole Good. (Wired&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 The Pentagon is adopting Musk’s Grok AI chatbot&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Just as it faces a backlash across the world for making non-consensual deepfakes. (NPR)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;The UK is launching a formal probe into X.&lt;/em&gt;&amp;nbsp;(The Guardian)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;It’s also bringing in a new law which will make it illegal to make these sorts of images.&lt;/em&gt;&amp;nbsp;(BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The push to power AI is devastating coastal villages in Taiwan&lt;/strong&gt;&lt;br /&gt;A rapid expansion of wind energy is hurting farmers and fishers. (Rest of World)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Stop worrying about your AI footprint. Look at the big picture instead.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Don’t hold your breath for robots’ ChatGPT moment&lt;/strong&gt;&lt;br /&gt;AI has unlocked impressive advances in robotics, but we’re a very long way from human-level capabilities. (FT&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Will we ever trust humanoid robots in our homes?&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Meta is about to lay off hundreds of metaverse employees&lt;/strong&gt;&lt;br /&gt;Reality Labs is yesterday’s news—now it’s all about AI. (NYT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8 We could eradicate flu&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;A “universal” flu vaccine could be far better at protecting us than any existing option. (Vox&amp;nbsp;$)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 You can now reserve a hotel room on the moon&lt;/strong&gt;&lt;br /&gt;It’s all yours, for just $250,000. (Ars Technica)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;This astronaut is training tourists to fly in the world’s first commercial space station.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 AI images are complicating efforts to find some monkeys in Missouri&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;For real. 🙈 (AP)&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"In big cities, everyone is an isolated, atomized individual. People live in soundproof apartments, not knowing the surname of their neighbors.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;—A user on social media platform RedNote explains why a new app called ‘Are you dead’ has become popular in China,&amp;nbsp;Business Insider&amp;nbsp;reports.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1114650" src="https://wp.technologyreview.com/wp-content/uploads/2025/04/Unknown-3-thumb.jpg" /&gt;&lt;div class="image-credit"&gt;STUART BRADFORD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;AI is coming for music, too&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While large language models that generate text have exploded in the last three years, a different type of AI, based on what are called diffusion models, is having an unprecedented impact on creative domains.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By transforming random noise into coherent patterns, diffusion models can generate new images, videos, or speech, guided by text prompts or other input data. The best ones can create outputs indistinguishable from the work of people.&lt;/p&gt;  &lt;p&gt;Now these models are marching into a creative field that is arguably more vulnerable to disruption than any other: music. And their output encapsulates how difficult it’s becoming to define authorship and originality in the age of AI.&amp;nbsp;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O'Donnell&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Bricking&amp;nbsp;your phone&amp;nbsp;is the new Dry January.&amp;nbsp;&lt;br /&gt;+ If you’re hankering for an adventure this year, check out this&amp;nbsp;National Geographic&amp;nbsp;list.&lt;br /&gt;+ There are few people more furiously punk than women going through the menopause, as this&amp;nbsp;new TV show&amp;nbsp;demonstrates ($).&lt;br /&gt;+ Aww, look how&amp;nbsp;Pallas cats keep their paws warm in winter.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Sodium-ion batteries are making their way into cars—and the grid&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For decades, lithium-ion batteries have powered our phones, laptops, and electric vehicles. But lithium’s limited supply and volatile price have led the industry to seek more resilient alternatives. Enter: sodium-ion batteries.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They work much like lithium-ion ones: they store and release energy by shuttling ions between two electrodes. But unlike lithium, a somewhat rare element that is currently mined in only a handful of countries, sodium is cheap and found everywhere.&amp;nbsp;Read why it’s poised to become more important to our energy future.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Sodium-ion batteries are one of&amp;nbsp;&lt;em&gt;MIT Technology Review’s&lt;/em&gt;&amp;nbsp;10 Breakthrough Technologies this year.&amp;nbsp;Take a look at what else made the list.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4 class="wp-block-heading"&gt;CES showed me why Chinese tech companies feel so optimistic&lt;/h4&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I decided to go to CES kind of at the last minute. Over the holiday break, contacts from China kept messaging me about their travel plans. After the umpteenth “See you in Vegas?” I caved. As a China tech writer based in the US, I have one week a year when my entire beat seems to come to me—no 20-hour flights required.&lt;/p&gt;  &lt;p&gt;CES, the Consumer Electronics Show, is the world’s biggest tech show, where companies launch new gadgets and announce new developments, and it happens every January. China has long had a presence at CES, but this year it showed up in a big way. Chinese companies showcased everything from AI gadgets to household appliances to robots, and the overall mood among them was upbeat.&amp;nbsp;Here’s why.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;This story was first featured in The Algorithm, our weekly newsletter giving you the inside story of what’s going on in AI.&amp;nbsp;Sign up&amp;nbsp;to receive it in your inbox every Monday.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;h4 class="wp-block-heading"&gt;This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity” &amp;nbsp;&lt;/h4&gt;  &lt;p&gt;At some point this month, a handful of volunteers will be injected with experimental gene therapies as part of an unusual clinical trial. The drugs are potential longevity therapies, says Ivan Morgunov, the CEO of Unlimited Bio, the company behind the trial.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The volunteers—who are covering their own travel and treatment costs—will receive a series of injections in their arms and legs. One of the therapies is designed to increase the blood supply to those muscles. The other is designed to support muscle growth. The company hopes to see improvements in strength, endurance, and recovery. It also plans to eventually trial similar therapies in the scalp (for baldness) and penis (for erectile dysfunction).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, some experts warn the trial is too small, and likely won’t reveal anything useful.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 Apple is teaming up with Google to give Siri an AI revamp&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;That’s a giant win for Google, and a blow for OpenAI. (CNBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump wants Elon Musk to help break Iran’s internet blackout&lt;/strong&gt;&lt;br /&gt;He’s appealing to Musk to let Iranians circumvent it with Starlink. (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Smuggled tech is Iran’s last link to the outside world.&lt;/em&gt;&amp;nbsp;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Right-wing influencers have flocked to Minneapolis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Their goal is to paint it as a lawless city, and justify ICE’s shooting of Renee Nicole Good. (Wired&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 The Pentagon is adopting Musk’s Grok AI chatbot&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Just as it faces a backlash across the world for making non-consensual deepfakes. (NPR)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;The UK is launching a formal probe into X.&lt;/em&gt;&amp;nbsp;(The Guardian)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;It’s also bringing in a new law which will make it illegal to make these sorts of images.&lt;/em&gt;&amp;nbsp;(BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The push to power AI is devastating coastal villages in Taiwan&lt;/strong&gt;&lt;br /&gt;A rapid expansion of wind energy is hurting farmers and fishers. (Rest of World)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Stop worrying about your AI footprint. Look at the big picture instead.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Don’t hold your breath for robots’ ChatGPT moment&lt;/strong&gt;&lt;br /&gt;AI has unlocked impressive advances in robotics, but we’re a very long way from human-level capabilities. (FT&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Will we ever trust humanoid robots in our homes?&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Meta is about to lay off hundreds of metaverse employees&lt;/strong&gt;&lt;br /&gt;Reality Labs is yesterday’s news—now it’s all about AI. (NYT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8 We could eradicate flu&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;A “universal” flu vaccine could be far better at protecting us than any existing option. (Vox&amp;nbsp;$)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 You can now reserve a hotel room on the moon&lt;/strong&gt;&lt;br /&gt;It’s all yours, for just $250,000. (Ars Technica)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;This astronaut is training tourists to fly in the world’s first commercial space station.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 AI images are complicating efforts to find some monkeys in Missouri&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;For real. 🙈 (AP)&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"In big cities, everyone is an isolated, atomized individual. People live in soundproof apartments, not knowing the surname of their neighbors.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;—A user on social media platform RedNote explains why a new app called ‘Are you dead’ has become popular in China,&amp;nbsp;Business Insider&amp;nbsp;reports.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1114650" src="https://wp.technologyreview.com/wp-content/uploads/2025/04/Unknown-3-thumb.jpg" /&gt;&lt;div class="image-credit"&gt;STUART BRADFORD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;AI is coming for music, too&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While large language models that generate text have exploded in the last three years, a different type of AI, based on what are called diffusion models, is having an unprecedented impact on creative domains.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By transforming random noise into coherent patterns, diffusion models can generate new images, videos, or speech, guided by text prompts or other input data. The best ones can create outputs indistinguishable from the work of people.&lt;/p&gt;  &lt;p&gt;Now these models are marching into a creative field that is arguably more vulnerable to disruption than any other: music. And their output encapsulates how difficult it’s becoming to define authorship and originality in the age of AI.&amp;nbsp;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O'Donnell&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Bricking&amp;nbsp;your phone&amp;nbsp;is the new Dry January.&amp;nbsp;&lt;br /&gt;+ If you’re hankering for an adventure this year, check out this&amp;nbsp;National Geographic&amp;nbsp;list.&lt;br /&gt;+ There are few people more furiously punk than women going through the menopause, as this&amp;nbsp;new TV show&amp;nbsp;demonstrates ($).&lt;br /&gt;+ Aww, look how&amp;nbsp;Pallas cats keep their paws warm in winter.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/13/1131245/the-download-sodium-ion-batteries-and-chinas-bright-tech-future/</guid><pubDate>Tue, 13 Jan 2026 13:00:00 +0000</pubDate></item><item><title>[NEW] Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI (AI | VentureBeat)</title><link>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt; on Tuesday launched an entirely rebuilt version of &lt;a href="https://slack.com/help/articles/202026038-An-introduction-to-Slackbot"&gt;Slackbot&lt;/a&gt;, the company&amp;#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.&lt;/p&gt;&lt;p&gt;The new Slackbot, now generally available to &lt;a href="https://slack.com/pricing/businessplus"&gt;Business+&lt;/a&gt; and &lt;a href="https://slack.com/enterprise"&gt;Enterprise+&lt;/a&gt; customers, is Salesforce&amp;#x27;s most aggressive move yet to position Slack at the center of the emerging &amp;quot;agentic AI&amp;quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.&lt;/p&gt;&lt;p&gt;&amp;quot;Slackbot isn&amp;#x27;t just another copilot or AI assistant,&amp;quot; said &lt;a href="https://www.salesforce.com/company/parker-harris-bio/"&gt;Parker Harris&lt;/a&gt;, Salesforce co-founder and Slack&amp;#x27;s chief technology officer, in an exclusive interview with Salesforce. &amp;quot;It&amp;#x27;s the front door to the agentic enterprise, powered by Salesforce.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Harris was blunt about what distinguishes the new Slackbot from its predecessor: &amp;quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&amp;quot;&lt;/p&gt;&lt;p&gt;The original Slackbot, which has existed since Slack&amp;#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s two different things,&amp;quot; Harris explained. &amp;quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&amp;#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&amp;quot;&lt;/p&gt;&lt;p&gt;Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &amp;quot;People know what Slackbot is, and so we wanted to carry that forward,&amp;quot; Harris said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Anthropic&amp;#x27;s Claude powers the new Slackbot — and which AI models could come next&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot runs on &lt;a href="https://claude.ai/"&gt;Claude&lt;/a&gt;, Anthropic&amp;#x27;s large language model, a choice driven partly by compliance requirements. Slack&amp;#x27;s commercial service operates under &lt;a href="https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/"&gt;FedRAMP Moderate certification&lt;/a&gt; to serve U.S. federal government customers, and Harris said Anthropic was &amp;quot;the only provider that could give us a compliant LLM&amp;quot; when Slack began building the new system.&lt;/p&gt;&lt;p&gt;But that exclusivity won&amp;#x27;t last. &amp;quot;We are, this year, going to support additional providers,&amp;quot; Harris said. &amp;quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&amp;#x27;re going to use Gemini for some things.&amp;quot; He added that OpenAI remains a possibility as well.&lt;/p&gt;&lt;p&gt;Harris echoed Salesforce CEO Marc Benioff&amp;#x27;s view that large language models are becoming commoditized: &amp;quot;You&amp;#x27;ve heard Marc talk about LLMs are commodities, that they&amp;#x27;re democratized. I call them CPUs.&amp;quot;&lt;/p&gt;&lt;p&gt;On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &amp;quot;Models don&amp;#x27;t have any sort of security,&amp;quot; he explained. &amp;quot;If we trained it on some confidential conversation that you and I have, I don&amp;#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&amp;#x27;t.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Salesforce&amp;#x27;s internal experiment: 80,000 employees tested Slackbot with striking results&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce has been &lt;a href="https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade"&gt;testing the new Slackbot internally for months&lt;/a&gt;, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&amp;#x27;s chief marketing officer, the results have been striking: &amp;quot;It&amp;#x27;s the fastest adopted product in Salesforce history.&amp;quot;&lt;/p&gt;&lt;p&gt;Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.&lt;/p&gt;&lt;p&gt;The adoption happened largely organically. &amp;quot;I think it was about five days, and a Canvas was developed by our employees called &amp;#x27;The Most Stealable Slackbot Prompts,&amp;#x27;&amp;quot; Gavin said. &amp;quot;People just started adding to it organically. I think it&amp;#x27;s up to 250-plus prompts that are in this Canvas right now.&amp;quot;&lt;/p&gt;&lt;p&gt;Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &amp;quot;Everybody is there to help each other learn and communicate hacks,&amp;quot; she said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Slackbot transforms scattered enterprise data into executive-ready insights&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;During a product demonstration, Amy Bauer, Slack&amp;#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.&lt;/p&gt;&lt;p&gt;&amp;quot;This is where Slackbot really earns its keep for me,&amp;quot; Bauer explained. &amp;quot;What it&amp;#x27;s doing is not just simply reading the image — it&amp;#x27;s actually looking at the image and comparing it to the insight it just generated for me.&amp;quot;&lt;/p&gt;&lt;p&gt;Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &amp;quot;a really great justification and plan to move forward.&amp;quot; Finally, it can synthesize all that information into a Canvas — Slack&amp;#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.&lt;/p&gt;&lt;p&gt;&amp;quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&amp;quot; Bauer said. &amp;quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&amp;quot;&lt;/p&gt;&lt;p&gt;Rob Seaman, Slack&amp;#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &amp;quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&amp;#x27;re going with Slackbot — we&amp;#x27;re eventually going to be adding in additional third-party tool calls.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;MrBeast&amp;#x27;s company became a Slackbot guinea pig—and employees say they&amp;#x27;re saving 90 minutes a day&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Among Salesforce&amp;#x27;s pilot customers is &lt;a href="https://www.thecashmerefund.com/portfolio-company/beast-industries"&gt;Beast Industries&lt;/a&gt;, the parent company of YouTube star MrBeast. Luis Madrigal, the company&amp;#x27;s chief information officer, joined the launch announcement to describe his experience.&lt;/p&gt;&lt;p&gt;&amp;quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&amp;quot; Madrigal said. &amp;quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&amp;quot;&lt;/p&gt;&lt;p&gt;Madrigal said his security team signed off &amp;quot;rather quickly&amp;quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &amp;quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&amp;#x27;re part of—that made my security team sign off rather quickly.&amp;quot;&lt;/p&gt;&lt;p&gt;One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &amp;quot;at bare minimum, 90 minutes a day.&amp;quot; Another employee, Spencer, a creative supervisor, described it as &amp;quot;an assistant who&amp;#x27;s paying attention when I&amp;#x27;m not.&amp;quot;&lt;/p&gt;&lt;p&gt;Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &amp;quot;an absolute &amp;#x27;chaos tamer&amp;#x27; for our team,&amp;quot; estimating it saves her about 30 minutes daily &amp;quot;just by eliminating context switching.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch puts Salesforce in direct competition with &lt;a href="https://copilot.microsoft.com/"&gt;Microsoft&amp;#x27;s Copilot&lt;/a&gt;, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&amp;#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.&lt;/p&gt;&lt;p&gt;&amp;quot;The thing that makes it most powerful for our customers and users is the proximity — it&amp;#x27;s just right there in your Slack,&amp;quot; Seaman said. &amp;quot;There&amp;#x27;s a tremendous convenience affordance that&amp;#x27;s naturally built into it.&amp;quot;&lt;/p&gt;&lt;p&gt;The deeper advantage, executives argue, is that Slackbot already understands users&amp;#x27; work without requiring setup or training. &amp;quot;Most AI tools sound the same no matter who is using them,&amp;quot; the company&amp;#x27;s announcement stated. &amp;quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris put it more directly: &amp;quot;If you&amp;#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&amp;#x27;s a great experience from a consumer perspective — Slackbot is really what we&amp;#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&amp;quot;&lt;/p&gt;&lt;p&gt;Amy Bauer emphasized the frictionless nature of the experience. &amp;quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&amp;quot; she said. &amp;quot;So as you continue working in Slack, Slackbot gets better because it&amp;#x27;s grounded in the work that you&amp;#x27;re doing there. There is no setup. There is no configuration for those end users.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce&amp;#x27;s ambitious plan to make Slackbot the one &amp;#x27;super agent&amp;#x27; that controls all the others&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce positions Slackbot as what Harris calls a &amp;quot;super agent&amp;quot; — a central hub that can eventually coordinate with other AI agents across an organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Every corporation is going to have an employee super agent,&amp;quot; Harris said. &amp;quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&amp;#x27;re really excited about it, is going to be that.&amp;quot;&lt;/p&gt;&lt;p&gt;The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&amp;#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.&lt;/p&gt;&lt;p&gt;&amp;quot;Most of the net-new apps that are being deployed to Slack are agents,&amp;quot; Seaman noted during the press conference. &amp;quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris described a future where Slackbot becomes an &lt;a href="https://modelcontextprotocol.io/docs/learn/client-concepts"&gt;MCP (Model Context Protocol) client&lt;/a&gt;, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &amp;quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;But Harris also cautioned against over-promising on multi-agent coordination. &amp;quot;I still think we&amp;#x27;re in the single agent world,&amp;quot; he said. &amp;quot;FY26 is going to be the year where we started to see more coordination. But we&amp;#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &amp;#x27;I&amp;#x27;ve got 1,000 agents working together,&amp;#x27; because I think that&amp;#x27;s unrealistic.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot costs nothing extra, but Salesforce&amp;#x27;s data access fees could squeeze some customers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Slackbot is included at no additional cost for customers on &lt;a href="https://slack.com/pricing/businessplus"&gt;Business+&lt;/a&gt; and &lt;a href="https://slack.com/enterprise"&gt;Enterprise+&lt;/a&gt; plans. &amp;quot;There&amp;#x27;s no additional fees customers have to do,&amp;quot; Gavin confirmed. &amp;quot;If they&amp;#x27;re on one of those plans, they&amp;#x27;re going to get Slackbot.&amp;quot;&lt;/p&gt;&lt;p&gt;However, some enterprise customers may face other cost pressures related to Salesforce&amp;#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.&lt;/p&gt;&lt;p&gt;Fivetran CEO George Fraser has warned that Salesforce&amp;#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &amp;quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&amp;quot; Fraser said in a &lt;a href="https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html"&gt;recent CIO report&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Salesforce has framed the pricing change as standard industry practice.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Slackbot can do today, what&amp;#x27;s coming in weeks, and what&amp;#x27;s still on the roadmap&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &amp;quot;coming a few weeks after,&amp;quot; according to Seaman. Image generation is not currently supported, though Bauer said it&amp;#x27;s &amp;quot;something that we are looking at in the future.&amp;quot;&lt;/p&gt;&lt;p&gt;When asked about integration with competing CRM systems like &lt;a href="https://www.hubspot.com/"&gt;HubSpot&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/dynamics-365"&gt;Microsoft Dynamics&lt;/a&gt;, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce is betting the future of work looks like a chat window—and it&amp;#x27;s not alone&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Slackbot launch is Salesforce&amp;#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.&lt;/p&gt;&lt;p&gt;Harris described Slack&amp;#x27;s product philosophy using principles like &amp;quot;don&amp;#x27;t make me think&amp;quot; and &amp;quot;be a great host.&amp;quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&amp;quot; Harris said. &amp;quot;And the amount of value you have if you&amp;#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&amp;#x27;re talking about work, you&amp;#x27;re sharing documents, you&amp;#x27;re making decisions, but you can&amp;#x27;t as a human go through that and really get the same value that an LLM can do.&amp;quot;&lt;/p&gt;&lt;p&gt;Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &amp;quot;We&amp;#x27;re kind of saturating what we can do with purely conversational UIs,&amp;quot; he said. &amp;quot;I think we&amp;#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.&lt;/p&gt;&lt;p&gt;For Salesforce, the stakes extend beyond a single product launch. After a &lt;a href="https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399"&gt;bruising year&lt;/a&gt; on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.&lt;/p&gt;&lt;p&gt;Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &amp;quot;I honestly can&amp;#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&amp;quot;&lt;/p&gt;&lt;p&gt;That&amp;#x27;s precisely what Salesforce is counting on.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt; on Tuesday launched an entirely rebuilt version of &lt;a href="https://slack.com/help/articles/202026038-An-introduction-to-Slackbot"&gt;Slackbot&lt;/a&gt;, the company&amp;#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.&lt;/p&gt;&lt;p&gt;The new Slackbot, now generally available to &lt;a href="https://slack.com/pricing/businessplus"&gt;Business+&lt;/a&gt; and &lt;a href="https://slack.com/enterprise"&gt;Enterprise+&lt;/a&gt; customers, is Salesforce&amp;#x27;s most aggressive move yet to position Slack at the center of the emerging &amp;quot;agentic AI&amp;quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.&lt;/p&gt;&lt;p&gt;&amp;quot;Slackbot isn&amp;#x27;t just another copilot or AI assistant,&amp;quot; said &lt;a href="https://www.salesforce.com/company/parker-harris-bio/"&gt;Parker Harris&lt;/a&gt;, Salesforce co-founder and Slack&amp;#x27;s chief technology officer, in an exclusive interview with Salesforce. &amp;quot;It&amp;#x27;s the front door to the agentic enterprise, powered by Salesforce.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Harris was blunt about what distinguishes the new Slackbot from its predecessor: &amp;quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&amp;quot;&lt;/p&gt;&lt;p&gt;The original Slackbot, which has existed since Slack&amp;#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s two different things,&amp;quot; Harris explained. &amp;quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&amp;#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&amp;quot;&lt;/p&gt;&lt;p&gt;Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &amp;quot;People know what Slackbot is, and so we wanted to carry that forward,&amp;quot; Harris said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Anthropic&amp;#x27;s Claude powers the new Slackbot — and which AI models could come next&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot runs on &lt;a href="https://claude.ai/"&gt;Claude&lt;/a&gt;, Anthropic&amp;#x27;s large language model, a choice driven partly by compliance requirements. Slack&amp;#x27;s commercial service operates under &lt;a href="https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/"&gt;FedRAMP Moderate certification&lt;/a&gt; to serve U.S. federal government customers, and Harris said Anthropic was &amp;quot;the only provider that could give us a compliant LLM&amp;quot; when Slack began building the new system.&lt;/p&gt;&lt;p&gt;But that exclusivity won&amp;#x27;t last. &amp;quot;We are, this year, going to support additional providers,&amp;quot; Harris said. &amp;quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&amp;#x27;re going to use Gemini for some things.&amp;quot; He added that OpenAI remains a possibility as well.&lt;/p&gt;&lt;p&gt;Harris echoed Salesforce CEO Marc Benioff&amp;#x27;s view that large language models are becoming commoditized: &amp;quot;You&amp;#x27;ve heard Marc talk about LLMs are commodities, that they&amp;#x27;re democratized. I call them CPUs.&amp;quot;&lt;/p&gt;&lt;p&gt;On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &amp;quot;Models don&amp;#x27;t have any sort of security,&amp;quot; he explained. &amp;quot;If we trained it on some confidential conversation that you and I have, I don&amp;#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&amp;#x27;t.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Salesforce&amp;#x27;s internal experiment: 80,000 employees tested Slackbot with striking results&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce has been &lt;a href="https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade"&gt;testing the new Slackbot internally for months&lt;/a&gt;, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&amp;#x27;s chief marketing officer, the results have been striking: &amp;quot;It&amp;#x27;s the fastest adopted product in Salesforce history.&amp;quot;&lt;/p&gt;&lt;p&gt;Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.&lt;/p&gt;&lt;p&gt;The adoption happened largely organically. &amp;quot;I think it was about five days, and a Canvas was developed by our employees called &amp;#x27;The Most Stealable Slackbot Prompts,&amp;#x27;&amp;quot; Gavin said. &amp;quot;People just started adding to it organically. I think it&amp;#x27;s up to 250-plus prompts that are in this Canvas right now.&amp;quot;&lt;/p&gt;&lt;p&gt;Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &amp;quot;Everybody is there to help each other learn and communicate hacks,&amp;quot; she said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Slackbot transforms scattered enterprise data into executive-ready insights&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;During a product demonstration, Amy Bauer, Slack&amp;#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.&lt;/p&gt;&lt;p&gt;&amp;quot;This is where Slackbot really earns its keep for me,&amp;quot; Bauer explained. &amp;quot;What it&amp;#x27;s doing is not just simply reading the image — it&amp;#x27;s actually looking at the image and comparing it to the insight it just generated for me.&amp;quot;&lt;/p&gt;&lt;p&gt;Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &amp;quot;a really great justification and plan to move forward.&amp;quot; Finally, it can synthesize all that information into a Canvas — Slack&amp;#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.&lt;/p&gt;&lt;p&gt;&amp;quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&amp;quot; Bauer said. &amp;quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&amp;quot;&lt;/p&gt;&lt;p&gt;Rob Seaman, Slack&amp;#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &amp;quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&amp;#x27;re going with Slackbot — we&amp;#x27;re eventually going to be adding in additional third-party tool calls.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;MrBeast&amp;#x27;s company became a Slackbot guinea pig—and employees say they&amp;#x27;re saving 90 minutes a day&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Among Salesforce&amp;#x27;s pilot customers is &lt;a href="https://www.thecashmerefund.com/portfolio-company/beast-industries"&gt;Beast Industries&lt;/a&gt;, the parent company of YouTube star MrBeast. Luis Madrigal, the company&amp;#x27;s chief information officer, joined the launch announcement to describe his experience.&lt;/p&gt;&lt;p&gt;&amp;quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&amp;quot; Madrigal said. &amp;quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&amp;quot;&lt;/p&gt;&lt;p&gt;Madrigal said his security team signed off &amp;quot;rather quickly&amp;quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &amp;quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&amp;#x27;re part of—that made my security team sign off rather quickly.&amp;quot;&lt;/p&gt;&lt;p&gt;One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &amp;quot;at bare minimum, 90 minutes a day.&amp;quot; Another employee, Spencer, a creative supervisor, described it as &amp;quot;an assistant who&amp;#x27;s paying attention when I&amp;#x27;m not.&amp;quot;&lt;/p&gt;&lt;p&gt;Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &amp;quot;an absolute &amp;#x27;chaos tamer&amp;#x27; for our team,&amp;quot; estimating it saves her about 30 minutes daily &amp;quot;just by eliminating context switching.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch puts Salesforce in direct competition with &lt;a href="https://copilot.microsoft.com/"&gt;Microsoft&amp;#x27;s Copilot&lt;/a&gt;, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&amp;#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.&lt;/p&gt;&lt;p&gt;&amp;quot;The thing that makes it most powerful for our customers and users is the proximity — it&amp;#x27;s just right there in your Slack,&amp;quot; Seaman said. &amp;quot;There&amp;#x27;s a tremendous convenience affordance that&amp;#x27;s naturally built into it.&amp;quot;&lt;/p&gt;&lt;p&gt;The deeper advantage, executives argue, is that Slackbot already understands users&amp;#x27; work without requiring setup or training. &amp;quot;Most AI tools sound the same no matter who is using them,&amp;quot; the company&amp;#x27;s announcement stated. &amp;quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris put it more directly: &amp;quot;If you&amp;#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&amp;#x27;s a great experience from a consumer perspective — Slackbot is really what we&amp;#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&amp;quot;&lt;/p&gt;&lt;p&gt;Amy Bauer emphasized the frictionless nature of the experience. &amp;quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&amp;quot; she said. &amp;quot;So as you continue working in Slack, Slackbot gets better because it&amp;#x27;s grounded in the work that you&amp;#x27;re doing there. There is no setup. There is no configuration for those end users.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce&amp;#x27;s ambitious plan to make Slackbot the one &amp;#x27;super agent&amp;#x27; that controls all the others&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce positions Slackbot as what Harris calls a &amp;quot;super agent&amp;quot; — a central hub that can eventually coordinate with other AI agents across an organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Every corporation is going to have an employee super agent,&amp;quot; Harris said. &amp;quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&amp;#x27;re really excited about it, is going to be that.&amp;quot;&lt;/p&gt;&lt;p&gt;The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&amp;#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.&lt;/p&gt;&lt;p&gt;&amp;quot;Most of the net-new apps that are being deployed to Slack are agents,&amp;quot; Seaman noted during the press conference. &amp;quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris described a future where Slackbot becomes an &lt;a href="https://modelcontextprotocol.io/docs/learn/client-concepts"&gt;MCP (Model Context Protocol) client&lt;/a&gt;, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &amp;quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;But Harris also cautioned against over-promising on multi-agent coordination. &amp;quot;I still think we&amp;#x27;re in the single agent world,&amp;quot; he said. &amp;quot;FY26 is going to be the year where we started to see more coordination. But we&amp;#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &amp;#x27;I&amp;#x27;ve got 1,000 agents working together,&amp;#x27; because I think that&amp;#x27;s unrealistic.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot costs nothing extra, but Salesforce&amp;#x27;s data access fees could squeeze some customers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Slackbot is included at no additional cost for customers on &lt;a href="https://slack.com/pricing/businessplus"&gt;Business+&lt;/a&gt; and &lt;a href="https://slack.com/enterprise"&gt;Enterprise+&lt;/a&gt; plans. &amp;quot;There&amp;#x27;s no additional fees customers have to do,&amp;quot; Gavin confirmed. &amp;quot;If they&amp;#x27;re on one of those plans, they&amp;#x27;re going to get Slackbot.&amp;quot;&lt;/p&gt;&lt;p&gt;However, some enterprise customers may face other cost pressures related to Salesforce&amp;#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.&lt;/p&gt;&lt;p&gt;Fivetran CEO George Fraser has warned that Salesforce&amp;#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &amp;quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&amp;quot; Fraser said in a &lt;a href="https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html"&gt;recent CIO report&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Salesforce has framed the pricing change as standard industry practice.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Slackbot can do today, what&amp;#x27;s coming in weeks, and what&amp;#x27;s still on the roadmap&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &amp;quot;coming a few weeks after,&amp;quot; according to Seaman. Image generation is not currently supported, though Bauer said it&amp;#x27;s &amp;quot;something that we are looking at in the future.&amp;quot;&lt;/p&gt;&lt;p&gt;When asked about integration with competing CRM systems like &lt;a href="https://www.hubspot.com/"&gt;HubSpot&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/dynamics-365"&gt;Microsoft Dynamics&lt;/a&gt;, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce is betting the future of work looks like a chat window—and it&amp;#x27;s not alone&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Slackbot launch is Salesforce&amp;#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.&lt;/p&gt;&lt;p&gt;Harris described Slack&amp;#x27;s product philosophy using principles like &amp;quot;don&amp;#x27;t make me think&amp;quot; and &amp;quot;be a great host.&amp;quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&amp;quot; Harris said. &amp;quot;And the amount of value you have if you&amp;#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&amp;#x27;re talking about work, you&amp;#x27;re sharing documents, you&amp;#x27;re making decisions, but you can&amp;#x27;t as a human go through that and really get the same value that an LLM can do.&amp;quot;&lt;/p&gt;&lt;p&gt;Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &amp;quot;We&amp;#x27;re kind of saturating what we can do with purely conversational UIs,&amp;quot; he said. &amp;quot;I think we&amp;#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.&lt;/p&gt;&lt;p&gt;For Salesforce, the stakes extend beyond a single product launch. After a &lt;a href="https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399"&gt;bruising year&lt;/a&gt; on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.&lt;/p&gt;&lt;p&gt;Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &amp;quot;I honestly can&amp;#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&amp;quot;&lt;/p&gt;&lt;p&gt;That&amp;#x27;s precisely what Salesforce is counting on.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</guid><pubDate>Tue, 13 Jan 2026 13:00:00 +0000</pubDate></item><item><title>[NEW] Slackbot is an AI agent now (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/slackbot-is-an-ai-agent-now/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Slackbot.png?resize=1200,785" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Slackbot, the automated assistant baked into the Salesforce-owned corporate messaging platform Slack, is entering a new era as an AI agent. And Salesforce CTO Parker Harris hopes it will be as viral as OpenAI’s ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud software giant rolled out the new version of Slackbot on Tuesday. This new AI agent version of Slackbot, which is generally available for Business+ and Enterprise+ customers, can find information, draft emails, and schedule meetings, among other things, all within the Slack platform, according to the company. It can also connect to, and interact with, other enterprise products like Microsoft Teams and Google Drive to find information if it’s granted permission. This allows users to work across a handful of different common enterprise applications without leaving Slack.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Salesforce, and its enterprise software competitors, are pouring resources into the development of AI products in a bid to preserve, and even grow, their market share. The remodeled Slackbot, which was originally announced at Salesforce’s annual Dreamforce conference in October, is just one piece of Salesforce’s enterprise AI-heavy product plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harris told TechCrunch the next-gen Slackbot is completely different than what existed before; the company kept the name because it is already well known.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harris added that Slack doesn’t generally release new features. Instead, Slack typically issues updates to the product to help drive adoption, which makes Slackbot quite different from past product updates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is an agent, it is a super agent that is your employee agent,” Harris said. “It’s powered by generative AI, and it is something that is highly crafted and highly curated to be an agentic experience that employees and users love.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce tests new products, like Slackbot, with its employees for months before they release them — Harris joked they like to drink their own champagne first. Slackbot has been the most adopted internal tool they’ve released, he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Just seeing the sheer active user count is a great sign we have hit on product-market-fit,” Harris said about internal adoption. “Adopted, not mandated, in corporations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is just the beginning of Slackbot’s second bloom as an AI agent, Harris said. In the future, they want Slackbot to move beyond just a text-based agent only in Slack. He said they want to add voice capabilities in the future and the ability for Slackbot to browse the internet alongside its users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am very confident that investing in Slackbot is not only good for Slack, it will be incredibly good for the entire company,” Harris said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Slackbot.png?resize=1200,785" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Slackbot, the automated assistant baked into the Salesforce-owned corporate messaging platform Slack, is entering a new era as an AI agent. And Salesforce CTO Parker Harris hopes it will be as viral as OpenAI’s ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud software giant rolled out the new version of Slackbot on Tuesday. This new AI agent version of Slackbot, which is generally available for Business+ and Enterprise+ customers, can find information, draft emails, and schedule meetings, among other things, all within the Slack platform, according to the company. It can also connect to, and interact with, other enterprise products like Microsoft Teams and Google Drive to find information if it’s granted permission. This allows users to work across a handful of different common enterprise applications without leaving Slack.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Salesforce, and its enterprise software competitors, are pouring resources into the development of AI products in a bid to preserve, and even grow, their market share. The remodeled Slackbot, which was originally announced at Salesforce’s annual Dreamforce conference in October, is just one piece of Salesforce’s enterprise AI-heavy product plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harris told TechCrunch the next-gen Slackbot is completely different than what existed before; the company kept the name because it is already well known.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harris added that Slack doesn’t generally release new features. Instead, Slack typically issues updates to the product to help drive adoption, which makes Slackbot quite different from past product updates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is an agent, it is a super agent that is your employee agent,” Harris said. “It’s powered by generative AI, and it is something that is highly crafted and highly curated to be an agentic experience that employees and users love.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce tests new products, like Slackbot, with its employees for months before they release them — Harris joked they like to drink their own champagne first. Slackbot has been the most adopted internal tool they’ve released, he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Just seeing the sheer active user count is a great sign we have hit on product-market-fit,” Harris said about internal adoption. “Adopted, not mandated, in corporations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is just the beginning of Slackbot’s second bloom as an AI agent, Harris said. In the future, they want Slackbot to move beyond just a text-based agent only in Slack. He said they want to add voice capabilities in the future and the ability for Slackbot to browse the internet alongside its users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am very confident that investing in Slackbot is not only good for Slack, it will be incredibly good for the entire company,” Harris said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/slackbot-is-an-ai-agent-now/</guid><pubDate>Tue, 13 Jan 2026 13:00:00 +0000</pubDate></item><item><title>[NEW] Deepgram raises $130M at $1.3B valuation and buys a YC AI startup (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/deepgram-raises-130m-at-1-3b-valuation-and-buys-a-yc-ai-startup/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Usage of voice AI in sales, marketing, customer support, and consumer applications has shot up in the last few years. As a result, model providers have seen increased business, along with investor interest. On the back of this demand, today, Deepgram said that it has raised $130 million in a Series C round led by AVP at a $1.3 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round also saw existing investors such as Alkeon, In-Q-Tel, Madrona, Tiger, Wing, and Y Combinator put in more money. Plus, new investors like&amp;nbsp;Alumni Ventures, Columbia University, Princeville Capital, Twilio, and SAP joined the round. The company has raised over $215 million in funding to date. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup’s raise continues the trend of sizable funding rounds in voice AI last year, including Sesame’s $250 million Series B, ElevenLab’s $180 million Series C, and Gradium’s $70 million seed round.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elizabeth de Saint-Aignan, a partner at AVP, told TechCrunch that when the fund was talking to enterprises about how they were using AI, voice came up frequently, and it started looking into companies working in this area.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In 2024, when we were talking to enterprises about how they were thinking about using AI inside their business, we started to hear about them using voice AI in processes like contact centers and sales developments. When we chatted with them more, we realized a lot of voice AI tech was powered by Deepgram, and that’s what led us to them [Deepgram],” de Saint-Aignan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She noted that voice AI could help in making customers’ interactions with enterprises more pleasant while reducing costs for companies, and Deepgram could play a central part in it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deepgram has a bunch of models related to text-to-speech and speech-to-text, along with platforms and APIs for conversational speech recognition and interruption handling with low latency. It noted that more than 1,300 organizations use its voice AI products and models, including meeting notetaker Granola, voice agent startup Vapi, and Twilio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s CEO, Scott Stephenson, said that the company didn’t need the fundraise and it was cashflow positive last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In the last year, voice AI has gone mainstream, and there is more potential pull. We see that we can make larger investment sooner in order to accelerate growth. And that is why we felt it could be a good time to raise,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We weren’t out looking for a raise, though. We had multiple people coming to us. We wanted strategic investors who understand voice AI and the technical intricacies of it and have relationships with companies building using the technology.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company wants to use the new fundraising to expand its global footprint and better support multiple languages. It is also focusing on catering to restaurants through voice AI. To that end, it has acquired Y Combinator-backed OfOne, which built a voice AI-powered solution for quick-service restaurants. The startup claims that it has more than 93% accuracy in receiving orders. Voice AI has had its challenges in the restaurant space. Last year, Taco Bell withdrew its voice AI experiment after a person ordered 18,000 water cups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am excited about this [voice AI-driven food ordering] because food ordering might be the first positive interaction more than 300 million Americans have with voice AI. There have been a lot of sour interactions with voice AI over the last 20 years, where a lot of assistants have come out, and people felt that those didn’t provide a magical experience. But when you can order your food using natural conversation, people would think the technology is ready,” Stephenson said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There seems to be investor interest in the sector, as OfOne’s acquisition news comes after Presto, which serves brands like Carl’s Jr., picked up $10 million in new funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Analysts’ reports peg the voice market to grow at over 30% year-over-year and become a $14-$20 billion market by 2030. With this growth rate, model and API providers will look to be multibillion-dollar companies by becoming a core component for enterprises and startups developing voice solutions.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Usage of voice AI in sales, marketing, customer support, and consumer applications has shot up in the last few years. As a result, model providers have seen increased business, along with investor interest. On the back of this demand, today, Deepgram said that it has raised $130 million in a Series C round led by AVP at a $1.3 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round also saw existing investors such as Alkeon, In-Q-Tel, Madrona, Tiger, Wing, and Y Combinator put in more money. Plus, new investors like&amp;nbsp;Alumni Ventures, Columbia University, Princeville Capital, Twilio, and SAP joined the round. The company has raised over $215 million in funding to date. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup’s raise continues the trend of sizable funding rounds in voice AI last year, including Sesame’s $250 million Series B, ElevenLab’s $180 million Series C, and Gradium’s $70 million seed round.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elizabeth de Saint-Aignan, a partner at AVP, told TechCrunch that when the fund was talking to enterprises about how they were using AI, voice came up frequently, and it started looking into companies working in this area.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In 2024, when we were talking to enterprises about how they were thinking about using AI inside their business, we started to hear about them using voice AI in processes like contact centers and sales developments. When we chatted with them more, we realized a lot of voice AI tech was powered by Deepgram, and that’s what led us to them [Deepgram],” de Saint-Aignan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She noted that voice AI could help in making customers’ interactions with enterprises more pleasant while reducing costs for companies, and Deepgram could play a central part in it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deepgram has a bunch of models related to text-to-speech and speech-to-text, along with platforms and APIs for conversational speech recognition and interruption handling with low latency. It noted that more than 1,300 organizations use its voice AI products and models, including meeting notetaker Granola, voice agent startup Vapi, and Twilio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s CEO, Scott Stephenson, said that the company didn’t need the fundraise and it was cashflow positive last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In the last year, voice AI has gone mainstream, and there is more potential pull. We see that we can make larger investment sooner in order to accelerate growth. And that is why we felt it could be a good time to raise,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We weren’t out looking for a raise, though. We had multiple people coming to us. We wanted strategic investors who understand voice AI and the technical intricacies of it and have relationships with companies building using the technology.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company wants to use the new fundraising to expand its global footprint and better support multiple languages. It is also focusing on catering to restaurants through voice AI. To that end, it has acquired Y Combinator-backed OfOne, which built a voice AI-powered solution for quick-service restaurants. The startup claims that it has more than 93% accuracy in receiving orders. Voice AI has had its challenges in the restaurant space. Last year, Taco Bell withdrew its voice AI experiment after a person ordered 18,000 water cups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am excited about this [voice AI-driven food ordering] because food ordering might be the first positive interaction more than 300 million Americans have with voice AI. There have been a lot of sour interactions with voice AI over the last 20 years, where a lot of assistants have come out, and people felt that those didn’t provide a magical experience. But when you can order your food using natural conversation, people would think the technology is ready,” Stephenson said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There seems to be investor interest in the sector, as OfOne’s acquisition news comes after Presto, which serves brands like Carl’s Jr., picked up $10 million in new funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Analysts’ reports peg the voice market to grow at over 30% year-over-year and become a $14-$20 billion market by 2030. With this growth rate, model and API providers will look to be multibillion-dollar companies by becoming a core component for enterprises and startups developing voice solutions.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/deepgram-raises-130m-at-1-3b-valuation-and-buys-a-yc-ai-startup/</guid><pubDate>Tue, 13 Jan 2026 13:30:00 +0000</pubDate></item><item><title>[NEW] Allister Frost: Tackling workforce anxiety for AI integration success (AI News)</title><link>https://www.artificialintelligence-news.com/news/allister-frost-tackling-workforce-anxiety-for-ai-integration-success/</link><description>&lt;p&gt;Navigating workforce anxiety remains a primary challenge for leaders as AI integration defines modern enterprise success.&lt;/p&gt;&lt;p&gt;For enterprise leaders, deploying AI is less a technical hurdle than a complex exercise in change management. The reality for many organisations is that, while algorithms offer efficiency, the human element dictates the speed of adoption.&lt;/p&gt;&lt;p&gt;Data from the TUC indicates that 51 percent of UK adults are concerned about the impact of AI and new technologies on their job. This anxiety creates a tangible risk to ROI; resistance halts the innovation leaders seek to foster.&lt;/p&gt;&lt;p&gt;Allister Frost, a former Microsoft leader and expert on business transformation, argues this friction stems from a misunderstanding of the technology’s capability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-address-the-misconception-of-true-intelligence"&gt;Address the misconception of true intelligence&lt;/h3&gt;&lt;p&gt;A common error in corporate strategy treats generative AI and Large Language Models (LLMs) as autonomous agents rather than data processors. This anthropomorphism drives the fear that machines will make human cognition obsolete.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="Allister Frost, a former Microsoft leader and expert on business transformation." class="wp-image-111581" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x1024.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;“The greatest misconception is that AI is as intelligent as its name suggests and can perform human-like tasks,” Frost notes. He clarifies the reality: “AI is primarily pattern-matching at scale, offering opportunities to help people work smarter, innovate faster, and explore new pathways to growth.”&lt;/p&gt;&lt;p&gt;Communicating this distinction is essential. When employees view these tools as pattern-matchers rather than sentient replacements, the narrative changes from competition to utility. Frost emphasises that “AI doesn’t have the ability to replicate human intelligence, it exists to augment it.”&lt;/p&gt;&lt;p&gt;Some finance and operations leaders view AI integration primarily as a mechanism to reduce salary overheads. Yet stripping away experienced staff for automation often degrades institutional memory.&lt;/p&gt;&lt;p&gt;Frost warns against this tactic: “Too often, businesses see AI as a shortcut to headcount reduction, putting experienced workers at risk for short-term savings. This approach overlooks the enormous economic and societal cost of losing skilled staff.”&lt;/p&gt;&lt;p&gt;Data confirms the workforce is on edge regarding this scenario. Acas reports that 26 percent of British workers cite job losses as their biggest concern regarding AI at work. History suggests, however, that technological integration expands rather than contracts the labour market.&lt;/p&gt;&lt;p&gt;“The reality is that AI is not poised to eliminate jobs indiscriminately, but rather to evolve the nature of work,” states Frost.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-operationalising-augmentation"&gt;Operationalising augmentation&lt;/h3&gt;&lt;p&gt;Successful integration requires changing how AI use cases are identified. Rather than looking for roles to remove, enterprise leaders should identify high-volume, low-value tasks that bottleneck productivity.&lt;/p&gt;&lt;p&gt;“AI tools have the potential to automate mundane tasks and free up human labour to focus on creative and strategic aspects,” explains Frost.&lt;/p&gt;&lt;p&gt;This allows leaders to move staff toward high-touch areas where algorithms struggle.&lt;/p&gt;&lt;p&gt;“As AI handles repetitive tasks, it frees up time to allow staff to upskill and transition into more complex roles that require a higher level of critical thinking and emotional intelligence.”&lt;/p&gt;&lt;p&gt;These competencies – empathy, ethical decision-making, and complex strategy – remain outside the grasp of current computational models.&lt;/p&gt;&lt;p&gt;Resistance to AI is often a symptom of “change fatigue,” a common response to the pace of digital updates. With 14 percent of UK workers explicitly worried about AI’s impact on their current job, transparent governance is required.&lt;/p&gt;&lt;p&gt;Leaders must recognise that “resisting AI’s integration can hinder progress and limit opportunities for innovation.” Active engagement is the solution. “Engaging employees in discussions about AI’s role within the organisation can help demystify its functions and build trust,” Frost advises.&lt;/p&gt;&lt;p&gt;This requires moving beyond top-down mandates. It involves creating a culture where staff feel safe to experiment with new tools without the immediate fear of displacing their own roles.&lt;/p&gt;&lt;p&gt;“Once leaders have cultivated an environment of transparency and inclusion, businesses can alleviate anxieties, ensuring all team members are aligned and prepared to harness AI’s benefits.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-adapting-the-workforce-for-successful-ai-integration"&gt;Adapting the workforce for successful AI integration&lt;/h3&gt;&lt;p&gt;Enterprise technology advancements have always demanded adaptation, and AI – while a larger transformation than many technologies in recent decades – is no different.&lt;/p&gt;&lt;p&gt;“Throughout history people have been resistant to new technological advancements, yet history shows us humans have repeatedly risen to the challenge of integrating new technologies.”&lt;/p&gt;&lt;p&gt;For enterprise leaders, success involves investing in resilience and continuous learning. By framing AI as a transformative tool rather than a threat, organisations can protect their talent pipeline while modernising operations.&lt;/p&gt;&lt;p&gt;A summary of advice to ensure successful AI integration:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reframe the narrative:&lt;/strong&gt; Explicitly communicate AI as a “pattern-matching” tool for augmentation, not a sentient replacement, to lower cultural resistance.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Audit for augmentation:&lt;/strong&gt; Identify the mundane and high-volume process bottlenecks for automation, specifically to free up staff for more rewarding creative work.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Invest in “human” skills:&lt;/strong&gt; Allocate learning and development budgets toward critical thinking, empathy, and ethical decision-making, as these are the non-replicable assets in an AI-driven market.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Combat change fatigue:&lt;/strong&gt; Ensure transparent and two-way dialogue regarding AI integration roadmaps and governance to build trust and mitigate the fear factor regarding job losses.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“My mission is to save one million working lives by showing that AI works best when it empowers humans, rather than replaces them,” Frost concludes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Shopify is bringing agentic AI to enterprise commerce&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Navigating workforce anxiety remains a primary challenge for leaders as AI integration defines modern enterprise success.&lt;/p&gt;&lt;p&gt;For enterprise leaders, deploying AI is less a technical hurdle than a complex exercise in change management. The reality for many organisations is that, while algorithms offer efficiency, the human element dictates the speed of adoption.&lt;/p&gt;&lt;p&gt;Data from the TUC indicates that 51 percent of UK adults are concerned about the impact of AI and new technologies on their job. This anxiety creates a tangible risk to ROI; resistance halts the innovation leaders seek to foster.&lt;/p&gt;&lt;p&gt;Allister Frost, a former Microsoft leader and expert on business transformation, argues this friction stems from a misunderstanding of the technology’s capability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-address-the-misconception-of-true-intelligence"&gt;Address the misconception of true intelligence&lt;/h3&gt;&lt;p&gt;A common error in corporate strategy treats generative AI and Large Language Models (LLMs) as autonomous agents rather than data processors. This anthropomorphism drives the fear that machines will make human cognition obsolete.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="Allister Frost, a former Microsoft leader and expert on business transformation." class="wp-image-111581" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x1024.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;“The greatest misconception is that AI is as intelligent as its name suggests and can perform human-like tasks,” Frost notes. He clarifies the reality: “AI is primarily pattern-matching at scale, offering opportunities to help people work smarter, innovate faster, and explore new pathways to growth.”&lt;/p&gt;&lt;p&gt;Communicating this distinction is essential. When employees view these tools as pattern-matchers rather than sentient replacements, the narrative changes from competition to utility. Frost emphasises that “AI doesn’t have the ability to replicate human intelligence, it exists to augment it.”&lt;/p&gt;&lt;p&gt;Some finance and operations leaders view AI integration primarily as a mechanism to reduce salary overheads. Yet stripping away experienced staff for automation often degrades institutional memory.&lt;/p&gt;&lt;p&gt;Frost warns against this tactic: “Too often, businesses see AI as a shortcut to headcount reduction, putting experienced workers at risk for short-term savings. This approach overlooks the enormous economic and societal cost of losing skilled staff.”&lt;/p&gt;&lt;p&gt;Data confirms the workforce is on edge regarding this scenario. Acas reports that 26 percent of British workers cite job losses as their biggest concern regarding AI at work. History suggests, however, that technological integration expands rather than contracts the labour market.&lt;/p&gt;&lt;p&gt;“The reality is that AI is not poised to eliminate jobs indiscriminately, but rather to evolve the nature of work,” states Frost.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-operationalising-augmentation"&gt;Operationalising augmentation&lt;/h3&gt;&lt;p&gt;Successful integration requires changing how AI use cases are identified. Rather than looking for roles to remove, enterprise leaders should identify high-volume, low-value tasks that bottleneck productivity.&lt;/p&gt;&lt;p&gt;“AI tools have the potential to automate mundane tasks and free up human labour to focus on creative and strategic aspects,” explains Frost.&lt;/p&gt;&lt;p&gt;This allows leaders to move staff toward high-touch areas where algorithms struggle.&lt;/p&gt;&lt;p&gt;“As AI handles repetitive tasks, it frees up time to allow staff to upskill and transition into more complex roles that require a higher level of critical thinking and emotional intelligence.”&lt;/p&gt;&lt;p&gt;These competencies – empathy, ethical decision-making, and complex strategy – remain outside the grasp of current computational models.&lt;/p&gt;&lt;p&gt;Resistance to AI is often a symptom of “change fatigue,” a common response to the pace of digital updates. With 14 percent of UK workers explicitly worried about AI’s impact on their current job, transparent governance is required.&lt;/p&gt;&lt;p&gt;Leaders must recognise that “resisting AI’s integration can hinder progress and limit opportunities for innovation.” Active engagement is the solution. “Engaging employees in discussions about AI’s role within the organisation can help demystify its functions and build trust,” Frost advises.&lt;/p&gt;&lt;p&gt;This requires moving beyond top-down mandates. It involves creating a culture where staff feel safe to experiment with new tools without the immediate fear of displacing their own roles.&lt;/p&gt;&lt;p&gt;“Once leaders have cultivated an environment of transparency and inclusion, businesses can alleviate anxieties, ensuring all team members are aligned and prepared to harness AI’s benefits.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-adapting-the-workforce-for-successful-ai-integration"&gt;Adapting the workforce for successful AI integration&lt;/h3&gt;&lt;p&gt;Enterprise technology advancements have always demanded adaptation, and AI – while a larger transformation than many technologies in recent decades – is no different.&lt;/p&gt;&lt;p&gt;“Throughout history people have been resistant to new technological advancements, yet history shows us humans have repeatedly risen to the challenge of integrating new technologies.”&lt;/p&gt;&lt;p&gt;For enterprise leaders, success involves investing in resilience and continuous learning. By framing AI as a transformative tool rather than a threat, organisations can protect their talent pipeline while modernising operations.&lt;/p&gt;&lt;p&gt;A summary of advice to ensure successful AI integration:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reframe the narrative:&lt;/strong&gt; Explicitly communicate AI as a “pattern-matching” tool for augmentation, not a sentient replacement, to lower cultural resistance.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Audit for augmentation:&lt;/strong&gt; Identify the mundane and high-volume process bottlenecks for automation, specifically to free up staff for more rewarding creative work.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Invest in “human” skills:&lt;/strong&gt; Allocate learning and development budgets toward critical thinking, empathy, and ethical decision-making, as these are the non-replicable assets in an AI-driven market.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Combat change fatigue:&lt;/strong&gt; Ensure transparent and two-way dialogue regarding AI integration roadmaps and governance to build trust and mitigate the fear factor regarding job losses.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“My mission is to save one million working lives by showing that AI works best when it empowers humans, rather than replaces them,” Frost concludes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Shopify is bringing agentic AI to enterprise commerce&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/allister-frost-tackling-workforce-anxiety-for-ai-integration-success/</guid><pubDate>Tue, 13 Jan 2026 13:39:53 +0000</pubDate></item><item><title>[NEW] Apple launches ‘Creator Studio’ bundle of apps for $12.99 per month (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/apple-launches-creator-studio-bundle-of-apps-for-12-99-per-month/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-13-at-9.34.59-AM.png?resize=1200,594" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is launching a new Creator Studio subscription bundle that offers access to six creative apps as well as premium content in iWork apps, the company announced on Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bundle costs $12.99 per month or $129 per year and includes access to Final Cut Pro, Logic Pro, and Pixelmator Pro on Mac and iPad, as well as Motion, Compressor, and MainStage on Mac. It also includes premium content for Keynote, Pages, and Numbers. Later, the bundle will include Freeform for iPhone, iPad, and Mac. College students and educators can subscribe for $2.99 per month or $29.99 per year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio will be available beginning January 28. All new subscribers will get a one-month free trial. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of Tuesday’s announcement, Apple revealed that these creative apps are launching new features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Final Cut Pro on Mac and iPad is getting Transcript Search to find soundbites, Visual Search to find exact moments by describing them, and Beat Detection. Final Cut Pro for iPad is getting Montage Maker to quickly start edits and Auto Crop to reframe content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also new features coming to Logic Pro, such as Synth Player, Chord ID, a new sound library, natural language search, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio also brings access to MainStage, which turns Macs into an instrument, voice processor, or guitar rig.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Pixelmator Pro, a company Apple bought in 2024, is also coming to iPad for the first time, bringing its editing tools to more creators. It includes full Apple Pencil support alongside fast image editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio also provides access to Motion, a motion graphics tool for creating 2D and 3D effects. It also includes Compressor, which works with Final Cut Pro and Motion to customize output settings for distribution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Apple Creator Studio is a great value that enables creators of all types to pursue their craft and grow their skills by providing easy access to the most powerful and intuitive tools for video editing, music making, creative imaging, and visual productivity — all leveled up with advanced intelligent tools to augment and accelerate workflows,” said Eddy Cue, Apple’s senior vice president of Internet Software and Services, in a press release.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Pages, Numbers, and Keynote, a Creator Studio subscription unlocks a new “Content Hub” where users can find high-quality photos, graphics, and illustrations. Plus, there are new premium templates and themes in Keynote, Pages, and Numbers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio gives users access to beta features in Keynote, including tools to generate presentation drafts from text outlines, create presenter notes from existing slides, and quickly clean up layouts and object placement. In Numbers, subscribers can generate formulas and automatically fill tables using pattern recognition with Magic Fill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant notes that Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage will continue to be available as one-time purchases on the Mac App Store, while free versions of Numbers, Pages, Keynote, and Freeform will remain available.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-13-at-9.34.59-AM.png?resize=1200,594" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is launching a new Creator Studio subscription bundle that offers access to six creative apps as well as premium content in iWork apps, the company announced on Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bundle costs $12.99 per month or $129 per year and includes access to Final Cut Pro, Logic Pro, and Pixelmator Pro on Mac and iPad, as well as Motion, Compressor, and MainStage on Mac. It also includes premium content for Keynote, Pages, and Numbers. Later, the bundle will include Freeform for iPhone, iPad, and Mac. College students and educators can subscribe for $2.99 per month or $29.99 per year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio will be available beginning January 28. All new subscribers will get a one-month free trial. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of Tuesday’s announcement, Apple revealed that these creative apps are launching new features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Final Cut Pro on Mac and iPad is getting Transcript Search to find soundbites, Visual Search to find exact moments by describing them, and Beat Detection. Final Cut Pro for iPad is getting Montage Maker to quickly start edits and Auto Crop to reframe content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also new features coming to Logic Pro, such as Synth Player, Chord ID, a new sound library, natural language search, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio also brings access to MainStage, which turns Macs into an instrument, voice processor, or guitar rig.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Pixelmator Pro, a company Apple bought in 2024, is also coming to iPad for the first time, bringing its editing tools to more creators. It includes full Apple Pencil support alongside fast image editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio also provides access to Motion, a motion graphics tool for creating 2D and 3D effects. It also includes Compressor, which works with Final Cut Pro and Motion to customize output settings for distribution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Apple Creator Studio is a great value that enables creators of all types to pursue their craft and grow their skills by providing easy access to the most powerful and intuitive tools for video editing, music making, creative imaging, and visual productivity — all leveled up with advanced intelligent tools to augment and accelerate workflows,” said Eddy Cue, Apple’s senior vice president of Internet Software and Services, in a press release.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Pages, Numbers, and Keynote, a Creator Studio subscription unlocks a new “Content Hub” where users can find high-quality photos, graphics, and illustrations. Plus, there are new premium templates and themes in Keynote, Pages, and Numbers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple Creator Studio gives users access to beta features in Keynote, including tools to generate presentation drafts from text outlines, create presenter notes from existing slides, and quickly clean up layouts and object placement. In Numbers, subscribers can generate formulas and automatically fill tables using pattern recognition with Magic Fill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant notes that Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage will continue to be available as one-time purchases on the Mac App Store, while free versions of Numbers, Pages, Keynote, and Freeform will remain available.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/apple-launches-creator-studio-bundle-of-apps-for-12-99-per-month/</guid><pubDate>Tue, 13 Jan 2026 14:40:19 +0000</pubDate></item><item><title>[NEW] ElevenLabs CEO says the voice AI startup crossed $330M ARR last year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/elevenlabs-ceo-says-the-voice-ai-startup-crossed-330-million-arr-last-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/ElevenLabs-feat.jpg?resize=1200,669" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs, the AI voice-generation startup, crossed $330 million in annual recurring revenue (ARR), CEO Mati Staniszewski said in an interview with Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Really, what this [growth in ARR] shows is that trajectory across the company. We started the company in 2022 and launched the first product in 2023. It took us 20 months to reach $100 million in ARR, 10 months to reach $200 million, and five months to reach the current number,” he said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Staniszewski mentioned that both Fortune 500 companies and startups are adopting its voice agent technology, which uses company data and knowledge bases to power customer support and customer experience interactions. In a separate post on X, the company noted that enterprises have deployed its technology to handle more than 50,000 calls per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup raised $180 million in Series C funding co-led by a16z and ICONIQ Growth at a $3.3 billion valuation in January 2025. It then doubled its valuation months later when ICONIQ and another earlier investor, Sequoia, shelled out another $100 million to snap up employee shares.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides providing models for voice generation and voice agents, the company launched music creation capabilities last year and also struck a deal with celebrities such as Michael Caine and Matthew McConaughey to use their voices for AI-generated content.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/ElevenLabs-feat.jpg?resize=1200,669" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs, the AI voice-generation startup, crossed $330 million in annual recurring revenue (ARR), CEO Mati Staniszewski said in an interview with Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Really, what this [growth in ARR] shows is that trajectory across the company. We started the company in 2022 and launched the first product in 2023. It took us 20 months to reach $100 million in ARR, 10 months to reach $200 million, and five months to reach the current number,” he said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Staniszewski mentioned that both Fortune 500 companies and startups are adopting its voice agent technology, which uses company data and knowledge bases to power customer support and customer experience interactions. In a separate post on X, the company noted that enterprises have deployed its technology to handle more than 50,000 calls per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup raised $180 million in Series C funding co-led by a16z and ICONIQ Growth at a $3.3 billion valuation in January 2025. It then doubled its valuation months later when ICONIQ and another earlier investor, Sequoia, shelled out another $100 million to snap up employee shares.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides providing models for voice generation and voice agents, the company launched music creation capabilities last year and also struck a deal with celebrities such as Michael Caine and Matthew McConaughey to use their voices for AI-generated content.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/elevenlabs-ceo-says-the-voice-ai-startup-crossed-330-million-arr-last-year/</guid><pubDate>Tue, 13 Jan 2026 16:15:22 +0000</pubDate></item><item><title>[NEW] Veo 3.1 Ingredients to Video: More consistency, creativity and control (Google DeepMind News)</title><link>https://deepmind.google/blog/veo-3-1-ingredients-to-video-more-consistency-creativity-and-control/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="A collage of various generated images, including an astronaut on Mars, a raccoon barista, a person in a hallway, a fantasy cityscape, and a close-up of coffee art, with the text &amp;quot;Veo 3.1 Ingredients to Video&amp;quot; overlayed." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/veo-3-1_keyword_blog_header_2096x.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Veo 3.1 Ingredients to Video: More consistency, creativity and control"&gt;
      &lt;source src="https://ftr.bazqux.com/self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today, Veo is getting more expressive, with improvements that help you create more fun, creative, high-quality videos based on ingredient images, built directly for the mobile format. We’re excited to bring new creative possibilities for everyone from casual storytellers to professional filmmakers.&lt;/p&gt;&lt;p&gt;We’re releasing:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;Improvements to Veo 3.1 Ingredients to Video,&lt;/b&gt; our capability that lets you create videos based on reference images. This update makes videos more expressive and creative, even with simple prompts&lt;/li&gt;&lt;li&gt;&lt;b&gt;Native vertical outputs for Ingredients to Video (portrait mode)&lt;/b&gt; to power mobile-first, short-form video creation&lt;/li&gt;&lt;li&gt;&lt;b&gt;State-of-the-art upscaling to 1080p and 4K resolution&lt;/b&gt; for high-fidelity production workflows&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Whether you are looking for livelier movement, better control over visual elements or broadcast-ready resolution, these updates give you the tools to bring your vision to life. These updates are launching in the Gemini app, YouTube, Flow, Google Vids, the Gemini API and Vertex AI.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Improvements to Veo 3.1 Ingredients to Video&lt;/h2&gt;&lt;h3&gt;Turn ingredient images into fun, shareable clips&lt;/h3&gt;&lt;p&gt;Even with short prompts, you can generate dynamic and engaging videos based on ingredient images. You’ll now see richer dialogue and storytelling, making your videos feel more alive and expressive.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Maintain identity consistency for your characters&lt;/h3&gt;&lt;p&gt;Identity consistency is better than ever with Veo 3.1 Ingredients to Video. Keep your characters looking the same even as the setting changes, making it easier to tell a full narrative by having the same character appear across multiple scenes.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Achieve background and object consistency&lt;/h3&gt;&lt;p&gt;Control the scene by maintaining the integrity of your setting and the objects within it. You can also reuse an object, backgrounds or textures across scenes.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Seamlessly blend textures, characters and objects&lt;/h3&gt;&lt;p&gt;Combine disparate elements — like characters, objects, textures and stylized backgrounds — into a cohesive, high-impact clip.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Pro tip:&lt;/b&gt; use the new Nano Banana Pro (Gemini 3 Pro Image) in the Gemini app or Flow to create your ingredient images, which you can then use to create stunning videos with Veo 3.1 Ingredients to Video.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Create high-fidelity visuals with upgraded capabilities&lt;/h2&gt;&lt;p&gt;With Veo 3.1’s new capabilities, we are introducing mobile-optimized outputs and professional-grade quality options.&lt;/p&gt;&lt;h3&gt;Native vertical outputs for Ingredients to Video&lt;/h3&gt;&lt;p&gt;For the first time, "Ingredients to Video" supports generating videos in a native 9:16 aspect ratio. Whether you are creating for YouTube Shorts or other platforms, you can now produce high-quality, full-screen vertical storytelling without cropping or quality loss.&lt;/p&gt;&lt;h3&gt;State-of-the-art upscaling to 1080p and 4K resolution&lt;/h3&gt;&lt;p&gt;Generate videos 1080p and 4K with state-of-the-art upscaling. Our improved 1080p resolution offers a sharper, cleaner video perfect for editing. For even more detail, choose 4K to capture rich textures and stunning clarity — ideal for high-end productions and large screens.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try these updates today&lt;/h2&gt;&lt;p&gt;Across our products and services, you can now access these new capabilities tailored to your workflow:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Consumers and creators:&lt;/b&gt; We are bringing Veo 3.1 Ingredients to Video directly to YouTube Shorts and the YouTube Create app for the first time. You can also try the enhanced Veo 3.1 Ingredients to Video and portrait mode for Veo in the Gemini app starting today.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Professional and enterprise workflows:&lt;/b&gt; The enhanced Veo 3.1 Ingredients to Video and native vertical format support are rolling out to Flow, the Gemini API, Vertex AI, and Google Vids, with 1080p and 4K resolution options also available on Flow, the API, and Vertex AI.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Verify videos in the Gemini app&lt;/h2&gt;&lt;p&gt;We’re committed to providing tools to make it easier to determine if content is AI-generated. This is why videos generated by Google’s tools are embedded with our imperceptible SynthID digital watermark.&lt;/p&gt;&lt;p&gt;In December we expanded our powerful verification tool in the Gemini app to include video. You can now upload a video and simply ask if it was generated with Google AI. This builds on our existing image verification tools, helping to foster a more transparent ecosystem for everyone.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;You can find out more about how we’re increasing transparency in AI content with SynthID in our blog post.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="A collage of various generated images, including an astronaut on Mars, a raccoon barista, a person in a hallway, a fantasy cityscape, and a close-up of coffee art, with the text &amp;quot;Veo 3.1 Ingredients to Video&amp;quot; overlayed." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/veo-3-1_keyword_blog_header_2096x.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Veo 3.1 Ingredients to Video: More consistency, creativity and control"&gt;
      &lt;source src="https://ftr.bazqux.com/self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today, Veo is getting more expressive, with improvements that help you create more fun, creative, high-quality videos based on ingredient images, built directly for the mobile format. We’re excited to bring new creative possibilities for everyone from casual storytellers to professional filmmakers.&lt;/p&gt;&lt;p&gt;We’re releasing:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;Improvements to Veo 3.1 Ingredients to Video,&lt;/b&gt; our capability that lets you create videos based on reference images. This update makes videos more expressive and creative, even with simple prompts&lt;/li&gt;&lt;li&gt;&lt;b&gt;Native vertical outputs for Ingredients to Video (portrait mode)&lt;/b&gt; to power mobile-first, short-form video creation&lt;/li&gt;&lt;li&gt;&lt;b&gt;State-of-the-art upscaling to 1080p and 4K resolution&lt;/b&gt; for high-fidelity production workflows&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Whether you are looking for livelier movement, better control over visual elements or broadcast-ready resolution, these updates give you the tools to bring your vision to life. These updates are launching in the Gemini app, YouTube, Flow, Google Vids, the Gemini API and Vertex AI.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Improvements to Veo 3.1 Ingredients to Video&lt;/h2&gt;&lt;h3&gt;Turn ingredient images into fun, shareable clips&lt;/h3&gt;&lt;p&gt;Even with short prompts, you can generate dynamic and engaging videos based on ingredient images. You’ll now see richer dialogue and storytelling, making your videos feel more alive and expressive.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Maintain identity consistency for your characters&lt;/h3&gt;&lt;p&gt;Identity consistency is better than ever with Veo 3.1 Ingredients to Video. Keep your characters looking the same even as the setting changes, making it easier to tell a full narrative by having the same character appear across multiple scenes.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Achieve background and object consistency&lt;/h3&gt;&lt;p&gt;Control the scene by maintaining the integrity of your setting and the objects within it. You can also reuse an object, backgrounds or textures across scenes.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h3&gt;Seamlessly blend textures, characters and objects&lt;/h3&gt;&lt;p&gt;Combine disparate elements — like characters, objects, textures and stylized backgrounds — into a cohesive, high-impact clip.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Pro tip:&lt;/b&gt; use the new Nano Banana Pro (Gemini 3 Pro Image) in the Gemini app or Flow to create your ingredient images, which you can then use to create stunning videos with Veo 3.1 Ingredients to Video.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Create high-fidelity visuals with upgraded capabilities&lt;/h2&gt;&lt;p&gt;With Veo 3.1’s new capabilities, we are introducing mobile-optimized outputs and professional-grade quality options.&lt;/p&gt;&lt;h3&gt;Native vertical outputs for Ingredients to Video&lt;/h3&gt;&lt;p&gt;For the first time, "Ingredients to Video" supports generating videos in a native 9:16 aspect ratio. Whether you are creating for YouTube Shorts or other platforms, you can now produce high-quality, full-screen vertical storytelling without cropping or quality loss.&lt;/p&gt;&lt;h3&gt;State-of-the-art upscaling to 1080p and 4K resolution&lt;/h3&gt;&lt;p&gt;Generate videos 1080p and 4K with state-of-the-art upscaling. Our improved 1080p resolution offers a sharper, cleaner video perfect for editing. For even more detail, choose 4K to capture rich textures and stunning clarity — ideal for high-end productions and large screens.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try these updates today&lt;/h2&gt;&lt;p&gt;Across our products and services, you can now access these new capabilities tailored to your workflow:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Consumers and creators:&lt;/b&gt; We are bringing Veo 3.1 Ingredients to Video directly to YouTube Shorts and the YouTube Create app for the first time. You can also try the enhanced Veo 3.1 Ingredients to Video and portrait mode for Veo in the Gemini app starting today.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Professional and enterprise workflows:&lt;/b&gt; The enhanced Veo 3.1 Ingredients to Video and native vertical format support are rolling out to Flow, the Gemini API, Vertex AI, and Google Vids, with 1080p and 4K resolution options also available on Flow, the API, and Vertex AI.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Verify videos in the Gemini app&lt;/h2&gt;&lt;p&gt;We’re committed to providing tools to make it easier to determine if content is AI-generated. This is why videos generated by Google’s tools are embedded with our imperceptible SynthID digital watermark.&lt;/p&gt;&lt;p&gt;In December we expanded our powerful verification tool in the Gemini app to include video. You can now upload a video and simply ask if it was generated with Google AI. This builds on our existing image verification tools, helping to foster a more transparent ecosystem for everyone.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;You can find out more about how we’re increasing transparency in AI content with SynthID in our blog post.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/veo-3-1-ingredients-to-video-more-consistency-creativity-and-control/</guid><pubDate>Tue, 13 Jan 2026 17:00:18 +0000</pubDate></item><item><title>[NEW] Neo humanoid maker 1X releases world model to help bots learn what they see (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/13/neo-humanoid-maker-1x-releases-world-model-to-help-bots-learn-what-they-see/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/1X_NEO-Home-Duster.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The robotics company behind the Neo humanoid robot, 1X, has unveiled a new AI model that it says understands the dynamics of the real world and can help bots learn new information on their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This physics-based model, called 1X World Model, uses a combination of video and prompts to give Neo robots new abilities. The video allows Neo robots to learn new tasks they weren’t previously trained on, according to 1X.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This release comes as 1X is gearing up to release its Neo humanoids into the home. The company opened up preorders for its humanoids in October with plans to ship the bots this year. A 1X spokesperson declined to share a timeline of when these bots were shipping or share any information regarding how many have been ordered beyond saying preorders exceeded expectations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“After years of developing our world model and making Neo’s design as close to human as possible, Neo can now learn from internet-scale video and apply that knowledge directly to the physical world,” Bernt Børnich, founder and CEO of 1X said in a statement. “With the ability to transform any prompt into new actions — even without prior examples — this marks the starting point of Neo’s ability to teach itself to master nearly anything you could think to ask.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Saying that the bot can transform &lt;em&gt;any prompt&lt;/em&gt; into a new action is a lofty claim and not entirely accurate; you can’t tell a Neo to drive a car and it will suddenly know how to parallel park, for instance. But there is some learning going on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;1X isn’t saying the world model allows today’s Neo bots to do a new task right away from capturing video and being prompted, a company spokesperson clarified. Instead, the bot takes video data linked to specific prompts and then sends that back into the world model. That model is then fed back into the network of bots to give them a better understanding of the physical world and more know-how. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also gives users insight into how Neo is thinking of behaving or reacting to a certain prompt. That kind of behavioral information could help 1X train these models to a point where robots will be able to react to a prompt of something they’ve never done before.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/1X_NEO-Home-Duster.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The robotics company behind the Neo humanoid robot, 1X, has unveiled a new AI model that it says understands the dynamics of the real world and can help bots learn new information on their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This physics-based model, called 1X World Model, uses a combination of video and prompts to give Neo robots new abilities. The video allows Neo robots to learn new tasks they weren’t previously trained on, according to 1X.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This release comes as 1X is gearing up to release its Neo humanoids into the home. The company opened up preorders for its humanoids in October with plans to ship the bots this year. A 1X spokesperson declined to share a timeline of when these bots were shipping or share any information regarding how many have been ordered beyond saying preorders exceeded expectations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“After years of developing our world model and making Neo’s design as close to human as possible, Neo can now learn from internet-scale video and apply that knowledge directly to the physical world,” Bernt Børnich, founder and CEO of 1X said in a statement. “With the ability to transform any prompt into new actions — even without prior examples — this marks the starting point of Neo’s ability to teach itself to master nearly anything you could think to ask.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Saying that the bot can transform &lt;em&gt;any prompt&lt;/em&gt; into a new action is a lofty claim and not entirely accurate; you can’t tell a Neo to drive a car and it will suddenly know how to parallel park, for instance. But there is some learning going on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;1X isn’t saying the world model allows today’s Neo bots to do a new task right away from capturing video and being prompted, a company spokesperson clarified. Instead, the bot takes video data linked to specific prompts and then sends that back into the world model. That model is then fed back into the network of bots to give them a better understanding of the physical world and more know-how. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also gives users insight into how Neo is thinking of behaving or reacting to a certain prompt. That kind of behavioral information could help 1X train these models to a point where robots will be able to react to a prompt of something they’ve never done before.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/13/neo-humanoid-maker-1x-releases-world-model-to-help-bots-learn-what-they-see/</guid><pubDate>Tue, 13 Jan 2026 17:14:08 +0000</pubDate></item></channel></rss>