<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Sep 2025 12:44:04 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>New AI system could accelerate clinical research (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-ai-system-could-accelerate-clinical-research-0925</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-Scalable-Segmentation-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Annotating regions of interest in medical images, a process known as segmentation, is often one of the first steps clinical researchers take when running a new study involving biomedical images.&lt;/p&gt;&lt;p&gt;For instance, to determine how the size of the brain’s hippocampus changes as patients age, the scientist first outlines each hippocampus in a series of brain scans. For many structures and image types, this is often a manual process that can be extremely time-consuming, especially if the regions being studied are challenging to delineate.&lt;/p&gt;&lt;p&gt;To streamline the process, MIT researchers developed an artificial intelligence-based system that enables a researcher to rapidly segment new biomedical imaging datasets by clicking, scribbling, and drawing boxes on the images. This new AI model uses these interactions to predict the segmentation.&lt;/p&gt;&lt;p&gt;As the user marks additional images, the number of interactions they need to perform decreases, eventually dropping to zero. The model can then segment each new image accurately without user input.&lt;/p&gt;&lt;p&gt;It can do this because the model’s architecture has been specially designed to use information from images it has already segmented to make new predictions.&lt;/p&gt;&lt;p&gt;Unlike other medical image segmentation models, this system allows the user to segment an entire dataset without repeating their work for each image.&lt;/p&gt;&lt;p&gt;In addition, the interactive tool does not require a presegmented image dataset for training, so users don’t need machine-learning expertise or extensive computational resources. They can use the system for a new segmentation task without retraining the model.&lt;/p&gt;&lt;p&gt;In the long run, this tool could accelerate studies of new treatment methods and reduce the cost of clinical trials and medical research. It could also be used by physicians to improve the efficiency of clinical applications, such as radiation treatment planning.&lt;/p&gt;&lt;p&gt;“Many scientists might only have time to segment a few images per day for their research because manual image segmentation is so time-consuming. Our hope is that this system will enable new science by allowing clinical researchers to conduct studies they were prohibited from doing before because of the lack of an efficient tool,” says Hallee Wong, an electrical engineering and computer science graduate student and lead author of a paper on this new tool.&lt;/p&gt;&lt;p&gt;She is joined on the paper by Jose Javier Gonzalez Ortiz PhD ’24; John Guttag, the Dugald C. Jackson Professor of Computer Science and Electrical Engineering; and senior author Adrian Dalca, an assistant professor at Harvard Medical School and MGH, and a research scientist in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). The research will be presented at the International Conference on Computer Vision.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Streamlining segmentation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There are primarily two methods researchers use to segment new sets of medical images. With interactive segmentation, they input an image into an AI system and use an interface to mark areas of interest. The model predicts the segmentation based on those interactions.&lt;/p&gt;&lt;p&gt;A tool previously developed by the MIT researchers,&amp;nbsp;ScribblePrompt, allows users to do this, but they must repeat the process for each new image.&lt;/p&gt;&lt;p&gt;Another approach is to develop a task-specific AI model to automatically segment the images. This approach requires the user to manually segment hundreds of images to create a dataset, and then train a machine-learning model. That model predicts the segmentation for a new image. But the user must start the complex, machine-learning-based process from scratch for each new task, and there is no way to correct the model if it makes a mistake.&lt;/p&gt;&lt;p&gt;This new system,&amp;nbsp;MultiverSeg, combines the best of each approach. It predicts a segmentation for a new image based on user interactions, like scribbles, but also keeps each segmented image in a context set that it refers to later.&lt;/p&gt;&lt;p&gt;When the user uploads a new image and marks areas of interest, the model draws on the examples in its context set to make a more accurate prediction, with less user input.&lt;/p&gt;&lt;p&gt;The researchers designed the model’s architecture to use a context set of any size, so&amp;nbsp;the user doesn’t need to have a certain number of images. This gives MultiverSeg the flexibility to be used in a range of applications.&lt;/p&gt;&lt;p&gt;“At some point, for many tasks, you shouldn’t need to provide any interactions. If you have enough examples in the context set, the model can accurately predict the segmentation on its own,” Wong says.&lt;/p&gt;&lt;p&gt;The researchers carefully engineered and trained the model on a diverse collection of biomedical imaging data to ensure it had the ability to incrementally improve its predictions based on user input.&lt;/p&gt;&lt;p&gt;The user doesn’t need to retrain or customize the model for their data. To use MultiverSeg for a new task, one can upload a new medical image and start marking it.&lt;/p&gt;&lt;p&gt;When the researchers compared MultiverSeg to state-of-the-art tools for in-context and interactive image segmentation, it outperformed each baseline.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Fewer clicks, better results&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Unlike these other tools, MultiverSeg requires less user input with each image. By the ninth new image, it needed only two clicks from the user to generate a segmentation more accurate than a model designed specifically for the task.&lt;/p&gt;&lt;p&gt;For some image types, like X-rays, the user might only need to segment one or two images manually before the model becomes accurate enough to make predictions on its own.&lt;/p&gt;&lt;p&gt;The tool’s interactivity also enables the user to make corrections to the model’s prediction, iterating until it reaches the desired level of accuracy. Compared to the researchers’ previous system, MultiverSeg reached 90 percent accuracy with roughly 2/3 the number of scribbles and 3/4 the number of clicks.&lt;/p&gt;&lt;p&gt;“With MultiverSeg, users can always provide more interactions to refine the AI predictions. This still dramatically accelerates the process because it is usually faster to correct something that exists than to start from scratch,” Wong says.&lt;/p&gt;&lt;p&gt;Moving forward, the researchers want to test this tool in real-world situations with clinical collaborators and improve it based on user feedback. They also want to enable MultiverSeg to segment 3D biomedical images.&lt;/p&gt;&lt;p&gt;This work is supported, in part, by Quanta Computer, Inc. and the National Institutes of Health, with hardware support from the Massachusetts Life Sciences Center.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-Scalable-Segmentation-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Annotating regions of interest in medical images, a process known as segmentation, is often one of the first steps clinical researchers take when running a new study involving biomedical images.&lt;/p&gt;&lt;p&gt;For instance, to determine how the size of the brain’s hippocampus changes as patients age, the scientist first outlines each hippocampus in a series of brain scans. For many structures and image types, this is often a manual process that can be extremely time-consuming, especially if the regions being studied are challenging to delineate.&lt;/p&gt;&lt;p&gt;To streamline the process, MIT researchers developed an artificial intelligence-based system that enables a researcher to rapidly segment new biomedical imaging datasets by clicking, scribbling, and drawing boxes on the images. This new AI model uses these interactions to predict the segmentation.&lt;/p&gt;&lt;p&gt;As the user marks additional images, the number of interactions they need to perform decreases, eventually dropping to zero. The model can then segment each new image accurately without user input.&lt;/p&gt;&lt;p&gt;It can do this because the model’s architecture has been specially designed to use information from images it has already segmented to make new predictions.&lt;/p&gt;&lt;p&gt;Unlike other medical image segmentation models, this system allows the user to segment an entire dataset without repeating their work for each image.&lt;/p&gt;&lt;p&gt;In addition, the interactive tool does not require a presegmented image dataset for training, so users don’t need machine-learning expertise or extensive computational resources. They can use the system for a new segmentation task without retraining the model.&lt;/p&gt;&lt;p&gt;In the long run, this tool could accelerate studies of new treatment methods and reduce the cost of clinical trials and medical research. It could also be used by physicians to improve the efficiency of clinical applications, such as radiation treatment planning.&lt;/p&gt;&lt;p&gt;“Many scientists might only have time to segment a few images per day for their research because manual image segmentation is so time-consuming. Our hope is that this system will enable new science by allowing clinical researchers to conduct studies they were prohibited from doing before because of the lack of an efficient tool,” says Hallee Wong, an electrical engineering and computer science graduate student and lead author of a paper on this new tool.&lt;/p&gt;&lt;p&gt;She is joined on the paper by Jose Javier Gonzalez Ortiz PhD ’24; John Guttag, the Dugald C. Jackson Professor of Computer Science and Electrical Engineering; and senior author Adrian Dalca, an assistant professor at Harvard Medical School and MGH, and a research scientist in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). The research will be presented at the International Conference on Computer Vision.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Streamlining segmentation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There are primarily two methods researchers use to segment new sets of medical images. With interactive segmentation, they input an image into an AI system and use an interface to mark areas of interest. The model predicts the segmentation based on those interactions.&lt;/p&gt;&lt;p&gt;A tool previously developed by the MIT researchers,&amp;nbsp;ScribblePrompt, allows users to do this, but they must repeat the process for each new image.&lt;/p&gt;&lt;p&gt;Another approach is to develop a task-specific AI model to automatically segment the images. This approach requires the user to manually segment hundreds of images to create a dataset, and then train a machine-learning model. That model predicts the segmentation for a new image. But the user must start the complex, machine-learning-based process from scratch for each new task, and there is no way to correct the model if it makes a mistake.&lt;/p&gt;&lt;p&gt;This new system,&amp;nbsp;MultiverSeg, combines the best of each approach. It predicts a segmentation for a new image based on user interactions, like scribbles, but also keeps each segmented image in a context set that it refers to later.&lt;/p&gt;&lt;p&gt;When the user uploads a new image and marks areas of interest, the model draws on the examples in its context set to make a more accurate prediction, with less user input.&lt;/p&gt;&lt;p&gt;The researchers designed the model’s architecture to use a context set of any size, so&amp;nbsp;the user doesn’t need to have a certain number of images. This gives MultiverSeg the flexibility to be used in a range of applications.&lt;/p&gt;&lt;p&gt;“At some point, for many tasks, you shouldn’t need to provide any interactions. If you have enough examples in the context set, the model can accurately predict the segmentation on its own,” Wong says.&lt;/p&gt;&lt;p&gt;The researchers carefully engineered and trained the model on a diverse collection of biomedical imaging data to ensure it had the ability to incrementally improve its predictions based on user input.&lt;/p&gt;&lt;p&gt;The user doesn’t need to retrain or customize the model for their data. To use MultiverSeg for a new task, one can upload a new medical image and start marking it.&lt;/p&gt;&lt;p&gt;When the researchers compared MultiverSeg to state-of-the-art tools for in-context and interactive image segmentation, it outperformed each baseline.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Fewer clicks, better results&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Unlike these other tools, MultiverSeg requires less user input with each image. By the ninth new image, it needed only two clicks from the user to generate a segmentation more accurate than a model designed specifically for the task.&lt;/p&gt;&lt;p&gt;For some image types, like X-rays, the user might only need to segment one or two images manually before the model becomes accurate enough to make predictions on its own.&lt;/p&gt;&lt;p&gt;The tool’s interactivity also enables the user to make corrections to the model’s prediction, iterating until it reaches the desired level of accuracy. Compared to the researchers’ previous system, MultiverSeg reached 90 percent accuracy with roughly 2/3 the number of scribbles and 3/4 the number of clicks.&lt;/p&gt;&lt;p&gt;“With MultiverSeg, users can always provide more interactions to refine the AI predictions. This still dramatically accelerates the process because it is usually faster to correct something that exists than to start from scratch,” Wong says.&lt;/p&gt;&lt;p&gt;Moving forward, the researchers want to test this tool in real-world situations with clinical collaborators and improve it based on user feedback. They also want to enable MultiverSeg to segment 3D biomedical images.&lt;/p&gt;&lt;p&gt;This work is supported, in part, by Quanta Computer, Inc. and the National Institutes of Health, with hardware support from the Massachusetts Life Sciences Center.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-ai-system-could-accelerate-clinical-research-0925</guid><pubDate>Thu, 25 Sep 2025 04:00:00 +0000</pubDate></item><item><title>It isn’t your imagination: Google Cloud is flooding the zone (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/24/it-isnt-your-imagination-google-cloud-is-flooding-the-zone/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The $100 billion partnership between Nvidia and OpenAI, announced Monday, represents – for now – the latest mega-deal reshaping the AI infrastructure landscape. The agreement involves non-voting shares tied to massive chip purchases and enough computing power for more than 5 million U.S. households, deepening the relationship between two of AI’s most powerful players.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Google Cloud is placing a different bet entirely. While the industry’s biggest players cement ever-tighter partnerships, Google Cloud is hellbent on capturing the next generation of AI companies before they become too big to court.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Francis deSouza, its COO, has seen the AI revolution from multiple vantage points. As the former CEO of genomics giant Illumina, he watched machine learning transform drug discovery. As co-founder of a two-year-old AI alignment startup, Synth Labs, he has grappled with the safety challenges of increasingly powerful models. Now, having joined the C-suite at Google Cloud in January, he’s orchestrating a massive wager on AI’s second wave.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a story deSouza likes to tell in numbers. In a conversation with this editor, he notes several times that nine out of the top 10 AI labs use Google’s infrastructure. He also says that nearly all generative AI unicorns run on Google Cloud, that 60% of all gen AI startups worldwide have chosen Google as their cloud provider, and that the company has lined up $58 billion in new revenue commitments over the next two years, which represents more than double its current annual run rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked what percentage of Google Cloud’s revenue comes from AI companies, he offers instead that “AI is resetting the cloud market, and Google Cloud is leading the way, especially with startups.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Nvidia-OpenAI deal exemplifies the scale of consolidation sweeping AI infrastructure. Microsoft’s original $1 billion OpenAI investment has grown to nearly $14 billion. Amazon followed with $8 billion in Anthropic investments,&amp;nbsp;securing deep hardware customizations that essentially tailor AI training to work better with Amazon’s infrastructure. Oracle has emerged as a surprise winner, too, landing a $30 billion cloud deal with OpenAI and then securing a jaw-dropping $300 billion five-year commitment starting in 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Meta, despite building its own infrastructure, signed a $10 billion deal with Google Cloud while planning $600 billion in U.S. infrastructure spending through 2028. The Trump administration’s $500 billion “Stargate” project, involving SoftBank, OpenAI and Oracle, adds another layer to these interlocking partnerships.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These gigantic deals might seem threatening for Google, given the partnerships that companies like OpenAI and Nvidia appear to be cementing elsewhere. In fact, it looks a lot like Google is being cut out of some frenzied dealmaking.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="3D Google logo" class="wp-image-3041112" height="454" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2198713751.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The Google logo appears during a meeting between Alphabet and Google CEO Sundar Pichai and Polish Prime Minister Donald Tusk at Google for Startups in Warsaw, Poland, on February 13, 2025. (Photo by Klaudia Radecka/NurPhoto via Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Klaudia Radecka/NurPhoto / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But the corporate behemoth isn’t exactly sitting on its hands. Instead, Google Cloud is signing smaller companies like Loveable and Windsurf — what deSouza calls the “next generation of companies coming up”– as “primary computing partners” without major upfront investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The approach reflects both opportunity and necessity. In a market where companies can go “from being a startup to being a multi-billion dollar company in a very short period of time,” as deSouza puts it, capturing future unicorns before they mature could prove more valuable than fighting over today’s giants.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The strategy extends beyond simple customer acquisition. Google offers AI startups $350,000 in cloud credits, access to its technical teams, and go-to-market support through its marketplace. Google Cloud also provides what deSouza describes as a “no compromise” AI stack – from chips to models to applications – with an “open ethos” that gives customers choice at every layer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Companies love the fact that they can get access to our AI stack, they can get access to our teams to understand where our technologies are going,” deSouza says during our interview. “They also love that they’re getting access to enterprise grade Google class infrastructure.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s infrastructure play got even more ambitious recently, with reporting revealing the company’s behind-the-scenes maneuvering to expand its custom AI chip business. According to The Information, Google has struck deals to place its tensor processing units (TPUs) in other cloud providers’ data centers for the first time, including an agreement with London-based Fluidstack that includes up to $3.2 billion in financial backing for a New York facility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Competing directly with AI companies while simultaneously providing them infrastructure requires — let’s call it — finesse. Google Cloud provides TPU chips to OpenAI and hosts Anthropic’s Claude model through its Vertex AI platform, even as its own Gemini models compete head-to-head with both. (Google Cloud’s parent company, Alphabet, also owns a 14% stake in Anthropic, per New York Times court documents obtained earlier this year, though when asked directly about Google’s financial relationship with Anthropic, deSouza calls the relationship a “multi-layered partnership” then quickly redirects me to Google Cloud’s model marketplace – noting that customers can access various foundation models.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if Google is trying to be Switzerland while advancing its own agenda, it has had plenty of practice. The approach has roots in Google’s open-source contributions, from Kubernetes to the foundational “Attention is All You Need” paper that enabled the transformer architecture underlying most modern AI. More recently, Google published an open-source protocol called Agent-to-Agent (A2A) for inter-agent communication in an attempt to demonstrate its continued commitment to openness even in competitive areas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have made the explicit choice over the years to be open at every layer of the stack, and we know that this means companies can absolutely take our technology and use it to build a competitor at the next layer,” deSouza acknowledges. “That’s been happening for decades. That’s something we are okay with.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google Cloud’s courtship of startups comes at a particularly interesting moment. Just this month, federal judge Amit Mehta delivered a nuanced ruling in the government’s five-year-old search monopoly case, attempting to curb Google’s dominance without hampering its AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google avoided the Justice Department’s most severe proposed penalties, including the forced divestment of its Chrome browser, the ruling underscored regulatory concerns about the company leveraging its search monopoly to dominate AI. Critics are worried, understandably, that Google’s vast trove of search data provides an unfair advantage in developing AI systems, and that the company could deploy the same monopolistic tactics that secured its search dominance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In conversation, deSouza is focused on far more positive outcomes. “I think we have an opportunity to fundamentally understand some of the major diseases that today we just don’t have a good understanding of,” deSouza says, for example, outlining a vision where Google Cloud helps power research into Alzheimer’s, Parkinson’s, and climate technologies. “We want to work very hard to make sure that we are pioneering the technologies that will enable that work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Critics may not easily be assuaged. By positioning itself as an open platform that empowers rather than controls the next generation of AI companies, Google Cloud may be showing regulators that it fosters competition rather than stifles it, all while forging relationships with startups that might help Google’s case if regulators ramp up pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;For our full chat with deSouza, check out this week’s StrictlyVC Download podcast; a new episode comes out every Tuesday.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The $100 billion partnership between Nvidia and OpenAI, announced Monday, represents – for now – the latest mega-deal reshaping the AI infrastructure landscape. The agreement involves non-voting shares tied to massive chip purchases and enough computing power for more than 5 million U.S. households, deepening the relationship between two of AI’s most powerful players.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Google Cloud is placing a different bet entirely. While the industry’s biggest players cement ever-tighter partnerships, Google Cloud is hellbent on capturing the next generation of AI companies before they become too big to court.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Francis deSouza, its COO, has seen the AI revolution from multiple vantage points. As the former CEO of genomics giant Illumina, he watched machine learning transform drug discovery. As co-founder of a two-year-old AI alignment startup, Synth Labs, he has grappled with the safety challenges of increasingly powerful models. Now, having joined the C-suite at Google Cloud in January, he’s orchestrating a massive wager on AI’s second wave.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a story deSouza likes to tell in numbers. In a conversation with this editor, he notes several times that nine out of the top 10 AI labs use Google’s infrastructure. He also says that nearly all generative AI unicorns run on Google Cloud, that 60% of all gen AI startups worldwide have chosen Google as their cloud provider, and that the company has lined up $58 billion in new revenue commitments over the next two years, which represents more than double its current annual run rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked what percentage of Google Cloud’s revenue comes from AI companies, he offers instead that “AI is resetting the cloud market, and Google Cloud is leading the way, especially with startups.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Nvidia-OpenAI deal exemplifies the scale of consolidation sweeping AI infrastructure. Microsoft’s original $1 billion OpenAI investment has grown to nearly $14 billion. Amazon followed with $8 billion in Anthropic investments,&amp;nbsp;securing deep hardware customizations that essentially tailor AI training to work better with Amazon’s infrastructure. Oracle has emerged as a surprise winner, too, landing a $30 billion cloud deal with OpenAI and then securing a jaw-dropping $300 billion five-year commitment starting in 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Meta, despite building its own infrastructure, signed a $10 billion deal with Google Cloud while planning $600 billion in U.S. infrastructure spending through 2028. The Trump administration’s $500 billion “Stargate” project, involving SoftBank, OpenAI and Oracle, adds another layer to these interlocking partnerships.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These gigantic deals might seem threatening for Google, given the partnerships that companies like OpenAI and Nvidia appear to be cementing elsewhere. In fact, it looks a lot like Google is being cut out of some frenzied dealmaking.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="3D Google logo" class="wp-image-3041112" height="454" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2198713751.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The Google logo appears during a meeting between Alphabet and Google CEO Sundar Pichai and Polish Prime Minister Donald Tusk at Google for Startups in Warsaw, Poland, on February 13, 2025. (Photo by Klaudia Radecka/NurPhoto via Getty Images)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Klaudia Radecka/NurPhoto / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But the corporate behemoth isn’t exactly sitting on its hands. Instead, Google Cloud is signing smaller companies like Loveable and Windsurf — what deSouza calls the “next generation of companies coming up”– as “primary computing partners” without major upfront investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The approach reflects both opportunity and necessity. In a market where companies can go “from being a startup to being a multi-billion dollar company in a very short period of time,” as deSouza puts it, capturing future unicorns before they mature could prove more valuable than fighting over today’s giants.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The strategy extends beyond simple customer acquisition. Google offers AI startups $350,000 in cloud credits, access to its technical teams, and go-to-market support through its marketplace. Google Cloud also provides what deSouza describes as a “no compromise” AI stack – from chips to models to applications – with an “open ethos” that gives customers choice at every layer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Companies love the fact that they can get access to our AI stack, they can get access to our teams to understand where our technologies are going,” deSouza says during our interview. “They also love that they’re getting access to enterprise grade Google class infrastructure.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s infrastructure play got even more ambitious recently, with reporting revealing the company’s behind-the-scenes maneuvering to expand its custom AI chip business. According to The Information, Google has struck deals to place its tensor processing units (TPUs) in other cloud providers’ data centers for the first time, including an agreement with London-based Fluidstack that includes up to $3.2 billion in financial backing for a New York facility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Competing directly with AI companies while simultaneously providing them infrastructure requires — let’s call it — finesse. Google Cloud provides TPU chips to OpenAI and hosts Anthropic’s Claude model through its Vertex AI platform, even as its own Gemini models compete head-to-head with both. (Google Cloud’s parent company, Alphabet, also owns a 14% stake in Anthropic, per New York Times court documents obtained earlier this year, though when asked directly about Google’s financial relationship with Anthropic, deSouza calls the relationship a “multi-layered partnership” then quickly redirects me to Google Cloud’s model marketplace – noting that customers can access various foundation models.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if Google is trying to be Switzerland while advancing its own agenda, it has had plenty of practice. The approach has roots in Google’s open-source contributions, from Kubernetes to the foundational “Attention is All You Need” paper that enabled the transformer architecture underlying most modern AI. More recently, Google published an open-source protocol called Agent-to-Agent (A2A) for inter-agent communication in an attempt to demonstrate its continued commitment to openness even in competitive areas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have made the explicit choice over the years to be open at every layer of the stack, and we know that this means companies can absolutely take our technology and use it to build a competitor at the next layer,” deSouza acknowledges. “That’s been happening for decades. That’s something we are okay with.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google Cloud’s courtship of startups comes at a particularly interesting moment. Just this month, federal judge Amit Mehta delivered a nuanced ruling in the government’s five-year-old search monopoly case, attempting to curb Google’s dominance without hampering its AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google avoided the Justice Department’s most severe proposed penalties, including the forced divestment of its Chrome browser, the ruling underscored regulatory concerns about the company leveraging its search monopoly to dominate AI. Critics are worried, understandably, that Google’s vast trove of search data provides an unfair advantage in developing AI systems, and that the company could deploy the same monopolistic tactics that secured its search dominance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In conversation, deSouza is focused on far more positive outcomes. “I think we have an opportunity to fundamentally understand some of the major diseases that today we just don’t have a good understanding of,” deSouza says, for example, outlining a vision where Google Cloud helps power research into Alzheimer’s, Parkinson’s, and climate technologies. “We want to work very hard to make sure that we are pioneering the technologies that will enable that work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Critics may not easily be assuaged. By positioning itself as an open platform that empowers rather than controls the next generation of AI companies, Google Cloud may be showing regulators that it fosters competition rather than stifles it, all while forging relationships with startups that might help Google’s case if regulators ramp up pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;For our full chat with deSouza, check out this week’s StrictlyVC Download podcast; a new episode comes out every Tuesday.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/24/it-isnt-your-imagination-google-cloud-is-flooding-the-zone/</guid><pubDate>Thu, 25 Sep 2025 04:41:36 +0000</pubDate></item><item><title>[NEW] How AI and Wikipedia have sent vulnerable languages into a doom spiral (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/0924f.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving.&lt;/p&gt;  &lt;p&gt;Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory, after visiting as a teenager. He’d spent years writing obscure Wikipedia articles in his native tongue on virtually everything to do with it. He even ended up moving to Copenhagen to study Greenlandic, a language spoken by some 57,000 mostly Indigenous Inuit people scattered across dozens of far-flung Arctic villages.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The Greenlandic-language edition was added to Wikipedia around 2003, just a few years after the site launched in English. By the time Wehr took its helm nearly 20 years later, hundreds of Wikipedians had contributed to it and had collectively written some 1,500 articles totaling over tens of thousands of words. It seemed to be an impressive vindication of the crowdsourcing approach that has made Wikipedia the go-to source for information online, demonstrating that it could work even in the unlikeliest places.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;There was only one problem: The Greenlandic Wikipedia was a mirage.&amp;nbsp;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Virtually every single article had been published by people who did not actually speak the language. Wehr, who now teaches Greenlandic in Denmark, speculates that perhaps only one or two Greenlanders had ever contributed. But what worried him most was something else: Over time, he had noticed that a growing number of articles appeared to be copy-pasted into Wikipedia by people using machine translators. They were riddled with elementary mistakes—from grammatical blunders to meaningless words to more significant inaccuracies, like an entry that claimed Canada had only 41 inhabitants. Other pages sometimes contained random strings of letters spat out by machines that were unable to find suitable Greenlandic words to express themselves.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It might have looked Greenlandic to [the authors], but they had no way of knowing,” complains Wehr. &lt;/p&gt; 
 &lt;p&gt;“Sentences wouldn’t make sense at all, or they would have obvious errors,” he adds. “AI translators are really bad at Greenlandic.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What Wehr describes is not unique to the Greenlandic edition.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed and tested. Many of these smaller editions have been swamped with automatically translated content as AI has become increasingly accessible. Volunteers working on four African languages, for instance, estimated to &lt;em&gt;MIT Technology Review &lt;/em&gt;that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations. And after auditing the Wikipedia edition in Inuktitut, an Indigenous language close to Greenlandic that’s spoken in Canada, &lt;em&gt;MIT Technology Review &lt;/em&gt;estimates that more than two-thirds of pages containing more than several sentences feature portions created this way.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is beginning to cause a wicked problem. AI systems, from Google Translate to ChatGPT, learn to “speak” new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages, grammatical or otherwise, can poison the wells that AI is expected to draw from. That can make the models’ translation of these languages particularly error-prone, which creates a sort of linguistic doom loop as people continue to add more and more poorly translated Wikipedia pages using those tools, and AI models continue to train from poorly translated pages. It’s a complicated problem, but it boils down to a simple concept: Garbage in, garbage out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“These models are built on raw data,” says Kevin Scannell, a former professor of computer science at Saint Louis University who now builds computer software tailored for endangered languages. “They will try and learn everything about a language from scratch. There is no other input. There are no grammar books. There are no dictionaries. There is nothing other than the text that is inputted.”&lt;/p&gt;  &lt;p&gt;There isn’t perfect data on the scale of this problem, particularly because a lot of AI training data is kept confidential and the field continues to evolve rapidly. But back in 2020, Wikipedia was estimated to make up more than half the training data that was fed into AI models translating some languages spoken by millions across Africa, including Malagasy, Yoruba, and Shona. In 2022, a research team from Germany that looked into what data could be obtained by online scraping even found that Wikipedia was the sole easily accessible source of online linguistic data for 27 under-resourced languages.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This could have significant repercussions in cases where Wikipedia is poorly written—potentially pushing the most vulnerable languages on Earth toward the precipice as future generations begin to turn away from them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Wikipedia will be reflected in the AI models for these languages,” says Trond Trosterud, a computational linguist at the University of Tromsø in Norway, who has been raising the alarm about the potentially harmful outcomes of badly run Wikipedia editions for years. “I find it hard to imagine it will not have consequences. And, of course, the more dominant position that Wikipedia has, the worse it will be.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Use responsibly&lt;/h3&gt;  &lt;p&gt;Automation has been built into Wikipedia since the very earliest days. Bots keep the platform operational: They repair broken links, fix bad formatting, and even correct spelling mistakes. These repetitive and mundane tasks can be automated away with little problem. There is even an army of bots that scurry around generating short articles about rivers, cities, or animals by slotting their names into formulaic phrases. They have generally made the platform better.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;But AI is different. Anybody can use it to cause massive damage with a few clicks.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Wikipedia has managed the onset of the AI era better than many other websites. It has not been flooded with AI bots or disinformation, as social media has been. It largely retains the innocence that characterized the earlier internet age. Wikipedia is open and free for anyone to use, edit, and pull from, and it’s run by the very same community it serves. It is transparent and easy to use. But community-run platforms live and die on the size of their communities. English has triumphed, while Greenlandic has sunk.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“We need good Wikipedians. This is something that people take for granted. It is not magic,” says Amir Aharoni, a member of the volunteer Language Committee, which oversees requests to open or close Wikipedia editions. “If you use machine translation responsibly, it can be efficient and useful. Unfortunately, you cannot trust all people to use it responsibly.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Trosterud has studied the behavior of users on small Wikipedia editions and says AI has empowered a subset that he terms “Wikipedia hijackers.” These users can range widely—from naive teenagers creating pages about their hometowns or their favorite YouTubers to well-meaning Wikipedians who think that by creating articles in minority languages they are in some way “helping” those communities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The problem with them nowadays is that they are armed with Google Translate,” Trosterud says, adding that this is allowing them to produce much longer and more plausible-looking content than they ever could before: “Earlier they were armed only with dictionaries.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This has effectively industrialized the acts of destruction—which affect vulnerable languages most, since AI translations are typically far less reliable for them. There can be lots of different reasons for this, but a meaningful part of the issue is the relatively small amount of source text that is available online. And sometimes models struggle to identify a language because it is similar to others, or because some, including Greenlandic and most Native American languages, have structures that make them badly suited to the way most machine translation systems work. (Wehr notes that in Greenlandic most words are agglutinative, meaning they are built by attaching prefixes and suffixes to stems. As a result, many words are extremely context specific and can express ideas that in other languages would take a full sentence.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Research produced by Google before a major expansion of Google Translate rolled out three years ago found that translation systems for lower-resourced languages were generally of a lower quality than those for better-resourced ones. Researchers found, for example, that their model would often mistranslate basic nouns across languages, including the names of animals and colors. (In a statement to &lt;em&gt;MIT&lt;/em&gt; &lt;em&gt;Technology Review&lt;/em&gt;, Google wrote that it is “committed to meeting a high standard of quality for all 249 languages” it supports “by rigorously testing and improving [its] systems, particularly for languages that may have limited public text resources on the web.”)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Wikipedia itself offers a built-in editing tool called Content Translate, which allows users to automatically translate articles from one language to another—the idea being that this will save time by preserving the references and fiddly formatting of the originals. But it piggybacks on external machine translation systems, so it’s largely plagued by the same weaknesses as other machine translators—a problem that the Wikimedia Foundation says is hard to solve. It’s up to each edition’s community to decide whether this tool is allowed, and some have decided against it. (Notably, English-language Wikipedia has largely banned its use, claiming that some 95% of articles created using Content Translate failed to meet an acceptable standard without significant additional work.) But it’s at least easy to tell when the program has been used; Content Translate adds a tag on the Wikipedia back end.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other AI programs can be harder to monitor. Still, many Wikipedia editors I spoke with said that once their languages were added to major online translation tools, they noticed a corresponding spike in the frequency with which poor, likely machine-translated pages were created.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some Wikipedians using AI to translate content do occasionally admit that they do not speak the target languages. They may see themselves as providing smaller communities with rough-cut articles that speakers can then fix—essentially following the same model that has worked well for more active Wikipedia editions.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt; &lt;/blockquote&gt;  &lt;p&gt;But once error-filled pages are produced in small languages, there is usually not an army of knowledgeable people who speak those languages standing ready to improve them. There are few readers of these editions, and sometimes not a single regular editor.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Yuet Man Lee, a Canadian teacher in his 20s, says that he used a mix of Google Translate and ChatGPT to translate a handful of articles that he had written for the English Wikipedia into Inuktitut, thinking it’d be nice to pitch in and help a smaller Wikipedia community. He says he added a note to one saying that it was only a rough translation. “I did not think that anybody would notice” the article, he explains. “If you put something out there on the smaller Wikipedias—most of the time nobody does.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But at the same time, he says, he still thought “someone might see it and fix it up”—adding that he had wondered whether the Inuktitut translation that the AI systems generated was grammatically correct. Nobody has touched the article since he created it.&lt;/p&gt; 
 &lt;p&gt;Lee, who teaches social sciences in Vancouver and first started editing entries in the English Wikipedia a decade ago, says that users familiar with more active Wikipedias can fall victim to this mindset, which he terms a “bigger-Wikipedia arrogance”: When they try to contribute to smaller Wikipedia editions, they assume that others will come along to fix their mistakes. It can sometimes work. Lee says he had previously contributed several articles to Wikipedia in Tatar, a language spoken by several million people mainly in Russia, and at least one of those was eventually corrected. But the Inuktitut Wikipedia is, by comparison, a “barren wasteland.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He emphasizes that his intentions had been good: He wanted to add more articles to an Indigenous Canadian Wikipedia. “I am now thinking that it may have been a bad idea. I did not consider that I could be contributing to a recursive loop,” he says. “It was about trying to get content out there, out of curiosity and for fun, without properly thinking about the consequences.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;&amp;nbsp;“Totally, completely no future”&lt;/h3&gt;  &lt;p&gt;Wikipedia is a project that is driven by wide-eyed optimism. Editing can be a thankless task, involving weeks spent bickering with faceless, pseudonymous people, but devotees put in hours of unpaid labor because of a commitment to a higher cause. It is this commitment that drives many of the regular small-language editors I spoke with. They all feared what would happen if garbage continued to appear on their pages.&lt;/p&gt;  &lt;p&gt;Abdulkadir Abdulkadir, a 26-year-old agricultural planner who spoke with me over a crackling phone call from a busy roadside in northern Nigeria, said that he spends three hours every day fiddling with entries in his native Fulfulde, a language used mainly by pastoralists and farmers across the Sahel. “But the work is too much,” he said.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Abdulkadir sees an urgent need for the Fufulde Wikipedia to work properly. He has been suggesting it as one of the few online resources for farmers in remote villages, potentially offering information on which seeds or crops might work best for their fields in a language they can understand. If you give them a machine-translated article, Abdulkadir told me, then it could “easily harm them,” as the information will probably not be translated correctly into Fulfulde.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Abdulkadir said he had recently been forced to correct an article about cowpeas, a foundational cash crop across much of Africa, after discovering that it was largely illegible.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If someone wants to create pages on the Fulfulde Wikipedia, Abdulkadir said, they should be translated manually. Otherwise, “whoever will read your articles will [not] be able to get even basic knowledge,” he tells these Wikipedians. Nevertheless, he estimates that some 60% of articles are still uncorrected machine translations. Abdulkadir told me that unless something important changes with how AI systems learn and are deployed, then the outlook for Fulfulde looks bleak. “It is going to be terrible, honestly,” he said. “Totally, completely no future.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Across the country from Abdulkadir, Lucy Iwuala contributes to Wikipedia in Igbo, a language spoken by several million people in southeastern Nigeria. “The harm has already been done,” she told me, opening the two most recently created articles. Both had been automatically translated via Wikipedia’s Content Translate and contained so many mistakes that she said it would have given her a headache to continue reading them. “There are some terms that have not even been translated. They are still in English,” she pointed out. She recognized the username that had created the pages as a serial offender. “This one even includes letters that are not used in the Igbo language,” she said.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Iwuala began regularly contributing to Wikipedia three years ago out of concern that Igbo was being displaced by English. It is a worry that is common to many who are active on smaller Wikipedia editions. “This is my culture. This is who I am,” she told me. “That is the essence of it all: to ensure that you are not erased.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Iwuala, who now works as a professional translator between English and Igbo, said the users doing the most damage are inexperienced and see AI translations as a way to quickly increase the profile of the Igbo Wikipedia. She often finds herself having to explain at online edit-a-thons she organizes, or over email to various error-prone editors, that the results can be the exact opposite, pushing users away: “You will be discouraged and you will no longer want to visit this place. You will just abandon it and go back to the English Wikipedia.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;These fears are echoed by Noah Ha‘alilio Solomon, an assistant professor of Hawaiian language at the University of Hawai‘i. He reports that some 35% of words on some pages in the Hawaiian Wikipedia are incomprehensible. “If this is the Hawaiian that is going to exist online, then it will do more harm than anything else,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hawaiian, which was teetering on the verge of extinction several decades ago, has been undergoing a recovery effort led by Indigenous activists and academics. Seeing such poor Hawaiian on such a widely used platform as Wikipedia is upsetting to Ha‘alilio Solomon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It is painful, because it reminds us of all the times that our culture and language has been appropriated,” he says. “We have been fighting tooth and nail in an uphill climb for language revitalization. There is nothing easy about that, and this can add extra impediments. People are going to think that this is an accurate representation of the Hawaiian language.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The consequences of all these Wikipedia errors can quickly become clear. AI translators that have undoubtedly ingested these pages in their training data are now assisting in the production, for instance, of error-strewn AI-generated books aimed at learners of languages as diverse as Inuktitut and Cree, Indigenous languages spoken in Canada, and Manx, a small Celtic language spoken on the Isle of Man. Many of these have been popping up for sale on Amazon. “It was just complete nonsense,” says Richard Compton, a linguist at the University of Quebec in Montreal, of a volume he reviewed that had purported to be an introductory phrasebook for Inuktitut.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Rather than making minority languages more accessible, AI is now creating an ever expanding minefield for students and speakers of those languages to navigate. “It is a slap in the face,” Compton says. He worries that younger generations in Canada, hoping to learn languages in communities that have fought uphill battles against discrimination to pass on their heritage, might turn to online tools such as ChatGPT or phrasebooks on Amazon and simply make matters worse. “It is fraud,” he says.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A race against time&lt;/h3&gt;  &lt;p&gt;According to UNESCO, a language is declared extinct every two weeks. But whether the Wikimedia Foundation, which runs Wikipedia, has an obligation to the languages used on its platform is an open question. When I spoke to Runa Bhattacharjee, a senior director at the foundation, she said that it was up to the individual communities to make decisions about what content they wanted to exist on their Wikipedia. “Ultimately, the responsibility really lies with the community to see that there is no vandalism or unwanted activity, whether through machine translation or other means,” she said. Usually, Bhattacharjee added, editions were considered for closure only if a specific complaint was raised about them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But if there is no active community, how can an edition be fixed or even have a complaint raised?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;Bhattacharjee explained that the Wikimedia Foundation sees its role in such cases as about maintaining the Wikipedia platform in case someone comes along to revive it: “It is the space that we provide for them to grow and develop. That is where we are at.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Inari Saami, spoken in a single remote community in northern Finland, is a poster child for how people can take good advantage of Wikipedia. The language was headed toward extinction four decades ago; there were only four children who spoke it. Their parents created the Inari Saami Language Association in a last-ditch bid to keep it going. The efforts worked. There are now several hundred speakers, schools that use Inari Saami as a medium of instruction, and 6,400 Wikipedia articles in the language, each one copy-edited by a fluent speaker.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This success highlights how Wikipedia can indeed provide small and determined communities with a unique vehicle to promote their languages’ preservation. “We don’t care about quantity. We care about quality,” says Fabrizio Brecciaroli, a member of the Inari Saami Language Association. “We are planning to use Wikipedia as a repository for the written language. We need to provide tools that can be used by the younger generations. It is important for them to be able to use Inari Saami digitally.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;This has been such a success that Wikipedia has been integrated into the curriculum at the Inari Saami–speaking schools, Brecciaroli adds. He fields phone calls from teachers asking him to write up simple pages on topics from tornadoes to Saami folklore. Wikipedia has even offered a way to introduce words into Inari Saami. “We have to make up new words all the time,” Brecciaroli says. “Young people need them to speak about sports, politics, and video games. If they are unsure how to say something, they now check Wikipedia.”&lt;/p&gt;  &lt;p&gt;Wikipedia is a monumental intellectual experiment. What’s happening with Inari Saami suggests that with maximum care, it can work in smaller languages. “The ultimate goal is to make sure that Inari Saami survives,” Brecciaroli says. “It might be a good thing that there isn’t a Google Translate in Inari Saami.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That may be true—though large language models like ChatGPT can be made to translate phrases into languages that more traditional machine translation tools do not offer. Brecciaroli told me that ChatGPT isn’t great in Inari Saami but that the quality varies significantly depending on what you ask it to do; if you ask it a question in the language, then the answer will be filled with words from Finnish and even words it invents. But if you ask it something in English, Finnish, or Italian and then ask it to reply in Inari Saami, it will perform better.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In light of all this, creating as much high-quality content online as can possibly be written becomes a race against time. “ChatGPT only needs a lot of words,” Brecciaroli says. “If we keep putting good material in, then sooner or later, we will get something out. That is the hope.” This is an idea supported by multiple linguists I spoke with—that it may be possible to end the “garbage in, garbage out” cycle. (OpenAI, which operates ChatGPT, did not respond to a request for comment.)&lt;/p&gt;  &lt;p&gt;Still, the overall problem is likely to grow and grow, since many languages are not as lucky as Inari Saami—and their AI translators will most likely be trained on more and more AI slop. Wehr, unfortunately, seems far less optimistic about the future of his beloved Greenlandic.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Since deleting much of the Greenlandic-language Wikipedia, he has spent years trying to recruit speakers to help him revive it. He has appeared in Greenlandic media and made social media appeals. But he hasn’t gotten much of a response; he says it has been demoralizing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There is nobody in Greenland who is interested in this, or who wants to contribute,” he says. “There is completely no point in it, and that is why it should be closed.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Late last year, he began a process requesting that the Wikipedia Language Committee shut down the Greenlandic-language edition. Months of bitter debate followed between dozens of Wikipedia bureaucrats; some seemed to be surprised that a superficially healthy-seeming edition could be gripped by so many problems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Then, earlier this month, Wehr’s proposal was accepted: Greenlandic Wikipedia is set to be shuttered, and any articles that remain will be moved into the Wikipedia Incubator, where new language editions are tested and built. Among the reasons cited by the Language Committee is the use of AI tools, which have “frequently produced nonsense that could misrepresent the language.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, it may be too late—mistakes in Greenlandic already seem to have become embedded in machine translators. If you prompt either Google Translate or ChatGPT to do something as simple as count to 10 in proper Greenlandic, neither program can deliver.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jacob Judah is an investigative journalist based in London.&amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/0924f.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving.&lt;/p&gt;  &lt;p&gt;Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory, after visiting as a teenager. He’d spent years writing obscure Wikipedia articles in his native tongue on virtually everything to do with it. He even ended up moving to Copenhagen to study Greenlandic, a language spoken by some 57,000 mostly Indigenous Inuit people scattered across dozens of far-flung Arctic villages.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The Greenlandic-language edition was added to Wikipedia around 2003, just a few years after the site launched in English. By the time Wehr took its helm nearly 20 years later, hundreds of Wikipedians had contributed to it and had collectively written some 1,500 articles totaling over tens of thousands of words. It seemed to be an impressive vindication of the crowdsourcing approach that has made Wikipedia the go-to source for information online, demonstrating that it could work even in the unlikeliest places.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;There was only one problem: The Greenlandic Wikipedia was a mirage.&amp;nbsp;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Virtually every single article had been published by people who did not actually speak the language. Wehr, who now teaches Greenlandic in Denmark, speculates that perhaps only one or two Greenlanders had ever contributed. But what worried him most was something else: Over time, he had noticed that a growing number of articles appeared to be copy-pasted into Wikipedia by people using machine translators. They were riddled with elementary mistakes—from grammatical blunders to meaningless words to more significant inaccuracies, like an entry that claimed Canada had only 41 inhabitants. Other pages sometimes contained random strings of letters spat out by machines that were unable to find suitable Greenlandic words to express themselves.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It might have looked Greenlandic to [the authors], but they had no way of knowing,” complains Wehr. &lt;/p&gt; 
 &lt;p&gt;“Sentences wouldn’t make sense at all, or they would have obvious errors,” he adds. “AI translators are really bad at Greenlandic.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What Wehr describes is not unique to the Greenlandic edition.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed and tested. Many of these smaller editions have been swamped with automatically translated content as AI has become increasingly accessible. Volunteers working on four African languages, for instance, estimated to &lt;em&gt;MIT Technology Review &lt;/em&gt;that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations. And after auditing the Wikipedia edition in Inuktitut, an Indigenous language close to Greenlandic that’s spoken in Canada, &lt;em&gt;MIT Technology Review &lt;/em&gt;estimates that more than two-thirds of pages containing more than several sentences feature portions created this way.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is beginning to cause a wicked problem. AI systems, from Google Translate to ChatGPT, learn to “speak” new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages, grammatical or otherwise, can poison the wells that AI is expected to draw from. That can make the models’ translation of these languages particularly error-prone, which creates a sort of linguistic doom loop as people continue to add more and more poorly translated Wikipedia pages using those tools, and AI models continue to train from poorly translated pages. It’s a complicated problem, but it boils down to a simple concept: Garbage in, garbage out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“These models are built on raw data,” says Kevin Scannell, a former professor of computer science at Saint Louis University who now builds computer software tailored for endangered languages. “They will try and learn everything about a language from scratch. There is no other input. There are no grammar books. There are no dictionaries. There is nothing other than the text that is inputted.”&lt;/p&gt;  &lt;p&gt;There isn’t perfect data on the scale of this problem, particularly because a lot of AI training data is kept confidential and the field continues to evolve rapidly. But back in 2020, Wikipedia was estimated to make up more than half the training data that was fed into AI models translating some languages spoken by millions across Africa, including Malagasy, Yoruba, and Shona. In 2022, a research team from Germany that looked into what data could be obtained by online scraping even found that Wikipedia was the sole easily accessible source of online linguistic data for 27 under-resourced languages.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This could have significant repercussions in cases where Wikipedia is poorly written—potentially pushing the most vulnerable languages on Earth toward the precipice as future generations begin to turn away from them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Wikipedia will be reflected in the AI models for these languages,” says Trond Trosterud, a computational linguist at the University of Tromsø in Norway, who has been raising the alarm about the potentially harmful outcomes of badly run Wikipedia editions for years. “I find it hard to imagine it will not have consequences. And, of course, the more dominant position that Wikipedia has, the worse it will be.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Use responsibly&lt;/h3&gt;  &lt;p&gt;Automation has been built into Wikipedia since the very earliest days. Bots keep the platform operational: They repair broken links, fix bad formatting, and even correct spelling mistakes. These repetitive and mundane tasks can be automated away with little problem. There is even an army of bots that scurry around generating short articles about rivers, cities, or animals by slotting their names into formulaic phrases. They have generally made the platform better.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;But AI is different. Anybody can use it to cause massive damage with a few clicks.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Wikipedia has managed the onset of the AI era better than many other websites. It has not been flooded with AI bots or disinformation, as social media has been. It largely retains the innocence that characterized the earlier internet age. Wikipedia is open and free for anyone to use, edit, and pull from, and it’s run by the very same community it serves. It is transparent and easy to use. But community-run platforms live and die on the size of their communities. English has triumphed, while Greenlandic has sunk.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“We need good Wikipedians. This is something that people take for granted. It is not magic,” says Amir Aharoni, a member of the volunteer Language Committee, which oversees requests to open or close Wikipedia editions. “If you use machine translation responsibly, it can be efficient and useful. Unfortunately, you cannot trust all people to use it responsibly.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Trosterud has studied the behavior of users on small Wikipedia editions and says AI has empowered a subset that he terms “Wikipedia hijackers.” These users can range widely—from naive teenagers creating pages about their hometowns or their favorite YouTubers to well-meaning Wikipedians who think that by creating articles in minority languages they are in some way “helping” those communities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The problem with them nowadays is that they are armed with Google Translate,” Trosterud says, adding that this is allowing them to produce much longer and more plausible-looking content than they ever could before: “Earlier they were armed only with dictionaries.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This has effectively industrialized the acts of destruction—which affect vulnerable languages most, since AI translations are typically far less reliable for them. There can be lots of different reasons for this, but a meaningful part of the issue is the relatively small amount of source text that is available online. And sometimes models struggle to identify a language because it is similar to others, or because some, including Greenlandic and most Native American languages, have structures that make them badly suited to the way most machine translation systems work. (Wehr notes that in Greenlandic most words are agglutinative, meaning they are built by attaching prefixes and suffixes to stems. As a result, many words are extremely context specific and can express ideas that in other languages would take a full sentence.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Research produced by Google before a major expansion of Google Translate rolled out three years ago found that translation systems for lower-resourced languages were generally of a lower quality than those for better-resourced ones. Researchers found, for example, that their model would often mistranslate basic nouns across languages, including the names of animals and colors. (In a statement to &lt;em&gt;MIT&lt;/em&gt; &lt;em&gt;Technology Review&lt;/em&gt;, Google wrote that it is “committed to meeting a high standard of quality for all 249 languages” it supports “by rigorously testing and improving [its] systems, particularly for languages that may have limited public text resources on the web.”)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Wikipedia itself offers a built-in editing tool called Content Translate, which allows users to automatically translate articles from one language to another—the idea being that this will save time by preserving the references and fiddly formatting of the originals. But it piggybacks on external machine translation systems, so it’s largely plagued by the same weaknesses as other machine translators—a problem that the Wikimedia Foundation says is hard to solve. It’s up to each edition’s community to decide whether this tool is allowed, and some have decided against it. (Notably, English-language Wikipedia has largely banned its use, claiming that some 95% of articles created using Content Translate failed to meet an acceptable standard without significant additional work.) But it’s at least easy to tell when the program has been used; Content Translate adds a tag on the Wikipedia back end.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other AI programs can be harder to monitor. Still, many Wikipedia editors I spoke with said that once their languages were added to major online translation tools, they noticed a corresponding spike in the frequency with which poor, likely machine-translated pages were created.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some Wikipedians using AI to translate content do occasionally admit that they do not speak the target languages. They may see themselves as providing smaller communities with rough-cut articles that speakers can then fix—essentially following the same model that has worked well for more active Wikipedia editions.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt; &lt;/blockquote&gt;  &lt;p&gt;But once error-filled pages are produced in small languages, there is usually not an army of knowledgeable people who speak those languages standing ready to improve them. There are few readers of these editions, and sometimes not a single regular editor.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Yuet Man Lee, a Canadian teacher in his 20s, says that he used a mix of Google Translate and ChatGPT to translate a handful of articles that he had written for the English Wikipedia into Inuktitut, thinking it’d be nice to pitch in and help a smaller Wikipedia community. He says he added a note to one saying that it was only a rough translation. “I did not think that anybody would notice” the article, he explains. “If you put something out there on the smaller Wikipedias—most of the time nobody does.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But at the same time, he says, he still thought “someone might see it and fix it up”—adding that he had wondered whether the Inuktitut translation that the AI systems generated was grammatically correct. Nobody has touched the article since he created it.&lt;/p&gt; 
 &lt;p&gt;Lee, who teaches social sciences in Vancouver and first started editing entries in the English Wikipedia a decade ago, says that users familiar with more active Wikipedias can fall victim to this mindset, which he terms a “bigger-Wikipedia arrogance”: When they try to contribute to smaller Wikipedia editions, they assume that others will come along to fix their mistakes. It can sometimes work. Lee says he had previously contributed several articles to Wikipedia in Tatar, a language spoken by several million people mainly in Russia, and at least one of those was eventually corrected. But the Inuktitut Wikipedia is, by comparison, a “barren wasteland.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He emphasizes that his intentions had been good: He wanted to add more articles to an Indigenous Canadian Wikipedia. “I am now thinking that it may have been a bad idea. I did not consider that I could be contributing to a recursive loop,” he says. “It was about trying to get content out there, out of curiosity and for fun, without properly thinking about the consequences.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;&amp;nbsp;“Totally, completely no future”&lt;/h3&gt;  &lt;p&gt;Wikipedia is a project that is driven by wide-eyed optimism. Editing can be a thankless task, involving weeks spent bickering with faceless, pseudonymous people, but devotees put in hours of unpaid labor because of a commitment to a higher cause. It is this commitment that drives many of the regular small-language editors I spoke with. They all feared what would happen if garbage continued to appear on their pages.&lt;/p&gt;  &lt;p&gt;Abdulkadir Abdulkadir, a 26-year-old agricultural planner who spoke with me over a crackling phone call from a busy roadside in northern Nigeria, said that he spends three hours every day fiddling with entries in his native Fulfulde, a language used mainly by pastoralists and farmers across the Sahel. “But the work is too much,” he said.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Abdulkadir sees an urgent need for the Fufulde Wikipedia to work properly. He has been suggesting it as one of the few online resources for farmers in remote villages, potentially offering information on which seeds or crops might work best for their fields in a language they can understand. If you give them a machine-translated article, Abdulkadir told me, then it could “easily harm them,” as the information will probably not be translated correctly into Fulfulde.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Abdulkadir said he had recently been forced to correct an article about cowpeas, a foundational cash crop across much of Africa, after discovering that it was largely illegible.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If someone wants to create pages on the Fulfulde Wikipedia, Abdulkadir said, they should be translated manually. Otherwise, “whoever will read your articles will [not] be able to get even basic knowledge,” he tells these Wikipedians. Nevertheless, he estimates that some 60% of articles are still uncorrected machine translations. Abdulkadir told me that unless something important changes with how AI systems learn and are deployed, then the outlook for Fulfulde looks bleak. “It is going to be terrible, honestly,” he said. “Totally, completely no future.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Across the country from Abdulkadir, Lucy Iwuala contributes to Wikipedia in Igbo, a language spoken by several million people in southeastern Nigeria. “The harm has already been done,” she told me, opening the two most recently created articles. Both had been automatically translated via Wikipedia’s Content Translate and contained so many mistakes that she said it would have given her a headache to continue reading them. “There are some terms that have not even been translated. They are still in English,” she pointed out. She recognized the username that had created the pages as a serial offender. “This one even includes letters that are not used in the Igbo language,” she said.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Iwuala began regularly contributing to Wikipedia three years ago out of concern that Igbo was being displaced by English. It is a worry that is common to many who are active on smaller Wikipedia editions. “This is my culture. This is who I am,” she told me. “That is the essence of it all: to ensure that you are not erased.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Iwuala, who now works as a professional translator between English and Igbo, said the users doing the most damage are inexperienced and see AI translations as a way to quickly increase the profile of the Igbo Wikipedia. She often finds herself having to explain at online edit-a-thons she organizes, or over email to various error-prone editors, that the results can be the exact opposite, pushing users away: “You will be discouraged and you will no longer want to visit this place. You will just abandon it and go back to the English Wikipedia.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;These fears are echoed by Noah Ha‘alilio Solomon, an assistant professor of Hawaiian language at the University of Hawai‘i. He reports that some 35% of words on some pages in the Hawaiian Wikipedia are incomprehensible. “If this is the Hawaiian that is going to exist online, then it will do more harm than anything else,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hawaiian, which was teetering on the verge of extinction several decades ago, has been undergoing a recovery effort led by Indigenous activists and academics. Seeing such poor Hawaiian on such a widely used platform as Wikipedia is upsetting to Ha‘alilio Solomon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It is painful, because it reminds us of all the times that our culture and language has been appropriated,” he says. “We have been fighting tooth and nail in an uphill climb for language revitalization. There is nothing easy about that, and this can add extra impediments. People are going to think that this is an accurate representation of the Hawaiian language.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The consequences of all these Wikipedia errors can quickly become clear. AI translators that have undoubtedly ingested these pages in their training data are now assisting in the production, for instance, of error-strewn AI-generated books aimed at learners of languages as diverse as Inuktitut and Cree, Indigenous languages spoken in Canada, and Manx, a small Celtic language spoken on the Isle of Man. Many of these have been popping up for sale on Amazon. “It was just complete nonsense,” says Richard Compton, a linguist at the University of Quebec in Montreal, of a volume he reviewed that had purported to be an introductory phrasebook for Inuktitut.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Rather than making minority languages more accessible, AI is now creating an ever expanding minefield for students and speakers of those languages to navigate. “It is a slap in the face,” Compton says. He worries that younger generations in Canada, hoping to learn languages in communities that have fought uphill battles against discrimination to pass on their heritage, might turn to online tools such as ChatGPT or phrasebooks on Amazon and simply make matters worse. “It is fraud,” he says.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A race against time&lt;/h3&gt;  &lt;p&gt;According to UNESCO, a language is declared extinct every two weeks. But whether the Wikimedia Foundation, which runs Wikipedia, has an obligation to the languages used on its platform is an open question. When I spoke to Runa Bhattacharjee, a senior director at the foundation, she said that it was up to the individual communities to make decisions about what content they wanted to exist on their Wikipedia. “Ultimately, the responsibility really lies with the community to see that there is no vandalism or unwanted activity, whether through machine translation or other means,” she said. Usually, Bhattacharjee added, editions were considered for closure only if a specific complaint was raised about them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But if there is no active community, how can an edition be fixed or even have a complaint raised?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;Bhattacharjee explained that the Wikimedia Foundation sees its role in such cases as about maintaining the Wikipedia platform in case someone comes along to revive it: “It is the space that we provide for them to grow and develop. That is where we are at.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Inari Saami, spoken in a single remote community in northern Finland, is a poster child for how people can take good advantage of Wikipedia. The language was headed toward extinction four decades ago; there were only four children who spoke it. Their parents created the Inari Saami Language Association in a last-ditch bid to keep it going. The efforts worked. There are now several hundred speakers, schools that use Inari Saami as a medium of instruction, and 6,400 Wikipedia articles in the language, each one copy-edited by a fluent speaker.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This success highlights how Wikipedia can indeed provide small and determined communities with a unique vehicle to promote their languages’ preservation. “We don’t care about quantity. We care about quality,” says Fabrizio Brecciaroli, a member of the Inari Saami Language Association. “We are planning to use Wikipedia as a repository for the written language. We need to provide tools that can be used by the younger generations. It is important for them to be able to use Inari Saami digitally.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;This has been such a success that Wikipedia has been integrated into the curriculum at the Inari Saami–speaking schools, Brecciaroli adds. He fields phone calls from teachers asking him to write up simple pages on topics from tornadoes to Saami folklore. Wikipedia has even offered a way to introduce words into Inari Saami. “We have to make up new words all the time,” Brecciaroli says. “Young people need them to speak about sports, politics, and video games. If they are unsure how to say something, they now check Wikipedia.”&lt;/p&gt;  &lt;p&gt;Wikipedia is a monumental intellectual experiment. What’s happening with Inari Saami suggests that with maximum care, it can work in smaller languages. “The ultimate goal is to make sure that Inari Saami survives,” Brecciaroli says. “It might be a good thing that there isn’t a Google Translate in Inari Saami.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That may be true—though large language models like ChatGPT can be made to translate phrases into languages that more traditional machine translation tools do not offer. Brecciaroli told me that ChatGPT isn’t great in Inari Saami but that the quality varies significantly depending on what you ask it to do; if you ask it a question in the language, then the answer will be filled with words from Finnish and even words it invents. But if you ask it something in English, Finnish, or Italian and then ask it to reply in Inari Saami, it will perform better.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In light of all this, creating as much high-quality content online as can possibly be written becomes a race against time. “ChatGPT only needs a lot of words,” Brecciaroli says. “If we keep putting good material in, then sooner or later, we will get something out. That is the hope.” This is an idea supported by multiple linguists I spoke with—that it may be possible to end the “garbage in, garbage out” cycle. (OpenAI, which operates ChatGPT, did not respond to a request for comment.)&lt;/p&gt;  &lt;p&gt;Still, the overall problem is likely to grow and grow, since many languages are not as lucky as Inari Saami—and their AI translators will most likely be trained on more and more AI slop. Wehr, unfortunately, seems far less optimistic about the future of his beloved Greenlandic.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Since deleting much of the Greenlandic-language Wikipedia, he has spent years trying to recruit speakers to help him revive it. He has appeared in Greenlandic media and made social media appeals. But he hasn’t gotten much of a response; he says it has been demoralizing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There is nobody in Greenland who is interested in this, or who wants to contribute,” he says. “There is completely no point in it, and that is why it should be closed.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Late last year, he began a process requesting that the Wikipedia Language Committee shut down the Greenlandic-language edition. Months of bitter debate followed between dozens of Wikipedia bureaucrats; some seemed to be surprised that a superficially healthy-seeming edition could be gripped by so many problems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Then, earlier this month, Wehr’s proposal was accepted: Greenlandic Wikipedia is set to be shuttered, and any articles that remain will be moved into the Wikipedia Incubator, where new language editions are tested and built. Among the reasons cited by the Language Committee is the use of AI tools, which have “frequently produced nonsense that could misrepresent the language.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, it may be too late—mistakes in Greenlandic already seem to have become embedded in machine translators. If you prompt either Google Translate or ChatGPT to do something as simple as count to 10 in proper Greenlandic, neither program can deliver.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jacob Judah is an investigative journalist based in London.&amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/</guid><pubDate>Thu, 25 Sep 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Inside Huawei’s plan to make thousands of AI chips think like one computer (AI News)</title><link>https://www.artificialintelligence-news.com/news/huawei-ai-chips-superpod-technology/</link><description>&lt;p&gt;Imagine connecting thousands of powerful AI chips scattered in dozens of server cabinets and making them work together as if they were a single, massive computer. That is exactly what Huawei demonstrated at HUAWEI CONNECT 2025, where the company unveiled a breakthrough in AI infrastructure architecture that could reshape how the world builds and scales artificial intelligence systems.&lt;/p&gt;&lt;p&gt;Instead of traditional approaches where individual servers work somewhat independently, Huawei’s new SuperPoD technology creates what the company’s executives describe as a single logical machine made from thousands of separate processing units, allowing them, or it, to “learn, think, and reason as one.”&lt;/p&gt;&lt;p&gt;The implications extend beyond impressive technical specifications, representing a shift in how AI computing power can be organised, scaled, and deployed in industries.&lt;/p&gt;&lt;h3&gt;The technical foundation: UnifiedBus 2.0&lt;/h3&gt;&lt;p&gt;At the core of Huawei’s infrastructure approach is UnifiedBus (UB). Yang Chaobin, Huawei’s Director of the Board and CEO of the ICT Business Group, explained that “Huawei has developed the groundbreaking SuperPoD architecture based on our UnifiedBus interconnect protocol. The architecture deeply interconnects physical servers so that they can learn, think, and reason like a single logical server.”&lt;/p&gt;&lt;p&gt;The technical specifications reveal the scope of this achievement. The UnifiedBus protocol addresses two challenges that, historically, have limited large-scale AI computing: the reliability of long-range communications and bandwidth-latency. Traditional copper connections provide high bandwidth but only over short distances, typically connecting perhaps two cabinets.&lt;/p&gt;&lt;p&gt;Optical cables support longer range but suffer from reliability issues that become more problematic the greater the distance and scale. Eric Xu, Huawei’s Deputy Chairman and Rotating Chairman, said that solving these fundamental connectivity challenges was essential to the company’s AI infrastructure strategy.&lt;/p&gt;&lt;p&gt;Xu detailed the breakthrough solutions in terms of the OSI model: “We have built reliability into every layer of our interconnect protocol, from the physical layer and data link layer, all the way up to the network and transmission layers. There is 100-ns-level fault detection and protection switching on optical paths, making any intermittent disconnections or faults of optical modules imperceptible at the application layer.”&lt;/p&gt;&lt;h3&gt;SuperPoD architecture: Scale and performance&lt;/h3&gt;&lt;p&gt;The Atlas 950 SuperPoD represents the flagship implementation of this architecture, comprising of up to 8,192 Ascend 950DT chips in a configuration that Xu described as delivering “8 EFLOPS in FP8 and 16 EFLOPS in FP4. Its interconnect bandwidth will be 16 PB/s. This means that a single Atlas 950 SuperPoD will have an interconnect bandwidth over 10 times higher than the entire globe’s total peak internet bandwidth.”&lt;/p&gt;&lt;p&gt;The specifications are more than incremental improvements. The Atlas 950 SuperPoD occupies 160 cabinets in 1,000m&lt;sup&gt;2&lt;/sup&gt;, with 128 compute cabinets and 32 comms cabinets linked with all-optical interconnects. The system’s memory capacity reaches 1,152 TB and maintains what Huawei claims is 2.1-microsecond latency in the entire system.&lt;/p&gt;&lt;p&gt;Later in the production pipeline will be the Atlas 960 SuperPoD, which is set to incorporate 15,488 Ascend 960 chips in 220 cabinets covering 2,200m&lt;sup&gt;2&lt;/sup&gt;. Xu said it will deliver “30 EFLOPS in FP8 and 60 EFLOPS in FP4, and come with 4,460 TB of memory and 34 PB/s interconnect bandwidth.”&lt;/p&gt;&lt;h3&gt;Beyond AI: General-purpose computing applications&lt;/h3&gt;&lt;p&gt;The SuperPoD concept extends beyond AI workloads into general-purpose computing through the TaiShan 950 SuperPoD. Built on Kunpeng 950 processors, this system addresses enterprise challenges in replacing legacy mainframes and mid-range computers.&lt;/p&gt;&lt;p&gt;Xu positioned this as particularly relevant for the finance sector, where “the TaiShan 950 SuperPoD, combined with the distributed GaussDB, can serve as an ideal alternative, and replace — once and for all — mainframes, mid-range computers, and Oracle’s Exadata database servers.”&lt;/p&gt;&lt;h3&gt;Open architecture strategy&lt;/h3&gt;&lt;p&gt;Perhaps most significantly for the broader AI infrastructure market, Huawei announced the release of UnifiedBus 2.0 technical specifications as open standards. The decision reflects both strategic positioning and practical constraints.&lt;/p&gt;&lt;p&gt;Xu acknowledged that “the Chinese mainland will lag behind in semiconductor manufacturing process nodes for a relatively long time” and emphasised that “sustainable computing power can only be achieved with process nodes that are practically available.”&lt;/p&gt;&lt;p&gt;Yang framed the open approach as ecosystem building: “We are committed to our open-hardware and open-source-software approach that will help more partners develop their own industry-scenario-based SuperPoD solutions. This will accelerate developer innovation and foster a thriving ecosystem.”&lt;/p&gt;&lt;p&gt;The company is to open-source hardware and software components, with hardware including NPU modules, air-cooled and liquid-cooled blade servers, AI cards, CPU boards, and cascade cards. For software, Huawei committed to fully open-sourcing CANN compiler tools, Mind series application kits, and openPangu foundation models by 31 December 2025.&lt;/p&gt;&lt;h3&gt;Market deployment and ecosystem impact&lt;/h3&gt;&lt;p&gt;Real-world deployment provides validation for these technical claims. Over 300 Atlas 900 A3 SuperPoD units have already been shipped in 2025, which have been deployed for more than 20 customers from multiple sectors, including the Internet, finance, carrier, electricity, and manufacturing sectors.&lt;/p&gt;&lt;p&gt;The implications for the development of China’s AI infrastructure are substantial. By creating an open ecosystem around domestic technology, Huawei is addressing the challenges of building competitive AI infrastructure inside parameters set by constrained semiconductor manufacturing and availability. Its approach enables broader industry participation in developing AI infrastructure solutions without needing access to the most advanced process nodes.&lt;/p&gt;&lt;p&gt;For the global AI infrastructure market, Huawei’s open architecture strategy introduces an alternative to the tightly integrated, proprietary hardware and software approach dominant among Western competitors. Whether the ecosystem proposed by Huawei can achieve comparable performance and maintain commercial viability remains to be demonstrated at scale.&lt;/p&gt;&lt;p&gt;Ultimately, the SuperPoD architecture represents more than an incremental advance for AI computing. Huawei is proposing a fundamental of how massive computational resources are connected, managed, and scaled. The open-source release of its specifications and elements will test whether collaborative development can accelerate AI infrastructure innovation in an ecosystem of partners. That has the potential to reshape competitive dynamics in the global AI infrastructure market.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Huawei commits to training 30,000 Malaysian AI professionals as local tech ecosystem expands&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Imagine connecting thousands of powerful AI chips scattered in dozens of server cabinets and making them work together as if they were a single, massive computer. That is exactly what Huawei demonstrated at HUAWEI CONNECT 2025, where the company unveiled a breakthrough in AI infrastructure architecture that could reshape how the world builds and scales artificial intelligence systems.&lt;/p&gt;&lt;p&gt;Instead of traditional approaches where individual servers work somewhat independently, Huawei’s new SuperPoD technology creates what the company’s executives describe as a single logical machine made from thousands of separate processing units, allowing them, or it, to “learn, think, and reason as one.”&lt;/p&gt;&lt;p&gt;The implications extend beyond impressive technical specifications, representing a shift in how AI computing power can be organised, scaled, and deployed in industries.&lt;/p&gt;&lt;h3&gt;The technical foundation: UnifiedBus 2.0&lt;/h3&gt;&lt;p&gt;At the core of Huawei’s infrastructure approach is UnifiedBus (UB). Yang Chaobin, Huawei’s Director of the Board and CEO of the ICT Business Group, explained that “Huawei has developed the groundbreaking SuperPoD architecture based on our UnifiedBus interconnect protocol. The architecture deeply interconnects physical servers so that they can learn, think, and reason like a single logical server.”&lt;/p&gt;&lt;p&gt;The technical specifications reveal the scope of this achievement. The UnifiedBus protocol addresses two challenges that, historically, have limited large-scale AI computing: the reliability of long-range communications and bandwidth-latency. Traditional copper connections provide high bandwidth but only over short distances, typically connecting perhaps two cabinets.&lt;/p&gt;&lt;p&gt;Optical cables support longer range but suffer from reliability issues that become more problematic the greater the distance and scale. Eric Xu, Huawei’s Deputy Chairman and Rotating Chairman, said that solving these fundamental connectivity challenges was essential to the company’s AI infrastructure strategy.&lt;/p&gt;&lt;p&gt;Xu detailed the breakthrough solutions in terms of the OSI model: “We have built reliability into every layer of our interconnect protocol, from the physical layer and data link layer, all the way up to the network and transmission layers. There is 100-ns-level fault detection and protection switching on optical paths, making any intermittent disconnections or faults of optical modules imperceptible at the application layer.”&lt;/p&gt;&lt;h3&gt;SuperPoD architecture: Scale and performance&lt;/h3&gt;&lt;p&gt;The Atlas 950 SuperPoD represents the flagship implementation of this architecture, comprising of up to 8,192 Ascend 950DT chips in a configuration that Xu described as delivering “8 EFLOPS in FP8 and 16 EFLOPS in FP4. Its interconnect bandwidth will be 16 PB/s. This means that a single Atlas 950 SuperPoD will have an interconnect bandwidth over 10 times higher than the entire globe’s total peak internet bandwidth.”&lt;/p&gt;&lt;p&gt;The specifications are more than incremental improvements. The Atlas 950 SuperPoD occupies 160 cabinets in 1,000m&lt;sup&gt;2&lt;/sup&gt;, with 128 compute cabinets and 32 comms cabinets linked with all-optical interconnects. The system’s memory capacity reaches 1,152 TB and maintains what Huawei claims is 2.1-microsecond latency in the entire system.&lt;/p&gt;&lt;p&gt;Later in the production pipeline will be the Atlas 960 SuperPoD, which is set to incorporate 15,488 Ascend 960 chips in 220 cabinets covering 2,200m&lt;sup&gt;2&lt;/sup&gt;. Xu said it will deliver “30 EFLOPS in FP8 and 60 EFLOPS in FP4, and come with 4,460 TB of memory and 34 PB/s interconnect bandwidth.”&lt;/p&gt;&lt;h3&gt;Beyond AI: General-purpose computing applications&lt;/h3&gt;&lt;p&gt;The SuperPoD concept extends beyond AI workloads into general-purpose computing through the TaiShan 950 SuperPoD. Built on Kunpeng 950 processors, this system addresses enterprise challenges in replacing legacy mainframes and mid-range computers.&lt;/p&gt;&lt;p&gt;Xu positioned this as particularly relevant for the finance sector, where “the TaiShan 950 SuperPoD, combined with the distributed GaussDB, can serve as an ideal alternative, and replace — once and for all — mainframes, mid-range computers, and Oracle’s Exadata database servers.”&lt;/p&gt;&lt;h3&gt;Open architecture strategy&lt;/h3&gt;&lt;p&gt;Perhaps most significantly for the broader AI infrastructure market, Huawei announced the release of UnifiedBus 2.0 technical specifications as open standards. The decision reflects both strategic positioning and practical constraints.&lt;/p&gt;&lt;p&gt;Xu acknowledged that “the Chinese mainland will lag behind in semiconductor manufacturing process nodes for a relatively long time” and emphasised that “sustainable computing power can only be achieved with process nodes that are practically available.”&lt;/p&gt;&lt;p&gt;Yang framed the open approach as ecosystem building: “We are committed to our open-hardware and open-source-software approach that will help more partners develop their own industry-scenario-based SuperPoD solutions. This will accelerate developer innovation and foster a thriving ecosystem.”&lt;/p&gt;&lt;p&gt;The company is to open-source hardware and software components, with hardware including NPU modules, air-cooled and liquid-cooled blade servers, AI cards, CPU boards, and cascade cards. For software, Huawei committed to fully open-sourcing CANN compiler tools, Mind series application kits, and openPangu foundation models by 31 December 2025.&lt;/p&gt;&lt;h3&gt;Market deployment and ecosystem impact&lt;/h3&gt;&lt;p&gt;Real-world deployment provides validation for these technical claims. Over 300 Atlas 900 A3 SuperPoD units have already been shipped in 2025, which have been deployed for more than 20 customers from multiple sectors, including the Internet, finance, carrier, electricity, and manufacturing sectors.&lt;/p&gt;&lt;p&gt;The implications for the development of China’s AI infrastructure are substantial. By creating an open ecosystem around domestic technology, Huawei is addressing the challenges of building competitive AI infrastructure inside parameters set by constrained semiconductor manufacturing and availability. Its approach enables broader industry participation in developing AI infrastructure solutions without needing access to the most advanced process nodes.&lt;/p&gt;&lt;p&gt;For the global AI infrastructure market, Huawei’s open architecture strategy introduces an alternative to the tightly integrated, proprietary hardware and software approach dominant among Western competitors. Whether the ecosystem proposed by Huawei can achieve comparable performance and maintain commercial viability remains to be demonstrated at scale.&lt;/p&gt;&lt;p&gt;Ultimately, the SuperPoD architecture represents more than an incremental advance for AI computing. Huawei is proposing a fundamental of how massive computational resources are connected, managed, and scaled. The open-source release of its specifications and elements will test whether collaborative development can accelerate AI infrastructure innovation in an ecosystem of partners. That has the potential to reshape competitive dynamics in the global AI infrastructure market.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Huawei commits to training 30,000 Malaysian AI professionals as local tech ecosystem expands&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/huawei-ai-chips-superpod-technology/</guid><pubDate>Thu, 25 Sep 2025 09:23:08 +0000</pubDate></item><item><title>[NEW] Fusion power plants don’t exist yet, but they’re making money anyway (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/25/1124050/fusion-future-funding/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/6-25-CFS-Magnet-Factory-in-Devens-1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week, Commonwealth Fusion Systems announced it has another customer for its first commercial fusion power plant, in Virginia. Eni, one of the world’s largest oil and gas companies, signed a billion-dollar deal to buy electricity from the facility.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One small detail? That reactor doesn’t exist yet. Neither does the smaller reactor Commonwealth is building first to demonstrate that its tokamak design will work as intended.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is a weird moment in fusion. Investors are pouring billions into the field to build power plants, and some companies are even signing huge agreements to purchase power from those still-nonexistent plants. All this comes before companies have actually completed a working reactor that can produce electricity. It takes money to develop a new technology, but all this funding could lead to some twisted expectations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nearly three years ago, the National Ignition Facility at Lawrence Livermore National Laboratory hit a major milestone for fusion power. With the help of the world’s most powerful lasers, scientists heated a pellet of fuel to 100 million °C. Hydrogen atoms in that fuel fused together, releasing more energy than the lasers put in.&lt;/p&gt; 
 &lt;p&gt;It was a game changer for the vibes in fusion. The NIF experiment finally showed that a fusion reactor could yield net energy. Plasma physicists’ models had certainly suggested that it should be true, but it was another thing to see it demonstrated in real life.&lt;/p&gt;  &lt;p&gt;But in some ways, the NIF results didn’t really change much for commercial fusion. That site’s lasers used a bonkers amount of energy, the setup was wildly complicated, and the whole thing lasted a fraction of a second. To operate a fusion power plant, not only do you have to achieve net energy, but you also need to do that on a somewhat constant basis and—crucially—do it economically.&lt;/p&gt; 
 &lt;p&gt;So in the wake of the NIF news, all eyes went to companies like Commonwealth, Helion, and Zap Energy. Who would be the first to demonstrate this milestone in a more commercially feasible reactor? Or better yet, who would be the first to get a power plant up and running?&lt;/p&gt;  &lt;p&gt;So far, the answer is none of them.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To be fair, many fusion companies have made technical progress. Commonwealth has built and tested its high-temperature superconducting magnets and published research about that work. Zap Energy demonstrated three hours of continuous operation in its test system, a milestone validated by the US Department of Energy. Helion started construction of its power plant in Washington in July. (And that’s not to mention a thriving, publicly funded fusion industry in China.)&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;These are all important milestones, and these and other companies have seen many more. But as Ed Morse, a professor of nuclear engineering at Berkeley, summed it up to me: “They don’t have a reactor.” (He was speaking specifically about Commonwealth, but really, the same goes for the others.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;And yet, the money pours in. Commonwealth raised over $800 million in funding earlier this year. And now it’s got two big customers signed on to buy electricity from this future power plant.&lt;/p&gt;  &lt;p&gt;Why buy electricity from a reactor that’s currently little more than ideas on paper? From the perspective of these particular potential buyers, such agreements can be something of a win-win, says Adam Stein, director of nuclear energy innovation at the Breakthrough Institute.&lt;/p&gt;  &lt;p&gt;By putting a vote of confidence behind Commonwealth, Eni could help the fusion startup get the capital it needs to actually build its plant. The company also directly invests in Commonwealth, so it stands to benefit from success. Getting a good rate on the capital needed to build the plant could also mean the electricity is ultimately cheaper for Eni, Stein says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, fusion needs a lot of money. If fossil-fuel companies and tech giants want to provide it, all the better. One concern I have, though, is how outside observers are interpreting these big commitments.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;US Energy Secretary Chris Wright has been loud about his support for fusion and his expectations of the technology. Earlier this month, he told the BBC that it will soon power the world.&lt;/p&gt;  &lt;p&gt;He’s certainly not the first to have big dreams for fusion, and it is an exciting technology. But despite the jaw-dropping financial milestones, this industry is still very much in development.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And while Wright praises fusion, the Trump administration is slashing support for other energy technologies, including wind and solar power, and spreading disinformation about their safety, cost, and effectiveness.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To meet the growing electricity demand and cut emissions from the power sector, we’ll need a whole range of technologies. It’s a risk and a distraction to put all our hopes on an unproven energy tech when there are plenty of options that actually exist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/6-25-CFS-Magnet-Factory-in-Devens-1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week, Commonwealth Fusion Systems announced it has another customer for its first commercial fusion power plant, in Virginia. Eni, one of the world’s largest oil and gas companies, signed a billion-dollar deal to buy electricity from the facility.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One small detail? That reactor doesn’t exist yet. Neither does the smaller reactor Commonwealth is building first to demonstrate that its tokamak design will work as intended.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is a weird moment in fusion. Investors are pouring billions into the field to build power plants, and some companies are even signing huge agreements to purchase power from those still-nonexistent plants. All this comes before companies have actually completed a working reactor that can produce electricity. It takes money to develop a new technology, but all this funding could lead to some twisted expectations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nearly three years ago, the National Ignition Facility at Lawrence Livermore National Laboratory hit a major milestone for fusion power. With the help of the world’s most powerful lasers, scientists heated a pellet of fuel to 100 million °C. Hydrogen atoms in that fuel fused together, releasing more energy than the lasers put in.&lt;/p&gt; 
 &lt;p&gt;It was a game changer for the vibes in fusion. The NIF experiment finally showed that a fusion reactor could yield net energy. Plasma physicists’ models had certainly suggested that it should be true, but it was another thing to see it demonstrated in real life.&lt;/p&gt;  &lt;p&gt;But in some ways, the NIF results didn’t really change much for commercial fusion. That site’s lasers used a bonkers amount of energy, the setup was wildly complicated, and the whole thing lasted a fraction of a second. To operate a fusion power plant, not only do you have to achieve net energy, but you also need to do that on a somewhat constant basis and—crucially—do it economically.&lt;/p&gt; 
 &lt;p&gt;So in the wake of the NIF news, all eyes went to companies like Commonwealth, Helion, and Zap Energy. Who would be the first to demonstrate this milestone in a more commercially feasible reactor? Or better yet, who would be the first to get a power plant up and running?&lt;/p&gt;  &lt;p&gt;So far, the answer is none of them.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To be fair, many fusion companies have made technical progress. Commonwealth has built and tested its high-temperature superconducting magnets and published research about that work. Zap Energy demonstrated three hours of continuous operation in its test system, a milestone validated by the US Department of Energy. Helion started construction of its power plant in Washington in July. (And that’s not to mention a thriving, publicly funded fusion industry in China.)&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;These are all important milestones, and these and other companies have seen many more. But as Ed Morse, a professor of nuclear engineering at Berkeley, summed it up to me: “They don’t have a reactor.” (He was speaking specifically about Commonwealth, but really, the same goes for the others.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;And yet, the money pours in. Commonwealth raised over $800 million in funding earlier this year. And now it’s got two big customers signed on to buy electricity from this future power plant.&lt;/p&gt;  &lt;p&gt;Why buy electricity from a reactor that’s currently little more than ideas on paper? From the perspective of these particular potential buyers, such agreements can be something of a win-win, says Adam Stein, director of nuclear energy innovation at the Breakthrough Institute.&lt;/p&gt;  &lt;p&gt;By putting a vote of confidence behind Commonwealth, Eni could help the fusion startup get the capital it needs to actually build its plant. The company also directly invests in Commonwealth, so it stands to benefit from success. Getting a good rate on the capital needed to build the plant could also mean the electricity is ultimately cheaper for Eni, Stein says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, fusion needs a lot of money. If fossil-fuel companies and tech giants want to provide it, all the better. One concern I have, though, is how outside observers are interpreting these big commitments.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;US Energy Secretary Chris Wright has been loud about his support for fusion and his expectations of the technology. Earlier this month, he told the BBC that it will soon power the world.&lt;/p&gt;  &lt;p&gt;He’s certainly not the first to have big dreams for fusion, and it is an exciting technology. But despite the jaw-dropping financial milestones, this industry is still very much in development.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And while Wright praises fusion, the Trump administration is slashing support for other energy technologies, including wind and solar power, and spreading disinformation about their safety, cost, and effectiveness.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To meet the growing electricity demand and cut emissions from the power sector, we’ll need a whole range of technologies. It’s a risk and a distraction to put all our hopes on an unproven energy tech when there are plenty of options that actually exist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/25/1124050/fusion-future-funding/</guid><pubDate>Thu, 25 Sep 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] DeepMind’s robotic ballet: An AI for coordinating manufacturing robots (AI – Ars Technica)</title><link>https://arstechnica.com/science/2025/09/deepminds-robotic-ballet-an-ai-for-coordinating-manufacturing-robots/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        An AI figures out how robots can get jobs done without getting in each other's way.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Image of an assembly line where two robots are coordinating the production of an automobile frame." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2223136363-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Image of an assembly line where two robots are coordinating the production of an automobile frame." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2223136363-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          China News Service 

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A lot of the stuff we use today is largely made by robots—arms with multiple degrees of freedom positioned along conveyor belts that move in a spectacle of precisely synchronized motions. All this motion is usually programmed by hand, which can take hundreds to thousands of hours. Google’s DeepMind team has developed an AI system called RoboBallet that lets manufacturing robots figure out what to do on their own.&lt;/p&gt;
&lt;h2&gt;Traveling salesmen&lt;/h2&gt;
&lt;p&gt;Planning what manufacturing robots should do to get their jobs done efficiently is really hard to automate. You need to solve both task allocation and scheduling—deciding which task should be done by which robot in what order. It’s like the famous traveling salesman problem on steroids. On top of that, there is the question of motion planning; you need to make sure all these robotic arms won’t collide with each other or with all the gear standing around them.&lt;/p&gt;
&lt;p&gt;At the end, you’re facing myriad possible combinations where you’ve got to solve not one but three computationally hard problems at the same time. “There are some tools that let you automate motion planning, but task allocation and scheduling are usually done manually,” says Matthew Lai, a research engineer at Google DeepMind. “Solving all three of these problems combined is what we tackled in our work.”&lt;/p&gt;
&lt;p&gt;Lai’s team started by generating simulated samples of what are called work cells, areas where teams of robots perform their tasks on a product being manufactured. The work cells contained something called a workpiece, a product on which the robots do work, in this case something to be constructed of aluminum struts placed on a table. Around the table, there were up to eight randomly placed Franka Panda robotic arms, each with 7 degrees of freedom, that were supposed to complete up to 40 tasks on a workpiece. Every task required a robotic arm’s end effector to get within 2.5 centimeters of the right spot on the right strut, approached from the correct angle, then stay there, frozen, for a moment. The pause simulates doing some work.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To make things harder, the team peppered every work cell with random obstacles the robots had to avoid. “We chose to work with up to eight robots, as this is around the sensible maximum for packing robots closely together without them blocking each other all the time,” Lai explains. Forcing the robots to perform 40 tasks on a workpiece was also something the team considered representative of what’s required at real factories.&lt;/p&gt;
&lt;p&gt;A setup like this would be a nightmare to tackle using even the most powerful reinforcement-learning algorithms. Lai and his colleagues found a way around it by turning it all into graphs.&lt;/p&gt;
&lt;h2&gt;Complex relationships&lt;/h2&gt;
&lt;p&gt;Graphs in Lai’s model comprised nodes and edges. Things like robots, tasks, and obstacles were treated as nodes. Relationships between them were encoded as either one- or bi-directional edges. One-directional edges connected robots with tasks and obstacles because the robots needed information about where the obstacles were and whether the tasks were completed or not. Bidirectional edges connected the robots to each other, because each robot had to know what other robots were doing at each time step to avoid collisions or duplicating tasks.&lt;/p&gt;
&lt;p&gt;To read and make sense of the graphs, the team used graph neural networks, a type of artificial intelligence designed to extract relationships between the nodes by passing messages along the edges of the connections among them. This decluttered the data, allowing the researchers to design a system that focused exclusively on what mattered most: finding the most efficient ways to complete tasks while navigating obstacles. After a few days of training on randomly generated work cells using a single Nvidia A100 GPU, the new industrial planning AI, called RoboBallet, could lay out seemingly viable trajectories through complex, previously unseen environments in a matter of seconds.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Most importantly, though, it scaled really well.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Economy of scale&lt;/h2&gt;
&lt;p&gt;The problem with applying traditional computational methods to complex problems like managing robots at a factory is that the challenge of computation grows exponentially with the number of items you have in your system. Computing the most optimal trajectories for one robot is relatively simple. Doing the same for two is considerably harder; when the number grows to eight, the problem becomes practically intractable.&lt;/p&gt;
&lt;p&gt;With RoboBallet, the complexity of computation also grew with the complexity of the system, but at a far slower rate. (The computations grew linearly with the growing number of tasks and obstacles, and quadratically with the number of robots.) According to the team, these computations should make the system feasible for industrial-scale use.&lt;/p&gt;
&lt;p&gt;The team wanted to test, however, whether the plans their AI was producing were any good. To check that, Lai and his colleagues computed the most optimal task allocations, schedules, and motions in a few simplified work cells and compared those with results delivered by RoboBallet. In terms of execution time, arguably the most important metric in manufacturing, the AI came very close to what human engineers could do. It wasn’t better than they were—it just provided an answer more quickly.&lt;/p&gt;
&lt;p&gt;The team also tested RoboBallet plans on a real-world physical setup of four Panda robots working on an aluminum workpiece, and they worked just as well as in simulations. But Lai says it can do more than just speed up the process of programming robots.&lt;/p&gt;
&lt;h2&gt;Limping along&lt;/h2&gt;
&lt;p&gt;RoboBallet, according to DeepMind’s team, also enables us to design better work cells. “Because it works so fast, it would be possible for a designer to try different layouts and different placement or selections of robots in almost real time,” Lai says. This way, engineers at factories would be able to see exactly how much time they would save by adding another robot to a cell or choosing a robot of a different type. Another thing RoboBallet can do is reprogram the work cell on the fly, allowing other robots to fill in when one of them breaks down.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, there are a few things that still need ironing out before RoboBallet can come to factories. “There are several simplifications we made,” Lai admits. The first was that the obstacles were decomposed into cuboids. Even the workpiece itself was cubical. While this was somewhat representative of the obstacles and equipment in real factories, there are lots of possible workpieces with more organic shapes. “It would be better to represent those in a more flexible way, like mesh graphs or point clouds,” Lai says. This, however, would likely mean a drop in RoboBallet’s blistering speed.&lt;/p&gt;
&lt;p&gt;Another thing is that the robots in Lai’s experiments were identical, while in a real-world work cell, robotic teams are quite often heterogeneous. “That’s why real-world applications would require additional research and engineering specific to the type of application,” Lai says. He adds, though, that the current RoboBallet is already designed with such adaptations in mind—it can be easily extended to support them. And once that’s done, his hope is that it will make factories faster and way more flexible.&lt;/p&gt;
&lt;p&gt;“The system would have to be given work cell models, the workpiece models, as well as the list of tasks that need to be done—based on that, RoboBallet would be able to generate a complete plan,” Lai says.&lt;/p&gt;
&lt;p&gt;Science Robotics, 2025. DOI: 10.1126/scirobotics.ads1204&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        An AI figures out how robots can get jobs done without getting in each other's way.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Image of an assembly line where two robots are coordinating the production of an automobile frame." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2223136363-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Image of an assembly line where two robots are coordinating the production of an automobile frame." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2223136363-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          China News Service 

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A lot of the stuff we use today is largely made by robots—arms with multiple degrees of freedom positioned along conveyor belts that move in a spectacle of precisely synchronized motions. All this motion is usually programmed by hand, which can take hundreds to thousands of hours. Google’s DeepMind team has developed an AI system called RoboBallet that lets manufacturing robots figure out what to do on their own.&lt;/p&gt;
&lt;h2&gt;Traveling salesmen&lt;/h2&gt;
&lt;p&gt;Planning what manufacturing robots should do to get their jobs done efficiently is really hard to automate. You need to solve both task allocation and scheduling—deciding which task should be done by which robot in what order. It’s like the famous traveling salesman problem on steroids. On top of that, there is the question of motion planning; you need to make sure all these robotic arms won’t collide with each other or with all the gear standing around them.&lt;/p&gt;
&lt;p&gt;At the end, you’re facing myriad possible combinations where you’ve got to solve not one but three computationally hard problems at the same time. “There are some tools that let you automate motion planning, but task allocation and scheduling are usually done manually,” says Matthew Lai, a research engineer at Google DeepMind. “Solving all three of these problems combined is what we tackled in our work.”&lt;/p&gt;
&lt;p&gt;Lai’s team started by generating simulated samples of what are called work cells, areas where teams of robots perform their tasks on a product being manufactured. The work cells contained something called a workpiece, a product on which the robots do work, in this case something to be constructed of aluminum struts placed on a table. Around the table, there were up to eight randomly placed Franka Panda robotic arms, each with 7 degrees of freedom, that were supposed to complete up to 40 tasks on a workpiece. Every task required a robotic arm’s end effector to get within 2.5 centimeters of the right spot on the right strut, approached from the correct angle, then stay there, frozen, for a moment. The pause simulates doing some work.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To make things harder, the team peppered every work cell with random obstacles the robots had to avoid. “We chose to work with up to eight robots, as this is around the sensible maximum for packing robots closely together without them blocking each other all the time,” Lai explains. Forcing the robots to perform 40 tasks on a workpiece was also something the team considered representative of what’s required at real factories.&lt;/p&gt;
&lt;p&gt;A setup like this would be a nightmare to tackle using even the most powerful reinforcement-learning algorithms. Lai and his colleagues found a way around it by turning it all into graphs.&lt;/p&gt;
&lt;h2&gt;Complex relationships&lt;/h2&gt;
&lt;p&gt;Graphs in Lai’s model comprised nodes and edges. Things like robots, tasks, and obstacles were treated as nodes. Relationships between them were encoded as either one- or bi-directional edges. One-directional edges connected robots with tasks and obstacles because the robots needed information about where the obstacles were and whether the tasks were completed or not. Bidirectional edges connected the robots to each other, because each robot had to know what other robots were doing at each time step to avoid collisions or duplicating tasks.&lt;/p&gt;
&lt;p&gt;To read and make sense of the graphs, the team used graph neural networks, a type of artificial intelligence designed to extract relationships between the nodes by passing messages along the edges of the connections among them. This decluttered the data, allowing the researchers to design a system that focused exclusively on what mattered most: finding the most efficient ways to complete tasks while navigating obstacles. After a few days of training on randomly generated work cells using a single Nvidia A100 GPU, the new industrial planning AI, called RoboBallet, could lay out seemingly viable trajectories through complex, previously unseen environments in a matter of seconds.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Most importantly, though, it scaled really well.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Economy of scale&lt;/h2&gt;
&lt;p&gt;The problem with applying traditional computational methods to complex problems like managing robots at a factory is that the challenge of computation grows exponentially with the number of items you have in your system. Computing the most optimal trajectories for one robot is relatively simple. Doing the same for two is considerably harder; when the number grows to eight, the problem becomes practically intractable.&lt;/p&gt;
&lt;p&gt;With RoboBallet, the complexity of computation also grew with the complexity of the system, but at a far slower rate. (The computations grew linearly with the growing number of tasks and obstacles, and quadratically with the number of robots.) According to the team, these computations should make the system feasible for industrial-scale use.&lt;/p&gt;
&lt;p&gt;The team wanted to test, however, whether the plans their AI was producing were any good. To check that, Lai and his colleagues computed the most optimal task allocations, schedules, and motions in a few simplified work cells and compared those with results delivered by RoboBallet. In terms of execution time, arguably the most important metric in manufacturing, the AI came very close to what human engineers could do. It wasn’t better than they were—it just provided an answer more quickly.&lt;/p&gt;
&lt;p&gt;The team also tested RoboBallet plans on a real-world physical setup of four Panda robots working on an aluminum workpiece, and they worked just as well as in simulations. But Lai says it can do more than just speed up the process of programming robots.&lt;/p&gt;
&lt;h2&gt;Limping along&lt;/h2&gt;
&lt;p&gt;RoboBallet, according to DeepMind’s team, also enables us to design better work cells. “Because it works so fast, it would be possible for a designer to try different layouts and different placement or selections of robots in almost real time,” Lai says. This way, engineers at factories would be able to see exactly how much time they would save by adding another robot to a cell or choosing a robot of a different type. Another thing RoboBallet can do is reprogram the work cell on the fly, allowing other robots to fill in when one of them breaks down.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, there are a few things that still need ironing out before RoboBallet can come to factories. “There are several simplifications we made,” Lai admits. The first was that the obstacles were decomposed into cuboids. Even the workpiece itself was cubical. While this was somewhat representative of the obstacles and equipment in real factories, there are lots of possible workpieces with more organic shapes. “It would be better to represent those in a more flexible way, like mesh graphs or point clouds,” Lai says. This, however, would likely mean a drop in RoboBallet’s blistering speed.&lt;/p&gt;
&lt;p&gt;Another thing is that the robots in Lai’s experiments were identical, while in a real-world work cell, robotic teams are quite often heterogeneous. “That’s why real-world applications would require additional research and engineering specific to the type of application,” Lai says. He adds, though, that the current RoboBallet is already designed with such adaptations in mind—it can be easily extended to support them. And once that’s done, his hope is that it will make factories faster and way more flexible.&lt;/p&gt;
&lt;p&gt;“The system would have to be given work cell models, the workpiece models, as well as the list of tasks that need to be done—based on that, RoboBallet would be able to generate a complete plan,” Lai says.&lt;/p&gt;
&lt;p&gt;Science Robotics, 2025. DOI: 10.1126/scirobotics.ads1204&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/science/2025/09/deepminds-robotic-ballet-an-ai-for-coordinating-manufacturing-robots/</guid><pubDate>Thu, 25 Sep 2025 11:15:40 +0000</pubDate></item><item><title>[NEW] Spotify to label AI music, filter spam and more in AI policy change (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/25/spotify-updates-ai-policy-to-label-tracks-cut-down-on-spam/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify on Thursday announced a series of updates to its AI policy, designed to better indicate when AI is being used to make music, to cut down on spam, and to make it clearer that unauthorized voice clones are not permitted on its service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will adopt an upcoming industry standard for identifying and labeling AI music in credits, known as DDEX, and will soon roll out a new music spam filter to catch more bad actors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the DDEX system, labels, distributors, and music partners submit standardized AI disclosures in music credits. This solution offers detailed information about the use of AI — like whether it was used for AI-generated vocals, instrumentation, or post-production, for example.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049945" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-4.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We know the use of AI is going to be a spectrum, with artists and producers incorporating AI in various parts of their creative workflow,” said Sam Duboff, Spotify’s Global Head of Marketing and Policy, in a press briefing on Wednesday. “This industry standard will allow for more accurate, nuanced disclosures. It won’t force tracks into a false binary where a song either has to be categorically AI or not AI at all,” he noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the same announcement, Spotify clarified its polices around AI-enabled personalization, stating directly thatunauthorized AI voice clones, deepfakes, and any other form of vocal replicas or impersonation are not allowed and will be removed from the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the DDEX standard is developing, Spotify says it’s received commitments from 15 labels and distributors who plan to adopt the technology, and sees its move as one that could signal to others it’s time to adopt the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because AI tools make it easier for anyone to release music, Spotify also has a new plan to cut down on the potential spam that results. This fall, the company will roll out a new music spam filter that will attempt to address spam tactics, tag them, and then stop recommending those tracks to users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049946" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-2.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We know AI has made it easier than ever for bad actors to mass upload content, create duplicates, use SEO tricks to manipulate search or recommendation systems…we’ve been fighting these kinds of tactics for years,” Duboff said. “But AI is accelerating these issues with more sophistication, and we know that requires new types of mitigations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it would roll out the filter gradually to make sure it’s targeting the right signals, then add more signals over time as the market evolves. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049944" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-3.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Related to this, Spotify will also work with distributors to address something called “profile mismatches,” a scheme where someone fraudulently uploads music to another artist’s profile across streaming services. The company said it hopes to prevent more of these before the music ever goes live. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the changes, Spotify executives emphasized that they still support use of AI provided it’s used in a non-fraudulent way. “We’re not here to punish artists for using AI authentically and responsibly. We hope that artists’ use of AI production tools will enable them to be more creative than ever,” noted Spotify VP and Global Head of Music, Charlie Hellman. “But we are here to stop the bad actors who are gaming the system, and we can only benefit from all that good side of AI if we aggressively protect against the downside,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify’s updates follow a rapid increase in AI-generated music across the industry. This summer, an AI-generated band called Velvet Sundown went viral on its service, leading users to complain that the company isn’t transparent about labeling its AI tracks. Meanwhile, streaming rival Deezer recently shared that about 18% of the music uploaded each day to its service — or more than 20,000 tracks — is now fully AI-generated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify wouldn’t share its own metrics on the matter directly — but Duboff told reporters that “the reality is, all streaming services have almost exactly the same catalog.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People tend to deliver the music to all services,” he explained, adding that uploading tracks doesn’t mean anyone’s listening or that the AI music makes money. “We know AI usage is increasingly not a binary, but kind of a spectrum of how artists and producers are using it.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify on Thursday announced a series of updates to its AI policy, designed to better indicate when AI is being used to make music, to cut down on spam, and to make it clearer that unauthorized voice clones are not permitted on its service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will adopt an upcoming industry standard for identifying and labeling AI music in credits, known as DDEX, and will soon roll out a new music spam filter to catch more bad actors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the DDEX system, labels, distributors, and music partners submit standardized AI disclosures in music credits. This solution offers detailed information about the use of AI — like whether it was used for AI-generated vocals, instrumentation, or post-production, for example.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049945" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-4.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We know the use of AI is going to be a spectrum, with artists and producers incorporating AI in various parts of their creative workflow,” said Sam Duboff, Spotify’s Global Head of Marketing and Policy, in a press briefing on Wednesday. “This industry standard will allow for more accurate, nuanced disclosures. It won’t force tracks into a false binary where a song either has to be categorically AI or not AI at all,” he noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the same announcement, Spotify clarified its polices around AI-enabled personalization, stating directly thatunauthorized AI voice clones, deepfakes, and any other form of vocal replicas or impersonation are not allowed and will be removed from the platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the DDEX standard is developing, Spotify says it’s received commitments from 15 labels and distributors who plan to adopt the technology, and sees its move as one that could signal to others it’s time to adopt the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because AI tools make it easier for anyone to release music, Spotify also has a new plan to cut down on the potential spam that results. This fall, the company will roll out a new music spam filter that will attempt to address spam tactics, tag them, and then stop recommending those tracks to users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049946" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-2.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We know AI has made it easier than ever for bad actors to mass upload content, create duplicates, use SEO tricks to manipulate search or recommendation systems…we’ve been fighting these kinds of tactics for years,” Duboff said. “But AI is accelerating these issues with more sophistication, and we know that requires new types of mitigations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it would roll out the filter gradually to make sure it’s targeting the right signals, then add more signals over time as the market evolves. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3049944" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/AI-3.png?w=544" width="544" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Related to this, Spotify will also work with distributors to address something called “profile mismatches,” a scheme where someone fraudulently uploads music to another artist’s profile across streaming services. The company said it hopes to prevent more of these before the music ever goes live. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the changes, Spotify executives emphasized that they still support use of AI provided it’s used in a non-fraudulent way. “We’re not here to punish artists for using AI authentically and responsibly. We hope that artists’ use of AI production tools will enable them to be more creative than ever,” noted Spotify VP and Global Head of Music, Charlie Hellman. “But we are here to stop the bad actors who are gaming the system, and we can only benefit from all that good side of AI if we aggressively protect against the downside,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify’s updates follow a rapid increase in AI-generated music across the industry. This summer, an AI-generated band called Velvet Sundown went viral on its service, leading users to complain that the company isn’t transparent about labeling its AI tracks. Meanwhile, streaming rival Deezer recently shared that about 18% of the music uploaded each day to its service — or more than 20,000 tracks — is now fully AI-generated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify wouldn’t share its own metrics on the matter directly — but Duboff told reporters that “the reality is, all streaming services have almost exactly the same catalog.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People tend to deliver the music to all services,” he explained, adding that uploading tracks doesn’t mean anyone’s listening or that the AI music makes money. “We know AI usage is increasingly not a binary, but kind of a spectrum of how artists and producers are using it.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/25/spotify-updates-ai-policy-to-label-tracks-cut-down-on-spam/</guid><pubDate>Thu, 25 Sep 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] The Download: growing threats to vulnerable languages, and fact-checking Trump’s medical claims (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/25/1124079/the-download-threats-vulnerable-languages-and-trump-medical-claims/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;How AI and Wikipedia have sent vulnerable languages into a doom spiral&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed. But many of these smaller editions are being swamped with AI-translated content. Volunteers working on four African languages, for instance, estimated to &lt;em&gt;MIT Technology Review &lt;/em&gt;that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations.&lt;/p&gt;  &lt;p&gt;This is beginning to cause a wicked problem. AI systems learn new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages can poison the wells that AI is expected to draw from. Volunteers are being forced to go to extreme lengths to fix the issue, even deleting certain languages from Wikipedia entirely. Read the full story.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;—&lt;em&gt;Jacob Judah&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;&lt;em&gt;This story is part of our Big Story series: MIT Technology Review’s most important, ambitious reporting. These stories take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;Check out the rest of the series here&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Trump is pushing leucovorin as a new treatment for autism. What is it?&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;On Monday, President Trump claimed that childhood vaccines and acetaminophen, the active ingredient in Tylenol, are to blame for the increasing prevalence of autism. He advised pregnant women against taking the medicine.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The administration also announced that the FDA would work to make a medication called leucovorin available as a treatment for children with autism. The president’s assertions left many dismayed. “The data cited do not support the claim that Tylenol causes autism and leucovorin is a cure, and only stoke fear and falsely suggest hope when there is no simple answer,” said the Coalition for Autism Researchers, a group of more than 250 scientists, in a statement. So what &lt;em&gt;does &lt;/em&gt;the evidence say? Read our story to find out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;—&lt;em&gt;Cassandra Willyard&amp;nbsp;&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;This is part of our MIT Technology Review Explains series, where our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read &lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;more from the series here&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;    &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;Fusion power plants don’t exist yet, but they’re making money anyway&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;This week, Commonwealth Fusion Systems announced it has another customer for its first commercial fusion power plant, in Virginia. Eni, one of the world’s largest oil and gas companies, signed a billion-dollar deal to buy electricity from the facility.&lt;/p&gt;  &lt;p&gt;One small detail? That reactor doesn’t exist yet. This is a weird moment in fusion. Investors are pouring billions into the field to build power plants, and companies are even signing huge agreements to purchase power from those still-nonexistent plants.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But all this comes before companies have actually completed a working reactor that can produce electricity. It takes money to develop a new technology, but all this funding could lead to some twisted expectations. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from The Spark, our weekly newsletter all about the latest in climate change and clean tech. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to receive it in your inbox every Wednesday.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The AI Hype Index: Cracking the chatbot code&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Millions of us use chatbots every day, even though we don’t really know how they work or how using them affects us. In a bid to address this, the FTC recently launched an inquiry into how chatbots affect children and teenagers. Elsewhere, OpenAI has started to shed more light on what people are actually using ChatGPT for, and why it thinks its LLMs are so prone to making stuff up.&lt;/p&gt;  &lt;p&gt;There’s still plenty we don’t know—but that isn’t stopping governments from forging ahead with AI projects. In the US, RFK Jr. is pushing his staffers to use ChatGPT, while Albania is using a chatbot for public contract procurement. Check out the latest edition of our AI Hype Index to help you sort AI reality from hyped-up fiction.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Huntington’s disease has been treated successfully for the first time&lt;/strong&gt;&lt;br /&gt;Gene therapy managed to slow progress of the disease in patients by 75%. (The Economist $)&amp;nbsp;&lt;br /&gt;+ &lt;em&gt;Here’s how the gene editing tool CRISPR is changing lives&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Google says 90% of tech workers are using AI&lt;/strong&gt;&lt;br /&gt;But most of them also say they don’t trust AI models’ outputs. (CNN)&lt;br /&gt;+ &lt;em&gt;Why does AI hallucinate?&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A MAGA TikTok takeover is coming&lt;/strong&gt;&lt;br /&gt;Just as free speech protections in the US start to look worryingly fragile. (The Atlantic $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Chinese tech workers are returning from the US&lt;/strong&gt;&lt;br /&gt;There’s a whole bunch of complex factors both driving them to leave, and luring them back. (Rest of World)&lt;br /&gt;+&lt;em&gt; But it’s hard to say what the impact of the new $100,000 fee for H-1B visas will be on India’s tech sector.&lt;/em&gt; (WP $)&lt;br /&gt;+&lt;em&gt; Europe is hoping to nab more tech talent too.&lt;/em&gt; (The Verge)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 If AI can diagnose us, what are doctors for?&lt;/strong&gt;&lt;br /&gt;They need to prepare for the fact chatbot use is becoming more and more widespread among patients. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;This medical startup uses LLMs to run appointments and make diagnoses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Drones have been spotted at four more airports in Denmark&lt;/strong&gt;&lt;br /&gt;It looks like a coordinated attack, but officials still haven’t worked out who is behind it. (FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 TSMC has unveiled AI-designed chips that use less energy&lt;/strong&gt;&lt;br /&gt;The AI software found better solutions than TSMC’s own human engineers&lt;em&gt;—&lt;/em&gt;and did so much faster. (South China Morning Post)&lt;br /&gt;+ &lt;em&gt;These four charts sum up the state of AI and energy.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 How to find love on dating apps&amp;nbsp;💑&lt;/strong&gt;&lt;br /&gt;It’s not easy, but it &lt;em&gt;is &lt;/em&gt;possible. (The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 AI models can’t cope with Persian social etiquette&lt;/strong&gt;&lt;br /&gt;It involves a lot of saying ‘no’ when you mean ‘yes’, which simply doesn’t wash with computers. (Ars Technica)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 VR headsets are better than ever, but no one seems to care&lt;/strong&gt;&lt;br /&gt;The tech industry keeps overestimating how willing people are to strap computers to their faces. (Gizmodo)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We are living through the most destructive arms race in human history.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ukrainian president Volodymyr Zelenskyy tells world leaders gathered at the UN that they need to intervene to stop the escalating development of drone technology and AI, The Guardian reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1081538" src="https://wp.technologyreview.com/wp-content/uploads/2023/10/2AIntellFinal2f_thumb.jpg" /&gt;&lt;div class="image-credit"&gt;STUART BRADFORD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;The great AI consciousness conundrum&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;AI consciousness isn’t just a tricky intellectual puzzle; it’s a morally weighty problem. Fail to identify a conscious AI, and you might unintentionally subjugate a being whose interests ought to matter. Mistake an unconscious AI for a conscious one, and you risk compromising human safety and happiness for the sake of an unthinking, unfeeling hunk of silicon and code.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Over the past few decades, a small research community has doggedly attacked the question of what consciousness is and how it works. The effort has yielded real progress. And now, with the rapid advance of AI technology, these insights could offer our only guide to the untested, morally fraught waters of artificial consciousness. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ It’s Fat Bear Week! Who gets your vote this year?&lt;br /&gt;+ Learn about Lord Woodbine, the forgotten sixth Beatle.&amp;nbsp;&lt;br /&gt;+ There are some truly wild and wacky recipes in this Medieval Cookery collection. Venison porridge, anyone?&amp;nbsp;&lt;br /&gt;+ Pessimism about technology is as old as technology itself, as this archive shows.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;How AI and Wikipedia have sent vulnerable languages into a doom spiral&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed. But many of these smaller editions are being swamped with AI-translated content. Volunteers working on four African languages, for instance, estimated to &lt;em&gt;MIT Technology Review &lt;/em&gt;that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations.&lt;/p&gt;  &lt;p&gt;This is beginning to cause a wicked problem. AI systems learn new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages can poison the wells that AI is expected to draw from. Volunteers are being forced to go to extreme lengths to fix the issue, even deleting certain languages from Wikipedia entirely. Read the full story.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;—&lt;em&gt;Jacob Judah&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;&lt;em&gt;This story is part of our Big Story series: MIT Technology Review’s most important, ambitious reporting. These stories take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;Check out the rest of the series here&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Trump is pushing leucovorin as a new treatment for autism. What is it?&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;On Monday, President Trump claimed that childhood vaccines and acetaminophen, the active ingredient in Tylenol, are to blame for the increasing prevalence of autism. He advised pregnant women against taking the medicine.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The administration also announced that the FDA would work to make a medication called leucovorin available as a treatment for children with autism. The president’s assertions left many dismayed. “The data cited do not support the claim that Tylenol causes autism and leucovorin is a cure, and only stoke fear and falsely suggest hope when there is no simple answer,” said the Coalition for Autism Researchers, a group of more than 250 scientists, in a statement. So what &lt;em&gt;does &lt;/em&gt;the evidence say? Read our story to find out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;—&lt;em&gt;Cassandra Willyard&amp;nbsp;&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;This is part of our MIT Technology Review Explains series, where our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read &lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;more from the series here&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;    &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;Fusion power plants don’t exist yet, but they’re making money anyway&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;This week, Commonwealth Fusion Systems announced it has another customer for its first commercial fusion power plant, in Virginia. Eni, one of the world’s largest oil and gas companies, signed a billion-dollar deal to buy electricity from the facility.&lt;/p&gt;  &lt;p&gt;One small detail? That reactor doesn’t exist yet. This is a weird moment in fusion. Investors are pouring billions into the field to build power plants, and companies are even signing huge agreements to purchase power from those still-nonexistent plants.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But all this comes before companies have actually completed a working reactor that can produce electricity. It takes money to develop a new technology, but all this funding could lead to some twisted expectations. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from The Spark, our weekly newsletter all about the latest in climate change and clean tech. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to receive it in your inbox every Wednesday.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The AI Hype Index: Cracking the chatbot code&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Millions of us use chatbots every day, even though we don’t really know how they work or how using them affects us. In a bid to address this, the FTC recently launched an inquiry into how chatbots affect children and teenagers. Elsewhere, OpenAI has started to shed more light on what people are actually using ChatGPT for, and why it thinks its LLMs are so prone to making stuff up.&lt;/p&gt;  &lt;p&gt;There’s still plenty we don’t know—but that isn’t stopping governments from forging ahead with AI projects. In the US, RFK Jr. is pushing his staffers to use ChatGPT, while Albania is using a chatbot for public contract procurement. Check out the latest edition of our AI Hype Index to help you sort AI reality from hyped-up fiction.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Huntington’s disease has been treated successfully for the first time&lt;/strong&gt;&lt;br /&gt;Gene therapy managed to slow progress of the disease in patients by 75%. (The Economist $)&amp;nbsp;&lt;br /&gt;+ &lt;em&gt;Here’s how the gene editing tool CRISPR is changing lives&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Google says 90% of tech workers are using AI&lt;/strong&gt;&lt;br /&gt;But most of them also say they don’t trust AI models’ outputs. (CNN)&lt;br /&gt;+ &lt;em&gt;Why does AI hallucinate?&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A MAGA TikTok takeover is coming&lt;/strong&gt;&lt;br /&gt;Just as free speech protections in the US start to look worryingly fragile. (The Atlantic $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Chinese tech workers are returning from the US&lt;/strong&gt;&lt;br /&gt;There’s a whole bunch of complex factors both driving them to leave, and luring them back. (Rest of World)&lt;br /&gt;+&lt;em&gt; But it’s hard to say what the impact of the new $100,000 fee for H-1B visas will be on India’s tech sector.&lt;/em&gt; (WP $)&lt;br /&gt;+&lt;em&gt; Europe is hoping to nab more tech talent too.&lt;/em&gt; (The Verge)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 If AI can diagnose us, what are doctors for?&lt;/strong&gt;&lt;br /&gt;They need to prepare for the fact chatbot use is becoming more and more widespread among patients. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;This medical startup uses LLMs to run appointments and make diagnoses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Drones have been spotted at four more airports in Denmark&lt;/strong&gt;&lt;br /&gt;It looks like a coordinated attack, but officials still haven’t worked out who is behind it. (FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 TSMC has unveiled AI-designed chips that use less energy&lt;/strong&gt;&lt;br /&gt;The AI software found better solutions than TSMC’s own human engineers&lt;em&gt;—&lt;/em&gt;and did so much faster. (South China Morning Post)&lt;br /&gt;+ &lt;em&gt;These four charts sum up the state of AI and energy.&lt;/em&gt; (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 How to find love on dating apps&amp;nbsp;💑&lt;/strong&gt;&lt;br /&gt;It’s not easy, but it &lt;em&gt;is &lt;/em&gt;possible. (The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 AI models can’t cope with Persian social etiquette&lt;/strong&gt;&lt;br /&gt;It involves a lot of saying ‘no’ when you mean ‘yes’, which simply doesn’t wash with computers. (Ars Technica)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 VR headsets are better than ever, but no one seems to care&lt;/strong&gt;&lt;br /&gt;The tech industry keeps overestimating how willing people are to strap computers to their faces. (Gizmodo)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We are living through the most destructive arms race in human history.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ukrainian president Volodymyr Zelenskyy tells world leaders gathered at the UN that they need to intervene to stop the escalating development of drone technology and AI, The Guardian reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1081538" src="https://wp.technologyreview.com/wp-content/uploads/2023/10/2AIntellFinal2f_thumb.jpg" /&gt;&lt;div class="image-credit"&gt;STUART BRADFORD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;The great AI consciousness conundrum&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;AI consciousness isn’t just a tricky intellectual puzzle; it’s a morally weighty problem. Fail to identify a conscious AI, and you might unintentionally subjugate a being whose interests ought to matter. Mistake an unconscious AI for a conscious one, and you risk compromising human safety and happiness for the sake of an unthinking, unfeeling hunk of silicon and code.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Over the past few decades, a small research community has doggedly attacked the question of what consciousness is and how it works. The effort has yielded real progress. And now, with the rapid advance of AI technology, these insights could offer our only guide to the untested, morally fraught waters of artificial consciousness. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ It’s Fat Bear Week! Who gets your vote this year?&lt;br /&gt;+ Learn about Lord Woodbine, the forgotten sixth Beatle.&amp;nbsp;&lt;br /&gt;+ There are some truly wild and wacky recipes in this Medieval Cookery collection. Venison porridge, anyone?&amp;nbsp;&lt;br /&gt;+ Pessimism about technology is as old as technology itself, as this archive shows.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/25/1124079/the-download-threats-vulnerable-languages-and-trump-medical-claims/</guid><pubDate>Thu, 25 Sep 2025 12:10:00 +0000</pubDate></item></channel></rss>