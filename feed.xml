<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 28 Nov 2025 18:31:09 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>What we still don’t know about weight-loss drugs (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/28/1128511/what-we-still-dont-know-about-weight-loss-drugs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/glp1-pregnancy.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;MIT Technology Review&lt;/em&gt;&amp;nbsp;Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read&amp;nbsp;more from the series here&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Weight-loss drugs have been back in the news this week. First, we heard that Eli Lilly, the company behind the drugs Mounjaro and Zepbound, became the first healthcare company in the world to achieve a &lt;em&gt;trillion-dollar&lt;/em&gt; valuation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Those two drugs, which are prescribed for diabetes and obesity respectively, are&amp;nbsp;generating billions of dollars in revenue for the company. Other GLP-1 agonist drugs—a class that includes Mounjaro and Zepbound, which have the same active ingredient—have also been approved to&amp;nbsp;reduce the risk of heart attack and stroke in overweight people. Many hope these apparent wonder drugs will also treat neurological disorders and potentially substance use disorders, too.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But this week we also learned that, disappointingly,&amp;nbsp;GLP-1 drugs don’t seem to help people with Alzheimer’s disease. And that people who stop taking the drugs when they become pregnant can experience potentially dangerous levels of weight gain during their pregnancies. On top of that, some researchers worry that people are using the drugs postpartum to lose pregnancy weight without understanding potential risks.&lt;/p&gt; 
 &lt;p&gt;All of this news should serve as a reminder that there’s a lot we still don’t know about these drugs. This week, let’s look at the enduring questions surrounding GLP-1 agonist drugs.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;First a quick recap.&lt;/strong&gt; Glucagon-like peptide-1 is a hormone made in the gut that helps regulate blood sugar levels. But we’ve learned that it also appears to have effects across the body. Receptors that GLP-1 can bind to have been found in multiple organs and throughout the brain, says Daniel Drucker, an endocrinologist at the University of Toronto who has been studying the hormone for decades.&lt;/p&gt; 
 &lt;p&gt;GLP-1 agonist drugs essentially mimic the hormone’s action. Quite a few have been developed, including semaglutide, tirzepatide, liraglutide, and exenatide, which have brand names like Ozempic, Saxenda and Wegovy. Some of them are recommended for some people with diabetes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;But because these drugs also seem to suppress appetite, they have become hugely popular weight loss aids. And studies have found that many people who take them for diabetes or weight loss experience surprising side effects; that&amp;nbsp;their mental health improves, for example, or that&amp;nbsp;they feel less inclined to smoke or consume alcohol. Research has also found that the drugs seem to increase the growth of brain cells in lab animals.&lt;/p&gt;  &lt;p&gt;So far, so promising. But there are a few outstanding gray areas.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Are they good for our brains?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Novo Nordisk, a competitor of Eli Lilly, manufactures GLP-1 drugs Wegovy and Saxenda. The company recently trialed an oral semaglutide in people with Alzheimer’s disease who had mild cognitive impairment or mild dementia. The placebo-controlled trial included 3808 volunteers.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Unfortunately, the company found that the drug did not appear to delay the progression of Alzheimer’s disease in the volunteers who took it.&lt;/p&gt;  &lt;p&gt;The news came as a huge disappointment to the research community. “It was kind of crushing,” says Drucker. That’s despite the fact that, deep down, he wasn’t expecting a “clear win.” Alzheimer’s disease has proven notoriously difficult to treat, and by the time people get a diagnosis, a lot of damage has already taken place.&lt;/p&gt;  &lt;p&gt;But he is one of many that isn’t giving up hope entirely. After all, research suggests that GLP-1 reduces inflammation in the brain and improves the health of neurons, and that it appears to improve the way brain regions communicate with each other. This all implies that GLP-1 drugs should benefit the brain, says Drucker. There’s still a chance that the drugs might help stave off Alzheimer’s in those who are still cognitively healthy.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Are they safe before, during or after pregnancy?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Other research published this week raises questions about the effects of GLP-1s taken around the time of pregnancy. At the moment, people are advised to plan to stop taking the medicines two months before they become pregnant. That’s partly because some animal studies suggest the drugs can harm the development of a fetus, but mainly because scientists haven’t studied the impact on pregnancy in humans.&lt;/p&gt;  &lt;p&gt;Among the broader population, research suggests that many people who take GLP-1s for weight loss&amp;nbsp;regain much of their lost weight once they stop taking those drugs. So perhaps it’s not surprising that&amp;nbsp;a study published in &lt;em&gt;JAMA&lt;/em&gt; earlier this week saw a similar effect in pregnant people.&lt;/p&gt;  &lt;p&gt;The study found that people who had been taking those drugs gained around 3.3kg more than others who had not. And those who had been taking the drugs also appeared to have a slightly higher risk of gestational diabetes, blood pressure disorders and even preterm birth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;It sounds pretty worrying. But&amp;nbsp;a different study published in August had the &lt;em&gt;opposite &lt;/em&gt;finding—it noted a reduction in the risk of those outcomes among women who had taken the drugs before becoming pregnant.&lt;/p&gt;  &lt;p&gt;If you’re wondering how to make sense of all this, you’re not the only one. No one really knows how these drugs should be used before pregnancy—or during it for that matter.&lt;/p&gt;  &lt;p&gt;Another&amp;nbsp;study out this week found that people (in Denmark) are increasingly taking GLP-1s postpartum to lose weight gained during pregnancy. Drucker tells me that, anecdotally, he gets asked about this potential use a lot.&lt;/p&gt;  &lt;p&gt;But there’s a lot going on in a postpartum body. It’s a time of huge physical and hormonal change that can include bonding, breastfeeding and even a rewiring of the brain. We have no idea if, or how, GLP-1s might affect any of those.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How&lt;/strong&gt;—&lt;strong&gt;and when&lt;/strong&gt;—&lt;strong&gt;can people safely stop using them?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yet&amp;nbsp;another study out this week—you can tell GLP-1s are one of the hottest topics in medicine right now—looked at what happens when people stop taking tirzepatide (marketed as Zepbound) for their obesity.&lt;/p&gt; 
 &lt;p&gt;The trial participants all took the drug for 36 weeks, at which point half continued with the drug, and half were switched to a placebo for another 52 weeks. During that first 36 weeks, the weight and heart health of the participants improved.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;But by the end of the study, most of those that had switched to a placebo had regained more than 25% of the weight they had originally lost. One in four had regained more than 75% of that weight, and 9% ended up at a higher weight than when they’d started the study. Their heart health also worsened.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Does that mean that people need to take these drugs forever? Scientists don’t have the answer to that one, either. Or if taking the drugs indefinitely is safe. The answer might depend on the individual, their age or health status, or what they are using the drug for.&lt;/p&gt;  &lt;p&gt;There are other gray areas. GLP-1s look promising for substance use disorders, but we don’t yet know how effective they might be. We don’t know the long-term effects these drugs have on children who take them. And we don’t know the long-term consequences these drugs might have for healthy-weight people who take them for weight loss.&lt;/p&gt;  &lt;p&gt;Earlier this year, Drucker accepted a Breakthrough Prize in Life Sciences at&amp;nbsp;a glitzy event in California. “All of these Hollywood celebrities were coming up to me and saying ‘thank you so much,’” he says. “A lot of these people don’t need to be on these medicines.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/glp1-pregnancy.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;MIT Technology Review&lt;/em&gt;&amp;nbsp;Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read&amp;nbsp;more from the series here&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Weight-loss drugs have been back in the news this week. First, we heard that Eli Lilly, the company behind the drugs Mounjaro and Zepbound, became the first healthcare company in the world to achieve a &lt;em&gt;trillion-dollar&lt;/em&gt; valuation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Those two drugs, which are prescribed for diabetes and obesity respectively, are&amp;nbsp;generating billions of dollars in revenue for the company. Other GLP-1 agonist drugs—a class that includes Mounjaro and Zepbound, which have the same active ingredient—have also been approved to&amp;nbsp;reduce the risk of heart attack and stroke in overweight people. Many hope these apparent wonder drugs will also treat neurological disorders and potentially substance use disorders, too.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But this week we also learned that, disappointingly,&amp;nbsp;GLP-1 drugs don’t seem to help people with Alzheimer’s disease. And that people who stop taking the drugs when they become pregnant can experience potentially dangerous levels of weight gain during their pregnancies. On top of that, some researchers worry that people are using the drugs postpartum to lose pregnancy weight without understanding potential risks.&lt;/p&gt; 
 &lt;p&gt;All of this news should serve as a reminder that there’s a lot we still don’t know about these drugs. This week, let’s look at the enduring questions surrounding GLP-1 agonist drugs.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;First a quick recap.&lt;/strong&gt; Glucagon-like peptide-1 is a hormone made in the gut that helps regulate blood sugar levels. But we’ve learned that it also appears to have effects across the body. Receptors that GLP-1 can bind to have been found in multiple organs and throughout the brain, says Daniel Drucker, an endocrinologist at the University of Toronto who has been studying the hormone for decades.&lt;/p&gt; 
 &lt;p&gt;GLP-1 agonist drugs essentially mimic the hormone’s action. Quite a few have been developed, including semaglutide, tirzepatide, liraglutide, and exenatide, which have brand names like Ozempic, Saxenda and Wegovy. Some of them are recommended for some people with diabetes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;But because these drugs also seem to suppress appetite, they have become hugely popular weight loss aids. And studies have found that many people who take them for diabetes or weight loss experience surprising side effects; that&amp;nbsp;their mental health improves, for example, or that&amp;nbsp;they feel less inclined to smoke or consume alcohol. Research has also found that the drugs seem to increase the growth of brain cells in lab animals.&lt;/p&gt;  &lt;p&gt;So far, so promising. But there are a few outstanding gray areas.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Are they good for our brains?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Novo Nordisk, a competitor of Eli Lilly, manufactures GLP-1 drugs Wegovy and Saxenda. The company recently trialed an oral semaglutide in people with Alzheimer’s disease who had mild cognitive impairment or mild dementia. The placebo-controlled trial included 3808 volunteers.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Unfortunately, the company found that the drug did not appear to delay the progression of Alzheimer’s disease in the volunteers who took it.&lt;/p&gt;  &lt;p&gt;The news came as a huge disappointment to the research community. “It was kind of crushing,” says Drucker. That’s despite the fact that, deep down, he wasn’t expecting a “clear win.” Alzheimer’s disease has proven notoriously difficult to treat, and by the time people get a diagnosis, a lot of damage has already taken place.&lt;/p&gt;  &lt;p&gt;But he is one of many that isn’t giving up hope entirely. After all, research suggests that GLP-1 reduces inflammation in the brain and improves the health of neurons, and that it appears to improve the way brain regions communicate with each other. This all implies that GLP-1 drugs should benefit the brain, says Drucker. There’s still a chance that the drugs might help stave off Alzheimer’s in those who are still cognitively healthy.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Are they safe before, during or after pregnancy?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Other research published this week raises questions about the effects of GLP-1s taken around the time of pregnancy. At the moment, people are advised to plan to stop taking the medicines two months before they become pregnant. That’s partly because some animal studies suggest the drugs can harm the development of a fetus, but mainly because scientists haven’t studied the impact on pregnancy in humans.&lt;/p&gt;  &lt;p&gt;Among the broader population, research suggests that many people who take GLP-1s for weight loss&amp;nbsp;regain much of their lost weight once they stop taking those drugs. So perhaps it’s not surprising that&amp;nbsp;a study published in &lt;em&gt;JAMA&lt;/em&gt; earlier this week saw a similar effect in pregnant people.&lt;/p&gt;  &lt;p&gt;The study found that people who had been taking those drugs gained around 3.3kg more than others who had not. And those who had been taking the drugs also appeared to have a slightly higher risk of gestational diabetes, blood pressure disorders and even preterm birth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;It sounds pretty worrying. But&amp;nbsp;a different study published in August had the &lt;em&gt;opposite &lt;/em&gt;finding—it noted a reduction in the risk of those outcomes among women who had taken the drugs before becoming pregnant.&lt;/p&gt;  &lt;p&gt;If you’re wondering how to make sense of all this, you’re not the only one. No one really knows how these drugs should be used before pregnancy—or during it for that matter.&lt;/p&gt;  &lt;p&gt;Another&amp;nbsp;study out this week found that people (in Denmark) are increasingly taking GLP-1s postpartum to lose weight gained during pregnancy. Drucker tells me that, anecdotally, he gets asked about this potential use a lot.&lt;/p&gt;  &lt;p&gt;But there’s a lot going on in a postpartum body. It’s a time of huge physical and hormonal change that can include bonding, breastfeeding and even a rewiring of the brain. We have no idea if, or how, GLP-1s might affect any of those.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How&lt;/strong&gt;—&lt;strong&gt;and when&lt;/strong&gt;—&lt;strong&gt;can people safely stop using them?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yet&amp;nbsp;another study out this week—you can tell GLP-1s are one of the hottest topics in medicine right now—looked at what happens when people stop taking tirzepatide (marketed as Zepbound) for their obesity.&lt;/p&gt; 
 &lt;p&gt;The trial participants all took the drug for 36 weeks, at which point half continued with the drug, and half were switched to a placebo for another 52 weeks. During that first 36 weeks, the weight and heart health of the participants improved.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;But by the end of the study, most of those that had switched to a placebo had regained more than 25% of the weight they had originally lost. One in four had regained more than 75% of that weight, and 9% ended up at a higher weight than when they’d started the study. Their heart health also worsened.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Does that mean that people need to take these drugs forever? Scientists don’t have the answer to that one, either. Or if taking the drugs indefinitely is safe. The answer might depend on the individual, their age or health status, or what they are using the drug for.&lt;/p&gt;  &lt;p&gt;There are other gray areas. GLP-1s look promising for substance use disorders, but we don’t yet know how effective they might be. We don’t know the long-term effects these drugs have on children who take them. And we don’t know the long-term consequences these drugs might have for healthy-weight people who take them for weight loss.&lt;/p&gt;  &lt;p&gt;Earlier this year, Drucker accepted a Breakthrough Prize in Life Sciences at&amp;nbsp;a glitzy event in California. “All of these Hollywood celebrities were coming up to me and saying ‘thank you so much,’” he says. “A lot of these people don’t need to be on these medicines.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/28/1128511/what-we-still-dont-know-about-weight-loss-drugs/</guid><pubDate>Fri, 28 Nov 2025 10:00:00 +0000</pubDate></item><item><title>How background AI builds operational resilience &amp; visible ROI (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Picture1-1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;If you asked most enterprise leaders which AI tools are delivering ROI, many would point to front-end chatbots or customer support automation. That’s the wrong door. The most value-generating AI systems today aren’t loud, customer-facing marvels. They’re tucked away in backend operations. They work silently, flagging irregularities in real-time, automating risk reviews, mapping data lineage, or helping compliance teams detect anomalies before regulators do. The tools don’t ask for credit, but are saving millions.&lt;/p&gt;&lt;p&gt;Operational resilience no longer comes from having the loudest AI tool. It comes from having the smartest one, placed where it quietly does the work of five teams before lunch.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-machines-that-spot-what-humans-don-t"&gt;The machines that spot what humans don’t&lt;/h3&gt;&lt;p&gt;Take the case of a global logistics company that integrated a background AI system for monitoring procurement contracts. The tool scanned thousands of PDFs, email chains, and invoice patterns per hour. No flashy dashboard. No alerts that interrupt workflow. Just continuous monitoring. In the first six months, it flagged multiple vendor inconsistencies that, if left unchecked, would have resulted in regulatory audits.&lt;/p&gt;&lt;p&gt;The system didn’t just detect anomalies. It interpreted patterns. It noticed a vendor whose delivery timelines were always one day off compared to logged timestamps. Humans had seen those reports for months. But the AI noticed that the error always occurred near quarter-end. The conclusion? Inventory padding. That insight led to a contract renegotiation that saved millions.&lt;/p&gt;&lt;p&gt;This isn’t hypothetical. One similar real-world use case reported a seven-figure operational loss prevented through a near-identical approach. That’s the kind of ROI that doesn’t need a flashy pitch deck.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-advanced-education-still-matters-in-the-age-of-ai"&gt;Why advanced education still matters in the age of AI&lt;/h3&gt;&lt;p&gt;It’s easy to fall into the trap of thinking AI tools are replacing human expertise. But smart organisations aren’t replacing but reinforcing. People with advanced academic backgrounds are helping enterprises integrate AI with strategic precision.&lt;/p&gt;&lt;p&gt;Specifically, those with a doctorate of business administration in business intelligence bring an irreplaceable level of systems thinking and contextual insight. The professionals understand the complexity behind data ecosystems, from governance models to algorithmic biases, and can assess which tools serve long-term resilience versus short-term automation hype.&lt;/p&gt;&lt;p&gt;When AI models are trained on historical data, it takes educated leadership to spot where historical bias may become a future liability. And when AI starts making high-stakes decisions, you need someone who can ask better questions about risk exposure, model explainability, and ethics in decision-making. This is where doctorates aren’t just nice to have – they’re essential.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-invisible-doesn-t-mean-simple"&gt;Invisible doesn’t mean simple&lt;/h3&gt;&lt;p&gt;Too often, companies install AI as if it were antivirus software. Set it, forget it, hope it works. That’s how you get black-box risk. Invisible tools must still be transparent internally. It’s not enough to say, “AI flagged it.” The teams relying on these tools – risk officers, auditors, operations leads – must understand the decision-making logic or at least the signals that drive the alert. The requires not just technical documentation, but collaboration between engineers and business units.&lt;/p&gt;&lt;p&gt;Enterprises that win with background AI systems build what could be called “decision-ready infrastructure.” The are workflows where data ingestion, validation, risk detection, and notification are all stitched together. Not in silos. Not in parallel systems. But in one loop that feeds actionable insight straight to the team responsible. That’s resilience.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-where-operational-ai-works-best"&gt;Where operational AI works best&lt;/h3&gt;&lt;p&gt;Here’s where invisible AI is already proving its worth in industries:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Compliance Monitoring: Automatically detecting early signs of non-compliance in internal logs, transactional data, and communication channels without triggering false positives.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data Integrity: Identifying stale, duplicate, or inconsistent data in business units to prevent decision errors and reporting flaws.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Fraud Detection: Recognising pattern shifts in transactions before losses occur. Not reactive alerts after the fact.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Supply Chain Optimisation: Mapping supplier dependencies and predicting bottlenecks based on third-party risk signals or external disruptions.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In all these cases, the key isn’t automation for automation’s sake. It’s precision. AI models that are well-calibrated, integrated with domain knowledge, and fine-tuned by experts – not simply deployed off the shelf.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-makes-the-systems-resilient"&gt;What makes the systems resilient?&lt;/h3&gt;&lt;p&gt;Operational resilience isn’t built in a sprint. It’s the result of smart layering. One layer catches data inconsistencies. Another tracks compliance drift. Another layer analyses behavioural signals in departments. And yet another feeds all of that into a risk model trained on historical issues.&lt;/p&gt;&lt;p&gt;The resilience depends on:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Human supervision with domain expertise, especially from those trained in business intelligence.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Cross-functional transparency, so that audit, tech, and business teams are aligned.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The ability to adapt models over time as the business evolves, not just retrain when performance dips.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Systems that get this wrong often create alert fatigue or over-correct with rigid rule-based models. That’s not AI. That’s bureaucracy in disguise.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-real-roi-doesn-t-scream"&gt;Real ROI doesn’t scream&lt;/h3&gt;&lt;p&gt;Most ROI-focused teams chase visibility. Dashboards, reports, charts. But the most valuable AI tools don’t scream. They tap a shoulder. They point out a loose thread. They suggest a second look. That’s where the money is. Quiet detection. Small interventions. Avoided disasters.&lt;/p&gt;&lt;p&gt;The companies that treat AI as a quiet partner – not a front-row magician – are already ahead. They’re using it to build internal resilience, not just customer-facing shine. They’re integrating it with human intelligence, not replacing it. And most of all, they’re measuring ROI not by how cool the tech looks, but by how quietly it works.&lt;/p&gt;&lt;p&gt;That’s the future. Invisible AI agents and assistants. Visible outcomes. Real, measurable resilience.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Picture1-1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;If you asked most enterprise leaders which AI tools are delivering ROI, many would point to front-end chatbots or customer support automation. That’s the wrong door. The most value-generating AI systems today aren’t loud, customer-facing marvels. They’re tucked away in backend operations. They work silently, flagging irregularities in real-time, automating risk reviews, mapping data lineage, or helping compliance teams detect anomalies before regulators do. The tools don’t ask for credit, but are saving millions.&lt;/p&gt;&lt;p&gt;Operational resilience no longer comes from having the loudest AI tool. It comes from having the smartest one, placed where it quietly does the work of five teams before lunch.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-machines-that-spot-what-humans-don-t"&gt;The machines that spot what humans don’t&lt;/h3&gt;&lt;p&gt;Take the case of a global logistics company that integrated a background AI system for monitoring procurement contracts. The tool scanned thousands of PDFs, email chains, and invoice patterns per hour. No flashy dashboard. No alerts that interrupt workflow. Just continuous monitoring. In the first six months, it flagged multiple vendor inconsistencies that, if left unchecked, would have resulted in regulatory audits.&lt;/p&gt;&lt;p&gt;The system didn’t just detect anomalies. It interpreted patterns. It noticed a vendor whose delivery timelines were always one day off compared to logged timestamps. Humans had seen those reports for months. But the AI noticed that the error always occurred near quarter-end. The conclusion? Inventory padding. That insight led to a contract renegotiation that saved millions.&lt;/p&gt;&lt;p&gt;This isn’t hypothetical. One similar real-world use case reported a seven-figure operational loss prevented through a near-identical approach. That’s the kind of ROI that doesn’t need a flashy pitch deck.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-advanced-education-still-matters-in-the-age-of-ai"&gt;Why advanced education still matters in the age of AI&lt;/h3&gt;&lt;p&gt;It’s easy to fall into the trap of thinking AI tools are replacing human expertise. But smart organisations aren’t replacing but reinforcing. People with advanced academic backgrounds are helping enterprises integrate AI with strategic precision.&lt;/p&gt;&lt;p&gt;Specifically, those with a doctorate of business administration in business intelligence bring an irreplaceable level of systems thinking and contextual insight. The professionals understand the complexity behind data ecosystems, from governance models to algorithmic biases, and can assess which tools serve long-term resilience versus short-term automation hype.&lt;/p&gt;&lt;p&gt;When AI models are trained on historical data, it takes educated leadership to spot where historical bias may become a future liability. And when AI starts making high-stakes decisions, you need someone who can ask better questions about risk exposure, model explainability, and ethics in decision-making. This is where doctorates aren’t just nice to have – they’re essential.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-invisible-doesn-t-mean-simple"&gt;Invisible doesn’t mean simple&lt;/h3&gt;&lt;p&gt;Too often, companies install AI as if it were antivirus software. Set it, forget it, hope it works. That’s how you get black-box risk. Invisible tools must still be transparent internally. It’s not enough to say, “AI flagged it.” The teams relying on these tools – risk officers, auditors, operations leads – must understand the decision-making logic or at least the signals that drive the alert. The requires not just technical documentation, but collaboration between engineers and business units.&lt;/p&gt;&lt;p&gt;Enterprises that win with background AI systems build what could be called “decision-ready infrastructure.” The are workflows where data ingestion, validation, risk detection, and notification are all stitched together. Not in silos. Not in parallel systems. But in one loop that feeds actionable insight straight to the team responsible. That’s resilience.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-where-operational-ai-works-best"&gt;Where operational AI works best&lt;/h3&gt;&lt;p&gt;Here’s where invisible AI is already proving its worth in industries:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Compliance Monitoring: Automatically detecting early signs of non-compliance in internal logs, transactional data, and communication channels without triggering false positives.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data Integrity: Identifying stale, duplicate, or inconsistent data in business units to prevent decision errors and reporting flaws.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Fraud Detection: Recognising pattern shifts in transactions before losses occur. Not reactive alerts after the fact.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Supply Chain Optimisation: Mapping supplier dependencies and predicting bottlenecks based on third-party risk signals or external disruptions.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In all these cases, the key isn’t automation for automation’s sake. It’s precision. AI models that are well-calibrated, integrated with domain knowledge, and fine-tuned by experts – not simply deployed off the shelf.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-makes-the-systems-resilient"&gt;What makes the systems resilient?&lt;/h3&gt;&lt;p&gt;Operational resilience isn’t built in a sprint. It’s the result of smart layering. One layer catches data inconsistencies. Another tracks compliance drift. Another layer analyses behavioural signals in departments. And yet another feeds all of that into a risk model trained on historical issues.&lt;/p&gt;&lt;p&gt;The resilience depends on:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Human supervision with domain expertise, especially from those trained in business intelligence.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Cross-functional transparency, so that audit, tech, and business teams are aligned.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The ability to adapt models over time as the business evolves, not just retrain when performance dips.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Systems that get this wrong often create alert fatigue or over-correct with rigid rule-based models. That’s not AI. That’s bureaucracy in disguise.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-real-roi-doesn-t-scream"&gt;Real ROI doesn’t scream&lt;/h3&gt;&lt;p&gt;Most ROI-focused teams chase visibility. Dashboards, reports, charts. But the most valuable AI tools don’t scream. They tap a shoulder. They point out a loose thread. They suggest a second look. That’s where the money is. Quiet detection. Small interventions. Avoided disasters.&lt;/p&gt;&lt;p&gt;The companies that treat AI as a quiet partner – not a front-row magician – are already ahead. They’re using it to build internal resilience, not just customer-facing shine. They’re integrating it with human intelligence, not replacing it. And most of all, they’re measuring ROI not by how cool the tech looks, but by how quietly it works.&lt;/p&gt;&lt;p&gt;That’s the future. Invisible AI agents and assistants. Visible outcomes. Real, measurable resilience.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/</guid><pubDate>Fri, 28 Nov 2025 10:51:13 +0000</pubDate></item><item><title>[NEW] The Download: the mysteries surrounding weight-loss drugs, and the economic effects of AI (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/28/1128516/the-download-the-mysteries-surrounding-weight-loss-drugs-and-the-economic-effects-of-ai/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What we still don’t know about weight-loss drugs&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Weight-loss drugs have been back in the news this week. First, we heard that Eli Lilly, the company behind Mounjaro and Zepbound, became the first healthcare company in the world to achieve a trillion-dollar valuation.&lt;/p&gt;&lt;p&gt;But we also learned that, disappointingly, GLP-1 drugs don’t seem to help people with Alzheimer’s disease. And that people who stop taking the drugs when they become pregnant can experience potentially dangerous levels of weight gain. On top of that, some researchers worry that people are using the drugs postpartum to lose pregnancy weight without understanding potential risks.&lt;/p&gt;  &lt;p&gt;All of this news should serve as a reminder that there’s a lot we still don’t know about these drugs. So let’s look at the enduring questions surrounding GLP-1 agonist drugs.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;If you’re interested in weight loss drugs and how they affect us, take a look at:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ GLP-1 agonists like Wegovy, Ozempic, and Mounjaro might benefit heart and brain health—but research suggests they might also cause pregnancy complications and harm some users. Read the full story.&lt;/p&gt;&lt;p&gt;+ We’ve never understood how hunger works. That might be about to change. Read the full story.&lt;/p&gt;&lt;p&gt;+ Weight-loss injections have taken over the internet. But what does this mean for people IRL?&lt;/p&gt;&lt;p&gt;+ This vibrating weight-loss pill seems to work—in pigs. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What we know about how AI is affecting the economy&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;There's a lot at stake when it comes to understanding how AI is changing the economy right now. Should we be pessimistic? Optimistic? Or is the situation too nuanced for that?&lt;/p&gt;&lt;p&gt;Hopefully, we can point you towards some answers. Mat Honan, our editor in chief, will hold a special subscriber-only Roundtables conversation with our editor at large David Rotman, and Richard Waters, &lt;em&gt;Financial Times&lt;/em&gt; columnist, exploring what's happening across different markets. Register here to join us at 1pm ET on Tuesday December 9.&lt;/p&gt;  &lt;p&gt;The event is part of the&lt;em&gt; Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt; “The State of AI” partnership, exploring the global impact of artificial intelligence. Over the past month, we’ve been running discussions between our journalists—sign up here to receive future editions every Monday.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Tech billionaires are gearing up to fight AI regulation&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;By amassing multi-million dollar war chests ahead of the 2026 US midterm elections. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Donald Trump’s “Manhattan Project” for AI is certainly ambitious. &lt;/em&gt;(The Information $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The EU wants to hold social media platforms liable for financial scams&lt;/strong&gt;&lt;br /&gt;New rules will force tech firms to compensate banks if they fail to remove reported scams. (Politico)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 China is worried about a humanoid robot bubble&lt;/strong&gt;&lt;br /&gt;Because more than 150 companies there are building very similar machines. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It could learn some lessons from the current AI bubble. &lt;/em&gt;(CNN)+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 A Myanmar scam compound was blown up&lt;br /&gt;But its residents will simply find new bases for their operations. (NYT $)&lt;br /&gt;+ &lt;em&gt;Experts suspect the destruction may have been for show. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Navies across the world are investing in submarine drones&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They cost a fraction of what it takes to run a traditional manned sub. (The Guardian)&lt;br /&gt;+ &lt;em&gt;How underwater drones could shape a potential Taiwan-China conflict. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 What to expect from China’s seemingly unstoppable innovation drive&lt;/strong&gt;&lt;br /&gt;Its extremely permissive regulators play a big role. (Economist $)&lt;br /&gt;+ &lt;em&gt;Is China about to win the AI race? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 The UK is waging a war on VPNs&lt;br /&gt;&lt;/strong&gt;Good luck trying to persuade people to stop using them. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 We’re learning more about Jeff Bezos’ mysterious clock project&lt;br /&gt;&lt;/strong&gt;He’s backed the Clock of the Long Now for years—and construction is amping up. (FT $)&lt;br /&gt;+ &lt;em&gt;How aging clocks can help us understand why we age—and if we can reverse it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Have we finally seen the first hints of dark matter?&lt;/strong&gt;&lt;br /&gt;These researchers seem to think so. (New Scientist $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 A helpful robot is helping archaeologists reconstruct Pompeii&lt;/strong&gt;&lt;br /&gt;Reassembling ancient frescos is fiddly and time-consuming, but less so if you’re a dextrous machine. (Reuters)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We do fail… a lot.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Defense company Anduril explains its move-fast-and-break-things ethos to the Wall Street Journal in response to reports its systems have been marred by issues in Ukraine.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128518" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_3103f2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How to build a better AI benchmark&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s not easy being one of Silicon Valley’s favorite benchmarks.&lt;/p&gt;  &lt;p&gt;SWE-Bench (pronounced “swee bench”) launched in November 2024 as a way to evaluate an AI model’s coding skill. It has since quickly become one of the most popular tests in AI. A SWE-Bench score has become a mainstay of major model releases from OpenAI, Anthropic, and Google—and outside of foundation models, the fine-tuners at AI firms are in constant competition to see who can rise above the pack.&lt;/p&gt; 
 &lt;p&gt;Despite all the fervor, this isn’t exactly a truthful assessment of which model is “better.” Entrants have begun to game the system—which is pushing many others to wonder whether there’s a better way to actually measure AI achievement. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Russell Brandom&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Aww, these sharks appear to be playing with pool toys.&lt;br /&gt;+ Strange things are happening over on Easter Island (even weirder than you can imagine) 🗿&lt;br /&gt;+ Very cool—archaeologists have uncovered a Roman tomb that’s been sealed shut for 1,700 years.&lt;br /&gt;+ This Japanese mass media collage is making my eyes swim, in a good way.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What we still don’t know about weight-loss drugs&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Weight-loss drugs have been back in the news this week. First, we heard that Eli Lilly, the company behind Mounjaro and Zepbound, became the first healthcare company in the world to achieve a trillion-dollar valuation.&lt;/p&gt;&lt;p&gt;But we also learned that, disappointingly, GLP-1 drugs don’t seem to help people with Alzheimer’s disease. And that people who stop taking the drugs when they become pregnant can experience potentially dangerous levels of weight gain. On top of that, some researchers worry that people are using the drugs postpartum to lose pregnancy weight without understanding potential risks.&lt;/p&gt;  &lt;p&gt;All of this news should serve as a reminder that there’s a lot we still don’t know about these drugs. So let’s look at the enduring questions surrounding GLP-1 agonist drugs.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;If you’re interested in weight loss drugs and how they affect us, take a look at:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ GLP-1 agonists like Wegovy, Ozempic, and Mounjaro might benefit heart and brain health—but research suggests they might also cause pregnancy complications and harm some users. Read the full story.&lt;/p&gt;&lt;p&gt;+ We’ve never understood how hunger works. That might be about to change. Read the full story.&lt;/p&gt;&lt;p&gt;+ Weight-loss injections have taken over the internet. But what does this mean for people IRL?&lt;/p&gt;&lt;p&gt;+ This vibrating weight-loss pill seems to work—in pigs. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What we know about how AI is affecting the economy&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;There's a lot at stake when it comes to understanding how AI is changing the economy right now. Should we be pessimistic? Optimistic? Or is the situation too nuanced for that?&lt;/p&gt;&lt;p&gt;Hopefully, we can point you towards some answers. Mat Honan, our editor in chief, will hold a special subscriber-only Roundtables conversation with our editor at large David Rotman, and Richard Waters, &lt;em&gt;Financial Times&lt;/em&gt; columnist, exploring what's happening across different markets. Register here to join us at 1pm ET on Tuesday December 9.&lt;/p&gt;  &lt;p&gt;The event is part of the&lt;em&gt; Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt; “The State of AI” partnership, exploring the global impact of artificial intelligence. Over the past month, we’ve been running discussions between our journalists—sign up here to receive future editions every Monday.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Tech billionaires are gearing up to fight AI regulation&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;By amassing multi-million dollar war chests ahead of the 2026 US midterm elections. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Donald Trump’s “Manhattan Project” for AI is certainly ambitious. &lt;/em&gt;(The Information $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The EU wants to hold social media platforms liable for financial scams&lt;/strong&gt;&lt;br /&gt;New rules will force tech firms to compensate banks if they fail to remove reported scams. (Politico)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 China is worried about a humanoid robot bubble&lt;/strong&gt;&lt;br /&gt;Because more than 150 companies there are building very similar machines. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It could learn some lessons from the current AI bubble. &lt;/em&gt;(CNN)+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 A Myanmar scam compound was blown up&lt;br /&gt;But its residents will simply find new bases for their operations. (NYT $)&lt;br /&gt;+ &lt;em&gt;Experts suspect the destruction may have been for show. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Navies across the world are investing in submarine drones&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They cost a fraction of what it takes to run a traditional manned sub. (The Guardian)&lt;br /&gt;+ &lt;em&gt;How underwater drones could shape a potential Taiwan-China conflict. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 What to expect from China’s seemingly unstoppable innovation drive&lt;/strong&gt;&lt;br /&gt;Its extremely permissive regulators play a big role. (Economist $)&lt;br /&gt;+ &lt;em&gt;Is China about to win the AI race? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 The UK is waging a war on VPNs&lt;br /&gt;&lt;/strong&gt;Good luck trying to persuade people to stop using them. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 We’re learning more about Jeff Bezos’ mysterious clock project&lt;br /&gt;&lt;/strong&gt;He’s backed the Clock of the Long Now for years—and construction is amping up. (FT $)&lt;br /&gt;+ &lt;em&gt;How aging clocks can help us understand why we age—and if we can reverse it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Have we finally seen the first hints of dark matter?&lt;/strong&gt;&lt;br /&gt;These researchers seem to think so. (New Scientist $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 A helpful robot is helping archaeologists reconstruct Pompeii&lt;/strong&gt;&lt;br /&gt;Reassembling ancient frescos is fiddly and time-consuming, but less so if you’re a dextrous machine. (Reuters)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We do fail… a lot.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Defense company Anduril explains its move-fast-and-break-things ethos to the Wall Street Journal in response to reports its systems have been marred by issues in Ukraine.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128518" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_3103f2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How to build a better AI benchmark&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s not easy being one of Silicon Valley’s favorite benchmarks.&lt;/p&gt;  &lt;p&gt;SWE-Bench (pronounced “swee bench”) launched in November 2024 as a way to evaluate an AI model’s coding skill. It has since quickly become one of the most popular tests in AI. A SWE-Bench score has become a mainstay of major model releases from OpenAI, Anthropic, and Google—and outside of foundation models, the fine-tuners at AI firms are in constant competition to see who can rise above the pack.&lt;/p&gt; 
 &lt;p&gt;Despite all the fervor, this isn’t exactly a truthful assessment of which model is “better.” Entrants have begun to game the system—which is pushing many others to wonder whether there’s a better way to actually measure AI achievement. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Russell Brandom&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Aww, these sharks appear to be playing with pool toys.&lt;br /&gt;+ Strange things are happening over on Easter Island (even weirder than you can imagine) 🗿&lt;br /&gt;+ Very cool—archaeologists have uncovered a Roman tomb that’s been sealed shut for 1,700 years.&lt;br /&gt;+ This Japanese mass media collage is making my eyes swim, in a good way.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/28/1128516/the-download-the-mysteries-surrounding-weight-loss-drugs-and-the-economic-effects-of-ai/</guid><pubDate>Fri, 28 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] The race to regulate AI has sparked a federal vs state showdown (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/28/the-race-to-regulate-ai-has-sparked-a-federal-vs-state-showdown/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the first time, Washington is getting close to deciding how to regulate artificial intelligence. And the fight that’s brewing isn’t about the technology, it’s about who gets to do the regulating.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the absence of a meaningful federal AI standard that focuses on consumer safety, states have introduced dozens of bills to protect residents against AI-related harms, including California’s AI safety bill SB-53 and Texas’s Responsible AI Governance Act, which prohibits intentional misuse of AI systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The tech giants and buzzy startups born out of Silicon Valley argue such laws create an unworkable patchwork that threatens innovation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s going to slow us in the race against China,” Josh Vlasto, co-founder of pro-AI PAC Leading the Future, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry, and several of its transplants in the White House, is pushing for a national standard or none at all. In the trenches of that all-or-nothing battle, new efforts have emerged to prohibit states from enacting their own AI legislation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;House lawmakers are reportedly trying to use the National Defense Authorization Act (NDAA) to block state AI laws. At the same time, a leaked draft of a White House executive order also demonstrates strong support for preempting state efforts to regulate AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A sweeping preemption that would take away states’ rights to regulate AI is unpopular in Congress, which voted overwhelmingly against a similar moratorium earlier this year. Lawmakers have argued that without a federal standard in place, blocking states will leave consumers exposed to harm, and tech companies free to operate without oversight.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To create that national standard, Rep. Ted Lieu (D-CA) and the bipartisan House AI Task Force are preparing a package of federal AI bills that cover a range of consumer protections, including fraud, healthcare, transparency, child safety, and catastrophic risk. A megabill such as this will likely take months, if not years, to become law, underscoring why the current rush to limit state authority has become one of the most contentious fights in AI policy.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-battle-lines-ndaa-and-the-eo"&gt;&lt;strong&gt;The battle lines: NDAA and the EO&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="US President Donald Trump displays an executive order on artificial intelligence he signed at the &amp;quot;Winning the AI Race&amp;quot; AI Summit at the Andrew W." class="wp-image-3030829" height="454" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Trump displays an executive order on AI he signed on July 23, 2025. (Photo by ANDREW CABALLERO-REYNOLDS / AFP) &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;ANDREW CABALLERO-REYNOLDS/AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Efforts to block states from regulating AI have ramped up in recent weeks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The House has considered tucking language in the NDAA that would prevent states from regulating AI, Majority Leader Steve Scalise (R-LA) told Punchbowl News. Congress was reportedly working to finalize a deal on the defense bill before Thanksgiving, Politico reported. A source familiar with the matter told TechCrunch negotiations have focused on narrowing the scope to potentially preserve state authority over areas like kids’ safety and transparency.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, a leaked White House EO draft reveals the administration’s own potential preemption strategy. The EO, which has reportedly been put on hold, would create an “AI Litigation Task Force” to challenge state AI laws in court, direct agencies to evaluate state laws deemed “onerous,” and push the Federal Communications Commission and Federal Trade Commission towards national standards that override state rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the EO would give David Sacks – Trump’s AI and Crypto Czar and co-founder of VC firm Craft Ventures – co-lead authority on creating a uniform legal framework. This would give Sacks direct influence over AI policy that supersedes the typical role of the White House Office of Science and Technology Policy, and its head Michael Kratsios.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks has publicly advocated for blocking state regulation and keeping federal oversight menial, favoring industry self-regulation to “maximize growth.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-patchwork-argument"&gt;&lt;strong&gt;The patchwork argument&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks’s position mirrors the viewpoint of much of the AI industry. Several pro-AI super PACs have emerged in recent months, throwing hundreds of millions of dollars into local and state elections to oppose candidates who support AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading the Future – backed by Andreessen Horowitz, OpenAI president Greg Brockman, Perplexity, and Palantir co-founder Joe Lonsdale – has raised more than $100 million. This week, Leading the Future launched a $10 million campaign pushing Congress to craft a national AI policy that overrides state laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re trying to drive innovation in the tech sector, you can’t have a situation where all these laws keep popping up from people who don’t necessarily have the technical expertise,” Vlasto told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that a patchwork of state regulations will “slow us in the race against China.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Leamer, executive director of Build American AI, the PAC’s advocacy arm, confirmed the group supports preemption without AI-specific federal consumer protections in place. Leamer argued that existing laws, like those addressing fraud or product liability, are sufficient to handle AI harms. Where state laws often seek to prevent problems before they arise, Leamer favors a more reactive approach: let companies move fast, address problems in court later.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-no-preemption-without-representation"&gt;&lt;strong&gt;No preemption without representation&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Alex Bores speaking at an event in Washington, D.C., on November 17, 2025." class="wp-image-3068604" height="510" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Alex Bores speaking at an event in Washington, D.C., on November 17, 2025. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Bores, a New York Assembly member running for Congress, is one of Leading the Future’s first targets. He sponsored the RAISE Act, which requires large AI labs to have safety plans to prevent critical harms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I believe in the power of AI, and that is why it is so important to have reasonable regulations,” Bores told TechCrunch. “Ultimately, the AI that’s going to win in the marketplace is going to be trustworthy AI, and often the marketplace undervalues or puts poor short-term incentives on investing in safety.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores supports a national AI policy, but argues states can move faster to address emerging risks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And it’s true that states move quicker.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of November 2025, 38 states have adopted more than 100 AI-related laws this year, mainly targeting deepfakes, transparency and disclosure, and government use of AI. (A recent study found that 69% of those laws impose no requirements on AI developers at all.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity in Congress provides more evidence of the slower-than-states argument. Hundreds of AI bills have been introduced, but few have passed. Since 2015, Rep. Lieu has introduced 67 bills to the House Science Committee. Only one became law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than 200 lawmakers signed an open letter opposing preemption in the NDAA, arguing that “states serve as laboratories of democracies” that must “retain the flexibility to confront new digital challenges as they arise.” Nearly 40 state attorneys general also sent an open letter opposing a state AI regulation ban.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cybersecurity expert Bruce Schneier and data scientist Nathan E. Sanders – authors of &lt;em&gt;Rewiring Democracy:&lt;/em&gt;&lt;em&gt; How AI Will Transform Our Politics, Government, and Citizenship &lt;/em&gt;– argue the patchwork complaint is overblown.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies already comply with tougher EU regulations, they note, and most industries find a way to operate under varying state laws. The real motive, they say, is avoiding accountability.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-what-could-a-federal-standard-look-like"&gt;&lt;strong&gt;What could a federal standard look like?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu is drafting an over 200-page megabill he hopes to introduce in December. It covers a range of issues, like fraud penalties, deepfake protections, whistleblower protections, compute resources for academia, and mandatory testing and disclosure for large language model companies.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That last provision would require AI labs to test their models and publish results – something most do voluntarily now. Lieu hasn’t yet introduced the bill, but he said it doesn’t direct any federal agencies to review AI models directly. That differs from a similar bill introduced by Sens Josh Hawley (R-MS) and Richard Blumenthal (D-CN) which would require a government-run evaluation program for advanced AI systems before they deployed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu acknowledged his bill wouldn’t be as strict, but he said it had a better chance at making it into law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My goal is to get something into law this term,” Lieu said, noting that House Majority Leader Scalise is openly hostile to AI regulation. “I’m not writing a bill that I’d have if I were king. I’m trying to write a bill that could pass a Republican-controlled House, a Republican-controlled Senate, and a Republican-controlled White House.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the first time, Washington is getting close to deciding how to regulate artificial intelligence. And the fight that’s brewing isn’t about the technology, it’s about who gets to do the regulating.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the absence of a meaningful federal AI standard that focuses on consumer safety, states have introduced dozens of bills to protect residents against AI-related harms, including California’s AI safety bill SB-53 and Texas’s Responsible AI Governance Act, which prohibits intentional misuse of AI systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The tech giants and buzzy startups born out of Silicon Valley argue such laws create an unworkable patchwork that threatens innovation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s going to slow us in the race against China,” Josh Vlasto, co-founder of pro-AI PAC Leading the Future, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry, and several of its transplants in the White House, is pushing for a national standard or none at all. In the trenches of that all-or-nothing battle, new efforts have emerged to prohibit states from enacting their own AI legislation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;House lawmakers are reportedly trying to use the National Defense Authorization Act (NDAA) to block state AI laws. At the same time, a leaked draft of a White House executive order also demonstrates strong support for preempting state efforts to regulate AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A sweeping preemption that would take away states’ rights to regulate AI is unpopular in Congress, which voted overwhelmingly against a similar moratorium earlier this year. Lawmakers have argued that without a federal standard in place, blocking states will leave consumers exposed to harm, and tech companies free to operate without oversight.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To create that national standard, Rep. Ted Lieu (D-CA) and the bipartisan House AI Task Force are preparing a package of federal AI bills that cover a range of consumer protections, including fraud, healthcare, transparency, child safety, and catastrophic risk. A megabill such as this will likely take months, if not years, to become law, underscoring why the current rush to limit state authority has become one of the most contentious fights in AI policy.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-battle-lines-ndaa-and-the-eo"&gt;&lt;strong&gt;The battle lines: NDAA and the EO&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="US President Donald Trump displays an executive order on artificial intelligence he signed at the &amp;quot;Winning the AI Race&amp;quot; AI Summit at the Andrew W." class="wp-image-3030829" height="454" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Trump displays an executive order on AI he signed on July 23, 2025. (Photo by ANDREW CABALLERO-REYNOLDS / AFP) &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;ANDREW CABALLERO-REYNOLDS/AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Efforts to block states from regulating AI have ramped up in recent weeks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The House has considered tucking language in the NDAA that would prevent states from regulating AI, Majority Leader Steve Scalise (R-LA) told Punchbowl News. Congress was reportedly working to finalize a deal on the defense bill before Thanksgiving, Politico reported. A source familiar with the matter told TechCrunch negotiations have focused on narrowing the scope to potentially preserve state authority over areas like kids’ safety and transparency.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, a leaked White House EO draft reveals the administration’s own potential preemption strategy. The EO, which has reportedly been put on hold, would create an “AI Litigation Task Force” to challenge state AI laws in court, direct agencies to evaluate state laws deemed “onerous,” and push the Federal Communications Commission and Federal Trade Commission towards national standards that override state rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the EO would give David Sacks – Trump’s AI and Crypto Czar and co-founder of VC firm Craft Ventures – co-lead authority on creating a uniform legal framework. This would give Sacks direct influence over AI policy that supersedes the typical role of the White House Office of Science and Technology Policy, and its head Michael Kratsios.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks has publicly advocated for blocking state regulation and keeping federal oversight menial, favoring industry self-regulation to “maximize growth.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-patchwork-argument"&gt;&lt;strong&gt;The patchwork argument&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks’s position mirrors the viewpoint of much of the AI industry. Several pro-AI super PACs have emerged in recent months, throwing hundreds of millions of dollars into local and state elections to oppose candidates who support AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading the Future – backed by Andreessen Horowitz, OpenAI president Greg Brockman, Perplexity, and Palantir co-founder Joe Lonsdale – has raised more than $100 million. This week, Leading the Future launched a $10 million campaign pushing Congress to craft a national AI policy that overrides state laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re trying to drive innovation in the tech sector, you can’t have a situation where all these laws keep popping up from people who don’t necessarily have the technical expertise,” Vlasto told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that a patchwork of state regulations will “slow us in the race against China.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Leamer, executive director of Build American AI, the PAC’s advocacy arm, confirmed the group supports preemption without AI-specific federal consumer protections in place. Leamer argued that existing laws, like those addressing fraud or product liability, are sufficient to handle AI harms. Where state laws often seek to prevent problems before they arise, Leamer favors a more reactive approach: let companies move fast, address problems in court later.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-no-preemption-without-representation"&gt;&lt;strong&gt;No preemption without representation&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Alex Bores speaking at an event in Washington, D.C., on November 17, 2025." class="wp-image-3068604" height="510" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Alex Bores speaking at an event in Washington, D.C., on November 17, 2025. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Bores, a New York Assembly member running for Congress, is one of Leading the Future’s first targets. He sponsored the RAISE Act, which requires large AI labs to have safety plans to prevent critical harms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I believe in the power of AI, and that is why it is so important to have reasonable regulations,” Bores told TechCrunch. “Ultimately, the AI that’s going to win in the marketplace is going to be trustworthy AI, and often the marketplace undervalues or puts poor short-term incentives on investing in safety.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores supports a national AI policy, but argues states can move faster to address emerging risks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And it’s true that states move quicker.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of November 2025, 38 states have adopted more than 100 AI-related laws this year, mainly targeting deepfakes, transparency and disclosure, and government use of AI. (A recent study found that 69% of those laws impose no requirements on AI developers at all.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity in Congress provides more evidence of the slower-than-states argument. Hundreds of AI bills have been introduced, but few have passed. Since 2015, Rep. Lieu has introduced 67 bills to the House Science Committee. Only one became law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than 200 lawmakers signed an open letter opposing preemption in the NDAA, arguing that “states serve as laboratories of democracies” that must “retain the flexibility to confront new digital challenges as they arise.” Nearly 40 state attorneys general also sent an open letter opposing a state AI regulation ban.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cybersecurity expert Bruce Schneier and data scientist Nathan E. Sanders – authors of &lt;em&gt;Rewiring Democracy:&lt;/em&gt;&lt;em&gt; How AI Will Transform Our Politics, Government, and Citizenship &lt;/em&gt;– argue the patchwork complaint is overblown.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies already comply with tougher EU regulations, they note, and most industries find a way to operate under varying state laws. The real motive, they say, is avoiding accountability.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-what-could-a-federal-standard-look-like"&gt;&lt;strong&gt;What could a federal standard look like?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu is drafting an over 200-page megabill he hopes to introduce in December. It covers a range of issues, like fraud penalties, deepfake protections, whistleblower protections, compute resources for academia, and mandatory testing and disclosure for large language model companies.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That last provision would require AI labs to test their models and publish results – something most do voluntarily now. Lieu hasn’t yet introduced the bill, but he said it doesn’t direct any federal agencies to review AI models directly. That differs from a similar bill introduced by Sens Josh Hawley (R-MS) and Richard Blumenthal (D-CN) which would require a government-run evaluation program for advanced AI systems before they deployed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu acknowledged his bill wouldn’t be as strict, but he said it had a better chance at making it into law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My goal is to get something into law this term,” Lieu said, noting that House Majority Leader Scalise is openly hostile to AI regulation. “I’m not writing a bill that I’d have if I were king. I’m trying to write a bill that could pass a Republican-controlled House, a Republican-controlled Senate, and a Republican-controlled White House.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/28/the-race-to-regulate-ai-has-sparked-a-federal-vs-state-showdown/</guid><pubDate>Fri, 28 Nov 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] How OpenAI and Google see AI changing go-to-market strategies (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/28/how-openai-and-google-see-ai-changing-go-to-market-strategies/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/gtm-disrupt-2025.jpeg?resize=1200,745" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, when it was time for startups to start selling their product, they could turn to any number of traditional playbooks. But as with so many things, AI is changing how companies prepare to go to market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can do more with less than ever before,” Max Altschuler, general partner at GTMfund, told the audience at TechCrunch Disrupt last month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The challenge for founders and operators, though, will be threading the needle. While there has been some chatter of startups hiring developers more versed and loosing them on typical GTM problems, he said, there’s still a need for more specific domain expertise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you have great advisors around you can learn some of the tried-and-true playbooks. Those things haven’t gone out the window. I think it’s still necessary that you have a general understanding of how and why certain things work in marketing,” Altschuler said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alison Wagonfeld, vice president of marketing at Google Cloud, said the craft of marketing is still very much required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “You certainly need the AI knowledge, the AI curiosity, the technologists, but also understanding what the purpose of marketing is, to understand customer insights, to do research, to see what great creative is like,” Wagonfeld said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Teams that adopt AI, though, can move more quickly “You can just get out there with so many more messages faster, and then you can think more holistically about what metrics am I driving for,” , she added. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marc Manara, head of startups at OpenAI, has found many startups have embraced AI in their GTM strategy, though it’s not necessarily with the sole focus of minimizing how many resources they put toward it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s a movement of, yes, you can do more with less, but you can also be very focused with how you do it,” he said. “The degree of personalization and signal following that you can do with AI is differentiated now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, he said there are tools that help build leads which are much more sophisticated than in the past. Rather than just a simple query of a database, AI prompts can help startups find prospective customers that fit a very specific set of requirements.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inbound marketing has changed, too, he added, by using the results of those prompts to qualify and score inbound leads “with a lot more precision could have been in the past.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it comes time for a startup to begin crafting its go-to-market strategy, Wagonfeld said its important to consider what qualities it might want in a GTM team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a change in hiring perspective, where the past it was more about hiring specialists, people who really knew, sometimes even like a sub-specialty within marketing or within sales. And now it’s hiring for a sense of curiosity and understanding,” she said. “It’s almost the top thing to hire for now.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/gtm-disrupt-2025.jpeg?resize=1200,745" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, when it was time for startups to start selling their product, they could turn to any number of traditional playbooks. But as with so many things, AI is changing how companies prepare to go to market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can do more with less than ever before,” Max Altschuler, general partner at GTMfund, told the audience at TechCrunch Disrupt last month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The challenge for founders and operators, though, will be threading the needle. While there has been some chatter of startups hiring developers more versed and loosing them on typical GTM problems, he said, there’s still a need for more specific domain expertise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you have great advisors around you can learn some of the tried-and-true playbooks. Those things haven’t gone out the window. I think it’s still necessary that you have a general understanding of how and why certain things work in marketing,” Altschuler said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alison Wagonfeld, vice president of marketing at Google Cloud, said the craft of marketing is still very much required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “You certainly need the AI knowledge, the AI curiosity, the technologists, but also understanding what the purpose of marketing is, to understand customer insights, to do research, to see what great creative is like,” Wagonfeld said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Teams that adopt AI, though, can move more quickly “You can just get out there with so many more messages faster, and then you can think more holistically about what metrics am I driving for,” , she added. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marc Manara, head of startups at OpenAI, has found many startups have embraced AI in their GTM strategy, though it’s not necessarily with the sole focus of minimizing how many resources they put toward it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s a movement of, yes, you can do more with less, but you can also be very focused with how you do it,” he said. “The degree of personalization and signal following that you can do with AI is differentiated now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, he said there are tools that help build leads which are much more sophisticated than in the past. Rather than just a simple query of a database, AI prompts can help startups find prospective customers that fit a very specific set of requirements.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inbound marketing has changed, too, he added, by using the results of those prompts to qualify and score inbound leads “with a lot more precision could have been in the past.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it comes time for a startup to begin crafting its go-to-market strategy, Wagonfeld said its important to consider what qualities it might want in a GTM team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a change in hiring perspective, where the past it was more about hiring specialists, people who really knew, sometimes even like a sub-specialty within marketing or within sales. And now it’s hiring for a sense of curiosity and understanding,” she said. “It’s almost the top thing to hire for now.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/28/how-openai-and-google-see-ai-changing-go-to-market-strategies/</guid><pubDate>Fri, 28 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] What to be thankful for in AI in 2025 (AI | VentureBeat)</title><link>https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025</link><description>[unable to retrieve full-text content]&lt;p&gt;Hello, dear readers. Happy belated Thanksgiving and Black Friday!&lt;/p&gt;&lt;p&gt;This year has felt like living inside a permanent DevDay. Every week, some lab drops a new model, a new agent framework, or a new “this changes everything” demo. It’s overwhelming. But it’s also the first year I’ve felt like AI is finally diversifying — not just one or two frontier models in the cloud, but a whole ecosystem: open and closed, giant and tiny, Western and Chinese, cloud and local.&lt;/p&gt;&lt;p&gt;So for this Thanksgiving edition, here’s what I’m genuinely thankful for in AI in 2025 — the releases that feel like they’ll matter in 12–24 months, not just during this week’s hype cycle.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;1. OpenAI kept shipping strong: GPT-5, GPT-5.1, Atlas, Sora 2 and open weights&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As the company that undeniably birthed the &amp;quot;generative AI&amp;quot; era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. &lt;/p&gt;&lt;p&gt;Thankfully, OpenAI rose to the challenge and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;November by GPT-5.1 &lt;/a&gt;with new Instant and Thinking variants that dynamically adjust how much “thinking time” they spend per task. &lt;/p&gt;&lt;p&gt;In practice, GPT-5’s launch was bumpy — VentureBeat documented early math and coding failures and a cooler-than-expected community reaction in “&lt;a href="https://venturebeat.com/ai/openais-gpt-5-rollout-is-not-going-smoothly"&gt;OpenAI’s GPT-5 rollout is not going smoothly&lt;/a&gt;,&amp;quot; but it quickly course corrected based on user feedback and, as a daily user of this model, I&amp;#x27;m personally pleased with it and impressed with it. &lt;/p&gt;&lt;p&gt;At the same time, enterprises actually using the models are reporting solid gains. &lt;a href="https://www.linkedin.com/company/zendesk-global/"&gt;ZenDesk Global&lt;/a&gt;, for example, &lt;a href="https://venturebeat.com/ai/zendesk-reports-30-faster-response-95-reliability-after-gpt-5-integration?utm_source=chatgpt.com"&gt;says GPT-5-powered agents now resolve more than half of customer tickets&lt;/a&gt;, with some customers seeing 80–90% resolution rates. That’s the quiet story: these models may not always impress the chattering classes on X, but they’re starting to move real KPIs.&lt;/p&gt;&lt;p&gt;On the tooling side, OpenAI finally gave developers a serious AI engineer with GPT-5.1-Codex-Max, a new coding model that can run long, agentic workflows and is already the default in OpenAI’s Codex environment. VentureBeat covered it in detail in “&lt;a href="https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24"&gt;OpenAI debuts GPT-5.1-Codex-Max coding model and it already completed a 24-hour task internally&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;Then there’s ChatGPT Atlas, &lt;a href="https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google"&gt;a full browser with ChatGPT baked into the chrome itself&lt;/a&gt; — sidebar summaries, on-page analysis, and search tightly integrated into regular browsing. It’s the clearest sign yet that “assistant” and “browser” are on a collision course.&lt;/p&gt;&lt;p&gt;On the media side, Sora 2 turned the original Sora video demo into a full video-and-audio model with better physics, synchronized sound and dialogue, and more control over style and shot structure, plus &lt;a href="https://venturebeat.com/ai/openai-debuts-sora-2-ai-video-generator-app-with-sound-and-self-insertion"&gt;a dedicated Sora app&lt;/a&gt; with a full fledged social networking component, allowing any user to &lt;a href="https://www.linkedin.com/pulse/your-own-personalized-tv-network-pocket-reflections-sora-mwz3e/?trackingId=F0O9AmNbiyBUvYozY3z8Dw%3D%3D"&gt;create their own TV network in their pocket&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Finally — and maybe most symbolically — &lt;a href="https://venturebeat.com/ai/openai-returns-to-open-source-roots-with-new-models-gpt-oss-120b-and-gpt-oss-20b"&gt;OpenAI released gpt-oss-120B and gpt-oss-20B&lt;/a&gt;, open-weight MoE reasoning models under an Apache 2.0–style license. Whatever you think of their quality (and early open-source users have been loud about their complaints), this is the first time since GPT-2 that OpenAI has put serious weights into the public commons.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;2. China’s open-source wave goes mainstream&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2023–24 was about Llama and Mistral, 2025 belongs to China’s open-weight ecosystem.&lt;/p&gt;&lt;p&gt;A study from MIT and Hugging Face found that &lt;a href="https://www.ft.com/content/931c8218-a9d7-4cbd-8b08-27516637ff41?utm_source=chatgpt.com"&gt;China now slightly leads the U.S. in global open-model downloads&lt;/a&gt;, largely thanks to DeepSeek and Alibaba’s Qwen family. &lt;/p&gt;&lt;p&gt;Highlights:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;DeepSeek-R1 &lt;/b&gt;&lt;a href="https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek"&gt;dropped in January&lt;/a&gt; as an open-source reasoning model rivaling OpenAI’s o1, with MIT-licensed weights and a family of distilled smaller models. VentureBeat has followed the story from its release to its &lt;a href="https://venturebeat.com/security/deepseek-helps-speed-up-threat-detection-while-raising-national-security-concerns"&gt;cybersecurity impact&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh?utm_source=chatgpt.com"&gt;performance-tuned R1 variants&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Kimi K2 Thinking &lt;/b&gt;from Moonshot, a “thinking” open-source model that reasons step-by-step with tools, very much in the o1/R1 mold, and is positioned as &lt;a href="https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming"&gt;the best open reasoning model so far in the world.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Z.ai&lt;/b&gt; shipped &lt;a href="https://venturebeat.com/ai/chinese-startup-z-ai-launches-powerful-open-source-glm-4-5-model-family-with-powerpoint-creation"&gt;GLM-4.5 and GLM-4.5-Air&lt;/a&gt; as “agentic” models, open-sourcing base and hybrid reasoning variants on GitHub.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Baidu’s &lt;b&gt;ERNIE 4.5 &lt;/b&gt;family arrived as a fully open-sourced, multimodal MoE suite under Apache 2.0, including a 0.3B dense model and visual “&lt;a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"&gt;Thinking&lt;/a&gt;” variants focused on charts, STEM, and tool use.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alibaba’s &lt;b&gt;Qwen3 &lt;/b&gt;line — including Qwen3-Coder, large reasoning models, and the Qwen3-VL series released over the summer and fall months of 2025 — continues to set a high bar for open weights in coding, translation, and multimodal reasoning, leading me to declare this past summer as &amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks"&gt;Qwen&amp;#x27;s summer.&lt;/a&gt;&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;VentureBeat has been tracking these shifts, including Chinese math and reasoning models like &lt;a href="https://venturebeat.com/ai/new-open-source-math-model-light-r1-32b-surpasses-equivalent-deepseek-performance-with-only-1000-in-training-costs?utm_source=chatgpt.com"&gt;Light-R1-32B&lt;/a&gt; and Weibo’s tiny &lt;a href="https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on"&gt;VibeThinker-1.5B&lt;/a&gt;, which beat DeepSeek baselines on shoestring training budgets.&lt;/p&gt;&lt;p&gt;If you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3. Small and local models grow up&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another thing I’m thankful for: we’re finally getting &lt;i&gt;good&lt;/i&gt; small models, not just toys.&lt;/p&gt;&lt;p&gt;Liquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and &lt;a href="https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model"&gt;LFM2-VL vision-language variants&lt;/a&gt;, designed from day one for low-latency, device-aware deployments — edge boxes, robots, and constrained servers, not just giant clusters. The newer &lt;a href="https://www.liquid.ai/blog/lfm2-vl-3b-a-new-efficient-vision-language-for-the-edge"&gt;LFM2-VL-3B&lt;/a&gt; targets embedded robotics and industrial autonomy, with demos planned at ROSCon. &lt;/p&gt;&lt;p&gt;On the big-tech side, &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;Google’s Gemma 3 line&lt;/a&gt; made a strong case that “tiny” can still be capable. Gemma 3 spans from 270M parameters up through 27B, all with open weights and multimodal support in the larger variants. &lt;/p&gt;&lt;p&gt;The standout is Gemma 3 270M, a compact model purpose-built for fine-tuning and structured text tasks — think custom formatters, routers, and watchdogs — covered both in Google’s developer blog and community discussions in local-LLM circles. &lt;/p&gt;&lt;p&gt;These models may never trend on X, but they’re exactly what you need for privacy-sensitive workloads, offline workflows, thin-client devices, and “agent swarms” where you don’t want every tool call hitting a giant frontier LLM.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4. Meta + Midjourney: aesthetics as a service&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of the stranger twists this year: Meta partnered with Midjourney instead of simply trying to beat it.&lt;/p&gt;&lt;p&gt;In August, Meta announced a deal to license Midjourney’s “aesthetic technology” — its image and video generation stack — and integrate it into Meta’s future models and products, from Facebook and Instagram feeds to Meta AI features.&lt;/p&gt;&lt;p&gt;VentureBeat covered the partnership in “&lt;a href="https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products"&gt;Meta is partnering with Midjourney and will license its technology for future models and products&lt;/a&gt;,” raising the obvious question: does this slow or reshape Midjourney’s own API roadmap? Still awaiting an answer there, but unfortunately, stated plans for an API release have yet to materialize, suggesting that it has. &lt;/p&gt;&lt;p&gt;For creators and brands, though, the immediate implication is simple: Midjourney-grade visuals start to show up in mainstream social tools instead of being locked away in a Discord bot. That could normalize higher-quality AI art for a much wider audience — and force rivals like OpenAI, Google, and Black Forest Labs to keep raising the bar.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;5. Google’s Gemini 3 and Nano Banana Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google tried to answer GPT-5 with Gemini 3, billed as its most capable model yet, with better reasoning, coding, and multimodal understanding, plus a new Deep Think mode for slow, hard problems. &lt;/p&gt;&lt;p&gt;VentureBeat’s coverage, “&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI&lt;/a&gt;,” framed it as a direct shot at frontier benchmarks and agentic workflows. &lt;/p&gt;&lt;p&gt;But the surprise hit is &lt;a href="https://venturebeat.com/ai/googles-upgraded-nano-banana-pro-ai-image-model-hailed-as-absolutely-bonkers"&gt;Nano Banana Pro (Gemini 3 Pro Image), Google’s new flagship image generator&lt;/a&gt;. It specializes in infographics, diagrams, multi-subject scenes, and multilingual text that actually renders legibly across 2K and 4K resolutions. &lt;/p&gt;&lt;p&gt;In the world of enterprise AI — where charts, product schematics, and “explain this system visually” images matter more than fantasy dragons — that’s a big deal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;6. Wild cards I’m keeping an eye on&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A few more releases I’m thankful for, even if they don’t fit neatly into one bucket:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Black Forest Labs’ Flux.2&lt;/b&gt; image models, which launched just earlier this week with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “&lt;a href="https://venturebeat.com/ai/black-forest-labs-launches-flux-2-ai-image-models-to-challenge-nano-banana"&gt;Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Anthropic’s Claude Opus 4.5&lt;/b&gt;, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, covered in “&lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding-skills-that-beat-humans"&gt;Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans&lt;/a&gt;.&amp;quot; &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Last thought (for now)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2024 was the year of “one big model in the cloud,” 2025 is the year the map exploded: multiple frontiers at the top, China taking the lead in open models, small and efficient systems maturing fast, and creative ecosystems like Midjourney getting pulled into big-tech stacks.&lt;/p&gt;&lt;p&gt;I’m thankful not just for any single model, but for the fact that we now have &lt;i&gt;options&lt;/i&gt; — closed and open, local and hosted, reasoning-first and media-first. For journalists, builders, and enterprises, that diversity is the real story of 2025.&lt;/p&gt;&lt;p&gt;Happy holidays and best to you and your loved ones!&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Hello, dear readers. Happy belated Thanksgiving and Black Friday!&lt;/p&gt;&lt;p&gt;This year has felt like living inside a permanent DevDay. Every week, some lab drops a new model, a new agent framework, or a new “this changes everything” demo. It’s overwhelming. But it’s also the first year I’ve felt like AI is finally diversifying — not just one or two frontier models in the cloud, but a whole ecosystem: open and closed, giant and tiny, Western and Chinese, cloud and local.&lt;/p&gt;&lt;p&gt;So for this Thanksgiving edition, here’s what I’m genuinely thankful for in AI in 2025 — the releases that feel like they’ll matter in 12–24 months, not just during this week’s hype cycle.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;1. OpenAI kept shipping strong: GPT-5, GPT-5.1, Atlas, Sora 2 and open weights&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As the company that undeniably birthed the &amp;quot;generative AI&amp;quot; era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. &lt;/p&gt;&lt;p&gt;Thankfully, OpenAI rose to the challenge and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;November by GPT-5.1 &lt;/a&gt;with new Instant and Thinking variants that dynamically adjust how much “thinking time” they spend per task. &lt;/p&gt;&lt;p&gt;In practice, GPT-5’s launch was bumpy — VentureBeat documented early math and coding failures and a cooler-than-expected community reaction in “&lt;a href="https://venturebeat.com/ai/openais-gpt-5-rollout-is-not-going-smoothly"&gt;OpenAI’s GPT-5 rollout is not going smoothly&lt;/a&gt;,&amp;quot; but it quickly course corrected based on user feedback and, as a daily user of this model, I&amp;#x27;m personally pleased with it and impressed with it. &lt;/p&gt;&lt;p&gt;At the same time, enterprises actually using the models are reporting solid gains. &lt;a href="https://www.linkedin.com/company/zendesk-global/"&gt;ZenDesk Global&lt;/a&gt;, for example, &lt;a href="https://venturebeat.com/ai/zendesk-reports-30-faster-response-95-reliability-after-gpt-5-integration?utm_source=chatgpt.com"&gt;says GPT-5-powered agents now resolve more than half of customer tickets&lt;/a&gt;, with some customers seeing 80–90% resolution rates. That’s the quiet story: these models may not always impress the chattering classes on X, but they’re starting to move real KPIs.&lt;/p&gt;&lt;p&gt;On the tooling side, OpenAI finally gave developers a serious AI engineer with GPT-5.1-Codex-Max, a new coding model that can run long, agentic workflows and is already the default in OpenAI’s Codex environment. VentureBeat covered it in detail in “&lt;a href="https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24"&gt;OpenAI debuts GPT-5.1-Codex-Max coding model and it already completed a 24-hour task internally&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;Then there’s ChatGPT Atlas, &lt;a href="https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google"&gt;a full browser with ChatGPT baked into the chrome itself&lt;/a&gt; — sidebar summaries, on-page analysis, and search tightly integrated into regular browsing. It’s the clearest sign yet that “assistant” and “browser” are on a collision course.&lt;/p&gt;&lt;p&gt;On the media side, Sora 2 turned the original Sora video demo into a full video-and-audio model with better physics, synchronized sound and dialogue, and more control over style and shot structure, plus &lt;a href="https://venturebeat.com/ai/openai-debuts-sora-2-ai-video-generator-app-with-sound-and-self-insertion"&gt;a dedicated Sora app&lt;/a&gt; with a full fledged social networking component, allowing any user to &lt;a href="https://www.linkedin.com/pulse/your-own-personalized-tv-network-pocket-reflections-sora-mwz3e/?trackingId=F0O9AmNbiyBUvYozY3z8Dw%3D%3D"&gt;create their own TV network in their pocket&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Finally — and maybe most symbolically — &lt;a href="https://venturebeat.com/ai/openai-returns-to-open-source-roots-with-new-models-gpt-oss-120b-and-gpt-oss-20b"&gt;OpenAI released gpt-oss-120B and gpt-oss-20B&lt;/a&gt;, open-weight MoE reasoning models under an Apache 2.0–style license. Whatever you think of their quality (and early open-source users have been loud about their complaints), this is the first time since GPT-2 that OpenAI has put serious weights into the public commons.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;2. China’s open-source wave goes mainstream&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2023–24 was about Llama and Mistral, 2025 belongs to China’s open-weight ecosystem.&lt;/p&gt;&lt;p&gt;A study from MIT and Hugging Face found that &lt;a href="https://www.ft.com/content/931c8218-a9d7-4cbd-8b08-27516637ff41?utm_source=chatgpt.com"&gt;China now slightly leads the U.S. in global open-model downloads&lt;/a&gt;, largely thanks to DeepSeek and Alibaba’s Qwen family. &lt;/p&gt;&lt;p&gt;Highlights:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;DeepSeek-R1 &lt;/b&gt;&lt;a href="https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek"&gt;dropped in January&lt;/a&gt; as an open-source reasoning model rivaling OpenAI’s o1, with MIT-licensed weights and a family of distilled smaller models. VentureBeat has followed the story from its release to its &lt;a href="https://venturebeat.com/security/deepseek-helps-speed-up-threat-detection-while-raising-national-security-concerns"&gt;cybersecurity impact&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh?utm_source=chatgpt.com"&gt;performance-tuned R1 variants&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Kimi K2 Thinking &lt;/b&gt;from Moonshot, a “thinking” open-source model that reasons step-by-step with tools, very much in the o1/R1 mold, and is positioned as &lt;a href="https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming"&gt;the best open reasoning model so far in the world.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Z.ai&lt;/b&gt; shipped &lt;a href="https://venturebeat.com/ai/chinese-startup-z-ai-launches-powerful-open-source-glm-4-5-model-family-with-powerpoint-creation"&gt;GLM-4.5 and GLM-4.5-Air&lt;/a&gt; as “agentic” models, open-sourcing base and hybrid reasoning variants on GitHub.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Baidu’s &lt;b&gt;ERNIE 4.5 &lt;/b&gt;family arrived as a fully open-sourced, multimodal MoE suite under Apache 2.0, including a 0.3B dense model and visual “&lt;a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"&gt;Thinking&lt;/a&gt;” variants focused on charts, STEM, and tool use.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alibaba’s &lt;b&gt;Qwen3 &lt;/b&gt;line — including Qwen3-Coder, large reasoning models, and the Qwen3-VL series released over the summer and fall months of 2025 — continues to set a high bar for open weights in coding, translation, and multimodal reasoning, leading me to declare this past summer as &amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks"&gt;Qwen&amp;#x27;s summer.&lt;/a&gt;&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;VentureBeat has been tracking these shifts, including Chinese math and reasoning models like &lt;a href="https://venturebeat.com/ai/new-open-source-math-model-light-r1-32b-surpasses-equivalent-deepseek-performance-with-only-1000-in-training-costs?utm_source=chatgpt.com"&gt;Light-R1-32B&lt;/a&gt; and Weibo’s tiny &lt;a href="https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on"&gt;VibeThinker-1.5B&lt;/a&gt;, which beat DeepSeek baselines on shoestring training budgets.&lt;/p&gt;&lt;p&gt;If you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3. Small and local models grow up&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another thing I’m thankful for: we’re finally getting &lt;i&gt;good&lt;/i&gt; small models, not just toys.&lt;/p&gt;&lt;p&gt;Liquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and &lt;a href="https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model"&gt;LFM2-VL vision-language variants&lt;/a&gt;, designed from day one for low-latency, device-aware deployments — edge boxes, robots, and constrained servers, not just giant clusters. The newer &lt;a href="https://www.liquid.ai/blog/lfm2-vl-3b-a-new-efficient-vision-language-for-the-edge"&gt;LFM2-VL-3B&lt;/a&gt; targets embedded robotics and industrial autonomy, with demos planned at ROSCon. &lt;/p&gt;&lt;p&gt;On the big-tech side, &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;Google’s Gemma 3 line&lt;/a&gt; made a strong case that “tiny” can still be capable. Gemma 3 spans from 270M parameters up through 27B, all with open weights and multimodal support in the larger variants. &lt;/p&gt;&lt;p&gt;The standout is Gemma 3 270M, a compact model purpose-built for fine-tuning and structured text tasks — think custom formatters, routers, and watchdogs — covered both in Google’s developer blog and community discussions in local-LLM circles. &lt;/p&gt;&lt;p&gt;These models may never trend on X, but they’re exactly what you need for privacy-sensitive workloads, offline workflows, thin-client devices, and “agent swarms” where you don’t want every tool call hitting a giant frontier LLM.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4. Meta + Midjourney: aesthetics as a service&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of the stranger twists this year: Meta partnered with Midjourney instead of simply trying to beat it.&lt;/p&gt;&lt;p&gt;In August, Meta announced a deal to license Midjourney’s “aesthetic technology” — its image and video generation stack — and integrate it into Meta’s future models and products, from Facebook and Instagram feeds to Meta AI features.&lt;/p&gt;&lt;p&gt;VentureBeat covered the partnership in “&lt;a href="https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products"&gt;Meta is partnering with Midjourney and will license its technology for future models and products&lt;/a&gt;,” raising the obvious question: does this slow or reshape Midjourney’s own API roadmap? Still awaiting an answer there, but unfortunately, stated plans for an API release have yet to materialize, suggesting that it has. &lt;/p&gt;&lt;p&gt;For creators and brands, though, the immediate implication is simple: Midjourney-grade visuals start to show up in mainstream social tools instead of being locked away in a Discord bot. That could normalize higher-quality AI art for a much wider audience — and force rivals like OpenAI, Google, and Black Forest Labs to keep raising the bar.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;5. Google’s Gemini 3 and Nano Banana Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google tried to answer GPT-5 with Gemini 3, billed as its most capable model yet, with better reasoning, coding, and multimodal understanding, plus a new Deep Think mode for slow, hard problems. &lt;/p&gt;&lt;p&gt;VentureBeat’s coverage, “&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI&lt;/a&gt;,” framed it as a direct shot at frontier benchmarks and agentic workflows. &lt;/p&gt;&lt;p&gt;But the surprise hit is &lt;a href="https://venturebeat.com/ai/googles-upgraded-nano-banana-pro-ai-image-model-hailed-as-absolutely-bonkers"&gt;Nano Banana Pro (Gemini 3 Pro Image), Google’s new flagship image generator&lt;/a&gt;. It specializes in infographics, diagrams, multi-subject scenes, and multilingual text that actually renders legibly across 2K and 4K resolutions. &lt;/p&gt;&lt;p&gt;In the world of enterprise AI — where charts, product schematics, and “explain this system visually” images matter more than fantasy dragons — that’s a big deal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;6. Wild cards I’m keeping an eye on&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A few more releases I’m thankful for, even if they don’t fit neatly into one bucket:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Black Forest Labs’ Flux.2&lt;/b&gt; image models, which launched just earlier this week with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “&lt;a href="https://venturebeat.com/ai/black-forest-labs-launches-flux-2-ai-image-models-to-challenge-nano-banana"&gt;Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Anthropic’s Claude Opus 4.5&lt;/b&gt;, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, covered in “&lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding-skills-that-beat-humans"&gt;Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans&lt;/a&gt;.&amp;quot; &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Last thought (for now)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2024 was the year of “one big model in the cloud,” 2025 is the year the map exploded: multiple frontiers at the top, China taking the lead in open models, small and efficient systems maturing fast, and creative ecosystems like Midjourney getting pulled into big-tech stacks.&lt;/p&gt;&lt;p&gt;I’m thankful not just for any single model, but for the fact that we now have &lt;i&gt;options&lt;/i&gt; — closed and open, local and hosted, reasoning-first and media-first. For journalists, builders, and enterprises, that diversity is the real story of 2025.&lt;/p&gt;&lt;p&gt;Happy holidays and best to you and your loved ones!&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025</guid><pubDate>Fri, 28 Nov 2025 16:19:00 +0000</pubDate></item><item><title>[NEW] Supabase CEO on the “painful” decisions that built a $5B company (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/supabase-ceo-on-the-painful-decisions-that-built-a-5b-company/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Supabase-Ant-Wilson-Paul-Copplestone.jpg?w=1067" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Listen to the full episode to hear about:&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why&amp;nbsp;Copplestone&amp;nbsp;believes “the death of Oracle won’t take a generation”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;The technical moonshots&amp;nbsp;Supabase&amp;nbsp;is funding to make Postgres even more scalable&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How he decides which enterprise deals to turn down, and why it still “feels very painful”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Supabase-Ant-Wilson-Paul-Copplestone.jpg?w=1067" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Listen to the full episode to hear about:&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why&amp;nbsp;Copplestone&amp;nbsp;believes “the death of Oracle won’t take a generation”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;The technical moonshots&amp;nbsp;Supabase&amp;nbsp;is funding to make Postgres even more scalable&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How he decides which enterprise deals to turn down, and why it still “feels very painful”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/supabase-ceo-on-the-painful-decisions-that-built-a-5b-company/</guid><pubDate>Fri, 28 Nov 2025 17:20:00 +0000</pubDate></item></channel></rss>