<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 14 Nov 2025 18:31:49 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Visa builds AI commerce infrastructure for the Asia Pacific’s 2026 Pilot (AI News)</title><link>https://www.artificialintelligence-news.com/news/visa-ai-commerce-intelligent-commerce-2026/</link><description>&lt;p&gt;When Visa&amp;nbsp;unveiled&amp;nbsp;its Intelligent Commerce platform for Asia Pacific on November 12, it wasn’t just launching another payment feature—it was building AI commerce infrastructure to solve a crisis most merchants haven’t noticed yet: their websites are&amp;nbsp;being flooded&amp;nbsp;by AI agents, and there’s no reliable way to tell which ones are legitimate shoppers and which are malicious bots.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With AI-driven traffic to retail sites exploding by 4,700% in just one year, Visa’s early 2026 regional pilots give businesses 14 months to prepare their payment systems for a world where artificial intelligence handles shopping and transactions on behalf of consumers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-asia-pacific-why-now"&gt;Why Asia Pacific, why now&lt;/h3&gt;&lt;p&gt;Visa’s strategic decision to pilot its agentic commerce capabilities in Asia Pacific by early 2026 reflects more than a geographic preference—it acknowledges the region’s leadership in mobile payments adoption and digital-first consumer behaviour.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Deploying the AI commerce infrastructure represents a fundamental architectural shift: payment systems designed from the ground up to accommodate machine-initiated transactions at speeds and volumes beyond what human shoppers can handle.&lt;/p&gt;&lt;p&gt;“Agentic commerce is transforming the very fabric of online payment transactions, requiring a unified ecosystem to unlock its full potential,” said T.R. Ramachandran, head of products and solutions for Asia Pacific at Visa.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“With Visa Intelligent Commerce and its cornerstone, Trusted Agent Protocol, Visa is connecting consumers, AI agents and merchants through secure, scalable solutions.” The numbers underscore why this infrastructure matters now.&amp;nbsp;&lt;/p&gt;&lt;p&gt;According to Adobe Data Insights cited in Visa’s announcement, 85% of consumers who’ve used AI for shopping report improved experiences. But this enthusiasm masks a brewing crisis: merchants can’t reliably distinguish between legitimate AI agents making purchases and sophisticated bots attempting fraud or data scraping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-technical-architecture-behind-agentic-commerce"&gt;The technical architecture behind Agentic Commerce&lt;/h3&gt;&lt;p&gt;Visa Intelligent Commerce comprises integrated APIs spanning tokenisation, authentication, payment instructions, and transaction signals—creating what amounts to a new protocol layer for AI commerce infrastructure.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At its core sits the Trusted Agent Protocol, which uses agent-specific cryptographic signatures to verify that AI assistants possess genuine commerce intent and valid consumer authorisation. This verification layer solves a problem that traditional payment security&amp;nbsp;wasn’t designed&amp;nbsp;to address.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Fraud detection systems identify suspicious patterns in human behaviour—unusual purchase locations, strange timing, or atypical product combinations. AI agents naturally exhibit behaviour that would trigger these alerts: simultaneous transactions across multiple merchants, machine-speed checkouts, and purchasing patterns optimised by algorithms rather than human impulse.&lt;/p&gt;&lt;p&gt;The infrastructure Visa is building maintains consumer visibility even as AI intermediates transactions. When an AI agent books a hotel or orders groceries, merchants can still identify the actual consumer, preserving customer relationship data that businesses depend on for marketing, loyalty programs, and service personalisation.&lt;/p&gt;&lt;p&gt;Critically, Visa designed its AI commerce infrastructure as an open, low-code framework. This architectural choice lowers integration barriers for merchants while enabling interoperability across the ecosystem of AI platforms, payment processors, and commerce applications emerging across the Asia Pacific.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-ecosystem-emerging-around-ai-payments"&gt;The ecosystem emerging around AI payments&lt;/h3&gt;&lt;p&gt;Visa’s partnerships with Ant International, LG Uplus, Microsoft, Perplexity, Stripe, and Tencent reveal the collaborative nature of building AI commerce infrastructure at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;These aren’t traditional payment processing relationships—they represent nodes in a network where AI agents will need to authenticate across platforms, access payment credentials&amp;nbsp;securely, and execute transactions that span multiple services&amp;nbsp;ina single consumer intent.&lt;/p&gt;&lt;p&gt;Consider a scenario&amp;nbsp;where&amp;nbsp;a consumer tells Microsoft’s AI assistant&amp;nbsp;to&amp;nbsp;“plan&amp;nbsp;a weekend in Kuala Lumpur.”&amp;nbsp;The agent might use Perplexity to research options, Stripe to process&amp;nbsp;payment for flights, and transact on Visa’s network—all while maintaining secure authentication and consumer authorisation throughout the journey.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This&amp;nbsp;requires infrastructure that enables seamless handoffs between platforms while maintaining security and transparency.&amp;nbsp;The early 2026 pilot timeline suggests that Visa is moving in parallel with regulatory frameworks still taking shape across&amp;nbsp;the&amp;nbsp;Asia Pacific markets.&amp;nbsp;Different countries will approach AI agent authorisation, consumer protection in automated transactions, and cross-border AI commerce differently—creating complexity that will inform global standards as the technology scales.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-for-digital-commerce"&gt;What this means for digital commerce&lt;/h3&gt;&lt;p&gt;The shift toward AI-mediated transactions changes fundamental assumptions about online retail. Consumer journeys that traditionally involved browsing, comparing, and clicking “buy” will increasingly happen through conversational instructions to AI assistants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Merchants optimising for human attention spans and click-through rates will need to rethink strategies for an environment where AI agents evaluate options&amp;nbsp;through algorithmic comparison&amp;nbsp;rather than emotional appeal.&lt;/p&gt;&lt;p&gt;Visa’s AI commerce infrastructure also introduces new competitive dynamics. Businesses that integrate early gain experience with agent-driven sales flows, develop strategies for maintaining customer relationships through AI intermediation, and refine fraud detection for machine-initiated transactions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Those who wait risk operational gaps when consumer adoption reaches critical mass. The payment giant showcased Intelligent Commerce at Singapore Fintech Festival from November 12-14, offering businesses concrete visibility into integration requirements and implementation challenges.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With Visa’s 4.8 billion credentials potentially accessible to AI agents across millions of merchant locations worldwide, the infrastructure&amp;nbsp;being piloted&amp;nbsp;in the Asia Pacific will likely define how agentic commerce operates globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-road-to-2026"&gt;The road to 2026&lt;/h3&gt;&lt;p&gt;Fourteen months until regional pilots launch may sound distant, but the technical, operational, and strategic preparations required make it a tight timeline. Businesses need to audit payment infrastructure for AI compatibility, evaluate customer experience design for agent-mediated interactions, and recalibrate security systems to distinguish legitimate AI commerce from threats.&lt;/p&gt;&lt;p&gt;The AI commerce infrastructure Visa is deploying doesn’t just enable a new payment method—it establishes the foundation for a different model of digital transactions. As the Asia Pacific becomes the proving ground for this transformation, the lessons learned will shape how commerce operates in an AI-driven world.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by: Yoco Photography)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How Huawei is building agentic AI systems that make decisions independently&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;When Visa&amp;nbsp;unveiled&amp;nbsp;its Intelligent Commerce platform for Asia Pacific on November 12, it wasn’t just launching another payment feature—it was building AI commerce infrastructure to solve a crisis most merchants haven’t noticed yet: their websites are&amp;nbsp;being flooded&amp;nbsp;by AI agents, and there’s no reliable way to tell which ones are legitimate shoppers and which are malicious bots.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With AI-driven traffic to retail sites exploding by 4,700% in just one year, Visa’s early 2026 regional pilots give businesses 14 months to prepare their payment systems for a world where artificial intelligence handles shopping and transactions on behalf of consumers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-asia-pacific-why-now"&gt;Why Asia Pacific, why now&lt;/h3&gt;&lt;p&gt;Visa’s strategic decision to pilot its agentic commerce capabilities in Asia Pacific by early 2026 reflects more than a geographic preference—it acknowledges the region’s leadership in mobile payments adoption and digital-first consumer behaviour.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Deploying the AI commerce infrastructure represents a fundamental architectural shift: payment systems designed from the ground up to accommodate machine-initiated transactions at speeds and volumes beyond what human shoppers can handle.&lt;/p&gt;&lt;p&gt;“Agentic commerce is transforming the very fabric of online payment transactions, requiring a unified ecosystem to unlock its full potential,” said T.R. Ramachandran, head of products and solutions for Asia Pacific at Visa.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“With Visa Intelligent Commerce and its cornerstone, Trusted Agent Protocol, Visa is connecting consumers, AI agents and merchants through secure, scalable solutions.” The numbers underscore why this infrastructure matters now.&amp;nbsp;&lt;/p&gt;&lt;p&gt;According to Adobe Data Insights cited in Visa’s announcement, 85% of consumers who’ve used AI for shopping report improved experiences. But this enthusiasm masks a brewing crisis: merchants can’t reliably distinguish between legitimate AI agents making purchases and sophisticated bots attempting fraud or data scraping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-technical-architecture-behind-agentic-commerce"&gt;The technical architecture behind Agentic Commerce&lt;/h3&gt;&lt;p&gt;Visa Intelligent Commerce comprises integrated APIs spanning tokenisation, authentication, payment instructions, and transaction signals—creating what amounts to a new protocol layer for AI commerce infrastructure.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At its core sits the Trusted Agent Protocol, which uses agent-specific cryptographic signatures to verify that AI assistants possess genuine commerce intent and valid consumer authorisation. This verification layer solves a problem that traditional payment security&amp;nbsp;wasn’t designed&amp;nbsp;to address.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Fraud detection systems identify suspicious patterns in human behaviour—unusual purchase locations, strange timing, or atypical product combinations. AI agents naturally exhibit behaviour that would trigger these alerts: simultaneous transactions across multiple merchants, machine-speed checkouts, and purchasing patterns optimised by algorithms rather than human impulse.&lt;/p&gt;&lt;p&gt;The infrastructure Visa is building maintains consumer visibility even as AI intermediates transactions. When an AI agent books a hotel or orders groceries, merchants can still identify the actual consumer, preserving customer relationship data that businesses depend on for marketing, loyalty programs, and service personalisation.&lt;/p&gt;&lt;p&gt;Critically, Visa designed its AI commerce infrastructure as an open, low-code framework. This architectural choice lowers integration barriers for merchants while enabling interoperability across the ecosystem of AI platforms, payment processors, and commerce applications emerging across the Asia Pacific.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-ecosystem-emerging-around-ai-payments"&gt;The ecosystem emerging around AI payments&lt;/h3&gt;&lt;p&gt;Visa’s partnerships with Ant International, LG Uplus, Microsoft, Perplexity, Stripe, and Tencent reveal the collaborative nature of building AI commerce infrastructure at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;These aren’t traditional payment processing relationships—they represent nodes in a network where AI agents will need to authenticate across platforms, access payment credentials&amp;nbsp;securely, and execute transactions that span multiple services&amp;nbsp;ina single consumer intent.&lt;/p&gt;&lt;p&gt;Consider a scenario&amp;nbsp;where&amp;nbsp;a consumer tells Microsoft’s AI assistant&amp;nbsp;to&amp;nbsp;“plan&amp;nbsp;a weekend in Kuala Lumpur.”&amp;nbsp;The agent might use Perplexity to research options, Stripe to process&amp;nbsp;payment for flights, and transact on Visa’s network—all while maintaining secure authentication and consumer authorisation throughout the journey.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This&amp;nbsp;requires infrastructure that enables seamless handoffs between platforms while maintaining security and transparency.&amp;nbsp;The early 2026 pilot timeline suggests that Visa is moving in parallel with regulatory frameworks still taking shape across&amp;nbsp;the&amp;nbsp;Asia Pacific markets.&amp;nbsp;Different countries will approach AI agent authorisation, consumer protection in automated transactions, and cross-border AI commerce differently—creating complexity that will inform global standards as the technology scales.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-for-digital-commerce"&gt;What this means for digital commerce&lt;/h3&gt;&lt;p&gt;The shift toward AI-mediated transactions changes fundamental assumptions about online retail. Consumer journeys that traditionally involved browsing, comparing, and clicking “buy” will increasingly happen through conversational instructions to AI assistants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Merchants optimising for human attention spans and click-through rates will need to rethink strategies for an environment where AI agents evaluate options&amp;nbsp;through algorithmic comparison&amp;nbsp;rather than emotional appeal.&lt;/p&gt;&lt;p&gt;Visa’s AI commerce infrastructure also introduces new competitive dynamics. Businesses that integrate early gain experience with agent-driven sales flows, develop strategies for maintaining customer relationships through AI intermediation, and refine fraud detection for machine-initiated transactions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Those who wait risk operational gaps when consumer adoption reaches critical mass. The payment giant showcased Intelligent Commerce at Singapore Fintech Festival from November 12-14, offering businesses concrete visibility into integration requirements and implementation challenges.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With Visa’s 4.8 billion credentials potentially accessible to AI agents across millions of merchant locations worldwide, the infrastructure&amp;nbsp;being piloted&amp;nbsp;in the Asia Pacific will likely define how agentic commerce operates globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-road-to-2026"&gt;The road to 2026&lt;/h3&gt;&lt;p&gt;Fourteen months until regional pilots launch may sound distant, but the technical, operational, and strategic preparations required make it a tight timeline. Businesses need to audit payment infrastructure for AI compatibility, evaluate customer experience design for agent-mediated interactions, and recalibrate security systems to distinguish legitimate AI commerce from threats.&lt;/p&gt;&lt;p&gt;The AI commerce infrastructure Visa is deploying doesn’t just enable a new payment method—it establishes the foundation for a different model of digital transactions. As the Asia Pacific becomes the proving ground for this transformation, the lessons learned will shape how commerce operates in an AI-driven world.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by: Yoco Photography)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How Huawei is building agentic AI systems that make decisions independently&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/visa-ai-commerce-intelligent-commerce-2026/</guid><pubDate>Fri, 14 Nov 2025 08:00:00 +0000</pubDate></item><item><title>These technologies could help put a stop to animal testing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/14/1127949/technologies-could-stop-animal-testing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/AdobeStock_48611539.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year, according to&amp;nbsp;a strategy released on Tuesday. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Animal welfare groups have been campaigning for commitments like these for decades. But a lack of alternatives has made it difficult to put a stop to animal testing. Advances in medical science and biotechnology are changing that.&lt;/p&gt; 
 &lt;p&gt;Animals have been used in scientific research&amp;nbsp;for thousands of years. Animal experimentation has led to many important discoveries about how the brains and bodies of animals work. And because regulators require drugs to be first tested in research animals, it has played an important role in the creation of medicines and devices for both humans and other animals.&lt;/p&gt;  &lt;p&gt;Today, countries like the UK and the US regulate animal research and require scientists to hold multiple licenses and adhere to rules on animal housing and care. Still, millions of animals are used annually in research. Plenty of scientists don’t want to take part in animal testing. And some question whether animal research is justifiable—especially considering that&amp;nbsp;around 95% of treatments that look promising in animals don’t make it to market.&lt;/p&gt; 
 &lt;p&gt;In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on humans or other animals.&lt;/p&gt;  &lt;p&gt;Take “organs on chips,” for example. Researchers have been creating miniature versions of human organs inside tiny plastic cases. These&amp;nbsp;systems are designed to contain the same mix of cells you’d find in a full-grown organ and receive a supply of nutrients that keeps them alive.&lt;/p&gt;  &lt;p&gt;Today, multiple teams have created models of livers, intestines, hearts, kidneys and even the brain. And they are already being used in research. Heart chips have been sent into space to observe how they respond to low gravity. The FDA used lung chips to assess covid-19 vaccines. Gut chips are being used to study the effects of radiation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Some researchers are even working to connect multiple chips to create a “body on a chip”—although this has been in the works for over a decade and no one has quite managed it yet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In the same vein, others have been working on creating model versions of organs—and even embryos—in the lab. By growing groups of cells into tiny 3D structures, scientists can study how organs develop and work, and even test drugs on them. They can even be personalized—if you take cells from someone, you should be able to model that person’s specific organs. Some researchers have even been able to create organoids of developing fetuses.&lt;/p&gt;  &lt;p&gt;The UK government strategy mentions the promise of artificial intelligence, too. Many scientists have been quick to adopt AI as a tool to help them make sense of vast databases, and to find connections between genes, proteins and disease, for example. Others are&amp;nbsp;using AI to design all-new drugs.&lt;/p&gt;  &lt;p&gt;Those new drugs could potentially be tested on virtual humans. Not flesh-and-blood people, but digital reconstructions that live in a computer. Biomedical engineers have already created digital twins of organs. In ongoing trials, digital hearts are being used to guide surgeons on how—and where—to operate on real hearts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;When I spoke to Natalia Trayanova, the biomedical engineering professor behind this trial, she told me that her model could recommend regions of heart tissue to be burned off as part of treatment for atrial fibrillation. Her tool would normally suggest two or three regions but occasionally would recommend many more. “They just have to trust us,”&amp;nbsp;she told me.&lt;/p&gt; 

 &lt;p&gt;It is unlikely that we’ll completely phase out animal testing by 2030. The UK government acknowledges that animal testing is still required by lots of regulators, including the FDA, the European Medicines Agency, and the World Health Organization. And while alternatives to animal testing have come a long way, none of them perfectly capture how a living body will respond to a treatment.&lt;/p&gt;  &lt;p&gt;At least not yet. Given all the progress that has been made in recent years, it’s not too hard to imagine a future without animal testing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/AdobeStock_48611539.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year, according to&amp;nbsp;a strategy released on Tuesday. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Animal welfare groups have been campaigning for commitments like these for decades. But a lack of alternatives has made it difficult to put a stop to animal testing. Advances in medical science and biotechnology are changing that.&lt;/p&gt; 
 &lt;p&gt;Animals have been used in scientific research&amp;nbsp;for thousands of years. Animal experimentation has led to many important discoveries about how the brains and bodies of animals work. And because regulators require drugs to be first tested in research animals, it has played an important role in the creation of medicines and devices for both humans and other animals.&lt;/p&gt;  &lt;p&gt;Today, countries like the UK and the US regulate animal research and require scientists to hold multiple licenses and adhere to rules on animal housing and care. Still, millions of animals are used annually in research. Plenty of scientists don’t want to take part in animal testing. And some question whether animal research is justifiable—especially considering that&amp;nbsp;around 95% of treatments that look promising in animals don’t make it to market.&lt;/p&gt; 
 &lt;p&gt;In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on humans or other animals.&lt;/p&gt;  &lt;p&gt;Take “organs on chips,” for example. Researchers have been creating miniature versions of human organs inside tiny plastic cases. These&amp;nbsp;systems are designed to contain the same mix of cells you’d find in a full-grown organ and receive a supply of nutrients that keeps them alive.&lt;/p&gt;  &lt;p&gt;Today, multiple teams have created models of livers, intestines, hearts, kidneys and even the brain. And they are already being used in research. Heart chips have been sent into space to observe how they respond to low gravity. The FDA used lung chips to assess covid-19 vaccines. Gut chips are being used to study the effects of radiation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Some researchers are even working to connect multiple chips to create a “body on a chip”—although this has been in the works for over a decade and no one has quite managed it yet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In the same vein, others have been working on creating model versions of organs—and even embryos—in the lab. By growing groups of cells into tiny 3D structures, scientists can study how organs develop and work, and even test drugs on them. They can even be personalized—if you take cells from someone, you should be able to model that person’s specific organs. Some researchers have even been able to create organoids of developing fetuses.&lt;/p&gt;  &lt;p&gt;The UK government strategy mentions the promise of artificial intelligence, too. Many scientists have been quick to adopt AI as a tool to help them make sense of vast databases, and to find connections between genes, proteins and disease, for example. Others are&amp;nbsp;using AI to design all-new drugs.&lt;/p&gt;  &lt;p&gt;Those new drugs could potentially be tested on virtual humans. Not flesh-and-blood people, but digital reconstructions that live in a computer. Biomedical engineers have already created digital twins of organs. In ongoing trials, digital hearts are being used to guide surgeons on how—and where—to operate on real hearts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;When I spoke to Natalia Trayanova, the biomedical engineering professor behind this trial, she told me that her model could recommend regions of heart tissue to be burned off as part of treatment for atrial fibrillation. Her tool would normally suggest two or three regions but occasionally would recommend many more. “They just have to trust us,”&amp;nbsp;she told me.&lt;/p&gt; 

 &lt;p&gt;It is unlikely that we’ll completely phase out animal testing by 2030. The UK government acknowledges that animal testing is still required by lots of regulators, including the FDA, the European Medicines Agency, and the World Health Organization. And while alternatives to animal testing have come a long way, none of them perfectly capture how a living body will respond to a treatment.&lt;/p&gt;  &lt;p&gt;At least not yet. Given all the progress that has been made in recent years, it’s not too hard to imagine a future without animal testing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/14/1127949/technologies-could-stop-animal-testing/</guid><pubDate>Fri, 14 Nov 2025 10:00:00 +0000</pubDate></item><item><title>ChatGPT launches pilot group chats across Japan, New Zealand, South Korea, and Taiwan (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/14/chatgpt-launches-pilot-group-chats-across-japan-new-zealand-south-korea-and-taiwan/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/ChatGPT-Groupchat-pilot-launch.png?w=995" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Thursday introduced a group chat feature for ChatGPT. The feature, currently being tested in select regions, including Japan, New Zealand, South Korea, and Taiwan, lets users collaborate directly within the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat is available to Free, Plus, and Team users on both mobile and web platforms. OpenAI says the pilot is designed to explore how people use group conversations in ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes after earlier reports that OpenAI had been testing a direct-message-style tool. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker describes this pilot as just a “small first step” toward creating a more “shared experience” in the app. Early users will be invited to provide feedback, which the company says will help shape how the feature eventually expands to more regions and offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to OpenAI, private chats and personal ChatGPT memory stay completely private. Group chats are invitation-only, and members can leave at any time. Most participants can remove others, though the group’s creator can only leave voluntarily. For users under 18, content is filtered, with extra safeguards and parental controls in place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting a group chat is easy. Just tap the people icon and add participants, either directly or by sharing a link. Groups can include one to 20 people. If you add someone to an existing chat, a new group is created, leaving the original conversation unchanged. Each group has a short profile, and all chats are organized in a labeled sidebar for easy access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Group chats work just like regular ChatGPT conversations but with multiple people joining in. GPT‑5.1 Auto handles responses and comes loaded with features such as search, image generation, file uploads, and dictation. In group chats, ChatGPT’s usage limits — which restrict how many AI responses users can receive per hour — only count when ChatGPT responds. Messages between human participants don’t count toward these limits.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT has learned new social skills for group chats, knowing when to jump in and when to stay quiet. You can tag “ChatGPT” to get it to respond. It can also react with emojis and use profile photos to create personalized images for the conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat feature represents the latest step in OpenAI’s gradual transformation from a simple AI assistant into something resembling a social platform. In late September, the company launched Sora 2, a stand-alone social media app with a TikTok-style feed for sharing AI-generated videos, complete with algorithmic recommendations based on user activity and location, parental controls, and direct messaging capabilities.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/ChatGPT-Groupchat-pilot-launch.png?w=995" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Thursday introduced a group chat feature for ChatGPT. The feature, currently being tested in select regions, including Japan, New Zealand, South Korea, and Taiwan, lets users collaborate directly within the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat is available to Free, Plus, and Team users on both mobile and web platforms. OpenAI says the pilot is designed to explore how people use group conversations in ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes after earlier reports that OpenAI had been testing a direct-message-style tool. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker describes this pilot as just a “small first step” toward creating a more “shared experience” in the app. Early users will be invited to provide feedback, which the company says will help shape how the feature eventually expands to more regions and offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to OpenAI, private chats and personal ChatGPT memory stay completely private. Group chats are invitation-only, and members can leave at any time. Most participants can remove others, though the group’s creator can only leave voluntarily. For users under 18, content is filtered, with extra safeguards and parental controls in place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting a group chat is easy. Just tap the people icon and add participants, either directly or by sharing a link. Groups can include one to 20 people. If you add someone to an existing chat, a new group is created, leaving the original conversation unchanged. Each group has a short profile, and all chats are organized in a labeled sidebar for easy access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Group chats work just like regular ChatGPT conversations but with multiple people joining in. GPT‑5.1 Auto handles responses and comes loaded with features such as search, image generation, file uploads, and dictation. In group chats, ChatGPT’s usage limits — which restrict how many AI responses users can receive per hour — only count when ChatGPT responds. Messages between human participants don’t count toward these limits.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT has learned new social skills for group chats, knowing when to jump in and when to stay quiet. You can tag “ChatGPT” to get it to respond. It can also react with emojis and use profile photos to create personalized images for the conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat feature represents the latest step in OpenAI’s gradual transformation from a simple AI assistant into something resembling a social platform. In late September, the company launched Sora 2, a stand-alone social media app with a TikTok-style feed for sharing AI-generated videos, complete with algorithmic recommendations based on user activity and location, parental controls, and direct messaging capabilities.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/14/chatgpt-launches-pilot-group-chats-across-japan-new-zealand-south-korea-and-taiwan/</guid><pubDate>Fri, 14 Nov 2025 10:58:08 +0000</pubDate></item><item><title>Anthropic details cyber espionage campaign orchestrated by AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/anthropic-details-cyber-espionage-campaign-orchestrated-by-ai/</link><description>&lt;p&gt;Security leaders face a new class of autonomous threat as Anthropic details the first cyber espionage campaign orchestrated by AI.&lt;/p&gt;&lt;p&gt;In a report released this week, the company’s Threat Intelligence team outlined its disruption of a sophisticated operation by a Chinese state-sponsored group – an assessment made with high confidence – dubbed GTG-1002 and detected in mid-September 2025.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities, including large tech companies, financial institutions, chemical manufacturing companies, and government agencies.&lt;/p&gt;&lt;p&gt;Rather than AI assisting human operators, the attackers successfully manipulated Anthropic’s Claude Code model to function as an autonomous agent to execute the vast majority of tactical operations independently.&lt;/p&gt;&lt;p&gt;This marks a worrying development for CISOs, moving cyber attacks from human-directed efforts to a model where AI agents perform 80-90 percent of the offensive work with humans acting only as high-level supervisors. Anthropic believes this is the first documented case of a large-scale cyberattack executed without substantial human intervention.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-agents-a-new-operational-model-for-cyberattacks"&gt;AI agents: A new operational model for cyberattacks&lt;/h3&gt;&lt;p&gt;The group used an orchestration system that tasked instances of Claude Code to function as autonomous penetration testing agents. These AI agents were directed as part of the espionage campaign to perform reconnaissance, discover vulnerabilities, develop exploits, harvest credentials, move laterally across networks, and exfiltrate data. This enabled the AI to perform reconnaissance in a fraction of the time it would have taken a team of human hackers.&lt;/p&gt;&lt;p&gt;Human involvement was limited to 10-20 percent of the total effort, primarily focused on campaign initiation and providing authorisation at a few key escalation points. For example, human operators would approve the transition from reconnaissance to active exploitation or authorise the final scope of data exfiltration.&lt;/p&gt;&lt;p&gt;The attackers bypassed the AI model’s built-in safeguards, which are trained to avoid harmful behaviours. They did this by jailbreaking the model, tricking it by breaking down attacks into seemingly innocent tasks and by adopting a “role-play” persona. Operators told Claude that it was an employee of a legitimate cybersecurity firm and was being used in defensive testing. This allowed the operation to proceed long enough to gain access to a handful of validated targets.&lt;/p&gt;&lt;p&gt;The technical sophistication of the attack lay not in novel malware, but in orchestration. The report notes the framework relied “overwhelmingly on open-source penetration testing tools”. The attackers used Model Context Protocol (MCP) servers as an interface between the AI and these commodity tools, enabling the AI to execute commands, analyse results, and maintain operational state across multiple targets and sessions. The AI was even directed to research and write its own exploit code for the espionage campaign.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-hallucinations-become-a-good-thing"&gt;AI hallucinations become a good thing&lt;/h3&gt;&lt;p&gt;While the campaign successfully breached high-value targets, Anthropic’s investigation uncovered a noteworthy limitation: the AI hallucinated during offensive operations.&lt;/p&gt;&lt;p&gt;The report states that Claude “frequently overstated findings and occasionally fabricated data”. This manifested as the AI claiming to have obtained credentials that did not work or identifying discoveries that “proved to be publicly available information.”&lt;/p&gt;&lt;p&gt;This tendency required the human operators to carefully validate all results, presenting challenges for the attackers’ operational effectiveness. According to Anthropic, this “remains an obstacle to fully autonomous cyberattacks”. For security leaders, this highlights a potential weakness in AI-driven attacks: they may generate a high volume of noise and false positives that can be identified with robust monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-defensive-ai-arms-race-against-new-cyber-espionage-threats"&gt;A defensive AI arms race against new cyber espionage threats&lt;/h3&gt;&lt;p&gt;The primary implication for business and technology leaders is that the barriers to performing sophisticated cyberattacks have dropped considerably. Groups with fewer resources may now be able to execute campaigns that previously required entire teams of experienced hackers.&lt;/p&gt;&lt;p&gt;This attack demonstrates a capability beyond “vibe hacking,” where humans remained firmly in control of operations. The GTG-1002 campaign proves that AI can be used to autonomously discover and exploit vulnerabilities in live operations.&lt;/p&gt;&lt;p&gt;Anthropic, which banned the accounts and notified authorities over a ten-day investigation, argues that this development shows the urgent need for AI-powered defence. The company states that “the very abilities that allow Claude to be used in these attacks also make it essential for cyber defense”. The company’s own Threat Intelligence team “used Claude extensively to analyse “the enormous amounts of data generated” during this investigation.&lt;/p&gt;&lt;p&gt;Security teams should operate under the assumption that a major change has occurred in cybersecurity. The report urges defenders to “experiment with applying AI for defense in areas like SOC automation, threat detection, vulnerability assessment, and incident response.”&lt;/p&gt;&lt;p&gt;The contest between AI-driven attacks and AI-powered defence has begun, and proactive adaptation to counter new espionage threats is the only viable path forward.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Wiz: Security lapses emerge amid the global AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Security leaders face a new class of autonomous threat as Anthropic details the first cyber espionage campaign orchestrated by AI.&lt;/p&gt;&lt;p&gt;In a report released this week, the company’s Threat Intelligence team outlined its disruption of a sophisticated operation by a Chinese state-sponsored group – an assessment made with high confidence – dubbed GTG-1002 and detected in mid-September 2025.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities, including large tech companies, financial institutions, chemical manufacturing companies, and government agencies.&lt;/p&gt;&lt;p&gt;Rather than AI assisting human operators, the attackers successfully manipulated Anthropic’s Claude Code model to function as an autonomous agent to execute the vast majority of tactical operations independently.&lt;/p&gt;&lt;p&gt;This marks a worrying development for CISOs, moving cyber attacks from human-directed efforts to a model where AI agents perform 80-90 percent of the offensive work with humans acting only as high-level supervisors. Anthropic believes this is the first documented case of a large-scale cyberattack executed without substantial human intervention.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-agents-a-new-operational-model-for-cyberattacks"&gt;AI agents: A new operational model for cyberattacks&lt;/h3&gt;&lt;p&gt;The group used an orchestration system that tasked instances of Claude Code to function as autonomous penetration testing agents. These AI agents were directed as part of the espionage campaign to perform reconnaissance, discover vulnerabilities, develop exploits, harvest credentials, move laterally across networks, and exfiltrate data. This enabled the AI to perform reconnaissance in a fraction of the time it would have taken a team of human hackers.&lt;/p&gt;&lt;p&gt;Human involvement was limited to 10-20 percent of the total effort, primarily focused on campaign initiation and providing authorisation at a few key escalation points. For example, human operators would approve the transition from reconnaissance to active exploitation or authorise the final scope of data exfiltration.&lt;/p&gt;&lt;p&gt;The attackers bypassed the AI model’s built-in safeguards, which are trained to avoid harmful behaviours. They did this by jailbreaking the model, tricking it by breaking down attacks into seemingly innocent tasks and by adopting a “role-play” persona. Operators told Claude that it was an employee of a legitimate cybersecurity firm and was being used in defensive testing. This allowed the operation to proceed long enough to gain access to a handful of validated targets.&lt;/p&gt;&lt;p&gt;The technical sophistication of the attack lay not in novel malware, but in orchestration. The report notes the framework relied “overwhelmingly on open-source penetration testing tools”. The attackers used Model Context Protocol (MCP) servers as an interface between the AI and these commodity tools, enabling the AI to execute commands, analyse results, and maintain operational state across multiple targets and sessions. The AI was even directed to research and write its own exploit code for the espionage campaign.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-hallucinations-become-a-good-thing"&gt;AI hallucinations become a good thing&lt;/h3&gt;&lt;p&gt;While the campaign successfully breached high-value targets, Anthropic’s investigation uncovered a noteworthy limitation: the AI hallucinated during offensive operations.&lt;/p&gt;&lt;p&gt;The report states that Claude “frequently overstated findings and occasionally fabricated data”. This manifested as the AI claiming to have obtained credentials that did not work or identifying discoveries that “proved to be publicly available information.”&lt;/p&gt;&lt;p&gt;This tendency required the human operators to carefully validate all results, presenting challenges for the attackers’ operational effectiveness. According to Anthropic, this “remains an obstacle to fully autonomous cyberattacks”. For security leaders, this highlights a potential weakness in AI-driven attacks: they may generate a high volume of noise and false positives that can be identified with robust monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-defensive-ai-arms-race-against-new-cyber-espionage-threats"&gt;A defensive AI arms race against new cyber espionage threats&lt;/h3&gt;&lt;p&gt;The primary implication for business and technology leaders is that the barriers to performing sophisticated cyberattacks have dropped considerably. Groups with fewer resources may now be able to execute campaigns that previously required entire teams of experienced hackers.&lt;/p&gt;&lt;p&gt;This attack demonstrates a capability beyond “vibe hacking,” where humans remained firmly in control of operations. The GTG-1002 campaign proves that AI can be used to autonomously discover and exploit vulnerabilities in live operations.&lt;/p&gt;&lt;p&gt;Anthropic, which banned the accounts and notified authorities over a ten-day investigation, argues that this development shows the urgent need for AI-powered defence. The company states that “the very abilities that allow Claude to be used in these attacks also make it essential for cyber defense”. The company’s own Threat Intelligence team “used Claude extensively to analyse “the enormous amounts of data generated” during this investigation.&lt;/p&gt;&lt;p&gt;Security teams should operate under the assumption that a major change has occurred in cybersecurity. The report urges defenders to “experiment with applying AI for defense in areas like SOC automation, threat detection, vulnerability assessment, and incident response.”&lt;/p&gt;&lt;p&gt;The contest between AI-driven attacks and AI-powered defence has begun, and proactive adaptation to counter new espionage threats is the only viable path forward.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Wiz: Security lapses emerge amid the global AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/anthropic-details-cyber-espionage-campaign-orchestrated-by-ai/</guid><pubDate>Fri, 14 Nov 2025 11:34:00 +0000</pubDate></item><item><title>Inside Harvey: How a first-year legal associate built one of Silicon Valley’s hottest startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/14/inside-harvey-how-a-first-year-legal-associate-built-one-of-silicon-valleys-hottest-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-14-at-11.50.31-AM.png?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal AI might not sound like the sexiest category in Silicon Valley, but Harvey‘s CEO Winston Weinberg has captured the attention of virtually every top-tier investor in the Valley. The company’s cap table reads like a who’s who of venture capital: the OpenAI Startup Fund (its first institutional investor), Sequoia Capital, Kleiner Perkins, Elad Gil, Google Ventures, Coatue, and most recently, Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco-based company’s valuation skyrocketed from $3 billion in February 2025 to $5 billion in June to $8 billion in late October — a rise that reflects both the bonkers price tags awarded to AI companies and Harvey’s ability to win over major law firms and corporate legal departments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fact, the startup now claims 700 clients across 63 countries, including a majority of the top 10 U.S. law firms. It also says it surpassed $100 million in annual recurring revenue as of August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke with Weinberg for this week’s StrictlyVC Download podcast to ask about the wild ride that he and co-founder Gabe Pereyra have been on so far. During that chat, he shared how a cold email sent a few summers ago to Sam Altman changed everything; why he believes lawyers will benefit rather than suffer from AI; and how Harvey is tackling the technically complex challenge of building a truly multiplayer platform that navigates ethical walls and data permissioning across dozens of countries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This interview has been edited lightly for length. For the full monty, check out the podcast.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You started as a first-year associate at O’Melveny &amp;amp; Myers. When did you realize AI could transform legal work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So my co-founder was working at Meta at the time; he was also my roommate. He was showing me GPT-3, and in the beginning, I swear to God, the main use case I had for it was running a Dungeons and Dragons game with friends in LA. Then I was assigned to this landlord-tenant case at O’Melveny, and I didn’t know anything about landlord-tenant law. I started using GPT-3 to work on it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;My co-founder Gabe and I figured out we could do chain-of-thought prompting before that was really a thing. We created this super long chain-of-thought prompt over California landlord-tenant statutes. We grabbed 100 questions from r/legaladvice [on Reddit] and ran that prompt over them, then gave the question-answer pairs to three landlord-tenant attorneys without saying anything about AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We just said, “A potential customer asked this question, here’s the answer — would you make any edits or would you send this as is?” On 86 of the 100 samples, two out of three attorneys or more said they would send it with zero edits. That was the moment when we were like, wow, this entire industry can be transformed by this technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What happened next?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We cold-emailed Sam Altman and Jason Kwon, who was the general counsel at OpenAI. We figured we had to email a lawyer because otherwise the person wouldn’t know if the outputs were right. On the morning of July 4 at 10 a.m. — I remember this specifically because it was July 4 — we got on a call with them and kind of the rest of the C-suite at OpenAI, and we made our pitch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Did they write a check right away?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yeah. It’s the OpenAI Startup Fund [they are the second-largest investor in Harvey]. OpenAI introduced us to our angel investors at the time, Sarah Guo and Elad Gil, and then everything else from there we were doing ourselves. I actually didn’t have any friends that worked in tech. I didn’t grow up in San Francisco. I didn’t know who the top VCs were. I didn’t understand how you’re supposed to fundraise. This was all just net new to me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For someone who wasn’t familiar with the VC scene, you’ve raised a lot of money. What enabled you to raise so much?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I might say something the VC community might not love, but I strongly believe that the best way to raise money is to just make sure your company is doing super well. I think there’s a lot of advice out there about networking, but to me, the most important thing is to spend almost the entire time on your business, and then find VCs who want to do that with you.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You need to find a few partners who you think are going to go the distance with you. So, 99% of your time, focus on the business going well, and then spend time trying to find a few folks who you really think you can partner with and who will be there for you for the long run.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You hit $100 million in ARR in August. With around 400 employees, how close are you to break-even?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Compute costs are more expensive for us than a lot of other things. We’re operating in more than 60 countries with data residency laws in all of them. For a long time, if you used multiple models in your product, you had to buy a bucket of compute — a minimum threshold — in every single one of those countries, even if you didn’t have enough clients yet to support that cost.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Germany and Australia have incredibly strict data processing laws. You cannot send financial data outside of those countries. We’d set up Azure or AWS instances in every single one of those countries, but we’d only use them to close three or four large clients. Our margins look very good on a token basis, but they’re worse because we have to spend so much on upfront compute across so many jurisdictions. That will get solved over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tell us about your sales process. How are you expanding globally?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the beginning of this year, about 4% of our revenue was from corporates and 96% from law firms. Right now, 33% of our revenue is from corporates, and my gut says, by the end of the year, that looks closer to 40%.&lt;br /&gt;In the beginning, we would take public litigation briefs from Pacer, find the partner who wrote it, put them into Harvey, and show them how they could argue against their own brief. That got massive attention because it was relevant to what they just did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what was interesting is once we got adoption at law firms, the law firms themselves would help us pitch to corporates. A firm like Latham will introduce Harvey to clients and say, “Hey, did you know this is how we can use AI to do XYZ?” So what started happening was law firms would actually help us sell to corporates because they want to collaborate in the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You refer to this as “multiplayer.” Can you expound on this as a growing area of focus?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a huge problem. You’ve seen announcements from OpenAI and Microsoft about shared threads and company memory. That’s hard — you have to get the permissioning right so agents can access the right systems. But you’re only solving it for one entity at a time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The secondary problem we have is: How do you solve that for a company plus all its law firms? You need to get the permissioning right internally and externally. There’s a concept in law called ethical walls. Think about a law firm in the valley that works with 20 VCs. If you’re working on a deal for Sequoia, but also working on another deal for Kleiner Perkins, what happens if you accidentally give all the data on the Sequoia deal to Kleiner Perkins? Huge, astronomical problem. We have to solve internal permissioning and external permissioning so agents can work correctly, and if you get it wrong, you’re going to have disastrous impacts on the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Have you solved this?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s definitely in process. We’re doing all of the security and the permissioning first. The first version of this at scale will probably be done in December. The nice thing is because such a high percentage of our customer base are already corporates using Harvey, the security problem is much easier because they’ve already gone through security review.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How &lt;em&gt;are&lt;/em&gt; lawyers primarily using Harvey today?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Number one is drafting. Number two is research — that’s emerging because we just have a partnership with LexisNexis. And the third is analyze. What I mean by analyze is running 10 questions over 100,000 documents, like what you do in diligence or discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the beginning, we had much more transactional use cases — M&amp;amp;A and fund formation. Those are still very popular, and we’re building modules specifically for those matters. The area that’s growing faster is litigation, and a lot of that is because you needed the data before you could do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Some critics have said Harvey is just a wrapper for ChatGPT. How do you respond?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The largest advantage we have over time is two things. One, we’re collecting a tremendous amount of workflow data — what are the main use cases these models can actually do? Evaluation becomes a pretty strong moat, because how do you evaluate the quality of a merger agreement? That becomes really hard. You have to set up evaluation frameworks and agentic systems that can self-eval all the different steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second strongest moat is our product is becoming very strongly multiplayer. This industry has two sides — providers of legal services and consumers. You need to build a platform that’s in between both. So far, I haven’t seen a competitor doing that. We have competitors doing what we do for law firms, and competitors doing what we do for in-house, but I haven’t seen someone build a truly multiplayer platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the “ChatGPT wrapper” criticism, for 2023 and 2024, a lot of the power behind the product is honestly the model, plus front-end work that makes the UI and UX easier. But if you’re trying to build something where I have 100,000 documents in this data room, 5,000 emails about this M&amp;amp;A, all these different statutes and codes, and I want is a system where I can ask questions over all of those pieces combined with high accuracy — that’s the holy grail. We’ve created all the pieces, and what we’ve been building for the past couple months is pulling that together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s your business model?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now it’s mostly seats, but we’re moving to more outcome-based pricing as the workflows get more complex. You want to do both. You want outcome-based pricing for very small things that you can ensure have the exact same level of accuracy as a human, or better, with very high speed. But the reality is, you’re going to want a lawyer in the loop for so much of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For at least the next year or two, it’s a productivity suite sold seat-based and multiplayer between law firms and their in-house teams. Slowly over time, we’ll build more consumption-based workflows as the systems get better and more accurate than humans in some areas. But it’s not going to be like you automate an entire M&amp;amp;A — it’s going to be specific pieces of diligence where you can have disclosure agents automate the first pass, then have lawyers jump in and do the rest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You mentioned to us earlier that penetration is really low in legal. How low?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What percentage of the lawyers on Earth are using Harvey right now? It’s a super low percentage. There are 8 or 9 million lawyers on Earth. But the more interesting point is we are in the unbelievably early innings on how complex work these systems can do. They’re very helpful and people are getting incredible ROI, but if you think about what percentage of legal work these systems can do today versus what I think it can do in the next five years, it’s so much lower.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think about the use case as, what is the value per token. The legal fees for a merger could easily be tens of millions of dollars. The artifact you have after that merger is a merger agreement and an SPA — maybe 200 pages total. What is the value per token on that document that required $20 million or $30 million of legal fees to generate? Those are the types of use cases where, when I say we’re at incredibly low penetration, it’s that we aren’t at the point where you can do something like that. And the value of being able to do that accurately is incredibly high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What happens to junior lawyers who are no longer getting the apprenticeship they might have had in the past?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I care about this potentially more than anything else at the company because I was a junior lawyer very recently. The goal of law firms in the next five to 10 years is: How fast can you train the best partners?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think right now, that’s partially the goal, but partially the goal is we hire armies of associates and bill them out a lot. Whether it’s because things become outcome-based pricing or because partners can charge more if AI systems can’t do what they do, the most important thing financially for a law firm is to make sure you’re hiring, training, and developing lawyers that get to being a partner as fast as humanly possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you can build tools that can do the first pass of an M&amp;amp;A, that is a one-on-one tutor for a junior associate. We work with a lot of law schools. You can imagine at some point you have an AI merger that you do in Harvey — the system’s teaching you, giving you real-time feedback. That’s an incredible training system. If you can build systems that can actually do a lot of the tasks, there’s no reason you couldn’t turn that into one of the best education platforms possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;With your valuation jumping from $3 billion to $8 billion in less than a year, what are your plans for future fundraising?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fundraising large rounds is not something we have planned anytime soon. We don’t need that much money, and we aren’t burning a crazy amount. The reason I did a lot of fundraising this year is there are research directions that are going to require a lot of compute, and we wanted to prepare ourselves for that. In terms of public markets, that’s definitely what we’re interested in long term. I can’t give you anything close to a timeline, but we’re interested.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-14-at-11.50.31-AM.png?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal AI might not sound like the sexiest category in Silicon Valley, but Harvey‘s CEO Winston Weinberg has captured the attention of virtually every top-tier investor in the Valley. The company’s cap table reads like a who’s who of venture capital: the OpenAI Startup Fund (its first institutional investor), Sequoia Capital, Kleiner Perkins, Elad Gil, Google Ventures, Coatue, and most recently, Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco-based company’s valuation skyrocketed from $3 billion in February 2025 to $5 billion in June to $8 billion in late October — a rise that reflects both the bonkers price tags awarded to AI companies and Harvey’s ability to win over major law firms and corporate legal departments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fact, the startup now claims 700 clients across 63 countries, including a majority of the top 10 U.S. law firms. It also says it surpassed $100 million in annual recurring revenue as of August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke with Weinberg for this week’s StrictlyVC Download podcast to ask about the wild ride that he and co-founder Gabe Pereyra have been on so far. During that chat, he shared how a cold email sent a few summers ago to Sam Altman changed everything; why he believes lawyers will benefit rather than suffer from AI; and how Harvey is tackling the technically complex challenge of building a truly multiplayer platform that navigates ethical walls and data permissioning across dozens of countries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This interview has been edited lightly for length. For the full monty, check out the podcast.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You started as a first-year associate at O’Melveny &amp;amp; Myers. When did you realize AI could transform legal work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So my co-founder was working at Meta at the time; he was also my roommate. He was showing me GPT-3, and in the beginning, I swear to God, the main use case I had for it was running a Dungeons and Dragons game with friends in LA. Then I was assigned to this landlord-tenant case at O’Melveny, and I didn’t know anything about landlord-tenant law. I started using GPT-3 to work on it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;My co-founder Gabe and I figured out we could do chain-of-thought prompting before that was really a thing. We created this super long chain-of-thought prompt over California landlord-tenant statutes. We grabbed 100 questions from r/legaladvice [on Reddit] and ran that prompt over them, then gave the question-answer pairs to three landlord-tenant attorneys without saying anything about AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We just said, “A potential customer asked this question, here’s the answer — would you make any edits or would you send this as is?” On 86 of the 100 samples, two out of three attorneys or more said they would send it with zero edits. That was the moment when we were like, wow, this entire industry can be transformed by this technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What happened next?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We cold-emailed Sam Altman and Jason Kwon, who was the general counsel at OpenAI. We figured we had to email a lawyer because otherwise the person wouldn’t know if the outputs were right. On the morning of July 4 at 10 a.m. — I remember this specifically because it was July 4 — we got on a call with them and kind of the rest of the C-suite at OpenAI, and we made our pitch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Did they write a check right away?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yeah. It’s the OpenAI Startup Fund [they are the second-largest investor in Harvey]. OpenAI introduced us to our angel investors at the time, Sarah Guo and Elad Gil, and then everything else from there we were doing ourselves. I actually didn’t have any friends that worked in tech. I didn’t grow up in San Francisco. I didn’t know who the top VCs were. I didn’t understand how you’re supposed to fundraise. This was all just net new to me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;For someone who wasn’t familiar with the VC scene, you’ve raised a lot of money. What enabled you to raise so much?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I might say something the VC community might not love, but I strongly believe that the best way to raise money is to just make sure your company is doing super well. I think there’s a lot of advice out there about networking, but to me, the most important thing is to spend almost the entire time on your business, and then find VCs who want to do that with you.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You need to find a few partners who you think are going to go the distance with you. So, 99% of your time, focus on the business going well, and then spend time trying to find a few folks who you really think you can partner with and who will be there for you for the long run.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You hit $100 million in ARR in August. With around 400 employees, how close are you to break-even?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Compute costs are more expensive for us than a lot of other things. We’re operating in more than 60 countries with data residency laws in all of them. For a long time, if you used multiple models in your product, you had to buy a bucket of compute — a minimum threshold — in every single one of those countries, even if you didn’t have enough clients yet to support that cost.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Germany and Australia have incredibly strict data processing laws. You cannot send financial data outside of those countries. We’d set up Azure or AWS instances in every single one of those countries, but we’d only use them to close three or four large clients. Our margins look very good on a token basis, but they’re worse because we have to spend so much on upfront compute across so many jurisdictions. That will get solved over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tell us about your sales process. How are you expanding globally?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the beginning of this year, about 4% of our revenue was from corporates and 96% from law firms. Right now, 33% of our revenue is from corporates, and my gut says, by the end of the year, that looks closer to 40%.&lt;br /&gt;In the beginning, we would take public litigation briefs from Pacer, find the partner who wrote it, put them into Harvey, and show them how they could argue against their own brief. That got massive attention because it was relevant to what they just did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what was interesting is once we got adoption at law firms, the law firms themselves would help us pitch to corporates. A firm like Latham will introduce Harvey to clients and say, “Hey, did you know this is how we can use AI to do XYZ?” So what started happening was law firms would actually help us sell to corporates because they want to collaborate in the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You refer to this as “multiplayer.” Can you expound on this as a growing area of focus?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a huge problem. You’ve seen announcements from OpenAI and Microsoft about shared threads and company memory. That’s hard — you have to get the permissioning right so agents can access the right systems. But you’re only solving it for one entity at a time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The secondary problem we have is: How do you solve that for a company plus all its law firms? You need to get the permissioning right internally and externally. There’s a concept in law called ethical walls. Think about a law firm in the valley that works with 20 VCs. If you’re working on a deal for Sequoia, but also working on another deal for Kleiner Perkins, what happens if you accidentally give all the data on the Sequoia deal to Kleiner Perkins? Huge, astronomical problem. We have to solve internal permissioning and external permissioning so agents can work correctly, and if you get it wrong, you’re going to have disastrous impacts on the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Have you solved this?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s definitely in process. We’re doing all of the security and the permissioning first. The first version of this at scale will probably be done in December. The nice thing is because such a high percentage of our customer base are already corporates using Harvey, the security problem is much easier because they’ve already gone through security review.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How &lt;em&gt;are&lt;/em&gt; lawyers primarily using Harvey today?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Number one is drafting. Number two is research — that’s emerging because we just have a partnership with LexisNexis. And the third is analyze. What I mean by analyze is running 10 questions over 100,000 documents, like what you do in diligence or discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the beginning, we had much more transactional use cases — M&amp;amp;A and fund formation. Those are still very popular, and we’re building modules specifically for those matters. The area that’s growing faster is litigation, and a lot of that is because you needed the data before you could do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Some critics have said Harvey is just a wrapper for ChatGPT. How do you respond?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The largest advantage we have over time is two things. One, we’re collecting a tremendous amount of workflow data — what are the main use cases these models can actually do? Evaluation becomes a pretty strong moat, because how do you evaluate the quality of a merger agreement? That becomes really hard. You have to set up evaluation frameworks and agentic systems that can self-eval all the different steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second strongest moat is our product is becoming very strongly multiplayer. This industry has two sides — providers of legal services and consumers. You need to build a platform that’s in between both. So far, I haven’t seen a competitor doing that. We have competitors doing what we do for law firms, and competitors doing what we do for in-house, but I haven’t seen someone build a truly multiplayer platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the “ChatGPT wrapper” criticism, for 2023 and 2024, a lot of the power behind the product is honestly the model, plus front-end work that makes the UI and UX easier. But if you’re trying to build something where I have 100,000 documents in this data room, 5,000 emails about this M&amp;amp;A, all these different statutes and codes, and I want is a system where I can ask questions over all of those pieces combined with high accuracy — that’s the holy grail. We’ve created all the pieces, and what we’ve been building for the past couple months is pulling that together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s your business model?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now it’s mostly seats, but we’re moving to more outcome-based pricing as the workflows get more complex. You want to do both. You want outcome-based pricing for very small things that you can ensure have the exact same level of accuracy as a human, or better, with very high speed. But the reality is, you’re going to want a lawyer in the loop for so much of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For at least the next year or two, it’s a productivity suite sold seat-based and multiplayer between law firms and their in-house teams. Slowly over time, we’ll build more consumption-based workflows as the systems get better and more accurate than humans in some areas. But it’s not going to be like you automate an entire M&amp;amp;A — it’s going to be specific pieces of diligence where you can have disclosure agents automate the first pass, then have lawyers jump in and do the rest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You mentioned to us earlier that penetration is really low in legal. How low?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What percentage of the lawyers on Earth are using Harvey right now? It’s a super low percentage. There are 8 or 9 million lawyers on Earth. But the more interesting point is we are in the unbelievably early innings on how complex work these systems can do. They’re very helpful and people are getting incredible ROI, but if you think about what percentage of legal work these systems can do today versus what I think it can do in the next five years, it’s so much lower.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think about the use case as, what is the value per token. The legal fees for a merger could easily be tens of millions of dollars. The artifact you have after that merger is a merger agreement and an SPA — maybe 200 pages total. What is the value per token on that document that required $20 million or $30 million of legal fees to generate? Those are the types of use cases where, when I say we’re at incredibly low penetration, it’s that we aren’t at the point where you can do something like that. And the value of being able to do that accurately is incredibly high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What happens to junior lawyers who are no longer getting the apprenticeship they might have had in the past?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I care about this potentially more than anything else at the company because I was a junior lawyer very recently. The goal of law firms in the next five to 10 years is: How fast can you train the best partners?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think right now, that’s partially the goal, but partially the goal is we hire armies of associates and bill them out a lot. Whether it’s because things become outcome-based pricing or because partners can charge more if AI systems can’t do what they do, the most important thing financially for a law firm is to make sure you’re hiring, training, and developing lawyers that get to being a partner as fast as humanly possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you can build tools that can do the first pass of an M&amp;amp;A, that is a one-on-one tutor for a junior associate. We work with a lot of law schools. You can imagine at some point you have an AI merger that you do in Harvey — the system’s teaching you, giving you real-time feedback. That’s an incredible training system. If you can build systems that can actually do a lot of the tasks, there’s no reason you couldn’t turn that into one of the best education platforms possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;With your valuation jumping from $3 billion to $8 billion in less than a year, what are your plans for future fundraising?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fundraising large rounds is not something we have planned anytime soon. We don’t need that much money, and we aren’t burning a crazy amount. The reason I did a lot of fundraising this year is there are research directions that are going to require a lot of compute, and we wanted to prepare ourselves for that. In terms of public markets, that’s definitely what we’re interested in long term. I can’t give you anything close to a timeline, but we’re interested.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/14/inside-harvey-how-a-first-year-legal-associate-built-one-of-silicon-valleys-hottest-startups/</guid><pubDate>Fri, 14 Nov 2025 11:57:24 +0000</pubDate></item><item><title>Researchers question Anthropic claim that AI-assisted attack was 90% autonomous (AI – Ars Technica)</title><link>https://arstechnica.com/security/2025/11/researchers-question-anthropic-claim-that-ai-assisted-attack-was-90-autonomous/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The results of AI-assisted hacking aren’t as impressive as many might have us believe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from Anthropic said they recently observed the “first reported AI-orchestrated cyber espionage campaign” after detecting China-state hackers using the company’s Claude AI tool in a campaign aimed at dozens of targets. Outside researchers are much more measured in describing the significance of the discovery.&lt;/p&gt;
&lt;p&gt;Anthropic published the reports on Thursday here and here. In September, the reports said, Anthropic discovered a “highly sophisticated espionage campaign,” carried out by a Chinese state-sponsored group, that used Claude Code to automate up to 90 percent of the work. Human intervention was required “only sporadically (perhaps 4-6 critical decision points per hacking campaign).” Anthropic said the hackers had employed AI agentic capabilities to an “unprecedented” extent.&lt;/p&gt;
&lt;p&gt;“This campaign has substantial implications for cybersecurity in the age of AI ‘agents’—systems that can be run autonomously for long periods of time and that complete complex tasks largely independent of human intervention,” Anthropic said. “Agents are valuable for everyday work and productivity—but in the wrong hands, they can substantially increase the viability of large-scale cyberattacks.”&lt;/p&gt;
&lt;h2&gt;“Ass-kissing, stonewalling, and acid trips”&lt;/h2&gt;
&lt;p&gt;Outside researchers weren’t convinced the discovery was the watershed moment the Anthropic posts made it out to be. They questioned why these sorts of advances are often attributed to malicious hackers when white-hat hackers and developers of legitimate software keep reporting only incremental gains from their use of AI.&lt;/p&gt;
&lt;p&gt;“I continue to refuse to believe that attackers are somehow able to get these models to jump through hoops that nobody else can,” Dan Tentler, executive founder of Phobos Group and a researcher with expertise in complex security breaches, told Ars. “Why do the models give these attackers what they want 90% of the time but the rest of us have to deal with ass-kissing, stonewalling, and acid trips?”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Researchers don’t deny that AI tools can improve workflow and shorten the time required for certain tasks, such as triage, log analysis, and reverse engineering. But the ability for AI to automate a complex chain of tasks with such minimal human interaction remains elusive. Many researchers compare advances from AI in cyberattacks to those provided by hacking tools such as Metasploit or SEToolkit, which have been in use for decades. There’s no doubt that these tools are useful, but their advent didn’t meaningfully increase hackers’ capabilities or the severity of the attacks they produced.&lt;/p&gt;
&lt;p&gt;Another reason the results aren’t as impressive as they’re made out to be: The threat actors—which Anthropic tracks as GTG-1002—targeted at least 30 organizations, including major technology corporations and government agencies. Of those, only a “small number” of the attacks succeeded. That, in turn, raises questions. Even assuming so much human interaction was eliminated from the process, what good is that when the success rate is so low? Would the number of successes have increased if the attackers had used more traditional, human-involved methods?&lt;/p&gt;
&lt;p&gt;According to Anthropic’s account, the hackers used Claude to orchestrate attacks using readily available open source software and frameworks. These tools have existed for years and are already easy for defenders to detect. Anthropic didn’t detail the specific techniques, tooling, or exploitation that occurred in the attacks, but so far, there’s no indication that the use of AI made them more potent or stealthy than more traditional techniques.&lt;/p&gt;
&lt;p&gt;“The threat actors aren’t inventing something new here,” independent researcher Kevin Beaumont said.&lt;/p&gt;
&lt;p&gt;Even Anthropic noted “an important limitation” in its findings:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Claude frequently overstated findings and occasionally fabricated data during autonomous operations, claiming to have obtained credentials that didn’t work or identifying critical discoveries that proved to be publicly available information. This AI hallucination in offensive security contexts presented challenges for the actor’s operational effectiveness, requiring careful validation of all claimed results. This remains an obstacle to fully autonomous cyberattacks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;How (Anthropic says) the attack unfolded&lt;/h2&gt;
&lt;p&gt;Anthropic said GTG-1002 developed an autonomous attack framework that used Claude as an orchestration mechanism that largely eliminated the need for human involvement. This orchestration system broke complex multi-stage attacks into smaller technical tasks such as vulnerability scanning, credential validation, data extraction, and lateral movement.&lt;/p&gt;
&lt;p&gt;“The architecture incorporated Claude’s technical capabilities as an execution engine within a larger automated system, where the AI performed specific technical actions based on the human operators’ instructions while the orchestration logic maintained attack state, managed phase transitions, and aggregated results across multiple sessions,” Anthropic said. “This approach allowed the threat actor to achieve operational scale typically associated with nation-state campaigns while maintaining minimal direct involvement, as the framework autonomously progressed through reconnaissance, initial access, persistence, and data exfiltration phases by sequencing Claude’s responses and adapting subsequent requests based on discovered information.”&lt;/p&gt;
&lt;p&gt;The attacks followed a five-phase structure that increased AI autonomy through each one.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127439 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="762" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-phase-cyberattack-claude-1024x762.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The life cycle of the cyberattack, showing the move from human-led targeting to largely AI-driven attacks using various tools, often via the Model Context Protocol (MCP). At various points during the attack, the AI returns to its human operator for review and further direction.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The attackers were able to bypass Claude guardrails in part by breaking tasks into small steps that, in isolation, the AI tool didn’t interpret as malicious. In other cases, the attackers couched their inquiries in the context of security professionals trying to use Claude to improve defenses.&lt;/p&gt;
&lt;p&gt;As noted last week, AI-developed malware has a long way to go before it poses a real-world threat. There’s no reason to doubt that AI-assisted cyberattacks may one day produce more potent attacks. But the data so far indicates that threat actors—like most others using AI—are seeing mixed results that aren’t nearly as impressive as those in the AI industry claim.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The results of AI-assisted hacking aren’t as impressive as many might have us believe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from Anthropic said they recently observed the “first reported AI-orchestrated cyber espionage campaign” after detecting China-state hackers using the company’s Claude AI tool in a campaign aimed at dozens of targets. Outside researchers are much more measured in describing the significance of the discovery.&lt;/p&gt;
&lt;p&gt;Anthropic published the reports on Thursday here and here. In September, the reports said, Anthropic discovered a “highly sophisticated espionage campaign,” carried out by a Chinese state-sponsored group, that used Claude Code to automate up to 90 percent of the work. Human intervention was required “only sporadically (perhaps 4-6 critical decision points per hacking campaign).” Anthropic said the hackers had employed AI agentic capabilities to an “unprecedented” extent.&lt;/p&gt;
&lt;p&gt;“This campaign has substantial implications for cybersecurity in the age of AI ‘agents’—systems that can be run autonomously for long periods of time and that complete complex tasks largely independent of human intervention,” Anthropic said. “Agents are valuable for everyday work and productivity—but in the wrong hands, they can substantially increase the viability of large-scale cyberattacks.”&lt;/p&gt;
&lt;h2&gt;“Ass-kissing, stonewalling, and acid trips”&lt;/h2&gt;
&lt;p&gt;Outside researchers weren’t convinced the discovery was the watershed moment the Anthropic posts made it out to be. They questioned why these sorts of advances are often attributed to malicious hackers when white-hat hackers and developers of legitimate software keep reporting only incremental gains from their use of AI.&lt;/p&gt;
&lt;p&gt;“I continue to refuse to believe that attackers are somehow able to get these models to jump through hoops that nobody else can,” Dan Tentler, executive founder of Phobos Group and a researcher with expertise in complex security breaches, told Ars. “Why do the models give these attackers what they want 90% of the time but the rest of us have to deal with ass-kissing, stonewalling, and acid trips?”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Researchers don’t deny that AI tools can improve workflow and shorten the time required for certain tasks, such as triage, log analysis, and reverse engineering. But the ability for AI to automate a complex chain of tasks with such minimal human interaction remains elusive. Many researchers compare advances from AI in cyberattacks to those provided by hacking tools such as Metasploit or SEToolkit, which have been in use for decades. There’s no doubt that these tools are useful, but their advent didn’t meaningfully increase hackers’ capabilities or the severity of the attacks they produced.&lt;/p&gt;
&lt;p&gt;Another reason the results aren’t as impressive as they’re made out to be: The threat actors—which Anthropic tracks as GTG-1002—targeted at least 30 organizations, including major technology corporations and government agencies. Of those, only a “small number” of the attacks succeeded. That, in turn, raises questions. Even assuming so much human interaction was eliminated from the process, what good is that when the success rate is so low? Would the number of successes have increased if the attackers had used more traditional, human-involved methods?&lt;/p&gt;
&lt;p&gt;According to Anthropic’s account, the hackers used Claude to orchestrate attacks using readily available open source software and frameworks. These tools have existed for years and are already easy for defenders to detect. Anthropic didn’t detail the specific techniques, tooling, or exploitation that occurred in the attacks, but so far, there’s no indication that the use of AI made them more potent or stealthy than more traditional techniques.&lt;/p&gt;
&lt;p&gt;“The threat actors aren’t inventing something new here,” independent researcher Kevin Beaumont said.&lt;/p&gt;
&lt;p&gt;Even Anthropic noted “an important limitation” in its findings:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Claude frequently overstated findings and occasionally fabricated data during autonomous operations, claiming to have obtained credentials that didn’t work or identifying critical discoveries that proved to be publicly available information. This AI hallucination in offensive security contexts presented challenges for the actor’s operational effectiveness, requiring careful validation of all claimed results. This remains an obstacle to fully autonomous cyberattacks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;How (Anthropic says) the attack unfolded&lt;/h2&gt;
&lt;p&gt;Anthropic said GTG-1002 developed an autonomous attack framework that used Claude as an orchestration mechanism that largely eliminated the need for human involvement. This orchestration system broke complex multi-stage attacks into smaller technical tasks such as vulnerability scanning, credential validation, data extraction, and lateral movement.&lt;/p&gt;
&lt;p&gt;“The architecture incorporated Claude’s technical capabilities as an execution engine within a larger automated system, where the AI performed specific technical actions based on the human operators’ instructions while the orchestration logic maintained attack state, managed phase transitions, and aggregated results across multiple sessions,” Anthropic said. “This approach allowed the threat actor to achieve operational scale typically associated with nation-state campaigns while maintaining minimal direct involvement, as the framework autonomously progressed through reconnaissance, initial access, persistence, and data exfiltration phases by sequencing Claude’s responses and adapting subsequent requests based on discovered information.”&lt;/p&gt;
&lt;p&gt;The attacks followed a five-phase structure that increased AI autonomy through each one.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127439 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="762" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-phase-cyberattack-claude-1024x762.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The life cycle of the cyberattack, showing the move from human-led targeting to largely AI-driven attacks using various tools, often via the Model Context Protocol (MCP). At various points during the attack, the AI returns to its human operator for review and further direction.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The attackers were able to bypass Claude guardrails in part by breaking tasks into small steps that, in isolation, the AI tool didn’t interpret as malicious. In other cases, the attackers couched their inquiries in the context of security professionals trying to use Claude to improve defenses.&lt;/p&gt;
&lt;p&gt;As noted last week, AI-developed malware has a long way to go before it poses a real-world threat. There’s no reason to doubt that AI-assisted cyberattacks may one day produce more potent attacks. But the data so far indicates that threat actors—like most others using AI—are seeing mixed results that aren’t nearly as impressive as those in the AI industry claim.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2025/11/researchers-question-anthropic-claim-that-ai-assisted-attack-was-90-autonomous/</guid><pubDate>Fri, 14 Nov 2025 12:20:48 +0000</pubDate></item><item><title>[NEW] The Download: how AI really works, and phasing out animal testing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/14/1127959/the-download-how-ai-really-works-and-phasing-out-animal-testing/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;OpenAI’s new LLM exposes the secrets of how AI really works&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;ChatGPT maker OpenAI has built an experimental large language model that is far easier to understand than typical models.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;It’s a big deal, because today’s LLMs are black boxes: Nobody fully understands how they do what they do. Building a model that is more transparent sheds light on how LLMs work in general, helping researchers figure out why models hallucinate, why they go off the rails, and just how far we should trust them with critical tasks. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google DeepMind is using Gemini to train agents inside Goat Simulator 3&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google DeepMind has built a new video-game-playing agent called SIMA 2 that can navigate and solve problems in 3D virtual worlds. The company claims it’s a big step toward more general-purpose agents and better real-world robots.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company first demoed SIMA (which stands for “scalable instructable multiworld agent”) last year. But this new version has been built on top of Gemini, the firm’s flagship large language model, which gives the agent a huge boost in capability. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;These technologies could help put a stop to animal testing&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&lt;/p&gt;&lt;p&gt;It’s good news for activists and scientists who don’t want to test on animals. And it’s timely too: In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on animals. Read the full story.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Chinese hackers used Anthropic’s AI to conduct an espionage campaign&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It automated a number of attacks on corporations and governments in September. (WSJ $)&lt;br /&gt;+ &lt;em&gt;The AI was able to handle the majority of the hacking workload itself. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Blue Origin successfully launched and landed its New Glenn rocket&lt;/strong&gt;&lt;br /&gt;It managed to deploy two NASA satellites into space without a hitch. (CNN)&lt;br /&gt;+ &lt;em&gt;The New Glenn is the company’s largest reusable rocket. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;The launch had been delayed twice before. &lt;/em&gt;(WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Brace yourself for flu season&lt;br /&gt;&lt;/strong&gt;It started five weeks earlier than usual in the UK, and the US is next. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Here’s why we don’t have a cold vaccine. Yet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Google is hosting a Border Protection facial recognition app&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The app alerts officials whether to contact ICE about identified immigrants. (404 Media)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids was just taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 OpenAI is trialling group chats in ChatGPT&lt;/strong&gt;&lt;br /&gt;It’d essentially make AI a participant in a conversation of up to 20 people. (Engadget)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 A TikTok stunt sparked debate over how charitable America’s churches really are&lt;br /&gt;&lt;/strong&gt;Content creator Nikalie Monroe asked churches for help feeding her baby. Very few stepped up. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Indian startups are attempting to tackle air pollution&lt;br /&gt;&lt;/strong&gt;But their solutions are far beyond the means of the average Indian household. (NYT $)&lt;br /&gt;+ &lt;em&gt;OpenAI is huge in India. Its models are steeped in caste bias. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 An AI tool could help reduce wasted efforts to transplant organs&lt;br /&gt;&lt;/strong&gt;It predicts how likely the would-be recipient is to die during the brief transplantation window. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Putin says organ transplants could grant immortality. Not quite. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 3D-printing isn’t making prosthetics more affordable&lt;/strong&gt;&lt;br /&gt;It turns out that plastic prostheses are often really uncomfortable. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;These prosthetics break the mold with third thumbs, spikes, and superhero skins. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 What happens when relationships with AI fall apart&lt;/strong&gt;&lt;br /&gt;Can you really file for divorce from an LLM? (Wired $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s a funky time.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Aileen Lee, founder and managing partner of Cowboy Ventures, tells TechCrunch the AI boom has torn up the traditional investment rulebook.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127963" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_0f9bae.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Restoring an ancient lake from the rubble of an unfinished airport in Mexico City&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Weeks after Mexican President Andrés Manuel López Obrador took office in 2018, he controversially canceled ambitious plans to build an airport on the deserted site of the former Lake Texcoco—despite the fact it was already around a third complete.&lt;/p&gt;&lt;p&gt;Instead, he tasked Iñaki Echeverria, a Mexican architect and landscape designer, with turning it into a vast urban park, an artificial wetland that aims to transform the future of the entire Valley region.&lt;/p&gt;&lt;p&gt;But as López Obrador’s presidential team nears its end, the plans for Lake Texcoco’s rebirth could yet vanish. Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Maybe Gen Z is onto something when it comes to vibe dating.&lt;br /&gt;+ Trust AC/DC to give the fans what they want, performing Jailbreak for the first time since 1991.&lt;br /&gt;+ Nieves González, the artist behind Lily Allen’s new album cover, has an eye for detail.&lt;br /&gt;+ Here’s what AI determines is a catchy tune.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;OpenAI’s new LLM exposes the secrets of how AI really works&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;ChatGPT maker OpenAI has built an experimental large language model that is far easier to understand than typical models.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;It’s a big deal, because today’s LLMs are black boxes: Nobody fully understands how they do what they do. Building a model that is more transparent sheds light on how LLMs work in general, helping researchers figure out why models hallucinate, why they go off the rails, and just how far we should trust them with critical tasks. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google DeepMind is using Gemini to train agents inside Goat Simulator 3&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google DeepMind has built a new video-game-playing agent called SIMA 2 that can navigate and solve problems in 3D virtual worlds. The company claims it’s a big step toward more general-purpose agents and better real-world robots.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company first demoed SIMA (which stands for “scalable instructable multiworld agent”) last year. But this new version has been built on top of Gemini, the firm’s flagship large language model, which gives the agent a huge boost in capability. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;These technologies could help put a stop to animal testing&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&lt;/p&gt;&lt;p&gt;It’s good news for activists and scientists who don’t want to test on animals. And it’s timely too: In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on animals. Read the full story.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Chinese hackers used Anthropic’s AI to conduct an espionage campaign&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It automated a number of attacks on corporations and governments in September. (WSJ $)&lt;br /&gt;+ &lt;em&gt;The AI was able to handle the majority of the hacking workload itself. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Blue Origin successfully launched and landed its New Glenn rocket&lt;/strong&gt;&lt;br /&gt;It managed to deploy two NASA satellites into space without a hitch. (CNN)&lt;br /&gt;+ &lt;em&gt;The New Glenn is the company’s largest reusable rocket. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;The launch had been delayed twice before. &lt;/em&gt;(WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Brace yourself for flu season&lt;br /&gt;&lt;/strong&gt;It started five weeks earlier than usual in the UK, and the US is next. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Here’s why we don’t have a cold vaccine. Yet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Google is hosting a Border Protection facial recognition app&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The app alerts officials whether to contact ICE about identified immigrants. (404 Media)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids was just taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 OpenAI is trialling group chats in ChatGPT&lt;/strong&gt;&lt;br /&gt;It’d essentially make AI a participant in a conversation of up to 20 people. (Engadget)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 A TikTok stunt sparked debate over how charitable America’s churches really are&lt;br /&gt;&lt;/strong&gt;Content creator Nikalie Monroe asked churches for help feeding her baby. Very few stepped up. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Indian startups are attempting to tackle air pollution&lt;br /&gt;&lt;/strong&gt;But their solutions are far beyond the means of the average Indian household. (NYT $)&lt;br /&gt;+ &lt;em&gt;OpenAI is huge in India. Its models are steeped in caste bias. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 An AI tool could help reduce wasted efforts to transplant organs&lt;br /&gt;&lt;/strong&gt;It predicts how likely the would-be recipient is to die during the brief transplantation window. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Putin says organ transplants could grant immortality. Not quite. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 3D-printing isn’t making prosthetics more affordable&lt;/strong&gt;&lt;br /&gt;It turns out that plastic prostheses are often really uncomfortable. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;These prosthetics break the mold with third thumbs, spikes, and superhero skins. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 What happens when relationships with AI fall apart&lt;/strong&gt;&lt;br /&gt;Can you really file for divorce from an LLM? (Wired $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s a funky time.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Aileen Lee, founder and managing partner of Cowboy Ventures, tells TechCrunch the AI boom has torn up the traditional investment rulebook.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127963" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_0f9bae.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Restoring an ancient lake from the rubble of an unfinished airport in Mexico City&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Weeks after Mexican President Andrés Manuel López Obrador took office in 2018, he controversially canceled ambitious plans to build an airport on the deserted site of the former Lake Texcoco—despite the fact it was already around a third complete.&lt;/p&gt;&lt;p&gt;Instead, he tasked Iñaki Echeverria, a Mexican architect and landscape designer, with turning it into a vast urban park, an artificial wetland that aims to transform the future of the entire Valley region.&lt;/p&gt;&lt;p&gt;But as López Obrador’s presidential team nears its end, the plans for Lake Texcoco’s rebirth could yet vanish. Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Maybe Gen Z is onto something when it comes to vibe dating.&lt;br /&gt;+ Trust AC/DC to give the fans what they want, performing Jailbreak for the first time since 1991.&lt;br /&gt;+ Nieves González, the artist behind Lily Allen’s new album cover, has an eye for detail.&lt;br /&gt;+ Here’s what AI determines is a catchy tune.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/14/1127959/the-download-how-ai-really-works-and-phasing-out-animal-testing/</guid><pubDate>Fri, 14 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] ChatGPT Group Chats are here … but not for everyone (yet) (AI | VentureBeat)</title><link>https://venturebeat.com/ai/chatgpt-group-chats-are-here-but-not-for-everyone-yet</link><description>[unable to retrieve full-text content]&lt;p&gt;It was originally found in &lt;a href="https://x.com/btibor91/status/1988029080726630822?s=20"&gt;leaked code and publicized by AI influencers on X&lt;/a&gt;, but OpenAI has made it official: &lt;a href="https://openai.com/index/group-chats-in-chatgpt/"&gt;ChatGPT now offers Group Chats,&lt;/a&gt; allowing multiple users to join the same, single ChatGPT conversation and send messages to each other and the underlying large language model (LLM), online and via its mobile apps. &lt;/p&gt;&lt;p&gt;Imagine adding ChatGPT as another member of your existing group chats, allowing you to text it as you would one of your friends or family members and have them respond as well, and you&amp;#x27;ll have an idea of the intriguing power and potential of this feature.&lt;/p&gt;&lt;p&gt;However, the feature is only available as a limited pilot for now to ChatGPT users in Japan, New Zealand, South Korea, and Taiwan (all tiers, including free usage).&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;“Group chats are just the beginning of ChatGPT becoming a shared space to collaborate and interact with others,” OpenAI wrote in its announcement.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This development builds on internal experimentation at OpenAI, where technical staffer &lt;a href="https://x.com/keyanzhang/status/1989139444650373281"&gt;Keyan Zhang said in a post on X&lt;/a&gt; that OpenAI&amp;#x27;s team initially considered multiplayer ChatGPT to be “a wild, out-of-distribution idea.”&lt;/p&gt;&lt;p&gt;According to Zhang, the model’s performance in those early tests demonstrated far more potential than existing interfaces typically allow.&lt;/p&gt;&lt;p&gt;The move follows OpenAI investor yet competitor &lt;a href="https://venturebeat.com/ai/microsoft-copilot-gets-12-big-updates-for-fall-including-new-ai-assistant"&gt;Microsoft&amp;#x27;s update of its Copilot AI assistant to allow group chats last month&lt;/a&gt;, as well as Anthropic&amp;#x27;s introduction of shareable context and chat histories from its Claude AI models through its &lt;a href="https://venturebeat.com/ai/anthropic-ai-assistant-claude-just-got-a-massive-upgrade-heres-what-you-need-to-know"&gt;Projects feature introduced summer 2024&lt;/a&gt;, though this is not a simultaneous, realtime group chat in the same way. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Collaborative functionality integrated into ChatGPT&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Group chats function as shared conversational spaces where users can plan events, brainstorm ideas, or collaborate on projects with the added support of ChatGPT. &lt;/p&gt;&lt;p&gt;These conversations are distinct from individual chats and are excluded from ChatGPT’s memory system—meaning no data from these group threads is used to train or personalize future interactions.&lt;/p&gt;&lt;p&gt;Users can initiate a group chat by selecting the people icon in a new or existing conversation. Adding others creates a copy of the original thread, preserving the source dialogue. Participants can join via a shareable link and are prompted to create a profile with a name, username, and photo. The feature supports 1 to 20 participants per group.&lt;/p&gt;&lt;p&gt;Each group chat is listed in a new section of the ChatGPT interface, and users can manage settings like naming the group, adding or removing participants, or muting notifications.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Powered by GPT-5.1 with expanded tools&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The new group chat feature runs on GPT-5.1 Auto, a backend setting that chooses the optimal model based on the user’s subscription tier and the prompt. &lt;/p&gt;&lt;p&gt;Functionality such as search, image generation, file upload, and dictation is available inside group conversations.&lt;/p&gt;&lt;p&gt;Importantly, the system applies rate limits only when ChatGPT is producing responses. Direct messages between human users in the group do not count toward any plan’s message cap.&lt;/p&gt;&lt;p&gt;OpenAI has added new social features to ChatGPT in support of this group dynamic. The model can react with emojis, interpret conversational context to decide when to respond, and personalize generated content using members’ profile photos—such as inserting user likenesses into images when asked.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Privacy by default, controls for younger users&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI emphasized that privacy and user control are integral to group chat design. The feature operates independently of the user’s personalized ChatGPT memory, and no new memories are created from these interactions. &lt;/p&gt;&lt;p&gt;Participation requires an invitation link, and members are always able to see who is in a chat or leave at any time.&lt;/p&gt;&lt;p&gt;Users under the age of 18 are automatically shielded from sensitive content in group chats. Parents or guardians can disable group chat access altogether via built-in parental controls.&lt;/p&gt;&lt;p&gt;Group creators retain special permissions, including immunity from being removed by others. All other participants can be added or removed by group members.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A testbed for shared AI experiences&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI frames group chats as an early step toward richer, multi-user applications of AI, hinting at broader ambitions for ChatGPT as a shared workspace. The company expects to expand access over time and refine the feature based on how early users engage with it.&lt;/p&gt;&lt;p&gt;Keyan Zhang’s post suggests that the underlying model capabilities are far ahead of the interfaces users currently interact with. This pilot, in OpenAI’s view, offers a new “container” where more of the model’s latent capacity can be surfaced.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;“Our models have a lot more room to shine than today’s experiences show, and the current containers only use a fraction of their capabilities,” Zhang said.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;With this initial pilot focused on a limited set of markets, OpenAI is likely monitoring both usage patterns and cultural fit as it plans for broader deployment. For now, the group chat experiment offers a new way for users to interact with ChatGPT—and with each other—in real time, using a conversational interface that blends productivity and personalization.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Developer access: Still unclear&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI has not provided any indication that Group Chats will be accessible via the API or SDK. The current rollout is framed strictly within the ChatGPT product environment, with no mention of tool calls, developer hooks, or integration support for programmatic use. This absence of signaling leaves it unclear whether the company views group interaction as a future developer primitive or as a contained UX feature for end users only.&lt;/p&gt;&lt;p&gt;For enterprise teams exploring how to replicate multi-user collaboration with generative models, any current implementation would require custom orchestration—such as managing multi-party context and prompts across separate API calls, and handling session state and response merging externally. Until OpenAI provides formal support, Group Chats remain a closed interface feature rather than a developer-accessible capability.&lt;/p&gt;&lt;p&gt;Here is a standalone concluding subsection tailored for the article, focusing on what the ChatGPT Group Chat rollout means for enterprise decision makers in both pilot regions and globally:&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Implications for enterprise AI and data leaders&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For enterprise teams already leveraging AI platforms—or preparing to—OpenAI’s group chat feature introduces a new layer of multi-user collaboration that could shift how generative models are deployed across workflows. While the pilot is limited to users in Japan, New Zealand, South Korea, and Taiwan, its design and roadmap offer key signals for AI engineers, orchestration specialists, and data leads globally.&lt;/p&gt;&lt;p&gt;AI engineers managing large language model (LLM) deployments can now begin to conceptualize real-time, multi-user interfaces not just as support tools, but as collaborative environments for research, content generation, and ideation. This adds another front in model tuning: not just how models respond to individuals, but how they behave in live group settings with context shifts and varied user intentions.&lt;/p&gt;&lt;p&gt;For AI orchestration leads, the ability to integrate ChatGPT into collaborative flows without exposing private memory or requiring custom builds may reduce friction in piloting generative AI in cross-functional teams. These group sessions could serve as lightweight alternatives to internal tools for brainstorming, prototyping, or knowledge sharing—useful for teams constrained by infrastructure, budget, or time.&lt;/p&gt;&lt;p&gt;Enterprise data managers may also find use cases in structured group chat sessions for data annotation, taxonomy validation, or internal training support. The system’s lack of memory persistence adds a level of data isolation that aligns with standard security and compliance practices—though global rollout will be key to validating regional data handling standards.&lt;/p&gt;&lt;p&gt;As group chat capabilities evolve, decision makers should monitor how shared usage patterns might inform future model behaviors, auditing needs, and governance structures. In the long term, features like these will influence not just how organizations interact with generative AI, but how they design team-level interfaces around it.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;It was originally found in &lt;a href="https://x.com/btibor91/status/1988029080726630822?s=20"&gt;leaked code and publicized by AI influencers on X&lt;/a&gt;, but OpenAI has made it official: &lt;a href="https://openai.com/index/group-chats-in-chatgpt/"&gt;ChatGPT now offers Group Chats,&lt;/a&gt; allowing multiple users to join the same, single ChatGPT conversation and send messages to each other and the underlying large language model (LLM), online and via its mobile apps. &lt;/p&gt;&lt;p&gt;Imagine adding ChatGPT as another member of your existing group chats, allowing you to text it as you would one of your friends or family members and have them respond as well, and you&amp;#x27;ll have an idea of the intriguing power and potential of this feature.&lt;/p&gt;&lt;p&gt;However, the feature is only available as a limited pilot for now to ChatGPT users in Japan, New Zealand, South Korea, and Taiwan (all tiers, including free usage).&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;“Group chats are just the beginning of ChatGPT becoming a shared space to collaborate and interact with others,” OpenAI wrote in its announcement.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This development builds on internal experimentation at OpenAI, where technical staffer &lt;a href="https://x.com/keyanzhang/status/1989139444650373281"&gt;Keyan Zhang said in a post on X&lt;/a&gt; that OpenAI&amp;#x27;s team initially considered multiplayer ChatGPT to be “a wild, out-of-distribution idea.”&lt;/p&gt;&lt;p&gt;According to Zhang, the model’s performance in those early tests demonstrated far more potential than existing interfaces typically allow.&lt;/p&gt;&lt;p&gt;The move follows OpenAI investor yet competitor &lt;a href="https://venturebeat.com/ai/microsoft-copilot-gets-12-big-updates-for-fall-including-new-ai-assistant"&gt;Microsoft&amp;#x27;s update of its Copilot AI assistant to allow group chats last month&lt;/a&gt;, as well as Anthropic&amp;#x27;s introduction of shareable context and chat histories from its Claude AI models through its &lt;a href="https://venturebeat.com/ai/anthropic-ai-assistant-claude-just-got-a-massive-upgrade-heres-what-you-need-to-know"&gt;Projects feature introduced summer 2024&lt;/a&gt;, though this is not a simultaneous, realtime group chat in the same way. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Collaborative functionality integrated into ChatGPT&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Group chats function as shared conversational spaces where users can plan events, brainstorm ideas, or collaborate on projects with the added support of ChatGPT. &lt;/p&gt;&lt;p&gt;These conversations are distinct from individual chats and are excluded from ChatGPT’s memory system—meaning no data from these group threads is used to train or personalize future interactions.&lt;/p&gt;&lt;p&gt;Users can initiate a group chat by selecting the people icon in a new or existing conversation. Adding others creates a copy of the original thread, preserving the source dialogue. Participants can join via a shareable link and are prompted to create a profile with a name, username, and photo. The feature supports 1 to 20 participants per group.&lt;/p&gt;&lt;p&gt;Each group chat is listed in a new section of the ChatGPT interface, and users can manage settings like naming the group, adding or removing participants, or muting notifications.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Powered by GPT-5.1 with expanded tools&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The new group chat feature runs on GPT-5.1 Auto, a backend setting that chooses the optimal model based on the user’s subscription tier and the prompt. &lt;/p&gt;&lt;p&gt;Functionality such as search, image generation, file upload, and dictation is available inside group conversations.&lt;/p&gt;&lt;p&gt;Importantly, the system applies rate limits only when ChatGPT is producing responses. Direct messages between human users in the group do not count toward any plan’s message cap.&lt;/p&gt;&lt;p&gt;OpenAI has added new social features to ChatGPT in support of this group dynamic. The model can react with emojis, interpret conversational context to decide when to respond, and personalize generated content using members’ profile photos—such as inserting user likenesses into images when asked.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Privacy by default, controls for younger users&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI emphasized that privacy and user control are integral to group chat design. The feature operates independently of the user’s personalized ChatGPT memory, and no new memories are created from these interactions. &lt;/p&gt;&lt;p&gt;Participation requires an invitation link, and members are always able to see who is in a chat or leave at any time.&lt;/p&gt;&lt;p&gt;Users under the age of 18 are automatically shielded from sensitive content in group chats. Parents or guardians can disable group chat access altogether via built-in parental controls.&lt;/p&gt;&lt;p&gt;Group creators retain special permissions, including immunity from being removed by others. All other participants can be added or removed by group members.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A testbed for shared AI experiences&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI frames group chats as an early step toward richer, multi-user applications of AI, hinting at broader ambitions for ChatGPT as a shared workspace. The company expects to expand access over time and refine the feature based on how early users engage with it.&lt;/p&gt;&lt;p&gt;Keyan Zhang’s post suggests that the underlying model capabilities are far ahead of the interfaces users currently interact with. This pilot, in OpenAI’s view, offers a new “container” where more of the model’s latent capacity can be surfaced.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;“Our models have a lot more room to shine than today’s experiences show, and the current containers only use a fraction of their capabilities,” Zhang said.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;With this initial pilot focused on a limited set of markets, OpenAI is likely monitoring both usage patterns and cultural fit as it plans for broader deployment. For now, the group chat experiment offers a new way for users to interact with ChatGPT—and with each other—in real time, using a conversational interface that blends productivity and personalization.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Developer access: Still unclear&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI has not provided any indication that Group Chats will be accessible via the API or SDK. The current rollout is framed strictly within the ChatGPT product environment, with no mention of tool calls, developer hooks, or integration support for programmatic use. This absence of signaling leaves it unclear whether the company views group interaction as a future developer primitive or as a contained UX feature for end users only.&lt;/p&gt;&lt;p&gt;For enterprise teams exploring how to replicate multi-user collaboration with generative models, any current implementation would require custom orchestration—such as managing multi-party context and prompts across separate API calls, and handling session state and response merging externally. Until OpenAI provides formal support, Group Chats remain a closed interface feature rather than a developer-accessible capability.&lt;/p&gt;&lt;p&gt;Here is a standalone concluding subsection tailored for the article, focusing on what the ChatGPT Group Chat rollout means for enterprise decision makers in both pilot regions and globally:&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Implications for enterprise AI and data leaders&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For enterprise teams already leveraging AI platforms—or preparing to—OpenAI’s group chat feature introduces a new layer of multi-user collaboration that could shift how generative models are deployed across workflows. While the pilot is limited to users in Japan, New Zealand, South Korea, and Taiwan, its design and roadmap offer key signals for AI engineers, orchestration specialists, and data leads globally.&lt;/p&gt;&lt;p&gt;AI engineers managing large language model (LLM) deployments can now begin to conceptualize real-time, multi-user interfaces not just as support tools, but as collaborative environments for research, content generation, and ideation. This adds another front in model tuning: not just how models respond to individuals, but how they behave in live group settings with context shifts and varied user intentions.&lt;/p&gt;&lt;p&gt;For AI orchestration leads, the ability to integrate ChatGPT into collaborative flows without exposing private memory or requiring custom builds may reduce friction in piloting generative AI in cross-functional teams. These group sessions could serve as lightweight alternatives to internal tools for brainstorming, prototyping, or knowledge sharing—useful for teams constrained by infrastructure, budget, or time.&lt;/p&gt;&lt;p&gt;Enterprise data managers may also find use cases in structured group chat sessions for data annotation, taxonomy validation, or internal training support. The system’s lack of memory persistence adds a level of data isolation that aligns with standard security and compliance practices—though global rollout will be key to validating regional data handling standards.&lt;/p&gt;&lt;p&gt;As group chat capabilities evolve, decision makers should monitor how shared usage patterns might inform future model behaviors, auditing needs, and governance structures. In the long term, features like these will influence not just how organizations interact with generative AI, but how they design team-level interfaces around it.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/chatgpt-group-chats-are-here-but-not-for-everyone-yet</guid><pubDate>Fri, 14 Nov 2025 15:54:00 +0000</pubDate></item><item><title>[NEW] How to Unlock Accelerated AI Storage Performance With RDMA for S3-Compatible Storage (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/s3-compatible-ai-storage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/rdma-for-s3-compatible-storage-main-feature.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today’s AI workloads are data-intensive, requiring more scalable and affordable storage than ever. By 2028, enterprises are projected to generate nearly 400 zettabytes of data annually, with 90% of new data being unstructured, comprising audio, video, PDFs, images and more.&lt;/p&gt;
&lt;p&gt;This massive scale, combined with the need for data portability between on-premises infrastructure and the cloud, is pushing the AI industry to evaluate new storage options.&lt;/p&gt;
&lt;p&gt;Enter RDMA for S3-compatible storage — which uses remote direct memory access (RDMA) to accelerate the S3-application programming interface (API)-based storage protocol and is optimized for AI data and workloads.&lt;/p&gt;
&lt;p&gt;Object storage has long been used as a lower-cost storage option for applications, such as archive, backups, data lakes and activity logs, that didn’t require the fastest performance. While some customers are already using object storage for AI training, they want more performance for the fast-paced world of AI.&lt;/p&gt;
&lt;p&gt;This solution, which incorporates NVIDIA networking, delivers faster and more efficient object storage by using RDMA for object data transfers.&lt;/p&gt;
&lt;p&gt;For customers, this means higher throughput per terabyte of storage, higher throughput per watt, lower cost per terabyte and significantly lower latencies compared with TCP, the traditional network transport protocol for object storage.&lt;/p&gt;
&lt;p&gt;Other benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Lower Cost:&lt;/b&gt; End users can lower the cost of their AI storage, which can also speed up project approval and implementation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Workload Portability:&lt;/b&gt; Customers can run their AI workloads unmodified in both on premises and in cloud service provider and neocloud environments, using a common storage API.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Accelerated Storage: &lt;/b&gt;Faster data access and performance for AI training and inference — including vector databases and key-value cache storage for inference in AI factories.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;AI data platform&lt;/b&gt; solutions gain faster storage object storage access and more metadata for content indexing and retrieval.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Reduced CPU Utilization:&lt;/b&gt; RDMA for S3-compatible storage doesn’t use the host CPU for data transfer, meaning this critical resource is available to deliver AI value for customers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA has developed RDMA client and server libraries to accelerate object storage. Storage partners have integrated these server libraries into their storage solutions to enable RDMA data transfer for S3-API-based object storage, leading to faster data transfers and higher efficiency for AI workloads.&lt;/p&gt;
&lt;p&gt;Client libraries for RDMA for S3-compatible storage run on AI GPU compute nodes. This allows AI workloads to access object storage data much faster than traditional TCP access — improving AI workload performance and GPU utilization.&lt;/p&gt;
&lt;p&gt;While the initial libraries are optimized for NVIDIA GPUs and networking, the architecture itself is open, because other vendors and customers can contribute to the client libraries and incorporate them into their software. They can also write their own software to support and use the RDMA for S3-compatible storage APIs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Standardization, Availability and Adoption &lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA is working with partners to standardize RDMA for S3-compatible storage.&lt;/p&gt;
&lt;p&gt;Several key object storage partners are already adopting the new technology. Cloudian, Dell Technologies and HPE are all incorporating RDMA for S3-compatible libraries into their high-performance object storage products: Cloudian HyperStore, Dell ObjectScale and the HPE Alletra Storage MP X10000.&lt;/p&gt;
&lt;p&gt;“Object storage is the future of scalable data management for AI,” said Jon Toor, chief marketing officer at Cloudian. “Cloudian is leading efforts with NVIDIA to standardize RDMA for S3-compatible storage, which enables faster, more efficient object storage that helps scale AI solutions and reduce storage costs. Standardization and Cloudian’s S3-API compatibility will seamlessly bring scalability and performance to thousands of existing S3-based applications and tools, both on premises and in the cloud.”&lt;/p&gt;
&lt;p&gt;“AI workloads demand storage performance at scale with thousands of GPUs reading or writing data concurrently, and enterprise customers, with multiple AI factories — on premises and in the cloud — desire AI workload portability for objects,” said Rajesh Rajaraman, chief technology officer and vice president of Dell Technologies Storage, Data and Cyber Resilience. “Dell Technologies has collaborated with NVIDIA to integrate RDMA for S3-compatible storage acceleration into Dell ObjectScale, object storage that delivers unmatched scalability, performance and dramatically lower latency with end-to-end RDMA. The latest Dell ObjectScale software update will provide an excellent storage foundation for AI factories and AI data platforms.”&lt;/p&gt;
&lt;p&gt;“As AI workloads continue to grow in scale and intensity, NVIDIA’s innovations in RDMA for S3-compatible storage APIs and libraries are redefining how data moves at massive scale,” said Jim O’Dorisio, senior vice president and general manager of storage at HPE. “Working closely with NVIDIA, HPE has built a solution that accelerates throughput, reduces latency and lowers total cost of ownership. With RDMA for S3-compatible storage capabilities now integrated into HPE Alletra Storage MP X10000, we are extending our leadership in intelligent, scalable storage for unstructured and AI-driven workloads.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;NVIDIA’s RDMA for S3-compatible storage libraries are now available to select partners and are expected to be generally available via the &lt;/i&gt;&lt;i&gt;NVIDIA CUDA Toolkit&lt;/i&gt;&lt;i&gt; in January. Plus, learn more about a new NVIDIA Object Storage Certification, part of the &lt;/i&gt;&lt;i&gt;NVIDIA-Certified Storage program&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/rdma-for-s3-compatible-storage-main-feature.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today’s AI workloads are data-intensive, requiring more scalable and affordable storage than ever. By 2028, enterprises are projected to generate nearly 400 zettabytes of data annually, with 90% of new data being unstructured, comprising audio, video, PDFs, images and more.&lt;/p&gt;
&lt;p&gt;This massive scale, combined with the need for data portability between on-premises infrastructure and the cloud, is pushing the AI industry to evaluate new storage options.&lt;/p&gt;
&lt;p&gt;Enter RDMA for S3-compatible storage — which uses remote direct memory access (RDMA) to accelerate the S3-application programming interface (API)-based storage protocol and is optimized for AI data and workloads.&lt;/p&gt;
&lt;p&gt;Object storage has long been used as a lower-cost storage option for applications, such as archive, backups, data lakes and activity logs, that didn’t require the fastest performance. While some customers are already using object storage for AI training, they want more performance for the fast-paced world of AI.&lt;/p&gt;
&lt;p&gt;This solution, which incorporates NVIDIA networking, delivers faster and more efficient object storage by using RDMA for object data transfers.&lt;/p&gt;
&lt;p&gt;For customers, this means higher throughput per terabyte of storage, higher throughput per watt, lower cost per terabyte and significantly lower latencies compared with TCP, the traditional network transport protocol for object storage.&lt;/p&gt;
&lt;p&gt;Other benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Lower Cost:&lt;/b&gt; End users can lower the cost of their AI storage, which can also speed up project approval and implementation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Workload Portability:&lt;/b&gt; Customers can run their AI workloads unmodified in both on premises and in cloud service provider and neocloud environments, using a common storage API.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Accelerated Storage: &lt;/b&gt;Faster data access and performance for AI training and inference — including vector databases and key-value cache storage for inference in AI factories.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;AI data platform&lt;/b&gt; solutions gain faster storage object storage access and more metadata for content indexing and retrieval.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Reduced CPU Utilization:&lt;/b&gt; RDMA for S3-compatible storage doesn’t use the host CPU for data transfer, meaning this critical resource is available to deliver AI value for customers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA has developed RDMA client and server libraries to accelerate object storage. Storage partners have integrated these server libraries into their storage solutions to enable RDMA data transfer for S3-API-based object storage, leading to faster data transfers and higher efficiency for AI workloads.&lt;/p&gt;
&lt;p&gt;Client libraries for RDMA for S3-compatible storage run on AI GPU compute nodes. This allows AI workloads to access object storage data much faster than traditional TCP access — improving AI workload performance and GPU utilization.&lt;/p&gt;
&lt;p&gt;While the initial libraries are optimized for NVIDIA GPUs and networking, the architecture itself is open, because other vendors and customers can contribute to the client libraries and incorporate them into their software. They can also write their own software to support and use the RDMA for S3-compatible storage APIs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Standardization, Availability and Adoption &lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA is working with partners to standardize RDMA for S3-compatible storage.&lt;/p&gt;
&lt;p&gt;Several key object storage partners are already adopting the new technology. Cloudian, Dell Technologies and HPE are all incorporating RDMA for S3-compatible libraries into their high-performance object storage products: Cloudian HyperStore, Dell ObjectScale and the HPE Alletra Storage MP X10000.&lt;/p&gt;
&lt;p&gt;“Object storage is the future of scalable data management for AI,” said Jon Toor, chief marketing officer at Cloudian. “Cloudian is leading efforts with NVIDIA to standardize RDMA for S3-compatible storage, which enables faster, more efficient object storage that helps scale AI solutions and reduce storage costs. Standardization and Cloudian’s S3-API compatibility will seamlessly bring scalability and performance to thousands of existing S3-based applications and tools, both on premises and in the cloud.”&lt;/p&gt;
&lt;p&gt;“AI workloads demand storage performance at scale with thousands of GPUs reading or writing data concurrently, and enterprise customers, with multiple AI factories — on premises and in the cloud — desire AI workload portability for objects,” said Rajesh Rajaraman, chief technology officer and vice president of Dell Technologies Storage, Data and Cyber Resilience. “Dell Technologies has collaborated with NVIDIA to integrate RDMA for S3-compatible storage acceleration into Dell ObjectScale, object storage that delivers unmatched scalability, performance and dramatically lower latency with end-to-end RDMA. The latest Dell ObjectScale software update will provide an excellent storage foundation for AI factories and AI data platforms.”&lt;/p&gt;
&lt;p&gt;“As AI workloads continue to grow in scale and intensity, NVIDIA’s innovations in RDMA for S3-compatible storage APIs and libraries are redefining how data moves at massive scale,” said Jim O’Dorisio, senior vice president and general manager of storage at HPE. “Working closely with NVIDIA, HPE has built a solution that accelerates throughput, reduces latency and lowers total cost of ownership. With RDMA for S3-compatible storage capabilities now integrated into HPE Alletra Storage MP X10000, we are extending our leadership in intelligent, scalable storage for unstructured and AI-driven workloads.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;NVIDIA’s RDMA for S3-compatible storage libraries are now available to select partners and are expected to be generally available via the &lt;/i&gt;&lt;i&gt;NVIDIA CUDA Toolkit&lt;/i&gt;&lt;i&gt; in January. Plus, learn more about a new NVIDIA Object Storage Certification, part of the &lt;/i&gt;&lt;i&gt;NVIDIA-Certified Storage program&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/s3-compatible-ai-storage/</guid><pubDate>Fri, 14 Nov 2025 16:00:54 +0000</pubDate></item><item><title>[NEW] OpenAI says it’s fixed ChatGPT’s em dash problem (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/14/openai-says-its-fixed-chatgpts-em-dash-problem/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says ChatGPT will now ditch the em dashes if you tell it to. The telltale sign that supposedly signals text written by AI has popped up everywhere in recent months, including in school papers, emails, comments, customer service chats, LinkedIn posts, online forums, ad copy, and more. The inclusion of the em dash has led people to criticize those writers for being lazy and turning to an AI chatbot to do their work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, many have also argued for the em dash, saying it’s been a part of their writing well before LLMs adopted the punctuation. However, the fact that chatbots couldn’t seem to avoid its use made the so-called “ChatGPT hyphen” a newly objectionable addition to any text, even if they weren’t a reliable signal of content created by generative AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The problem had stumped OpenAI for some time, as ChatGPT users were unable to get the chatbot to stop using the symbol, even when they specifically asked it not to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, OpenAI CEO Sam Altman says the company has fixed the problem. In a post on X, Altman writes, “If you tell ChatGPT not to use em-dashes in your custom instructions, it finally does what it’s supposed to do,” calling the update a “small-but-happy win.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Small-but-happy win:&lt;/p&gt;&lt;p&gt;If you tell ChatGPT not to use em-dashes in your custom instructions, it finally does what it's supposed to do!&lt;/p&gt;— Sam Altman (@sama) November 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company explains in a post on Threads (where it forced ChatGPT to apologize for “ruining the em dash”) that ChatGPT will be better at not using the em dash if you instruct it not to via the custom instructions in your personalization settings. That means it won’t necessarily eliminate the em dash from its output by default, but you will at least have more control over the frequency of its appearance.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says ChatGPT will now ditch the em dashes if you tell it to. The telltale sign that supposedly signals text written by AI has popped up everywhere in recent months, including in school papers, emails, comments, customer service chats, LinkedIn posts, online forums, ad copy, and more. The inclusion of the em dash has led people to criticize those writers for being lazy and turning to an AI chatbot to do their work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, many have also argued for the em dash, saying it’s been a part of their writing well before LLMs adopted the punctuation. However, the fact that chatbots couldn’t seem to avoid its use made the so-called “ChatGPT hyphen” a newly objectionable addition to any text, even if they weren’t a reliable signal of content created by generative AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The problem had stumped OpenAI for some time, as ChatGPT users were unable to get the chatbot to stop using the symbol, even when they specifically asked it not to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, OpenAI CEO Sam Altman says the company has fixed the problem. In a post on X, Altman writes, “If you tell ChatGPT not to use em-dashes in your custom instructions, it finally does what it’s supposed to do,” calling the update a “small-but-happy win.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Small-but-happy win:&lt;/p&gt;&lt;p&gt;If you tell ChatGPT not to use em-dashes in your custom instructions, it finally does what it's supposed to do!&lt;/p&gt;— Sam Altman (@sama) November 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company explains in a post on Threads (where it forced ChatGPT to apologize for “ruining the em dash”) that ChatGPT will be better at not using the em dash if you instruct it not to via the custom instructions in your personalization settings. That means it won’t necessarily eliminate the em dash from its output by default, but you will at least have more control over the frequency of its appearance.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/14/openai-says-its-fixed-chatgpts-em-dash-problem/</guid><pubDate>Fri, 14 Nov 2025 17:59:45 +0000</pubDate></item></channel></rss>