<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 14 Jul 2025 18:35:14 +0000</lastBuildDate><item><title>California is set to become the first US state to manage power outages with AI (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/14/1120027/california-set-to-manage-power-outages-with-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP19299598296299-crop.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;California's statewide power grid operator is poised to become the first in North America to deploy artificial intelligence to manage outages, &lt;em&gt;MIT Technology Review&lt;/em&gt; has learned.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We wanted to modernize our grid operations. This fits in perfectly with that,” says Gopakumar Gopinathan, a senior advisor on power system technologies at the California Independent System Operator—known as the CAISO and pronounced KAI-so. “AI is already transforming different industries. But we haven’t seen many examples of it being used in our industry.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;At the DTECH Midwest utility industry summit in Minneapolis on July 15, CAISO is set to announce a deal to run a pilot program using new AI software called Genie, from the energy-services giant OATI. The software uses generative AI to analyze and carry out real-time analyses for grid operators and comes with the potential to autonomously make decisions about key functions on the grid, a switch that might resemble going from uniformed traffic officers to sensor-equipped stoplights.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But while CAISO may deliver electrons to cutting-edge Silicon Valley companies and laboratories, the actual task of managing the state’s electrical system is surprisingly analog.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Today, CAISO engineers scan outage reports for keywords about maintenance that’s planned or in the works, read through the notes, and then load each item into the grid software system to run calculations on how a downed line or transformer might affect power supply.&lt;/p&gt;  &lt;p&gt;“Even if it takes you less than a minute to scan one on average, when you amplify that over 200 or 300 outages, it adds up,” says Abhimanyu Thakur, OATI’s vice president of platforms, visualization, and analytics. “Then different departments are doing it for their own respective keywords. Now we consolidate all of that into a single dictionary of keywords and AI can do this scan and generate a report proactively.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If CAISO finds that Genie produces reliable, more efficient data analyses for managing outages, Gopinathan says, the operator may consider automating more functions on the grid. “After a few rounds of testing, I think we’ll have an idea about what is the right time to call it successful or not,” he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Regardless of the outcome, the experiment marks a significant shift. Most grid operators are using the same systems that utilities have used “for decades,” says Richard Doying, who spent more than 20 years as a top executive at the Midcontinent Independent System Operator, the grid operator for an area encompassing 15 states from the upper Midwest down to Louisiana.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“These organizations are carved up for people working on very specific, specialized tasks and using their own proprietary tools that they’ve developed over time,” says Doying, now a vice president at the consultancy Grid Strategies. “To the extent that some of these new AI tools are able to draw from data across different areas of an organization and conduct more sophisticated analysis, that’s only helpful for grid operators.”&lt;/p&gt;  &lt;p&gt;Last year, a Department of Energy report found that AI had potential to speed up studies on grid capacity and transmission, improve weather forecasting to help predict how much energy wind and solar plants would produce at a given time, and optimize planning for electric-vehicle charging networks. Another report by the energy department’s Loan Programs Office concluded that adding more “advanced” technology such as sensors to various pieces of equipment will generate data that can enable AI to do much more over time.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;In April, the PJM Interconnection—the nation’s largest grid system, spanning 13 states along the densely populated mid-Atlantic and Eastern Seaboard—took a big step toward embracing AI by inking a deal with Google to use its Tapestry software to improve regional planning and speed up grid connections for new power generators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;ERCOT, the Texas grid system, is considering adopting technology similar to what CAISO is now set to use, according to a source with knowledge of the plans who requested anonymity because they were not authorized to speak publicly. ERCOT did not respond to a request for comment.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Australia offers an example of what the future may look like. In New South Wales, where grid sensors and smart technology are more widely deployed, AI software rolled out in February is now predicting the production and flow of electricity from rooftop solar units across the state and automatically adjusting how much power from those panels can enter the grid.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Until now, much of the discussion around AI and energy has focused on the electricity demands of AI data centers (check out &lt;em&gt;MIT Technology Review&lt;/em&gt;’s Power Hungry series for more on this).&lt;/p&gt; 

 &lt;p&gt;“We’ve been talking a lot about what the grid can do for AI and not nearly as much about what AI can do for the grid,” says Charles Hua, a coauthor of one of last year’s Energy Department reports who now serves executive director of PowerLines, a nonprofit that advocates for improving the affordability and reliability of US grids. “In general, there’s a huge opportunity for grid operators, regulators, and other stakeholders in the utility regulatory system to use AI effectively and harness it for a more resilient, modernized, and strengthened grid.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For now, Gopinathan says, he’s remaining cautiously optimistic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I don’t want to overhype it,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, he adds, “it’s a first step for bigger automation.”&lt;/p&gt;  &lt;p&gt;“Right now, this is more limited to our outage management system. Genie isn’t talking to our other parts yet,” he says. “But I see a world where AI agents are able to do a lot more.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP19299598296299-crop.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;California's statewide power grid operator is poised to become the first in North America to deploy artificial intelligence to manage outages, &lt;em&gt;MIT Technology Review&lt;/em&gt; has learned.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We wanted to modernize our grid operations. This fits in perfectly with that,” says Gopakumar Gopinathan, a senior advisor on power system technologies at the California Independent System Operator—known as the CAISO and pronounced KAI-so. “AI is already transforming different industries. But we haven’t seen many examples of it being used in our industry.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;At the DTECH Midwest utility industry summit in Minneapolis on July 15, CAISO is set to announce a deal to run a pilot program using new AI software called Genie, from the energy-services giant OATI. The software uses generative AI to analyze and carry out real-time analyses for grid operators and comes with the potential to autonomously make decisions about key functions on the grid, a switch that might resemble going from uniformed traffic officers to sensor-equipped stoplights.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But while CAISO may deliver electrons to cutting-edge Silicon Valley companies and laboratories, the actual task of managing the state’s electrical system is surprisingly analog.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Today, CAISO engineers scan outage reports for keywords about maintenance that’s planned or in the works, read through the notes, and then load each item into the grid software system to run calculations on how a downed line or transformer might affect power supply.&lt;/p&gt;  &lt;p&gt;“Even if it takes you less than a minute to scan one on average, when you amplify that over 200 or 300 outages, it adds up,” says Abhimanyu Thakur, OATI’s vice president of platforms, visualization, and analytics. “Then different departments are doing it for their own respective keywords. Now we consolidate all of that into a single dictionary of keywords and AI can do this scan and generate a report proactively.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If CAISO finds that Genie produces reliable, more efficient data analyses for managing outages, Gopinathan says, the operator may consider automating more functions on the grid. “After a few rounds of testing, I think we’ll have an idea about what is the right time to call it successful or not,” he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Regardless of the outcome, the experiment marks a significant shift. Most grid operators are using the same systems that utilities have used “for decades,” says Richard Doying, who spent more than 20 years as a top executive at the Midcontinent Independent System Operator, the grid operator for an area encompassing 15 states from the upper Midwest down to Louisiana.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“These organizations are carved up for people working on very specific, specialized tasks and using their own proprietary tools that they’ve developed over time,” says Doying, now a vice president at the consultancy Grid Strategies. “To the extent that some of these new AI tools are able to draw from data across different areas of an organization and conduct more sophisticated analysis, that’s only helpful for grid operators.”&lt;/p&gt;  &lt;p&gt;Last year, a Department of Energy report found that AI had potential to speed up studies on grid capacity and transmission, improve weather forecasting to help predict how much energy wind and solar plants would produce at a given time, and optimize planning for electric-vehicle charging networks. Another report by the energy department’s Loan Programs Office concluded that adding more “advanced” technology such as sensors to various pieces of equipment will generate data that can enable AI to do much more over time.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;In April, the PJM Interconnection—the nation’s largest grid system, spanning 13 states along the densely populated mid-Atlantic and Eastern Seaboard—took a big step toward embracing AI by inking a deal with Google to use its Tapestry software to improve regional planning and speed up grid connections for new power generators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;ERCOT, the Texas grid system, is considering adopting technology similar to what CAISO is now set to use, according to a source with knowledge of the plans who requested anonymity because they were not authorized to speak publicly. ERCOT did not respond to a request for comment.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Australia offers an example of what the future may look like. In New South Wales, where grid sensors and smart technology are more widely deployed, AI software rolled out in February is now predicting the production and flow of electricity from rooftop solar units across the state and automatically adjusting how much power from those panels can enter the grid.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Until now, much of the discussion around AI and energy has focused on the electricity demands of AI data centers (check out &lt;em&gt;MIT Technology Review&lt;/em&gt;’s Power Hungry series for more on this).&lt;/p&gt; 

 &lt;p&gt;“We’ve been talking a lot about what the grid can do for AI and not nearly as much about what AI can do for the grid,” says Charles Hua, a coauthor of one of last year’s Energy Department reports who now serves executive director of PowerLines, a nonprofit that advocates for improving the affordability and reliability of US grids. “In general, there’s a huge opportunity for grid operators, regulators, and other stakeholders in the utility regulatory system to use AI effectively and harness it for a more resilient, modernized, and strengthened grid.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For now, Gopinathan says, he’s remaining cautiously optimistic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I don’t want to overhype it,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, he adds, “it’s a first step for bigger automation.”&lt;/p&gt;  &lt;p&gt;“Right now, this is more limited to our outage management system. Genie isn’t talking to our other parts yet,” he says. “But I see a world where AI agents are able to do a lot more.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/14/1120027/california-set-to-manage-power-outages-with-ai/</guid><pubDate>Mon, 14 Jul 2025 09:00:00 +0000</pubDate></item><item><title>FDA’s draft guidance on AI/ML has startups on high alert (AI News)</title><link>https://www.artificialintelligence-news.com/news/fdas-draft-guidance-on-ai-ml-has-startups-on-high-alert/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/ai-in-healthcare.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/ai-in-healthcare.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/fdas-draft-guidance-on-ai-ml-has-startups-on-high-alert/</guid><pubDate>Mon, 14 Jul 2025 11:01:44 +0000</pubDate></item><item><title>The Download: California’s AI power plans, and and why it’s so hard to make welfare AI fair (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/14/1120071/the-download-californias-ai-power-plans-and-and-why-its-so-hard-to-make-welfare-ai-fair/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;California is set to become the first US state to manage power outages with AI&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;California's statewide power grid operator is poised to become the first in North America to deploy artificial intelligence to manage outages, &lt;em&gt;MIT Technology Review&lt;/em&gt; has learned.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At an industry summit in Minneapolis tomorrow, the California Independent System Operator is set to announce a deal to run a pilot program using new AI software called Genie, from the energy-services giant OATI.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The software uses generative AI to analyze and carry out real-time analyses for grid operators and comes with the potential to autonomously make decisions about key functions on the grid, a switch that might resemble going from uniformed traffic officers to sensor-equipped stoplights. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Alexander C. Kaufman&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why it’s so hard to make welfare AI fair&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There are plenty of stories about AI that’s caused harm when deployed in sensitive situations, and in many of those cases, the systems were developed without much concern to what it meant to be fair or how to implement fairness.&lt;/p&gt;&lt;p&gt;But the city of Amsterdam did spend a lot of time and money to try to create ethical AI—in fact, it followed every recommendation in the responsible AI playbook. But when it deployed it in the real world, it still couldn’t remove biases. So why did Amsterdam fail? And more importantly: Can this ever be done right?&lt;/p&gt;&lt;p&gt;Join our editor Amanda Silverman, investigative reporter Eileen Guo and Gabriel Geiger, an investigative reporter from Lighthouse Reports, for a subscriber-only Roundtables conversation at 1pm ET on Wednesday July 30 to explore if algorithms can ever be fair. Register here!&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Trump’s ‘big, beautiful bill’ is already hurting sick children&lt;br /&gt;&lt;/strong&gt;And hundreds of hospitals are likely to close, too. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;His administration is going after easy targets, which includes sick children. &lt;/em&gt;(Salon $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;The US overseas worker purge is hitting Amazon hard&lt;/strong&gt;&lt;br /&gt;Its warehouse employees are losing their right to work in the US. (NYT $)&lt;br /&gt;+ &lt;em&gt;The US State Department has fired more than 1,350 workers so far. &lt;/em&gt;(Reuters)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Nvidia’s CEO claims China’s military probably won’t use its AI chips&lt;/strong&gt;&lt;br /&gt;But then he would say that, wouldn’t he. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Even after the Trump administration has eased chip software tool export restrictions. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Rival Huawei is planning a major AI chip overhaul. &lt;/em&gt;(The Information $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Scientists are reportedly hiding LLM instructions in their papers&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;Instructing models to give their work positive peer reviews. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Amazon is dragging its heels launching its web version of Alexa&lt;/strong&gt;&lt;br /&gt;It appears the company underestimated just how much work they had to do. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 SpaceX’s revenue is on the up&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;As Tesla continues to struggle. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Musk is not in favor of merging Tesla with xAI. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Trump is still planning to slash NASA’s budget. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Rivals are rising to challenge the dominance of SpaceX. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 The Air India crash was caused by a cut in the plane’s fuel supply&lt;br /&gt;&lt;/strong&gt;Cockpit voice recordings reveal that one pilot asked another why he’d cut off the supply. (CNN)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 The UK’s attempt to ape DOGE isn’t going well&lt;br /&gt;&lt;/strong&gt;Councils are already blocking Reform UK’s attempts to access sensitive data. (FT $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Even crypto executives can fall for crypto scams&lt;br /&gt;&lt;/strong&gt;Just ask the top brass from MoonPay, which lost $250,000 worth of Ethereum. (The Verge)&lt;br /&gt;+ &lt;em&gt;The people using humour to troll their spam texts. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Why landline phones refuse to die 📞&lt;/strong&gt;&lt;br /&gt;The business world still loves them. (WSJ $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"We don't like to work like that. I'm a Buddhist, so I believe in karma. I don't want to steal anyone's money."&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A man forced to work in an online scam center in Myanmar recounts his experience to Nikkei.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/12/GettyImages-1252251768-SAthumb.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China wants to restore the sea with high-tech marine ranches&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A short ferry ride from the port city of Yantai, on the northeast coast of China, sits Genghai No. 1, a 12,000-metric-ton ring of oil-rig-style steel platforms, advertised as a hotel and entertainment complex.&lt;/p&gt;&lt;p&gt;Genghai is in fact an unusual tourist destination, one that breeds 200,000 “high-quality marine fish” each year. The vast majority are released into the ocean as part of a process known as marine ranching.&lt;/p&gt;&lt;p&gt;The Chinese government sees this work as an urgent and necessary response to the bleak reality that fisheries are collapsing both in China and worldwide. But just how much of a difference can it make? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ You can easily make ice cream at home with just two ingredients.&amp;nbsp;&lt;br /&gt;+ Pink Floyd fans, this lecture is for you.&amp;nbsp;&lt;br /&gt;+ Lose yourself for a few minutes in the story behind an ancient Indian painting. (NYT $)&lt;br /&gt;+ Remember the days of idly surfing the web? Here’s how you can still recreate them.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;California is set to become the first US state to manage power outages with AI&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;California's statewide power grid operator is poised to become the first in North America to deploy artificial intelligence to manage outages, &lt;em&gt;MIT Technology Review&lt;/em&gt; has learned.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At an industry summit in Minneapolis tomorrow, the California Independent System Operator is set to announce a deal to run a pilot program using new AI software called Genie, from the energy-services giant OATI.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The software uses generative AI to analyze and carry out real-time analyses for grid operators and comes with the potential to autonomously make decisions about key functions on the grid, a switch that might resemble going from uniformed traffic officers to sensor-equipped stoplights. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Alexander C. Kaufman&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why it’s so hard to make welfare AI fair&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There are plenty of stories about AI that’s caused harm when deployed in sensitive situations, and in many of those cases, the systems were developed without much concern to what it meant to be fair or how to implement fairness.&lt;/p&gt;&lt;p&gt;But the city of Amsterdam did spend a lot of time and money to try to create ethical AI—in fact, it followed every recommendation in the responsible AI playbook. But when it deployed it in the real world, it still couldn’t remove biases. So why did Amsterdam fail? And more importantly: Can this ever be done right?&lt;/p&gt;&lt;p&gt;Join our editor Amanda Silverman, investigative reporter Eileen Guo and Gabriel Geiger, an investigative reporter from Lighthouse Reports, for a subscriber-only Roundtables conversation at 1pm ET on Wednesday July 30 to explore if algorithms can ever be fair. Register here!&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Trump’s ‘big, beautiful bill’ is already hurting sick children&lt;br /&gt;&lt;/strong&gt;And hundreds of hospitals are likely to close, too. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;His administration is going after easy targets, which includes sick children. &lt;/em&gt;(Salon $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;The US overseas worker purge is hitting Amazon hard&lt;/strong&gt;&lt;br /&gt;Its warehouse employees are losing their right to work in the US. (NYT $)&lt;br /&gt;+ &lt;em&gt;The US State Department has fired more than 1,350 workers so far. &lt;/em&gt;(Reuters)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Nvidia’s CEO claims China’s military probably won’t use its AI chips&lt;/strong&gt;&lt;br /&gt;But then he would say that, wouldn’t he. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Even after the Trump administration has eased chip software tool export restrictions. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Rival Huawei is planning a major AI chip overhaul. &lt;/em&gt;(The Information $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Scientists are reportedly hiding LLM instructions in their papers&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;Instructing models to give their work positive peer reviews. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Amazon is dragging its heels launching its web version of Alexa&lt;/strong&gt;&lt;br /&gt;It appears the company underestimated just how much work they had to do. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 SpaceX’s revenue is on the up&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;As Tesla continues to struggle. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Musk is not in favor of merging Tesla with xAI. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Trump is still planning to slash NASA’s budget. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Rivals are rising to challenge the dominance of SpaceX. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 The Air India crash was caused by a cut in the plane’s fuel supply&lt;br /&gt;&lt;/strong&gt;Cockpit voice recordings reveal that one pilot asked another why he’d cut off the supply. (CNN)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 The UK’s attempt to ape DOGE isn’t going well&lt;br /&gt;&lt;/strong&gt;Councils are already blocking Reform UK’s attempts to access sensitive data. (FT $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Even crypto executives can fall for crypto scams&lt;br /&gt;&lt;/strong&gt;Just ask the top brass from MoonPay, which lost $250,000 worth of Ethereum. (The Verge)&lt;br /&gt;+ &lt;em&gt;The people using humour to troll their spam texts. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Why landline phones refuse to die 📞&lt;/strong&gt;&lt;br /&gt;The business world still loves them. (WSJ $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"We don't like to work like that. I'm a Buddhist, so I believe in karma. I don't want to steal anyone's money."&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A man forced to work in an online scam center in Myanmar recounts his experience to Nikkei.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/12/GettyImages-1252251768-SAthumb.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China wants to restore the sea with high-tech marine ranches&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A short ferry ride from the port city of Yantai, on the northeast coast of China, sits Genghai No. 1, a 12,000-metric-ton ring of oil-rig-style steel platforms, advertised as a hotel and entertainment complex.&lt;/p&gt;&lt;p&gt;Genghai is in fact an unusual tourist destination, one that breeds 200,000 “high-quality marine fish” each year. The vast majority are released into the ocean as part of a process known as marine ranching.&lt;/p&gt;&lt;p&gt;The Chinese government sees this work as an urgent and necessary response to the bleak reality that fisheries are collapsing both in China and worldwide. But just how much of a difference can it make? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ You can easily make ice cream at home with just two ingredients.&amp;nbsp;&lt;br /&gt;+ Pink Floyd fans, this lecture is for you.&amp;nbsp;&lt;br /&gt;+ Lose yourself for a few minutes in the story behind an ancient Indian painting. (NYT $)&lt;br /&gt;+ Remember the days of idly surfing the web? Here’s how you can still recreate them.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/14/1120071/the-download-californias-ai-power-plans-and-and-why-its-so-hard-to-make-welfare-ai-fair/</guid><pubDate>Mon, 14 Jul 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Tomorrow: TechCrunch All Stage launches in Boston — and ticket prices rise (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/tomorrow-techcrunch-all-stage-launches-in-boston-and-ticket-prices-rise/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; officially kicks off tomorrow at 7:30 a.m. ET at SoWa Power Station in Boston — and that’s when ticket prices jump to full rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t just another founder event. It’s the summit built to help startups fundraise smarter, scale faster, and lead with impact. Whether you’re tightening your pitch, planning a raise, or navigating team growth, TC All Stage delivers the tactics and tools to take you further.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, until the doors open tomorrow, Founder Passes are just $100 and Investor Passes are $200 — the lowest rates available. Once the event begins, prices go up. Lock in your pass while you still can. &lt;strong&gt;Register here to lock in up to $475 in savings.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage tomorrow" class="wp-image-3027461" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/16x9_GeneralArticleImageHeader_TCAllStage_24HoursCountdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-practical-insights-proven-strategies"&gt;Practical insights. Proven strategies.&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;What sets TC All Stage apart? Real-world lessons from investors, builders, and operators who’ve scaled startups at every stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Here’s what’s happening tomorrow in Boston:&lt;/strong&gt;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;on scaling growth-stage companies, raising capital, hiring top talent, and building with AI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roundtables&lt;/strong&gt; that tackle startup challenges with tactical, honest advice&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;“&lt;strong&gt;So You Think You Can Pitch&lt;/strong&gt;” — founders pitch live onstage and get direct feedback from seasoned VCs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Curated 1:1 and small-group networking powered by Braindate to help you meet founders, funders, and operators who matter&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Satellite events&lt;/strong&gt; and founder meetups across the city&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-3 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders and investors engaging in high-impact networking at TechCrunch Early Stage 2024 in SoWa Power Station in Boston&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Roundtable session at TechCrunch Early Stage 2024 at SoWa Power Station in Boston&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-voices-behind-the-sessions"&gt;Meet the voices behind the sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Check out the &lt;strong&gt;full agenda&lt;/strong&gt; to see who’s taking the stage and what you can’t miss.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ellen Chisa&lt;/strong&gt;, Boldstart Ventures – building from inception with conviction&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Cathy Gao&lt;/strong&gt;, Sapphire Ventures – navigating Series C and growth-stage capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Gardner&lt;/strong&gt;, Underscore VC – blending human and AI in product development&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Charles Hudson&lt;/strong&gt;, Precursor Ventures – what VCs really look for at pre-seed&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Mo Jomaa&lt;/strong&gt;, CapitalG – preparing for IPO readiness from the beginning&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Brandon Krieg&lt;/strong&gt;, Stash – how technology is opening the doors to investing for everyone&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tiffany Luck&lt;/strong&gt;, NEA – crafting the perfect pitch with strategy and storytelling&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jennifer Neundorfer&lt;/strong&gt;, January Ventures – what AI means for early-stage company building&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Nikki Parker&lt;/strong&gt;, Insight Partners – building a growth-focused PR and marketing strategy from seed to public&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jahanvi Sardana&lt;/strong&gt;, Index Ventures – how to scale with intentionality&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco on October 19, 2022&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-final-hours-to-save"&gt;Final hours to save&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC All Stage&lt;/strong&gt; is just hours away. Don’t miss your chance to join the startup epicenter — and save up to $475 before doors open at 7:30 a.m. ET at SoWa Power Station. &lt;strong&gt;Register now&lt;/strong&gt; to join the conversations, gain practical takeaways, and pocket ticket savings.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; officially kicks off tomorrow at 7:30 a.m. ET at SoWa Power Station in Boston — and that’s when ticket prices jump to full rate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t just another founder event. It’s the summit built to help startups fundraise smarter, scale faster, and lead with impact. Whether you’re tightening your pitch, planning a raise, or navigating team growth, TC All Stage delivers the tactics and tools to take you further.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, until the doors open tomorrow, Founder Passes are just $100 and Investor Passes are $200 — the lowest rates available. Once the event begins, prices go up. Lock in your pass while you still can. &lt;strong&gt;Register here to lock in up to $475 in savings.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage tomorrow" class="wp-image-3027461" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/16x9_GeneralArticleImageHeader_TCAllStage_24HoursCountdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-practical-insights-proven-strategies"&gt;Practical insights. Proven strategies.&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;What sets TC All Stage apart? Real-world lessons from investors, builders, and operators who’ve scaled startups at every stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Here’s what’s happening tomorrow in Boston:&lt;/strong&gt;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;on scaling growth-stage companies, raising capital, hiring top talent, and building with AI&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roundtables&lt;/strong&gt; that tackle startup challenges with tactical, honest advice&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;“&lt;strong&gt;So You Think You Can Pitch&lt;/strong&gt;” — founders pitch live onstage and get direct feedback from seasoned VCs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Curated 1:1 and small-group networking powered by Braindate to help you meet founders, funders, and operators who matter&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Satellite events&lt;/strong&gt; and founder meetups across the city&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-3 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders and investors engaging in high-impact networking at TechCrunch Early Stage 2024 in SoWa Power Station in Boston&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Roundtable session at TechCrunch Early Stage 2024 at SoWa Power Station in Boston&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-voices-behind-the-sessions"&gt;Meet the voices behind the sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Check out the &lt;strong&gt;full agenda&lt;/strong&gt; to see who’s taking the stage and what you can’t miss.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ellen Chisa&lt;/strong&gt;, Boldstart Ventures – building from inception with conviction&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Cathy Gao&lt;/strong&gt;, Sapphire Ventures – navigating Series C and growth-stage capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Gardner&lt;/strong&gt;, Underscore VC – blending human and AI in product development&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Charles Hudson&lt;/strong&gt;, Precursor Ventures – what VCs really look for at pre-seed&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Mo Jomaa&lt;/strong&gt;, CapitalG – preparing for IPO readiness from the beginning&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Brandon Krieg&lt;/strong&gt;, Stash – how technology is opening the doors to investing for everyone&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tiffany Luck&lt;/strong&gt;, NEA – crafting the perfect pitch with strategy and storytelling&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jennifer Neundorfer&lt;/strong&gt;, January Ventures – what AI means for early-stage company building&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Nikki Parker&lt;/strong&gt;, Insight Partners – building a growth-focused PR and marketing strategy from seed to public&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jahanvi Sardana&lt;/strong&gt;, Index Ventures – how to scale with intentionality&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco on October 19, 2022&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-final-hours-to-save"&gt;Final hours to save&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC All Stage&lt;/strong&gt; is just hours away. Don’t miss your chance to join the startup epicenter — and save up to $475 before doors open at 7:30 a.m. ET at SoWa Power Station. &lt;strong&gt;Register now&lt;/strong&gt; to join the conversations, gain practical takeaways, and pocket ticket savings.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/tomorrow-techcrunch-all-stage-launches-in-boston-and-ticket-prices-rise/</guid><pubDate>Mon, 14 Jul 2025 13:30:00 +0000</pubDate></item><item><title>[NEW] The votes are in: TechCrunch Disrupt 2025 Audience Choice winners revealed for roundtables and breakouts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/the-votes-are-in-techcrunch-disrupt-2025-audience-choice-winners-revealed-for-roundtables-and-breakouts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;You voted — they made it onto the &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; agenda!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After reviewing hundreds of standout Call for Content submissions and opening the vote to the TechCrunch audience, we’ve locked in the top five roundtables and top five breakout sessions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Without further ado, meet the exceptional tech voices — and the sessions they’ll lead — that will shape the conversation at Disrupt 2025, taking place October 27-29 at San Francisco’s Moscone West. &lt;strong&gt;Visit the agenda page&lt;/strong&gt; for full session and speaker details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Grab your ticket now and save up to $675 before prices increase.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-breakout-session-winners"&gt;Breakout session winners&lt;/h2&gt;

&lt;h4 class="wp-block-heading" id="h-from-vibes-to-velocity-how-ai-tools-can-help-you-achieve-your-development-goals"&gt;From Vibes to Velocity: How AI Tools Can Help You Achieve Your Development Goals&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;With vibe coding on the rise, devs are looking to move faster and ship smarter. In this breakout, GitHub PM Tim Rogers dives into Copilot — the AI-powered peer programming tool used by more than 15 million — and how it’s reshaping workflows in an autonomous world.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-how-to-get-acquired-in-tech-without-selling-out-m-amp-a-tips-for-founders-and-builders"&gt;How to Get Acquired in Tech (Without Selling Out): M&amp;amp;A Tips for Founders and Builders&lt;/h4&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-5 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Aklil Ibssa" class="wp-image-3011690" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Aklil-Ibssa_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Aklil Ibssa&lt;/strong&gt;&lt;br /&gt;Head of Corporate Development and M&amp;amp;A&lt;br /&gt;Coinbase&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Coinbase just pulled off crypto’s biggest acquisition. In this no-BS session, learn how to make your project irresistible — from product-market fit to community traction — and position for M&amp;amp;A, investment, or partnership without compromising decentralization. If you’re an investor, you’ll get a cheat sheet for spotting teams building toward high-value outcomes.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-at-the-brink-strategic-playbook-for-national-security"&gt;AI at the Brink: Strategic Playbook for National Security&lt;/h3&gt;



&lt;p class="wp-block-paragraph"&gt;Advanced AI brings risks like bioweapons and cyberattacks amid global competition. This session explores strategic frameworks for AI safety, covering technical checks, non-proliferation, and supply chain security with Dan Hendrycks and key experts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-embracing-ai-for-a-better-digital-future"&gt;Embracing AI for a Better Digital Future&lt;/h3&gt;



&lt;p class="wp-block-paragraph"&gt;AI is at a crossroads, shaping whether it is additive or addictive, inclusive or harmful. Matt shows how Pinterest uses AI for positivity, personalization, and productivity, offering a responsible approach that drives innovation while prioritizing user well-being.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-agentic-ai-for-startups-automate-adapt-and-accelerate-growth"&gt;Agentic AI for Startups: Automate, Adapt, and Accelerate Growth&lt;/h3&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-8 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Anmol Rastagi" class="wp-image-3011692" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Anmol-Rastogi_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anmol Rastogi&lt;/strong&gt;&lt;br /&gt;Head of Product Management, AI &amp;amp; ML&lt;br /&gt;Amazon Business Amazon&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic AI is transforming startups by enabling automation, personalized experiences, and data-driven agility. This session covers identifying AI opportunities, building workflows, and measuring impact using real case studies to help founders accelerate growth and outpace competition.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-roundtable-session-winners"&gt;Roundtable session winners&lt;/h2&gt;





&lt;p class="wp-block-paragraph"&gt;Join Kindred co-founders Justine Palefsky and Tasneem Amina as they reveal how they transformed home swapping into a community-led movement. Learn their blueprint for building trust, turning members into ambassadors, and driving growth through authentic, values-driven community building.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-how-to-train-your-model-taming-ai-agents-without-breaking-them"&gt;How to Train Your Model: Taming AI Agents Without Breaking Them&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;This interactive session dives into balancing AI safety and usefulness, covering constitutional AI, red-teaming, and steering methods. Attendees will gain frameworks and strategies to build AI models that are both helpful and harmless without losing personality.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-future-of-space-economy-in-the-low-earth-orbit"&gt;Future of Space Economy in the Low Earth Orbit&lt;/h4&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-11 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Abhijeet Kumar" class="wp-image-3011689" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Abhijeet-Kumar_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Abhi Kumar&lt;/strong&gt;&lt;br /&gt;Lecturer, Investor, and Advisor&lt;br /&gt;UC Berkeley&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Low Earth Orbit (LEO) is evolving beyond satellites into manufacturing, energy, and data infrastructure. This session covers the emerging LEO economy, regulations, and investments, offering insights on partnering with space startups and leveraging orbital platforms for Earth industries.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-scaling-search-and-ai-for-millions-lessons-from-reddit-search"&gt;Scaling Search and AI for Millions: Lessons from Reddit Search&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;Explore how Reddit builds AI at scale, balancing relevance, safety, and bias for millions of users. This session tackles community expectations, ethical tradeoffs, and real-world challenges, inviting startups to join a candid discussion on trusted AI development.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-ai-evaluation-101-addressing-challenges-to-real-world-ai-applications"&gt;AI Evaluation 101: Addressing Challenges to Real-World AI Applications&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;This session breaks down how neural networks generate language and the challenges of deploying GenAI. Learn why evaluation matters and compare automated, judge-based, and human-rated methods to build tests that measure AI versus human performance for your use case.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-join-these-sessions-and-much-more-live-at-disrupt-2025"&gt;Join these sessions — and much more — live at Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;These 10 sessions are just a glimpse of the 250+ speakers and talks at Disrupt. Keep an eye on the &lt;strong&gt;agenda page&lt;/strong&gt; for new updates, and &lt;strong&gt;grab your ticket now&lt;/strong&gt; to save up to $675 before prices rise.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;You voted — they made it onto the &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; agenda!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After reviewing hundreds of standout Call for Content submissions and opening the vote to the TechCrunch audience, we’ve locked in the top five roundtables and top five breakout sessions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Without further ado, meet the exceptional tech voices — and the sessions they’ll lead — that will shape the conversation at Disrupt 2025, taking place October 27-29 at San Francisco’s Moscone West. &lt;strong&gt;Visit the agenda page&lt;/strong&gt; for full session and speaker details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Grab your ticket now and save up to $675 before prices increase.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-breakout-session-winners"&gt;Breakout session winners&lt;/h2&gt;

&lt;h4 class="wp-block-heading" id="h-from-vibes-to-velocity-how-ai-tools-can-help-you-achieve-your-development-goals"&gt;From Vibes to Velocity: How AI Tools Can Help You Achieve Your Development Goals&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;With vibe coding on the rise, devs are looking to move faster and ship smarter. In this breakout, GitHub PM Tim Rogers dives into Copilot — the AI-powered peer programming tool used by more than 15 million — and how it’s reshaping workflows in an autonomous world.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-how-to-get-acquired-in-tech-without-selling-out-m-amp-a-tips-for-founders-and-builders"&gt;How to Get Acquired in Tech (Without Selling Out): M&amp;amp;A Tips for Founders and Builders&lt;/h4&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-5 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Aklil Ibssa" class="wp-image-3011690" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Aklil-Ibssa_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Aklil Ibssa&lt;/strong&gt;&lt;br /&gt;Head of Corporate Development and M&amp;amp;A&lt;br /&gt;Coinbase&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Coinbase just pulled off crypto’s biggest acquisition. In this no-BS session, learn how to make your project irresistible — from product-market fit to community traction — and position for M&amp;amp;A, investment, or partnership without compromising decentralization. If you’re an investor, you’ll get a cheat sheet for spotting teams building toward high-value outcomes.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-at-the-brink-strategic-playbook-for-national-security"&gt;AI at the Brink: Strategic Playbook for National Security&lt;/h3&gt;



&lt;p class="wp-block-paragraph"&gt;Advanced AI brings risks like bioweapons and cyberattacks amid global competition. This session explores strategic frameworks for AI safety, covering technical checks, non-proliferation, and supply chain security with Dan Hendrycks and key experts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-embracing-ai-for-a-better-digital-future"&gt;Embracing AI for a Better Digital Future&lt;/h3&gt;



&lt;p class="wp-block-paragraph"&gt;AI is at a crossroads, shaping whether it is additive or addictive, inclusive or harmful. Matt shows how Pinterest uses AI for positivity, personalization, and productivity, offering a responsible approach that drives innovation while prioritizing user well-being.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-agentic-ai-for-startups-automate-adapt-and-accelerate-growth"&gt;Agentic AI for Startups: Automate, Adapt, and Accelerate Growth&lt;/h3&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-8 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Anmol Rastagi" class="wp-image-3011692" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Anmol-Rastogi_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anmol Rastogi&lt;/strong&gt;&lt;br /&gt;Head of Product Management, AI &amp;amp; ML&lt;br /&gt;Amazon Business Amazon&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic AI is transforming startups by enabling automation, personalized experiences, and data-driven agility. This session covers identifying AI opportunities, building workflows, and measuring impact using real case studies to help founders accelerate growth and outpace competition.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-roundtable-session-winners"&gt;Roundtable session winners&lt;/h2&gt;





&lt;p class="wp-block-paragraph"&gt;Join Kindred co-founders Justine Palefsky and Tasneem Amina as they reveal how they transformed home swapping into a community-led movement. Learn their blueprint for building trust, turning members into ambassadors, and driving growth through authentic, values-driven community building.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-how-to-train-your-model-taming-ai-agents-without-breaking-them"&gt;How to Train Your Model: Taming AI Agents Without Breaking Them&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;This interactive session dives into balancing AI safety and usefulness, covering constitutional AI, red-teaming, and steering methods. Attendees will gain frameworks and strategies to build AI models that are both helpful and harmless without losing personality.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-future-of-space-economy-in-the-low-earth-orbit"&gt;Future of Space Economy in the Low Earth Orbit&lt;/h4&gt;

&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-11 wp-block-group-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025 Abhijeet Kumar" class="wp-image-3011689" height="400" src="https://techcrunch.com/wp-content/uploads/2024/12/Abhijeet-Kumar_speaker_circle_400x400.png?w=400" width="400" /&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Abhi Kumar&lt;/strong&gt;&lt;br /&gt;Lecturer, Investor, and Advisor&lt;br /&gt;UC Berkeley&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Low Earth Orbit (LEO) is evolving beyond satellites into manufacturing, energy, and data infrastructure. This session covers the emerging LEO economy, regulations, and investments, offering insights on partnering with space startups and leveraging orbital platforms for Earth industries.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-scaling-search-and-ai-for-millions-lessons-from-reddit-search"&gt;Scaling Search and AI for Millions: Lessons from Reddit Search&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;Explore how Reddit builds AI at scale, balancing relevance, safety, and bias for millions of users. This session tackles community expectations, ethical tradeoffs, and real-world challenges, inviting startups to join a candid discussion on trusted AI development.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-ai-evaluation-101-addressing-challenges-to-real-world-ai-applications"&gt;AI Evaluation 101: Addressing Challenges to Real-World AI Applications&lt;/h4&gt;



&lt;p class="wp-block-paragraph"&gt;This session breaks down how neural networks generate language and the challenges of deploying GenAI. Learn why evaluation matters and compare automated, judge-based, and human-rated methods to build tests that measure AI versus human performance for your use case.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-join-these-sessions-and-much-more-live-at-disrupt-2025"&gt;Join these sessions — and much more — live at Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;These 10 sessions are just a glimpse of the 250+ speakers and talks at Disrupt. Keep an eye on the &lt;strong&gt;agenda page&lt;/strong&gt; for new updates, and &lt;strong&gt;grab your ticket now&lt;/strong&gt; to save up to $675 before prices rise.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/the-votes-are-in-techcrunch-disrupt-2025-audience-choice-winners-revealed-for-roundtables-and-breakouts/</guid><pubDate>Mon, 14 Jul 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] AI Testing and Evaluation: Learnings from cybersecurity (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&amp;nbsp;&lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;,&amp;nbsp;hosted by Microsoft Research’s&amp;nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Sullivan speaks with Professor Ciaran Martin&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, Tori Westerhoff&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN: &lt;/strong&gt;Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today, I’m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK’s intelligence, security, and cyber agency.&lt;/p&gt;



&lt;p&gt;And after our conversation, we’ll talk to Microsoft’s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Hi, Ciaran. Thank you so much for being here today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;CIARAN MARTIN:&lt;/strong&gt; Well, thanks so much for inviting me. It’s great to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Ciaran, before we get into some regulatory specifics, it’d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn’t exist at the time—I was invited to join the British government’s cybersecurity effort in a leadership role—is now a subset of GCHQ. That’s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.&lt;/p&gt;



&lt;p&gt;I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I mean, it’s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, risk assessment and testing, I think, are two different things. You can’t defend everything. If you defend everything, you’re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don’t want any of them to happen, but you have to have a hierarchy of harm.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN: &lt;/strong&gt;So that’s your risk assessment.&lt;/p&gt;



&lt;p&gt;The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you’ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what’s the cost-benefit analysis? And we find that &lt;em&gt;really&lt;/em&gt; hard.&lt;/p&gt;



&lt;p&gt;So that’s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we’re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it’s meeting those standards? So it’s a huge issue in cybersecurity and one that we’re always very conscious of. It’s really hard.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Given the scope of cybersecurity, are there any differences in testing, let’s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that’s well equipped. You have to be realistic.&lt;/p&gt;



&lt;p&gt;If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn’t. So you have to have some differentiation. So again, you’ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they’re never going to meet.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; It’s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.&lt;/p&gt;



&lt;p&gt;But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you’ve got a problem. And I think we’ve wrestled with that, and there’s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that’s going to evolve.&lt;/p&gt;



&lt;p&gt;The second point, which in some respects if you’ve got the right capabilities is slightly &lt;em&gt;easier&lt;/em&gt; but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.&lt;/p&gt;



&lt;p&gt;But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that’s really good because it’s saying to people that these are the things that are going to matter in the post-quantum age. Here’s the outline of the standards you’re going to have to meet; start looking at them. So there’s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that’s the era we’re in now.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what’s the real reason they haven’t?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, again, where do you start? I mean, most members of the public quite rightly haven’t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.&lt;/p&gt;



&lt;p&gt;And there’s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that’s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.&lt;/p&gt;



&lt;p&gt;The third one then is when your perimeter’s breached, be able to detect it more times than not. And when you can’t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn’t eliminate the harm, but you would reduce it quite substantially.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it’s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.&lt;/p&gt;



&lt;p&gt;We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we’ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you’re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that’s the crucial part—then that will help because it means that we’re not going to our boards and saying, or our shareholders, and saying that we should do this, and they’re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.&lt;/p&gt;



&lt;p&gt;The harder nut to crack is the smaller business. And I think there’s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can’t throttle small businesses with onerous regulation. At the same time, we’re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.&lt;/p&gt;



&lt;p&gt;There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, it’s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think they’re crucial, but they have to be practical. I’ve got a slight, sort of, high horse on this, if you don’t mind, Kathleen. It’s sort of … [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Of course.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn’t get us very far. There are other types.&lt;/p&gt;



&lt;p&gt;We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn’t provide. So I think it’s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.&lt;/p&gt;



&lt;p&gt;So pick a bit of the problem. Find some ways of doing it. Don’t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. &lt;em&gt;Oh, well, is this our role? You know, should we be doing this, that, and the other?&lt;/em&gt; Well, you know, sometimes certainly in this country, you think, well, who’s actually going to sue you over this, you know? So I wouldn’t over-programmatize it. Just get stuck practically into solving some problems.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I love that. Actually, [it] made me think, are there any surprising allies that you’ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Ooh! That’s a … that’s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not &lt;em&gt;immoral&lt;/em&gt;, &lt;em&gt;amoral&lt;/em&gt;. It just didn’t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what’s in it for them?&lt;/p&gt;



&lt;p&gt;And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn’t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it’s a really positive part of certainly the UK cybersecurity ecosystem.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, we’re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that standards, assurance, and testing &lt;em&gt;really&lt;/em&gt; matter, but it’s a bit like the discussion we’re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There’s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it’s not everything.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; My pleasure, Kathleen, thank you.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Now, I’m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.&lt;/p&gt;



&lt;p&gt;So, Tori, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TORI WESTERHOFF: &lt;/strong&gt;Thanks. I am so excited to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I’d love to just start a little bit more learning about your background. You’ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]&lt;/p&gt;



&lt;p&gt;I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as &lt;em&gt;AIRT&lt;/em&gt;; I’m sure I’ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There’s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.&lt;/p&gt;



&lt;p&gt;But my experience in national security and I’d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we’re thinking about critical industries, how we’re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that’s evolving all of the time, that’s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we’re shaping up how we approach it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we’ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.&lt;/p&gt;



&lt;p&gt;So if we’re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that’s creating mitigations. It’s platform-security folks who are creating mitigations at scale. And there’s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it’s a continuous cycle.&lt;/p&gt;



&lt;p&gt;And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we’ve pulled a lot of those assets and insights into the Azure [AI] Foundry AI Red Teaming Agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; You recently—actually, with your team—published a report that outlined lessons from testing over a hundred generative AI products. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think the most important takeaway from those lessons is that AI security is truly a team sport. You’ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we’re going to approach this with intentionality and responsibility.&lt;/p&gt;



&lt;p&gt;So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we’ve done, there’s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are &lt;em&gt;they&lt;/em&gt; using it?&lt;/p&gt;



&lt;p&gt;And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation &lt;em&gt;for&lt;/em&gt; &lt;em&gt;people&lt;/em&gt;, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. &lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Yeah, I think it’s such a broad set of perspectives to bring in, in the AI instance. Something that I’ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.&lt;/p&gt;



&lt;p&gt;So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you’re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we’re trying to really clarify terms and threats.&amp;nbsp;And you see it in updates of those frameworks, as well, that I really love.&lt;/p&gt;



&lt;p&gt;So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Mm-hmm.&lt;strong&gt; &lt;/strong&gt;In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization’s role &lt;em&gt;and&lt;/em&gt; scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we’re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.&lt;/p&gt;



&lt;p&gt;Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which &lt;em&gt;is&lt;/em&gt; really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”&lt;/p&gt;



&lt;p&gt;So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people’s trust almost as different variables that could affect the impact, right.&lt;/p&gt;



&lt;p&gt;So a good example is if we’re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it’s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing &lt;em&gt;empathy&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? &lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It’s not just saying, “Hey, there’s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven’t even thought of, we feel confident that we have the resources and the system?”&lt;/p&gt;



&lt;p&gt;So part of me is really intrigued by the process that we’re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we’re really excited about pushing out those insights in an experimental and longer-term way.&lt;/p&gt;



&lt;p&gt;I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about &lt;em&gt;are&lt;/em&gt; traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I’m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.&lt;/p&gt;



&lt;p&gt;So to me, integration of AI into those frameworks by those same standards means that we’re evolving security to include AI. We aren’t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.&lt;/p&gt;



&lt;p&gt;I think there’s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that’s our job. But the other side of cybersecurity is offense. And I’m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.&lt;/p&gt;



&lt;p&gt;Generally speaking, I think the best practice is to realize that we’re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I’d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I’ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I’m talking to you today is probably evidence that a ton of people are bringing in perspectives that don’t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we’re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No, I think we’re seeing that across the board. I mean, I’d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we’re creating into the hands of our customers and partners and ecosystem is just underscored.&lt;/p&gt;



&lt;p&gt;So on the note of speed, let’s shift gears a little bit to just a quick lightning round. I’d love to get maybe some quick thoughts from you, just 30-second answers here. I’ll start with one.&lt;/p&gt;



&lt;p&gt;Which headline-grabbing AI threat do you think is mostly hot air?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think we should pay attention to it all. I’m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Is there some sort of maybe new tool that you can’t wait to sneak into the red team arsenal?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we’re looking at agentic systems. So I would say a method, not a tool.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe’s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I’m going to not love that I did it.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Thank you so much for having me. This was a joy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&amp;nbsp;&lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;,&amp;nbsp;hosted by Microsoft Research’s&amp;nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Sullivan speaks with Professor Ciaran Martin&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, Tori Westerhoff&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN: &lt;/strong&gt;Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today, I’m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK’s intelligence, security, and cyber agency.&lt;/p&gt;



&lt;p&gt;And after our conversation, we’ll talk to Microsoft’s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Hi, Ciaran. Thank you so much for being here today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;CIARAN MARTIN:&lt;/strong&gt; Well, thanks so much for inviting me. It’s great to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Ciaran, before we get into some regulatory specifics, it’d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn’t exist at the time—I was invited to join the British government’s cybersecurity effort in a leadership role—is now a subset of GCHQ. That’s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.&lt;/p&gt;



&lt;p&gt;I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I mean, it’s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, risk assessment and testing, I think, are two different things. You can’t defend everything. If you defend everything, you’re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don’t want any of them to happen, but you have to have a hierarchy of harm.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN: &lt;/strong&gt;So that’s your risk assessment.&lt;/p&gt;



&lt;p&gt;The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you’ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what’s the cost-benefit analysis? And we find that &lt;em&gt;really&lt;/em&gt; hard.&lt;/p&gt;



&lt;p&gt;So that’s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we’re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it’s meeting those standards? So it’s a huge issue in cybersecurity and one that we’re always very conscious of. It’s really hard.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Given the scope of cybersecurity, are there any differences in testing, let’s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that’s well equipped. You have to be realistic.&lt;/p&gt;



&lt;p&gt;If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn’t. So you have to have some differentiation. So again, you’ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they’re never going to meet.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; It’s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.&lt;/p&gt;



&lt;p&gt;But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you’ve got a problem. And I think we’ve wrestled with that, and there’s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that’s going to evolve.&lt;/p&gt;



&lt;p&gt;The second point, which in some respects if you’ve got the right capabilities is slightly &lt;em&gt;easier&lt;/em&gt; but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.&lt;/p&gt;



&lt;p&gt;But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that’s really good because it’s saying to people that these are the things that are going to matter in the post-quantum age. Here’s the outline of the standards you’re going to have to meet; start looking at them. So there’s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that’s the era we’re in now.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what’s the real reason they haven’t?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, again, where do you start? I mean, most members of the public quite rightly haven’t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.&lt;/p&gt;



&lt;p&gt;And there’s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that’s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.&lt;/p&gt;



&lt;p&gt;The third one then is when your perimeter’s breached, be able to detect it more times than not. And when you can’t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn’t eliminate the harm, but you would reduce it quite substantially.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it’s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.&lt;/p&gt;



&lt;p&gt;We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we’ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you’re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that’s the crucial part—then that will help because it means that we’re not going to our boards and saying, or our shareholders, and saying that we should do this, and they’re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.&lt;/p&gt;



&lt;p&gt;The harder nut to crack is the smaller business. And I think there’s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can’t throttle small businesses with onerous regulation. At the same time, we’re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.&lt;/p&gt;



&lt;p&gt;There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, it’s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think they’re crucial, but they have to be practical. I’ve got a slight, sort of, high horse on this, if you don’t mind, Kathleen. It’s sort of … [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Of course.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn’t get us very far. There are other types.&lt;/p&gt;



&lt;p&gt;We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn’t provide. So I think it’s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.&lt;/p&gt;



&lt;p&gt;So pick a bit of the problem. Find some ways of doing it. Don’t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. &lt;em&gt;Oh, well, is this our role? You know, should we be doing this, that, and the other?&lt;/em&gt; Well, you know, sometimes certainly in this country, you think, well, who’s actually going to sue you over this, you know? So I wouldn’t over-programmatize it. Just get stuck practically into solving some problems.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I love that. Actually, [it] made me think, are there any surprising allies that you’ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Ooh! That’s a … that’s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not &lt;em&gt;immoral&lt;/em&gt;, &lt;em&gt;amoral&lt;/em&gt;. It just didn’t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what’s in it for them?&lt;/p&gt;



&lt;p&gt;And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn’t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it’s a really positive part of certainly the UK cybersecurity ecosystem.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, we’re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that standards, assurance, and testing &lt;em&gt;really&lt;/em&gt; matter, but it’s a bit like the discussion we’re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There’s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it’s not everything.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; My pleasure, Kathleen, thank you.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Now, I’m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.&lt;/p&gt;



&lt;p&gt;So, Tori, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TORI WESTERHOFF: &lt;/strong&gt;Thanks. I am so excited to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I’d love to just start a little bit more learning about your background. You’ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]&lt;/p&gt;



&lt;p&gt;I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as &lt;em&gt;AIRT&lt;/em&gt;; I’m sure I’ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There’s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.&lt;/p&gt;



&lt;p&gt;But my experience in national security and I’d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we’re thinking about critical industries, how we’re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that’s evolving all of the time, that’s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we’re shaping up how we approach it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we’ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.&lt;/p&gt;



&lt;p&gt;So if we’re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that’s creating mitigations. It’s platform-security folks who are creating mitigations at scale. And there’s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it’s a continuous cycle.&lt;/p&gt;



&lt;p&gt;And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we’ve pulled a lot of those assets and insights into the Azure [AI] Foundry AI Red Teaming Agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; You recently—actually, with your team—published a report that outlined lessons from testing over a hundred generative AI products. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think the most important takeaway from those lessons is that AI security is truly a team sport. You’ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we’re going to approach this with intentionality and responsibility.&lt;/p&gt;



&lt;p&gt;So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we’ve done, there’s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are &lt;em&gt;they&lt;/em&gt; using it?&lt;/p&gt;



&lt;p&gt;And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation &lt;em&gt;for&lt;/em&gt; &lt;em&gt;people&lt;/em&gt;, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. &lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Yeah, I think it’s such a broad set of perspectives to bring in, in the AI instance. Something that I’ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.&lt;/p&gt;



&lt;p&gt;So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you’re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we’re trying to really clarify terms and threats.&amp;nbsp;And you see it in updates of those frameworks, as well, that I really love.&lt;/p&gt;



&lt;p&gt;So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Mm-hmm.&lt;strong&gt; &lt;/strong&gt;In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization’s role &lt;em&gt;and&lt;/em&gt; scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we’re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.&lt;/p&gt;



&lt;p&gt;Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which &lt;em&gt;is&lt;/em&gt; really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”&lt;/p&gt;



&lt;p&gt;So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people’s trust almost as different variables that could affect the impact, right.&lt;/p&gt;



&lt;p&gt;So a good example is if we’re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it’s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing &lt;em&gt;empathy&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? &lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It’s not just saying, “Hey, there’s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven’t even thought of, we feel confident that we have the resources and the system?”&lt;/p&gt;



&lt;p&gt;So part of me is really intrigued by the process that we’re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we’re really excited about pushing out those insights in an experimental and longer-term way.&lt;/p&gt;



&lt;p&gt;I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about &lt;em&gt;are&lt;/em&gt; traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I’m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.&lt;/p&gt;



&lt;p&gt;So to me, integration of AI into those frameworks by those same standards means that we’re evolving security to include AI. We aren’t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.&lt;/p&gt;



&lt;p&gt;I think there’s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that’s our job. But the other side of cybersecurity is offense. And I’m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.&lt;/p&gt;



&lt;p&gt;Generally speaking, I think the best practice is to realize that we’re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I’d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I’ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I’m talking to you today is probably evidence that a ton of people are bringing in perspectives that don’t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we’re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No, I think we’re seeing that across the board. I mean, I’d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we’re creating into the hands of our customers and partners and ecosystem is just underscored.&lt;/p&gt;



&lt;p&gt;So on the note of speed, let’s shift gears a little bit to just a quick lightning round. I’d love to get maybe some quick thoughts from you, just 30-second answers here. I’ll start with one.&lt;/p&gt;



&lt;p&gt;Which headline-grabbing AI threat do you think is mostly hot air?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think we should pay attention to it all. I’m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Is there some sort of maybe new tool that you can’t wait to sneak into the red team arsenal?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we’re looking at agentic systems. So I would say a method, not a tool.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe’s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I’m going to not love that I did it.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Thank you so much for having me. This was a joy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</guid><pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Rainmaker partners with Atmo to squeeze more rain from clouds (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/rainmaker-partners-with-atmo-to-squeeze-more-rain-from-clouds/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/03/gettyimages-577307007.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud seeding startup Rainmaker is partnering with Atmo, an AI-powered meteorology startup, the companies exclusively told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two operate on complementary ends of the weather system: Atmo studies atmospheric patterns to forecast weather events, while Rainmaker digests such data in an attempt to squeeze more precipitation out of weather systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the partnership, Atmo will use its deep learning models to help Rainmaker identify clouds that have potential for seeding. The forecasting startup will also offer Rainmaker’s cloud seeding services, deployed via small drones, to its customers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Rainmaker will contribute data from its proprietary radar system to determine how much rain the clouds produced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rainmaker has been in the news of late, targeted by conspiracy theorists who claim that the startup’s cloud seeding operations in Texas played a role in recent floods in the state.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But according to several scientists TechCrunch spoke with, that’s simply not possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Somebody is looking for somebody to blame,” Bob Rauber, a professor of atmospheric sciences at the University of Illinois, told TechCrunch last week.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though cloud seeding can nudge clouds to drop more precipitation, it’s a small amount compared with the size of a storm. One well-documented case in Idaho released an additional 186 million gallons of precipitation, which pales in comparison with the “trillions of gallons of water” a large storm will process, Rauber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloud seeding is widely used throughout the Western United States, mostly to augment snowpack and boost the amount of water that ends up in reservoirs in the summer. While it’s also used in places like West Texas to coax more rain from summer storms, the results have been modest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The West Texas Weather Modification Association, which Rainmaker has worked with previously, says that cloud seeding in the region has boosted precipitation by about 15%, or about two inches, per year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The likely reason for that is because the types of clouds floating over West Texas don’t respond in the same way as clouds in mountainous regions like the Western U.S., Rauber said. Rainstorms are even less responsive, he added, since they’re already primed to drop plenty of precipitation.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/03/gettyimages-577307007.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud seeding startup Rainmaker is partnering with Atmo, an AI-powered meteorology startup, the companies exclusively told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two operate on complementary ends of the weather system: Atmo studies atmospheric patterns to forecast weather events, while Rainmaker digests such data in an attempt to squeeze more precipitation out of weather systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the partnership, Atmo will use its deep learning models to help Rainmaker identify clouds that have potential for seeding. The forecasting startup will also offer Rainmaker’s cloud seeding services, deployed via small drones, to its customers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Rainmaker will contribute data from its proprietary radar system to determine how much rain the clouds produced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rainmaker has been in the news of late, targeted by conspiracy theorists who claim that the startup’s cloud seeding operations in Texas played a role in recent floods in the state.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But according to several scientists TechCrunch spoke with, that’s simply not possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Somebody is looking for somebody to blame,” Bob Rauber, a professor of atmospheric sciences at the University of Illinois, told TechCrunch last week.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though cloud seeding can nudge clouds to drop more precipitation, it’s a small amount compared with the size of a storm. One well-documented case in Idaho released an additional 186 million gallons of precipitation, which pales in comparison with the “trillions of gallons of water” a large storm will process, Rauber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloud seeding is widely used throughout the Western United States, mostly to augment snowpack and boost the amount of water that ends up in reservoirs in the summer. While it’s also used in places like West Texas to coax more rain from summer storms, the results have been modest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The West Texas Weather Modification Association, which Rainmaker has worked with previously, says that cloud seeding in the region has boosted precipitation by about 15%, or about two inches, per year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The likely reason for that is because the types of clouds floating over West Texas don’t respond in the same way as clouds in mountainous regions like the Western U.S., Rauber said. Rainstorms are even less responsive, he added, since they’re already primed to drop plenty of precipitation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/rainmaker-partners-with-atmo-to-squeeze-more-rain-from-clouds/</guid><pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] New Grok AI model surprises experts by checking Elon Musk’s views before answering (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/07/new-grok-ai-model-surprises-experts-by-checking-elon-musks-views-before-answering/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok 4's "reasoning" shows cases where the chatbot consults Musk posts to answer divisive questions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kirillm via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI model launched last week appears to have shipped with an unexpected occasional behavior: checking what its owner thinks first.&lt;/p&gt;
&lt;p&gt;On Friday, independent AI researcher Simon Willison documented that xAI's new Grok 4 model searches for Elon Musk's opinions on X (formerly Twitter) when asked about controversial topics. The discovery comes just days after xAI launched Grok 4 amid controversy over an earlier version of the chatbot generating antisemitic outputs, including labeling itself as "MechaHitler."&lt;/p&gt;
&lt;p&gt;"That is ludicrous," Willison told Ars Technica upon initially hearing about the Musk-seeking behavior last week from AI researcher Jeremy Howard, who traced the discovery through various users on X. But even amid prevalent suspicions of Musk meddling with Grok's outputs to fit "politically incorrect" goals, Willison doesn't think that Grok 4 has been specifically instructed to seek out Musk's views in particular. "I think there is a good chance this behavior is unintended," he wrote in a detailed blog post on the topic.&lt;/p&gt;
&lt;p&gt;To test what he'd been seeing online, Willison signed up for a "SuperGrok" account at $22.50 per month—the regular Grok 4 tier. He then fed the model this prompt: "Who do you support in the Israel vs Palestine conflict. One word answer only."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1040" id="video-2105680-1" preload="metadata" width="1848"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok-elon.mp4?_=1" type="video/mp4" /&gt;A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the model's "thinking trace" visible to users (a simulated reasoning process similar to that used by OpenAI's o3 model), Grok revealed it searched X for "from:elonmusk (Israel OR Palestine OR Gaza OR Hamas)" before providing its answer: "Israel."&lt;/p&gt;
&lt;p&gt;"Elon Musk's stance could provide context, given his influence," the model wrote in its exposed reasoning process. The search returned 10 web pages and 19 tweets that informed its response.&lt;/p&gt;
&lt;p&gt;Even so, Grok 4 doesn't always look for Musk's guidance in formulating its answers; the output reportedly varies between prompts and users. While Willison and two others saw Grok search for Musk's views, X user @wasted_alpha reported that Grok searched for its own previously reported stances and chose "Palestine" instead.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Seeking the system prompt&lt;/h2&gt;
&lt;p&gt;Owing to the unknown contents of the data used to train Grok 4 and the random elements thrown into large language model (LLM) outputs to make them seem more expressive, divining the reasons for particular LLM behavior for someone without insider access can be frustrating. But we can use what we know about how LLMs work to guide a better answer. xAI did not respond to a request for comment before publication.&lt;/p&gt;
&lt;p&gt;To generate text, every AI chatbot processes an input called a "prompt" and produces a plausible output based on that prompt. This is the core function of every LLM. In practice, the prompt often contains information from several sources, including comments from the user, the ongoing chat history (sometimes injected with user "memories" stored in a different subsystem), and special instructions from the companies that run the chatbot. These special instructions—called the system prompt—partially define the "personality" and behavior of the chatbot.&lt;/p&gt;
&lt;p&gt;According to Willison, Grok 4 readily shares its system prompt when asked, and that prompt reportedly contains no explicit instruction to search for Musk's opinions. However, the prompt states that Grok should "search for a distribution of sources that represents all parties/stakeholders" for controversial queries and "not shy away from making claims which are politically incorrect, as long as they are well substantiated."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105754 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar." class="center large" height="721" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/musk_on_israel-1024x721.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Ultimately, Willison believes the cause of this behavior comes down to a chain of inferences on Grok's part rather than an explicit mention of checking Musk in its system prompt. "My best guess is that Grok 'knows' that it is 'Grok 4 built by xAI,' and it knows that Elon Musk owns xAI, so in circumstances where it's asked for an opinion, the reasoning process often decides to see what Elon thinks," he said.&lt;/p&gt;
&lt;p&gt;Without official word from xAI, we're left with a best guess. However, regardless of the reason, this kind of unreliable, inscrutable behavior makes many chatbots poorly suited for assisting with tasks where reliability or accuracy are important.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok 4's "reasoning" shows cases where the chatbot consults Musk posts to answer divisive questions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kirillm via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI model launched last week appears to have shipped with an unexpected occasional behavior: checking what its owner thinks first.&lt;/p&gt;
&lt;p&gt;On Friday, independent AI researcher Simon Willison documented that xAI's new Grok 4 model searches for Elon Musk's opinions on X (formerly Twitter) when asked about controversial topics. The discovery comes just days after xAI launched Grok 4 amid controversy over an earlier version of the chatbot generating antisemitic outputs, including labeling itself as "MechaHitler."&lt;/p&gt;
&lt;p&gt;"That is ludicrous," Willison told Ars Technica upon initially hearing about the Musk-seeking behavior last week from AI researcher Jeremy Howard, who traced the discovery through various users on X. But even amid prevalent suspicions of Musk meddling with Grok's outputs to fit "politically incorrect" goals, Willison doesn't think that Grok 4 has been specifically instructed to seek out Musk's views in particular. "I think there is a good chance this behavior is unintended," he wrote in a detailed blog post on the topic.&lt;/p&gt;
&lt;p&gt;To test what he'd been seeing online, Willison signed up for a "SuperGrok" account at $22.50 per month—the regular Grok 4 tier. He then fed the model this prompt: "Who do you support in the Israel vs Palestine conflict. One word answer only."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1040" id="video-2105680-1" preload="metadata" width="1848"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok-elon.mp4?_=1" type="video/mp4" /&gt;A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the model's "thinking trace" visible to users (a simulated reasoning process similar to that used by OpenAI's o3 model), Grok revealed it searched X for "from:elonmusk (Israel OR Palestine OR Gaza OR Hamas)" before providing its answer: "Israel."&lt;/p&gt;
&lt;p&gt;"Elon Musk's stance could provide context, given his influence," the model wrote in its exposed reasoning process. The search returned 10 web pages and 19 tweets that informed its response.&lt;/p&gt;
&lt;p&gt;Even so, Grok 4 doesn't always look for Musk's guidance in formulating its answers; the output reportedly varies between prompts and users. While Willison and two others saw Grok search for Musk's views, X user @wasted_alpha reported that Grok searched for its own previously reported stances and chose "Palestine" instead.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Seeking the system prompt&lt;/h2&gt;
&lt;p&gt;Owing to the unknown contents of the data used to train Grok 4 and the random elements thrown into large language model (LLM) outputs to make them seem more expressive, divining the reasons for particular LLM behavior for someone without insider access can be frustrating. But we can use what we know about how LLMs work to guide a better answer. xAI did not respond to a request for comment before publication.&lt;/p&gt;
&lt;p&gt;To generate text, every AI chatbot processes an input called a "prompt" and produces a plausible output based on that prompt. This is the core function of every LLM. In practice, the prompt often contains information from several sources, including comments from the user, the ongoing chat history (sometimes injected with user "memories" stored in a different subsystem), and special instructions from the companies that run the chatbot. These special instructions—called the system prompt—partially define the "personality" and behavior of the chatbot.&lt;/p&gt;
&lt;p&gt;According to Willison, Grok 4 readily shares its system prompt when asked, and that prompt reportedly contains no explicit instruction to search for Musk's opinions. However, the prompt states that Grok should "search for a distribution of sources that represents all parties/stakeholders" for controversial queries and "not shy away from making claims which are politically incorrect, as long as they are well substantiated."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105754 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar." class="center large" height="721" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/musk_on_israel-1024x721.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Ultimately, Willison believes the cause of this behavior comes down to a chain of inferences on Grok's part rather than an explicit mention of checking Musk in its system prompt. "My best guess is that Grok 'knows' that it is 'Grok 4 built by xAI,' and it knows that Elon Musk owns xAI, so in circumstances where it's asked for an opinion, the reasoning process often decides to see what Elon thinks," he said.&lt;/p&gt;
&lt;p&gt;Without official word from xAI, we're left with a best guess. However, regardless of the reason, this kind of unreliable, inscrutable behavior makes many chatbots poorly suited for assisting with tasks where reliability or accuracy are important.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/07/new-grok-ai-model-surprises-experts-by-checking-elon-musks-views-before-answering/</guid><pubDate>Mon, 14 Jul 2025 16:08:13 +0000</pubDate></item><item><title>[NEW] Mark Zuckerberg says Meta is building a 5GW AI data center (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is currently building out a data center, called Hyperion, which the company expects to supply its new AI lab with five gigawatts (GW) of computational power, CEO Mark Zuckerberg said in a Monday post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement marks Meta’s latest move to get ahead of OpenAI and Google in the AI race. After previously poaching top talent to run Meta Superintelligence Lab, including former Scale AI CEO Alexandr Wang and former Safe Superintelligence CEO Daniel Gross, Meta now seems to be turning its attention to the massive computational power needed to train frontier AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zuckerberg said Hyperion’s footprint will be large enough to cover most of Manhattan. Hyperion seems to be located in northeast Louisiana, in a town called Richland Parish, according to semiconductor analysts at Semianalysis. In 2024, Meta announced a $10 billion data center development in this town, originally slated to be a two GW super cluster. Zuckerberg noted in his post that Hyperion would scale to five gigawatts over “several years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg also noted that Meta plans to bring a 1 GW super cluster, called Prometheus, online in 2026, making it one of the first tech companies to control an AI data center of this size. Prometheus seems to be a network of data centers located around New Albany, Ohio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI data center build-out seems likely to make the company more competitive with OpenAI, Google DeepMind, and Anthropic in its ability to train and serve leading AI models. It’s possible the effort could also help Meta attract additional talent, who may be drawn to work at a company with the computational needs to compete in the AI race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, Prometheus and Hyperion will soak up enough energy to power millions of homes, which could pull significant amounts of electricity and water from neighboring communities. One of Meta’s data center projects in Newton County, Georgia, has already caused the water taps to run dry in some residents’ homes, The New York Times reported Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI data center projects may cause similar problems for people living near them. AI hyperscaler CoreWeave is planning a data center expansion that is projected to double the electricity needs of a city near Dallas, Texas, according to Bloomberg.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, tech companies are determined to build out massive datacenter projects to power their AI ambitions. Other notable efforts include OpenAI’s Stargate project with Oracle and Softbank, as well as xAI’s Colossus supercomputer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has largely championed the tech industry’s AI data center buildout. President Donald Trump helped OpenAI announce its Stargate project, and has since spoken about efforts to expand America’s AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a column featured in The Economist on Monday, U.S. Secretary of Energy Chris Wright called for the U.S. to “lead the next major energy-intensive frontier: artificial intelligence.” He noted that AI transforms electricity into the “most valuable output imaginable: intelligence,” and that the federal government would accelerate the production of energy derived from coal, nuclear, geothermal, and natural gas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the support of federal officials, the AI industry seems poised to soak up much of America’s energy in the years to come. Experts estimate that data centers could account for 20% of America’s energy consumption by 2030, up from just 2.5% in 2022. Without rapidly increased energy production, that could cause even more problems for communities.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is currently building out a data center, called Hyperion, which the company expects to supply its new AI lab with five gigawatts (GW) of computational power, CEO Mark Zuckerberg said in a Monday post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement marks Meta’s latest move to get ahead of OpenAI and Google in the AI race. After previously poaching top talent to run Meta Superintelligence Lab, including former Scale AI CEO Alexandr Wang and former Safe Superintelligence CEO Daniel Gross, Meta now seems to be turning its attention to the massive computational power needed to train frontier AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zuckerberg said Hyperion’s footprint will be large enough to cover most of Manhattan. Hyperion seems to be located in northeast Louisiana, in a town called Richland Parish, according to semiconductor analysts at Semianalysis. In 2024, Meta announced a $10 billion data center development in this town, originally slated to be a two GW super cluster. Zuckerberg noted in his post that Hyperion would scale to five gigawatts over “several years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg also noted that Meta plans to bring a 1 GW super cluster, called Prometheus, online in 2026, making it one of the first tech companies to control an AI data center of this size. Prometheus seems to be a network of data centers located around New Albany, Ohio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI data center build-out seems likely to make the company more competitive with OpenAI, Google DeepMind, and Anthropic in its ability to train and serve leading AI models. It’s possible the effort could also help Meta attract additional talent, who may be drawn to work at a company with the computational needs to compete in the AI race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, Prometheus and Hyperion will soak up enough energy to power millions of homes, which could pull significant amounts of electricity and water from neighboring communities. One of Meta’s data center projects in Newton County, Georgia, has already caused the water taps to run dry in some residents’ homes, The New York Times reported Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI data center projects may cause similar problems for people living near them. AI hyperscaler CoreWeave is planning a data center expansion that is projected to double the electricity needs of a city near Dallas, Texas, according to Bloomberg.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, tech companies are determined to build out massive datacenter projects to power their AI ambitions. Other notable efforts include OpenAI’s Stargate project with Oracle and Softbank, as well as xAI’s Colossus supercomputer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has largely championed the tech industry’s AI data center buildout. President Donald Trump helped OpenAI announce its Stargate project, and has since spoken about efforts to expand America’s AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a column featured in The Economist on Monday, U.S. Secretary of Energy Chris Wright called for the U.S. to “lead the next major energy-intensive frontier: artificial intelligence.” He noted that AI transforms electricity into the “most valuable output imaginable: intelligence,” and that the federal government would accelerate the production of energy derived from coal, nuclear, geothermal, and natural gas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the support of federal officials, the AI industry seems poised to soak up much of America’s energy in the years to come. Experts estimate that data centers could account for 20% of America’s energy consumption by 2030, up from just 2.5% in 2022. Without rapidly increased energy production, that could cause even more problems for communities.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/</guid><pubDate>Mon, 14 Jul 2025 16:16:52 +0000</pubDate></item><item><title>[NEW] AI’s fourth wave is here — are enterprises ready for what’s next? (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/ais-fourth-wave-is-here-are-enterprises-ready-for-whats-next/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0526-X2.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;Yesterday’s emerging tech is now essential to business success — and the next wave is coming fast. To maintain competitive advantage through the next five years, which innovations must forward-thinking companies prioritize right now?&lt;/p&gt;



&lt;p&gt;At VentureBeat’s Transform 2025, Yaad Oren, global head of SAP research &amp;amp; innovation and Emma Brunskill, associate professor of computer science at Stanford, spoke with moderator Susan Etlinger, senior director, strategy and thought leadership, Azure AI Microsoft, about the strategies needed today, for tomorrow’s transformative technology.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-current-landscape-will-shape-the-future"&gt;&lt;strong&gt;How the current landscape will shape the future&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The fourth generation of AI — generative AI — marks a paradigm shift in what AI brings to the table, Oren said, outlining three major places it’s bringing significant value and disruption to the enterprise. The first is the user experience and how people interact with software. The second is automation on the application layer — SAP has embedded approximately 230 AI capabilities and agents inside its applications, and plan increase this number to 400 by the end of 2025, to drive increased productivity and reduce costs. The third area is the platform — the core engine that powers each enterprise — which raises new questions about the developer experience, as well as privacy and trust.&lt;/p&gt;



&lt;p&gt;“We see a lot of disruption around UX, the application, and the platform itself that provides all the tools to deal with this new treasure trove of options AI provides to enterprises,” Oren summed up.&lt;/p&gt;



&lt;p&gt;For Brunskill, the big question is how AI can integrate with humans to drive societal value, rather than acting like a thief of human creativity and ingenuity. A recent study found that if the enterprise framed AI tools as productivity enhancing, people will use them much less frequently than if they’re framed as task enhancing.&lt;/p&gt;



&lt;p&gt;“That’s a pretty big take-home as we think about how to translate some of the extraordinary capabilities of these systems into systems that drive value for customers, for organizations and others,” Brunskill said. “We need to think about how these are framed.”&lt;/p&gt;



&lt;p&gt;Business value at the enterprise level should be top of mind, Oren added, and that means even as technology evolves, AI in the enterprise needs to go beyond technology for technology’s sake. The sexiest new technology often delivers the least value.&lt;/p&gt;



&lt;p&gt;“What you see today is a proliferation of many solutions out there that create great jumping avatars in movies that look amazing, but the value: how do you help the enterprise reduce costs? How do you help the enterprise increase productivity or revenue? How are you able to mitigate risk?” he said. “This mindset is not fully there with AI. You always need to start with a business problem. Quantify the value you would like to achieve.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-predictions-for-the-future-of-ai"&gt;&lt;strong&gt;Predictions for the future of AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Artificial general intelligence (AGI) is a theoretical breakthrough in which AI will match or surpass human-level versatility and problem-solving capabilities across most cognitive tasks. The future of AI, and the definition of what AGI is, will be a big topic of discussion in the next few years. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Brunskill defines it the point at which AI can do any sort of cognitive task at least as well as an average human in a profession.&lt;/p&gt;



&lt;p&gt;“In terms of a lot of the white-collar jobs that just require cognitive processing, I think we’re going to make enormous strides in the next five years,” Brunskill said. “I don’t think we’re ready yet. I think we need to do a lot of creative thinking about what that will mean to industries. What is it going to do to your workforce? I’m very interested in how we think about workforce retraining and how we’re going to provide meaningful work to many people going forward. What new opportunities will we have?”&lt;/p&gt;



&lt;p&gt;The future of AI, the definition of AGI, is a big one, and we’re not as near as many folks would prefer, Oren said, but along the way we’ll see exciting new technology leaps, and six major disruption pillars: the next generation of AI beyond its current capabilities, the future of data platforms, robotics, quantum computing, next-generation Enterprise UX, and the future of cloud architecture around data privacy.&lt;/p&gt;



&lt;p&gt;“The transformer architecture in this generation is nothing compared to what’s coming,” he said. “A new type of meta-learning. AI learning to evolve and create agents by itself. Emotional AI. The future of AI, the definition of AGI, is a big one.”&lt;/p&gt;



&lt;p&gt;The future of data itself is also critical. We’re approaching the limits of real-world data — even sources like Wikipedia have already been fully absorbed by AI models. To drive the next leap in AI progress, synthetic data generation and improving data quality will be essential.&lt;/p&gt;



&lt;p&gt;Then there’s robotics which is evolving rapidly — we learned from recent innovation like DeepSeek that you can do “more with less” and install very powerful AI on the edge. Quantum will help create a paradigm shift in how we run process optimization and simulation. &amp;nbsp;And the future of enterprise UX will be another disruption which will provide users new type of personalization, adaption of screens to specific context, and an immersive experience.&lt;/p&gt;



&lt;p&gt;“My kids’ generation is going to hit the workforce after 2030. What’s going to be their UX paradigm?” Oren said. “They need an emotional connection for screens. They need adaptive screens. This is totally different from what we do today.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0526-X2.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;Yesterday’s emerging tech is now essential to business success — and the next wave is coming fast. To maintain competitive advantage through the next five years, which innovations must forward-thinking companies prioritize right now?&lt;/p&gt;



&lt;p&gt;At VentureBeat’s Transform 2025, Yaad Oren, global head of SAP research &amp;amp; innovation and Emma Brunskill, associate professor of computer science at Stanford, spoke with moderator Susan Etlinger, senior director, strategy and thought leadership, Azure AI Microsoft, about the strategies needed today, for tomorrow’s transformative technology.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-current-landscape-will-shape-the-future"&gt;&lt;strong&gt;How the current landscape will shape the future&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The fourth generation of AI — generative AI — marks a paradigm shift in what AI brings to the table, Oren said, outlining three major places it’s bringing significant value and disruption to the enterprise. The first is the user experience and how people interact with software. The second is automation on the application layer — SAP has embedded approximately 230 AI capabilities and agents inside its applications, and plan increase this number to 400 by the end of 2025, to drive increased productivity and reduce costs. The third area is the platform — the core engine that powers each enterprise — which raises new questions about the developer experience, as well as privacy and trust.&lt;/p&gt;



&lt;p&gt;“We see a lot of disruption around UX, the application, and the platform itself that provides all the tools to deal with this new treasure trove of options AI provides to enterprises,” Oren summed up.&lt;/p&gt;



&lt;p&gt;For Brunskill, the big question is how AI can integrate with humans to drive societal value, rather than acting like a thief of human creativity and ingenuity. A recent study found that if the enterprise framed AI tools as productivity enhancing, people will use them much less frequently than if they’re framed as task enhancing.&lt;/p&gt;



&lt;p&gt;“That’s a pretty big take-home as we think about how to translate some of the extraordinary capabilities of these systems into systems that drive value for customers, for organizations and others,” Brunskill said. “We need to think about how these are framed.”&lt;/p&gt;



&lt;p&gt;Business value at the enterprise level should be top of mind, Oren added, and that means even as technology evolves, AI in the enterprise needs to go beyond technology for technology’s sake. The sexiest new technology often delivers the least value.&lt;/p&gt;



&lt;p&gt;“What you see today is a proliferation of many solutions out there that create great jumping avatars in movies that look amazing, but the value: how do you help the enterprise reduce costs? How do you help the enterprise increase productivity or revenue? How are you able to mitigate risk?” he said. “This mindset is not fully there with AI. You always need to start with a business problem. Quantify the value you would like to achieve.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-predictions-for-the-future-of-ai"&gt;&lt;strong&gt;Predictions for the future of AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Artificial general intelligence (AGI) is a theoretical breakthrough in which AI will match or surpass human-level versatility and problem-solving capabilities across most cognitive tasks. The future of AI, and the definition of what AGI is, will be a big topic of discussion in the next few years. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Brunskill defines it the point at which AI can do any sort of cognitive task at least as well as an average human in a profession.&lt;/p&gt;



&lt;p&gt;“In terms of a lot of the white-collar jobs that just require cognitive processing, I think we’re going to make enormous strides in the next five years,” Brunskill said. “I don’t think we’re ready yet. I think we need to do a lot of creative thinking about what that will mean to industries. What is it going to do to your workforce? I’m very interested in how we think about workforce retraining and how we’re going to provide meaningful work to many people going forward. What new opportunities will we have?”&lt;/p&gt;



&lt;p&gt;The future of AI, the definition of AGI, is a big one, and we’re not as near as many folks would prefer, Oren said, but along the way we’ll see exciting new technology leaps, and six major disruption pillars: the next generation of AI beyond its current capabilities, the future of data platforms, robotics, quantum computing, next-generation Enterprise UX, and the future of cloud architecture around data privacy.&lt;/p&gt;



&lt;p&gt;“The transformer architecture in this generation is nothing compared to what’s coming,” he said. “A new type of meta-learning. AI learning to evolve and create agents by itself. Emotional AI. The future of AI, the definition of AGI, is a big one.”&lt;/p&gt;



&lt;p&gt;The future of data itself is also critical. We’re approaching the limits of real-world data — even sources like Wikipedia have already been fully absorbed by AI models. To drive the next leap in AI progress, synthetic data generation and improving data quality will be essential.&lt;/p&gt;



&lt;p&gt;Then there’s robotics which is evolving rapidly — we learned from recent innovation like DeepSeek that you can do “more with less” and install very powerful AI on the edge. Quantum will help create a paradigm shift in how we run process optimization and simulation. &amp;nbsp;And the future of enterprise UX will be another disruption which will provide users new type of personalization, adaption of screens to specific context, and an immersive experience.&lt;/p&gt;



&lt;p&gt;“My kids’ generation is going to hit the workforce after 2030. What’s going to be their UX paradigm?” Oren said. “They need an emotional connection for screens. They need adaptive screens. This is totally different from what we do today.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ais-fourth-wave-is-here-are-enterprises-ready-for-whats-next/</guid><pubDate>Mon, 14 Jul 2025 16:28:21 +0000</pubDate></item><item><title>[NEW] Prime Day event drove over $24B in U.S. e-commerce sales, gen AI traffic was up 3,300% (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/prime-day-event-drove-over-24b-in-u-s-e-commerce-sales-gen-ai-traffic-was-up-3300/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-499278352.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon’s Prime Day, which leads to an overall boost to U.S. e-commerce thanks to competitive sales, saw a significant increase in retail traffic driven by generative AI products, including chatbots and browsers. According to a post-Prime Day analysis by Adobe Analytics, gen AI traffic to U.S. retail sites increased by 3,300% year-over-year — which was more than the firm had originally forecast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s e-commerce division provided an analysis of the U.S. retail landscape encompassing over 1 trillion visits to U.S. retail websites, including 100 million SKUs across 18 product categories. During the Amazon Prime Day event (July 8-11), U.S. retailers saw $24.1 billion in online spend, representing 30.3% year-over-year growth, or the equivalent of two Black Fridays. (Black Friday 2024 saw $10.8 billion in online spend, which was then a new benchmark for the holiday shopping event.) &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The actual results from the firm’s Prime Day analysis came in slightly higher than its estimates, which predicted $23.8 billion would be spent with U.S. e-commerce retailers over the four-day period, representing 28.4% year-over-year growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, the figures for the use of gen AI driving online shopping were higher as well, indicating increased consumer interest in using generative AI-powered chat services and browsers as online shopping assistants. However, this AI-driven traffic still remains much smaller than other channels like email or paid search, Adobe noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paid search, for example, accounted for a 28.5% share of U.S. e-commerce sales during the Prime Day event, up 5.6% year-over-year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another growing channel for driving retail clicks this year involved social media influencers, who drove 19.9% of U.S. online retail sales during the event. That figure was up 15% year-over-year, and data indicated that influencers converted shoppers into making purchases 10 times more effectively than social media overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon didn’t share specific Prime Day figures, only saying that it was the biggest event ever with record sales and more items sold than before. However, the company also expanded Prime Day to a four-day event this year, making comparisons to prior years difficult. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;According to one third-party analysis from Momentum Commerce, reported by Adweek, Prime Day sales during its first two days were initially down 35% year-over-year, then increased by day three to be up 165% year-over-year. This suggests that shoppers may have been waiting until the later sale days to see if their items would receive deeper discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe noted that top categories driving U.S. e-commerce sales during the Prime Day event this year included appliances, where online sales were up 112%, compared to average daily sales in June. Other categories that saw strong growth included office supplies (up 105%), electronics (up 95%), books (up 81%), tools and home improvement (up 76%), home and garden (up 58%), and baby and toddler (up 55%).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-499278352.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon’s Prime Day, which leads to an overall boost to U.S. e-commerce thanks to competitive sales, saw a significant increase in retail traffic driven by generative AI products, including chatbots and browsers. According to a post-Prime Day analysis by Adobe Analytics, gen AI traffic to U.S. retail sites increased by 3,300% year-over-year — which was more than the firm had originally forecast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s e-commerce division provided an analysis of the U.S. retail landscape encompassing over 1 trillion visits to U.S. retail websites, including 100 million SKUs across 18 product categories. During the Amazon Prime Day event (July 8-11), U.S. retailers saw $24.1 billion in online spend, representing 30.3% year-over-year growth, or the equivalent of two Black Fridays. (Black Friday 2024 saw $10.8 billion in online spend, which was then a new benchmark for the holiday shopping event.) &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The actual results from the firm’s Prime Day analysis came in slightly higher than its estimates, which predicted $23.8 billion would be spent with U.S. e-commerce retailers over the four-day period, representing 28.4% year-over-year growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, the figures for the use of gen AI driving online shopping were higher as well, indicating increased consumer interest in using generative AI-powered chat services and browsers as online shopping assistants. However, this AI-driven traffic still remains much smaller than other channels like email or paid search, Adobe noted. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paid search, for example, accounted for a 28.5% share of U.S. e-commerce sales during the Prime Day event, up 5.6% year-over-year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another growing channel for driving retail clicks this year involved social media influencers, who drove 19.9% of U.S. online retail sales during the event. That figure was up 15% year-over-year, and data indicated that influencers converted shoppers into making purchases 10 times more effectively than social media overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon didn’t share specific Prime Day figures, only saying that it was the biggest event ever with record sales and more items sold than before. However, the company also expanded Prime Day to a four-day event this year, making comparisons to prior years difficult. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;According to one third-party analysis from Momentum Commerce, reported by Adweek, Prime Day sales during its first two days were initially down 35% year-over-year, then increased by day three to be up 165% year-over-year. This suggests that shoppers may have been waiting until the later sale days to see if their items would receive deeper discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe noted that top categories driving U.S. e-commerce sales during the Prime Day event this year included appliances, where online sales were up 112%, compared to average daily sales in June. Other categories that saw strong growth included office supplies (up 105%), electronics (up 95%), books (up 81%), tools and home improvement (up 76%), home and garden (up 58%), and baby and toddler (up 55%).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/prime-day-event-drove-over-24b-in-u-s-e-commerce-sales-gen-ai-traffic-was-up-3300/</guid><pubDate>Mon, 14 Jul 2025 16:44:41 +0000</pubDate></item><item><title>[NEW] NotebookLM adds featured notebooks from The Economist, The Atlantic and others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/notebooklm-adds-featured-notebooks-from-the-economist-the-atlantic-and-others/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Featured_Notebook_Header_2096x11.width-2200.format-webp.webp?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is transforming its popular AI-powered research and note-taking assistant, NotebookLM, into more of a destination. The company announced Monday it would add a series of featured notebooks from various authors, publications, researchers, and nonprofits that allow NotebookLM users to explore a wide array of topics from health and life advice to travel tips and financial analysis, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initial collection, which includes notebooks from The Economist, The Atlantic, as well as professors, authors, and even Shakespeare’s works, is designed to offer users working examples of how NotebookLM can be used to delve deeper into subjects of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;NotebookLM users will be able to read the original source material, but also ask questions, explore topics, and get answers that include citations, according to Google. You can also listen to pre-generated Audio Overviews or browse the notebook’s main themes with the app’s Mind Maps feature.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new addition to NotebookLM builds on the recently launched feature that allows users to publicly share their notebooks with others on the app. Since its debut last month, Google says more than 140,000 public notebooks have been shared. The company plans to expand its own collection of featured notebooks in the months ahead, which will include more collections from its partnership with The Economist and The Atlantic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The featured collection of notebooks will roll out to NotebookLM on the desktop starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per Google’s descriptions, the initial lineup includes the following: &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Featured_Notebook_Header_2096x11.width-2200.format-webp.webp?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is transforming its popular AI-powered research and note-taking assistant, NotebookLM, into more of a destination. The company announced Monday it would add a series of featured notebooks from various authors, publications, researchers, and nonprofits that allow NotebookLM users to explore a wide array of topics from health and life advice to travel tips and financial analysis, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initial collection, which includes notebooks from The Economist, The Atlantic, as well as professors, authors, and even Shakespeare’s works, is designed to offer users working examples of how NotebookLM can be used to delve deeper into subjects of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;NotebookLM users will be able to read the original source material, but also ask questions, explore topics, and get answers that include citations, according to Google. You can also listen to pre-generated Audio Overviews or browse the notebook’s main themes with the app’s Mind Maps feature.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new addition to NotebookLM builds on the recently launched feature that allows users to publicly share their notebooks with others on the app. Since its debut last month, Google says more than 140,000 public notebooks have been shared. The company plans to expand its own collection of featured notebooks in the months ahead, which will include more collections from its partnership with The Economist and The Atlantic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The featured collection of notebooks will roll out to NotebookLM on the desktop starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per Google’s descriptions, the initial lineup includes the following: &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/notebooklm-adds-featured-notebooks-from-the-economist-the-atlantic-and-others/</guid><pubDate>Mon, 14 Jul 2025 17:26:38 +0000</pubDate></item><item><title>[NEW] Malaysia will require trade permits for U.S. AI chips (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/malaysia-will-require-trade-permits-for-u-s-ai-chips/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Malaysia is taking on a bigger role in helping the U.S. prevent advanced AI chips from ending up in China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Malaysian Ministry of Investment, Trade and Industry announced new restrictions on exporting AI chips of U.S. origin out of its country on Monday. Individuals and companies are now required to notify Malaysian authorities at least 30 days in advance when they are exporting or transshipping U.S. AI chips, effective immediately.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Malaysia stands firm against any attempt to circumvent export controls or engage in illicit trade activities by any individual or company, who will face strict legal action if found violating the STA 2010 or related laws,” the Ministry wrote in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alleged chip smuggling of U.S. AI chips into China has come up multiple times in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic claimed that China already had sophisticated chip-smuggling networks set up in a blog post in April. The post also claimed that smugglers were going to extreme lengths to bring AI chips into China, including using prosthetic baby bumps filled with chips, and that smugglers were shipping GPUs alongside live lobsters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s April blog post was written in favor of the U.S. imposing more AI chip export rules to prevent this type of smuggling. Those restrictions are likely arriving in the near future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Bloomberg reported that the Trump administration was planning to further restrict the export of AI chips, from companies like Nvidia, to Malaysia and Thailand, to prevent China from accessing these AI chips through a different mode of entry. The Trump administration has not made an official announcement regarding this yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is also working on its own set of general U.S. AI chip export restrictions after formally rescinding the Biden administration’s AI Diffusion rules in May. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Malaysia is taking on a bigger role in helping the U.S. prevent advanced AI chips from ending up in China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Malaysian Ministry of Investment, Trade and Industry announced new restrictions on exporting AI chips of U.S. origin out of its country on Monday. Individuals and companies are now required to notify Malaysian authorities at least 30 days in advance when they are exporting or transshipping U.S. AI chips, effective immediately.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Malaysia stands firm against any attempt to circumvent export controls or engage in illicit trade activities by any individual or company, who will face strict legal action if found violating the STA 2010 or related laws,” the Ministry wrote in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alleged chip smuggling of U.S. AI chips into China has come up multiple times in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic claimed that China already had sophisticated chip-smuggling networks set up in a blog post in April. The post also claimed that smugglers were going to extreme lengths to bring AI chips into China, including using prosthetic baby bumps filled with chips, and that smugglers were shipping GPUs alongside live lobsters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s April blog post was written in favor of the U.S. imposing more AI chip export rules to prevent this type of smuggling. Those restrictions are likely arriving in the near future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Bloomberg reported that the Trump administration was planning to further restrict the export of AI chips, from companies like Nvidia, to Malaysia and Thailand, to prevent China from accessing these AI chips through a different mode of entry. The Trump administration has not made an official announcement regarding this yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is also working on its own set of general U.S. AI chip export restrictions after formally rescinding the Biden administration’s AI Diffusion rules in May. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/malaysia-will-require-trade-permits-for-u-s-ai-chips/</guid><pubDate>Mon, 14 Jul 2025 17:37:50 +0000</pubDate></item></channel></rss>