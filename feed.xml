<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 26 Jan 2026 18:40:27 +0000</lastBuildDate><item><title>[NEW] Synthesia hits $4B valuation, lets employees cash out (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/synthesia-hits-4b-valuation-lets-employees-cash-in/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Synthesia-cofounders-Steffen-Tjerrild-and-Victor-Riparbelli.jpg?resize=1200,833" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;British startup Synthesia, whose AI platform helps companies create interactive training videos, has raised a $200 million Series E round of funding that brings its valuation to $4 billion ‚Äî up from $2.1 billion just a year ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike some other AI startups that are still a long way from turning a profit, Synthesia has found a lucrative business in transforming corporate training thanks to AI-generated avatars. With enterprise clients including Bosch, Merck, and SAP, the London-based company crossed $100 million in annual recurring revenue (ARR) in April 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This milestone explains why Synthesia‚Äôs venture backers are literally doubling down. The Series E that nearly doubled its valuation was led by existing investor GV (Google Ventures), with participation from several other previous backers ‚Äî including Series B lead Kleiner Perkins, Series C lead Accel, Series D lead New Enterprise Associates (NEA), Nvidia‚Äôs venture capital arm NVentures, Air Street Capital, and PSP Growth.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from ongoing support, this round will bring both new and departing investors. On one hand, Matt Miller‚Äôs VC firm Evantic and the secretive VC firm Hedosophia are joining the cap table as new entrants. On the other hand, Synthesia will facilitate an employee secondary sale in partnership with Nasdaq, TechCrunch has learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Synthesia isn‚Äôt going public just yet ‚Äî Nasdaq isn‚Äôt acting as a public exchange in this operation, but as a private markets facilitator that will help early team members turn their shares into cash. These employee stock sales often happen outside of this framework, but usually at prices either below or above the company‚Äôs official valuation, and are sometimes frowned upon by other shareholders. With this process, all sales will be tied to the same $4 billion valuation as Synthesia‚Äôs Series E, while the company keeps an element of control.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis secondary is first and foremost about our employees,‚Äù Synthesia CFO Daniel Kim told TechCrunch. ‚ÄúIt gives employees a meaningful opportunity to access liquidity and share in the value they‚Äôve helped create, while we continue to operate as a private company focused on long-term growth.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Synthesia, this long-term growth involves going beyond expressive videos and embracing the AI agents trend. According to a press release, the company is developing AI agents that will let its clients‚Äô employees ‚Äúinteract with company knowledge in a more intuitive, human-like way by asking questions, exploring scenarios through role-play, and receiving tailored explanations.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company said early pilots have received positive feedback from customers, who reported higher engagement and faster knowledge transfer compared to traditional formats. This positive response explains why Synthesia now plans to make agents a ‚Äúcore strategic focus‚Äù to invest in, alongside further product improvements to its existing platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While it didn‚Äôt disclose revenue forecasts, the company hopes its platform will offer a welcome answer to the struggles of enterprises in keeping their workforce adequately trained despite rapid changes. ‚ÄúWe see a rare convergence of two major shifts: a technology shift with AI agents becoming more capable, and a market shift where upskilling and internal knowledge sharing have become board-level priorities,‚Äù Synthesia‚Äôs co-founder and CEO Victor Riparbelli said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seeing boards care more about employees as a result of AI wasn‚Äôt on anyone‚Äôs bingo card, except perhaps Riparbelli. Together with his co-founder, Synthesia COO Steffen Tjerrild, Riparbelli took the initiative of conducting a secondary sale so that employees could share in the success of the unicorn company. Founded in 2017, Synthesia now has more than 500 team members, a 20,000-square-foot HQ in London, and additional offices in Amsterdam, Copenhagen, Munich, New York City, and Zurich.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While unusual for a British startup, this coordinated secondary sale isn‚Äôt a first and likely not a last, Synthesia‚Äôs head of corporate affairs and policy, Alexandru Voica told TechCrunch. ‚ÄúMy guess is that as [U.K.-based] private companies stay private longer, this type of structured, cross-border employee liquidity may become increasingly common, so I wouldn‚Äôt be surprised to see others do it, either with Nasdaq or others,‚Äù he predicted.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Synthesia-cofounders-Steffen-Tjerrild-and-Victor-Riparbelli.jpg?resize=1200,833" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;British startup Synthesia, whose AI platform helps companies create interactive training videos, has raised a $200 million Series E round of funding that brings its valuation to $4 billion ‚Äî up from $2.1 billion just a year ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike some other AI startups that are still a long way from turning a profit, Synthesia has found a lucrative business in transforming corporate training thanks to AI-generated avatars. With enterprise clients including Bosch, Merck, and SAP, the London-based company crossed $100 million in annual recurring revenue (ARR) in April 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This milestone explains why Synthesia‚Äôs venture backers are literally doubling down. The Series E that nearly doubled its valuation was led by existing investor GV (Google Ventures), with participation from several other previous backers ‚Äî including Series B lead Kleiner Perkins, Series C lead Accel, Series D lead New Enterprise Associates (NEA), Nvidia‚Äôs venture capital arm NVentures, Air Street Capital, and PSP Growth.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from ongoing support, this round will bring both new and departing investors. On one hand, Matt Miller‚Äôs VC firm Evantic and the secretive VC firm Hedosophia are joining the cap table as new entrants. On the other hand, Synthesia will facilitate an employee secondary sale in partnership with Nasdaq, TechCrunch has learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Synthesia isn‚Äôt going public just yet ‚Äî Nasdaq isn‚Äôt acting as a public exchange in this operation, but as a private markets facilitator that will help early team members turn their shares into cash. These employee stock sales often happen outside of this framework, but usually at prices either below or above the company‚Äôs official valuation, and are sometimes frowned upon by other shareholders. With this process, all sales will be tied to the same $4 billion valuation as Synthesia‚Äôs Series E, while the company keeps an element of control.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis secondary is first and foremost about our employees,‚Äù Synthesia CFO Daniel Kim told TechCrunch. ‚ÄúIt gives employees a meaningful opportunity to access liquidity and share in the value they‚Äôve helped create, while we continue to operate as a private company focused on long-term growth.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Synthesia, this long-term growth involves going beyond expressive videos and embracing the AI agents trend. According to a press release, the company is developing AI agents that will let its clients‚Äô employees ‚Äúinteract with company knowledge in a more intuitive, human-like way by asking questions, exploring scenarios through role-play, and receiving tailored explanations.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company said early pilots have received positive feedback from customers, who reported higher engagement and faster knowledge transfer compared to traditional formats. This positive response explains why Synthesia now plans to make agents a ‚Äúcore strategic focus‚Äù to invest in, alongside further product improvements to its existing platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While it didn‚Äôt disclose revenue forecasts, the company hopes its platform will offer a welcome answer to the struggles of enterprises in keeping their workforce adequately trained despite rapid changes. ‚ÄúWe see a rare convergence of two major shifts: a technology shift with AI agents becoming more capable, and a market shift where upskilling and internal knowledge sharing have become board-level priorities,‚Äù Synthesia‚Äôs co-founder and CEO Victor Riparbelli said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seeing boards care more about employees as a result of AI wasn‚Äôt on anyone‚Äôs bingo card, except perhaps Riparbelli. Together with his co-founder, Synthesia COO Steffen Tjerrild, Riparbelli took the initiative of conducting a secondary sale so that employees could share in the success of the unicorn company. Founded in 2017, Synthesia now has more than 500 team members, a 20,000-square-foot HQ in London, and additional offices in Amsterdam, Copenhagen, Munich, New York City, and Zurich.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While unusual for a British startup, this coordinated secondary sale isn‚Äôt a first and likely not a last, Synthesia‚Äôs head of corporate affairs and policy, Alexandru Voica told TechCrunch. ‚ÄúMy guess is that as [U.K.-based] private companies stay private longer, this type of structured, cross-border employee liquidity may become increasingly common, so I wouldn‚Äôt be surprised to see others do it, either with Nasdaq or others,‚Äù he predicted.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/synthesia-hits-4b-valuation-lets-employees-cash-in/</guid><pubDate>Mon, 26 Jan 2026 09:00:00 +0000</pubDate></item><item><title>Modernising apps triples the odds of AI returns, Cloudflare says (AI News)</title><link>https://www.artificialintelligence-news.com/news/modernising-apps-triples-the-odds-of-ai-returns-cloudflare-says/</link><description>&lt;p&gt;For many organisations, the AI debate has moved on from whether to adopt the technology to a harder question: why do the results feel uneven? New tools are in place, pilots are running, and budgets are rising, yet clear AI returns remain elusive. According to Cloudflare‚Äôs 2026 App Innovation Report, the difference often has less to do with AI itself and more to do with the state of the applications underneath it.&lt;/p&gt;&lt;p&gt;The report, based on a survey of more than 2,300 senior leaders in APAC, EMEA, and the Americas, points to application modernisation as the clearest divider between organisations seeing real AI value and those still struggling. Companies that are ahead of schedule in modernising their applications are nearly three times more likely to report a clear payoff from their AI investments. In APAC, the link is even more explicit: 92% of leaders say updating their software was the single most important factor in improving their AI abilities.&lt;/p&gt;&lt;h3&gt;Modernisation, not experimentation, drives AI returns&lt;/h3&gt;&lt;p&gt;The finding re-frames AI success as a foundation problem not a tooling problem. AI systems depend on fast access to data, flexible architectures, and reliable integration points. Legacy applications, fragmented infrastructure, and brittle workflows make it harder for AI projects to move beyond isolated use cases. Modernised applications, by contrast, give organisations room to experiment, scale, and adapt without constant rework.&lt;/p&gt;&lt;p&gt;The report describes this relationship as a reinforcing cycle. Organisations modernise applications to support AI, then use AI results to justify deeper modernisation. Leaders in this group report far higher confidence that their infrastructure can support AI development, and that confidence translates into action. In APAC, 90% of leading organisations have already integrated AI into existing applications, compared with much lower levels among those behind schedule. Around 80% plan to increase that integration further over the next year.&lt;/p&gt;&lt;p&gt;The shift marks a change in mindset, as earlier waves of AI adoption focused on testing and pilots. Now, the emphasis is on integration. AI is not treated as a standalone project but as part of everyday systems, from internal workflows to customer-facing applications. The report shows that leading organisations are using AI to improve internal processes, build content-driven applications, and support revenue-generating work, while lagging organisations remain more cautious and fragmented in their approach.&lt;/p&gt;&lt;h3&gt;The cost of delay shows up in security and confidence&lt;/h3&gt;&lt;p&gt;The cost of falling behind is becoming clearer as well. Organisations that lag on modernisation tend to modernise reactively, often after a security incident or operational failure. In APAC, these organisations report lower confidence in both their infrastructure and their teams‚Äô ability to support AI. That lack of confidence slows decision-making and limits how far AI projects can go. Instead of expanding use cases, teams spend time managing risk, fixing gaps, and dealing with technical debt.&lt;/p&gt;&lt;p&gt;Security plays a central role in this dynamic. The report shows that organisations with strong alignment between security and application teams are far more likely to scale AI successfully. Where that alignment is weak, security issues consume time and attention, pushing modernisation and AI work further down the priority list. Many lagging organisations report difficulty tracking risks in applications and APIs, which makes it harder to move quickly without increasing exposure.&lt;/p&gt;&lt;p&gt;For leaders, security is treated as part of application design not an add-on. That approach reduces the amount of reactive work needed after incidents and frees teams to focus on building and improving systems. Over time, this also lowers the operational drag that can stall AI efforts. The report suggests that reliability has become a practical limit on speed: organisations that cannot maintain stable, secure systems struggle to move AI projects into production.&lt;/p&gt;&lt;h3&gt;Fewer tools, clearer foundations, faster AI integration&lt;/h3&gt;&lt;p&gt;Another pressure point highlighted in the APAC data is tool sprawl. Nearly all organisations report challenges in managing large and complex technology stacks, but leaders are responding more aggressively. About 86% of APAC leaders say they are actively cutting redundant tools and addressing shadow IT. The goal is not just cost control, but clarity. Fewer platforms and integrations make it easier to modernise applications, apply consistent security controls, and integrate AI without friction.&lt;/p&gt;&lt;p&gt;Developer time is also a factor. In organisations with a modernised foundation, developers spend more time maintaining and improving systems that already work. In lagging organisations, developers are more likely to rebuild from scratch or spend time on configuration and remediation. That difference affects how quickly new AI abilities can be introduced and refined. When teams are tied up fixing problems, AI becomes harder to prioritise.&lt;/p&gt;&lt;p&gt;Taken together, the findings suggest that AI success is less about racing to deploy new models and more about removing the obstacles that slow everything else down. Application modernisation creates the conditions for AI to deliver value, while fragmented systems and reactive practices limit what AI can achieve. Without that foundation, organisations find it harder to turn AI investment into measurable AI returns.&lt;/p&gt;&lt;p&gt;For APAC organisations, the message is that AI investment without modernisation tends to produce shallow results. Modernisation without integration plans risks becoming an ongoing rebuild. The organisations seeing the strongest returns are those that treat application updates, security alignment, and AI integration as connected work, not separate initiatives.&lt;/p&gt;&lt;p&gt;The report does not suggest a single path forward, but it does draw a clear line between organisations that act early and those that wait. The advantage not comes from having AI, but from having applications ready to use it.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Julio Lopez)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Controlling AI agent sprawl: The CIO‚Äôs guide to governance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For many organisations, the AI debate has moved on from whether to adopt the technology to a harder question: why do the results feel uneven? New tools are in place, pilots are running, and budgets are rising, yet clear AI returns remain elusive. According to Cloudflare‚Äôs 2026 App Innovation Report, the difference often has less to do with AI itself and more to do with the state of the applications underneath it.&lt;/p&gt;&lt;p&gt;The report, based on a survey of more than 2,300 senior leaders in APAC, EMEA, and the Americas, points to application modernisation as the clearest divider between organisations seeing real AI value and those still struggling. Companies that are ahead of schedule in modernising their applications are nearly three times more likely to report a clear payoff from their AI investments. In APAC, the link is even more explicit: 92% of leaders say updating their software was the single most important factor in improving their AI abilities.&lt;/p&gt;&lt;h3&gt;Modernisation, not experimentation, drives AI returns&lt;/h3&gt;&lt;p&gt;The finding re-frames AI success as a foundation problem not a tooling problem. AI systems depend on fast access to data, flexible architectures, and reliable integration points. Legacy applications, fragmented infrastructure, and brittle workflows make it harder for AI projects to move beyond isolated use cases. Modernised applications, by contrast, give organisations room to experiment, scale, and adapt without constant rework.&lt;/p&gt;&lt;p&gt;The report describes this relationship as a reinforcing cycle. Organisations modernise applications to support AI, then use AI results to justify deeper modernisation. Leaders in this group report far higher confidence that their infrastructure can support AI development, and that confidence translates into action. In APAC, 90% of leading organisations have already integrated AI into existing applications, compared with much lower levels among those behind schedule. Around 80% plan to increase that integration further over the next year.&lt;/p&gt;&lt;p&gt;The shift marks a change in mindset, as earlier waves of AI adoption focused on testing and pilots. Now, the emphasis is on integration. AI is not treated as a standalone project but as part of everyday systems, from internal workflows to customer-facing applications. The report shows that leading organisations are using AI to improve internal processes, build content-driven applications, and support revenue-generating work, while lagging organisations remain more cautious and fragmented in their approach.&lt;/p&gt;&lt;h3&gt;The cost of delay shows up in security and confidence&lt;/h3&gt;&lt;p&gt;The cost of falling behind is becoming clearer as well. Organisations that lag on modernisation tend to modernise reactively, often after a security incident or operational failure. In APAC, these organisations report lower confidence in both their infrastructure and their teams‚Äô ability to support AI. That lack of confidence slows decision-making and limits how far AI projects can go. Instead of expanding use cases, teams spend time managing risk, fixing gaps, and dealing with technical debt.&lt;/p&gt;&lt;p&gt;Security plays a central role in this dynamic. The report shows that organisations with strong alignment between security and application teams are far more likely to scale AI successfully. Where that alignment is weak, security issues consume time and attention, pushing modernisation and AI work further down the priority list. Many lagging organisations report difficulty tracking risks in applications and APIs, which makes it harder to move quickly without increasing exposure.&lt;/p&gt;&lt;p&gt;For leaders, security is treated as part of application design not an add-on. That approach reduces the amount of reactive work needed after incidents and frees teams to focus on building and improving systems. Over time, this also lowers the operational drag that can stall AI efforts. The report suggests that reliability has become a practical limit on speed: organisations that cannot maintain stable, secure systems struggle to move AI projects into production.&lt;/p&gt;&lt;h3&gt;Fewer tools, clearer foundations, faster AI integration&lt;/h3&gt;&lt;p&gt;Another pressure point highlighted in the APAC data is tool sprawl. Nearly all organisations report challenges in managing large and complex technology stacks, but leaders are responding more aggressively. About 86% of APAC leaders say they are actively cutting redundant tools and addressing shadow IT. The goal is not just cost control, but clarity. Fewer platforms and integrations make it easier to modernise applications, apply consistent security controls, and integrate AI without friction.&lt;/p&gt;&lt;p&gt;Developer time is also a factor. In organisations with a modernised foundation, developers spend more time maintaining and improving systems that already work. In lagging organisations, developers are more likely to rebuild from scratch or spend time on configuration and remediation. That difference affects how quickly new AI abilities can be introduced and refined. When teams are tied up fixing problems, AI becomes harder to prioritise.&lt;/p&gt;&lt;p&gt;Taken together, the findings suggest that AI success is less about racing to deploy new models and more about removing the obstacles that slow everything else down. Application modernisation creates the conditions for AI to deliver value, while fragmented systems and reactive practices limit what AI can achieve. Without that foundation, organisations find it harder to turn AI investment into measurable AI returns.&lt;/p&gt;&lt;p&gt;For APAC organisations, the message is that AI investment without modernisation tends to produce shallow results. Modernisation without integration plans risks becoming an ongoing rebuild. The organisations seeing the strongest returns are those that treat application updates, security alignment, and AI integration as connected work, not separate initiatives.&lt;/p&gt;&lt;p&gt;The report does not suggest a single path forward, but it does draw a clear line between organisations that act early and those that wait. The advantage not comes from having AI, but from having applications ready to use it.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Julio Lopez)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Controlling AI agent sprawl: The CIO‚Äôs guide to governance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/modernising-apps-triples-the-odds-of-ai-returns-cloudflare-says/</guid><pubDate>Mon, 26 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] The Download: why LLMs are like aliens, and the future of head transplants (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/26/1131717/the-download-why-llms-are-like-aliens-and-the-future-of-head-transplants/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the new biologists treating LLMs like aliens&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;How large is a large language model? We now coexist with machines so vast and so complicated that nobody quite understands what they are, how they work, or what they can really do‚Äînot even the people who build them.&lt;/p&gt;&lt;p&gt;That‚Äôs a problem. Even though nobody fully understands how it works‚Äîand thus exactly what its limitations might be‚Äîhundreds of millions of people now use this technology every day.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To help overcome our ignorance, researchers are studying LLMs as if they were doing biology or neuroscience on vast living creatures‚Äîcity-size xenomorphs that have appeared in our midst. And they‚Äôre discovering that large language models are even weirder than they thought. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;‚ÄîWill Douglas Heaven&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This is our latest &lt;/strong&gt;&lt;strong&gt;story&lt;/strong&gt;&lt;strong&gt; to be turned into a MIT Technology Review Narrated podcast, which we publish each week on &lt;/strong&gt;&lt;strong&gt;Spotify&lt;/strong&gt;&lt;strong&gt; and &lt;/strong&gt;&lt;strong&gt;Apple Podcasts&lt;/strong&gt;&lt;strong&gt;. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And &lt;/strong&gt;&lt;strong&gt;mechanistic interpretability&lt;/strong&gt;&lt;strong&gt;, the technique these researchers are using to try and understand AI models, is one of our 10 Breakthrough Technologies for 2026. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Job titles of the future: Head-transplant surgeon&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person‚Äôs head‚Äîor perhaps just the brain‚Äîonto a younger, healthier body.&lt;/p&gt;&lt;p&gt;Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed‚Äîor to believe his claim that a procedure on a live person was imminent.&lt;/p&gt;  &lt;p&gt;Canavero may have withdrawn from the spotlight, but the idea of head transplants isn‚Äôt going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;‚ÄîAntonio Regalado&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the latest print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is &lt;/strong&gt;&lt;strong&gt;all about exciting innovations&lt;/strong&gt;&lt;strong&gt;. If you haven‚Äôt already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Big Tech is facing multiple high-profile social media addiction lawsuits&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Meta, TikTok and YouTube will face parents‚Äô accusations in court this week. (WP $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs the first time they‚Äôre defending against these claims before a jury in a court of law. &lt;/em&gt;(CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Power prices are surging in the world‚Äôs largest data center hub&lt;/strong&gt;&lt;br /&gt;Virginia is struggling to meet record demand during a winter storm, partly because of the centers‚Äô electricity demands. (Reuters)&lt;br /&gt;+ &lt;em&gt;Why these kinds of violent storms are getting harder to forecast. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is changing the grid. Could it help more than it harms? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 TikTok has started collecting even more data on its users&lt;/strong&gt;&lt;br /&gt;Including precise information about their location. (Wired $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 ICE-watching groups are successfully fighting DHS efforts to unmask them&lt;br /&gt;An anonymous account holder sued to block ICE from identifying them‚Äîand won. (Ars Technica)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 A new wave of AI companies want to use AI to make AI better&lt;br /&gt;The AI ouroboros is never-ending. (NYT $)&lt;br /&gt;+ &lt;em&gt;Is AI really capable of making bona fide scientific advancements? &lt;/em&gt;(Undark)&lt;br /&gt;+ &lt;em&gt;AI trained on AI garbage spits out AI garbage. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Iran is testing a two-tier internet&lt;/strong&gt;&lt;br /&gt;Meaning its current blackout could become permanent. (Rest of World)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;7 Don‚Äôt believe the humanoid robot hype&lt;br /&gt;Even a leading robot maker admits that at best, they‚Äôre only half as efficient as humans. (FT $)&lt;br /&gt;+ &lt;em&gt;Tesla wants to put its Optimus bipedal machine to work in its Austin factory. &lt;/em&gt;(Insider)&lt;br /&gt;+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 AI is changing how manufacturers create new products&lt;/strong&gt;&lt;br /&gt;Including thinner chewing gum containers and new body wash odors. (WSJ $)&lt;br /&gt;+ &lt;em&gt;AI could make better beer. Here‚Äôs how. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 New Jersey has had enough of e-bikes üö≤&lt;br /&gt;But will other US states follow its lead? (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Sci-fi writers are cracking down on AI&lt;/strong&gt;&lt;br /&gt;Human-produced works only, please. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;San Diego Comic-Con was previously a safe space for AI-generated art. &lt;/em&gt;(404 Media)&lt;br /&gt;+ &lt;em&gt;Generative AI is reshaping South Korea‚Äôs webcomics industry. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúChoosing American digital technology by default is too easy and must stop.‚Äù&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;‚ÄîNicolas Dufourcq, head of French state-owned investment bank Bpifrance, makes his case for why Big European companies should use European-made software as tensions with the US rise, the Wall Street Journal reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1131719" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/image_cf7335.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The return of pneumatic tubes&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Pneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future‚Äîeven in dystopias like George Orwell‚Äôs 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party‚Äôs changing narrative.&lt;/p&gt;&lt;p&gt;In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.&lt;/p&gt;&lt;p&gt;But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîVanessa Armstrong&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ You really can‚Äôt beat the humble jacket potato for a cheap, comforting meal.&amp;nbsp;&lt;br /&gt;+ These tips might help you whenever anxiety strikes. ($)&lt;br /&gt;+ There are some amazing photos in this year‚Äôs Capturing Ecology awards.&lt;br /&gt;+ You can benefit from meditation any time, anywhere. Give it a go!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the new biologists treating LLMs like aliens&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;How large is a large language model? We now coexist with machines so vast and so complicated that nobody quite understands what they are, how they work, or what they can really do‚Äînot even the people who build them.&lt;/p&gt;&lt;p&gt;That‚Äôs a problem. Even though nobody fully understands how it works‚Äîand thus exactly what its limitations might be‚Äîhundreds of millions of people now use this technology every day.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To help overcome our ignorance, researchers are studying LLMs as if they were doing biology or neuroscience on vast living creatures‚Äîcity-size xenomorphs that have appeared in our midst. And they‚Äôre discovering that large language models are even weirder than they thought. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;‚ÄîWill Douglas Heaven&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This is our latest &lt;/strong&gt;&lt;strong&gt;story&lt;/strong&gt;&lt;strong&gt; to be turned into a MIT Technology Review Narrated podcast, which we publish each week on &lt;/strong&gt;&lt;strong&gt;Spotify&lt;/strong&gt;&lt;strong&gt; and &lt;/strong&gt;&lt;strong&gt;Apple Podcasts&lt;/strong&gt;&lt;strong&gt;. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And &lt;/strong&gt;&lt;strong&gt;mechanistic interpretability&lt;/strong&gt;&lt;strong&gt;, the technique these researchers are using to try and understand AI models, is one of our 10 Breakthrough Technologies for 2026. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Job titles of the future: Head-transplant surgeon&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person‚Äôs head‚Äîor perhaps just the brain‚Äîonto a younger, healthier body.&lt;/p&gt;&lt;p&gt;Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed‚Äîor to believe his claim that a procedure on a live person was imminent.&lt;/p&gt;  &lt;p&gt;Canavero may have withdrawn from the spotlight, but the idea of head transplants isn‚Äôt going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;‚ÄîAntonio Regalado&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the latest print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is &lt;/strong&gt;&lt;strong&gt;all about exciting innovations&lt;/strong&gt;&lt;strong&gt;. If you haven‚Äôt already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Big Tech is facing multiple high-profile social media addiction lawsuits&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Meta, TikTok and YouTube will face parents‚Äô accusations in court this week. (WP $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs the first time they‚Äôre defending against these claims before a jury in a court of law. &lt;/em&gt;(CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Power prices are surging in the world‚Äôs largest data center hub&lt;/strong&gt;&lt;br /&gt;Virginia is struggling to meet record demand during a winter storm, partly because of the centers‚Äô electricity demands. (Reuters)&lt;br /&gt;+ &lt;em&gt;Why these kinds of violent storms are getting harder to forecast. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is changing the grid. Could it help more than it harms? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 TikTok has started collecting even more data on its users&lt;/strong&gt;&lt;br /&gt;Including precise information about their location. (Wired $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 ICE-watching groups are successfully fighting DHS efforts to unmask them&lt;br /&gt;An anonymous account holder sued to block ICE from identifying them‚Äîand won. (Ars Technica)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 A new wave of AI companies want to use AI to make AI better&lt;br /&gt;The AI ouroboros is never-ending. (NYT $)&lt;br /&gt;+ &lt;em&gt;Is AI really capable of making bona fide scientific advancements? &lt;/em&gt;(Undark)&lt;br /&gt;+ &lt;em&gt;AI trained on AI garbage spits out AI garbage. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Iran is testing a two-tier internet&lt;/strong&gt;&lt;br /&gt;Meaning its current blackout could become permanent. (Rest of World)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;7 Don‚Äôt believe the humanoid robot hype&lt;br /&gt;Even a leading robot maker admits that at best, they‚Äôre only half as efficient as humans. (FT $)&lt;br /&gt;+ &lt;em&gt;Tesla wants to put its Optimus bipedal machine to work in its Austin factory. &lt;/em&gt;(Insider)&lt;br /&gt;+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 AI is changing how manufacturers create new products&lt;/strong&gt;&lt;br /&gt;Including thinner chewing gum containers and new body wash odors. (WSJ $)&lt;br /&gt;+ &lt;em&gt;AI could make better beer. Here‚Äôs how. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 New Jersey has had enough of e-bikes üö≤&lt;br /&gt;But will other US states follow its lead? (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Sci-fi writers are cracking down on AI&lt;/strong&gt;&lt;br /&gt;Human-produced works only, please. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;San Diego Comic-Con was previously a safe space for AI-generated art. &lt;/em&gt;(404 Media)&lt;br /&gt;+ &lt;em&gt;Generative AI is reshaping South Korea‚Äôs webcomics industry. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúChoosing American digital technology by default is too easy and must stop.‚Äù&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;‚ÄîNicolas Dufourcq, head of French state-owned investment bank Bpifrance, makes his case for why Big European companies should use European-made software as tensions with the US rise, the Wall Street Journal reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1131719" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/image_cf7335.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The return of pneumatic tubes&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Pneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future‚Äîeven in dystopias like George Orwell‚Äôs 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party‚Äôs changing narrative.&lt;/p&gt;&lt;p&gt;In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.&lt;/p&gt;&lt;p&gt;But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîVanessa Armstrong&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ You really can‚Äôt beat the humble jacket potato for a cheap, comforting meal.&amp;nbsp;&lt;br /&gt;+ These tips might help you whenever anxiety strikes. ($)&lt;br /&gt;+ There are some amazing photos in this year‚Äôs Capturing Ecology awards.&lt;br /&gt;+ You can benefit from meditation any time, anywhere. Give it a go!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/26/1131717/the-download-why-llms-are-like-aliens-and-the-future-of-head-transplants/</guid><pubDate>Mon, 26 Jan 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] The power of sound in a virtual world (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/26/1124655/the-power-of-sound-in-a-virtual-world/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Erik-Vaveris-Brian-Scholl-V3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Shure&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;   &lt;p&gt;In an era where business, education, and even casual conversations occur via screens, sound has become a differentiating factor. We obsess over lighting, camera angles, and virtual backgrounds, but how we sound can be just as critical to credibility, trust, and connection.&lt;/p&gt;  &lt;p&gt;That‚Äôs the insight driving Erik Vaveris, vice president of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception &amp;amp; Cognition Laboratory at Yale University. Both see audio as more than a technical layer: It‚Äôs a human factor shaping how people perceive intelligence, trustworthiness, and authority in virtual settings.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;"If you're willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course, your customers," says Vaveris.&lt;/p&gt;  &lt;p&gt;Scholl‚Äôs research shows that poor audio quality can make a speaker seem less persuasive, less hireable, and even less credible.&lt;/p&gt; 
 &lt;p&gt;"We know that [poor] sound doesn't reflect the people themselves, but we really just can't stop ourselves from having those impressions," says Scholl. "We all understand intuitively that if we're having difficulty being understood while we're talking, then that's bad. But we sort of think that as long as you can make out the words I'm saying, then that's probably all fine. And this research showed in a somewhat surprising way, to a surprising degree, that this is not so."&lt;/p&gt;  &lt;p&gt;For organizations navigating hybrid work, training, and marketing, the stakes have become high.&lt;/p&gt; 
 &lt;p&gt;Vaveris points out that the pandemic was a watershed moment for audio technology. As classrooms, boardrooms, and conferences shifted online almost overnight, demand accelerated for advanced noise suppression, echo cancellation, and AI-driven processing tools that make meetings more seamless. Today, machine learning algorithms can strip away keyboard clicks or reverberation and isolate a speaker‚Äôs voice in noisy environments. That clarity underpins the accuracy of AI meeting assistants that can step in to transcribe, summarize, and analyze discussions.&lt;/p&gt;  &lt;p&gt;The implications across industries are rippling. Clearer audio levels the playing field for remote participants, enabling inclusive collaboration. It empowers executives and creators alike to produce broadcast-quality content from the comfort of their home office. And it offers companies new ways to build credibility with customers and employees without the costly overhead of traditional production.&lt;/p&gt;  &lt;p&gt;Looking forward, the convergence of audio innovation and AI promises an even more dynamic landscape: from real-time captioning in your native language to audio filtering, to smarter meeting tools that capture not only what is said but how it‚Äôs said, and to technologies that disappear into the background while amplifying the human voice at the center.&lt;/p&gt;  &lt;p&gt;"There's a future out there where this technology can really be something that helps bring people together," says Vaveris. "Now that we have so many years of history with the internet, we know there's usually two sides to the coin of technology, but there's definitely going to be a positive side to this, and I'm really looking forward to it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In a world increasingly mediated by screens, sound may prove to be the most powerful connector of all.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This episode of Business Lab is produced in partnership with Shure.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Full Transcript&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan Tatum: &lt;/em&gt;From MIT Technology Review, I'm Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.&lt;/p&gt;&lt;p&gt;This episode is produced in partnership with Shure.&lt;/p&gt;&lt;p&gt;Our topic today is the power of sound. As our personal and professional lives become increasingly virtual, audio is emerging as an essential tool for everything from remote work to virtual conferences to virtual happy hour. While appearance is often top of mind in video conferencing and streaming, audio can be as or even more important, not only to effective communication, but potentially to brand equity for both the speaker and the company.&lt;/p&gt;&lt;p&gt;Two words for you: crystal clear.&lt;/p&gt;&lt;p&gt;My guests today are Erik Vaveris, VP of Product Management and Chief Marketing Officer at Shure, and Brian Scholl, Director of the Perception &amp;amp; Cognition Laboratory at Yale University.&lt;/p&gt;&lt;p&gt;Welcome, Erik and Brian.&lt;/p&gt; 

 &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik Vaveris:&lt;/em&gt; Thank you, Megan. And hello, Brian. Thrilled to be here today.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian Scholl:&lt;/em&gt; Good afternoon, everyone.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. Thank you both so much for being here. Erik, let's open with a bit of background. I imagine the pandemic changed the audio industry in some significant ways, given the pivot to our modern remote hybrid lifestyles. Could you talk a bit about that journey and some of the interesting audio advances that arose from that transformative shift?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Absolutely, Megan. That's an interesting thing to think about now being here in 2025. And if you put yourself back in those moments in 2020, when things were fully shut down and everything was fully remote, the importance of audio quality became immediately obvious. As people adopted Zoom or Teams or platforms like that overnight, there were a lot of technical challenges that people experienced, but the importance of how they were presenting themselves to people via their audio quality was a bit less obvious. As Brian's noted in a lot of the press that he's received for his wonderful study, we know how we look on video. We can see ourselves back on the screen, but we don't know how we sound to the people with whom we're speaking.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;If a meeting participant on the other side can manage to parse the words that you're saying, they're not likely to speak up and say, "Hey, I'm having a little bit of trouble hearing you." They'll just let the meeting continue. And if you don't have a really strong level of audio quality, you're asking the people that you're talking to devote way too much brainpower to just determining the words that you're saying. And you're going to be fatiguing to listen to. And your message won't come across. In contrast, if you're willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course your customers. Back in 2020, this very quickly became a marketing story that we had to tell immediately.&lt;/p&gt;  &lt;p&gt;And I have to say, it's so gratifying to see Brian's research in the news because, to me, it was like, "Yes, this is what we've been experiencing. And this is what we've been trying to educate people about." Having the real science to back it up means a lot. But from that, development on improvements to key audio processing algorithms accelerated across the whole AV industry.&lt;/p&gt;  &lt;p&gt;I think, Megan and Brian, you probably remember hearing loud keyboard clicking when you were on calls and meetings, or people eating potato chips and things like that back on those. But you don't hear that much today because most platforms have invested in AI-trained algorithms to remove undesirable noises. And I know we're going to talk more about that later on.&lt;/p&gt;  &lt;p&gt;But the other thing that happened, thankfully, was that as we got into the late spring and summer of 2020, was that educational institutions, especially universities, and also businesses realized that things were going to need to change quickly. Nothing was going to be the same. And universities realized that all classrooms were going to need hybrid capabilities for both remote students and students in the classroom. And that helped the market for professional AV equipment start to recover because we had been pretty much completely shut down in the earlier months. But that focus on hybrid meeting spaces of all types accelerated more investment and more R&amp;amp;D into making equipment and further developing those key audio processing algorithms for more and different types of spaces and use cases. And since then, we've really seen a proliferation of different types of unobtrusive audio capture devices based on arrays of microphones and the supporting signal processing behind them. And right now, machine-learning-trained signal processing is really the norm. And that all accelerated, unfortunately, because of the pandemic.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Such an interesting period of change, as you say. And Brian, what did you observe and experience in academia during that time? How did that time period affect the work at your lab?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; I'll admit, Megan, I had never given a single thought to audio quality or anything like that, certainly until the pandemic hit. I was thrown into this, just like the rest of the world was. I don't believe I'd ever had a single video conference with a student or with a class or anything like that before the pandemic hit. But in some ways, our experience in universities was quite extreme. I went on a Tuesday from teaching an in-person class with 300 students to being on Zoom with everyone suddenly on a Thursday. Business meetings come in all shapes and sizes. But this was quite extreme. This was a case where suddenly I'm talking to hundreds and hundreds of people over Zoom. And every single one of them knows exactly what I sound like, except for me, because I'm just speaking my normal voice and I have no idea how it's being translated through all the different levels of technology.&lt;/p&gt; 
 &lt;p&gt;I will say, part of the general rhetoric we have about the pandemic focuses on all the negatives and the lack of personal connection and nuance and the fact that we can't see how everyone's paying attention to each other. Our experience was a bit more mixed. I'll just tell you one anecdote. Shortly after the pandemic started, I started teaching a seminar with about 20 students. And of course, this was still online. What I did is I just invited, for whatever topic we were discussing on any given day, I sent a note to whoever was the clear world leader in the study of whatever that topic was. I said, "Hey, don't prepare a talk. You don't have to answer any questions. But just come join us on Zoom and just participate in the conversation. The students will have read some of your work."&lt;/p&gt;  &lt;p&gt;Every single one of them said, "Let me check my schedule. Oh, I'm stuck at home for a year. Sure. I'd be happy to do that." And that was quite a positive. The students got to meet a who's who of cognitive science from this experience. And it's true that there were all these technological difficulties, but that would never, ever have happened if we were teaching the class in real life. That would've just been way too much travel and airfare and hotel and scheduling and all of that. So, it was a mixed bag for us.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;That's fascinating.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Megan, can I add?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Of course.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;That is really interesting. And that's such a cool idea. And it's so wonderful that that worked out. I would say that working for a global company, we like to think that, "Oh, we're all together. And we're having these meetings. And we're in the same room," but the reality was we weren't in the same room. And there hadn't been enough attention paid to the people who were conferencing in speaking not their native language in a different time zone, maybe pretty deep into the evening, in some cases. And the remote work that everybody got thrown into immediately at the start of the pandemic did force everybody to start to think more about those types of interactions and put everybody on a level playing field.&lt;/p&gt; 
 &lt;p&gt;And that was insightful. And that helped some people have stronger voices in the work that we were doing than they maybe did before. And it's also led businesses really across the board, there's a lot written about this, to be much more focused on making sure that participants from those who may be remote at home, may be in the office, may be in different offices, may be in different time zones, are all able to participate and collaborate on really a level playing field. And that is a positive. &lt;a&gt;That's a good thing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah. There are absolutely some positive side effects there, aren't there? And it inspired you, Brian, to look at this more closely. And you've done a study that shows poor audio quality can actually affect the perception of listeners. So, I wonder what prompted the study, in particular. And what kinds of data did you gather? What methodology did you use?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Yeah. The motivation for this study was actually a real-world experience, just like we've been talking about. In addition to all of our classes moving online with no notice whatsoever, the same thing was true of our departmental faculty meetings. Very early on in the pandemic, we had one of these meetings. And we were talking about some contentious issue about hiring or whatever. And two of my colleagues, who I'd known very well and for many, many years, spoke up to offer their opinions. And one of these colleagues is someone who I'm very close with. We almost always see eye to eye. He was actually a former graduate student of mine once upon a time. And we almost always see eye to eye on things. He happened to be participating in that meeting from an old not-so-hot laptop. His audio quality had that sort of familiar tinny quality that we're all familiar with. I could totally understand everything he was saying, but I found myself just being a little skeptical.&lt;/p&gt;  &lt;p&gt;I didn't find his points so compelling as usual. Meanwhile, I had another colleague, someone who I deeply respect, I've collaborated with, but we don't always see eye to eye on these things. And he was participating in this first virtual faculty meeting from his home recording studio. Erik, I don't know if his equipment would be up to your level or not, but he sounded better than real life. He sounded like he was all around us. And I found myself just sort of naturally agreeing with his points, which sort of was notable and a little surprising in that context. And so, we turned this into a study.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;We played people a number of short audio clips, maybe like 30 seconds or so. And we had these being played in the context of very familiar situations and decisions. One of them might be like a hiring decision. You would have to listen to this person telling you why they think they might be a good fit for your job. And then afterwards, you had to make a simple judgment. It might be of a trait. How intelligent did that person seem? Or it might be a real-world decision like, "Hey, based on this, how likely would you be to pursue trying to hire them?" And critically, we had people listen to exactly the same sort of scripts, but with a little bit of work behind the scenes to affect the audio quality. In one case, the audio sounded crisp and clear. Recorded with a decent microphone. And here's what it sounded like.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Audio Clip&lt;/em&gt;: After eight years in sales, I'm currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I'm an excellent fit for your company and will be an asset to your team as a senior sales manager.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Okay. Whatever you think of the content of that message, at least it's nice and clear. Other subjects listened to exactly the same recording. But again, it had that sort of tinny quality that we're all familiar with when people's voices are filtered through a microphone or a recording setup that's not so hot. That sounded like this.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Audio Clip&lt;/em&gt;: After eight years in sales, I'm currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I'm an excellent fit for your company and will be an asset to your team as a senior sales manager.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;All right. Now, the thing that I hope you can get from that recording there is that although it clearly has this what we would call, as a technical term, a disfluent sound, it's just a little harder to process, you are ultimately successful, right? Megan, Erik, you were able to understand the words in that second recording.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Mm-hmm.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;And we made sure this was true for all of our subjects. We had them do word-for-word transcription after they made these judgments. And I'll also just point out that this kind of manipulation clearly can't be about the person themselves, right? You couldn't make your voices sound like that in real world conversation if you tried. Voices just don't do those sorts of things. Nevertheless, in a way that sort of didn't make sense, that was kind of irrational because this couldn't reflect the person, this affected all sorts of judgments about people.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;So, people were judged to be about 8% less hirable. They were judged to be about 8% less intelligent. We also did this in other contexts. We did this in the context of dateability as if you were listening to a little audio clip from someone who was maybe interested in dating you, and then you had to make a judgment of how likely would you be to date this person. Same exact result. People were a little less datable when their audio was a little more tinny, even though they were completely understandable.&lt;/p&gt;  &lt;p&gt;The experiment, the result that I thought was in some ways most striking is one of the clips was about someone who had been in a car accident. It was a little narrative about what had happened in the car accident. And they were talking as if to the insurance agent. They were saying, "Hey, it wasn't my fault. This is what happened." And afterwards, we simply had people make a natural intuitive judgment of how credible do you think the person's story was. And when it was recorded with high-end audio, these messages were judged to be about 8% more credible in this context. So those are our experiments. What it shows really is something about the power of perception. We know that that sort of sound doesn't reflect the people themselves, but we really just can't stop ourselves from having those impressions made. And I don't know about you guys, but, Erik, I think you're right, that we all understand intuitively that if we're having difficulty being understood while we're talking, then that's bad. But we sort of think that as long as you can make out the words I'm saying, then that's probably all fine. And this research showed in a somewhat surprising way to a surprising degree that this is not so&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;It's absolutely fascinating.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Wow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;From an industry perspective, Erik, what are your thoughts on those study results? Did it surprise you as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; No, like I said, I found it very, very gratifying because we invest a lot in trying to make sure that people understand the importance of quality audio, but we kind of come about that intuitively. Our entire company is audio people. So of course, we think that. And it's our mission to help other people achieve those higher levels of audio in everything that they do, whether you're a minister at a church or you're teaching a class or you're performing on stage. When I first saw in the news about Brian's study, I think it was the NPR article that just came up in one of my feeds. I read it and it made me feel like my life's work has been validated to some extent. I wouldn't say we were surprised by it, but iIt made a lot of sense to us. Let's put it that way.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And how-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;This is what we're hearing. Oh, sorry. Megan, I was going to say this is what we're hearing from a lot of the audio professionals as they're saying, "Hey, you scientists, you finally caught up to us." But of course-&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; I wouldn't say it that way, Brian.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Erik, you're in an unusual circumstance because you guys think about audio every day. When we're on Zoom, look, I can see the little rectangle as well as you can. I can see exactly how I look like. I can check the lighting. I check my hair. We all do that every day. But I would say most people really, they use whatever microphone came with their setup, and never give a second thought to what they sound like because they don't know what they sound like.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Avoid listening to yourself back as well. I think that's common. We don't scrutinize audio as much as we should. I wonder, Erik, since the study came out, how are you seeing that research play out across industry? Can you talk a bit about the importance of strong, clear audio in today's virtual world and the challenges that companies and employees are facing as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Sure, Megan. That's a great question. And studies kind of back this up, businesses understand that collaboration is the key to many things that we do. They know that that's critical. And they are investing in making the experiences for the people at work better because of that knowledge, that intuitive understanding. But there are challenges. It can be expensive. You need solutions that people who are going to walk into a room or join a meeting on their personal device, that they're motivated to use and that they can use because they're simple. You also have to overcome the barriers to investment. We in the AV industry have had to look a lot at how can we bring down the overall cost of ownership of setting up AV technology because, as we've seen, the prices of everything that goes into making a product are not coming down.&lt;/p&gt;  &lt;p&gt;Simplifying deployment and management is critical. Beyond just audio technology, IoT technology and cloud technology for IT teams to be able to easily deploy and manage classrooms across an entire university campus or conference rooms across a global enterprise are really, really critical. And those are quickly evolving. And integrations with more standard common IT tools are coming out. And that's one area. Another thing is just for the end user, having the same user interface in each conference room that is familiar to everyone from their personal devices is also important. For many, many years, a lot of people had the experience where, "Hey, it's time we're going to actually do a conference meeting." And you might have a few rooms in your company or in your office area that could do that. And you walk into the meeting room. And how long does it take you to actually get connected to the people you're going to talk with?&lt;/p&gt;  &lt;p&gt;There was always a joke that you'd have to spend the first 15 minutes of a meeting working all of that out. And that's because the technology was fragmented and you had to do a lot of custom work to make that happen. But these days, I would say platforms like Zoom and Teams and Google and others are doing a really great job with this. If you have the latest and greatest in your meeting rooms and you know how to join from your own personal device, it's basically the same experience. And that is streamlining the process for everyone. Bringing down the costs of owning it so that companies can get to those benefits to collaboration is kind of the key.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; I was going to ask if we could dive a little deeper into that kind of audio quality, the technological advancements that AI has made possible, which you did touch on slightly there, Erik. What are the most significant advancements, in your view? And how are those impacting the ways we use audio and the things we can do with it?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Okay. Let me try to break that down into-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;That's a big question. Sorry.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;... a couple different sections. Yeah. No, and one that's just so exciting. Machine-learning-based digital signal processing, or DSP, is here and is the norm now. If you think about the beginning of telephones and teleconferencing, just going way back, one of the initial problems you had whenever you tried to get something out of a dedicated handset onto a table was echo. And I'm sure we've all heard that at some point in our life. You need to have a way to cancel echo. But by the way, you also want people to be able to speak at the same time on both ends of a call. You get to some of those very rudimentary things. Machine learning is really supercharging those algorithms to provide better performance with fewer trade-offs, fewer artifacts in the actual audio signal.&lt;/p&gt;  &lt;p&gt;Noise reduction has come a long way. I mentioned earlier on, keyboard sounds and the sounds of people eating, and how you just don't hear that anymore, at least I &lt;a&gt;don't when I'm on conference calls. But only a few years ago, that could be a major problem. The machine-learning-trained digital signal processing is in the market now and it's doing a better job than ever in removing things that you don't want from your sound. We have a new de-verberation algorithm, so if you have a reverberant room with echoes and reflections that's getting into the audio signal, that can degrade the experience there. We can remove that now. Another thing, the flip side of that is that there's also a focus on isolating the sound that you do want and the signal that you do want.&lt;/p&gt;  &lt;p&gt;Microsoft has rolled out a voice print feature in Teams that allows you, if you're willing, to provide them with a sample of your voice. And then whenever you're talking from your device, it will take out anything else that the microphone may be picking up so that even if you're in a really noisy environment outdoors or, say, in an airport, the people that you're speaking with are going to hear you and only you. And it's pretty amazing as well. So those are some of the things that are happening today and are available today.&lt;/p&gt;  &lt;p&gt;Another thing that's emerged from all of this is we've been talking about how important audio quality is to the people participating in a discussion, the people speaking, the people listening, how everyone is perceived, but a new consumer, if you will, of audio in a discussion or a meeting has emerged, and that is in the form of the AI agent that can summarize meetings and create action plans, do those sorts of things. But for it to work, a clean transcription of what was said is already table stakes. It can't garbled. It can't miss key things. It needs to get it word for word, sentence for sentence throughout the entire meeting. And the ability to attribute who said what to the meeting participants, even if they're all in the same room, is quickly upon us. And the ability to detect and integrate sentiment and emotion of the participants is going to become very important as well for us to really get the full value out of those kinds of AI agents.&lt;/p&gt;  &lt;p&gt;So audio quality is as important as ever for humans, as Brian notes, in some ways more important because this is now the normal way that we talk and meet, but it's also critical for AI agents to work properly. And it's different, right? It's a different set of considerations. And there's a lot of emerging thought and work that's going into that as well. And boy, Megan, there's so much more we could say about this beyond meetings and video conferences. AI tools to simplify the production process. And of course, there's generative AI of music content. I know that's beyond the scope of what we're talking about. But it's really pretty incredible when you look around at the work that's happening and the capabilities that are emerging.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Absolutely. Sounds like there are so many elements to consider and work going on. It's all fascinating. Brian, what kinds of emerging capabilities and use cases around AI and audio quality are you seeing in your lab as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Yeah. Well, I'm sorry that Brian himself was not able to be here today, but I'm an AI agent.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;You got me for a second there.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Just kidding. The fascinating thing that we're seeing from the lab, from the study of people's impressions is that all of this technology that Erik has described, when it works best, it's completely invisible. Erik, I loved your point about not hearing potato chips being eaten or rain in the background or something like that. You're totally right. I used to notice that all the time. I don't think I've noticed that recently, but I also didn't notice that I haven't noticed that recently, right? It just kind of disappears. The interesting thing about these perceptual impressions, we're constantly drawing intuitive conclusions about people based on how they sound. And that might be a good thing or a bad thing when we're judging things like trustworthiness, for example, on the basis of a short audio clip.&lt;/p&gt;  &lt;p&gt;But clearly, some of these things are valid, right? We can judge the size of someone or even of an animal based on how they sound, right? A chihuahua can't make the sound of a lion. A lion can't make the sound of a chihuahua. And that's always been true because we're producing audio signals that go right into each other's ears. And now, of course, everything that Erik is talking about, that's not true. It goes through all of these different layers of technology increasingly fueled by AI. But when that technology works the best way, it's as if it isn't there at all and we're just hearing each other directly.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; That's the goal, right? That it's seamless open communication and we don't have to think about the technology anymore.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;It's a tough business to be in, I think, though, Erik, because people have to know what's going on behind the surface in order to value it. Otherwise, we just expect it to work.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Well, that's why we try to put the logo of our products on the side of them so they show up in the videos. But yeah, it's a good point.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Very good. Very good.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;And we've talked about virtual meetings and conversations quite a bit, but there's also streamed and recorded content, which are increasingly important at work as well. I wondered, Erik, if you could talk a bit about how businesses are leveraging audio in new ways for things like marketing campaigns and internal upskilling and training and areas like that?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Well, one of the things I think we've all seen in marketing is that not everything is a high production value commercial anymore. And there's still a place for that, for sure. But people tend to trust influencers that they follow. People search on TikTok, on YouTube for topics. Those can be the place that they start. And as technology's gotten more accessible, not just audio, but of course, the video technology too, content creators can produce satisfying content on their own or with just a couple of people with them. And Brian's study shows that it doesn't really matter what the origins of the content are for it to be compelling.&lt;/p&gt;  &lt;p&gt;For the person delivering the message to be compelling, the audio quality does have to hit a certain level. But because the tools are simpler to use and you need less things to connect and pull together a decent production system, creator-driven content is becoming even more and more integral to a marketing campaign. And so not just what they maybe post on their Instagram page or post on LinkedIn, for example, but us as a brand being able to take that content and use that actually in paid media and things like that is all entirely possible because of the overall quality of the content. So that's something that's been a trend that's been in process really, I would say, maybe since the advent of podcasts. But it's been an evolution. And it's come a long, long way.&lt;/p&gt;  &lt;p&gt;Another thing, and this is really interesting, and this hits home personally, but I remember when I first entered the workforce, and I hope I'm not showing my age too badly here, but I remember the word processing department. And you would write down on a piece of paper, like a memo, and you would give it to the word processing department and somebody would type it up for you. That was a thing. And these days, we're seeing actually more and more video production with audio, of course, transfer to the actual producers of the content.&lt;/p&gt;  &lt;p&gt;In my company, at Shure, we make videos for different purposes to talk about different initiatives or product launches or things that we're doing just for internal use. And right now, everybody, including our CEO, she makes these videos just at her own desk. She has a little software tool and she can show a PowerPoint and herself and speak to things. And with very, very limited amount of editing, you can put that out there. And I've seen friends and colleagues at other companies in very high-level roles just kind of doing their own production. Being able to buy a very high quality microphone with really advanced signal processing built right in, but just plug it in via USB and have it be handled as simply as any consumer device, has made it possible to do really very useful production where you are going to actually sound good and get your message across, but without having to make such a big production out of it, which is kind of cool.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah. Really democratizes access to sort of creating high quality content, doesn't it? And of course, no technology discussion is complete without a mention of return on investment, particularly nowadays. Erik, what are some ways companies can get returns on their audio tech investments as well? Where are the most common places you see cost savings?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Yeah. Well, we collaborated on a study with IDC Research. And they came up with some really interesting findings on this. And one of them was, no surprise, two-thirds or more of companies have taken action on improving their communication and collaboration technology, and even more have additional or initial investments still planned. But the ROI of those initiatives isn't really tied to the initiative itself. It's not like when you come out with a new product, you look at how that product performs, and that's the driver of your ROI. The benefits of smoother collaboration come in the form of shorter meetings, more productive meetings, better decision-making, faster decision-making, stronger teamwork. And so to build an ROI model, what IDC concluded was that you have to build your model to account for those advantages really across the enterprise or across your university, or whatever it may be, and kind of up and down the different set of activities where they're actually going to be utilized.&lt;/p&gt;  &lt;p&gt;So that can be complex. Quantifying things can always be a challenge. But like I said, companies do seem to understand this. And I think that's because, this is just my hunch, but because everybody, including the CEO and the CFO and the whole finance department, uses and benefits from collaboration technology too. Perhaps that's one reason why the value is easier to convey. Even if they have not taken the time to articulate things like we're doing here today, they know when a meeting is good and when it's not good. And maybe that's one of the things that's helping companies to justify these investments. But it's always tricky to do ROI on projects like that. But again, focusing on the broader benefits of collaboration and breaking it down into what it means for specific activities and types of meetings, I think, is the way to go about doing that.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Absolutely. And Brian, what kinds of advancements are you seeing in the lab that perhaps one day might contribute to those cost savings?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Well, I don't know anything about cost savings, Megan. I'm a college professor. I live a pure life of the mind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Of course.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;ROI does not compute for me. No, I would say we are in an extremely exciting frontier right now because of AI and many different technologies. The studies that we talked about earlier, in one sense, they were broad. We explored many different traits from dating to hiring to credibility. And we isolated them in all sorts of ways we didn't talk about. We showed that it wasn't due to overall affect or pessimism or something like that. But in those studies, we really only tested one very particular set of dimensions along which an audio signal can vary, which is some sort of model of clarity. But in reality, the audio signal is so multi-dimensional. And as we're getting more and more tools these days, we can not only change audio along the lines of clarity, as we've been talking about, but we can potentially manipulate it in all sorts of ways.&lt;/p&gt;  &lt;p&gt;We're very interested in pushing these studies forward and in exploring how people's sort of brute impressions that they make are affected by all sorts of things. Meg and Erik, we walk around the world all the time making these judgments about people, right? You meet someone and you're like, "Wow, I could really be friends with them. They seem like a great person." And you know that you're making that judgment, but you have no idea why, right? It just seems kind of intuitive. Well, in an audio signal, when you're talking to someone, you can think of, "What if their signal is more bass heavy? What if it's a little more treble heavy? What if we manipulate it in this way? In that way?"&lt;/p&gt;  &lt;p&gt;When we talked about the faculty meeting that motivated this whole research program, I mentioned that my colleague, who was speaking from his home recording studio, he actually didn't sound clear like in real life. He sounded better than in real life. He sounded like he was all around us. What is the implication of that? I think there's so many different dimensions of an audio signal that we're just being able to readily control and manipulate that it's going to be very exciting to see how all of these sorts of things impact our impressions of each other.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And there may be some overlap with this as well, but I wondered if we could close with a future forward look, Brian. What are you looking forward to in emerging audio technology? What are some exciting opportunities on the horizon, perhaps related to what you were just talking about there?&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Brian:&lt;/em&gt; Well, we're interested in studying this from a scientific perspective. Erik, you talked about how when you started. When I started doing this science, we didn't have a word processing department. We had a stone tablet department. But I hear tell that the current generation, when they send photos back and forth to each other, that they, as a matter, of course, they apply all sorts of filters-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Oh, yes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; ... to those video signals, those video or just photographic signals. We're all familiar with that. That hasn't quite happened with the audio signals yet, but I think that's coming up as well. You can imagine that you record yourself saying a little message and then you filter it this way or that way. And that's going to become the Wild West about the kinds of impressions we make on each other, especially if and when you don't know that those filters have been operating in the first place.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan: &lt;/em&gt;That's so interesting. Erik, what are you looking forward to in audio technology as well?&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik:&lt;/em&gt; Well, I'm still thinking about what Brian said.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. That's-&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik: &lt;/em&gt;That's very interesting.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan:&lt;/em&gt; It's terrifying.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik:&lt;/em&gt; I have to go back again. I'll go back to the past, maybe 15 to 20 years. And I remember at work, we had meeting rooms with the Starfish phones in the middle of the table. And I remember that we would have international meetings with our partners there that were selling our products in different countries, including in Japan and in China, and the people actually in our own company in those countries. We knew the time zone was bad. And we knew that English wasn't their native language, and tried to be as courteous as possible with written materials and things like that. But I went over to China, and I had to actually be on the other end of one of those calls. And I'm a native English speaker, or at least a native Chicago dialect of American English speaker. And really understanding how challenging it was for them to participate in those meetings just hit me right between the eyes.&lt;/p&gt;  &lt;p&gt;We've come so far, which is wonderful. But I think of a scenario, and this is not far off, there are many companies working on this right now, where not only can you get a real time captioning in your native language, no matter what the language of the participant, you can actually hear the person who's speaking's voice manipulated into your native language.&lt;/p&gt;  &lt;p&gt;I'm never going to be a fluent Japanese or Chinese speaker, that's for sure. But I love the thought that I could actually talk with people and they could understand me as though I were speaking their native language, and that they could communicate to me and I could understand them in the way that they want to be understood. I think there's a future out there where this technology can really be something that helps bring people together. Now that we have so many years of history with the internet, we know there's usually two sides to the coin of technology, but there's definitely going to be a positive side to this, and I'm really looking forward to it.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Gosh, that sounds absolutely fascinating. Thank you both so much for such an interesting discussion.&lt;/p&gt;  &lt;p&gt;That was Erik Vaveris, the VP of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception &amp;amp; Cognition Laboratory at Yale University, whom I spoke with from Brighton in England.&lt;/p&gt;&lt;p&gt;That's it for this episode of Business Lab. I'm your host, Megan Tatum. I'm a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology. And you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.&lt;/p&gt;&lt;p&gt;This show is available wherever you get your podcasts. If you enjoyed this episode, we hope you'll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. And this episode was produced by Giro Studios. Thanks for listening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Erik-Vaveris-Brian-Scholl-V3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Shure&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;   &lt;p&gt;In an era where business, education, and even casual conversations occur via screens, sound has become a differentiating factor. We obsess over lighting, camera angles, and virtual backgrounds, but how we sound can be just as critical to credibility, trust, and connection.&lt;/p&gt;  &lt;p&gt;That‚Äôs the insight driving Erik Vaveris, vice president of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception &amp;amp; Cognition Laboratory at Yale University. Both see audio as more than a technical layer: It‚Äôs a human factor shaping how people perceive intelligence, trustworthiness, and authority in virtual settings.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;"If you're willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course, your customers," says Vaveris.&lt;/p&gt;  &lt;p&gt;Scholl‚Äôs research shows that poor audio quality can make a speaker seem less persuasive, less hireable, and even less credible.&lt;/p&gt; 
 &lt;p&gt;"We know that [poor] sound doesn't reflect the people themselves, but we really just can't stop ourselves from having those impressions," says Scholl. "We all understand intuitively that if we're having difficulty being understood while we're talking, then that's bad. But we sort of think that as long as you can make out the words I'm saying, then that's probably all fine. And this research showed in a somewhat surprising way, to a surprising degree, that this is not so."&lt;/p&gt;  &lt;p&gt;For organizations navigating hybrid work, training, and marketing, the stakes have become high.&lt;/p&gt; 
 &lt;p&gt;Vaveris points out that the pandemic was a watershed moment for audio technology. As classrooms, boardrooms, and conferences shifted online almost overnight, demand accelerated for advanced noise suppression, echo cancellation, and AI-driven processing tools that make meetings more seamless. Today, machine learning algorithms can strip away keyboard clicks or reverberation and isolate a speaker‚Äôs voice in noisy environments. That clarity underpins the accuracy of AI meeting assistants that can step in to transcribe, summarize, and analyze discussions.&lt;/p&gt;  &lt;p&gt;The implications across industries are rippling. Clearer audio levels the playing field for remote participants, enabling inclusive collaboration. It empowers executives and creators alike to produce broadcast-quality content from the comfort of their home office. And it offers companies new ways to build credibility with customers and employees without the costly overhead of traditional production.&lt;/p&gt;  &lt;p&gt;Looking forward, the convergence of audio innovation and AI promises an even more dynamic landscape: from real-time captioning in your native language to audio filtering, to smarter meeting tools that capture not only what is said but how it‚Äôs said, and to technologies that disappear into the background while amplifying the human voice at the center.&lt;/p&gt;  &lt;p&gt;"There's a future out there where this technology can really be something that helps bring people together," says Vaveris. "Now that we have so many years of history with the internet, we know there's usually two sides to the coin of technology, but there's definitely going to be a positive side to this, and I'm really looking forward to it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In a world increasingly mediated by screens, sound may prove to be the most powerful connector of all.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This episode of Business Lab is produced in partnership with Shure.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Full Transcript&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan Tatum: &lt;/em&gt;From MIT Technology Review, I'm Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.&lt;/p&gt;&lt;p&gt;This episode is produced in partnership with Shure.&lt;/p&gt;&lt;p&gt;Our topic today is the power of sound. As our personal and professional lives become increasingly virtual, audio is emerging as an essential tool for everything from remote work to virtual conferences to virtual happy hour. While appearance is often top of mind in video conferencing and streaming, audio can be as or even more important, not only to effective communication, but potentially to brand equity for both the speaker and the company.&lt;/p&gt;&lt;p&gt;Two words for you: crystal clear.&lt;/p&gt;&lt;p&gt;My guests today are Erik Vaveris, VP of Product Management and Chief Marketing Officer at Shure, and Brian Scholl, Director of the Perception &amp;amp; Cognition Laboratory at Yale University.&lt;/p&gt;&lt;p&gt;Welcome, Erik and Brian.&lt;/p&gt; 

 &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik Vaveris:&lt;/em&gt; Thank you, Megan. And hello, Brian. Thrilled to be here today.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian Scholl:&lt;/em&gt; Good afternoon, everyone.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. Thank you both so much for being here. Erik, let's open with a bit of background. I imagine the pandemic changed the audio industry in some significant ways, given the pivot to our modern remote hybrid lifestyles. Could you talk a bit about that journey and some of the interesting audio advances that arose from that transformative shift?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Absolutely, Megan. That's an interesting thing to think about now being here in 2025. And if you put yourself back in those moments in 2020, when things were fully shut down and everything was fully remote, the importance of audio quality became immediately obvious. As people adopted Zoom or Teams or platforms like that overnight, there were a lot of technical challenges that people experienced, but the importance of how they were presenting themselves to people via their audio quality was a bit less obvious. As Brian's noted in a lot of the press that he's received for his wonderful study, we know how we look on video. We can see ourselves back on the screen, but we don't know how we sound to the people with whom we're speaking.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;If a meeting participant on the other side can manage to parse the words that you're saying, they're not likely to speak up and say, "Hey, I'm having a little bit of trouble hearing you." They'll just let the meeting continue. And if you don't have a really strong level of audio quality, you're asking the people that you're talking to devote way too much brainpower to just determining the words that you're saying. And you're going to be fatiguing to listen to. And your message won't come across. In contrast, if you're willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course your customers. Back in 2020, this very quickly became a marketing story that we had to tell immediately.&lt;/p&gt;  &lt;p&gt;And I have to say, it's so gratifying to see Brian's research in the news because, to me, it was like, "Yes, this is what we've been experiencing. And this is what we've been trying to educate people about." Having the real science to back it up means a lot. But from that, development on improvements to key audio processing algorithms accelerated across the whole AV industry.&lt;/p&gt;  &lt;p&gt;I think, Megan and Brian, you probably remember hearing loud keyboard clicking when you were on calls and meetings, or people eating potato chips and things like that back on those. But you don't hear that much today because most platforms have invested in AI-trained algorithms to remove undesirable noises. And I know we're going to talk more about that later on.&lt;/p&gt;  &lt;p&gt;But the other thing that happened, thankfully, was that as we got into the late spring and summer of 2020, was that educational institutions, especially universities, and also businesses realized that things were going to need to change quickly. Nothing was going to be the same. And universities realized that all classrooms were going to need hybrid capabilities for both remote students and students in the classroom. And that helped the market for professional AV equipment start to recover because we had been pretty much completely shut down in the earlier months. But that focus on hybrid meeting spaces of all types accelerated more investment and more R&amp;amp;D into making equipment and further developing those key audio processing algorithms for more and different types of spaces and use cases. And since then, we've really seen a proliferation of different types of unobtrusive audio capture devices based on arrays of microphones and the supporting signal processing behind them. And right now, machine-learning-trained signal processing is really the norm. And that all accelerated, unfortunately, because of the pandemic.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Such an interesting period of change, as you say. And Brian, what did you observe and experience in academia during that time? How did that time period affect the work at your lab?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; I'll admit, Megan, I had never given a single thought to audio quality or anything like that, certainly until the pandemic hit. I was thrown into this, just like the rest of the world was. I don't believe I'd ever had a single video conference with a student or with a class or anything like that before the pandemic hit. But in some ways, our experience in universities was quite extreme. I went on a Tuesday from teaching an in-person class with 300 students to being on Zoom with everyone suddenly on a Thursday. Business meetings come in all shapes and sizes. But this was quite extreme. This was a case where suddenly I'm talking to hundreds and hundreds of people over Zoom. And every single one of them knows exactly what I sound like, except for me, because I'm just speaking my normal voice and I have no idea how it's being translated through all the different levels of technology.&lt;/p&gt; 
 &lt;p&gt;I will say, part of the general rhetoric we have about the pandemic focuses on all the negatives and the lack of personal connection and nuance and the fact that we can't see how everyone's paying attention to each other. Our experience was a bit more mixed. I'll just tell you one anecdote. Shortly after the pandemic started, I started teaching a seminar with about 20 students. And of course, this was still online. What I did is I just invited, for whatever topic we were discussing on any given day, I sent a note to whoever was the clear world leader in the study of whatever that topic was. I said, "Hey, don't prepare a talk. You don't have to answer any questions. But just come join us on Zoom and just participate in the conversation. The students will have read some of your work."&lt;/p&gt;  &lt;p&gt;Every single one of them said, "Let me check my schedule. Oh, I'm stuck at home for a year. Sure. I'd be happy to do that." And that was quite a positive. The students got to meet a who's who of cognitive science from this experience. And it's true that there were all these technological difficulties, but that would never, ever have happened if we were teaching the class in real life. That would've just been way too much travel and airfare and hotel and scheduling and all of that. So, it was a mixed bag for us.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;That's fascinating.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Megan, can I add?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Of course.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;That is really interesting. And that's such a cool idea. And it's so wonderful that that worked out. I would say that working for a global company, we like to think that, "Oh, we're all together. And we're having these meetings. And we're in the same room," but the reality was we weren't in the same room. And there hadn't been enough attention paid to the people who were conferencing in speaking not their native language in a different time zone, maybe pretty deep into the evening, in some cases. And the remote work that everybody got thrown into immediately at the start of the pandemic did force everybody to start to think more about those types of interactions and put everybody on a level playing field.&lt;/p&gt; 
 &lt;p&gt;And that was insightful. And that helped some people have stronger voices in the work that we were doing than they maybe did before. And it's also led businesses really across the board, there's a lot written about this, to be much more focused on making sure that participants from those who may be remote at home, may be in the office, may be in different offices, may be in different time zones, are all able to participate and collaborate on really a level playing field. And that is a positive. &lt;a&gt;That's a good thing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah. There are absolutely some positive side effects there, aren't there? And it inspired you, Brian, to look at this more closely. And you've done a study that shows poor audio quality can actually affect the perception of listeners. So, I wonder what prompted the study, in particular. And what kinds of data did you gather? What methodology did you use?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Yeah. The motivation for this study was actually a real-world experience, just like we've been talking about. In addition to all of our classes moving online with no notice whatsoever, the same thing was true of our departmental faculty meetings. Very early on in the pandemic, we had one of these meetings. And we were talking about some contentious issue about hiring or whatever. And two of my colleagues, who I'd known very well and for many, many years, spoke up to offer their opinions. And one of these colleagues is someone who I'm very close with. We almost always see eye to eye. He was actually a former graduate student of mine once upon a time. And we almost always see eye to eye on things. He happened to be participating in that meeting from an old not-so-hot laptop. His audio quality had that sort of familiar tinny quality that we're all familiar with. I could totally understand everything he was saying, but I found myself just being a little skeptical.&lt;/p&gt;  &lt;p&gt;I didn't find his points so compelling as usual. Meanwhile, I had another colleague, someone who I deeply respect, I've collaborated with, but we don't always see eye to eye on these things. And he was participating in this first virtual faculty meeting from his home recording studio. Erik, I don't know if his equipment would be up to your level or not, but he sounded better than real life. He sounded like he was all around us. And I found myself just sort of naturally agreeing with his points, which sort of was notable and a little surprising in that context. And so, we turned this into a study.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;We played people a number of short audio clips, maybe like 30 seconds or so. And we had these being played in the context of very familiar situations and decisions. One of them might be like a hiring decision. You would have to listen to this person telling you why they think they might be a good fit for your job. And then afterwards, you had to make a simple judgment. It might be of a trait. How intelligent did that person seem? Or it might be a real-world decision like, "Hey, based on this, how likely would you be to pursue trying to hire them?" And critically, we had people listen to exactly the same sort of scripts, but with a little bit of work behind the scenes to affect the audio quality. In one case, the audio sounded crisp and clear. Recorded with a decent microphone. And here's what it sounded like.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Audio Clip&lt;/em&gt;: After eight years in sales, I'm currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I'm an excellent fit for your company and will be an asset to your team as a senior sales manager.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Okay. Whatever you think of the content of that message, at least it's nice and clear. Other subjects listened to exactly the same recording. But again, it had that sort of tinny quality that we're all familiar with when people's voices are filtered through a microphone or a recording setup that's not so hot. That sounded like this.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Audio Clip&lt;/em&gt;: After eight years in sales, I'm currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I'm an excellent fit for your company and will be an asset to your team as a senior sales manager.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;All right. Now, the thing that I hope you can get from that recording there is that although it clearly has this what we would call, as a technical term, a disfluent sound, it's just a little harder to process, you are ultimately successful, right? Megan, Erik, you were able to understand the words in that second recording.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Mm-hmm.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;And we made sure this was true for all of our subjects. We had them do word-for-word transcription after they made these judgments. And I'll also just point out that this kind of manipulation clearly can't be about the person themselves, right? You couldn't make your voices sound like that in real world conversation if you tried. Voices just don't do those sorts of things. Nevertheless, in a way that sort of didn't make sense, that was kind of irrational because this couldn't reflect the person, this affected all sorts of judgments about people.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;So, people were judged to be about 8% less hirable. They were judged to be about 8% less intelligent. We also did this in other contexts. We did this in the context of dateability as if you were listening to a little audio clip from someone who was maybe interested in dating you, and then you had to make a judgment of how likely would you be to date this person. Same exact result. People were a little less datable when their audio was a little more tinny, even though they were completely understandable.&lt;/p&gt;  &lt;p&gt;The experiment, the result that I thought was in some ways most striking is one of the clips was about someone who had been in a car accident. It was a little narrative about what had happened in the car accident. And they were talking as if to the insurance agent. They were saying, "Hey, it wasn't my fault. This is what happened." And afterwards, we simply had people make a natural intuitive judgment of how credible do you think the person's story was. And when it was recorded with high-end audio, these messages were judged to be about 8% more credible in this context. So those are our experiments. What it shows really is something about the power of perception. We know that that sort of sound doesn't reflect the people themselves, but we really just can't stop ourselves from having those impressions made. And I don't know about you guys, but, Erik, I think you're right, that we all understand intuitively that if we're having difficulty being understood while we're talking, then that's bad. But we sort of think that as long as you can make out the words I'm saying, then that's probably all fine. And this research showed in a somewhat surprising way to a surprising degree that this is not so&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;It's absolutely fascinating.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Wow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;From an industry perspective, Erik, what are your thoughts on those study results? Did it surprise you as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; No, like I said, I found it very, very gratifying because we invest a lot in trying to make sure that people understand the importance of quality audio, but we kind of come about that intuitively. Our entire company is audio people. So of course, we think that. And it's our mission to help other people achieve those higher levels of audio in everything that they do, whether you're a minister at a church or you're teaching a class or you're performing on stage. When I first saw in the news about Brian's study, I think it was the NPR article that just came up in one of my feeds. I read it and it made me feel like my life's work has been validated to some extent. I wouldn't say we were surprised by it, but iIt made a lot of sense to us. Let's put it that way.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And how-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;This is what we're hearing. Oh, sorry. Megan, I was going to say this is what we're hearing from a lot of the audio professionals as they're saying, "Hey, you scientists, you finally caught up to us." But of course-&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; I wouldn't say it that way, Brian.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Erik, you're in an unusual circumstance because you guys think about audio every day. When we're on Zoom, look, I can see the little rectangle as well as you can. I can see exactly how I look like. I can check the lighting. I check my hair. We all do that every day. But I would say most people really, they use whatever microphone came with their setup, and never give a second thought to what they sound like because they don't know what they sound like.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Avoid listening to yourself back as well. I think that's common. We don't scrutinize audio as much as we should. I wonder, Erik, since the study came out, how are you seeing that research play out across industry? Can you talk a bit about the importance of strong, clear audio in today's virtual world and the challenges that companies and employees are facing as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Sure, Megan. That's a great question. And studies kind of back this up, businesses understand that collaboration is the key to many things that we do. They know that that's critical. And they are investing in making the experiences for the people at work better because of that knowledge, that intuitive understanding. But there are challenges. It can be expensive. You need solutions that people who are going to walk into a room or join a meeting on their personal device, that they're motivated to use and that they can use because they're simple. You also have to overcome the barriers to investment. We in the AV industry have had to look a lot at how can we bring down the overall cost of ownership of setting up AV technology because, as we've seen, the prices of everything that goes into making a product are not coming down.&lt;/p&gt;  &lt;p&gt;Simplifying deployment and management is critical. Beyond just audio technology, IoT technology and cloud technology for IT teams to be able to easily deploy and manage classrooms across an entire university campus or conference rooms across a global enterprise are really, really critical. And those are quickly evolving. And integrations with more standard common IT tools are coming out. And that's one area. Another thing is just for the end user, having the same user interface in each conference room that is familiar to everyone from their personal devices is also important. For many, many years, a lot of people had the experience where, "Hey, it's time we're going to actually do a conference meeting." And you might have a few rooms in your company or in your office area that could do that. And you walk into the meeting room. And how long does it take you to actually get connected to the people you're going to talk with?&lt;/p&gt;  &lt;p&gt;There was always a joke that you'd have to spend the first 15 minutes of a meeting working all of that out. And that's because the technology was fragmented and you had to do a lot of custom work to make that happen. But these days, I would say platforms like Zoom and Teams and Google and others are doing a really great job with this. If you have the latest and greatest in your meeting rooms and you know how to join from your own personal device, it's basically the same experience. And that is streamlining the process for everyone. Bringing down the costs of owning it so that companies can get to those benefits to collaboration is kind of the key.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; I was going to ask if we could dive a little deeper into that kind of audio quality, the technological advancements that AI has made possible, which you did touch on slightly there, Erik. What are the most significant advancements, in your view? And how are those impacting the ways we use audio and the things we can do with it?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Okay. Let me try to break that down into-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;That's a big question. Sorry.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;... a couple different sections. Yeah. No, and one that's just so exciting. Machine-learning-based digital signal processing, or DSP, is here and is the norm now. If you think about the beginning of telephones and teleconferencing, just going way back, one of the initial problems you had whenever you tried to get something out of a dedicated handset onto a table was echo. And I'm sure we've all heard that at some point in our life. You need to have a way to cancel echo. But by the way, you also want people to be able to speak at the same time on both ends of a call. You get to some of those very rudimentary things. Machine learning is really supercharging those algorithms to provide better performance with fewer trade-offs, fewer artifacts in the actual audio signal.&lt;/p&gt;  &lt;p&gt;Noise reduction has come a long way. I mentioned earlier on, keyboard sounds and the sounds of people eating, and how you just don't hear that anymore, at least I &lt;a&gt;don't when I'm on conference calls. But only a few years ago, that could be a major problem. The machine-learning-trained digital signal processing is in the market now and it's doing a better job than ever in removing things that you don't want from your sound. We have a new de-verberation algorithm, so if you have a reverberant room with echoes and reflections that's getting into the audio signal, that can degrade the experience there. We can remove that now. Another thing, the flip side of that is that there's also a focus on isolating the sound that you do want and the signal that you do want.&lt;/p&gt;  &lt;p&gt;Microsoft has rolled out a voice print feature in Teams that allows you, if you're willing, to provide them with a sample of your voice. And then whenever you're talking from your device, it will take out anything else that the microphone may be picking up so that even if you're in a really noisy environment outdoors or, say, in an airport, the people that you're speaking with are going to hear you and only you. And it's pretty amazing as well. So those are some of the things that are happening today and are available today.&lt;/p&gt;  &lt;p&gt;Another thing that's emerged from all of this is we've been talking about how important audio quality is to the people participating in a discussion, the people speaking, the people listening, how everyone is perceived, but a new consumer, if you will, of audio in a discussion or a meeting has emerged, and that is in the form of the AI agent that can summarize meetings and create action plans, do those sorts of things. But for it to work, a clean transcription of what was said is already table stakes. It can't garbled. It can't miss key things. It needs to get it word for word, sentence for sentence throughout the entire meeting. And the ability to attribute who said what to the meeting participants, even if they're all in the same room, is quickly upon us. And the ability to detect and integrate sentiment and emotion of the participants is going to become very important as well for us to really get the full value out of those kinds of AI agents.&lt;/p&gt;  &lt;p&gt;So audio quality is as important as ever for humans, as Brian notes, in some ways more important because this is now the normal way that we talk and meet, but it's also critical for AI agents to work properly. And it's different, right? It's a different set of considerations. And there's a lot of emerging thought and work that's going into that as well. And boy, Megan, there's so much more we could say about this beyond meetings and video conferences. AI tools to simplify the production process. And of course, there's generative AI of music content. I know that's beyond the scope of what we're talking about. But it's really pretty incredible when you look around at the work that's happening and the capabilities that are emerging.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Absolutely. Sounds like there are so many elements to consider and work going on. It's all fascinating. Brian, what kinds of emerging capabilities and use cases around AI and audio quality are you seeing in your lab as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Yeah. Well, I'm sorry that Brian himself was not able to be here today, but I'm an AI agent.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;You got me for a second there.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;Just kidding. The fascinating thing that we're seeing from the lab, from the study of people's impressions is that all of this technology that Erik has described, when it works best, it's completely invisible. Erik, I loved your point about not hearing potato chips being eaten or rain in the background or something like that. You're totally right. I used to notice that all the time. I don't think I've noticed that recently, but I also didn't notice that I haven't noticed that recently, right? It just kind of disappears. The interesting thing about these perceptual impressions, we're constantly drawing intuitive conclusions about people based on how they sound. And that might be a good thing or a bad thing when we're judging things like trustworthiness, for example, on the basis of a short audio clip.&lt;/p&gt;  &lt;p&gt;But clearly, some of these things are valid, right? We can judge the size of someone or even of an animal based on how they sound, right? A chihuahua can't make the sound of a lion. A lion can't make the sound of a chihuahua. And that's always been true because we're producing audio signals that go right into each other's ears. And now, of course, everything that Erik is talking about, that's not true. It goes through all of these different layers of technology increasingly fueled by AI. But when that technology works the best way, it's as if it isn't there at all and we're just hearing each other directly.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; That's the goal, right? That it's seamless open communication and we don't have to think about the technology anymore.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;It's a tough business to be in, I think, though, Erik, because people have to know what's going on behind the surface in order to value it. Otherwise, we just expect it to work.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Well, that's why we try to put the logo of our products on the side of them so they show up in the videos. But yeah, it's a good point.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Very good. Very good.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;And we've talked about virtual meetings and conversations quite a bit, but there's also streamed and recorded content, which are increasingly important at work as well. I wondered, Erik, if you could talk a bit about how businesses are leveraging audio in new ways for things like marketing campaigns and internal upskilling and training and areas like that?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik:&lt;/em&gt; Yeah. Well, one of the things I think we've all seen in marketing is that not everything is a high production value commercial anymore. And there's still a place for that, for sure. But people tend to trust influencers that they follow. People search on TikTok, on YouTube for topics. Those can be the place that they start. And as technology's gotten more accessible, not just audio, but of course, the video technology too, content creators can produce satisfying content on their own or with just a couple of people with them. And Brian's study shows that it doesn't really matter what the origins of the content are for it to be compelling.&lt;/p&gt;  &lt;p&gt;For the person delivering the message to be compelling, the audio quality does have to hit a certain level. But because the tools are simpler to use and you need less things to connect and pull together a decent production system, creator-driven content is becoming even more and more integral to a marketing campaign. And so not just what they maybe post on their Instagram page or post on LinkedIn, for example, but us as a brand being able to take that content and use that actually in paid media and things like that is all entirely possible because of the overall quality of the content. So that's something that's been a trend that's been in process really, I would say, maybe since the advent of podcasts. But it's been an evolution. And it's come a long, long way.&lt;/p&gt;  &lt;p&gt;Another thing, and this is really interesting, and this hits home personally, but I remember when I first entered the workforce, and I hope I'm not showing my age too badly here, but I remember the word processing department. And you would write down on a piece of paper, like a memo, and you would give it to the word processing department and somebody would type it up for you. That was a thing. And these days, we're seeing actually more and more video production with audio, of course, transfer to the actual producers of the content.&lt;/p&gt;  &lt;p&gt;In my company, at Shure, we make videos for different purposes to talk about different initiatives or product launches or things that we're doing just for internal use. And right now, everybody, including our CEO, she makes these videos just at her own desk. She has a little software tool and she can show a PowerPoint and herself and speak to things. And with very, very limited amount of editing, you can put that out there. And I've seen friends and colleagues at other companies in very high-level roles just kind of doing their own production. Being able to buy a very high quality microphone with really advanced signal processing built right in, but just plug it in via USB and have it be handled as simply as any consumer device, has made it possible to do really very useful production where you are going to actually sound good and get your message across, but without having to make such a big production out of it, which is kind of cool.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Yeah. Really democratizes access to sort of creating high quality content, doesn't it? And of course, no technology discussion is complete without a mention of return on investment, particularly nowadays. Erik, what are some ways companies can get returns on their audio tech investments as well? Where are the most common places you see cost savings?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Yeah. Well, we collaborated on a study with IDC Research. And they came up with some really interesting findings on this. And one of them was, no surprise, two-thirds or more of companies have taken action on improving their communication and collaboration technology, and even more have additional or initial investments still planned. But the ROI of those initiatives isn't really tied to the initiative itself. It's not like when you come out with a new product, you look at how that product performs, and that's the driver of your ROI. The benefits of smoother collaboration come in the form of shorter meetings, more productive meetings, better decision-making, faster decision-making, stronger teamwork. And so to build an ROI model, what IDC concluded was that you have to build your model to account for those advantages really across the enterprise or across your university, or whatever it may be, and kind of up and down the different set of activities where they're actually going to be utilized.&lt;/p&gt;  &lt;p&gt;So that can be complex. Quantifying things can always be a challenge. But like I said, companies do seem to understand this. And I think that's because, this is just my hunch, but because everybody, including the CEO and the CFO and the whole finance department, uses and benefits from collaboration technology too. Perhaps that's one reason why the value is easier to convey. Even if they have not taken the time to articulate things like we're doing here today, they know when a meeting is good and when it's not good. And maybe that's one of the things that's helping companies to justify these investments. But it's always tricky to do ROI on projects like that. But again, focusing on the broader benefits of collaboration and breaking it down into what it means for specific activities and types of meetings, I think, is the way to go about doing that.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Absolutely. And Brian, what kinds of advancements are you seeing in the lab that perhaps one day might contribute to those cost savings?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; Well, I don't know anything about cost savings, Megan. I'm a college professor. I live a pure life of the mind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Of course.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian: &lt;/em&gt;ROI does not compute for me. No, I would say we are in an extremely exciting frontier right now because of AI and many different technologies. The studies that we talked about earlier, in one sense, they were broad. We explored many different traits from dating to hiring to credibility. And we isolated them in all sorts of ways we didn't talk about. We showed that it wasn't due to overall affect or pessimism or something like that. But in those studies, we really only tested one very particular set of dimensions along which an audio signal can vary, which is some sort of model of clarity. But in reality, the audio signal is so multi-dimensional. And as we're getting more and more tools these days, we can not only change audio along the lines of clarity, as we've been talking about, but we can potentially manipulate it in all sorts of ways.&lt;/p&gt;  &lt;p&gt;We're very interested in pushing these studies forward and in exploring how people's sort of brute impressions that they make are affected by all sorts of things. Meg and Erik, we walk around the world all the time making these judgments about people, right? You meet someone and you're like, "Wow, I could really be friends with them. They seem like a great person." And you know that you're making that judgment, but you have no idea why, right? It just seems kind of intuitive. Well, in an audio signal, when you're talking to someone, you can think of, "What if their signal is more bass heavy? What if it's a little more treble heavy? What if we manipulate it in this way? In that way?"&lt;/p&gt;  &lt;p&gt;When we talked about the faculty meeting that motivated this whole research program, I mentioned that my colleague, who was speaking from his home recording studio, he actually didn't sound clear like in real life. He sounded better than in real life. He sounded like he was all around us. What is the implication of that? I think there's so many different dimensions of an audio signal that we're just being able to readily control and manipulate that it's going to be very exciting to see how all of these sorts of things impact our impressions of each other.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And there may be some overlap with this as well, but I wondered if we could close with a future forward look, Brian. What are you looking forward to in emerging audio technology? What are some exciting opportunities on the horizon, perhaps related to what you were just talking about there?&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Brian:&lt;/em&gt; Well, we're interested in studying this from a scientific perspective. Erik, you talked about how when you started. When I started doing this science, we didn't have a word processing department. We had a stone tablet department. But I hear tell that the current generation, when they send photos back and forth to each other, that they, as a matter, of course, they apply all sorts of filters-&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Erik: &lt;/em&gt;Oh, yes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Brian:&lt;/em&gt; ... to those video signals, those video or just photographic signals. We're all familiar with that. That hasn't quite happened with the audio signals yet, but I think that's coming up as well. You can imagine that you record yourself saying a little message and then you filter it this way or that way. And that's going to become the Wild West about the kinds of impressions we make on each other, especially if and when you don't know that those filters have been operating in the first place.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan: &lt;/em&gt;That's so interesting. Erik, what are you looking forward to in audio technology as well?&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik:&lt;/em&gt; Well, I'm still thinking about what Brian said.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. That's-&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik: &lt;/em&gt;That's very interesting.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;p&gt;&lt;br /&gt;&lt;em&gt;Megan:&lt;/em&gt; It's terrifying.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Erik:&lt;/em&gt; I have to go back again. I'll go back to the past, maybe 15 to 20 years. And I remember at work, we had meeting rooms with the Starfish phones in the middle of the table. And I remember that we would have international meetings with our partners there that were selling our products in different countries, including in Japan and in China, and the people actually in our own company in those countries. We knew the time zone was bad. And we knew that English wasn't their native language, and tried to be as courteous as possible with written materials and things like that. But I went over to China, and I had to actually be on the other end of one of those calls. And I'm a native English speaker, or at least a native Chicago dialect of American English speaker. And really understanding how challenging it was for them to participate in those meetings just hit me right between the eyes.&lt;/p&gt;  &lt;p&gt;We've come so far, which is wonderful. But I think of a scenario, and this is not far off, there are many companies working on this right now, where not only can you get a real time captioning in your native language, no matter what the language of the participant, you can actually hear the person who's speaking's voice manipulated into your native language.&lt;/p&gt;  &lt;p&gt;I'm never going to be a fluent Japanese or Chinese speaker, that's for sure. But I love the thought that I could actually talk with people and they could understand me as though I were speaking their native language, and that they could communicate to me and I could understand them in the way that they want to be understood. I think there's a future out there where this technology can really be something that helps bring people together. Now that we have so many years of history with the internet, we know there's usually two sides to the coin of technology, but there's definitely going to be a positive side to this, and I'm really looking forward to it.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan: &lt;/em&gt;Gosh, that sounds absolutely fascinating. Thank you both so much for such an interesting discussion.&lt;/p&gt;  &lt;p&gt;That was Erik Vaveris, the VP of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception &amp;amp; Cognition Laboratory at Yale University, whom I spoke with from Brighton in England.&lt;/p&gt;&lt;p&gt;That's it for this episode of Business Lab. I'm your host, Megan Tatum. I'm a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology. And you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.&lt;/p&gt;&lt;p&gt;This show is available wherever you get your podcasts. If you enjoyed this episode, we hope you'll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. And this episode was produced by Giro Studios. Thanks for listening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/26/1124655/the-power-of-sound-in-a-virtual-world/</guid><pubDate>Mon, 26 Jan 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Nvidia‚Äôs new AI weather models probably saw this storm coming weeks ago (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/nvidias-new-ai-weather-models-probably-saw-this-storm-coming-weeks-ago/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/11/GettyImages-969384810.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In the run-up to the winter storm currently pummeling much of the U.S., weather forecasts for some regions were all over the map, with snowfall predictions varying wildly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia couldn‚Äôt have timed the release of its new Earth-2 weather forecasting models any better. Or, given how accurate the company claims the new models are, maybe it knew something we didn‚Äôt?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new AI models promise to make weather forecasting faster and more accurate. Nvidia claims that one model in particular, Earth-2 Medium Range, beats Google DeepMind‚Äôs AI weather model, GenCast, on more than 70 variables. GenCast, which Google released in December 2024, was itself significantly more accurate than existing weather models that were capable of generating forecasts up to 15 days out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia announced the new tools Monday at the American Meteorological Society meeting in Houston.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPhilosophically, scientifically, it‚Äôs a return to simplicity,‚Äù Mike Pritchard, director of climate simulation at Nvidia, told reporters on a call before the meeting. ‚ÄúWe‚Äôre moving away from hand-tailored niche AI architectures and leaning into the future of simple, scalable, transformer architectures.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Traditionally, most weather forecasts rely on simulations of physics as observed in the real world. AI models are a relatively recent addition. The Earth-2 Medium Range model is based on a new Nvidia architecture called Atlas, about which the company said it would release more details on Monday.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Medium Range, Nvidia‚Äôs Earth-2 suite includes a Nowcasting model and Global Data Assimilation model.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nowcasting produces short-term predictions from zero to six hours into the future, and it‚Äôs aimed at helping meteorologists forecast the impacts of storms and other hazardous weather.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBecause this model is trained directly on globally available geostationary satellite observations, rather than region-specific physics model outputs, Nowcasting‚Äôs approach can be adapted anywhere on the planet with good satellite coverage,‚Äù Pritchard said. That should help governments of states and smaller countries understand how severe weather systems might affect their territories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Global Data Assimilation model uses data from sources like weather stations and balloons to produce continuous snapshots of weather conditions at thousands of locations around the world. Those snapshots are then used as launching points for weather models to make their predictions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Traditionally, those snapshots have required tremendous amounts of computing power before the forecasting work could begin. ‚ÄúIt consumes roughly 50% of the total supercomputing loads of traditional weather [forecasting],‚Äù Pritchard said. ‚ÄúThis model can do that in minutes on GPUs instead of hours on supercomputers.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three new models join two existing ones: CorrDiff, which uses coarse-grained forecasts to generate speedy, high-resolution predictions, and FourCastNet 3, which models individual weather variables like temperature, wind, and humidity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pritchard said that the new models should give more users access to powerful weather forecasting tools, which have historically been the domain of wealthier countries and large corporations, which have the funds to pay for costly supercomputer time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis provides the fundamental building blocks used by everyone in the ecosystem ‚Äî national meteorological services, financial service firms, energy companies ‚Äî anyone who wants to build and refine weather forecasting models,‚Äù Pritchard said. Some of the tools are already in use. Meteorologists in Israel and Taiwan have been using Earth-2 CorrDiff, for example, while The Weather Company and Total Energies are evaluating Nowcasting, Nvidia said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúFor some users, it makes sense to subscribe to an enterprise centralized weather forecasting system. But for others like countries, sovereignty matters,‚Äù Pritchard said. ‚ÄúWeather is a national security issue, and sovereignty and weather are inseparable.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/11/GettyImages-969384810.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In the run-up to the winter storm currently pummeling much of the U.S., weather forecasts for some regions were all over the map, with snowfall predictions varying wildly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia couldn‚Äôt have timed the release of its new Earth-2 weather forecasting models any better. Or, given how accurate the company claims the new models are, maybe it knew something we didn‚Äôt?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new AI models promise to make weather forecasting faster and more accurate. Nvidia claims that one model in particular, Earth-2 Medium Range, beats Google DeepMind‚Äôs AI weather model, GenCast, on more than 70 variables. GenCast, which Google released in December 2024, was itself significantly more accurate than existing weather models that were capable of generating forecasts up to 15 days out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia announced the new tools Monday at the American Meteorological Society meeting in Houston.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPhilosophically, scientifically, it‚Äôs a return to simplicity,‚Äù Mike Pritchard, director of climate simulation at Nvidia, told reporters on a call before the meeting. ‚ÄúWe‚Äôre moving away from hand-tailored niche AI architectures and leaning into the future of simple, scalable, transformer architectures.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Traditionally, most weather forecasts rely on simulations of physics as observed in the real world. AI models are a relatively recent addition. The Earth-2 Medium Range model is based on a new Nvidia architecture called Atlas, about which the company said it would release more details on Monday.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Medium Range, Nvidia‚Äôs Earth-2 suite includes a Nowcasting model and Global Data Assimilation model.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nowcasting produces short-term predictions from zero to six hours into the future, and it‚Äôs aimed at helping meteorologists forecast the impacts of storms and other hazardous weather.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBecause this model is trained directly on globally available geostationary satellite observations, rather than region-specific physics model outputs, Nowcasting‚Äôs approach can be adapted anywhere on the planet with good satellite coverage,‚Äù Pritchard said. That should help governments of states and smaller countries understand how severe weather systems might affect their territories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Global Data Assimilation model uses data from sources like weather stations and balloons to produce continuous snapshots of weather conditions at thousands of locations around the world. Those snapshots are then used as launching points for weather models to make their predictions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Traditionally, those snapshots have required tremendous amounts of computing power before the forecasting work could begin. ‚ÄúIt consumes roughly 50% of the total supercomputing loads of traditional weather [forecasting],‚Äù Pritchard said. ‚ÄúThis model can do that in minutes on GPUs instead of hours on supercomputers.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three new models join two existing ones: CorrDiff, which uses coarse-grained forecasts to generate speedy, high-resolution predictions, and FourCastNet 3, which models individual weather variables like temperature, wind, and humidity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pritchard said that the new models should give more users access to powerful weather forecasting tools, which have historically been the domain of wealthier countries and large corporations, which have the funds to pay for costly supercomputer time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis provides the fundamental building blocks used by everyone in the ecosystem ‚Äî national meteorological services, financial service firms, energy companies ‚Äî anyone who wants to build and refine weather forecasting models,‚Äù Pritchard said. Some of the tools are already in use. Meteorologists in Israel and Taiwan have been using Earth-2 CorrDiff, for example, while The Weather Company and Total Energies are evaluating Nowcasting, Nvidia said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúFor some users, it makes sense to subscribe to an enterprise centralized weather forecasting system. But for others like countries, sovereignty matters,‚Äù Pritchard said. ‚ÄúWeather is a national security issue, and sovereignty and weather are inseparable.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/nvidias-new-ai-weather-models-probably-saw-this-storm-coming-weeks-ago/</guid><pubDate>Mon, 26 Jan 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] NVIDIA Launches Earth-2 Family of Open Models ‚Äî the World‚Äôs First Fully Open, Accelerated Set of Models and Tools for AI Weather (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-earth-2-open-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/hpc-corp-blog-earth-2-model-1920x1080-1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Accurate weather forecasting helps save lives and protect environments ‚Äî and is a cornerstone of decision-making in agriculture, energy, public health and other industries.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Researchers, weather agencies, climate-tech innovators and enterprises are already running, fine-tuning and building on these state-of-the-art models to unlock scientific breakthroughs using their own local AI infrastructure.&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Weather Forecasting&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;AI weather tool provider &lt;b&gt;Brightband&lt;/b&gt; ‚Äî a member of the NVIDIA Inception program‚Äôs Sustainable Futures initiative ‚Äî is running Earth-2 Medium Range to issue real-world global forecasts daily.&amp;nbsp;&lt;/p&gt;&lt;p&gt;‚ÄúThe revolution of new AI weather tools for forecasting is very exciting and continues to gather speed with new models like NVIDIA Earth-2 Medium Range,‚Äù said Julian Green, cofounder and CEO of Brightband. ‚ÄúBrightband is among the first to run Earth-2 Medium Range operationally, and the model being open source speeds up innovation, allowing easier comparison and improvements by other members of the weather enterprise.‚Äù&lt;/p&gt;&lt;p&gt;The &lt;b&gt;Israel Meteorological Service&lt;/b&gt; is using Earth-2 CorrDiff in operation ‚Äî and plans to use Earth-2 Nowcasting ‚Äî to generate high-resolution forecasts up to eight times daily, enabling decision-makers to respond more effectively to extreme weather while reducing computational costs.&lt;/p&gt;&lt;p&gt;‚ÄúNVIDIA Earth-2 models give us a 90% reduction in compute time at 2.5-kilometer resolution compared with running a classic numerical weather prediction model without AI on a CPU cluster,‚Äù said Amir Givati, director of the Israel Meteorological Service. ‚ÄúAfter a recent rainstorm, our AI model trained with CorrDiff was the best of all our operational models for a six-hour verification of accumulated precipitation.‚Äù&lt;/p&gt;&lt;p&gt;&lt;b&gt;The Weather Company&lt;/b&gt; is evaluating Earth-2 Nowcasting for localized severe-weather applications, and &lt;b&gt;NWS&lt;/b&gt; is evaluating the new models to enhance its operational workflows.&amp;nbsp;&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Energy Forecasting and Grid Operations&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;TotalEnergies&lt;/b&gt; is evaluating Earth-2 Nowcasting to improve short-term risk awareness and decision-making.&lt;/p&gt;&lt;p&gt;‚ÄúNVIDIA Earth-2 represents a major step forward in how advanced weather intelligence can be operationalized at scale,‚Äù said Emmanuel Le Borgne, climate and weather forecast product manager at TotalEnergies. ‚ÄúModels like Earth-2 Nowcasting are groundbreaking for our business because they improve short-term risk awareness and decision-making in energy systems where minutes and local impacts matter.‚Äù&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eni&lt;/b&gt; is intensively testing Earth-2 models, including FourCastNet and CorrDiff, for semi-operational downscaling of predictions to produce probabilistic, high-resolution forecasts of weather and gas demand weeks ahead.&lt;/p&gt;&lt;p&gt;&lt;b&gt;GCL&lt;/b&gt;, one of China‚Äôs largest solar material producers and a global integrated energy operator, is running NVIDIA Earth-2 models in operation for its photovoltaic prediction system. Compared with traditional numerical weather prediction, Earth-2 provides more accurate prediction data at a lower cost, significantly improving the accuracy of GCL‚Äôs photovoltaic power generation prediction.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Southwest Power Pool&lt;/b&gt;, in collaboration with &lt;b&gt;Hitachi&lt;/b&gt;, is using Earth-2 Nowcasting and FourCastNet3 to improve intraday and day-ahead wind forecasting. This effort supports Southwest Power Pool‚Äôs commitment to enhancing grid reliability and enabling more informed operational decisions across the SPP footprint.&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Financial Impact Assessment&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;S&amp;amp;P Global Energy&lt;/b&gt; is harnessing NVIDIA Earth-2 CorrDiff to turn climate data into local insights for risk assessment. Global insurance group &lt;b&gt;AXA&lt;/b&gt; is using FourCastNet to generate thousands of hypothetical hurricane scenarios as part of its R&amp;amp;D program in model evaluation, methodological development and benchmarking on existing techniques.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/hpc-corp-blog-earth-2-model-1920x1080-1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Accurate weather forecasting helps save lives and protect environments ‚Äî and is a cornerstone of decision-making in agriculture, energy, public health and other industries.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Researchers, weather agencies, climate-tech innovators and enterprises are already running, fine-tuning and building on these state-of-the-art models to unlock scientific breakthroughs using their own local AI infrastructure.&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Weather Forecasting&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;AI weather tool provider &lt;b&gt;Brightband&lt;/b&gt; ‚Äî a member of the NVIDIA Inception program‚Äôs Sustainable Futures initiative ‚Äî is running Earth-2 Medium Range to issue real-world global forecasts daily.&amp;nbsp;&lt;/p&gt;&lt;p&gt;‚ÄúThe revolution of new AI weather tools for forecasting is very exciting and continues to gather speed with new models like NVIDIA Earth-2 Medium Range,‚Äù said Julian Green, cofounder and CEO of Brightband. ‚ÄúBrightband is among the first to run Earth-2 Medium Range operationally, and the model being open source speeds up innovation, allowing easier comparison and improvements by other members of the weather enterprise.‚Äù&lt;/p&gt;&lt;p&gt;The &lt;b&gt;Israel Meteorological Service&lt;/b&gt; is using Earth-2 CorrDiff in operation ‚Äî and plans to use Earth-2 Nowcasting ‚Äî to generate high-resolution forecasts up to eight times daily, enabling decision-makers to respond more effectively to extreme weather while reducing computational costs.&lt;/p&gt;&lt;p&gt;‚ÄúNVIDIA Earth-2 models give us a 90% reduction in compute time at 2.5-kilometer resolution compared with running a classic numerical weather prediction model without AI on a CPU cluster,‚Äù said Amir Givati, director of the Israel Meteorological Service. ‚ÄúAfter a recent rainstorm, our AI model trained with CorrDiff was the best of all our operational models for a six-hour verification of accumulated precipitation.‚Äù&lt;/p&gt;&lt;p&gt;&lt;b&gt;The Weather Company&lt;/b&gt; is evaluating Earth-2 Nowcasting for localized severe-weather applications, and &lt;b&gt;NWS&lt;/b&gt; is evaluating the new models to enhance its operational workflows.&amp;nbsp;&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Energy Forecasting and Grid Operations&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;TotalEnergies&lt;/b&gt; is evaluating Earth-2 Nowcasting to improve short-term risk awareness and decision-making.&lt;/p&gt;&lt;p&gt;‚ÄúNVIDIA Earth-2 represents a major step forward in how advanced weather intelligence can be operationalized at scale,‚Äù said Emmanuel Le Borgne, climate and weather forecast product manager at TotalEnergies. ‚ÄúModels like Earth-2 Nowcasting are groundbreaking for our business because they improve short-term risk awareness and decision-making in energy systems where minutes and local impacts matter.‚Äù&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eni&lt;/b&gt; is intensively testing Earth-2 models, including FourCastNet and CorrDiff, for semi-operational downscaling of predictions to produce probabilistic, high-resolution forecasts of weather and gas demand weeks ahead.&lt;/p&gt;&lt;p&gt;&lt;b&gt;GCL&lt;/b&gt;, one of China‚Äôs largest solar material producers and a global integrated energy operator, is running NVIDIA Earth-2 models in operation for its photovoltaic prediction system. Compared with traditional numerical weather prediction, Earth-2 provides more accurate prediction data at a lower cost, significantly improving the accuracy of GCL‚Äôs photovoltaic power generation prediction.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Southwest Power Pool&lt;/b&gt;, in collaboration with &lt;b&gt;Hitachi&lt;/b&gt;, is using Earth-2 Nowcasting and FourCastNet3 to improve intraday and day-ahead wind forecasting. This effort supports Southwest Power Pool‚Äôs commitment to enhancing grid reliability and enabling more informed operational decisions across the SPP footprint.&lt;/p&gt;&lt;h3&gt;&lt;em&gt;&lt;b&gt;Financial Impact Assessment&lt;/b&gt;&lt;/em&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;S&amp;amp;P Global Energy&lt;/b&gt; is harnessing NVIDIA Earth-2 CorrDiff to turn climate data into local insights for risk assessment. Global insurance group &lt;b&gt;AXA&lt;/b&gt; is using FourCastNet to generate thousands of hypothetical hurricane scenarios as part of its R&amp;amp;D program in model evaluation, methodological development and benchmarking on existing techniques.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-earth-2-open-models/</guid><pubDate>Mon, 26 Jan 2026 14:00:53 +0000</pubDate></item><item><title>[NEW] EU launches formal investigation of xAI over Grok's sexualized deepfakes (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/eu-launches-formal-investigation-of-xai-over-groks-sexualized-deepfakes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Elon Musk‚Äôs company faces fines of up to 6 percent of its daily turnover.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo illustration in which the logo of Grok 4 is displayed on a smartphone screen with the xAI logo in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-640x426.jpg" width="640" /&gt;
                  &lt;img alt="Photo illustration in which the logo of Grok 4 is displayed on a smartphone screen with the xAI logo in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | VCG 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The EU has launched a formal investigation into Elon Musk‚Äôs xAI following a public outcry over how its Grok chatbot spread sexualized images of women and children.&lt;/p&gt;
&lt;p&gt;The billionaire entrepreneur has come under scrutiny from regulators around the world this month after people began using Grok to generate deepfakes of people without consent. The images were posted on the X social network as well as the separate Grok app, both of which are run by xAI.&lt;/p&gt;
&lt;p&gt;The probe, announced on Monday under the EU‚Äôs Digital Services Act, will assess if xAI tried to mitigate the risks of deploying Grok‚Äôs tools on X and the proliferation of content that ‚Äúmay amount to child sexual abuse material.‚Äù&lt;/p&gt;
&lt;p&gt;‚ÄúNon-consensual sexual deepfakes of women and children are a violent, unacceptable form of degradation,‚Äù the EU‚Äôs tech chief, Henna Virkkunen, said.&lt;/p&gt;
&lt;p&gt;‚ÄúWith this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens‚Äîincluding those of women and children‚Äîas collateral damage of its service.‚Äù&lt;/p&gt;
&lt;p&gt;If the company is found to be in breach of the rules, the bloc can impose fines worth up to 6 percent of the worldwide annual turnover. An EU official said there will be no interim measures during the investigation.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The European probe comes after UK media regulator Ofcom opened a formal investigation into Grok, while Malaysia and Indonesia have banned the chatbot altogether.&lt;/p&gt;
&lt;p&gt;Following the backlash, xAI restricted the use of Grok to paying subscribers and said it has ‚Äúimplemented technological measures‚Äù to limit Grok from generating certain sexualized images.&lt;/p&gt;
&lt;p&gt;Musk has also said ‚Äúanyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.‚Äù&lt;/p&gt;
&lt;p&gt;An EU official said that ‚Äúwith the harm that is exposed to individuals that are subject to these images, we have not been convinced so far by what mitigating measures the platform has taken to have that under control.‚Äù&lt;/p&gt;
&lt;p&gt;The company, which acquired Musk‚Äôs social media site X last year, has designed its AI products to have fewer content ‚Äúguardrails‚Äù than competitors such as OpenAI and Google. Musk called its Grok model ‚Äúmaximally truth-seeking.‚Äù&lt;/p&gt;
&lt;p&gt;The commission fined X ‚Ç¨120 million in December last year for breaching its regulations for transparency, providing insufficient access to data and the deceptive design of its blue ticks for verified accounts.&lt;/p&gt;
&lt;p&gt;The fine was criticized by Musk and the US government, with the Trump administration claiming the EU was unfairly targeting American groups and infringing freedom of speech principles championed by the Maga movement.&lt;/p&gt;
&lt;p&gt;X did not immediately reply to a request for comment.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;¬© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Elon Musk‚Äôs company faces fines of up to 6 percent of its daily turnover.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo illustration in which the logo of Grok 4 is displayed on a smartphone screen with the xAI logo in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-640x426.jpg" width="640" /&gt;
                  &lt;img alt="Photo illustration in which the logo of Grok 4 is displayed on a smartphone screen with the xAI logo in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | VCG 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The EU has launched a formal investigation into Elon Musk‚Äôs xAI following a public outcry over how its Grok chatbot spread sexualized images of women and children.&lt;/p&gt;
&lt;p&gt;The billionaire entrepreneur has come under scrutiny from regulators around the world this month after people began using Grok to generate deepfakes of people without consent. The images were posted on the X social network as well as the separate Grok app, both of which are run by xAI.&lt;/p&gt;
&lt;p&gt;The probe, announced on Monday under the EU‚Äôs Digital Services Act, will assess if xAI tried to mitigate the risks of deploying Grok‚Äôs tools on X and the proliferation of content that ‚Äúmay amount to child sexual abuse material.‚Äù&lt;/p&gt;
&lt;p&gt;‚ÄúNon-consensual sexual deepfakes of women and children are a violent, unacceptable form of degradation,‚Äù the EU‚Äôs tech chief, Henna Virkkunen, said.&lt;/p&gt;
&lt;p&gt;‚ÄúWith this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens‚Äîincluding those of women and children‚Äîas collateral damage of its service.‚Äù&lt;/p&gt;
&lt;p&gt;If the company is found to be in breach of the rules, the bloc can impose fines worth up to 6 percent of the worldwide annual turnover. An EU official said there will be no interim measures during the investigation.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The European probe comes after UK media regulator Ofcom opened a formal investigation into Grok, while Malaysia and Indonesia have banned the chatbot altogether.&lt;/p&gt;
&lt;p&gt;Following the backlash, xAI restricted the use of Grok to paying subscribers and said it has ‚Äúimplemented technological measures‚Äù to limit Grok from generating certain sexualized images.&lt;/p&gt;
&lt;p&gt;Musk has also said ‚Äúanyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.‚Äù&lt;/p&gt;
&lt;p&gt;An EU official said that ‚Äúwith the harm that is exposed to individuals that are subject to these images, we have not been convinced so far by what mitigating measures the platform has taken to have that under control.‚Äù&lt;/p&gt;
&lt;p&gt;The company, which acquired Musk‚Äôs social media site X last year, has designed its AI products to have fewer content ‚Äúguardrails‚Äù than competitors such as OpenAI and Google. Musk called its Grok model ‚Äúmaximally truth-seeking.‚Äù&lt;/p&gt;
&lt;p&gt;The commission fined X ‚Ç¨120 million in December last year for breaching its regulations for transparency, providing insufficient access to data and the deceptive design of its blue ticks for verified accounts.&lt;/p&gt;
&lt;p&gt;The fine was criticized by Musk and the US government, with the Trump administration claiming the EU was unfairly targeting American groups and infringing freedom of speech principles championed by the Maga movement.&lt;/p&gt;
&lt;p&gt;X did not immediately reply to a request for comment.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;¬© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/eu-launches-formal-investigation-of-xai-over-groks-sexualized-deepfakes/</guid><pubDate>Mon, 26 Jan 2026 14:17:46 +0000</pubDate></item><item><title>[NEW] How Formula E uses Google Cloud AI to meet net zero targets (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-formula-e-uses-google-cloud-ai-to-meet-net-zero-targets/</link><description>&lt;p&gt;Formula E is using Google Cloud AI to meet its net zero targets by driving efficiency across its global logistics and commercial operations. As part of an expanded multi-year agreement, the electric racing series will integrate Gemini models into its ecosystem to support performance analysis, back-office workflows, and event logistics.&lt;/p&gt;&lt;p&gt;The collaboration demonstrates how sports organisations are utilising cloud infrastructure to drive tangible business outcomes, rather than just securing surface-level sponsorship. The partnership focuses on optimising business operations, ranging from race management to the fan experience.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-operational-twins-and-carbon-data-to-achieve-net-zero-targets"&gt;Operational twins and carbon data to achieve net zero targets&lt;/h3&gt;&lt;p&gt;While marketing visibility often drives sports partnerships, this agreement builds on a technical foundation first formalised in January 2025. The elevation to ‚ÄúPrincipal Partner‚Äù involves Formula E adopting Google Cloud technologies for business-critical functions.&lt;/p&gt;&lt;p&gt;The immediate application involves optimising the complex logistics of a global championship. Advanced AI modelling of the back office and the creation of race and event digital twins allow the organisation to simulate and optimise site builds virtually.&lt;/p&gt;&lt;p&gt;This application directly affects Scope 3 emissions. The capability to plan infrastructure virtually minimises the need for physical on-site reconnaissance and reduces the transport of heavy equipment.&lt;/p&gt;&lt;p&gt;For a championship that is the only sport-certified net zero carbon entity since inception, maintaining this status requires finding efficiencies in the supply chain. The digital twin approach delivers a quantifiable reduction in the operational carbon footprint while maintaining performance.&lt;/p&gt;&lt;p&gt;Beyond logistical modelling, the Google Cloud AI partnership extends into the workforce productivity layer. Formula E is deploying Google Workspace with Gemini AI to enable greater agility and efficiency across its organisation.&lt;/p&gt;&lt;p&gt;The organisation intends to use these tools to accelerate performance and deliver faster operations. This reflects a broader trend where generative AI tools are provisioned to reduce administrative latency in distributed workforces.&lt;/p&gt;&lt;p&gt;The viability of these implementations to achieve net zero targets is supported by previous collaborative projects. Formula E recently utilised Google‚Äôs AI Studio and Gemini models to execute the ‚ÄòMountain Recharge‚Äô initiative.&lt;/p&gt;&lt;p&gt;Engineers used the models to map an optimal route for the GENBETA car during a mountain descent. The AI identified and analysed specific braking zones, calculating the necessary regenerative braking required to harvest enough energy to complete a full lap of the Monaco circuit subsequently.&lt;/p&gt;&lt;p&gt;This specific use case demonstrates how high-dimensional data ‚Äì including topography, friction, and energy consumption ‚Äì can be processed to define physical execution.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-google-cloud-ai-to-enhance-formula-e-s-data-product"&gt;Using Google Cloud AI to enhance Formula E‚Äôs data product&lt;/h3&gt;&lt;p&gt;The partnership also addresses the commercial requirement to retain and grow a digital audience. Formula E has integrated a ‚ÄòStrategy Agent‚Äô into its live broadcasts. This tool processes real-time data to provide viewers with tailored insights and predictions regarding race strategy and driver performance.&lt;/p&gt;&lt;p&gt;Millions of viewers have utilised these insights, which explain complex race dynamics as they unfold. This mirrors the enterprise challenge of observability (i.e. taking vast streams of real-time technical data and synthesising them into understandable narratives for stakeholders.)&lt;/p&gt;&lt;p&gt;Beyond helping to achieve net zero targets, the leadership at both organisations frames this expansion as a necessary evolution of their technical stack.&lt;/p&gt;&lt;p&gt;Jeff Dodds, CEO of Formula E, said: ‚ÄúOur expanded partnership with Google Cloud is a true game-changer for Formula E and for motorsport as a whole. We are already pushing the boundaries of technology in sport, and this Principal Partnership confirms our vision.&lt;/p&gt;&lt;p&gt;‚ÄúThe integration of Google Cloud‚Äôs AI capabilities will unlock a new dimension of real-time performance optimisation and strategic decision-making, both for the Championship and for our global broadcast audience. This collaboration will redefine how fans experience our races and set a new benchmark for technology integration in sport worldwide.‚Äù&lt;/p&gt;&lt;p&gt;Tara Brady, President of Google Cloud EMEA, added: ‚ÄúFormula E is a hub of innovation, where milliseconds can define success. This expanded partnership is a testament to the power of Google Cloud‚Äôs AI and data analytics, showing how our technology can deliver a competitive advantage in the most demanding scenarios.‚Äù&lt;/p&gt;&lt;p&gt;The progression from the initial partnership in January 2025 to this expanded scope suggests the pilot programs provided sufficient ROI to warrant a broader rollout. As organisations face pressure to balance performance with net zero targets, the use of virtual simulation to optimise physical deployment remains a high-value area for investment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Controlling AI agent sprawl: The CIO‚Äôs guide to governance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Formula E is using Google Cloud AI to meet its net zero targets by driving efficiency across its global logistics and commercial operations. As part of an expanded multi-year agreement, the electric racing series will integrate Gemini models into its ecosystem to support performance analysis, back-office workflows, and event logistics.&lt;/p&gt;&lt;p&gt;The collaboration demonstrates how sports organisations are utilising cloud infrastructure to drive tangible business outcomes, rather than just securing surface-level sponsorship. The partnership focuses on optimising business operations, ranging from race management to the fan experience.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-operational-twins-and-carbon-data-to-achieve-net-zero-targets"&gt;Operational twins and carbon data to achieve net zero targets&lt;/h3&gt;&lt;p&gt;While marketing visibility often drives sports partnerships, this agreement builds on a technical foundation first formalised in January 2025. The elevation to ‚ÄúPrincipal Partner‚Äù involves Formula E adopting Google Cloud technologies for business-critical functions.&lt;/p&gt;&lt;p&gt;The immediate application involves optimising the complex logistics of a global championship. Advanced AI modelling of the back office and the creation of race and event digital twins allow the organisation to simulate and optimise site builds virtually.&lt;/p&gt;&lt;p&gt;This application directly affects Scope 3 emissions. The capability to plan infrastructure virtually minimises the need for physical on-site reconnaissance and reduces the transport of heavy equipment.&lt;/p&gt;&lt;p&gt;For a championship that is the only sport-certified net zero carbon entity since inception, maintaining this status requires finding efficiencies in the supply chain. The digital twin approach delivers a quantifiable reduction in the operational carbon footprint while maintaining performance.&lt;/p&gt;&lt;p&gt;Beyond logistical modelling, the Google Cloud AI partnership extends into the workforce productivity layer. Formula E is deploying Google Workspace with Gemini AI to enable greater agility and efficiency across its organisation.&lt;/p&gt;&lt;p&gt;The organisation intends to use these tools to accelerate performance and deliver faster operations. This reflects a broader trend where generative AI tools are provisioned to reduce administrative latency in distributed workforces.&lt;/p&gt;&lt;p&gt;The viability of these implementations to achieve net zero targets is supported by previous collaborative projects. Formula E recently utilised Google‚Äôs AI Studio and Gemini models to execute the ‚ÄòMountain Recharge‚Äô initiative.&lt;/p&gt;&lt;p&gt;Engineers used the models to map an optimal route for the GENBETA car during a mountain descent. The AI identified and analysed specific braking zones, calculating the necessary regenerative braking required to harvest enough energy to complete a full lap of the Monaco circuit subsequently.&lt;/p&gt;&lt;p&gt;This specific use case demonstrates how high-dimensional data ‚Äì including topography, friction, and energy consumption ‚Äì can be processed to define physical execution.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-google-cloud-ai-to-enhance-formula-e-s-data-product"&gt;Using Google Cloud AI to enhance Formula E‚Äôs data product&lt;/h3&gt;&lt;p&gt;The partnership also addresses the commercial requirement to retain and grow a digital audience. Formula E has integrated a ‚ÄòStrategy Agent‚Äô into its live broadcasts. This tool processes real-time data to provide viewers with tailored insights and predictions regarding race strategy and driver performance.&lt;/p&gt;&lt;p&gt;Millions of viewers have utilised these insights, which explain complex race dynamics as they unfold. This mirrors the enterprise challenge of observability (i.e. taking vast streams of real-time technical data and synthesising them into understandable narratives for stakeholders.)&lt;/p&gt;&lt;p&gt;Beyond helping to achieve net zero targets, the leadership at both organisations frames this expansion as a necessary evolution of their technical stack.&lt;/p&gt;&lt;p&gt;Jeff Dodds, CEO of Formula E, said: ‚ÄúOur expanded partnership with Google Cloud is a true game-changer for Formula E and for motorsport as a whole. We are already pushing the boundaries of technology in sport, and this Principal Partnership confirms our vision.&lt;/p&gt;&lt;p&gt;‚ÄúThe integration of Google Cloud‚Äôs AI capabilities will unlock a new dimension of real-time performance optimisation and strategic decision-making, both for the Championship and for our global broadcast audience. This collaboration will redefine how fans experience our races and set a new benchmark for technology integration in sport worldwide.‚Äù&lt;/p&gt;&lt;p&gt;Tara Brady, President of Google Cloud EMEA, added: ‚ÄúFormula E is a hub of innovation, where milliseconds can define success. This expanded partnership is a testament to the power of Google Cloud‚Äôs AI and data analytics, showing how our technology can deliver a competitive advantage in the most demanding scenarios.‚Äù&lt;/p&gt;&lt;p&gt;The progression from the initial partnership in January 2025 to this expanded scope suggests the pilot programs provided sufficient ROI to warrant a broader rollout. As organisations face pressure to balance performance with net zero targets, the use of virtual simulation to optimise physical deployment remains a high-value area for investment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Controlling AI agent sprawl: The CIO‚Äôs guide to governance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-formula-e-uses-google-cloud-ai-to-meet-net-zero-targets/</guid><pubDate>Mon, 26 Jan 2026 14:38:53 +0000</pubDate></item><item><title>[NEW] **NVIDIA Earth-2 Open Models Span the Whole Weather Stack** (Hugging Face - Blog)</title><link>https://huggingface.co/blog/nvidia/earth-2-open-models</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-uploads.huggingface.co/production/uploads/69767cbee0e9addbc199b9c5/ulQKMbGq2yyxdMHw51j3W.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
NVIDIA is excited to announce three new open-source models as part of the NVIDIA Earth-2 family, making it easier than ever to build weather forecasting capabilities across the weather stack, including tasks such as data assimilation, forecasting, nowcasting, downscaling and more. In addition, developers can quickly get started building weather and climate simulations by using NVIDIA open source software: Earth2Studio for creating inference pipelines and Physics Nemo for training models.
&lt;p&gt;NVIDIA Earth-2 comprises a set of accelerated tools and models which enables developers to bring together typically disparate weather and climate AI capabilities. Because Earth-2 is completely open, developers can customize and fine-tune their simulations to their specific needs, using their own data and their own infrastructure to build sovereign weather and climate predictions they fully own and control. Earth-2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is a suite of leading open weather and climate models   &lt;/li&gt;
&lt;li&gt;Is easy-to-use thanks to an ecosystem of open source software  &lt;/li&gt;
&lt;li&gt;Enables you to create your own sovereign capabilities&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Nowcasting: Kilometer-Scale Severe Weather Prediction&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Out now on Hugging Face: Earth-2 Nowcasting, powered by a new model architecture called StormScope,  using generative AI to make country-scale forecasts into kilometer‚Äëresolution, zero- to six-hour predictions of local storms and hazardous weather in just minutes. Earth-2 Nowcasting can generate the first predictions that outperform traditional, physics-based weather-prediction models on short-term precipitation forecasting by simulating storm dynamics directly. It harnesses AI to directly predict satellite and radar data.&lt;/p&gt;
&lt;p&gt;This version is trained directly on globally available geostationary satellite observations (GOES) over the contiguous US (CONUS). However, this method could be applied to train versions of the model over other regions with similar satellite coverage.&lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20NowCasting%20StormScope%20Visible%20and%20Radar%20CONUS%201080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: Learning Accurate Storm-Scale Evolution from Observations&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Medium Range: Highly accurate 15-Day Global Forecasts&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Out now on Hugging Face: Earth-2 Medium Range, powered by a new model architecture called Atlas, enabling high-accuracy weather prediction for medium-range forecasts ‚Äî or forecasts of up to 15 days in advance ‚Äî across 70+ weather variables including temperature, pressure, wind and humidity.  It uses a latent diffusion transformer architecture to predict incremental changes in the atmosphere so as to preserve critical atmospheric structures and reduce forecasting errors. On standard benchmarks, it outperforms leading open models such as GenCast on the most common forecasting variables measured by the industry.&lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20Medium%20Range%20Forecast%20Ensembles%201080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: Demystifying Data-Driven Probabilistic Medium-Range
Weather Forecasting&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Global Data Assimilation: An End-to-End AI Pipeline&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Coming soon to Hugging Face: Earth-2 Global Data Assimilation, powered by a new model architecture called HealDA, which produces initial conditions for weather prediction ‚Äî snapshots of the current atmosphere, including the temperature, wind speed, humidity and air pressure, at thousands of locations around the globe. Earth-2 Global Data Assimilation can generate initial conditions in seconds on GPUs instead of hours on supercomputers. When coupled with Earth-2 Medium Range, this results in the most skillful forecasting predictions produced by an open, entirely AI pipeline. &lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20GlobalDataAssimilation_CombinedRotate-1080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: HealDA: Highlighting the Importance of Initial Errors in
End-to-End AI Weather Forecasts&lt;/p&gt;
&lt;p&gt;These models join established open NVIDIA weather and climate models such as FourcastNet3, CorrDiff, cBottle, DLESym and more.&lt;/p&gt;

&lt;p&gt;NVIDIA Earth2Studio is an open-source Python ecosystem for quickly creating powerful AI weather and climate simulations. It provides all the necessary inference tools to get started with the new model checkpoints on Hugging Face. It‚Äôs as easy as:&lt;/p&gt;
&lt;p&gt;Getting Started Video&lt;/p&gt;

&lt;p&gt;Corporate Blog: NVIDIA Launches Earth-2 Family of Open Models ‚Äî the World‚Äôs First Fully Open Set of Models and Tools for AI Weather&lt;/p&gt;
&lt;p&gt;Launch Video: NVIDIA Earth-2: The Future of AI Weather Forecasting is Open&lt;/p&gt;
&lt;p&gt;Web Page: Earth-2&lt;/p&gt;
&lt;p&gt;Hugging Face Package for Earth-2 Nowcasting&lt;/p&gt;
&lt;p&gt;Research Paper: Learning Accurate Storm-Scale Evolution from Observations&lt;/p&gt;
&lt;p&gt;Hugging Face Package for Earth-2 Medium-Range&lt;/p&gt;
&lt;p&gt;Research Paper: Demystifying Data-Driven Probabilistic Medium-Range
Weather Forecasting&lt;/p&gt;
&lt;p&gt;Research Paper: HealDA: Highlighting the Importance of Initial Errors in
End-to-End AI Weather Forecasts&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-uploads.huggingface.co/production/uploads/69767cbee0e9addbc199b9c5/ulQKMbGq2yyxdMHw51j3W.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
NVIDIA is excited to announce three new open-source models as part of the NVIDIA Earth-2 family, making it easier than ever to build weather forecasting capabilities across the weather stack, including tasks such as data assimilation, forecasting, nowcasting, downscaling and more. In addition, developers can quickly get started building weather and climate simulations by using NVIDIA open source software: Earth2Studio for creating inference pipelines and Physics Nemo for training models.
&lt;p&gt;NVIDIA Earth-2 comprises a set of accelerated tools and models which enables developers to bring together typically disparate weather and climate AI capabilities. Because Earth-2 is completely open, developers can customize and fine-tune their simulations to their specific needs, using their own data and their own infrastructure to build sovereign weather and climate predictions they fully own and control. Earth-2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is a suite of leading open weather and climate models   &lt;/li&gt;
&lt;li&gt;Is easy-to-use thanks to an ecosystem of open source software  &lt;/li&gt;
&lt;li&gt;Enables you to create your own sovereign capabilities&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Nowcasting: Kilometer-Scale Severe Weather Prediction&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Out now on Hugging Face: Earth-2 Nowcasting, powered by a new model architecture called StormScope,  using generative AI to make country-scale forecasts into kilometer‚Äëresolution, zero- to six-hour predictions of local storms and hazardous weather in just minutes. Earth-2 Nowcasting can generate the first predictions that outperform traditional, physics-based weather-prediction models on short-term precipitation forecasting by simulating storm dynamics directly. It harnesses AI to directly predict satellite and radar data.&lt;/p&gt;
&lt;p&gt;This version is trained directly on globally available geostationary satellite observations (GOES) over the contiguous US (CONUS). However, this method could be applied to train versions of the model over other regions with similar satellite coverage.&lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20NowCasting%20StormScope%20Visible%20and%20Radar%20CONUS%201080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: Learning Accurate Storm-Scale Evolution from Observations&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Medium Range: Highly accurate 15-Day Global Forecasts&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Out now on Hugging Face: Earth-2 Medium Range, powered by a new model architecture called Atlas, enabling high-accuracy weather prediction for medium-range forecasts ‚Äî or forecasts of up to 15 days in advance ‚Äî across 70+ weather variables including temperature, pressure, wind and humidity.  It uses a latent diffusion transformer architecture to predict incremental changes in the atmosphere so as to preserve critical atmospheric structures and reduce forecasting errors. On standard benchmarks, it outperforms leading open models such as GenCast on the most common forecasting variables measured by the industry.&lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20Medium%20Range%20Forecast%20Ensembles%201080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: Demystifying Data-Driven Probabilistic Medium-Range
Weather Forecasting&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Earth-2 Global Data Assimilation: An End-to-End AI Pipeline&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Coming soon to Hugging Face: Earth-2 Global Data Assimilation, powered by a new model architecture called HealDA, which produces initial conditions for weather prediction ‚Äî snapshots of the current atmosphere, including the temperature, wind speed, humidity and air pressure, at thousands of locations around the globe. Earth-2 Global Data Assimilation can generate initial conditions in seconds on GPUs instead of hours on supercomputers. When coupled with Earth-2 Medium Range, this results in the most skillful forecasting predictions produced by an open, entirely AI pipeline. &lt;/p&gt;
&lt;video controls="controls" loop="loop"&gt;
  &lt;source src="https://huggingface.co/datasets/MikePritchard/Media-Jan2026-Earth2Launch/resolve/main/Earth-2%20GlobalDataAssimilation_CombinedRotate-1080p.mov" type="video/mp4" /&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Research Paper: HealDA: Highlighting the Importance of Initial Errors in
End-to-End AI Weather Forecasts&lt;/p&gt;
&lt;p&gt;These models join established open NVIDIA weather and climate models such as FourcastNet3, CorrDiff, cBottle, DLESym and more.&lt;/p&gt;

&lt;p&gt;NVIDIA Earth2Studio is an open-source Python ecosystem for quickly creating powerful AI weather and climate simulations. It provides all the necessary inference tools to get started with the new model checkpoints on Hugging Face. It‚Äôs as easy as:&lt;/p&gt;
&lt;p&gt;Getting Started Video&lt;/p&gt;

&lt;p&gt;Corporate Blog: NVIDIA Launches Earth-2 Family of Open Models ‚Äî the World‚Äôs First Fully Open Set of Models and Tools for AI Weather&lt;/p&gt;
&lt;p&gt;Launch Video: NVIDIA Earth-2: The Future of AI Weather Forecasting is Open&lt;/p&gt;
&lt;p&gt;Web Page: Earth-2&lt;/p&gt;
&lt;p&gt;Hugging Face Package for Earth-2 Nowcasting&lt;/p&gt;
&lt;p&gt;Research Paper: Learning Accurate Storm-Scale Evolution from Observations&lt;/p&gt;
&lt;p&gt;Hugging Face Package for Earth-2 Medium-Range&lt;/p&gt;
&lt;p&gt;Research Paper: Demystifying Data-Driven Probabilistic Medium-Range
Weather Forecasting&lt;/p&gt;
&lt;p&gt;Research Paper: HealDA: Highlighting the Importance of Initial Errors in
End-to-End AI Weather Forecasts&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/nvidia/earth-2-open-models</guid><pubDate>Mon, 26 Jan 2026 14:53:45 +0000</pubDate></item><item><title>[NEW] Only 5 days left: Over half of the first 500 TechCrunch Disrupt 2026 plus-one passes at 50% off are already gone (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/only-5-days-left-over-half-of-the-first-500-techcrunch-disrupt-2026-plus-one-passes-at-50-off-are-already-gone/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The clock is officially ticking.&amp;nbsp;In just&amp;nbsp;5 days, the lowest ticket prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt;&amp;nbsp;‚Äî plus the exclusive&amp;nbsp;50% off plus-one pass for the first 500 registrations&amp;nbsp;‚Äî will be gone. And with&amp;nbsp;more than half of those first 500 already claimed, this window is closing fast. If Disrupt has been on your must-attend list, this is your moment to lock in the best deal and bring a plus-one for half the price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;save&amp;nbsp;&lt;strong&gt;up to $680 on your pass&lt;/strong&gt;&amp;nbsp;and get a second ticket at&amp;nbsp;&lt;strong&gt;50% off&lt;/strong&gt;. This offer&amp;nbsp;ends&amp;nbsp;&lt;strong&gt;January 30&lt;/strong&gt;,&amp;nbsp;or&amp;nbsp;the moment the first 500 tickets are claimed. Whichever comes first.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2022" class="wp-image-2540398" height="427" src="https://techcrunch.com/wp-content/uploads/2023/05/disrupt-expo-hall-crop.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-disrupt"&gt;Why Disrupt?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;From October 13‚Äì15,&amp;nbsp;San Francisco‚Äôs&amp;nbsp;Moscone West will become the global epicenter of tech.&amp;nbsp;&lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt;&amp;nbsp;is a curated, three-day experience designed to maximize signal over noise ‚Äî uniting 10,000&amp;nbsp;founders,&amp;nbsp;investors, operators, and tech leaders for 200+ expert-led sessions featuring 250+ influential voices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Explore&amp;nbsp;what‚Äôs&amp;nbsp;next as&amp;nbsp;300+ startups debut their breakthroughs, experience the high-stakes energy of&amp;nbsp;Startup Battlefield 200, and tap into&amp;nbsp;curated, high-impact networking&amp;nbsp;with the leaders shaping the future of tech.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="matt-mullenweg-bling-watch" class="wp-image-2908808" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/matt-mullenweg-bling-watch.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Past speakers have included some of the industry‚Äôs greatest minds:&lt;/p&gt;



























&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2428022" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-500.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-a-more-curated-way-to-experience-disrupt-nbsp"&gt;A more curated way to experience Disrupt&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt&amp;nbsp;isn‚Äôt&amp;nbsp;about wandering between sessions.&amp;nbsp;It‚Äôs&amp;nbsp;about &lt;strong&gt;intentional connections and curated experiences&lt;/strong&gt; designed for how you&amp;nbsp;actually work&amp;nbsp;in tech. Founders connect directly with investors. VCs cut through the noise to discover startups aligned with their theses. Operators exchange real-world insights on building, scaling, and shipping&amp;nbsp;what‚Äôs&amp;nbsp;next. If&amp;nbsp;you‚Äôre&amp;nbsp;hands-on in tech, Disrupt was built with you in mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Explore ticket options to find the right fit for you, your partner, and your team.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-founders-and-investors-unique-benefits"&gt;Founders and investors‚Äô unique benefits&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Founders and investors can unlock specialized passes designed to support your goals:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;:&amp;nbsp;Get the tools, insights, and connections you need to accelerate your&amp;nbsp;startup‚Äôs&amp;nbsp;growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;:&amp;nbsp;Access curated opportunities to connect with standout startups and expand your portfolio. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-time-is-running-out-on-the-plus-one-deal"&gt;Time is running out on the plus-one deal&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;More than&amp;nbsp;half of the first 500 plus-one passes are already gone, and this offer ends in&amp;nbsp;just 5 days.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;save&amp;nbsp;&lt;strong&gt;up to $680&lt;/strong&gt;&amp;nbsp;on your Disrupt ticket and bring a plus-one at&amp;nbsp;&lt;strong&gt;50% off&lt;/strong&gt;&amp;nbsp;while discounted passes&amp;nbsp;remain.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The clock is officially ticking.&amp;nbsp;In just&amp;nbsp;5 days, the lowest ticket prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt;&amp;nbsp;‚Äî plus the exclusive&amp;nbsp;50% off plus-one pass for the first 500 registrations&amp;nbsp;‚Äî will be gone. And with&amp;nbsp;more than half of those first 500 already claimed, this window is closing fast. If Disrupt has been on your must-attend list, this is your moment to lock in the best deal and bring a plus-one for half the price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;save&amp;nbsp;&lt;strong&gt;up to $680 on your pass&lt;/strong&gt;&amp;nbsp;and get a second ticket at&amp;nbsp;&lt;strong&gt;50% off&lt;/strong&gt;. This offer&amp;nbsp;ends&amp;nbsp;&lt;strong&gt;January 30&lt;/strong&gt;,&amp;nbsp;or&amp;nbsp;the moment the first 500 tickets are claimed. Whichever comes first.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2022" class="wp-image-2540398" height="427" src="https://techcrunch.com/wp-content/uploads/2023/05/disrupt-expo-hall-crop.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-disrupt"&gt;Why Disrupt?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;From October 13‚Äì15,&amp;nbsp;San Francisco‚Äôs&amp;nbsp;Moscone West will become the global epicenter of tech.&amp;nbsp;&lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt;&amp;nbsp;is a curated, three-day experience designed to maximize signal over noise ‚Äî uniting 10,000&amp;nbsp;founders,&amp;nbsp;investors, operators, and tech leaders for 200+ expert-led sessions featuring 250+ influential voices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Explore&amp;nbsp;what‚Äôs&amp;nbsp;next as&amp;nbsp;300+ startups debut their breakthroughs, experience the high-stakes energy of&amp;nbsp;Startup Battlefield 200, and tap into&amp;nbsp;curated, high-impact networking&amp;nbsp;with the leaders shaping the future of tech.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="matt-mullenweg-bling-watch" class="wp-image-2908808" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/matt-mullenweg-bling-watch.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Past speakers have included some of the industry‚Äôs greatest minds:&lt;/p&gt;



























&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2428022" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-500.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-a-more-curated-way-to-experience-disrupt-nbsp"&gt;A more curated way to experience Disrupt&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt&amp;nbsp;isn‚Äôt&amp;nbsp;about wandering between sessions.&amp;nbsp;It‚Äôs&amp;nbsp;about &lt;strong&gt;intentional connections and curated experiences&lt;/strong&gt; designed for how you&amp;nbsp;actually work&amp;nbsp;in tech. Founders connect directly with investors. VCs cut through the noise to discover startups aligned with their theses. Operators exchange real-world insights on building, scaling, and shipping&amp;nbsp;what‚Äôs&amp;nbsp;next. If&amp;nbsp;you‚Äôre&amp;nbsp;hands-on in tech, Disrupt was built with you in mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Explore ticket options to find the right fit for you, your partner, and your team.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-founders-and-investors-unique-benefits"&gt;Founders and investors‚Äô unique benefits&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Founders and investors can unlock specialized passes designed to support your goals:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;:&amp;nbsp;Get the tools, insights, and connections you need to accelerate your&amp;nbsp;startup‚Äôs&amp;nbsp;growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;:&amp;nbsp;Access curated opportunities to connect with standout startups and expand your portfolio. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-time-is-running-out-on-the-plus-one-deal"&gt;Time is running out on the plus-one deal&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;More than&amp;nbsp;half of the first 500 plus-one passes are already gone, and this offer ends in&amp;nbsp;just 5 days.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;save&amp;nbsp;&lt;strong&gt;up to $680&lt;/strong&gt;&amp;nbsp;on your Disrupt ticket and bring a plus-one at&amp;nbsp;&lt;strong&gt;50% off&lt;/strong&gt;&amp;nbsp;while discounted passes&amp;nbsp;remain.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/only-5-days-left-over-half-of-the-first-500-techcrunch-disrupt-2026-plus-one-passes-at-50-off-are-already-gone/</guid><pubDate>Mon, 26 Jan 2026 15:00:00 +0000</pubDate></item><item><title>[NEW] Expereo: Enterprise connectivity amid AI surge with ‚Äòvisibility at the speed of life‚Äô (AI News)</title><link>https://www.artificialintelligence-news.com/news/expereo-enterprise-connectivity-amid-ai-surge-with-visibility-at-the-speed-of-life/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/pexels-pixabay-248747-2-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI continues to reshape technology and business; yet for the network, enterprise connectivity in the AI age means being always-on, and extra vigilant for sovereignty and security besides.&lt;/p&gt;&lt;p&gt;This means that speed is not the only requirement. As Julian Skeels, chief digital officer at Expereo notes, it is more about ‚Äòcertainty.‚Äô ‚ÄúAI workloads are distributed, they‚Äôre continuous, they‚Äôre incredibly latency-sensitive. Inference, monitoring, retrieval and remediation never stop, so that changes the network‚Äôs role,‚Äù says Skeels.&lt;/p&gt;&lt;p&gt;‚ÄúIn the world of AI, networking actually becomes a system dependency,‚Äù he adds. ‚ÄúWhen the network degrades, the application degrades immediately.&lt;/p&gt;&lt;p&gt;‚ÄúAn AI-ready network needs to make data movement deterministic. It‚Äôs not just about it being fast; it‚Äôs about it being predictable, and observable, and governable, and resilient ‚Äì and to do all those things under continual change.‚Äù&lt;/p&gt;&lt;p&gt;Many CIOs, however, are struggling right now with what Skeels describes as ‚Äòconnectivity everywhere but visibility nowhere.‚Äô&lt;/p&gt;&lt;p&gt;‚ÄúThey‚Äôre dealing with hybrid networks, multiple clouds, multiple providers and portals that create a constant operational drag to their teams,‚Äù says Skeels. ‚ÄúWhat they want is clarity and control ‚Äì not more tools.‚Äù&lt;/p&gt;&lt;p&gt;Skeels arrived at Expereo last year with myriad cross-industry experience in product and digital transformation initiatives under his belt. He found an industry ripe for accelerative change, and a company determined to lead the way and ensure pricing global connectivity should take minutes rather than weeks.&lt;/p&gt;&lt;p&gt;‚ÄúWhen I came to Expereo, I saw that global connectivity has, I would say, largely resisted real digital transformation for a long time,‚Äù notes Skeels. ‚ÄúMost customers will still experience it as slow, and manual, and opaque, and fragmented across the dozens of providers and portals they need to work with.&lt;/p&gt;&lt;p&gt;‚ÄúWe believe, though, that with emerging technologies such as agentic AI, that‚Äôs finally changing,‚Äù adds Skeels. ‚ÄúOur ambition here is to make global connectivity as simple, and immediate, and transparent as cloud computing is for our customers.‚Äù&lt;/p&gt;&lt;p&gt;Enabling such change for customers requires that mix of speed and visibility ‚Äì and this is where the expereoOne platform comes in, to provide what the company calls ‚Äòvisibility at the speed of life‚Äô and give customers a single, global view of what is being deployed, how it is performing, and what it costs. Beyond visibility, customers also need proactivity, as Skeels explains. ‚ÄúWe‚Äôre deeply integrated into our customers‚Äô order management, their ITSM, their ERP systems, which makes working with Expereo at scale absolutely seamless,‚Äù he says.&lt;/p&gt;&lt;p&gt;‚ÄúThe key point is that better visibility isn‚Äôt about more dashboards. It‚Äôs about connecting network behaviour to their business outcomes in terms of resilience, security experience, and cost.‚Äù&lt;/p&gt;&lt;p&gt;Skeels is speaking at the Digital Transformation Expo Global on February 4-5 around designing the AI-ready network ‚Äì and his session promises to subvert the usual advice for those in attendance. ‚ÄúI want to challenge a few things,‚Äù notes Skeels. ‚ÄúI want to ask people to consider even unlearning things they‚Äôve learned in the past.&lt;/p&gt;&lt;p&gt;‚ÄúA lot of what we‚Äôve taken for granted about networks no longer holds in an AI world.‚Äù&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full conversation between Julian Skeels and TechEx‚Äôs James Bourne below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="1080" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Julian_Skeels_Expereo_19_01.mp4" width="1920"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Pixabay&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/pexels-pixabay-248747-2-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI continues to reshape technology and business; yet for the network, enterprise connectivity in the AI age means being always-on, and extra vigilant for sovereignty and security besides.&lt;/p&gt;&lt;p&gt;This means that speed is not the only requirement. As Julian Skeels, chief digital officer at Expereo notes, it is more about ‚Äòcertainty.‚Äô ‚ÄúAI workloads are distributed, they‚Äôre continuous, they‚Äôre incredibly latency-sensitive. Inference, monitoring, retrieval and remediation never stop, so that changes the network‚Äôs role,‚Äù says Skeels.&lt;/p&gt;&lt;p&gt;‚ÄúIn the world of AI, networking actually becomes a system dependency,‚Äù he adds. ‚ÄúWhen the network degrades, the application degrades immediately.&lt;/p&gt;&lt;p&gt;‚ÄúAn AI-ready network needs to make data movement deterministic. It‚Äôs not just about it being fast; it‚Äôs about it being predictable, and observable, and governable, and resilient ‚Äì and to do all those things under continual change.‚Äù&lt;/p&gt;&lt;p&gt;Many CIOs, however, are struggling right now with what Skeels describes as ‚Äòconnectivity everywhere but visibility nowhere.‚Äô&lt;/p&gt;&lt;p&gt;‚ÄúThey‚Äôre dealing with hybrid networks, multiple clouds, multiple providers and portals that create a constant operational drag to their teams,‚Äù says Skeels. ‚ÄúWhat they want is clarity and control ‚Äì not more tools.‚Äù&lt;/p&gt;&lt;p&gt;Skeels arrived at Expereo last year with myriad cross-industry experience in product and digital transformation initiatives under his belt. He found an industry ripe for accelerative change, and a company determined to lead the way and ensure pricing global connectivity should take minutes rather than weeks.&lt;/p&gt;&lt;p&gt;‚ÄúWhen I came to Expereo, I saw that global connectivity has, I would say, largely resisted real digital transformation for a long time,‚Äù notes Skeels. ‚ÄúMost customers will still experience it as slow, and manual, and opaque, and fragmented across the dozens of providers and portals they need to work with.&lt;/p&gt;&lt;p&gt;‚ÄúWe believe, though, that with emerging technologies such as agentic AI, that‚Äôs finally changing,‚Äù adds Skeels. ‚ÄúOur ambition here is to make global connectivity as simple, and immediate, and transparent as cloud computing is for our customers.‚Äù&lt;/p&gt;&lt;p&gt;Enabling such change for customers requires that mix of speed and visibility ‚Äì and this is where the expereoOne platform comes in, to provide what the company calls ‚Äòvisibility at the speed of life‚Äô and give customers a single, global view of what is being deployed, how it is performing, and what it costs. Beyond visibility, customers also need proactivity, as Skeels explains. ‚ÄúWe‚Äôre deeply integrated into our customers‚Äô order management, their ITSM, their ERP systems, which makes working with Expereo at scale absolutely seamless,‚Äù he says.&lt;/p&gt;&lt;p&gt;‚ÄúThe key point is that better visibility isn‚Äôt about more dashboards. It‚Äôs about connecting network behaviour to their business outcomes in terms of resilience, security experience, and cost.‚Äù&lt;/p&gt;&lt;p&gt;Skeels is speaking at the Digital Transformation Expo Global on February 4-5 around designing the AI-ready network ‚Äì and his session promises to subvert the usual advice for those in attendance. ‚ÄúI want to challenge a few things,‚Äù notes Skeels. ‚ÄúI want to ask people to consider even unlearning things they‚Äôve learned in the past.&lt;/p&gt;&lt;p&gt;‚ÄúA lot of what we‚Äôve taken for granted about networks no longer holds in an AI world.‚Äù&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full conversation between Julian Skeels and TechEx‚Äôs James Bourne below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="1080" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Julian_Skeels_Expereo_19_01.mp4" width="1920"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Pixabay&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/expereo-enterprise-connectivity-amid-ai-surge-with-visibility-at-the-speed-of-life/</guid><pubDate>Mon, 26 Jan 2026 15:23:57 +0000</pubDate></item><item><title>[NEW] Nvidia invests $2B to help debt-ridden CoreWeave add 5GW of AI compute (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/nvidia-invests-2b-to-help-debt-ridden-coreweave-add-5gw-of-ai-compute/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-1468360413.jpg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia said on Monday it has invested $2 billion in CoreWeave to hasten the data center company‚Äôs efforts to add more than 5 gigawatts of AI computing capacity by 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The chipmaker, already an investor in CoreWeave, said it had bought the company‚Äôs Class A shares at $87.20 per share. As part of the deal, CoreWeave and Nvidia plan to together build ‚ÄúAI factories‚Äù (data centers) that would use the chipmaker‚Äôs products. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave will also integrate Nvidia‚Äôs products across its platform, including the new Rubin chip architecture (set to replace the current Blackwell architecture), Bluefield storage systems, as well as the chipmaker‚Äôs new CPU line, Vera. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal is a strong show of support for CoreWeave, which has come under scrutiny over the past few months for raising billions in debt to continue building out its data center operations. The company had $18.81 billion in debt obligations as of September 2025, according to PitchBook data, and it reported revenue of $1.36 billion in the third quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company‚Äôs CEO Michael Intrator has defended its business model (funding operations by raising debt with its GPUs as collateral), and has addressed concerns of circular deals in the AI industry by saying companies have to ‚Äúwork together‚Äù to address a ‚Äúviolent change in supply and demand.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has managed to successfully ride the AI wave since its transition from a crypto mining company to a provider of data center services for AI training and inference. And since its IPO in March last year, it has been busy fleshing out its technology stack with a slew of acquisitions. It acquired Weights &amp;amp; Biases, an AI developer platform, in March, and then soon after bought reinforcement learning startup OpenPipe. In October, it agreed to acquire Marimo (an open source Jupyter notebook competitor) and Monolith, another AI company. It also recently expanded its cloud partnership with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently counts several hyperscalers as customers, including OpenAI, Meta, and Microsoft.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Nvidia will also help CoreWeave buy land and power for data centers, and work with the smaller company to include its AI software and architecture within Nvidia‚Äôs reference architecture to sell to cloud businesses and enterprises. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave‚Äôs shares were up more than 15% following news of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Nvidia, arguably the biggest benefactor and driver of the AI boom, the deal is the latest of several dozen investments in the past year as the company does its best to continue fueling the precipitous pace of investment in, and development of, the nascent technology. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-1468360413.jpg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia said on Monday it has invested $2 billion in CoreWeave to hasten the data center company‚Äôs efforts to add more than 5 gigawatts of AI computing capacity by 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The chipmaker, already an investor in CoreWeave, said it had bought the company‚Äôs Class A shares at $87.20 per share. As part of the deal, CoreWeave and Nvidia plan to together build ‚ÄúAI factories‚Äù (data centers) that would use the chipmaker‚Äôs products. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave will also integrate Nvidia‚Äôs products across its platform, including the new Rubin chip architecture (set to replace the current Blackwell architecture), Bluefield storage systems, as well as the chipmaker‚Äôs new CPU line, Vera. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal is a strong show of support for CoreWeave, which has come under scrutiny over the past few months for raising billions in debt to continue building out its data center operations. The company had $18.81 billion in debt obligations as of September 2025, according to PitchBook data, and it reported revenue of $1.36 billion in the third quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company‚Äôs CEO Michael Intrator has defended its business model (funding operations by raising debt with its GPUs as collateral), and has addressed concerns of circular deals in the AI industry by saying companies have to ‚Äúwork together‚Äù to address a ‚Äúviolent change in supply and demand.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has managed to successfully ride the AI wave since its transition from a crypto mining company to a provider of data center services for AI training and inference. And since its IPO in March last year, it has been busy fleshing out its technology stack with a slew of acquisitions. It acquired Weights &amp;amp; Biases, an AI developer platform, in March, and then soon after bought reinforcement learning startup OpenPipe. In October, it agreed to acquire Marimo (an open source Jupyter notebook competitor) and Monolith, another AI company. It also recently expanded its cloud partnership with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently counts several hyperscalers as customers, including OpenAI, Meta, and Microsoft.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Nvidia will also help CoreWeave buy land and power for data centers, and work with the smaller company to include its AI software and architecture within Nvidia‚Äôs reference architecture to sell to cloud businesses and enterprises. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave‚Äôs shares were up more than 15% following news of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Nvidia, arguably the biggest benefactor and driver of the AI boom, the deal is the latest of several dozen investments in the past year as the company does its best to continue fueling the precipitous pace of investment in, and development of, the nascent technology. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/nvidia-invests-2b-to-help-debt-ridden-coreweave-add-5gw-of-ai-compute/</guid><pubDate>Mon, 26 Jan 2026 15:52:55 +0000</pubDate></item><item><title>[NEW] Microsoft announces powerful new chip for AI inference (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/microsoft-announces-powerful-new-chip-for-ai-inference/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Maia200-Hero-Image.png?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft has announced the launch of its latest chip, the Maia 200, which the company describes as a silicon workhorse designed for scaling AI inference.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 200, which follows the company‚Äôs Maia 100 released in 2023, has been technically outfitted to run powerful AI models at faster speeds and with more efficiency, the company has said. Maia comes equipped with over 100 billion transistors, delivering over 10 petaflops in 4-bit precision and approximately 5 petaflops of 8-bit performance ‚Äî a substantial increase over its predecessor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inference refers to the computing process of running a model, in contrast with the compute required to train it. As AI companies mature, inference costs have become an increasingly important part of their overall operating cost, leading to renewed interest in ways to optimize the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft is hoping that the Maia 200 can be part of that optimization, making AI businesses run with less disruption and lower power use. ‚ÄúIn practical terms, one Maia 200 node can effortlessly run today‚Äôs largest models, with plenty of headroom for even bigger models in the future,‚Äù the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft‚Äôs new chip is also part of a growing trend of tech giants turning to self-designed chips as a way to lessen their dependence on Nvidia, whose cutting-edge GPUs have become increasingly pivotal to AI companies‚Äô success. Google, for instance, has its TPU, the tensor processing units ‚Äî which aren‚Äôt sold as chips but as compute power made accessible through its cloud. Then there‚Äôs Amazon Trainium, the e-commerce giant‚Äôs own AI accelerator chip, which just launched its latest version, the Trainium3, in December. In each case, the TPUs can be used to offload some of the compute that would otherwise be assigned to Nvidia GPUs, lessening the overall hardware cost.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Maia, Microsoft is positioning itself to compete with those alternatives. In its press release Monday, the company noted that Maia delivers 3x the FP4 performance of third-generation Amazon Trainium chips, and FP8 performance above Google‚Äôs seventh generation TPU.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft says that Maia is already hard at work fueling the company‚Äôs AI models from its&amp;nbsp;Superintelligence team. It has also been supporting the operations of Copilot, its chatbot. As of Monday, the company said it has invited a variety of parties ‚Äî including developers, academics, and frontier AI labs ‚Äî to use its Maia 200 software development kit in their workloads.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Maia200-Hero-Image.png?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft has announced the launch of its latest chip, the Maia 200, which the company describes as a silicon workhorse designed for scaling AI inference.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 200, which follows the company‚Äôs Maia 100 released in 2023, has been technically outfitted to run powerful AI models at faster speeds and with more efficiency, the company has said. Maia comes equipped with over 100 billion transistors, delivering over 10 petaflops in 4-bit precision and approximately 5 petaflops of 8-bit performance ‚Äî a substantial increase over its predecessor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inference refers to the computing process of running a model, in contrast with the compute required to train it. As AI companies mature, inference costs have become an increasingly important part of their overall operating cost, leading to renewed interest in ways to optimize the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft is hoping that the Maia 200 can be part of that optimization, making AI businesses run with less disruption and lower power use. ‚ÄúIn practical terms, one Maia 200 node can effortlessly run today‚Äôs largest models, with plenty of headroom for even bigger models in the future,‚Äù the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft‚Äôs new chip is also part of a growing trend of tech giants turning to self-designed chips as a way to lessen their dependence on Nvidia, whose cutting-edge GPUs have become increasingly pivotal to AI companies‚Äô success. Google, for instance, has its TPU, the tensor processing units ‚Äî which aren‚Äôt sold as chips but as compute power made accessible through its cloud. Then there‚Äôs Amazon Trainium, the e-commerce giant‚Äôs own AI accelerator chip, which just launched its latest version, the Trainium3, in December. In each case, the TPUs can be used to offload some of the compute that would otherwise be assigned to Nvidia GPUs, lessening the overall hardware cost.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Maia, Microsoft is positioning itself to compete with those alternatives. In its press release Monday, the company noted that Maia delivers 3x the FP4 performance of third-generation Amazon Trainium chips, and FP8 performance above Google‚Äôs seventh generation TPU.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft says that Maia is already hard at work fueling the company‚Äôs AI models from its&amp;nbsp;Superintelligence team. It has also been supporting the operations of Copilot, its chatbot. As of Monday, the company said it has invited a variety of parties ‚Äî including developers, academics, and frontier AI labs ‚Äî to use its Maia 200 software development kit in their workloads.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/microsoft-announces-powerful-new-chip-for-ai-inference/</guid><pubDate>Mon, 26 Jan 2026 16:00:00 +0000</pubDate></item><item><title>[NEW] Tech workers call for CEOs to speak up against ICE after the killing of Alex Pretti (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/tech-workers-call-for-ceos-to-speak-up-against-ice-after-the-killing-of-alex-pretti/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2257473113.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;More than 450 tech workers from companies like Google, Meta, OpenAI, Amazon, and Salesforce have signed a letter urging their CEOs to call the White House and demand that United States Immigration and Custom Enforcement (ICE) leave U.S. cities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúFor months now, Trump has sent federal agents to our cities to criminalize us, our neighbors, friends, colleagues, and family members,‚Äù reads the open letter from IceOut.Tech. ‚ÄúFrom Minneapolis to Los Angeles to Chicago, we‚Äôve seen armed and masked thugs bring reckless violence, kidnapping, terror and cruelty with no end in sight.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Minneapolis has become the focal point of a large-scale federal immigration operation, employing tactics so intense that many have characterized it as a military occupation. The operation has been marked by confrontations between federal agents and community members protesting the raids, with law enforcement indiscriminately deploying crowd control tactics, including pepper spray, tear gas, rubber bullets, and sound cannons.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis cannot continue, and we know the tech industry can make a difference,‚Äù the letter from tech industry workers continues. ‚ÄúWhen Trump threatened to send the National Guard to San Francisco in October, tech industry leaders called the White House. It worked: Trump backed down.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The campaign among tech workers began after ICE agents shot and killed U.S. citizen Renee Good in Minneapolis three weeks ago, and it grew over the weekend after Border Patrol agents shot and killed Alex Pretti, a 37-year-old ICU nurse at the Minneapolis VA hospital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The organizers of the letter did not disclose their names, and many who signed the letter did so anonymously out of fear of retribution.&amp;nbsp;TechCrunch has reached out for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of tech leaders have already spoken out against federal actions in Minneapolis. LinkedIn co-founder Reid Hoffman said the way ICE operates is ‚Äúterrible for the people,‚Äù and Khosla Ventures founder Vinod Khosla called the current enforcement ‚Äúmacho ICE vigilantes running amuck empowered by a conscious-less administration.‚Äù Google DeepMind‚Äôs chief scientist Jeff Dean called for ‚Äúevery person regardless of political affiliation‚Äù to denounce the escalation of violence. OpenAI‚Äôs head of global business, James Dyett, criticized the industry‚Äôs silence, posting on X that ‚Äúthere is far more outrage from tech leaders over a wealth tax than masked ICE agents terrorizing communities.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Signal President Meredith Whittaker bemoaned that masked agents are ‚Äúexecuting people in the streets and powerful leaders are openly lying to cover for them. To everyone in my industry who‚Äôs ever claimed to value freedom ‚Äî draw on the courage of your convictions and stand up.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, many of the most powerful figures in tech leaders have not only largely stayed quiet about opposition to the Trump administration‚Äôs directives, but they have actively attempted to curry favor with the president. Amazon owner Jeff Bezos, Apple CEO Tim Cook, Google CEO Sundar Pichai and Meta CEO Mark Zuckerberg all attended during President Trump‚Äôs inauguration and donated to the inauguration fund either personally or through their corporations. None have spoken out publicly about the ramping up of ICE raids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI president Greg Brockman and his wife Anna are also prominent donors to causes and candidates associated with President Trump and have refrained from speaking out. In keeping with his anti-immigration views, Elon Musk has actively supported ICE operations, calling protestors ‚Äúpure evil.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The letter also calls on tech CEOs to cancel all company contracts with ICE ‚Äî potentially an expensive demand, as several tech firms currently hold contracts with ICE. Palantir is one of ICE‚Äôs most significant tech partners. Last year the company was awarded a $30 million contract to build a new AI-driven surveillance platform called ‚ÄúImmigrationOS.‚Äù Last year, facial recognition company Clearview AI signed a contract to provide ICE with facial-matching technology. Amazon Web Services, Microsoft, and Oracle also provide cloud infrastructure to the Department of Homeland Security and ICE, as well as IT services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to the companies for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We‚Äôre reporting on the inner workings of the AI industry ‚Äî from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com&lt;/em&gt; &lt;em&gt;or Russell Brandom at russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at @rebeccabellan.491&lt;/em&gt; &lt;em&gt;and @russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2257473113.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;More than 450 tech workers from companies like Google, Meta, OpenAI, Amazon, and Salesforce have signed a letter urging their CEOs to call the White House and demand that United States Immigration and Custom Enforcement (ICE) leave U.S. cities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúFor months now, Trump has sent federal agents to our cities to criminalize us, our neighbors, friends, colleagues, and family members,‚Äù reads the open letter from IceOut.Tech. ‚ÄúFrom Minneapolis to Los Angeles to Chicago, we‚Äôve seen armed and masked thugs bring reckless violence, kidnapping, terror and cruelty with no end in sight.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Minneapolis has become the focal point of a large-scale federal immigration operation, employing tactics so intense that many have characterized it as a military occupation. The operation has been marked by confrontations between federal agents and community members protesting the raids, with law enforcement indiscriminately deploying crowd control tactics, including pepper spray, tear gas, rubber bullets, and sound cannons.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis cannot continue, and we know the tech industry can make a difference,‚Äù the letter from tech industry workers continues. ‚ÄúWhen Trump threatened to send the National Guard to San Francisco in October, tech industry leaders called the White House. It worked: Trump backed down.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The campaign among tech workers began after ICE agents shot and killed U.S. citizen Renee Good in Minneapolis three weeks ago, and it grew over the weekend after Border Patrol agents shot and killed Alex Pretti, a 37-year-old ICU nurse at the Minneapolis VA hospital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The organizers of the letter did not disclose their names, and many who signed the letter did so anonymously out of fear of retribution.&amp;nbsp;TechCrunch has reached out for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of tech leaders have already spoken out against federal actions in Minneapolis. LinkedIn co-founder Reid Hoffman said the way ICE operates is ‚Äúterrible for the people,‚Äù and Khosla Ventures founder Vinod Khosla called the current enforcement ‚Äúmacho ICE vigilantes running amuck empowered by a conscious-less administration.‚Äù Google DeepMind‚Äôs chief scientist Jeff Dean called for ‚Äúevery person regardless of political affiliation‚Äù to denounce the escalation of violence. OpenAI‚Äôs head of global business, James Dyett, criticized the industry‚Äôs silence, posting on X that ‚Äúthere is far more outrage from tech leaders over a wealth tax than masked ICE agents terrorizing communities.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Signal President Meredith Whittaker bemoaned that masked agents are ‚Äúexecuting people in the streets and powerful leaders are openly lying to cover for them. To everyone in my industry who‚Äôs ever claimed to value freedom ‚Äî draw on the courage of your convictions and stand up.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, many of the most powerful figures in tech leaders have not only largely stayed quiet about opposition to the Trump administration‚Äôs directives, but they have actively attempted to curry favor with the president. Amazon owner Jeff Bezos, Apple CEO Tim Cook, Google CEO Sundar Pichai and Meta CEO Mark Zuckerberg all attended during President Trump‚Äôs inauguration and donated to the inauguration fund either personally or through their corporations. None have spoken out publicly about the ramping up of ICE raids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI president Greg Brockman and his wife Anna are also prominent donors to causes and candidates associated with President Trump and have refrained from speaking out. In keeping with his anti-immigration views, Elon Musk has actively supported ICE operations, calling protestors ‚Äúpure evil.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The letter also calls on tech CEOs to cancel all company contracts with ICE ‚Äî potentially an expensive demand, as several tech firms currently hold contracts with ICE. Palantir is one of ICE‚Äôs most significant tech partners. Last year the company was awarded a $30 million contract to build a new AI-driven surveillance platform called ‚ÄúImmigrationOS.‚Äù Last year, facial recognition company Clearview AI signed a contract to provide ICE with facial-matching technology. Amazon Web Services, Microsoft, and Oracle also provide cloud infrastructure to the Department of Homeland Security and ICE, as well as IT services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to the companies for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We‚Äôre reporting on the inner workings of the AI industry ‚Äî from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com&lt;/em&gt; &lt;em&gt;or Russell Brandom at russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at @rebeccabellan.491&lt;/em&gt; &lt;em&gt;and @russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/tech-workers-call-for-ceos-to-speak-up-against-ice-after-the-killing-of-alex-pretti/</guid><pubDate>Mon, 26 Jan 2026 16:26:49 +0000</pubDate></item><item><title>[NEW] Retailers examine options for on-AI retail (AI News)</title><link>https://www.artificialintelligence-news.com/news/retailers-examine-options-for-on-ai-retail/</link><description>&lt;p&gt; Big retailers are committing more heavily to agentic AI-led commerce, and accepting some loss of customer proximity and data control in the process.&lt;/p&gt;&lt;p&gt; As reported by &lt;i&gt;Retail Dive&lt;/i&gt;, the opening weeks of 2026 have seen Etsy, Target and Walmart push  product ranges onto third-party AI platforms, forming new partnerships with Google‚Äôs Gemini and Microsoft‚Äôs Copilot, after last year‚Äôs collaborations with OpenAI‚Äôs ChatGPT. These let consumers purchase goods inside the AI‚Äôs conversation interface.&lt;/p&gt;&lt;p&gt; Amazon and Walmart have been investing in their own consumer-facing AI assistants, Rufus and Sparky respectively to change how shoppers interact with their brands.&lt;/p&gt;&lt;p&gt; Agentic AI is beginning to redraw direct-to-consumer engagement, and industry figures regard this trend as an important moment in online retail. ‚ÄúI think this has the potential to disrupt retail in the same way the internet once did,‚Äù Kartik Hosanagar, a marketing professor at the Wharton School of the University of Pennsylvania, told the website‚Äôs reporters.&lt;/p&gt;&lt;p&gt; Partnering with AIs like ChatGPT or Gemini engages consumers wherever they happen to be and may choose to shop. Adobe‚Äôs 2025 Holiday Shopping report found that AI-driven traffic to US e-commerce sites grew 758% year on year between in November 2025, and Cyber Monday saw a 670% increase in AI-referred retail visits.&lt;/p&gt;&lt;p&gt; ‚ÄúWhat we expect is a deepening of consumer engagement,‚Äù Katherine Black, a partner at Kearney specialising in food, drug and mass-market retail, said in an email to &lt;i&gt;Retail Dive&lt;/i&gt;. ‚ÄúMore shoppers will rely on AI for purchasing, and across a wider range of missions. As retailers‚Äô capabilities within these tools improve, adoption should accelerate further.‚Äù&lt;/p&gt;&lt;p&gt; Meeting customers on AI platforms comes with trade-offs, according to industry observers, with questions around data ownership and the risk that retailers are sidelined. 81% of retail executives believe generative AI will erode brand loyalty by 2027, according to Deloitte‚Äôs 2026 Retail Industry Global Outlook, published earlier this month.&lt;/p&gt;&lt;p&gt; Retailers‚Äô websites or apps provide a stream of behavioural data, and if discovery, evaluation, and purchase happen externally, any insight doesn‚Äôt reach the retailer. ‚ÄúThis fundamentally changes where power sits,‚Äù Hosanagar said. ‚ÄúControl over the agent increasingly means control over the customer relationship.‚Äù&lt;/p&gt;&lt;p&gt; Google and Alphabet CEO Sundar Pichai has unveiled new commerce tools for Gemini, outlining how it will support customers from discovery to final purchase. Nikki Baird, vice president of strategy and product at Aptos, says this raises difficult questions. ‚ÄúWhat he‚Äôs describing is Google owning the data across discovery, decision and transaction. Even if some information is shared back, missing context from those stages leaves retailers with a much poorer understanding of their customers.‚Äù&lt;/p&gt;&lt;p&gt; Pichai reassured retailers collaboration remains central to Google. ‚ÄúFrom nearly three decades of working with retailers, we know success only comes when we work together,‚Äù he told an NRF audience. ‚ÄúOur aim is to use our full technology stack to help shape the next era of retail.‚Äù&lt;/p&gt;&lt;p&gt; Yet agentic systems‚Äô features like instant checkout absorb the shopping experience into one platform. ‚ÄúIf research, discovery and purchase all happen on OpenAI rather than Walmart.com, you‚Äôre effectively giving away the brand experience. At that point, the retailer risks becoming little more than a fulfilment operation,‚Äù Hosanagar said.&lt;/p&gt;&lt;p&gt; Amazon has not announced plans to sell directly through ChatGPT, doubling down on its own AI initiatives. Earlier this month, the company launched a dedicated site for Alexa+, its generative AI assistant that helps users research and plan purchases.&lt;/p&gt;&lt;p&gt; Yet participation in third-party AI commerce may become unavoidable. When OpenAI launched its Instant Checkout feature on ChatGPT last September, it suggested that enabling the function could influence how merchants are ranked in search results, in addition to price and product quality. Uploading product catalogues to AI chat platforms may be the first step in a transformation of online retail.&lt;/p&gt;&lt;p&gt; According to Deloitte, roughly half of retail executives expect the current multi-stage shopping process to reduce to a single AI-driven interaction by 2027. For now the industry remains at an early stage of any transition. ‚ÄúThe real inflection point is when consumers rely on an autonomous agent to shop on their behalf,‚Äù Hosanagar told &lt;i&gt;Retail Dive&lt;/i&gt;.&lt;/p&gt;&lt;p&gt; ‚ÄúRetailers will engage less with humans directly and more with their representatives ‚Äî AI agents. That agent processes information differently, requires data in new formats and responds to persuasion in ways unlike a person.‚Äù&lt;/p&gt;&lt;p&gt; Today, consumers can access ChatGPT on their phones while in-store, effectively consulting an always-available expert. ‚ÄúIt‚Äôs not just the internet in your pocket,‚Äù Baird told &lt;i&gt;Retail Dive&lt;/i&gt;. ‚ÄúIt‚Äôs like having a highly knowledgeable store associate who knows every retailer.‚Äù&lt;/p&gt;&lt;p&gt; This may prompt retailers to equip frontline staff with their own AI tools, offering instant insight into customer preferences or shopping history. Alternatively, a retailer‚Äôs AI agent could proactively notify customers when a favoured item is back in stock, helping associates convert interest into sales. ‚ÄúThe goal is to enable store associates to perform at their best,‚Äù Baird said.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: ‚ÄúShopping trauma!‚Äù by Elsie esq. is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt; Big retailers are committing more heavily to agentic AI-led commerce, and accepting some loss of customer proximity and data control in the process.&lt;/p&gt;&lt;p&gt; As reported by &lt;i&gt;Retail Dive&lt;/i&gt;, the opening weeks of 2026 have seen Etsy, Target and Walmart push  product ranges onto third-party AI platforms, forming new partnerships with Google‚Äôs Gemini and Microsoft‚Äôs Copilot, after last year‚Äôs collaborations with OpenAI‚Äôs ChatGPT. These let consumers purchase goods inside the AI‚Äôs conversation interface.&lt;/p&gt;&lt;p&gt; Amazon and Walmart have been investing in their own consumer-facing AI assistants, Rufus and Sparky respectively to change how shoppers interact with their brands.&lt;/p&gt;&lt;p&gt; Agentic AI is beginning to redraw direct-to-consumer engagement, and industry figures regard this trend as an important moment in online retail. ‚ÄúI think this has the potential to disrupt retail in the same way the internet once did,‚Äù Kartik Hosanagar, a marketing professor at the Wharton School of the University of Pennsylvania, told the website‚Äôs reporters.&lt;/p&gt;&lt;p&gt; Partnering with AIs like ChatGPT or Gemini engages consumers wherever they happen to be and may choose to shop. Adobe‚Äôs 2025 Holiday Shopping report found that AI-driven traffic to US e-commerce sites grew 758% year on year between in November 2025, and Cyber Monday saw a 670% increase in AI-referred retail visits.&lt;/p&gt;&lt;p&gt; ‚ÄúWhat we expect is a deepening of consumer engagement,‚Äù Katherine Black, a partner at Kearney specialising in food, drug and mass-market retail, said in an email to &lt;i&gt;Retail Dive&lt;/i&gt;. ‚ÄúMore shoppers will rely on AI for purchasing, and across a wider range of missions. As retailers‚Äô capabilities within these tools improve, adoption should accelerate further.‚Äù&lt;/p&gt;&lt;p&gt; Meeting customers on AI platforms comes with trade-offs, according to industry observers, with questions around data ownership and the risk that retailers are sidelined. 81% of retail executives believe generative AI will erode brand loyalty by 2027, according to Deloitte‚Äôs 2026 Retail Industry Global Outlook, published earlier this month.&lt;/p&gt;&lt;p&gt; Retailers‚Äô websites or apps provide a stream of behavioural data, and if discovery, evaluation, and purchase happen externally, any insight doesn‚Äôt reach the retailer. ‚ÄúThis fundamentally changes where power sits,‚Äù Hosanagar said. ‚ÄúControl over the agent increasingly means control over the customer relationship.‚Äù&lt;/p&gt;&lt;p&gt; Google and Alphabet CEO Sundar Pichai has unveiled new commerce tools for Gemini, outlining how it will support customers from discovery to final purchase. Nikki Baird, vice president of strategy and product at Aptos, says this raises difficult questions. ‚ÄúWhat he‚Äôs describing is Google owning the data across discovery, decision and transaction. Even if some information is shared back, missing context from those stages leaves retailers with a much poorer understanding of their customers.‚Äù&lt;/p&gt;&lt;p&gt; Pichai reassured retailers collaboration remains central to Google. ‚ÄúFrom nearly three decades of working with retailers, we know success only comes when we work together,‚Äù he told an NRF audience. ‚ÄúOur aim is to use our full technology stack to help shape the next era of retail.‚Äù&lt;/p&gt;&lt;p&gt; Yet agentic systems‚Äô features like instant checkout absorb the shopping experience into one platform. ‚ÄúIf research, discovery and purchase all happen on OpenAI rather than Walmart.com, you‚Äôre effectively giving away the brand experience. At that point, the retailer risks becoming little more than a fulfilment operation,‚Äù Hosanagar said.&lt;/p&gt;&lt;p&gt; Amazon has not announced plans to sell directly through ChatGPT, doubling down on its own AI initiatives. Earlier this month, the company launched a dedicated site for Alexa+, its generative AI assistant that helps users research and plan purchases.&lt;/p&gt;&lt;p&gt; Yet participation in third-party AI commerce may become unavoidable. When OpenAI launched its Instant Checkout feature on ChatGPT last September, it suggested that enabling the function could influence how merchants are ranked in search results, in addition to price and product quality. Uploading product catalogues to AI chat platforms may be the first step in a transformation of online retail.&lt;/p&gt;&lt;p&gt; According to Deloitte, roughly half of retail executives expect the current multi-stage shopping process to reduce to a single AI-driven interaction by 2027. For now the industry remains at an early stage of any transition. ‚ÄúThe real inflection point is when consumers rely on an autonomous agent to shop on their behalf,‚Äù Hosanagar told &lt;i&gt;Retail Dive&lt;/i&gt;.&lt;/p&gt;&lt;p&gt; ‚ÄúRetailers will engage less with humans directly and more with their representatives ‚Äî AI agents. That agent processes information differently, requires data in new formats and responds to persuasion in ways unlike a person.‚Äù&lt;/p&gt;&lt;p&gt; Today, consumers can access ChatGPT on their phones while in-store, effectively consulting an always-available expert. ‚ÄúIt‚Äôs not just the internet in your pocket,‚Äù Baird told &lt;i&gt;Retail Dive&lt;/i&gt;. ‚ÄúIt‚Äôs like having a highly knowledgeable store associate who knows every retailer.‚Äù&lt;/p&gt;&lt;p&gt; This may prompt retailers to equip frontline staff with their own AI tools, offering instant insight into customer preferences or shopping history. Alternatively, a retailer‚Äôs AI agent could proactively notify customers when a favoured item is back in stock, helping associates convert interest into sales. ‚ÄúThe goal is to enable store associates to perform at their best,‚Äù Baird said.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: ‚ÄúShopping trauma!‚Äù by Elsie esq. is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/retailers-examine-options-for-on-ai-retail/</guid><pubDate>Mon, 26 Jan 2026 16:40:00 +0000</pubDate></item><item><title>[NEW] Why chatbots are starting to check your age (Artificial intelligence ‚Äì MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/260122_algo_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;How do tech companies check if their users are kids?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This question has taken on new urgency recently thanks to growing concern about the dangers that can arise when children talk to AI chatbots. For years Big Tech asked for birthdays (that one could make up) to avoid violating child privacy laws, but they weren‚Äôt required to moderate content accordingly. Two developments over the last week show how quickly things are changing in the US and how this issue is becoming a new battleground, even among parents and child-safety advocates.&lt;/p&gt;  &lt;p&gt;In one corner is the Republican Party, which has supported laws passed in several states that require sites with adult content to verify users‚Äô ages. Critics say this provides cover to block anything deemed ‚Äúharmful to minors,‚Äù which could include sex education. Other states, like California, are coming after AI companies with laws to protect kids who talk to chatbots (by requiring them to verify who‚Äôs a kid). Meanwhile, President Trump is attempting to keep AI regulation a national issue rather than allowing states to make their own rules. Support for various bills in Congress is constantly in flux.&lt;/p&gt; 
 &lt;p&gt;So what might happen? The debate is quickly moving away from whether age verification is necessary and toward who will be responsible for it.&lt;strong&gt; &lt;/strong&gt;This responsibility is a hot potato that no company wants to hold.&lt;/p&gt;  &lt;p&gt;In a blog post last Tuesday, OpenAI revealed that it plans to roll out automatic age prediction. In short, the company will apply a model that uses factors like the time of day, among others, to predict whether a person chatting is under 18. For those identified as teens or children, ChatGPT will apply filters to ‚Äúreduce exposure‚Äù to content like graphic violence or sexual role-play. YouTube launched something similar last year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If you support age verification but are concerned about privacy, this might sound like a win. But there's a catch. The system is not perfect, of course, so it could classify a child as an adult or vice versa. People who are wrongly labeled under 18 can verify their identity by submitting a selfie or government ID to a company called Persona.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Selfie verifications have issues: They fail more often for people of color and those with certain disabilities. Sameer Hinduja, who co-directs the Cyberbullying Research Center, says the fact that Persona will need to hold millions of government IDs and masses of biometric data is another weak point. ‚ÄúWhen those get breached, we‚Äôve exposed massive populations all at once,‚Äù he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hinduja instead advocates for device-level verification, where a parent specifies a child‚Äôs age when setting up the child‚Äôs phone for the first time. This information is then kept on the device and shared securely with apps and websites.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That‚Äôs more or less what Tim Cook, the CEO of Apple, recently lobbied US lawmakers to call for. Cook was fighting lawmakers who wanted to require app stores to verify ages, which would saddle Apple with lots of liability.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;More signals of where this is all headed will come on Wednesday, when the Federal Trade Commission‚Äîthe agency that would be responsible for enforcing these new laws‚Äîis holding an all-day workshop on age verification. Apple‚Äôs head of government affairs, Nick Rossi, will be there. He‚Äôll be joined by higher-ups in child safety at Google and Meta, as well as a company that specializes in marketing to children.&lt;/p&gt;  &lt;p&gt;The FTC has become increasingly politicized under President Trump (his firing of the sole Democratic commissioner was struck down by a federal court, a decision that is now pending review by the US Supreme Court). In July, I wrote about signals that the agency is softening its stance toward AI companies. Indeed, in December, the FTC overturned a Biden-era ruling against an AI company that allowed people to flood the internet with fake product reviews, writing that it clashed with President Trump‚Äôs AI Action Plan.&lt;/p&gt;  &lt;p&gt;Wednesday‚Äôs workshop may shed light on how partisan the FTC‚Äôs approach to age verification will be. Red states favor laws that require porn websites to verify ages (but critics warn this could be used to block a much wider range of content). Bethany Soye, a Republican state representative who is leading an effort to pass such a bill in her state of South Dakota, is scheduled to speak at the FTC meeting. The ACLU generally opposes laws requiring IDs to visit websites and has instead advocated for an expansion of existing parental controls.&lt;/p&gt;  &lt;p&gt;While all this gets debated, though, AI has set the world of child safety on fire. We‚Äôre dealing with increased generation of child sexual abuse material, concerns (and lawsuits) about suicides and self-harm following chatbot conversations, and troubling evidence of kids‚Äô forming attachments to AI companions. Colliding stances on privacy, politics, free expression, and surveillance will complicate any effort to find a solution. Write to me with your thoughts.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/260122_algo_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;How do tech companies check if their users are kids?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This question has taken on new urgency recently thanks to growing concern about the dangers that can arise when children talk to AI chatbots. For years Big Tech asked for birthdays (that one could make up) to avoid violating child privacy laws, but they weren‚Äôt required to moderate content accordingly. Two developments over the last week show how quickly things are changing in the US and how this issue is becoming a new battleground, even among parents and child-safety advocates.&lt;/p&gt;  &lt;p&gt;In one corner is the Republican Party, which has supported laws passed in several states that require sites with adult content to verify users‚Äô ages. Critics say this provides cover to block anything deemed ‚Äúharmful to minors,‚Äù which could include sex education. Other states, like California, are coming after AI companies with laws to protect kids who talk to chatbots (by requiring them to verify who‚Äôs a kid). Meanwhile, President Trump is attempting to keep AI regulation a national issue rather than allowing states to make their own rules. Support for various bills in Congress is constantly in flux.&lt;/p&gt; 
 &lt;p&gt;So what might happen? The debate is quickly moving away from whether age verification is necessary and toward who will be responsible for it.&lt;strong&gt; &lt;/strong&gt;This responsibility is a hot potato that no company wants to hold.&lt;/p&gt;  &lt;p&gt;In a blog post last Tuesday, OpenAI revealed that it plans to roll out automatic age prediction. In short, the company will apply a model that uses factors like the time of day, among others, to predict whether a person chatting is under 18. For those identified as teens or children, ChatGPT will apply filters to ‚Äúreduce exposure‚Äù to content like graphic violence or sexual role-play. YouTube launched something similar last year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If you support age verification but are concerned about privacy, this might sound like a win. But there's a catch. The system is not perfect, of course, so it could classify a child as an adult or vice versa. People who are wrongly labeled under 18 can verify their identity by submitting a selfie or government ID to a company called Persona.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Selfie verifications have issues: They fail more often for people of color and those with certain disabilities. Sameer Hinduja, who co-directs the Cyberbullying Research Center, says the fact that Persona will need to hold millions of government IDs and masses of biometric data is another weak point. ‚ÄúWhen those get breached, we‚Äôve exposed massive populations all at once,‚Äù he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hinduja instead advocates for device-level verification, where a parent specifies a child‚Äôs age when setting up the child‚Äôs phone for the first time. This information is then kept on the device and shared securely with apps and websites.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That‚Äôs more or less what Tim Cook, the CEO of Apple, recently lobbied US lawmakers to call for. Cook was fighting lawmakers who wanted to require app stores to verify ages, which would saddle Apple with lots of liability.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;More signals of where this is all headed will come on Wednesday, when the Federal Trade Commission‚Äîthe agency that would be responsible for enforcing these new laws‚Äîis holding an all-day workshop on age verification. Apple‚Äôs head of government affairs, Nick Rossi, will be there. He‚Äôll be joined by higher-ups in child safety at Google and Meta, as well as a company that specializes in marketing to children.&lt;/p&gt;  &lt;p&gt;The FTC has become increasingly politicized under President Trump (his firing of the sole Democratic commissioner was struck down by a federal court, a decision that is now pending review by the US Supreme Court). In July, I wrote about signals that the agency is softening its stance toward AI companies. Indeed, in December, the FTC overturned a Biden-era ruling against an AI company that allowed people to flood the internet with fake product reviews, writing that it clashed with President Trump‚Äôs AI Action Plan.&lt;/p&gt;  &lt;p&gt;Wednesday‚Äôs workshop may shed light on how partisan the FTC‚Äôs approach to age verification will be. Red states favor laws that require porn websites to verify ages (but critics warn this could be used to block a much wider range of content). Bethany Soye, a Republican state representative who is leading an effort to pass such a bill in her state of South Dakota, is scheduled to speak at the FTC meeting. The ACLU generally opposes laws requiring IDs to visit websites and has instead advocated for an expansion of existing parental controls.&lt;/p&gt;  &lt;p&gt;While all this gets debated, though, AI has set the world of child safety on fire. We‚Äôre dealing with increased generation of child sexual abuse material, concerns (and lawsuits) about suicides and self-harm following chatbot conversations, and troubling evidence of kids‚Äô forming attachments to AI companions. Colliding stances on privacy, politics, free expression, and surveillance will complicate any effort to find a solution. Write to me with your thoughts.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/</guid><pubDate>Mon, 26 Jan 2026 17:05:00 +0000</pubDate></item><item><title>[NEW] Anthropic launches interactive Claude apps, including Slack and other workplace tools (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/anthropic-launches-interactive-claude-apps-including-slack-and-other-workplace-tools/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/mcp-asana-crop.jpg?resize=1200,987" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Claude users will now be able to call up interactive apps within the chatbot interface, thanks to a new feature announced by Anthropic on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In keeping with Anthropic‚Äôs enterprise focus, the launch apps are mostly workplace tools, including Slack, Canva, Figma, Box, and Clay, with a Salesforce implementation expected soon. In each case, the app will enable a logged-in instance of the service that‚Äôs accessible to Claude, enabling users to send Slack messages, generate charts, or access cloud files, depending on which apps have been enabled.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúAnalyzing data, designing content, and managing projects all work better with a dedicated visual interface,‚Äù Anthropic said in a blog post announcing the feature. ‚ÄúCombined with Claude‚Äôs intelligence, you can work and iterate faster than either could offer alone.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature is available to Pro, Max, Team, and Enterprise subscribers, but not free users. Eligible users can activate the tools at claude.ai/directory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system is similar to OpenAI‚Äôs Apps system, which launched in October and also enables interactive third-party tools. Both systems of app integrations are built on the Model Context Protocol, an open standard introduced by Anthropic in 2024. MCP launched support for apps in November, drawing on work from both companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new apps will be particularly powerful when integrated with Claude Cowork, an all-purpose agent tool launched by Anthropic last week. Built on top of Claude Code, Cowork lets users assign multi-stage tasks that draw on large and open-ended datasets ‚Äî tasks that would have previously required terminal commands. Combined with the new apps feature, Cowork could be granted access to cloud files or ongoing work projects. For example, Cowork could update a marketing graphic in Figma or use new data from the company‚Äôs Box instance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apps are not available in Cowork at launch, but Anthropic said the integration would be ‚Äúcoming soon.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic systems can be unpredictable, and Anthropic‚Äôs own safety documentation for Cowork encourages users to monitor the agent closely and not grant any unnecessary permissions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBe cautious about granting access to sensitive information like financial documents, credentials, or personal records,‚Äù the company recommends. ‚ÄúConsider creating a dedicated working folder for Claude rather than granting broad access.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/mcp-asana-crop.jpg?resize=1200,987" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Claude users will now be able to call up interactive apps within the chatbot interface, thanks to a new feature announced by Anthropic on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In keeping with Anthropic‚Äôs enterprise focus, the launch apps are mostly workplace tools, including Slack, Canva, Figma, Box, and Clay, with a Salesforce implementation expected soon. In each case, the app will enable a logged-in instance of the service that‚Äôs accessible to Claude, enabling users to send Slack messages, generate charts, or access cloud files, depending on which apps have been enabled.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúAnalyzing data, designing content, and managing projects all work better with a dedicated visual interface,‚Äù Anthropic said in a blog post announcing the feature. ‚ÄúCombined with Claude‚Äôs intelligence, you can work and iterate faster than either could offer alone.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature is available to Pro, Max, Team, and Enterprise subscribers, but not free users. Eligible users can activate the tools at claude.ai/directory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system is similar to OpenAI‚Äôs Apps system, which launched in October and also enables interactive third-party tools. Both systems of app integrations are built on the Model Context Protocol, an open standard introduced by Anthropic in 2024. MCP launched support for apps in November, drawing on work from both companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new apps will be particularly powerful when integrated with Claude Cowork, an all-purpose agent tool launched by Anthropic last week. Built on top of Claude Code, Cowork lets users assign multi-stage tasks that draw on large and open-ended datasets ‚Äî tasks that would have previously required terminal commands. Combined with the new apps feature, Cowork could be granted access to cloud files or ongoing work projects. For example, Cowork could update a marketing graphic in Figma or use new data from the company‚Äôs Box instance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apps are not available in Cowork at launch, but Anthropic said the integration would be ‚Äúcoming soon.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic systems can be unpredictable, and Anthropic‚Äôs own safety documentation for Cowork encourages users to monitor the agent closely and not grant any unnecessary permissions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBe cautious about granting access to sensitive information like financial documents, credentials, or personal records,‚Äù the company recommends. ‚ÄúConsider creating a dedicated working folder for Claude rather than granting broad access.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/anthropic-launches-interactive-claude-apps-including-slack-and-other-workplace-tools/</guid><pubDate>Mon, 26 Jan 2026 18:00:00 +0000</pubDate></item><item><title>[NEW] Obvious Ventures lands fund five with a 360-degree view of planetary, human, economic health (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/26/obvious-ventures-lands-fund-five-with-a-360-degree-view-of-planetary-human-economic-health/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Obvious-Five-high-rez39.png?resize=1200,684" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Obvious Ventures, the firm co-founded by Twitter‚Äôs Evan Williams, has raised a fifth fund, and this one, just like its predecessors, comes with a ‚Äúfun‚Äù number: $360,360,360.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe invest in the frontiers of math and science and physics, and we like to celebrate math in our fund numbers as well,‚Äù James Joaquin (pictured far right), the firm‚Äôs co-founder and managing director, told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The firm‚Äôs first fund was $123,456,789, and the second was $191,919,191 (a palindromic number that reads the same forward and backwards). The third was $271,828,182 (which mathematicians and engineers instantly recognize as e, or Euler‚Äôs number), while the fourth fund, announced in mid-2022, continued the tradition as another palindrome at $355,111,553.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you haven‚Äôt guessed it by now, the meaning of Obvious Ventures newest fund size is a little less about geeky math and more about the firm‚Äôs investing philosophy. Twelve years into its journey, Obvious says the figure represents a full-circle perspective on its three broad focus areas: planetary health, human health, and economic health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe love the metaphor of taking a 360-degree view in each of those areas,‚Äù Joaquin said. ‚ÄúYou have to be a student of the past to understand what‚Äôs worked and what hasn‚Äôt worked.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What‚Äôs working for the firm, according to Joaquin, is keeping its fund sizes small enough so that a single investment, if it becomes a durable public company, has the opportunity to return the entire fund. Joaquin likely placed an emphasis on durability in part because Obvious Venture‚Äôs initial winners, Beyond Meat, reached a market capitalization of over $14 billion shortly after its 2019 IPO, but had fallen to below a billion by late 2022. &amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Joaquin says the firm has seen meaningful cash distributions to limited partners from all of its core funds, and it boasts several companies with successful public-market exits. In 2015, Obvious Ventures invested in the satellite imagery company Planet Labs, which went public via a SPAC in 2021 and is currently valued at approximately $8.5 billion. Meanwhile, its Series A investment in Recursion Pharmaceuticals maintains a market capitalization of over $2 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Obvious is also an early investor in the HR and payroll platform Gusto, which was most recently valued at more than $9 billion in the private market and is widely considered to be on an IPO trajectory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a venture capital environment where only 17% of firms successfully raise more than three funds, per research from Sapphire Partners, Obvious Ventures‚Äô latest fundraise solidifies the firm as an established VC player.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe made it to fund five, which is actually a big deal in the venture landscape,‚Äù Joaquin said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Obvious Ventures may take a playful approach to fund sizes, but its focus on investing in startups that make a positive impact on the world is serious. Joaquin pointed to several investments in each of the firm‚Äôs three pillars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within the planetary health sector, the firm invested in Zanskar, a startup using proprietary data and AI to identify and harness geothermal energy, one of the most cost-effective power sources available. Just last week, Zanskar announced a $115 million Series C. Obvious Ventures, which led the company‚Äôs previous round, is particularly excited about the investment. Joaquin noted that the geothermal power harnessed by Zanskar can help fuel energy-hungry AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its human health strategy, Obvious Ventures touted its investment in Inceptive, an AI platform for molecule development. Inceptive was founded by Jakob Uszkoreit, one of the primary authors of the seminal ‚ÄúAttention is All You Need‚Äù paper, which introduced the transformer architecture, the breakthrough behind generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the area of economic health, Joaquin pointed to Dexterity Robotics. The company, which was at $1.65 billion last year, builds humanoids to handle ‚Äúdull, dirty, and dangerous‚Äù jobs tasks currently performed by humans in warehouses and factories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to Joaquin, Obvious Ventures has four active investors, including co-founder Vishal Vasishth. (Ev Williams remains a co-founder and an adviser.) The firm intends to make approximately 10 investments annually, with check sizes ranging from $5 million to $12 million for Seed and Series A startups.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Obvious-Five-high-rez39.png?resize=1200,684" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Obvious Ventures, the firm co-founded by Twitter‚Äôs Evan Williams, has raised a fifth fund, and this one, just like its predecessors, comes with a ‚Äúfun‚Äù number: $360,360,360.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe invest in the frontiers of math and science and physics, and we like to celebrate math in our fund numbers as well,‚Äù James Joaquin (pictured far right), the firm‚Äôs co-founder and managing director, told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The firm‚Äôs first fund was $123,456,789, and the second was $191,919,191 (a palindromic number that reads the same forward and backwards). The third was $271,828,182 (which mathematicians and engineers instantly recognize as e, or Euler‚Äôs number), while the fourth fund, announced in mid-2022, continued the tradition as another palindrome at $355,111,553.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you haven‚Äôt guessed it by now, the meaning of Obvious Ventures newest fund size is a little less about geeky math and more about the firm‚Äôs investing philosophy. Twelve years into its journey, Obvious says the figure represents a full-circle perspective on its three broad focus areas: planetary health, human health, and economic health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe love the metaphor of taking a 360-degree view in each of those areas,‚Äù Joaquin said. ‚ÄúYou have to be a student of the past to understand what‚Äôs worked and what hasn‚Äôt worked.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What‚Äôs working for the firm, according to Joaquin, is keeping its fund sizes small enough so that a single investment, if it becomes a durable public company, has the opportunity to return the entire fund. Joaquin likely placed an emphasis on durability in part because Obvious Venture‚Äôs initial winners, Beyond Meat, reached a market capitalization of over $14 billion shortly after its 2019 IPO, but had fallen to below a billion by late 2022. &amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Joaquin says the firm has seen meaningful cash distributions to limited partners from all of its core funds, and it boasts several companies with successful public-market exits. In 2015, Obvious Ventures invested in the satellite imagery company Planet Labs, which went public via a SPAC in 2021 and is currently valued at approximately $8.5 billion. Meanwhile, its Series A investment in Recursion Pharmaceuticals maintains a market capitalization of over $2 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Obvious is also an early investor in the HR and payroll platform Gusto, which was most recently valued at more than $9 billion in the private market and is widely considered to be on an IPO trajectory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a venture capital environment where only 17% of firms successfully raise more than three funds, per research from Sapphire Partners, Obvious Ventures‚Äô latest fundraise solidifies the firm as an established VC player.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe made it to fund five, which is actually a big deal in the venture landscape,‚Äù Joaquin said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Obvious Ventures may take a playful approach to fund sizes, but its focus on investing in startups that make a positive impact on the world is serious. Joaquin pointed to several investments in each of the firm‚Äôs three pillars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within the planetary health sector, the firm invested in Zanskar, a startup using proprietary data and AI to identify and harness geothermal energy, one of the most cost-effective power sources available. Just last week, Zanskar announced a $115 million Series C. Obvious Ventures, which led the company‚Äôs previous round, is particularly excited about the investment. Joaquin noted that the geothermal power harnessed by Zanskar can help fuel energy-hungry AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its human health strategy, Obvious Ventures touted its investment in Inceptive, an AI platform for molecule development. Inceptive was founded by Jakob Uszkoreit, one of the primary authors of the seminal ‚ÄúAttention is All You Need‚Äù paper, which introduced the transformer architecture, the breakthrough behind generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the area of economic health, Joaquin pointed to Dexterity Robotics. The company, which was at $1.65 billion last year, builds humanoids to handle ‚Äúdull, dirty, and dangerous‚Äù jobs tasks currently performed by humans in warehouses and factories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to Joaquin, Obvious Ventures has four active investors, including co-founder Vishal Vasishth. (Ev Williams remains a co-founder and an adviser.) The firm intends to make approximately 10 investments annually, with check sizes ranging from $5 million to $12 million for Seed and Series A startups.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/26/obvious-ventures-lands-fund-five-with-a-360-degree-view-of-planetary-human-economic-health/</guid><pubDate>Mon, 26 Jan 2026 18:00:00 +0000</pubDate></item></channel></rss>