<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 23 Jul 2025 18:33:50 +0000</lastBuildDate><item><title>Sam Altman: AI will cause job losses and national security threats (AI News)</title><link>https://www.artificialintelligence-news.com/news/sam-altman-ai-cause-job-losses-national-security-threats/</link><description>&lt;p&gt;In the halls of power in Washington, OpenAI’s chief, Sam Altman, warned of total job losses from AI and how national security is being rewritten. Altman positions OpenAI as not just a participant, but as the essential architect of our destiny.&lt;/p&gt;&lt;p&gt;Holding court at the Federal Reserve’s conference for large banks, Altman clearly stated how he believes AI will impact how people earn a living. He spoke of certain jobs not just being changed, but erased completely.&lt;/p&gt;&lt;p&gt;“Some areas, again, I think will be totally, totally gone,” he said, pointing at the customer support industry as an example. “That’s a category where I just say, you know what, when you call customer support, you’re speaking to AI, and that’s fine.”&lt;/p&gt;&lt;p&gt;He described this shift not as a distant forecast but as a present-day reality. To the Federal Reserve’s Michelle Bowman, he described an almost utopian interaction with an AI agent.&lt;/p&gt;&lt;p&gt;“You call one of these things and AI answers. It’s like a super-smart, capable person,” says Altman. “There’s no phone tree, there’s no transfers. It can do everything that any customer support agent at that company could do. It does not make mistakes. It’s very quick. You call once and the thing just happens.”&lt;/p&gt;&lt;p&gt;But Altman’s belief that AI will cause total job losses in some careers isn’t the only story being told in the tech world. Others argue that the future isn’t about what AI will do to us, but what we choose to do with it. Manoj Chaudhary, CTO of the integration firm Jitterbit, offers a dose of caution.&lt;/p&gt;&lt;p&gt;“AI isn’t what threatens jobs, but rather poorly planned deployment. The real danger lies in using powerful tools without purpose or human judgment,” Chaudhary warned. He sees a risk in a blind rush for technological solutions.&lt;/p&gt;&lt;p&gt;“Companies chasing quick efficiencies risk discarding the human insight that drives real value. As many are now realising, AI isn’t a cure-all; even the smartest systems fall short where empathy and nuance matter. Without careful, human-led oversight, the consequences of AI misuse will be hard to ignore.”&lt;/p&gt;&lt;p&gt;The scale of Altman’s vision for AI, however, extends far beyond call centres. The transformation, he suggests, is already knocking at the door of our healthcare system. He made the claim that his company’s own creation is already a world-class physician.&lt;/p&gt;&lt;p&gt;“ChatGPT today, by the way, most of the time, is like a better diagnostician than most doctors in the world,” he asserted. Yet, in a moment of candour – after championing AI as the superior doctor – he confessed he wouldn’t fully trust it with his own health.&lt;/p&gt;&lt;p&gt;“Yet people still go to doctors, and I am not, like, maybe I’m a dinosaur here, but I really do not want to, like, entrust my medical fate to ChatGPT with no human doctor in the loop,” he admitted.&lt;/p&gt;&lt;p&gt;This tightrope walk between promotion and precaution is happening on a new political stage. Under the Trump administration, the conversation in Washington around AI has shifted from the caution and regulation sought under President Biden to minimise impacts like job losses, to an unrelenting focus on acceleration to outpace China.&lt;/p&gt;&lt;p&gt;It is in this high-stakes environment that Altman shared his deepest fears. He spoke of sleepless nights, troubled by the thought of a hostile nation using AI as a weapon to cripple the US financial system.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Altman also marvelled at the power of voice cloning technology but warned of how it could be used for unstoppable fraud, especially since “there are still some financial institutions that will accept voiceprints for authentication.”&lt;/p&gt;&lt;p&gt;The OpenAI chief’s visit, his first major congressional testimony since he exploded onto the global stage in 2023, is part of a clear strategy as the firm plans to open an OpenAI office in Washington next year.&lt;/p&gt;&lt;p&gt;Altman came to Washington with two messages that seem to pull in opposite directions. The first is that his technology will bring about an age of incredible progress. However, the second is that AI holds the potential for immense destruction—causing total job losses and increasing national security threats.&lt;/p&gt;&lt;p&gt;The ultimate goal, it seems, is to convince the world that only he and OpenAI can safely navigate the path between the two.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image credit: World Economic Forum / Benedikt von Loebell under CC BY-NC-SA 2.0 license. Image has been cropped.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s newest Gemini 2.5 model aims for ‘intelligence per dollar’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;In the halls of power in Washington, OpenAI’s chief, Sam Altman, warned of total job losses from AI and how national security is being rewritten. Altman positions OpenAI as not just a participant, but as the essential architect of our destiny.&lt;/p&gt;&lt;p&gt;Holding court at the Federal Reserve’s conference for large banks, Altman clearly stated how he believes AI will impact how people earn a living. He spoke of certain jobs not just being changed, but erased completely.&lt;/p&gt;&lt;p&gt;“Some areas, again, I think will be totally, totally gone,” he said, pointing at the customer support industry as an example. “That’s a category where I just say, you know what, when you call customer support, you’re speaking to AI, and that’s fine.”&lt;/p&gt;&lt;p&gt;He described this shift not as a distant forecast but as a present-day reality. To the Federal Reserve’s Michelle Bowman, he described an almost utopian interaction with an AI agent.&lt;/p&gt;&lt;p&gt;“You call one of these things and AI answers. It’s like a super-smart, capable person,” says Altman. “There’s no phone tree, there’s no transfers. It can do everything that any customer support agent at that company could do. It does not make mistakes. It’s very quick. You call once and the thing just happens.”&lt;/p&gt;&lt;p&gt;But Altman’s belief that AI will cause total job losses in some careers isn’t the only story being told in the tech world. Others argue that the future isn’t about what AI will do to us, but what we choose to do with it. Manoj Chaudhary, CTO of the integration firm Jitterbit, offers a dose of caution.&lt;/p&gt;&lt;p&gt;“AI isn’t what threatens jobs, but rather poorly planned deployment. The real danger lies in using powerful tools without purpose or human judgment,” Chaudhary warned. He sees a risk in a blind rush for technological solutions.&lt;/p&gt;&lt;p&gt;“Companies chasing quick efficiencies risk discarding the human insight that drives real value. As many are now realising, AI isn’t a cure-all; even the smartest systems fall short where empathy and nuance matter. Without careful, human-led oversight, the consequences of AI misuse will be hard to ignore.”&lt;/p&gt;&lt;p&gt;The scale of Altman’s vision for AI, however, extends far beyond call centres. The transformation, he suggests, is already knocking at the door of our healthcare system. He made the claim that his company’s own creation is already a world-class physician.&lt;/p&gt;&lt;p&gt;“ChatGPT today, by the way, most of the time, is like a better diagnostician than most doctors in the world,” he asserted. Yet, in a moment of candour – after championing AI as the superior doctor – he confessed he wouldn’t fully trust it with his own health.&lt;/p&gt;&lt;p&gt;“Yet people still go to doctors, and I am not, like, maybe I’m a dinosaur here, but I really do not want to, like, entrust my medical fate to ChatGPT with no human doctor in the loop,” he admitted.&lt;/p&gt;&lt;p&gt;This tightrope walk between promotion and precaution is happening on a new political stage. Under the Trump administration, the conversation in Washington around AI has shifted from the caution and regulation sought under President Biden to minimise impacts like job losses, to an unrelenting focus on acceleration to outpace China.&lt;/p&gt;&lt;p&gt;It is in this high-stakes environment that Altman shared his deepest fears. He spoke of sleepless nights, troubled by the thought of a hostile nation using AI as a weapon to cripple the US financial system.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Altman also marvelled at the power of voice cloning technology but warned of how it could be used for unstoppable fraud, especially since “there are still some financial institutions that will accept voiceprints for authentication.”&lt;/p&gt;&lt;p&gt;The OpenAI chief’s visit, his first major congressional testimony since he exploded onto the global stage in 2023, is part of a clear strategy as the firm plans to open an OpenAI office in Washington next year.&lt;/p&gt;&lt;p&gt;Altman came to Washington with two messages that seem to pull in opposite directions. The first is that his technology will bring about an age of incredible progress. However, the second is that AI holds the potential for immense destruction—causing total job losses and increasing national security threats.&lt;/p&gt;&lt;p&gt;The ultimate goal, it seems, is to convince the world that only he and OpenAI can safely navigate the path between the two.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image credit: World Economic Forum / Benedikt von Loebell under CC BY-NC-SA 2.0 license. Image has been cropped.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s newest Gemini 2.5 model aims for ‘intelligence per dollar’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/sam-altman-ai-cause-job-losses-national-security-threats/</guid><pubDate>Wed, 23 Jul 2025 10:57:29 +0000</pubDate></item><item><title>Trump is set to unveil his AI roadmap: Here’s what to know (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/trump-is-set-to-unveil-his-ai-roadmap-heres-what-to-know/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1327493808.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 10:00 am PT: Trump’s AI Action Plan was unveiled after this article published. Read TechCrunch’s coverage on the fully released plan here.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;U.S. President Donald Trump is expected to unveil his long-awaited AI Action Plan at a Washington, D.C. event Wednesday hosted by Silicon Valley insiders — his first major address concerning artificial intelligence since he took office for the second time in January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI Action Plan should provide a roadmap of the Trump administration’s strategies, priorities, and concerns around AI — likely a technology that will come to define the 47th president’s term.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan is effectively a replacement for the Biden AI executive order, the previous administration’s AI strategy which placed a large focus on mandating AI companies to submit safety and security reports, and trying to limit racial or otherwise discriminatory bias in frontier AI models. Trump repealed Biden’s order within days of his inauguration, arguing that its requirements could be onerous for AI companies, and may hinder American innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first six months, the Trump administration has broadly encouraged efforts to accelerate the development and distribution of American AI technology. Trump helped OpenAI, Oracle, and SoftBank announce their multibillion-dollar Stargate data center project, and the president peeled back restrictions on Nvidia selling its AI chips around the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, Trump’s AI czar David Sacks has picked a fight with technology companies over “woke” AI, claiming that OpenAI, Anthropic, and Google are supposedly instilling left-leaning values into their AI chatbots and censoring conservative viewpoints. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are already pushing back on Trump’s AI Action plan for allegedly putting corporate interests ahead of the public. On Tuesday, a group of more than 90 organizations, including labor, environmental justice, and consumer protection nonprofits, published an open letter called the People’s AI&amp;nbsp;Action Plan. This puts forth a series of AI policies that claim to put the interests of American citizens first, and counter what Trump is expected to announce.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We can’t let Big Tech and Big Oil lobbyists write the rules for AI and our economy at the expense of our freedom and equality, workers and families’ well-being,” the group said in a statement to TechCrunch that acknowledged the energy needs of Silicon Valley’s AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan should advance his administration’s agenda more explicitly, but exactly how remains unclear. Trump is expected to share more details about the plan at the “Winning the AI Race” summit, an event hosted by The Hill and Valley Forum and the All In podcast, which Sacks co-hosts when he’s not serving as a government official or venture capitalist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here’s what we know about the AI Action Plan so far.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-accelerating-american-ai"&gt;Accelerating American AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI strategy is expected to focus on three pillars — infrastructure, innovation, and global influence — according to a report from Time Magazine.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For infrastructure, the Trump administration is reportedly planning to overhaul permitting rules to speed up the development of AI data centers. This aims to help AI companies meet with the growing energy needs to train and serve their AI models. However, it’s widely expected that the rise of AI data centers — which suck up immense amounts of energy and water from neighboring communities — could cause energy shortages by the end of the decade unless there’s a rapid increase in energy production.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The president’s infrastructure pillar is also expected to include a plan to modernize America’s electrical grid and add new sources of energy to power these data centers, according to Time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the innovation front, Trump reportedly plans to use his AI Action Plan to revive the conversation around blocking state AI laws (even though a federal proposition on the issue overwhelmingly failed last month). This is part of an effort to reduce barriers to innovation for American AI companies, but may ultimately block lawmakers from passing meaningful safety and security standards for AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the global influence pillar, Trump is expected to put forth a strategy to advance the adoption of American AI models and chips, not just in the U.S., but around the world. Federal officials were spooked by the rise of DeepSeek, and other Chinese AI labs such as Qwen and Moonshot AI have since become worthy competitors to OpenAI. Trump wants America’s technology to be the global standard.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To advance its goals, the Trump administration is also expected to sign a series of AI-related executive orders on Wednesday, according to The Washington Post. Some of these orders clear the path for faster data center buildouts, while others encourage the export of American technologies.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-woke-ai"&gt;Combating “woke” AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;One of the executive orders Trump is slated to sign Wednesday would crack down on “woke” AI models, The Wall Street Journal reported earlier this week. The order requires AI companies with federal contracts — which includes OpenAI, xAI, Google, and Anthropic — to ensure their AI models have neutral and unbiased language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The crackdown on “woke” AI marks the Republican party’s latest attack on Silicon Valley’s historically left-leaning crowd. In past years, Republicans investigated social media companies for allegedly altering their algorithms to censor conservative voices. Meta’s Mark Zuckerberg recently capitulated to these allegations, and overhauled Facebook and Instagram’s content moderation to represent more voices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A key question looming around this executive order is who defines whether AI models are neutral or biased, and how they determine it. Trump has long stated he’s an advocate of free speech, so an executive order setting rules around what an AI model can and can’t say may seem counterintuitive. That said, a Florida judge recently ruled that AI chatbots are not protected by the First Amendment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In light of this crackdown, OpenAI and other AI labs have tried to make their AI chatbots represent more viewpoints. These companies are in the awkward position to generate AI responses that please everyone, while also not spreading extremist viewpoints or misinformation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk, once Trump’s greatest financial backer whose relationship with the president has recently soured, explicitly started xAI to develop an “anti-woke” AI chatbot, Grok, and combat ChatGPT. However, xAI’s effort to create such a chatbot hasn’t gone so well. In recent weeks, xAI was forced to apologize repeatedly when its AI chatbot went on antisemitic rants and consulted Musk’s personal opinions on hot-button issues.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-silicon-valley-and-big-tech-want"&gt;What Silicon Valley and Big Tech want&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The White House announced in April it had received more than 10,000 public comments from companies, local governments, and nonprofit organizations regarding Trump’s AI Action Plan. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, Google, Meta, and Amazon effectively took the opportunity to submit wishlists of friendly AI policies they’d like to see the Trump administration implement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of America’s leading AI model developers asked Trump to use his AI Action plan to guarantee that training large language models on copyrighted material would be fair use, and should therefore be allowed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a protection could benefit these companies significantly, as many of them are involved in active lawsuits with copyright owners from the music, film, news, and book industries. These publishers have accused AI companies of illegally training on their copyrighted works to make AI models, potentially devaluing their media in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Meta asked Trump to protect open AI models — which are freely available to download online. By releasing its Llama models openly, Meta has been able to undercut OpenAI and Google’s closed offerings. However, Anthropic has raised concerns over whether open AI models could leak powerful technology to bad actors, including China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other interest groups, including nonprofits such as The Future of Life Institute, used the commenting period to ask the Trump administration to increase investment into AI research efforts outside of commercial entities. The request comes at a time when the Trump administration and DOGE have slashed funding for American universities, many of which have been powerhouses for scientific breakthroughs in recent decades.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It seems unlikely that Trump’s AI Action Plan will feature the same safety and security reporting standards that the Biden administration sought to impose. However, polls show that most Americans want AI companies to be held to safety standards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several state lawmakers are pushing bills that would create safety and security reporting mandates, but they may face opposition from the Trump administration and Republican lawmakers should they contradict Trump’s AI Action Plan.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1327493808.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 10:00 am PT: Trump’s AI Action Plan was unveiled after this article published. Read TechCrunch’s coverage on the fully released plan here.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;U.S. President Donald Trump is expected to unveil his long-awaited AI Action Plan at a Washington, D.C. event Wednesday hosted by Silicon Valley insiders — his first major address concerning artificial intelligence since he took office for the second time in January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI Action Plan should provide a roadmap of the Trump administration’s strategies, priorities, and concerns around AI — likely a technology that will come to define the 47th president’s term.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan is effectively a replacement for the Biden AI executive order, the previous administration’s AI strategy which placed a large focus on mandating AI companies to submit safety and security reports, and trying to limit racial or otherwise discriminatory bias in frontier AI models. Trump repealed Biden’s order within days of his inauguration, arguing that its requirements could be onerous for AI companies, and may hinder American innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first six months, the Trump administration has broadly encouraged efforts to accelerate the development and distribution of American AI technology. Trump helped OpenAI, Oracle, and SoftBank announce their multibillion-dollar Stargate data center project, and the president peeled back restrictions on Nvidia selling its AI chips around the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, Trump’s AI czar David Sacks has picked a fight with technology companies over “woke” AI, claiming that OpenAI, Anthropic, and Google are supposedly instilling left-leaning values into their AI chatbots and censoring conservative viewpoints. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are already pushing back on Trump’s AI Action plan for allegedly putting corporate interests ahead of the public. On Tuesday, a group of more than 90 organizations, including labor, environmental justice, and consumer protection nonprofits, published an open letter called the People’s AI&amp;nbsp;Action Plan. This puts forth a series of AI policies that claim to put the interests of American citizens first, and counter what Trump is expected to announce.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We can’t let Big Tech and Big Oil lobbyists write the rules for AI and our economy at the expense of our freedom and equality, workers and families’ well-being,” the group said in a statement to TechCrunch that acknowledged the energy needs of Silicon Valley’s AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan should advance his administration’s agenda more explicitly, but exactly how remains unclear. Trump is expected to share more details about the plan at the “Winning the AI Race” summit, an event hosted by The Hill and Valley Forum and the All In podcast, which Sacks co-hosts when he’s not serving as a government official or venture capitalist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here’s what we know about the AI Action Plan so far.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-accelerating-american-ai"&gt;Accelerating American AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI strategy is expected to focus on three pillars — infrastructure, innovation, and global influence — according to a report from Time Magazine.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For infrastructure, the Trump administration is reportedly planning to overhaul permitting rules to speed up the development of AI data centers. This aims to help AI companies meet with the growing energy needs to train and serve their AI models. However, it’s widely expected that the rise of AI data centers — which suck up immense amounts of energy and water from neighboring communities — could cause energy shortages by the end of the decade unless there’s a rapid increase in energy production.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The president’s infrastructure pillar is also expected to include a plan to modernize America’s electrical grid and add new sources of energy to power these data centers, according to Time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the innovation front, Trump reportedly plans to use his AI Action Plan to revive the conversation around blocking state AI laws (even though a federal proposition on the issue overwhelmingly failed last month). This is part of an effort to reduce barriers to innovation for American AI companies, but may ultimately block lawmakers from passing meaningful safety and security standards for AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the global influence pillar, Trump is expected to put forth a strategy to advance the adoption of American AI models and chips, not just in the U.S., but around the world. Federal officials were spooked by the rise of DeepSeek, and other Chinese AI labs such as Qwen and Moonshot AI have since become worthy competitors to OpenAI. Trump wants America’s technology to be the global standard.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To advance its goals, the Trump administration is also expected to sign a series of AI-related executive orders on Wednesday, according to The Washington Post. Some of these orders clear the path for faster data center buildouts, while others encourage the export of American technologies.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-combating-woke-ai"&gt;Combating “woke” AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;One of the executive orders Trump is slated to sign Wednesday would crack down on “woke” AI models, The Wall Street Journal reported earlier this week. The order requires AI companies with federal contracts — which includes OpenAI, xAI, Google, and Anthropic — to ensure their AI models have neutral and unbiased language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The crackdown on “woke” AI marks the Republican party’s latest attack on Silicon Valley’s historically left-leaning crowd. In past years, Republicans investigated social media companies for allegedly altering their algorithms to censor conservative voices. Meta’s Mark Zuckerberg recently capitulated to these allegations, and overhauled Facebook and Instagram’s content moderation to represent more voices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A key question looming around this executive order is who defines whether AI models are neutral or biased, and how they determine it. Trump has long stated he’s an advocate of free speech, so an executive order setting rules around what an AI model can and can’t say may seem counterintuitive. That said, a Florida judge recently ruled that AI chatbots are not protected by the First Amendment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In light of this crackdown, OpenAI and other AI labs have tried to make their AI chatbots represent more viewpoints. These companies are in the awkward position to generate AI responses that please everyone, while also not spreading extremist viewpoints or misinformation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk, once Trump’s greatest financial backer whose relationship with the president has recently soured, explicitly started xAI to develop an “anti-woke” AI chatbot, Grok, and combat ChatGPT. However, xAI’s effort to create such a chatbot hasn’t gone so well. In recent weeks, xAI was forced to apologize repeatedly when its AI chatbot went on antisemitic rants and consulted Musk’s personal opinions on hot-button issues.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-silicon-valley-and-big-tech-want"&gt;What Silicon Valley and Big Tech want&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The White House announced in April it had received more than 10,000 public comments from companies, local governments, and nonprofit organizations regarding Trump’s AI Action Plan. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, Google, Meta, and Amazon effectively took the opportunity to submit wishlists of friendly AI policies they’d like to see the Trump administration implement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of America’s leading AI model developers asked Trump to use his AI Action plan to guarantee that training large language models on copyrighted material would be fair use, and should therefore be allowed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a protection could benefit these companies significantly, as many of them are involved in active lawsuits with copyright owners from the music, film, news, and book industries. These publishers have accused AI companies of illegally training on their copyrighted works to make AI models, potentially devaluing their media in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Meta asked Trump to protect open AI models — which are freely available to download online. By releasing its Llama models openly, Meta has been able to undercut OpenAI and Google’s closed offerings. However, Anthropic has raised concerns over whether open AI models could leak powerful technology to bad actors, including China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other interest groups, including nonprofits such as The Future of Life Institute, used the commenting period to ask the Trump administration to increase investment into AI research efforts outside of commercial entities. The request comes at a time when the Trump administration and DOGE have slashed funding for American universities, many of which have been powerhouses for scientific breakthroughs in recent decades.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It seems unlikely that Trump’s AI Action Plan will feature the same safety and security reporting standards that the Biden administration sought to impose. However, polls show that most Americans want AI companies to be held to safety standards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several state lawmakers are pushing bills that would create safety and security reporting mandates, but they may face opposition from the Trump administration and Republican lawmakers should they contradict Trump’s AI Action Plan.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/trump-is-set-to-unveil-his-ai-roadmap-heres-what-to-know/</guid><pubDate>Wed, 23 Jul 2025 12:00:00 +0000</pubDate></item><item><title>The Download: what’s next for AI agents, and how Trump protects US tech companies overseas (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/23/1120571/the-download-whats-next-for-ai-agents-and-how-trump-protects-us-tech-companies-overseas/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Navigating the rise of AI agents&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;AI agents is a buzzy term that essentially refers to AI models and algorithms that can not only provide you with information, but take actions on your behalf. Companies like OpenAI and Anthropic have launched ‘agentic’ products that can do things for you like making bookings, filling in forms, and collaborating with you on coding projects.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On a LinkedIn Live event yesterday our editor-in-chief Mat Honan, senior editor for AI Will Douglas Heaven, and senior AI reporter Grace Huckins discussed what’s exciting about agents and where the technology will go next, but also its limitations, and the risks that currently come with adopting it. Check out what they had to say!&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And if you’re interested in learning more about AI agents, read our stories:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ Are we ready to hand AI agents the keys? We’re starting to give AI agents real autonomy, and we’re not prepared for what could happen next. Read the full story.&lt;/p&gt;&lt;p&gt;+ Anthropic’s chief scientist on 4 ways agents will get even better. Read the full story.&lt;/p&gt;&lt;p&gt;+ Cyberattacks by AI agents are coming. Agents could make it easier and cheaper for criminals to hack systems at scale. We need to be ready.&lt;/p&gt;&lt;p&gt;+ When AIs bargain, a less advanced agent could cost you. In AI-to-AI price negotiations, weaker models often lose out—costing users real money and raising concerns about growing digital inequality. Read the full story.&lt;/p&gt;&lt;p&gt;+ There’s been huge hype about a new general AI agent from China called Manus. We put it to the test.&amp;nbsp;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The Trump administration is seeking to protect US tech firms abroad&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s using its global trade wars as a way to prevent other countries from imposing new taxes, regulations and tariffs on American tech companies. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Tech firms are increasingly trying to shape US AI policy. &lt;/em&gt;(FT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 UK border officials plan to use AI to assess child asylum seekers&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;A pilot scheme will estimate the age of new arrivals to the country.&amp;nbsp; (The Guardian)&lt;br /&gt;+ &lt;em&gt;US border patrol is arresting immigrants nowhere near the US-Mexico border.&amp;nbsp; &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The US wants to use facial recognition to identify migrant children as they age. &lt;/em&gt;(MIT Technology Review)&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;3 AI is hitting web traffic hard&lt;br /&gt;&lt;/strong&gt;Google’s AI Overviews are causing a massive drop in clicks to actual websites. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;It’s good news for Google, bad news for everyone else. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;AI means the end of internet search as we’ve known it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Dozens of Iranians’ iPhones have been targeted with government spyware&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;But the actual total number of targets is likely to be far higher. (Bloomberg $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;5 Amazon is shutting down its AI lab in Shanghai&lt;/strong&gt;&lt;br /&gt;It’s the latest in a line of US tech giants to scale back their research in the country. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Californian billionaires have set their sights on building an industrial park&lt;/strong&gt;&lt;br /&gt;After their plans to create a brand new city didn’t get off the ground. (Gizmodo)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Tesla’s robotaxi launch didn’t quite go to plan&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Prospective customers appear to be a bit freaked out. (Wired $)&lt;br /&gt;+ &lt;em&gt;Ride-hailing companies aren’t meeting their EV adoption targets. &lt;/em&gt;(Rest of World)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;8 Why AI slop could finally help us to log off&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;If AI garbage renders a lot of the web unusable, it could be our only option. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 You may regrow your own teeth in the future 🦷&lt;/strong&gt;&lt;br /&gt;The age of dentures and implants could be nearly over. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Humanlike “teeth” have been grown in mini pigs. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Inside one man’s hunt for an elusive Chinese typewriter&lt;/strong&gt;&lt;br /&gt;It made it possible to type tens of thousands of characters using just 72 keys. (NYT $)&lt;br /&gt;+ &lt;em&gt;How the quest to type Chinese on a QWERTY keyboard created autocomplete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The truth is, China’s really doing ‘007’ now—midnight to midnight, seven days a week.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Venture capitalist Harry Stebbings explains how Chinese startups have moved from ‘996’ work schedules (9am to 9pm, six days a week) to a routine that’s even more punishing, Wired reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/240320_Thwaites-Glacier-hero2.jpg?fit=1456,818" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside a new quest to save the “doomsday glacier”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica, guarding the low-lying ice sheet behind it.&lt;/p&gt;  &lt;p&gt;But a strong, warm ocean current is weakening its foundations and accelerating its slide into the sea. Scientists fear the waters could topple the walls in the coming decades, kick-starting a runaway process that would crack up the West Antarctic Ice Sheet, marking the start of a global climate disaster. As a result, they are eager to understand just how likely such a collapse is, when it could happen, and if we have the power to stop it.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Scientists at MIT and Dartmouth College founded the Arête Glacier Initiative last year in the hope of providing clearer answers to these questions. The nonprofit research organization will officially unveil itself, launch its website, and post requests for research proposals today, timed to coincide with the UN’s inaugural World Day for Glaciers, MIT Technology Review can report exclusively. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;+ A fun-looking major retrospect of David Bailey’s starry career is opening in Spain.&lt;br /&gt;+ Creepy new horror flick &lt;em&gt;Weapons&lt;/em&gt; is getting rave reviews.&lt;br /&gt;+ This amazing website takes you through Apollo 11’s first landing on the moon in real time.&lt;br /&gt;+ Rest in power Ozzy Osbourne, the first ever heavy metal frontman, and the undisputed Prince of Darkness.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Navigating the rise of AI agents&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;AI agents is a buzzy term that essentially refers to AI models and algorithms that can not only provide you with information, but take actions on your behalf. Companies like OpenAI and Anthropic have launched ‘agentic’ products that can do things for you like making bookings, filling in forms, and collaborating with you on coding projects.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On a LinkedIn Live event yesterday our editor-in-chief Mat Honan, senior editor for AI Will Douglas Heaven, and senior AI reporter Grace Huckins discussed what’s exciting about agents and where the technology will go next, but also its limitations, and the risks that currently come with adopting it. Check out what they had to say!&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And if you’re interested in learning more about AI agents, read our stories:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ Are we ready to hand AI agents the keys? We’re starting to give AI agents real autonomy, and we’re not prepared for what could happen next. Read the full story.&lt;/p&gt;&lt;p&gt;+ Anthropic’s chief scientist on 4 ways agents will get even better. Read the full story.&lt;/p&gt;&lt;p&gt;+ Cyberattacks by AI agents are coming. Agents could make it easier and cheaper for criminals to hack systems at scale. We need to be ready.&lt;/p&gt;&lt;p&gt;+ When AIs bargain, a less advanced agent could cost you. In AI-to-AI price negotiations, weaker models often lose out—costing users real money and raising concerns about growing digital inequality. Read the full story.&lt;/p&gt;&lt;p&gt;+ There’s been huge hype about a new general AI agent from China called Manus. We put it to the test.&amp;nbsp;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The Trump administration is seeking to protect US tech firms abroad&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s using its global trade wars as a way to prevent other countries from imposing new taxes, regulations and tariffs on American tech companies. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Tech firms are increasingly trying to shape US AI policy. &lt;/em&gt;(FT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 UK border officials plan to use AI to assess child asylum seekers&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;A pilot scheme will estimate the age of new arrivals to the country.&amp;nbsp; (The Guardian)&lt;br /&gt;+ &lt;em&gt;US border patrol is arresting immigrants nowhere near the US-Mexico border.&amp;nbsp; &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The US wants to use facial recognition to identify migrant children as they age. &lt;/em&gt;(MIT Technology Review)&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;3 AI is hitting web traffic hard&lt;br /&gt;&lt;/strong&gt;Google’s AI Overviews are causing a massive drop in clicks to actual websites. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;It’s good news for Google, bad news for everyone else. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;AI means the end of internet search as we’ve known it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Dozens of Iranians’ iPhones have been targeted with government spyware&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;But the actual total number of targets is likely to be far higher. (Bloomberg $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;5 Amazon is shutting down its AI lab in Shanghai&lt;/strong&gt;&lt;br /&gt;It’s the latest in a line of US tech giants to scale back their research in the country. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Californian billionaires have set their sights on building an industrial park&lt;/strong&gt;&lt;br /&gt;After their plans to create a brand new city didn’t get off the ground. (Gizmodo)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Tesla’s robotaxi launch didn’t quite go to plan&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Prospective customers appear to be a bit freaked out. (Wired $)&lt;br /&gt;+ &lt;em&gt;Ride-hailing companies aren’t meeting their EV adoption targets. &lt;/em&gt;(Rest of World)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;8 Why AI slop could finally help us to log off&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;If AI garbage renders a lot of the web unusable, it could be our only option. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 You may regrow your own teeth in the future 🦷&lt;/strong&gt;&lt;br /&gt;The age of dentures and implants could be nearly over. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Humanlike “teeth” have been grown in mini pigs. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Inside one man’s hunt for an elusive Chinese typewriter&lt;/strong&gt;&lt;br /&gt;It made it possible to type tens of thousands of characters using just 72 keys. (NYT $)&lt;br /&gt;+ &lt;em&gt;How the quest to type Chinese on a QWERTY keyboard created autocomplete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The truth is, China’s really doing ‘007’ now—midnight to midnight, seven days a week.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Venture capitalist Harry Stebbings explains how Chinese startups have moved from ‘996’ work schedules (9am to 9pm, six days a week) to a routine that’s even more punishing, Wired reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/240320_Thwaites-Glacier-hero2.jpg?fit=1456,818" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside a new quest to save the “doomsday glacier”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica, guarding the low-lying ice sheet behind it.&lt;/p&gt;  &lt;p&gt;But a strong, warm ocean current is weakening its foundations and accelerating its slide into the sea. Scientists fear the waters could topple the walls in the coming decades, kick-starting a runaway process that would crack up the West Antarctic Ice Sheet, marking the start of a global climate disaster. As a result, they are eager to understand just how likely such a collapse is, when it could happen, and if we have the power to stop it.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Scientists at MIT and Dartmouth College founded the Arête Glacier Initiative last year in the hope of providing clearer answers to these questions. The nonprofit research organization will officially unveil itself, launch its website, and post requests for research proposals today, timed to coincide with the UN’s inaugural World Day for Glaciers, MIT Technology Review can report exclusively. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;+ A fun-looking major retrospect of David Bailey’s starry career is opening in Spain.&lt;br /&gt;+ Creepy new horror flick &lt;em&gt;Weapons&lt;/em&gt; is getting rave reviews.&lt;br /&gt;+ This amazing website takes you through Apollo 11’s first landing on the moon in real time.&lt;br /&gt;+ Rest in power Ozzy Osbourne, the first ever heavy metal frontman, and the undisputed Prince of Darkness.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/23/1120571/the-download-whats-next-for-ai-agents-and-how-trump-protects-us-tech-companies-overseas/</guid><pubDate>Wed, 23 Jul 2025 12:10:00 +0000</pubDate></item><item><title>Proton’s new privacy-first AI assistant encrypts all chats, keeps no logs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/protons-new-privacy-first-ai-assistant-encrypts-all-chats-keeps-no-logs/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Privacy-focused productivity tools maker Proton on Wednesday released its AI assistant, called Lumo, which it says prioritizes protecting user data. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the chatbot keeps no logs of your conversations, has end-to-end encryption for storing chats, and offers a ghost mode for conversations that disappear as soon as you close the window.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Available via a web client, as well as Android and iOS apps, Lumo doesn’t require you to have an account to use the chatbot and ask questions. You can upload files to have the chatbot answer questions about them, and if you have a Proton Drive account, you can connect it with Lumo to access files stored in the cloud. While the chatbot has access to the web, it might not find you the latest results if you use it to search.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030408" height="340" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-23-at-5.43.34PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Screenshot by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Proton seems intent on making it clear that its focus is on privacy. The company says Lumo is based on open source models, and it will only depend on them for research and development going forward without utilizing user data to train its models. It also said Lumo relies on zero-access encryption, an encryption method that other Proton products also use, to let users store their conversation history, which can be decrypted on the device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Throughout its blog post about Lumo, Proton emphasized its European base, saying it gives the company a leg up over AI companies based in the U.S. and China when it comes to privacy.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030409" height="206" src="https://techcrunch.com/wp-content/uploads/2025/07/image-26_863148c074.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Proton.me&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Lumo is based upon open-source language models and operates from Proton’s European datacenters. This gives you much greater transparency into the way Lumo works than any other major AI assistant. Unlike Apple Intelligence and others, Lumo is not a partnership with OpenAI or other American or Chinese AI companies, and your queries are never sent to any third parties,” Proton said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is not Proton’s first foray into the fast-developing AI tools space: Last year, it rolled out an AI-powered writing assistant for its Mail product that also runs on the user’s device.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Privacy-focused productivity tools maker Proton on Wednesday released its AI assistant, called Lumo, which it says prioritizes protecting user data. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the chatbot keeps no logs of your conversations, has end-to-end encryption for storing chats, and offers a ghost mode for conversations that disappear as soon as you close the window.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Available via a web client, as well as Android and iOS apps, Lumo doesn’t require you to have an account to use the chatbot and ask questions. You can upload files to have the chatbot answer questions about them, and if you have a Proton Drive account, you can connect it with Lumo to access files stored in the cloud. While the chatbot has access to the web, it might not find you the latest results if you use it to search.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030408" height="340" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-23-at-5.43.34PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Screenshot by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Proton seems intent on making it clear that its focus is on privacy. The company says Lumo is based on open source models, and it will only depend on them for research and development going forward without utilizing user data to train its models. It also said Lumo relies on zero-access encryption, an encryption method that other Proton products also use, to let users store their conversation history, which can be decrypted on the device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Throughout its blog post about Lumo, Proton emphasized its European base, saying it gives the company a leg up over AI companies based in the U.S. and China when it comes to privacy.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030409" height="206" src="https://techcrunch.com/wp-content/uploads/2025/07/image-26_863148c074.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Proton.me&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Lumo is based upon open-source language models and operates from Proton’s European datacenters. This gives you much greater transparency into the way Lumo works than any other major AI assistant. Unlike Apple Intelligence and others, Lumo is not a partnership with OpenAI or other American or Chinese AI companies, and your queries are never sent to any third parties,” Proton said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is not Proton’s first foray into the fast-developing AI tools space: Last year, it rolled out an AI-powered writing assistant for its Mail product that also runs on the user’s device.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/protons-new-privacy-first-ai-assistant-encrypts-all-chats-keeps-no-logs/</guid><pubDate>Wed, 23 Jul 2025 12:49:08 +0000</pubDate></item><item><title>[NEW] Into the Omniverse: How Global Brands Are Scaling Personalized Advertising With AI and 3D Content Generation (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/personalized-advertising-ai-3d-content-generation/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;In today’s fast-evolving digital landscape, marketing teams face increasing pressure to deliver personalized, brand-accurate content at scale and speed. Traditional content creation workflows are often time-consuming, costly and fragmented across multiple tools and teams.&lt;/p&gt;
&lt;p&gt;Universal Scene Description (OpenUSD), an open and extensible 3D framework, is helping teams overcome these challenges by streamlining how marketing content is created, managed and delivered.&lt;/p&gt;
&lt;p&gt;Global brands including Coca-Cola, Moët Hennessy, Nestlé and Unilever are harnessing innovative marketing solutions built on NVIDIA Omniverse — a platform for developing OpenUSD applications. These AI-based solutions dramatically accelerate content generation for advertising and consumer engagement:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moët Hennessy boosts local responsiveness by scaling over 3 million content variations globally, at double the speed.&lt;/li&gt;
&lt;li&gt;Nestlé reduces time and costs associated with advertising by 70% by scaling digital twins.&lt;/li&gt;
&lt;li&gt;Unilever’s content imagery is being created 2x faster and at half the cost of traditional methods, leading to 100% brand consistency and quicker content creation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using the NVIDIA Omniverse Blueprint for precise visual generative AI, solution providers and software developers are enabling organizations to rapidly produce high-quality, brand-accurate, engaging visuals for local markets at scale, streamlining workflows and ensuring creative consistency across every channel.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Content Creation From Weeks to Minutes&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Industry leaders are already seeing the results of tapping AI and OpenUSD for marketing workflows.&lt;/p&gt;
&lt;p&gt;Accenture Song used OpenUSD in Omniverse to launch an AI-powered content service for Nestlé. The content service creates exact 3D virtual replicas of products for e-commerce and digital media channels, demonstrating the impact of digital twins and advanced 3D workflows.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class="wp-image-83270 aligncenter" height="336" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/NespressoOption2-scaled.png" width="1007" /&gt;Accenture Song, Nestlé&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;SKAI Intelligence, a global provider of AI-powered content creation solutions, recently debuted the world’s first end-to-end, retail-focused AI-generated content production pipeline built entirely on NVIDIA Omniverse. The browser-based, AI-native workflow automates the entire content generation process — from product scanning and modeling to animation, lighting and rendering — and delivers up to 95% faster production speeds versus traditional methods.&lt;/p&gt;
&lt;p&gt;Katana Studio, a real-time 3D content creation studio and developer behind the COATcreate tool, has used NVIDIA Omniverse to streamline automotive marketing for Nissan, significantly reducing asset creation timelines and costs.&lt;/p&gt;
&lt;p&gt;INDG, a digital content automation company, developed the software-as-a-service platform Grip on NVIDIA Omniverse and OpenUSD to empower global brands like Moët Hennessy and Coca-Cola to produce high-quality, brand-consistent content across markets.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class="size-full wp-image-83273 aligncenter" height="450" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/CloudyBay1-ezgif.com-video-to-gif-converter.gif" width="800" /&gt;Grip, Moët Hennessy&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;By centralizing OpenUSD asset libraries and creating digital twins of products, Grip enables teams to quickly assemble, adapt and deploy campaign-ready content in just minutes — rather than weeks. This approach directly addresses the challenges of slow, costly and inconsistent manual localization processes that have long hindered marketing efforts.&lt;/p&gt;
&lt;p&gt;Grip relies on rules-based AI, NVIDIA RTX GPUs and the NVIDIA AI Enterprise software platform to ensure brand consistency across diverse markets. The Grip platform also integrates Bria’s visual generative AI models to enhance automated content production at scale. Grip’s content engine acts as a virtual art director, codifying and enforcing brand guidelines for every asset while dynamically adjusting composition, lighting and product details.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Dive deeper into Grip’s innovative approach at the company’s upcoming &lt;/i&gt;&lt;i&gt;session at SIGGRAPH&lt;/i&gt;&lt;i&gt;, a computer graphics conference taking place Aug. 10-14 at the Vancouver Convention Centre and online.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Unilever, in collaboration with Collective World, is using Omniverse, OpenUSD and photorealistic 3D digital twins to accelerate content production. Unilever’s new content-creation workflow, powered by real-time 3D rendering, has cut production timelines from months to days, halved costs and enabled consistent brand experiences across markets with a 5x reduction in content duplication.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class=" wp-image-83276 aligncenter" height="541" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/nexxus-26-1920-1080.jpg" width="962" /&gt;Collective World, Unilever, Nexxus&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Monks, a digital-first marketing and technology services company, is also using Omniverse and OpenUSD to drive hyperpersonalized and collaborative product experiences. The technologies allow Monks’ services to empower brands to virtually explore and customize product designs in real time.&lt;/p&gt;
&lt;p&gt;Hear Monks representatives discuss how they’re building automated pipelines and agentic systems to ease deployment and scaling of AI-driven marketing operations across the enterprise:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Get Plugged Into the World of OpenUSD&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Discover the future of 3D content creation and connect with the OpenUSD community by joining NVIDIA at SIGGRAPH. Highlights will include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;A special address &lt;/b&gt;on Monday, Aug. 11, with NVIDIA AI research leaders Sanja Fidler, Aaron Lefohn and Ming-Yu Liu, who’ll chart the next frontier in computer graphics and physical AI.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;OpenUSD Day, &lt;/b&gt;taking place on Wednesday, Aug. 13, features sessions and a developer meetup where developers and industry leaders can explore how OpenUSD is adopted across every application, from content creation and simulation to physical AI.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Hands-on OpenUSD&lt;/b&gt; training for all skill levels, including the first-ever in-person opportunity to receive USD certification.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Discover why developers and 3D practitioners are using OpenUSD and learn how to optimize 3D workflows with the self-paced “Learn OpenUSD” curriculum for 3D developers and practitioners, available for free through the NVIDIA Deep Learning Institute.&lt;/p&gt;
&lt;p&gt;Explore the Alliance for OpenUSD forum and the AOUSD website.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following NVIDIA Omniverse on &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Medium&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;i&gt;Featured image courtesy &lt;/i&gt;&lt;i&gt;of Grip, Moët Hennessy.&lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;In today’s fast-evolving digital landscape, marketing teams face increasing pressure to deliver personalized, brand-accurate content at scale and speed. Traditional content creation workflows are often time-consuming, costly and fragmented across multiple tools and teams.&lt;/p&gt;
&lt;p&gt;Universal Scene Description (OpenUSD), an open and extensible 3D framework, is helping teams overcome these challenges by streamlining how marketing content is created, managed and delivered.&lt;/p&gt;
&lt;p&gt;Global brands including Coca-Cola, Moët Hennessy, Nestlé and Unilever are harnessing innovative marketing solutions built on NVIDIA Omniverse — a platform for developing OpenUSD applications. These AI-based solutions dramatically accelerate content generation for advertising and consumer engagement:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moët Hennessy boosts local responsiveness by scaling over 3 million content variations globally, at double the speed.&lt;/li&gt;
&lt;li&gt;Nestlé reduces time and costs associated with advertising by 70% by scaling digital twins.&lt;/li&gt;
&lt;li&gt;Unilever’s content imagery is being created 2x faster and at half the cost of traditional methods, leading to 100% brand consistency and quicker content creation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using the NVIDIA Omniverse Blueprint for precise visual generative AI, solution providers and software developers are enabling organizations to rapidly produce high-quality, brand-accurate, engaging visuals for local markets at scale, streamlining workflows and ensuring creative consistency across every channel.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Content Creation From Weeks to Minutes&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Industry leaders are already seeing the results of tapping AI and OpenUSD for marketing workflows.&lt;/p&gt;
&lt;p&gt;Accenture Song used OpenUSD in Omniverse to launch an AI-powered content service for Nestlé. The content service creates exact 3D virtual replicas of products for e-commerce and digital media channels, demonstrating the impact of digital twins and advanced 3D workflows.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class="wp-image-83270 aligncenter" height="336" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/NespressoOption2-scaled.png" width="1007" /&gt;Accenture Song, Nestlé&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;SKAI Intelligence, a global provider of AI-powered content creation solutions, recently debuted the world’s first end-to-end, retail-focused AI-generated content production pipeline built entirely on NVIDIA Omniverse. The browser-based, AI-native workflow automates the entire content generation process — from product scanning and modeling to animation, lighting and rendering — and delivers up to 95% faster production speeds versus traditional methods.&lt;/p&gt;
&lt;p&gt;Katana Studio, a real-time 3D content creation studio and developer behind the COATcreate tool, has used NVIDIA Omniverse to streamline automotive marketing for Nissan, significantly reducing asset creation timelines and costs.&lt;/p&gt;
&lt;p&gt;INDG, a digital content automation company, developed the software-as-a-service platform Grip on NVIDIA Omniverse and OpenUSD to empower global brands like Moët Hennessy and Coca-Cola to produce high-quality, brand-consistent content across markets.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class="size-full wp-image-83273 aligncenter" height="450" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/CloudyBay1-ezgif.com-video-to-gif-converter.gif" width="800" /&gt;Grip, Moët Hennessy&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;By centralizing OpenUSD asset libraries and creating digital twins of products, Grip enables teams to quickly assemble, adapt and deploy campaign-ready content in just minutes — rather than weeks. This approach directly addresses the challenges of slow, costly and inconsistent manual localization processes that have long hindered marketing efforts.&lt;/p&gt;
&lt;p&gt;Grip relies on rules-based AI, NVIDIA RTX GPUs and the NVIDIA AI Enterprise software platform to ensure brand consistency across diverse markets. The Grip platform also integrates Bria’s visual generative AI models to enhance automated content production at scale. Grip’s content engine acts as a virtual art director, codifying and enforcing brand guidelines for every asset while dynamically adjusting composition, lighting and product details.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Dive deeper into Grip’s innovative approach at the company’s upcoming &lt;/i&gt;&lt;i&gt;session at SIGGRAPH&lt;/i&gt;&lt;i&gt;, a computer graphics conference taking place Aug. 10-14 at the Vancouver Convention Centre and online.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Unilever, in collaboration with Collective World, is using Omniverse, OpenUSD and photorealistic 3D digital twins to accelerate content production. Unilever’s new content-creation workflow, powered by real-time 3D rendering, has cut production timelines from months to days, halved costs and enabled consistent brand experiences across markets with a 5x reduction in content duplication.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&lt;img alt="alt" class=" wp-image-83276 aligncenter" height="541" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/nexxus-26-1920-1080.jpg" width="962" /&gt;Collective World, Unilever, Nexxus&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Monks, a digital-first marketing and technology services company, is also using Omniverse and OpenUSD to drive hyperpersonalized and collaborative product experiences. The technologies allow Monks’ services to empower brands to virtually explore and customize product designs in real time.&lt;/p&gt;
&lt;p&gt;Hear Monks representatives discuss how they’re building automated pipelines and agentic systems to ease deployment and scaling of AI-driven marketing operations across the enterprise:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Get Plugged Into the World of OpenUSD&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Discover the future of 3D content creation and connect with the OpenUSD community by joining NVIDIA at SIGGRAPH. Highlights will include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;A special address &lt;/b&gt;on Monday, Aug. 11, with NVIDIA AI research leaders Sanja Fidler, Aaron Lefohn and Ming-Yu Liu, who’ll chart the next frontier in computer graphics and physical AI.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;OpenUSD Day, &lt;/b&gt;taking place on Wednesday, Aug. 13, features sessions and a developer meetup where developers and industry leaders can explore how OpenUSD is adopted across every application, from content creation and simulation to physical AI.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Hands-on OpenUSD&lt;/b&gt; training for all skill levels, including the first-ever in-person opportunity to receive USD certification.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Discover why developers and 3D practitioners are using OpenUSD and learn how to optimize 3D workflows with the self-paced “Learn OpenUSD” curriculum for 3D developers and practitioners, available for free through the NVIDIA Deep Learning Institute.&lt;/p&gt;
&lt;p&gt;Explore the Alliance for OpenUSD forum and the AOUSD website.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following NVIDIA Omniverse on &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Medium&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;i&gt;Featured image courtesy &lt;/i&gt;&lt;i&gt;of Grip, Moët Hennessy.&lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/personalized-advertising-ai-3d-content-generation/</guid><pubDate>Wed, 23 Jul 2025 13:00:17 +0000</pubDate></item><item><title>[NEW] Eight months in, Swedish unicorn Lovable crosses the $100M ARR milestone (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/eight-months-in-swedish-unicorn-lovable-crosses-the-100m-arr-milestone/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Summer-2025-Lovable-Team-Picture.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Less than a week after it became Europe’s latest unicorn, Swedish vibe coding startup Lovable is now also a centaur — a company with more than $100 million in annual recurring revenue (ARR).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable took only eight months since its launch to get here, thanks to the skyrocketing popularity of its AI-powered website and app builder. The startup claims it now has more than 2.3 million active users, and last reported 180,000 paying subscribers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With only 45 full-time employees, and 14 open positions on its careers page, that makes for an impressive employee-to-revenue ratio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscriptions seem to be driving the bulk of Lovable’s revenue, but the company isn’t prioritizing sales at all costs. Shortly after Lovable said it had reached ARR of $75 million in June, its CEO Anton Osika wrote on X that Lovable had “lost $1.5 million ARR in a single day” because it had moved all users on its Team tier to its less expensive Pro tier, which now also accommodates collaboration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Teams plan is now being replaced by a Business tier, which sits between the Pro and custom Enterprise offerings. The new plan offers business-focused features such as self-serve, Single Sign-On (SSO), templates, private projects that won’t be visible to the entire team, and the option to opt-out from having your data be used for training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable already has a slate of large customers like Klarna, HubSpot, and Photoroom, but there are still notable barriers and concerns around vibe coding among enterprises — where the big money is. This new tier could help Lovable find intermediary use cases and drive more businesses to use its tools for more than prototyping, which is what the startup says most people use it for today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This has been one focus for the company, and Osika recently said that businesses were driving significant revenue from projects built with Lovable.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup says more than 10 million projects have been created on Lovable to date. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $100 million ARR club isn’t large, especially in Europe, but it is growing thanks to tailwinds from all things AI. In April, Nvidia-backed B2B AI video platform Synthesia also surpassed that milestone — though it was founded in 2017, not late 2024.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Summer-2025-Lovable-Team-Picture.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Less than a week after it became Europe’s latest unicorn, Swedish vibe coding startup Lovable is now also a centaur — a company with more than $100 million in annual recurring revenue (ARR).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable took only eight months since its launch to get here, thanks to the skyrocketing popularity of its AI-powered website and app builder. The startup claims it now has more than 2.3 million active users, and last reported 180,000 paying subscribers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With only 45 full-time employees, and 14 open positions on its careers page, that makes for an impressive employee-to-revenue ratio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscriptions seem to be driving the bulk of Lovable’s revenue, but the company isn’t prioritizing sales at all costs. Shortly after Lovable said it had reached ARR of $75 million in June, its CEO Anton Osika wrote on X that Lovable had “lost $1.5 million ARR in a single day” because it had moved all users on its Team tier to its less expensive Pro tier, which now also accommodates collaboration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Teams plan is now being replaced by a Business tier, which sits between the Pro and custom Enterprise offerings. The new plan offers business-focused features such as self-serve, Single Sign-On (SSO), templates, private projects that won’t be visible to the entire team, and the option to opt-out from having your data be used for training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable already has a slate of large customers like Klarna, HubSpot, and Photoroom, but there are still notable barriers and concerns around vibe coding among enterprises — where the big money is. This new tier could help Lovable find intermediary use cases and drive more businesses to use its tools for more than prototyping, which is what the startup says most people use it for today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This has been one focus for the company, and Osika recently said that businesses were driving significant revenue from projects built with Lovable.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup says more than 10 million projects have been created on Lovable to date. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $100 million ARR club isn’t large, especially in Europe, but it is growing thanks to tailwinds from all things AI. In April, Nvidia-backed B2B AI video platform Synthesia also surpassed that milestone — though it was founded in 2017, not late 2024.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/eight-months-in-swedish-unicorn-lovable-crosses-the-100m-arr-milestone/</guid><pubDate>Wed, 23 Jul 2025 13:08:00 +0000</pubDate></item><item><title>[NEW] AI’s talent arms race is starting to look like pro sports (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/ais-talent-arms-race-is-starting-to-look-like-pro-sports/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI is entering a new phase where access to top talent is becoming as important as, if not more important than, compute or data. The market for AI researchers is so overheated, it’s starting to look a lot like pro sports — complete with outsized contracts and unprecedented infrastructure needs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan chatted with Deedy Das, principal at Menlo Ventures. Das has seen this shift from multiple angles, first as an engineer and product leader at Google, Facebook, and AI startup Glean, and now as an investor helping technical founders figure out how to build enduring companies in this new AI landscape.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The reason people are being paid this much is because there’s a disparity between the prize to be made in a short amount of time and the amount of people who have the talent to get you to that prize,” Das explained. “As long as that gap remains, you pay up and you get the talent. […] Over time, there will be less prize in AI. I imagine a lot of that value will be captured by a few people, and there will be a lot more talent to fill the supply.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Meta is spending billions on both compute and researchers.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How compensation packages and acquisitions are warping startup hiring and retention.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What motivates top researchers to leave, even when they’ve already made millions.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How VCs are thinking about key-person risk in the AI era.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI is entering a new phase where access to top talent is becoming as important as, if not more important than, compute or data. The market for AI researchers is so overheated, it’s starting to look a lot like pro sports — complete with outsized contracts and unprecedented infrastructure needs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan chatted with Deedy Das, principal at Menlo Ventures. Das has seen this shift from multiple angles, first as an engineer and product leader at Google, Facebook, and AI startup Glean, and now as an investor helping technical founders figure out how to build enduring companies in this new AI landscape.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The reason people are being paid this much is because there’s a disparity between the prize to be made in a short amount of time and the amount of people who have the talent to get you to that prize,” Das explained. “As long as that gap remains, you pay up and you get the talent. […] Over time, there will be less prize in AI. I imagine a lot of that value will be captured by a few people, and there will be a lot more talent to fill the supply.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Meta is spending billions on both compute and researchers.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How compensation packages and acquisitions are warping startup hiring and retention.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What motivates top researchers to leave, even when they’ve already made millions.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How VCs are thinking about key-person risk in the AI era.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/ais-talent-arms-race-is-starting-to-look-like-pro-sports/</guid><pubDate>Wed, 23 Jul 2025 14:35:00 +0000</pubDate></item><item><title>[NEW] Aeneas transforms how historians connect the past (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/aeneas-transforms-how-historians-connect-the-past/</link><description>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Research&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-07-23"&gt;23 July 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Aeneas team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="alt" class="picture__image" height="603" src="https://lh3.googleusercontent.com/eMe8bNk3nHJU_unVGcgIUKuPiI-it3NstOK0wixMnl_EwVI5RudgU2W6ktg0RMLsEovZyA8ckoMg2t9_ARQKev-HZhTgFzKTQtU4UC6dr6hektPG=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Introducing the first model for contextualizing ancient inscriptions, designed to help historians better interpret, attribute and restore fragmentary texts.&lt;/p&gt;&lt;p&gt;Writing was everywhere in the Roman world — etched onto everything from imperial monuments to everyday objects. From political graffiti, love poems and epitaphs to business transactions, birthday invitations and magical spells, inscriptions offer modern historians rich insights into the diversity of everyday life across the Roman world.&lt;/p&gt;&lt;p&gt;Often, these texts are fragmentary, weathered or deliberately defaced. Restoring, dating and placing them is nearly impossible without contextual information, especially when comparing similar inscriptions.&lt;/p&gt;&lt;p&gt;Today, we’re publishing a paper in Nature introducing Aeneas, the first artificial intelligence (AI) model for contextualizing ancient inscriptions.&lt;/p&gt;&lt;p&gt;When working with ancient inscriptions, historians traditionally rely on their expertise and specialized resources to identify “parallels” — which are texts that share similarities in wording, syntax, standardized formulas or provenance.&lt;/p&gt;&lt;p&gt;Aeneas greatly accelerates this complex and time-consuming work. It reasons across thousands of Latin inscriptions, retrieving textual and contextual parallels in seconds that allow historians to interpret and build upon&amp;nbsp;the model’s findings.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Our model can also be adapted to other ancient languages, scripts and media, from papyri to coinage, expanding its capabilities to help draw connections across a wider range of historical evidence.&lt;/p&gt;&lt;p&gt;We co-developed Aeneas with the University of Nottingham, and in partnership with researchers at the Universities of Warwick, Oxford and Athens University of Economics and Business (AUEB). This work was part of a wider effort to explore how generative AI can help historians better identify and interpret parallels at scale.&lt;/p&gt;&lt;p&gt;We want this research to benefit as many people as possible, so we’re making an interactive version of Aeneas freely-available to researchers, students, educators, museum professionals and more at predictingthepast.com. To support further research, we’re also open-sourcing our code and dataset.&lt;/p&gt;&lt;h2&gt;Aeneas’ advanced capabilities&lt;/h2&gt;&lt;p&gt;Named after the wandering hero of Graeco-Roman mythology, Aeneas builds upon Ithaca, our earlier work using AI to restore, date and place ancient Greek inscriptions.&lt;/p&gt;&lt;p&gt;Aeneas goes a step further, helping historians interpret and contextualize a text, give meaning to isolated fragments, draw richer conclusions and piece together a better understanding of ancient history.&lt;/p&gt;&lt;p&gt;Our model’s advanced capabilities include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Parallels search:&lt;/strong&gt; It searches for parallels across a vast collection of Latin inscriptions. By turning each text into a kind of historical fingerprint, Aeneas identifies deep connections that can help historians situate inscriptions within their broader historical context.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Processing multimodal input:&lt;/strong&gt; Aeneas is the first model to determine a text's geographical provenance using multimodal inputs. It analyzes both text and visual information, like images of an inscription.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Restoring gaps of unknown length:&lt;/strong&gt; For the first time, Aeneas can restore gaps in texts where the missing length is unknown. This makes it a more versatile tool for historians dealing with heavily damaged material.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;State-of-the-art performance:&lt;/strong&gt; Aeneas sets a new state-of-the-art benchmark in restoring damaged texts and predicting when and where they were written.&lt;/li&gt;&lt;/ul&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-40a13ded-d615-48fd-8864-760b811b1d5a"&gt;
    &lt;p&gt;Animation of a restored bronze military diploma from Sardinia 113/14 C.E. (&lt;i&gt;CIL&lt;/i&gt; XVI, 60).&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;How Aeneas works&lt;/h2&gt;&lt;p&gt;Aeneas is a multimodal generative neural network that takes an inscription’s text and image as input. To train Aeneas, we curated a large and reliable dataset, drawing from decades of work by historians to create digital collections, especially the Epigraphic Database Roma (EDR), Epigraphic Database Heidelberg (EDH) and Epigraphic Database Clauss Slaby (EDCS-ELT).&lt;/p&gt;&lt;p&gt;We cleaned, harmonized and linked these records into a single machine-actionable dataset that we refer to as the Latin Epigraphic Dataset (LED), comprising over 176,000 Latin inscriptions from across the ancient Roman world.&lt;/p&gt;&lt;p&gt;Our model uses a transformer-based decoder to process the textual input of an inscription. Specialized networks handle character restoration and dating using text, while geographical attribution also uses images of the inscriptions as input. The decoder retrieves similar inscriptions from the LED, ranked by relevance.&lt;/p&gt;&lt;p&gt;For each inscription, Aeneas’ contextualization mechanism retrieves a list of parallels using a technique called “embeddings” — encoding the textual and contextual information of each inscription into a kind of historical fingerprint containing details of what the text says, its language, when and where it came from, and how it relates to other inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-a19ad875-18af-40dd-984b-09593964c0f6"&gt;
    &lt;p&gt;Diagram of Aeneas’ architecture showing how the model takes text and image input to generate province, date and restoration predictions.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;State-of-the-art performance&lt;/h2&gt;&lt;p&gt;Aeneas groups inscriptions by date of writing far more clearly than other general-purpose models also trained on Latin, as shown in the visualization below.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-ebcd9939-3f0e-401d-af55-841453a2057b"&gt;
    &lt;p&gt;Uniform Manifold Approximation and Projection (UMAP) visualization illustrating the chronological attribution of Aeneas’ historically rich embeddings compared to generic large language model textual embeddings.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas restores damaged inscriptions with a Top-20 accuracy of 73% in gaps of up to ten characters. This only decreases to 58% when the restoration length is unknown - itself an incredibly challenging task. It also shows its reasoning in an interpretable way, providing saliency maps that highlight which parts of the inputs influenced its predictions. Thanks to its use of visual data, our model can attribute an inscription to one of 62 ancient Roman provinces with 72% accuracy. For dating, Aeneas places a text within 13 years of the date ranges provided by historians.&lt;/p&gt;&lt;h2&gt;A new lens on historical debates&lt;/h2&gt;&lt;p&gt;To test Aeneas’ capabilities on an ongoing research debate, we gave it one of the most famous Roman inscriptions: the &lt;i&gt;Res Gestae Divi Augusti,&lt;/i&gt; Emperor Augustus’ first-person account of his achievements.&lt;/p&gt;&lt;p&gt;Historians have long-argued about the dating of this inscription. Rather than predicting a single fixed date, Aeneas produced a detailed distribution of possible dates, showing two distinct peaks, with one smaller peak around 10-1  BCE and a larger, more confident peak between 10-20 CE. These results captured both prevailing dating hypotheses in a quantitative way.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-c4acf043-f24d-41a6-93c4-8a28d712acce"&gt;
    &lt;p&gt;Histogram showing Aeneas’ chronological attribution prediction for the &lt;i&gt;Res Gestae&lt;/i&gt;, which models scholarly debates around dating this famous inscription.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas based its predictions on subtle linguistic features and historical markers such as official titles and monuments mentioned in the text. By turning the dating question into a probabilistic estimate grounded in linguistic and contextual data, our model offers a new, quantitative way of engaging with long-standing historical debates.&lt;/p&gt;&lt;p&gt;Most importantly, Aeneas also retrieved many relevant parallels from imperial legal texts tied to Augustus’ legacy, highlighting how the ideology of empire was reproduced across media and geography.&lt;/p&gt;&lt;h2&gt;Advancing historical research collaboratively&lt;/h2&gt;&lt;p&gt;To assess Aeneas’ impact as an aid for research, we conducted a large-scale Historian and AI collaborative study. We invited twenty-three historians who regularly work with inscriptions to restore, date and place a set of texts using Aeneas.&lt;/p&gt;&lt;p&gt;Our evaluation, summarized in the table below, shows how the most effective results were achieved when historians used Aeneas’ contextual information alongside its predictions for restoring and attributing Roman inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-711d77ad-af97-423c-8f11-4c707bc71eb5"&gt;
    &lt;p&gt;Table showing historians’ performance on three epigraphic tasks (restoration, geographical attribution, dating) using 60 inscriptions from our database test set. Tasks were first performed independently, then with Aeneas’ parallels information, or parallels and predictions together.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas helped the historians in our study identify new parallels and increased their confidence when tackling complex epigraphic tasks. Historians consistently highlighted Aeneas’ value in accelerating their work and expanding the range of most relevant parallel inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;Aeneas’ parallels completely changed my perception of the inscription. It noticed details that made all the difference for restoring and chronologically attributing the text.&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Anonymised historian from our study&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Sharing the tools, shaping the future&lt;/h2&gt;&lt;p&gt;Aeneas is designed to integrate within historians' existing research workflows. By combining expert knowledge with machine learning, it opens up a collaborative process, offering interpretable suggestions that serve as valuable starting points for historical inquiry.&lt;/p&gt;&lt;p&gt;As part of today’s release, we’re upgrading Ithaca, our ancient Greek model, to be powered by Aeneas and include the contextualization function, restorations of unknown length and better performance overall.&lt;/p&gt;&lt;p&gt;We’ve also co-designed a new teaching syllabus for bridging technical skills with historical thinking in the classroom. This syllabus aligns with AI literacy initiatives, including the European Commission's Digital Competences Framework for Citizens (DigComp 2.2), UNESCO’s AI Competency Framework for Students, and the preview of European Commission and the Organization for Economic Cooperation and Development (OECD) AILit Framework.&lt;/p&gt;&lt;p&gt;The Aeneas team is continuing to partner with diverse subject matter experts, using Aeneas to help shed light to our ancient past — with more to come.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more about Aeneas&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The research was co-led by Yannis Assael and Thea Sommerschield.&lt;/p&gt;&lt;p&gt;Contributors include: Alison Cooley, Brendan Shillingford, John Pavlopoulos, Priyanka Suresh, Bailey Herms, Jonathan Prag, Alex Mullen and Shakir Mohamed. The Aeneas web interface was developed by Justin Grayston, Benjamin Maynard, and Nicholas Dietrich, and is powered by Google Cloud.&lt;/p&gt;&lt;p&gt;The syllabus was developed by Robbe Wulgaert, Sint-Lievenscollege, Ghent, Belgium.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</description><content:encoded>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Research&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-07-23"&gt;23 July 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Aeneas team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="alt" class="picture__image" height="603" src="https://lh3.googleusercontent.com/eMe8bNk3nHJU_unVGcgIUKuPiI-it3NstOK0wixMnl_EwVI5RudgU2W6ktg0RMLsEovZyA8ckoMg2t9_ARQKev-HZhTgFzKTQtU4UC6dr6hektPG=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Introducing the first model for contextualizing ancient inscriptions, designed to help historians better interpret, attribute and restore fragmentary texts.&lt;/p&gt;&lt;p&gt;Writing was everywhere in the Roman world — etched onto everything from imperial monuments to everyday objects. From political graffiti, love poems and epitaphs to business transactions, birthday invitations and magical spells, inscriptions offer modern historians rich insights into the diversity of everyday life across the Roman world.&lt;/p&gt;&lt;p&gt;Often, these texts are fragmentary, weathered or deliberately defaced. Restoring, dating and placing them is nearly impossible without contextual information, especially when comparing similar inscriptions.&lt;/p&gt;&lt;p&gt;Today, we’re publishing a paper in Nature introducing Aeneas, the first artificial intelligence (AI) model for contextualizing ancient inscriptions.&lt;/p&gt;&lt;p&gt;When working with ancient inscriptions, historians traditionally rely on their expertise and specialized resources to identify “parallels” — which are texts that share similarities in wording, syntax, standardized formulas or provenance.&lt;/p&gt;&lt;p&gt;Aeneas greatly accelerates this complex and time-consuming work. It reasons across thousands of Latin inscriptions, retrieving textual and contextual parallels in seconds that allow historians to interpret and build upon&amp;nbsp;the model’s findings.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Our model can also be adapted to other ancient languages, scripts and media, from papyri to coinage, expanding its capabilities to help draw connections across a wider range of historical evidence.&lt;/p&gt;&lt;p&gt;We co-developed Aeneas with the University of Nottingham, and in partnership with researchers at the Universities of Warwick, Oxford and Athens University of Economics and Business (AUEB). This work was part of a wider effort to explore how generative AI can help historians better identify and interpret parallels at scale.&lt;/p&gt;&lt;p&gt;We want this research to benefit as many people as possible, so we’re making an interactive version of Aeneas freely-available to researchers, students, educators, museum professionals and more at predictingthepast.com. To support further research, we’re also open-sourcing our code and dataset.&lt;/p&gt;&lt;h2&gt;Aeneas’ advanced capabilities&lt;/h2&gt;&lt;p&gt;Named after the wandering hero of Graeco-Roman mythology, Aeneas builds upon Ithaca, our earlier work using AI to restore, date and place ancient Greek inscriptions.&lt;/p&gt;&lt;p&gt;Aeneas goes a step further, helping historians interpret and contextualize a text, give meaning to isolated fragments, draw richer conclusions and piece together a better understanding of ancient history.&lt;/p&gt;&lt;p&gt;Our model’s advanced capabilities include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Parallels search:&lt;/strong&gt; It searches for parallels across a vast collection of Latin inscriptions. By turning each text into a kind of historical fingerprint, Aeneas identifies deep connections that can help historians situate inscriptions within their broader historical context.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Processing multimodal input:&lt;/strong&gt; Aeneas is the first model to determine a text's geographical provenance using multimodal inputs. It analyzes both text and visual information, like images of an inscription.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Restoring gaps of unknown length:&lt;/strong&gt; For the first time, Aeneas can restore gaps in texts where the missing length is unknown. This makes it a more versatile tool for historians dealing with heavily damaged material.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;State-of-the-art performance:&lt;/strong&gt; Aeneas sets a new state-of-the-art benchmark in restoring damaged texts and predicting when and where they were written.&lt;/li&gt;&lt;/ul&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-40a13ded-d615-48fd-8864-760b811b1d5a"&gt;
    &lt;p&gt;Animation of a restored bronze military diploma from Sardinia 113/14 C.E. (&lt;i&gt;CIL&lt;/i&gt; XVI, 60).&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;How Aeneas works&lt;/h2&gt;&lt;p&gt;Aeneas is a multimodal generative neural network that takes an inscription’s text and image as input. To train Aeneas, we curated a large and reliable dataset, drawing from decades of work by historians to create digital collections, especially the Epigraphic Database Roma (EDR), Epigraphic Database Heidelberg (EDH) and Epigraphic Database Clauss Slaby (EDCS-ELT).&lt;/p&gt;&lt;p&gt;We cleaned, harmonized and linked these records into a single machine-actionable dataset that we refer to as the Latin Epigraphic Dataset (LED), comprising over 176,000 Latin inscriptions from across the ancient Roman world.&lt;/p&gt;&lt;p&gt;Our model uses a transformer-based decoder to process the textual input of an inscription. Specialized networks handle character restoration and dating using text, while geographical attribution also uses images of the inscriptions as input. The decoder retrieves similar inscriptions from the LED, ranked by relevance.&lt;/p&gt;&lt;p&gt;For each inscription, Aeneas’ contextualization mechanism retrieves a list of parallels using a technique called “embeddings” — encoding the textual and contextual information of each inscription into a kind of historical fingerprint containing details of what the text says, its language, when and where it came from, and how it relates to other inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-a19ad875-18af-40dd-984b-09593964c0f6"&gt;
    &lt;p&gt;Diagram of Aeneas’ architecture showing how the model takes text and image input to generate province, date and restoration predictions.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;State-of-the-art performance&lt;/h2&gt;&lt;p&gt;Aeneas groups inscriptions by date of writing far more clearly than other general-purpose models also trained on Latin, as shown in the visualization below.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-ebcd9939-3f0e-401d-af55-841453a2057b"&gt;
    &lt;p&gt;Uniform Manifold Approximation and Projection (UMAP) visualization illustrating the chronological attribution of Aeneas’ historically rich embeddings compared to generic large language model textual embeddings.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas restores damaged inscriptions with a Top-20 accuracy of 73% in gaps of up to ten characters. This only decreases to 58% when the restoration length is unknown - itself an incredibly challenging task. It also shows its reasoning in an interpretable way, providing saliency maps that highlight which parts of the inputs influenced its predictions. Thanks to its use of visual data, our model can attribute an inscription to one of 62 ancient Roman provinces with 72% accuracy. For dating, Aeneas places a text within 13 years of the date ranges provided by historians.&lt;/p&gt;&lt;h2&gt;A new lens on historical debates&lt;/h2&gt;&lt;p&gt;To test Aeneas’ capabilities on an ongoing research debate, we gave it one of the most famous Roman inscriptions: the &lt;i&gt;Res Gestae Divi Augusti,&lt;/i&gt; Emperor Augustus’ first-person account of his achievements.&lt;/p&gt;&lt;p&gt;Historians have long-argued about the dating of this inscription. Rather than predicting a single fixed date, Aeneas produced a detailed distribution of possible dates, showing two distinct peaks, with one smaller peak around 10-1  BCE and a larger, more confident peak between 10-20 CE. These results captured both prevailing dating hypotheses in a quantitative way.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-c4acf043-f24d-41a6-93c4-8a28d712acce"&gt;
    &lt;p&gt;Histogram showing Aeneas’ chronological attribution prediction for the &lt;i&gt;Res Gestae&lt;/i&gt;, which models scholarly debates around dating this famous inscription.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas based its predictions on subtle linguistic features and historical markers such as official titles and monuments mentioned in the text. By turning the dating question into a probabilistic estimate grounded in linguistic and contextual data, our model offers a new, quantitative way of engaging with long-standing historical debates.&lt;/p&gt;&lt;p&gt;Most importantly, Aeneas also retrieved many relevant parallels from imperial legal texts tied to Augustus’ legacy, highlighting how the ideology of empire was reproduced across media and geography.&lt;/p&gt;&lt;h2&gt;Advancing historical research collaboratively&lt;/h2&gt;&lt;p&gt;To assess Aeneas’ impact as an aid for research, we conducted a large-scale Historian and AI collaborative study. We invited twenty-three historians who regularly work with inscriptions to restore, date and place a set of texts using Aeneas.&lt;/p&gt;&lt;p&gt;Our evaluation, summarized in the table below, shows how the most effective results were achieved when historians used Aeneas’ contextual information alongside its predictions for restoring and attributing Roman inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-711d77ad-af97-423c-8f11-4c707bc71eb5"&gt;
    &lt;p&gt;Table showing historians’ performance on three epigraphic tasks (restoration, geographical attribution, dating) using 60 inscriptions from our database test set. Tasks were first performed independently, then with Aeneas’ parallels information, or parallels and predictions together.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Aeneas helped the historians in our study identify new parallels and increased their confidence when tackling complex epigraphic tasks. Historians consistently highlighted Aeneas’ value in accelerating their work and expanding the range of most relevant parallel inscriptions.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;Aeneas’ parallels completely changed my perception of the inscription. It noticed details that made all the difference for restoring and chronologically attributing the text.&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Anonymised historian from our study&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Sharing the tools, shaping the future&lt;/h2&gt;&lt;p&gt;Aeneas is designed to integrate within historians' existing research workflows. By combining expert knowledge with machine learning, it opens up a collaborative process, offering interpretable suggestions that serve as valuable starting points for historical inquiry.&lt;/p&gt;&lt;p&gt;As part of today’s release, we’re upgrading Ithaca, our ancient Greek model, to be powered by Aeneas and include the contextualization function, restorations of unknown length and better performance overall.&lt;/p&gt;&lt;p&gt;We’ve also co-designed a new teaching syllabus for bridging technical skills with historical thinking in the classroom. This syllabus aligns with AI literacy initiatives, including the European Commission's Digital Competences Framework for Citizens (DigComp 2.2), UNESCO’s AI Competency Framework for Students, and the preview of European Commission and the Organization for Economic Cooperation and Development (OECD) AILit Framework.&lt;/p&gt;&lt;p&gt;The Aeneas team is continuing to partner with diverse subject matter experts, using Aeneas to help shed light to our ancient past — with more to come.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more about Aeneas&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The research was co-led by Yannis Assael and Thea Sommerschield.&lt;/p&gt;&lt;p&gt;Contributors include: Alison Cooley, Brendan Shillingford, John Pavlopoulos, Priyanka Suresh, Bailey Herms, Jonathan Prag, Alex Mullen and Shakir Mohamed. The Aeneas web interface was developed by Justin Grayston, Benjamin Maynard, and Nicholas Dietrich, and is powered by Google Cloud.&lt;/p&gt;&lt;p&gt;The syllabus was developed by Robbe Wulgaert, Sint-Lievenscollege, Ghent, Belgium.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/aeneas-transforms-how-historians-connect-the-past/</guid><pubDate>Wed, 23 Jul 2025 14:59:00 +0000</pubDate></item><item><title>[NEW] Early Anthropic hire raises $15M to insure AI agents and help startups deploy safely (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/former-anthropic-exec-raises-15m-to-insure-ai-agents-and-help-startups-deploy-safely/</link><description>&lt;p&gt;A new startup founded by an early Anthropic hire has raised $15 million to solve one of the most pressing challenges facing enterprises today: how to deploy artificial intelligence systems without risking catastrophic failures that could damage their businesses.&lt;/p&gt;&lt;p&gt;The Artificial Intelligence Underwriting Company (AIUC), which launches publicly today, combines insurance coverage with rigorous safety standards and independent audits to give companies confidence in deploying AI agents — autonomous software systems that can perform complex tasks like customer service, coding, and data analysis.&lt;/p&gt;&lt;p&gt;The seed funding round was led by Nat Friedman, former GitHub CEO, through his firm NFDG, with participation from Emergence Capital, Terrain, and several notable angel investors including Ben Mann, co-founder of Anthropic, and former chief information security officers at Google Cloud and MongoDB.&lt;/p&gt;&lt;p&gt;“Enterprises are walking a tightrope,” said Rune Kvist, AIUC’s co-founder and CEO, in an interview. “On the one hand, you can stay on the sidelines and watch your competitors make you irrelevant, or you can lean in and risk making headlines for having your chatbot spew Nazi propaganda, or hallucinating your refund policy, or discriminating against the people you’re trying to recruit.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The company’s approach tackles a fundamental trust gap that has emerged as AI capabilities rapidly advance. While AI systems can now perform tasks that rival human undergraduate-level reasoning, many enterprises remain hesitant to deploy them due to concerns about unpredictable failures, liability issues, and reputational risks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-creating-security-standards-that-move-at-ai-speed"&gt;Creating security standards that move at AI speed&lt;/h2&gt;



&lt;p&gt;AIUC’s solution centers on creating what Kvist calls “SOC 2 for AI agents” — a comprehensive security and risk framework specifically designed for artificial intelligence systems. SOC 2 is the widely-adopted cybersecurity standard that enterprises typically require from vendors before sharing sensitive data.&lt;/p&gt;



&lt;p&gt;“SOC 2 is a standard for cybersecurity that specifies all the best practices you must adopt in sufficient detail so that a third party can come and check whether a company meets those requirements,” Kvist explained. “But it doesn’t say anything about AI. There are tons of new questions like: how are you handling my training data? What about hallucinations? What about these tool calls?”&lt;/p&gt;



&lt;p&gt;The AIUC-1 standard addresses six key categories: safety, security, reliability, accountability, data privacy, and societal risks. The framework requires AI companies to implement specific safeguards, from monitoring systems to incident response plans, that can be independently verified through rigorous testing.&lt;/p&gt;



&lt;p&gt;“We take these agents and test them extensively, using customer support as an example since that’s easy to relate to. We try to get the system to say something racist, to give me a refund I don’t deserve, to give me a bigger refund than I deserve, to say something outrageous, or to leak another customer’s data. We do this thousands of times to get a real picture of how robust the AI agent actually is,” Kvist said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-benjamin-franklin-s-fire-insurance-to-ai-risk-management"&gt;From Benjamin Franklin’s fire insurance to AI risk management&lt;/h2&gt;



&lt;p&gt;The insurance-centered approach draws on centuries of precedent where private markets moved faster than regulation to enable the safe adoption of transformative technologies. Kvist frequently references Benjamin Franklin’s creation of America’s first fire insurance company in 1752, which led to building codes and fire inspections that tamed the blazes ravaging Philadelphia’s rapid growth.&lt;/p&gt;



&lt;p&gt;“Throughout history, insurance has been the right model for this, and the reason is that insurers have an incentive to tell the truth,” Kvist explained. “If they say the risks are bigger than they are, someone’s going to sell cheaper insurance. If they say the risks are smaller than they are, they’re going to have to pay the bill and go out of business.”&lt;/p&gt;



&lt;p&gt;The same pattern emerged with automobiles in the 20th century, when insurers created the Insurance Institute of Highway Safety and developed crash testing standards that incentivized safety features like airbags and seatbelts — years before government regulation mandated them.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-major-ai-companies-already-using-the-new-insurance-model"&gt;Major AI companies already using the new insurance model&lt;/h2&gt;



&lt;p&gt;AIUC has already begun working with several high-profile AI companies to validate its approach. The company works with unicorn startups Ada (customer support) and Cognition (coding) to help unlock enterprise deployments that had been stalled due to trust concerns.&lt;/p&gt;



&lt;p&gt;“Ada, we help them unlock a deal with the top five social media company where we came in and ran independent tests on the risks that this company cared about, and that helped unlock that deal, basically giving them the confidence that this could actually be shown to their customers,” Kvist said.&lt;/p&gt;



&lt;p&gt;The startup is also developing partnerships with established insurance providers to provide the financial backing for policies. This addresses a key concern about trusting a startup with major liability coverage. “The insurance policies are going to be backed by the balance sheets of the big insurers,” Kvist explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-quarterly-updates-vs-years-long-regulatory-cycles"&gt;Quarterly updates vs. years-long regulatory cycles&lt;/h2&gt;



&lt;p&gt;One of AIUC’s key innovations is designing standards that can keep pace with AI’s breakneck development speed. While traditional regulatory frameworks like the EU AI Act take years to develop and implement, AIUC plans to update its standards quarterly.&lt;/p&gt;



&lt;p&gt;“The EU AI Act was started back in 2021, they’re now about to release it, but they’re pausing it again because it’s too onerous four years later,” Kvist noted. “That cycle makes it very hard to get the legacy regulatory process to keep up with this technology.”&lt;/p&gt;



&lt;p&gt;This agility has become increasingly important as the competitive gap between US and Chinese AI capabilities narrows. “A year and a half ago, everyone would say, like, we’re two years ahead now, that sounds like eight months, something like that,” Kvist observed.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-ai-insurance-actually-works-testing-systems-to-breaking-point"&gt;How AI insurance actually works: testing systems to breaking point&lt;/h2&gt;



&lt;p&gt;AIUC’s insurance policies cover various types of AI failures, from data breaches and discriminatory hiring practices to intellectual property infringement and incorrect automated decisions. The company prices coverage based on extensive testing that attempts to break AI systems thousands of times across different failure modes.&lt;/p&gt;



&lt;p&gt;“For some of the other things, we think it’s interesting to you. Or not wait for a lawsuit. So for example, if you issue an incorrect refund, great, well, the price of that is obvious, is the amount of money that you incorrectly refunded,” Kvist explained.&lt;/p&gt;



&lt;p&gt;The startup works with a consortium of partners including PwC (one of the “Big Four” accounting firms), Orrick (a leading AI law firm), and academics from Stanford and MIT to develop and validate its standards.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-former-anthropic-executive-leaves-to-solve-ai-trust-problem"&gt;Former Anthropic executive leaves to solve AI trust problem&lt;/h2&gt;



&lt;p&gt;The founding team brings deep experience from both AI development and institutional risk management. Kvist was the first product and go-to-market hire at Anthropic in early 2022, before ChatGPT’s launch, and sits on the board of the Center for AI Safety. Co-founder Brandon Wang is a Thiel Fellow who previously built consumer underwriting businesses, while Rajiv Dattani is a former McKinsey partner who led global insurance work and served as COO of METR, a nonprofit that evaluates leading AI models.&lt;/p&gt;



&lt;p&gt;“The question that really interested me is: how, as a society, are we going to deal with this technology that’s washing over us?” Kvist said of his decision to leave Anthropic. “I think building AI, which is what Anthropic is doing, is very exciting and will do a lot of good for the world. But the most central question that gets me up in the morning is: how, as a society, are we going to deal with this?”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-race-to-make-ai-safe-before-regulation-catches-up"&gt;The race to make AI safe before regulation catches up&lt;/h2&gt;



&lt;p&gt;AIUC’s launch signals a broader shift in how the AI industry approaches risk management as the technology moves from experimental deployments to mission-critical business applications. The insurance model offers enterprises a path between the extremes of reckless AI adoption and paralyzed inaction while waiting for comprehensive government oversight.&lt;/p&gt;



&lt;p&gt;The startup’s approach could prove crucial as AI agents become more capable and widespread across industries. By creating financial incentives for responsible development while enabling faster deployment, companies like AIUC are building the infrastructure that could determine whether artificial intelligence transforms the economy safely or chaotically.&lt;/p&gt;



&lt;p&gt;“We’re hoping that this insurance model, this market-based model, both incentivizes fast adoption and investment in security,” Kvist said. “We’ve seen this throughout history—that the market can move faster than legislation on these issues.”&lt;/p&gt;



&lt;p&gt;The stakes couldn’t be higher. As AI systems edge closer to human-level reasoning across more domains, the window for building robust safety infrastructure may be rapidly closing. AIUC’s bet is that by the time regulators catch up to AI’s breakneck pace, the market will have already built the guardrails.&lt;/p&gt;



&lt;p&gt;After all, Philadelphia’s fires didn’t wait for government building codes — and today’s AI arms race won’t wait for Washington either.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;A new startup founded by an early Anthropic hire has raised $15 million to solve one of the most pressing challenges facing enterprises today: how to deploy artificial intelligence systems without risking catastrophic failures that could damage their businesses.&lt;/p&gt;&lt;p&gt;The Artificial Intelligence Underwriting Company (AIUC), which launches publicly today, combines insurance coverage with rigorous safety standards and independent audits to give companies confidence in deploying AI agents — autonomous software systems that can perform complex tasks like customer service, coding, and data analysis.&lt;/p&gt;&lt;p&gt;The seed funding round was led by Nat Friedman, former GitHub CEO, through his firm NFDG, with participation from Emergence Capital, Terrain, and several notable angel investors including Ben Mann, co-founder of Anthropic, and former chief information security officers at Google Cloud and MongoDB.&lt;/p&gt;&lt;p&gt;“Enterprises are walking a tightrope,” said Rune Kvist, AIUC’s co-founder and CEO, in an interview. “On the one hand, you can stay on the sidelines and watch your competitors make you irrelevant, or you can lean in and risk making headlines for having your chatbot spew Nazi propaganda, or hallucinating your refund policy, or discriminating against the people you’re trying to recruit.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The company’s approach tackles a fundamental trust gap that has emerged as AI capabilities rapidly advance. While AI systems can now perform tasks that rival human undergraduate-level reasoning, many enterprises remain hesitant to deploy them due to concerns about unpredictable failures, liability issues, and reputational risks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-creating-security-standards-that-move-at-ai-speed"&gt;Creating security standards that move at AI speed&lt;/h2&gt;



&lt;p&gt;AIUC’s solution centers on creating what Kvist calls “SOC 2 for AI agents” — a comprehensive security and risk framework specifically designed for artificial intelligence systems. SOC 2 is the widely-adopted cybersecurity standard that enterprises typically require from vendors before sharing sensitive data.&lt;/p&gt;



&lt;p&gt;“SOC 2 is a standard for cybersecurity that specifies all the best practices you must adopt in sufficient detail so that a third party can come and check whether a company meets those requirements,” Kvist explained. “But it doesn’t say anything about AI. There are tons of new questions like: how are you handling my training data? What about hallucinations? What about these tool calls?”&lt;/p&gt;



&lt;p&gt;The AIUC-1 standard addresses six key categories: safety, security, reliability, accountability, data privacy, and societal risks. The framework requires AI companies to implement specific safeguards, from monitoring systems to incident response plans, that can be independently verified through rigorous testing.&lt;/p&gt;



&lt;p&gt;“We take these agents and test them extensively, using customer support as an example since that’s easy to relate to. We try to get the system to say something racist, to give me a refund I don’t deserve, to give me a bigger refund than I deserve, to say something outrageous, or to leak another customer’s data. We do this thousands of times to get a real picture of how robust the AI agent actually is,” Kvist said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-benjamin-franklin-s-fire-insurance-to-ai-risk-management"&gt;From Benjamin Franklin’s fire insurance to AI risk management&lt;/h2&gt;



&lt;p&gt;The insurance-centered approach draws on centuries of precedent where private markets moved faster than regulation to enable the safe adoption of transformative technologies. Kvist frequently references Benjamin Franklin’s creation of America’s first fire insurance company in 1752, which led to building codes and fire inspections that tamed the blazes ravaging Philadelphia’s rapid growth.&lt;/p&gt;



&lt;p&gt;“Throughout history, insurance has been the right model for this, and the reason is that insurers have an incentive to tell the truth,” Kvist explained. “If they say the risks are bigger than they are, someone’s going to sell cheaper insurance. If they say the risks are smaller than they are, they’re going to have to pay the bill and go out of business.”&lt;/p&gt;



&lt;p&gt;The same pattern emerged with automobiles in the 20th century, when insurers created the Insurance Institute of Highway Safety and developed crash testing standards that incentivized safety features like airbags and seatbelts — years before government regulation mandated them.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-major-ai-companies-already-using-the-new-insurance-model"&gt;Major AI companies already using the new insurance model&lt;/h2&gt;



&lt;p&gt;AIUC has already begun working with several high-profile AI companies to validate its approach. The company works with unicorn startups Ada (customer support) and Cognition (coding) to help unlock enterprise deployments that had been stalled due to trust concerns.&lt;/p&gt;



&lt;p&gt;“Ada, we help them unlock a deal with the top five social media company where we came in and ran independent tests on the risks that this company cared about, and that helped unlock that deal, basically giving them the confidence that this could actually be shown to their customers,” Kvist said.&lt;/p&gt;



&lt;p&gt;The startup is also developing partnerships with established insurance providers to provide the financial backing for policies. This addresses a key concern about trusting a startup with major liability coverage. “The insurance policies are going to be backed by the balance sheets of the big insurers,” Kvist explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-quarterly-updates-vs-years-long-regulatory-cycles"&gt;Quarterly updates vs. years-long regulatory cycles&lt;/h2&gt;



&lt;p&gt;One of AIUC’s key innovations is designing standards that can keep pace with AI’s breakneck development speed. While traditional regulatory frameworks like the EU AI Act take years to develop and implement, AIUC plans to update its standards quarterly.&lt;/p&gt;



&lt;p&gt;“The EU AI Act was started back in 2021, they’re now about to release it, but they’re pausing it again because it’s too onerous four years later,” Kvist noted. “That cycle makes it very hard to get the legacy regulatory process to keep up with this technology.”&lt;/p&gt;



&lt;p&gt;This agility has become increasingly important as the competitive gap between US and Chinese AI capabilities narrows. “A year and a half ago, everyone would say, like, we’re two years ahead now, that sounds like eight months, something like that,” Kvist observed.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-ai-insurance-actually-works-testing-systems-to-breaking-point"&gt;How AI insurance actually works: testing systems to breaking point&lt;/h2&gt;



&lt;p&gt;AIUC’s insurance policies cover various types of AI failures, from data breaches and discriminatory hiring practices to intellectual property infringement and incorrect automated decisions. The company prices coverage based on extensive testing that attempts to break AI systems thousands of times across different failure modes.&lt;/p&gt;



&lt;p&gt;“For some of the other things, we think it’s interesting to you. Or not wait for a lawsuit. So for example, if you issue an incorrect refund, great, well, the price of that is obvious, is the amount of money that you incorrectly refunded,” Kvist explained.&lt;/p&gt;



&lt;p&gt;The startup works with a consortium of partners including PwC (one of the “Big Four” accounting firms), Orrick (a leading AI law firm), and academics from Stanford and MIT to develop and validate its standards.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-former-anthropic-executive-leaves-to-solve-ai-trust-problem"&gt;Former Anthropic executive leaves to solve AI trust problem&lt;/h2&gt;



&lt;p&gt;The founding team brings deep experience from both AI development and institutional risk management. Kvist was the first product and go-to-market hire at Anthropic in early 2022, before ChatGPT’s launch, and sits on the board of the Center for AI Safety. Co-founder Brandon Wang is a Thiel Fellow who previously built consumer underwriting businesses, while Rajiv Dattani is a former McKinsey partner who led global insurance work and served as COO of METR, a nonprofit that evaluates leading AI models.&lt;/p&gt;



&lt;p&gt;“The question that really interested me is: how, as a society, are we going to deal with this technology that’s washing over us?” Kvist said of his decision to leave Anthropic. “I think building AI, which is what Anthropic is doing, is very exciting and will do a lot of good for the world. But the most central question that gets me up in the morning is: how, as a society, are we going to deal with this?”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-race-to-make-ai-safe-before-regulation-catches-up"&gt;The race to make AI safe before regulation catches up&lt;/h2&gt;



&lt;p&gt;AIUC’s launch signals a broader shift in how the AI industry approaches risk management as the technology moves from experimental deployments to mission-critical business applications. The insurance model offers enterprises a path between the extremes of reckless AI adoption and paralyzed inaction while waiting for comprehensive government oversight.&lt;/p&gt;



&lt;p&gt;The startup’s approach could prove crucial as AI agents become more capable and widespread across industries. By creating financial incentives for responsible development while enabling faster deployment, companies like AIUC are building the infrastructure that could determine whether artificial intelligence transforms the economy safely or chaotically.&lt;/p&gt;



&lt;p&gt;“We’re hoping that this insurance model, this market-based model, both incentivizes fast adoption and investment in security,” Kvist said. “We’ve seen this throughout history—that the market can move faster than legislation on these issues.”&lt;/p&gt;



&lt;p&gt;The stakes couldn’t be higher. As AI systems edge closer to human-level reasoning across more domains, the window for building robust safety infrastructure may be rapidly closing. AIUC’s bet is that by the time regulators catch up to AI’s breakneck pace, the market will have already built the guardrails.&lt;/p&gt;



&lt;p&gt;After all, Philadelphia’s fires didn’t wait for government building codes — and today’s AI arms race won’t wait for Washington either.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/former-anthropic-exec-raises-15m-to-insure-ai-agents-and-help-startups-deploy-safely/</guid><pubDate>Wed, 23 Jul 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Google DeepMind’s new AI can help historians understand ancient Latin inscriptions (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/23/1120574/deepmind-ai-aeneas-helps-historians-interpret-latin-inscriptions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/aeneas2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google DeepMind has unveiled new artificial-intelligence software that could help historians recover the meaning and context behind ancient Latin engravings.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Aeneas can analyze words written in long-weathered stone to say when and where they were originally inscribed. It follows Google’s previous archaeological tool Ithaca, which also used deep learning to reconstruct and contextualize ancient text, in its case Greek. But while Ithaca and Aeneas use some similar systems, Aeneas also promises to give researchers jumping-off points for further analysis.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;To do this, Aeneas takes in partial transcriptions of an inscription alongside a scanned image of it. Using these, it gives possible dates and places of origins for the engraving, along with potential fill-ins for any missing text. For example, a slab damaged at the start and continuing with &lt;em&gt;... us populusque Romanus&lt;/em&gt; would likely prompt Aeneas to guess that &lt;em&gt;Senat&lt;/em&gt; comes before &lt;em&gt;us&lt;/em&gt; to create the phrase &lt;em&gt;Senatus populusque Romanus&lt;/em&gt;, “The Senate and the people of Rome.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is similar to how Ithaca works. But Aeneas also cross-references the text with a stored database of almost 150,000 inscriptions, which originated everywhere from modern-day Britain to modern-day Iraq, to give possible parallels—other catalogued Latin engravings that feature similar words, phrases, and analogies.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This database, alongside a few thousand images of inscriptions, makes up the training set for Aeneas’s deep neural network. While it may seem like a good number of samples, it pales in comparison to the billions of documents used to train general-purpose large language models like Google’s Gemini. There simply aren’t enough high-quality scans of inscriptions to train a language model to learn this kind of task. That’s why specialized solutions like Aeneas are needed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The Aeneas team believes it could help researchers “connect the past,” said Yannis Assael, a researcher at Google DeepMind who worked on the project. Rather than seeking to automate epigraphy—the research field dealing with deciphering and understanding inscriptions—he and his colleagues are interested in “crafting a tool that will integrate with the workflow of a historian,” Assael said in a press briefing.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Their goal is to give researchers trying to analyze a specific inscription many hypotheses to work from, saving them the effort of sifting through records by hand. To validate the system, the team presented 23 historians with inscriptions that had been previously dated and tested their workflows both with and without Aeneas. The findings, which were published today in &lt;em&gt;Nature&lt;/em&gt;, showed that Aeneas helped spur research ideas among the historians for 90% of inscriptions and that it led to more accurate determinations of where and when the inscriptions originated.&lt;/p&gt;  &lt;p&gt;In addition to this study, the researchers tested Aeneas on the Monumentum Ancyranum, a famous inscription carved into the walls of a temple in Ankara, Turkey. Here, Aeneas managed to give estimates and parallels that reflected existing historical analysis of the work, and in its attention to detail, the paper claims, it closely matched how a trained historian would approach the problem. “That was jaw-dropping,” Thea Sommerschield, an epigrapher at the University of Nottingham who also worked on Aeneas, said in the press briefing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, much remains to be seen about Aeneas’s capabilities in the real world. It doesn’t guess the meaning of texts, so it can’t interpret newly found engravings on its own, and it’s not clear yet how useful it will be to historians’ workflows in the long term, according to Kathleen Coleman, a professor of classics at Harvard. The Monumentum Ancyranum is considered to be one of the best-known and most well-studied inscriptions in epigraphy, raising the question of how Aeneas will fare on more obscure samples.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;Google DeepMind has now made Aeneas open-source, and the interface for the system is freely available for teachers, students, museum workers, and academics. The group is working with schools in Belgium to integrate Aeneas into their secondary history education.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“To have Aeneas at your side while you’re in the museum or at the archaeological site where a new inscription has just been found—that is our sort of dream scenario,” Sommerschield said.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/aeneas2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google DeepMind has unveiled new artificial-intelligence software that could help historians recover the meaning and context behind ancient Latin engravings.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Aeneas can analyze words written in long-weathered stone to say when and where they were originally inscribed. It follows Google’s previous archaeological tool Ithaca, which also used deep learning to reconstruct and contextualize ancient text, in its case Greek. But while Ithaca and Aeneas use some similar systems, Aeneas also promises to give researchers jumping-off points for further analysis.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;To do this, Aeneas takes in partial transcriptions of an inscription alongside a scanned image of it. Using these, it gives possible dates and places of origins for the engraving, along with potential fill-ins for any missing text. For example, a slab damaged at the start and continuing with &lt;em&gt;... us populusque Romanus&lt;/em&gt; would likely prompt Aeneas to guess that &lt;em&gt;Senat&lt;/em&gt; comes before &lt;em&gt;us&lt;/em&gt; to create the phrase &lt;em&gt;Senatus populusque Romanus&lt;/em&gt;, “The Senate and the people of Rome.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is similar to how Ithaca works. But Aeneas also cross-references the text with a stored database of almost 150,000 inscriptions, which originated everywhere from modern-day Britain to modern-day Iraq, to give possible parallels—other catalogued Latin engravings that feature similar words, phrases, and analogies.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This database, alongside a few thousand images of inscriptions, makes up the training set for Aeneas’s deep neural network. While it may seem like a good number of samples, it pales in comparison to the billions of documents used to train general-purpose large language models like Google’s Gemini. There simply aren’t enough high-quality scans of inscriptions to train a language model to learn this kind of task. That’s why specialized solutions like Aeneas are needed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The Aeneas team believes it could help researchers “connect the past,” said Yannis Assael, a researcher at Google DeepMind who worked on the project. Rather than seeking to automate epigraphy—the research field dealing with deciphering and understanding inscriptions—he and his colleagues are interested in “crafting a tool that will integrate with the workflow of a historian,” Assael said in a press briefing.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Their goal is to give researchers trying to analyze a specific inscription many hypotheses to work from, saving them the effort of sifting through records by hand. To validate the system, the team presented 23 historians with inscriptions that had been previously dated and tested their workflows both with and without Aeneas. The findings, which were published today in &lt;em&gt;Nature&lt;/em&gt;, showed that Aeneas helped spur research ideas among the historians for 90% of inscriptions and that it led to more accurate determinations of where and when the inscriptions originated.&lt;/p&gt;  &lt;p&gt;In addition to this study, the researchers tested Aeneas on the Monumentum Ancyranum, a famous inscription carved into the walls of a temple in Ankara, Turkey. Here, Aeneas managed to give estimates and parallels that reflected existing historical analysis of the work, and in its attention to detail, the paper claims, it closely matched how a trained historian would approach the problem. “That was jaw-dropping,” Thea Sommerschield, an epigrapher at the University of Nottingham who also worked on Aeneas, said in the press briefing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, much remains to be seen about Aeneas’s capabilities in the real world. It doesn’t guess the meaning of texts, so it can’t interpret newly found engravings on its own, and it’s not clear yet how useful it will be to historians’ workflows in the long term, according to Kathleen Coleman, a professor of classics at Harvard. The Monumentum Ancyranum is considered to be one of the best-known and most well-studied inscriptions in epigraphy, raising the question of how Aeneas will fare on more obscure samples.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;Google DeepMind has now made Aeneas open-source, and the interface for the system is freely available for teachers, students, museum workers, and academics. The group is working with schools in Belgium to integrate Aeneas into their secondary history education.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“To have Aeneas at your side while you’re in the museum or at the archaeological site where a new inscription has just been found—that is our sort of dream scenario,” Sommerschield said.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/23/1120574/deepmind-ai-aeneas-helps-historians-interpret-latin-inscriptions/</guid><pubDate>Wed, 23 Jul 2025 15:00:08 +0000</pubDate></item><item><title>[NEW] Technical approach for classifying human-AI interactions at scale (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="The image features four white icons on a gradient background that transitions from blue on the left to green on the right. The first icon is a network or molecule structure with interconnected nodes. The second icon shows a stylized person in front of a computer screen. The third icon shows an organization tree with one main node and three nodes branching out side by side below it." class="wp-image-1144473" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;As large language models (LLMs) become foundational to modern AI systems, the ability to run them at scale—efficiently, reliably, and in near real-time—is no longer a nice-to-have. It’s essential. The Semantic Telemetry project tackles this challenge by applying LLM-based classifiers to hundreds of millions of sampled, anonymized Bing Chat conversations each week. These classifiers extract signals like user expertise, primary topic, and satisfaction, enabling deeper insight into human-AI interactions and driving continuous system improvement.&lt;/p&gt;



&lt;p&gt;But building a pipeline that can handle this volume isn’t just about plugging into an API. It requires a high-throughput, high-performance architecture that can orchestrate distributed processing, manage token and prompt complexity, and gracefully handle the unpredictability of remote LLM endpoints.&lt;/p&gt;



&lt;p&gt;In this latest post in our series on Semantic Telemetry, we’ll walk through the engineering behind that system—how we designed for scale from the start, the trade-offs we made, and the lessons we learned along the way. From batching strategies and token optimization and orchestration, we’ll share what it takes to build a real-time LLM classification pipeline.&lt;/p&gt;



&lt;p&gt;For additional project background: Semantic Telemetry: Understanding how users interact with AI systems and Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="system-architecture-highlights"&gt;System architecture highlights&lt;/h2&gt;



&lt;p&gt;The Semantic Telemetry pipeline&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is a highly-scalable, highly-configurable, data transformation pipeline. While it follows a familiar ETL structure, several architectural innovations make it uniquely suited for high-throughput LLM integration:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Hybrid compute engine&lt;/strong&gt;&lt;br /&gt;The pipeline combines the distributed power of PySpark with the speed and simplicity of Polars, enabling it to scale across large datasets or run lightweight jobs in Spark-less environments—without code changes.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LLM-centric transformation layer&lt;/strong&gt;&lt;br /&gt;At the core of the pipeline is a multi-stage transformation process tailored for running across multiple LLM endpoints such that:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Runs model agnostic. Provides a generic interface for LLMs and adopts model specific interfaces built from a generic interface.&lt;/li&gt;



&lt;li&gt;Prompt templates are defined using the Prompty language specification for consistency and reuse, with options for users to include custom prompts.&lt;/li&gt;



&lt;li&gt;Parsing and cleaning logic ensures structured, schema-aligned outputs, even when LLM responses are imperfect such as removing extra characters in output, resolving not-exact label matches (i.e. “create” versus “created”) and relabeling invalid classifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1. Architecture diagram of LLM workflow" class="wp-image-1144472" height="650" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Architecture diagram&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The pipeline supports multiple classification tasks (e.g., user expertise, topic, satisfaction) through modular prompt templates and configurable execution paths—making it easy to adapt to new use cases or environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="engineering-challenges-solutions"&gt;Engineering challenges &amp;amp; solutions&lt;/h2&gt;



&lt;p&gt;Building a high-throughput, LLM-powered classification pipeline at scale introduced a range of engineering challenges—from managing latency and token limits to ensuring system resilience. Below are the key hurdles we encountered and how we addressed them.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="llm-endpoint-latency-variability"&gt;LLM endpoint latency &amp;amp; variability&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: LLM endpoints, especially those hosted remotely (e.g., Azure OpenAI), introduce unpredictable latency due to model load, prompt complexity, and network variability. This made it difficult to maintain consistent throughput across the pipeline.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We implemented a combination of:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Multiple Azure OpenAI endpoints&lt;/strong&gt; in rotation to increase throughput and distribute workload. We can analyze throughput and redistribute as needed.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Saving output in intervals&lt;/strong&gt; to write data asynchronously in case of network errors.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Utilizing models with higher tokens per minute (TPM)&lt;/strong&gt; such as OpenAI’s GPT-4o mini. GPT-4o mini had a 2M TPM limit which is a 25x throughput increase from GPT-4 (80K TPM -&amp;gt; 2M TPM)&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Timeouts and retries&lt;/strong&gt; with exponential backoff.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="evolving-llm-models-prompt-alignment"&gt;Evolving LLM models &amp;amp; prompt alignment&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: Each new LLM release—such as Phi, Mistral, DeepSeek, and successive generations of GPT (e.g., GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o)—brings improvements, but also subtle behavioral shifts. These changes can affect classification consistency, output formatting, and even the interpretation of prompts. Maintaining alignment with baseline expectations across models became a moving target.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We developed a model evaluation workflow to test prompt alignment across LLM versions:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Small-sample testing&lt;/strong&gt;: We ran the pipeline on a representative sample using the new model and compared the output distribution to a known baseline.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Distribution analysis&lt;/strong&gt;: If the new model’s output aligned closely, we scaled up testing. If not, we iteratively &lt;strong&gt;tuned the prompts&lt;/strong&gt; and re-ran comparisons.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Interpretation flexibility&lt;/strong&gt;: We also recognized that a shift in distribution isn’t always a regression. Sometimes it reflects a more accurate or nuanced classification, especially as models improve.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;To support this process, we used tools like Sammo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which allowed us to compare outputs across multiple models and prompt variants. This helped us quantify the impact of prompt changes and model upgrades and make informed decisions about when to adopt a new model or adjust our classification schema.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="dynamic-concurrency-scaling-for-llm-calls"&gt;Dynamic concurrency scaling for LLM calls&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: LLM endpoints frequently encounter rate limits and inconsistent response times under heavy usage. The models’ speeds can also vary, complicating the selection of optimal concurrency levels. Furthermore, users may choose suboptimal settings due to lack of familiarity, and default concurrency configurations are rarely ideal for every situation. Dynamic adjustments based on throughput, measured in various ways, can assist in determining optimal concurrency levels.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We implemented a dynamic concurrency control mechanism that proactively adjusts the number of parallel LLM calls based on real-time system behavior:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;External task awareness&lt;/strong&gt;: The system monitors the number of parallel tasks running across the pipeline (e.g., Spark executors or async workers) and uses this to inform the initial concurrency level.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Success/failure rate monitoring&lt;/strong&gt;: The system tracks the rolling success and failure rates of LLM calls. A spike in failures triggers a temporary reduction in concurrency, while sustained success allows for gradual ramp-up.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Latency-based feedback loop&lt;/strong&gt;: Instead of waiting for rate-limit errors, measure the response time of LLM calls. If latency increases, reduce concurrency; if latency decreases and success rates remain high, cautiously scale up.&lt;/li&gt;
&lt;/ul&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="optimization-experiments"&gt;Optimization experiments&lt;/h2&gt;



&lt;p&gt;To further improve throughput and efficiency, we ran a series of optimization experiments. Each approach came with trade-offs that we carefully measured.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="batch-endpoints-azure-openai"&gt;Batch endpoints (Azure/OpenAI)&lt;/h3&gt;



&lt;p&gt;Batch endpoints are a cost-effective, moderately high-throughput way of executing LLM requests. Batch endpoints process large lists of LLM prompts over a 24-hour period, recording responses in a file. They are about 50% cheaper than non-batch endpoints and have separate token limits, enabling increased throughput when used alongside regular endpoints. However, they require at least 24 hours to complete requests and provide lower overall throughput compared to non-batch endpoints, making them unsuitable for situations needing quick results.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="conversation-batching-in-prompts-during-pipeline-runtime"&gt;Conversation batching in prompts during pipeline runtime&lt;/h3&gt;



&lt;p&gt;Batching multiple conversations for classification at once can significantly increase throughput and reduce token usage, but it may impact the accuracy of results. In our experiment with a domain classifier, classifying 10 conversations simultaneously led to an average of 15-20% of domain assignments changing between repeated runs of the same prompt. To address this, one mitigation approach is to use a grader LLM prompt: first classify the batch, then have the LLM identify any incorrectly classified conversations, and finally re-classify those as needed. While batching offers efficiency gains, it is important to monitor for potential drops in classification quality.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="combining-classifiers-in-a-single-prompt"&gt;Combining classifiers in a single prompt&lt;/h3&gt;



&lt;p&gt;Combining multiple classifiers into a single prompt increases throughput by allowing one call to the LLM instead of multiple calls. This not only multiplies the overall throughput by the number of classifiers processed but also reduces the total number of tokens used, since the conversation text is only passed in once. However, this approach may compromise classification accuracy, so results should be closely monitored.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="classification-using-text-embeddings"&gt;Classification using text embeddings&lt;/h3&gt;



&lt;p&gt;An alternative approach is to train custom neural network models for each classifier using only the text embeddings of conversations. This method delivers both cost and time savings by avoiding making multiple LLM requests for every classifier and conversation—instead, the system only needs to request conversation text embeddings once and can reuse these embeddings across all classifier models.&lt;/p&gt;



&lt;p&gt;For example, starting with a set of conversations to validate and test the new model, run these conversations through the original prompt-based classifier to generate a set of golden classifications, then obtain text embeddings (using a tool like text-embedding-3-large) for each conversation. These embeddings and their corresponding classifications are used to train a model such as a multi-layer perceptron. In production, the workflow involves retrieving the text embedding for each conversation and passing it through the trained model; if there is a model for each classifier, a single embedding retrieval per conversation suffices for all classifiers.&lt;/p&gt;



&lt;p&gt;The benefits of this approach include significantly increased throughput and cost savings—since it’s not necessary to call the LLM for every classifier and conversation. However, this setup can require GPU compute which can increase costs and infrastructure complexity, and the resulting models may not achieve the same accuracy as prompt-based classification methods.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="prompt-compression"&gt;Prompt compression&lt;/h3&gt;



&lt;p&gt;Compressing prompts by eliminating unnecessary tokens or by using a tool such as LLMLingua&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to automate prompt compression can optimize classification prompts either ahead of time or in real-time. This approach increases overall throughput and results in cost savings due to a reduced number of tokens, but there are risks: changes to the classifier prompt or conversation text may impact classification accuracy, and depending on the compression technique, it could even decrease throughput if the compression process takes longer than simply sending uncompressed text to the LLM.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="text-truncation"&gt;Text truncation&lt;/h3&gt;



&lt;p&gt;Truncating conversations to a specific length limits the overall number of tokens sent through an endpoint, offering cost savings and increased throughput like prompt compression. By reducing the number of tokens per request, throughput rises because more requests can be made before reaching the endpoint’s tokens-per-minute (TPM) limit, and costs decrease due to fewer tokens being processed. However, the ideal truncation length depends on both the classifiers and the conversation content, so it’s important to assess how truncation affects output quality before implementation. While this approach brings clear efficiency benefits, it also poses a risk: long conversations may have their most important content cut off, which can reduce classification accuracy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;Building a scalable, high-throughput pipeline for LLM-based classification is far from trivial. It requires navigating a constantly shifting landscape of model capabilities, prompt behaviors, and infrastructure constraints. As LLMs become faster, cheaper, and more capable, they’re unlocking new possibilities for real-time understanding of human-AI interactions at scale. The techniques we’ve shared represent a snapshot of what’s working today. But more importantly, they offer a foundation for what’s possible tomorrow.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="The image features four white icons on a gradient background that transitions from blue on the left to green on the right. The first icon is a network or molecule structure with interconnected nodes. The second icon shows a stylized person in front of a computer screen. The third icon shows an organization tree with one main node and three nodes branching out side by side below it." class="wp-image-1144473" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;As large language models (LLMs) become foundational to modern AI systems, the ability to run them at scale—efficiently, reliably, and in near real-time—is no longer a nice-to-have. It’s essential. The Semantic Telemetry project tackles this challenge by applying LLM-based classifiers to hundreds of millions of sampled, anonymized Bing Chat conversations each week. These classifiers extract signals like user expertise, primary topic, and satisfaction, enabling deeper insight into human-AI interactions and driving continuous system improvement.&lt;/p&gt;



&lt;p&gt;But building a pipeline that can handle this volume isn’t just about plugging into an API. It requires a high-throughput, high-performance architecture that can orchestrate distributed processing, manage token and prompt complexity, and gracefully handle the unpredictability of remote LLM endpoints.&lt;/p&gt;



&lt;p&gt;In this latest post in our series on Semantic Telemetry, we’ll walk through the engineering behind that system—how we designed for scale from the start, the trade-offs we made, and the lessons we learned along the way. From batching strategies and token optimization and orchestration, we’ll share what it takes to build a real-time LLM classification pipeline.&lt;/p&gt;



&lt;p&gt;For additional project background: Semantic Telemetry: Understanding how users interact with AI systems and Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project.&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="system-architecture-highlights"&gt;System architecture highlights&lt;/h2&gt;



&lt;p&gt;The Semantic Telemetry pipeline&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is a highly-scalable, highly-configurable, data transformation pipeline. While it follows a familiar ETL structure, several architectural innovations make it uniquely suited for high-throughput LLM integration:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Hybrid compute engine&lt;/strong&gt;&lt;br /&gt;The pipeline combines the distributed power of PySpark with the speed and simplicity of Polars, enabling it to scale across large datasets or run lightweight jobs in Spark-less environments—without code changes.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LLM-centric transformation layer&lt;/strong&gt;&lt;br /&gt;At the core of the pipeline is a multi-stage transformation process tailored for running across multiple LLM endpoints such that:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Runs model agnostic. Provides a generic interface for LLMs and adopts model specific interfaces built from a generic interface.&lt;/li&gt;



&lt;li&gt;Prompt templates are defined using the Prompty language specification for consistency and reuse, with options for users to include custom prompts.&lt;/li&gt;



&lt;li&gt;Parsing and cleaning logic ensures structured, schema-aligned outputs, even when LLM responses are imperfect such as removing extra characters in output, resolving not-exact label matches (i.e. “create” versus “created”) and relabeling invalid classifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1. Architecture diagram of LLM workflow" class="wp-image-1144472" height="650" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Architecture diagram&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The pipeline supports multiple classification tasks (e.g., user expertise, topic, satisfaction) through modular prompt templates and configurable execution paths—making it easy to adapt to new use cases or environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="engineering-challenges-solutions"&gt;Engineering challenges &amp;amp; solutions&lt;/h2&gt;



&lt;p&gt;Building a high-throughput, LLM-powered classification pipeline at scale introduced a range of engineering challenges—from managing latency and token limits to ensuring system resilience. Below are the key hurdles we encountered and how we addressed them.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="llm-endpoint-latency-variability"&gt;LLM endpoint latency &amp;amp; variability&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: LLM endpoints, especially those hosted remotely (e.g., Azure OpenAI), introduce unpredictable latency due to model load, prompt complexity, and network variability. This made it difficult to maintain consistent throughput across the pipeline.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We implemented a combination of:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Multiple Azure OpenAI endpoints&lt;/strong&gt; in rotation to increase throughput and distribute workload. We can analyze throughput and redistribute as needed.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Saving output in intervals&lt;/strong&gt; to write data asynchronously in case of network errors.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Utilizing models with higher tokens per minute (TPM)&lt;/strong&gt; such as OpenAI’s GPT-4o mini. GPT-4o mini had a 2M TPM limit which is a 25x throughput increase from GPT-4 (80K TPM -&amp;gt; 2M TPM)&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Timeouts and retries&lt;/strong&gt; with exponential backoff.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="evolving-llm-models-prompt-alignment"&gt;Evolving LLM models &amp;amp; prompt alignment&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: Each new LLM release—such as Phi, Mistral, DeepSeek, and successive generations of GPT (e.g., GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o)—brings improvements, but also subtle behavioral shifts. These changes can affect classification consistency, output formatting, and even the interpretation of prompts. Maintaining alignment with baseline expectations across models became a moving target.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We developed a model evaluation workflow to test prompt alignment across LLM versions:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Small-sample testing&lt;/strong&gt;: We ran the pipeline on a representative sample using the new model and compared the output distribution to a known baseline.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Distribution analysis&lt;/strong&gt;: If the new model’s output aligned closely, we scaled up testing. If not, we iteratively &lt;strong&gt;tuned the prompts&lt;/strong&gt; and re-ran comparisons.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Interpretation flexibility&lt;/strong&gt;: We also recognized that a shift in distribution isn’t always a regression. Sometimes it reflects a more accurate or nuanced classification, especially as models improve.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;To support this process, we used tools like Sammo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which allowed us to compare outputs across multiple models and prompt variants. This helped us quantify the impact of prompt changes and model upgrades and make informed decisions about when to adopt a new model or adjust our classification schema.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="dynamic-concurrency-scaling-for-llm-calls"&gt;Dynamic concurrency scaling for LLM calls&lt;/h3&gt;



&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: LLM endpoints frequently encounter rate limits and inconsistent response times under heavy usage. The models’ speeds can also vary, complicating the selection of optimal concurrency levels. Furthermore, users may choose suboptimal settings due to lack of familiarity, and default concurrency configurations are rarely ideal for every situation. Dynamic adjustments based on throughput, measured in various ways, can assist in determining optimal concurrency levels.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We implemented a dynamic concurrency control mechanism that proactively adjusts the number of parallel LLM calls based on real-time system behavior:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;External task awareness&lt;/strong&gt;: The system monitors the number of parallel tasks running across the pipeline (e.g., Spark executors or async workers) and uses this to inform the initial concurrency level.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Success/failure rate monitoring&lt;/strong&gt;: The system tracks the rolling success and failure rates of LLM calls. A spike in failures triggers a temporary reduction in concurrency, while sustained success allows for gradual ramp-up.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Latency-based feedback loop&lt;/strong&gt;: Instead of waiting for rate-limit errors, measure the response time of LLM calls. If latency increases, reduce concurrency; if latency decreases and success rates remain high, cautiously scale up.&lt;/li&gt;
&lt;/ul&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="optimization-experiments"&gt;Optimization experiments&lt;/h2&gt;



&lt;p&gt;To further improve throughput and efficiency, we ran a series of optimization experiments. Each approach came with trade-offs that we carefully measured.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="batch-endpoints-azure-openai"&gt;Batch endpoints (Azure/OpenAI)&lt;/h3&gt;



&lt;p&gt;Batch endpoints are a cost-effective, moderately high-throughput way of executing LLM requests. Batch endpoints process large lists of LLM prompts over a 24-hour period, recording responses in a file. They are about 50% cheaper than non-batch endpoints and have separate token limits, enabling increased throughput when used alongside regular endpoints. However, they require at least 24 hours to complete requests and provide lower overall throughput compared to non-batch endpoints, making them unsuitable for situations needing quick results.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="conversation-batching-in-prompts-during-pipeline-runtime"&gt;Conversation batching in prompts during pipeline runtime&lt;/h3&gt;



&lt;p&gt;Batching multiple conversations for classification at once can significantly increase throughput and reduce token usage, but it may impact the accuracy of results. In our experiment with a domain classifier, classifying 10 conversations simultaneously led to an average of 15-20% of domain assignments changing between repeated runs of the same prompt. To address this, one mitigation approach is to use a grader LLM prompt: first classify the batch, then have the LLM identify any incorrectly classified conversations, and finally re-classify those as needed. While batching offers efficiency gains, it is important to monitor for potential drops in classification quality.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="combining-classifiers-in-a-single-prompt"&gt;Combining classifiers in a single prompt&lt;/h3&gt;



&lt;p&gt;Combining multiple classifiers into a single prompt increases throughput by allowing one call to the LLM instead of multiple calls. This not only multiplies the overall throughput by the number of classifiers processed but also reduces the total number of tokens used, since the conversation text is only passed in once. However, this approach may compromise classification accuracy, so results should be closely monitored.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="classification-using-text-embeddings"&gt;Classification using text embeddings&lt;/h3&gt;



&lt;p&gt;An alternative approach is to train custom neural network models for each classifier using only the text embeddings of conversations. This method delivers both cost and time savings by avoiding making multiple LLM requests for every classifier and conversation—instead, the system only needs to request conversation text embeddings once and can reuse these embeddings across all classifier models.&lt;/p&gt;



&lt;p&gt;For example, starting with a set of conversations to validate and test the new model, run these conversations through the original prompt-based classifier to generate a set of golden classifications, then obtain text embeddings (using a tool like text-embedding-3-large) for each conversation. These embeddings and their corresponding classifications are used to train a model such as a multi-layer perceptron. In production, the workflow involves retrieving the text embedding for each conversation and passing it through the trained model; if there is a model for each classifier, a single embedding retrieval per conversation suffices for all classifiers.&lt;/p&gt;



&lt;p&gt;The benefits of this approach include significantly increased throughput and cost savings—since it’s not necessary to call the LLM for every classifier and conversation. However, this setup can require GPU compute which can increase costs and infrastructure complexity, and the resulting models may not achieve the same accuracy as prompt-based classification methods.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="prompt-compression"&gt;Prompt compression&lt;/h3&gt;



&lt;p&gt;Compressing prompts by eliminating unnecessary tokens or by using a tool such as LLMLingua&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to automate prompt compression can optimize classification prompts either ahead of time or in real-time. This approach increases overall throughput and results in cost savings due to a reduced number of tokens, but there are risks: changes to the classifier prompt or conversation text may impact classification accuracy, and depending on the compression technique, it could even decrease throughput if the compression process takes longer than simply sending uncompressed text to the LLM.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="text-truncation"&gt;Text truncation&lt;/h3&gt;



&lt;p&gt;Truncating conversations to a specific length limits the overall number of tokens sent through an endpoint, offering cost savings and increased throughput like prompt compression. By reducing the number of tokens per request, throughput rises because more requests can be made before reaching the endpoint’s tokens-per-minute (TPM) limit, and costs decrease due to fewer tokens being processed. However, the ideal truncation length depends on both the classifiers and the conversation content, so it’s important to assess how truncation affects output quality before implementation. While this approach brings clear efficiency benefits, it also poses a risk: long conversations may have their most important content cut off, which can reduce classification accuracy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;Building a scalable, high-throughput pipeline for LLM-based classification is far from trivial. It requires navigating a constantly shifting landscape of model capabilities, prompt behaviors, and infrastructure constraints. As LLMs become faster, cheaper, and more capable, they’re unlocking new possibilities for real-time understanding of human-AI interactions at scale. The techniques we’ve shared represent a snapshot of what’s working today. But more importantly, they offer a foundation for what’s possible tomorrow.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/</guid><pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google Photos adds AI features for ‘remixing’ photos in different styles, turning pics into videos (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/google-photos-adds-ai-features-for-remixing-photos-in-different-styles-turning-pics-into-videos/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Photos is getting major AI chops. On Wednesday, Google announced a handful of new features that will allow users to get more creative with their photo memories, including an option to turn photos into videos, and “remix” photos into different styles, like anime, comics, sketches, or 3D animations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app will also centralize access to its creative tools — including both AI-powered and traditional tools — in a new “Create” tab in the Photos app. The two newly launched features will be housed in this tab, alongside other tools that let you create collages, highlight videos, and other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030442" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Create-tab.png?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update brings AI prowess to one of Google’s most popular consumer-facing services: Google Photos today has over 1.5 billion users. That will put AI into more people’s hands, including those who have not spent as much time experimenting with what AI can do. It also gives Google a large base to learn from as people try out the new features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company noted these features are experimental, so it will ask users to leave a thumbs-up or thumbs-down on the AI-generated images and videos to provide feedback. That feedback will help Google to improve the product and overall experience, it says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030443" height="372" src="https://techcrunch.com/wp-content/uploads/2025/07/photo-to-video.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the new photo-to-video feature, similar to the offering already available in Gemini (and, as of today, YouTube), users will be able to make short videos from their own photos using Google’s Veo 2 model. In past years, animating old family photos was a clever trick, driving downloads of apps like MyHeritage as people brought long-past relatives to life. Now that ability is being commoditized with the use of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you’ve selected a photo, you can choose from one of two prompts — “Subtle movements,” or “I’m feeling lucky” — to turn the photo into a six-second video clip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Photo to Video is rolling out today to users in the U.S. on Android and iOS.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the new Remix feature, powered by Google’s Imagen AI model, lets you pick any photo from your gallery, then transform it into a different style in just seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature will be available in the U.S. on Android and iOS in the next few weeks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030445" height="381" src="https://techcrunch.com/wp-content/uploads/2025/07/remix.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Both features will include an invisible&amp;nbsp;SynthID&amp;nbsp;digital watermark on their outputs to identify them as being AI-generated. Google Photos already does this with other AI tools, like&amp;nbsp;images edited using Reimagine, for example. Generated videos will also include a visual watermark, similar to those generated by Gemini.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Create tab will arrive in the U.S. in August. Google says it will update the tab over time, adding new tools and experiments and refining existing options.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI features were introduced alongside similar tools for YouTube Shorts, which is also now offering its own photo-to-video option as well as new AI effects, powered by Veo 2. (Shorts will get access to Veo 3 later this summer, Google said.)&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Photos is getting major AI chops. On Wednesday, Google announced a handful of new features that will allow users to get more creative with their photo memories, including an option to turn photos into videos, and “remix” photos into different styles, like anime, comics, sketches, or 3D animations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app will also centralize access to its creative tools — including both AI-powered and traditional tools — in a new “Create” tab in the Photos app. The two newly launched features will be housed in this tab, alongside other tools that let you create collages, highlight videos, and other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030442" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Create-tab.png?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update brings AI prowess to one of Google’s most popular consumer-facing services: Google Photos today has over 1.5 billion users. That will put AI into more people’s hands, including those who have not spent as much time experimenting with what AI can do. It also gives Google a large base to learn from as people try out the new features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company noted these features are experimental, so it will ask users to leave a thumbs-up or thumbs-down on the AI-generated images and videos to provide feedback. That feedback will help Google to improve the product and overall experience, it says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030443" height="372" src="https://techcrunch.com/wp-content/uploads/2025/07/photo-to-video.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the new photo-to-video feature, similar to the offering already available in Gemini (and, as of today, YouTube), users will be able to make short videos from their own photos using Google’s Veo 2 model. In past years, animating old family photos was a clever trick, driving downloads of apps like MyHeritage as people brought long-past relatives to life. Now that ability is being commoditized with the use of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once you’ve selected a photo, you can choose from one of two prompts — “Subtle movements,” or “I’m feeling lucky” — to turn the photo into a six-second video clip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Photo to Video is rolling out today to users in the U.S. on Android and iOS.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the new Remix feature, powered by Google’s Imagen AI model, lets you pick any photo from your gallery, then transform it into a different style in just seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature will be available in the U.S. on Android and iOS in the next few weeks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030445" height="381" src="https://techcrunch.com/wp-content/uploads/2025/07/remix.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Both features will include an invisible&amp;nbsp;SynthID&amp;nbsp;digital watermark on their outputs to identify them as being AI-generated. Google Photos already does this with other AI tools, like&amp;nbsp;images edited using Reimagine, for example. Generated videos will also include a visual watermark, similar to those generated by Gemini.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Create tab will arrive in the U.S. in August. Google says it will update the tab over time, adding new tools and experiments and refining existing options.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI features were introduced alongside similar tools for YouTube Shorts, which is also now offering its own photo-to-video option as well as new AI effects, powered by Veo 2. (Shorts will get access to Veo 3 later this summer, Google said.)&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/google-photos-adds-ai-features-for-remixing-photos-in-different-styles-turning-pics-into-videos/</guid><pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] YouTube Shorts is adding an image-to-video AI tool, new AI effects (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/youtube-shorts-is-adding-an-image-to-video-ai-tool-new-ai-effects/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube announced on Wednesday that it’s giving Shorts creators access to new generative AI features, including an image-to-video AI tool and new AI effects. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The image to video feature lets users turn a picture from their camera roll into a six-second video. Users will see a selection of suggestions that are relevant to the photo they uploaded. YouTube says the feature can be used to add movement to landscape photos, animate pictures of everyday photos, or bring group photos to life.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In an example given by YouTube, the feature turns a static image of a pedestrian signal into a short video that slowly zooms into a dancing version of the walking man symbol. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030444" height="569" src="https://techcrunch.com/wp-content/uploads/2025/07/YouTube-Photo-to-video.gif?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The feature works similarly to an&amp;nbsp;offering already available in Gemini. Plus, it’s similar to the Animate tool in Meta’s Edits app, which also uses AI to transform static images into videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new tool is rolling out over the next week in the United States, Canada, Australia, and New Zealand. YouTube plans to bring it to more regions later this year. It’s worth noting that Google Photos is also getting a similar image-to-video tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new AI effects, creators can use them to transform their doodles into artistic images and turn their selfies into videos where they’re swimming underwater, twinning with someone, and more. Users can find these new effects by navigating to the “Effects” icon in the Shorts camera and then tapping “AI” to browse all of the generative effects. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030449" height="569" src="https://techcrunch.com/wp-content/uploads/2025/07/YouTube-Effect-Underwater.gif?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the features announced today are powered by Veo 2, Google’s AI model for video generation. YouTube says it uses&amp;nbsp;SynthID&amp;nbsp;watermarks and&amp;nbsp;clear labels&amp;nbsp;to indicate that these creations were generated with AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last month at Cannes Lions 2025, YouTube CEO Neal Mohan announced that Google’s Veo 3 video generator, which can generate both video and audio, will be coming to Shorts later this summer. He also shared that Shorts are now averaging more than&amp;nbsp;200 billion daily views. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube also announced on Wednesday that AI Playground is its new home for generative AI creation tools, inspirational examples, prefilled prompts, and more. Creators can find AI Playground by tapping the Create button and then the sparkle icon in the top right corner. It’s available now for everyone in the United States, Canada, Australia, and New Zealand.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube announced on Wednesday that it’s giving Shorts creators access to new generative AI features, including an image-to-video AI tool and new AI effects. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The image to video feature lets users turn a picture from their camera roll into a six-second video. Users will see a selection of suggestions that are relevant to the photo they uploaded. YouTube says the feature can be used to add movement to landscape photos, animate pictures of everyday photos, or bring group photos to life.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In an example given by YouTube, the feature turns a static image of a pedestrian signal into a short video that slowly zooms into a dancing version of the walking man symbol. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030444" height="569" src="https://techcrunch.com/wp-content/uploads/2025/07/YouTube-Photo-to-video.gif?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The feature works similarly to an&amp;nbsp;offering already available in Gemini. Plus, it’s similar to the Animate tool in Meta’s Edits app, which also uses AI to transform static images into videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new tool is rolling out over the next week in the United States, Canada, Australia, and New Zealand. YouTube plans to bring it to more regions later this year. It’s worth noting that Google Photos is also getting a similar image-to-video tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new AI effects, creators can use them to transform their doodles into artistic images and turn their selfies into videos where they’re swimming underwater, twinning with someone, and more. Users can find these new effects by navigating to the “Effects” icon in the Shorts camera and then tapping “AI” to browse all of the generative effects. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030449" height="569" src="https://techcrunch.com/wp-content/uploads/2025/07/YouTube-Effect-Underwater.gif?w=320" width="320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the features announced today are powered by Veo 2, Google’s AI model for video generation. YouTube says it uses&amp;nbsp;SynthID&amp;nbsp;watermarks and&amp;nbsp;clear labels&amp;nbsp;to indicate that these creations were generated with AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last month at Cannes Lions 2025, YouTube CEO Neal Mohan announced that Google’s Veo 3 video generator, which can generate both video and audio, will be coming to Shorts later this summer. He also shared that Shorts are now averaging more than&amp;nbsp;200 billion daily views. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube also announced on Wednesday that AI Playground is its new home for generative AI creation tools, inspirational examples, prefilled prompts, and more. Creators can find AI Playground by tapping the Create button and then the sparkle icon in the top right corner. It’s available now for everyone in the United States, Canada, Australia, and New Zealand.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/youtube-shorts-is-adding-an-image-to-video-ai-tool-new-ai-effects/</guid><pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] AI Action Plan: US leadership must be ‘unchallenged’ (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-action-plan-us-leadership-must-be-unchallenged/</link><description>&lt;p&gt;The White House has released its ‘AI Action Plan’, which frames the coming decade as a technological race the US cannot afford to lose.&lt;/p&gt;&lt;p&gt;Laced with the urgent rhetoric of a new cold war, the action plan argues that securing victory in AI is nothing short of a national imperative. Trump’s foreword sets the tone, calling for America to “achieve and maintain unquestioned and unchallenged global technological dominance” as a core tenet of national security.&lt;/p&gt;&lt;p&gt;To get there, the administration is making a three-pronged push: ignite a firestorm of domestic innovation, build the colossal infrastructure to sustain it, and project American power across the globe to secure the win.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🇺🇸&lt;/p&gt;&lt;p&gt;Today is a day we have been working towards for six months. We are announcing America’s AI action plan putting us on the road to continued AI dominance. &lt;/p&gt;&lt;p&gt;The three core themes:&lt;br /&gt;– Accelerate AI innovation&lt;br /&gt;– Build American AI infrastructure &lt;br /&gt;– Lead in international AI… pic.twitter.com/KBHmxCmxC6&lt;/p&gt;— Sriram Krishnan (@sriramk) July 23, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-pillar-i-an-action-plan-to-support-the-private-ai-sector"&gt;Pillar I: An action plan to support the private AI sector&lt;/h3&gt;&lt;p&gt;At its heart, the strategy is a full-throated endorsement of the private sector. The first move is to take a buzzsaw to the regulatory frameworks of the past, with the document explicitly targeting the “onerous” approach of the previous administration.&lt;/p&gt;&lt;p&gt;The philosophy is simple: get out of the way and let innovators innovate. According to US Vice President JD Vance, smothering the technology with rules now would be to “paralyse one of the most promising technologies we have seen in generations.”&lt;/p&gt;&lt;p&gt;The plan even uses the power of federal funding as a stick, threatening to withhold money from states that dare to enact their own “burdensome AI regulations.”&lt;/p&gt;&lt;p&gt;It also strides confidently into the culture wars, insisting that AI systems paid for by the taxpayer must reflect “American values.” This means a preference for models that are “objective and free from top-down ideological bias” and a directive to scrub concepts like misinformation and Diversity, Equity, and Inclusion from the government’s official AI risk guides.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pillar-ii-a-foundation-of-concrete-and-code"&gt;Pillar II: A foundation of concrete and code&lt;/h3&gt;&lt;p&gt;The second pillar of the action plan relates to the raw, physical demands of the AI revolution.&lt;/p&gt;&lt;p&gt;“AI is the first digital service in modern life that challenges America to build vastly greater energy generation than we have today,” the plan bluntly states. Its answer is a national mobilisation under the banner of “Build, Baby, Build!”—a vast undertaking to erect data centres, bring semiconductor manufacturing home, and construct the power grid of the future.&lt;/p&gt;&lt;p&gt;This means fast-tracking environmental permits and overhauling the nation’s energy supply, mixing today’s power sources with tomorrow’s bets on nuclear fusion. Bringing chipmaking back to US shores is central to this vision, with a promise to refocus the CHIPS Program Office on delivering results without ideological strings attached.&lt;/p&gt;&lt;p&gt;And, behind it all, a push to train a new generation of technicians and engineers to build and maintain this new industrial backbone.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pillar-iii-ensuring-an-undisputed-lead-on-the-world-stage"&gt;Pillar III: Ensuring an undisputed lead on the world stage&lt;/h3&gt;&lt;p&gt;The final pillar is about shaping the world in America’s image. The ambition is to make the entire US tech stack – from silicon to the software – the undisputed “gold standard for AI worldwide.” This involves an aggressive export strategy to arm allies with American technology, explicitly to counter the influence of a rising China.&lt;/p&gt;&lt;p&gt;This new foreign policy will involve pushing back against Chinese influence in global forums like the United Nations, which the administration believes are being used to promote innovation-killing regulations. It also signals a more hawkish approach to security, demanding tighter controls on the advanced chips that fuel AI progress.&lt;/p&gt;&lt;p&gt;The plan confronts the dark side of AI head-on, acknowledging its potential for misuse in everything from cybercrime to bioweapons, and calls for a national effort to get ahead of the threat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-action-plan-lands-in-a-divided-industry"&gt;AI Action Plan lands in a divided industry&lt;/h3&gt;&lt;p&gt;The administration’s confident blueprint for the future lands in an industry deeply conflicted about its own creation. Just this week, OpenAI CEO Sam Altman warned about the technology’s disruptive power.&lt;/p&gt;&lt;p&gt;Altman warns that AI will not only eliminate jobs but also pose national security threats. He has spoken of a looming “fraud crisis” powered by AI’s ability to fool security systems, and has gone so far as to co-sign a letter stating that “mitigating the risk of extinction from AI should be a global priority”.&lt;/p&gt;&lt;p&gt;His commentary is a stark reminder that the race for AI dominance is also a race to control a technology with world-altering potential. While Washington focuses on winning, the architects of AI are quietly wrestling with what victory might actually mean.&lt;/p&gt;&lt;p&gt;However, the plan received a cautious welcome from the nonprofit Americans for Responsible Innovation (ARI). The group saw its own fingerprints on several proposals, from stronger export controls to more research into AI safety.&lt;/p&gt;&lt;p&gt;Yet ARI is deeply troubled by the administration’s move to punish states that pursue their own AI safety rules. This position also seems at odds with the views of industry leaders like Altman, who has himself warned against the chaos of 50 different state-level regulations.&lt;/p&gt;&lt;p&gt;“Ultimately, this action plan is about increasing oversight of AI systems while maintaining a hands-off approach to hard and fast regulations,” said ARI President Brad Carson. He sees a chance to better understand the “big risks frontier models create for the public,” but worries about the administration’s tactics.&lt;/p&gt;&lt;p&gt;“The plan’s targeting of state-passed AI safeguards is cause for concern. For America to lead on AI, we have to build public trust in these systems, and safeguards are essential to that public confidence.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Luke Michael)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Sam Altman: AI will cause job losses and national security threats&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The White House has released its ‘AI Action Plan’, which frames the coming decade as a technological race the US cannot afford to lose.&lt;/p&gt;&lt;p&gt;Laced with the urgent rhetoric of a new cold war, the action plan argues that securing victory in AI is nothing short of a national imperative. Trump’s foreword sets the tone, calling for America to “achieve and maintain unquestioned and unchallenged global technological dominance” as a core tenet of national security.&lt;/p&gt;&lt;p&gt;To get there, the administration is making a three-pronged push: ignite a firestorm of domestic innovation, build the colossal infrastructure to sustain it, and project American power across the globe to secure the win.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🇺🇸&lt;/p&gt;&lt;p&gt;Today is a day we have been working towards for six months. We are announcing America’s AI action plan putting us on the road to continued AI dominance. &lt;/p&gt;&lt;p&gt;The three core themes:&lt;br /&gt;– Accelerate AI innovation&lt;br /&gt;– Build American AI infrastructure &lt;br /&gt;– Lead in international AI… pic.twitter.com/KBHmxCmxC6&lt;/p&gt;— Sriram Krishnan (@sriramk) July 23, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-pillar-i-an-action-plan-to-support-the-private-ai-sector"&gt;Pillar I: An action plan to support the private AI sector&lt;/h3&gt;&lt;p&gt;At its heart, the strategy is a full-throated endorsement of the private sector. The first move is to take a buzzsaw to the regulatory frameworks of the past, with the document explicitly targeting the “onerous” approach of the previous administration.&lt;/p&gt;&lt;p&gt;The philosophy is simple: get out of the way and let innovators innovate. According to US Vice President JD Vance, smothering the technology with rules now would be to “paralyse one of the most promising technologies we have seen in generations.”&lt;/p&gt;&lt;p&gt;The plan even uses the power of federal funding as a stick, threatening to withhold money from states that dare to enact their own “burdensome AI regulations.”&lt;/p&gt;&lt;p&gt;It also strides confidently into the culture wars, insisting that AI systems paid for by the taxpayer must reflect “American values.” This means a preference for models that are “objective and free from top-down ideological bias” and a directive to scrub concepts like misinformation and Diversity, Equity, and Inclusion from the government’s official AI risk guides.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pillar-ii-a-foundation-of-concrete-and-code"&gt;Pillar II: A foundation of concrete and code&lt;/h3&gt;&lt;p&gt;The second pillar of the action plan relates to the raw, physical demands of the AI revolution.&lt;/p&gt;&lt;p&gt;“AI is the first digital service in modern life that challenges America to build vastly greater energy generation than we have today,” the plan bluntly states. Its answer is a national mobilisation under the banner of “Build, Baby, Build!”—a vast undertaking to erect data centres, bring semiconductor manufacturing home, and construct the power grid of the future.&lt;/p&gt;&lt;p&gt;This means fast-tracking environmental permits and overhauling the nation’s energy supply, mixing today’s power sources with tomorrow’s bets on nuclear fusion. Bringing chipmaking back to US shores is central to this vision, with a promise to refocus the CHIPS Program Office on delivering results without ideological strings attached.&lt;/p&gt;&lt;p&gt;And, behind it all, a push to train a new generation of technicians and engineers to build and maintain this new industrial backbone.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pillar-iii-ensuring-an-undisputed-lead-on-the-world-stage"&gt;Pillar III: Ensuring an undisputed lead on the world stage&lt;/h3&gt;&lt;p&gt;The final pillar is about shaping the world in America’s image. The ambition is to make the entire US tech stack – from silicon to the software – the undisputed “gold standard for AI worldwide.” This involves an aggressive export strategy to arm allies with American technology, explicitly to counter the influence of a rising China.&lt;/p&gt;&lt;p&gt;This new foreign policy will involve pushing back against Chinese influence in global forums like the United Nations, which the administration believes are being used to promote innovation-killing regulations. It also signals a more hawkish approach to security, demanding tighter controls on the advanced chips that fuel AI progress.&lt;/p&gt;&lt;p&gt;The plan confronts the dark side of AI head-on, acknowledging its potential for misuse in everything from cybercrime to bioweapons, and calls for a national effort to get ahead of the threat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-action-plan-lands-in-a-divided-industry"&gt;AI Action Plan lands in a divided industry&lt;/h3&gt;&lt;p&gt;The administration’s confident blueprint for the future lands in an industry deeply conflicted about its own creation. Just this week, OpenAI CEO Sam Altman warned about the technology’s disruptive power.&lt;/p&gt;&lt;p&gt;Altman warns that AI will not only eliminate jobs but also pose national security threats. He has spoken of a looming “fraud crisis” powered by AI’s ability to fool security systems, and has gone so far as to co-sign a letter stating that “mitigating the risk of extinction from AI should be a global priority”.&lt;/p&gt;&lt;p&gt;His commentary is a stark reminder that the race for AI dominance is also a race to control a technology with world-altering potential. While Washington focuses on winning, the architects of AI are quietly wrestling with what victory might actually mean.&lt;/p&gt;&lt;p&gt;However, the plan received a cautious welcome from the nonprofit Americans for Responsible Innovation (ARI). The group saw its own fingerprints on several proposals, from stronger export controls to more research into AI safety.&lt;/p&gt;&lt;p&gt;Yet ARI is deeply troubled by the administration’s move to punish states that pursue their own AI safety rules. This position also seems at odds with the views of industry leaders like Altman, who has himself warned against the chaos of 50 different state-level regulations.&lt;/p&gt;&lt;p&gt;“Ultimately, this action plan is about increasing oversight of AI systems while maintaining a hands-off approach to hard and fast regulations,” said ARI President Brad Carson. He sees a chance to better understand the “big risks frontier models create for the public,” but worries about the administration’s tactics.&lt;/p&gt;&lt;p&gt;“The plan’s targeting of state-passed AI safeguards is cause for concern. For America to lead on AI, we have to build public trust in these systems, and safeguards are essential to that public confidence.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Luke Michael)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Sam Altman: AI will cause job losses and national security threats&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-action-plan-us-leadership-must-be-unchallenged/</guid><pubDate>Wed, 23 Jul 2025 16:20:24 +0000</pubDate></item><item><title>[NEW] Trump’s AI strategy trades guardrails for growth in race against China (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/23/trumps-ai-strategy-trades-guardrails-for-growth-in-race-against-china/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225249178.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration published its much-anticipated AI Action Plan on Wednesday, a document that takes a sharp shift away from former President Biden’s cautious approach to addressing the risks of AI,&amp;nbsp;and instead barrels ahead with plans to build out AI infrastructure, cut red tape for tech companies, shore up national security, and compete with China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The downstream effects of this shift will likely ripple throughout various industries and may even be felt by the average American consumer. For instance, the AI Action Plan downplays efforts to mitigate possible harms of AI and instead prioritizes building out data centers to power the AI industry, even if it means using federal lands or keeping them powered during critical energy grid periods.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Much of its effects, however, will depend on how the AI Action Plan is executed, and many of those details have yet to be sorted. The AI Action Plan is more blueprint for action than a step-by-step instruction book. But the direction is clear: Progress is king.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration positions this as the only way to “usher in a new golden age of human flourishing.” Its goal is to convince the American public that spending billions of taxpayer dollars on building data centers is in their best interest. Parts of the plan also include policy suggestions around upskilling workers and partnering with local governments to create jobs related to working in data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To secure our future, we must harness the full power of American innovation,” Trump said in a statement. “To do that, we will continue to reject radical climate dogma and bureaucratic red tape, as the Administration has done since Inauguration Day. Simply put, we need to ‘Build, Baby, Build!’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI Action Plan is authored by the Trump administration’s team of technology and AI specialists, many of whom come from Silicon Valley companies. This includes Office of Science and Technology Policy director Michael Kratsios; AI and crypto czar David Sacks; and assistant to the president for national security affairs Marco Rubio. More than 10,000 interest groups submitted public comments that were considered for the plan.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-deregulation-and-bringing-back-the-ai-moratorium"&gt;Deregulation and bringing back the AI moratorium&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At the start of this month, the Senate removed a controversial provision in the budget bill that would bar states from regulating AI for 10 years. That provision, if it had been included in the bill, would tie states’ federal broadband funding to compliance with the moratorium.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It appears that matter hasn’t been put to rest yet, as the AI Action Plan explores a new way to hinder states from regulating AI. As part of a broader mission to “unleash prosperity through deregulation,” the administration threatens to limit states’ federal funding based on their AI regulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan also directs the Federal Communications Commission to “evaluate whether state AI regulations interfere with the agency’s ability to carry out its obligations and authorities.” In other words, if state AI regulations touch on radio, TV, and internet — which many do — then the FCC can get involved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the federal level, the action plan directs the Office of Science and Technology Policy to ask businesses and the public about any current federal regulations that hinder AI innovation and adoption so that federal agencies can take appropriate action.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-cutting-red-tape-around-data-centers"&gt;Cutting red tape around data centers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s call for deregulation extends to how the administration hopes to accelerate the buildout of AI-related infrastructure, like data centers, semiconductor fabs, and power sources. The administration argues that existing environmental regulations — like NEPA, the Clean Air Act, and the Clean Water Act — are hindering America’s need to meet the rapid demands of the AI arms race.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s why Trump’s AI Action Plan places an emphasis on stabilizing America’s energy grid. At the same time, the plan asks the federal government to find new ways to ensure large power consumers — such as AI companies — can manage their power consumption during critical grid periods.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Certain companies, like xAI and Meta, have been criticized for concentrating pollution in vulnerable communities. Critics have accused xAI of bypassing environmental safeguards and exposing residents to harmful emissions from gas-powered turbines with its Memphis data center.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The action plan calls for creating categorical exclusions, streamlining permitting processes, and expanding the use of fast-track programs like FAST-41 to make it easier for companies to build critical AI infrastructure, especially on federal lands, which includes national parks, federally protected wilderness areas, and military bases.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tying back to other Trump themes of beating China, the strategy focuses on locking out foreign tech and emphasizing security protections to keep “adversarial technology” — like Chinese-made chips and hardware — out of the U.S. supply chain.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-trump-s-war-on-biased-ai"&gt;Trump’s war on “biased AI”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;One of the main standouts in Trump’s AI Action plan is a focus on protecting free speech and “American values,” in part by eliminating references to misinformation, DEI, and climate change from federal risk-assessment frameworks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is essential that these systems be built from the ground up with freedom of speech and expression in mind, and that U.S. government policy does not interfere with that objective,” the plan reads. “We must ensure that free speech flourishes in the era of AI and that AI procured by the Federal government objectively reflects truth rather than social engineering agendas.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the intention to ensure that government policy doesn’t interfere with freedom of speech, the AI Action Plan has the potential to do just that.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the recommended policy actions is to update federal procurement guidelines to ensure the government only contracts with frontier large language model developers who “ensure their systems are objective and free from top-down ideological bias.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That language is similar to what The Wall Street Journal reported would be in Trump’s executive order, which is expected to be released later today.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem is that achieving objectivity is hard, and the government has not yet defined how it plans to evaluate models on the basis of neutrality.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The only way to be neutral would be literal non-engagement,” Rumman Chowdhury, a data scientist, CEO of the tech nonprofit Humane Intelligence, and former U.S. science envoy for AI, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, xAI, Google, and OpenAI have all secured government contracts worth up to $200 million each to help integrate AI applications into the Department of Defense. The implications of Trump’s policy suggestion, and his impending executive order, could be far-reaching.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For instance, an order that says, ‘We won’t do any business, as to AI models or otherwise, with any company that produces a non-neutral AI model’ would likely violate the First Amendment,” Eugene Volokh, an American legal scholar who specializes in First Amendment and Second Amendment issues, said in an email. “An order that says, ‘We will only enter into contracts to buy models that are sufficiently neutral’ would be more constitutionally defensible, though of course implementing it effectively may be very difficult (partly because it’s so hard to know what’s ‘neutral’ in these situations).”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added: “If the order instructs agencies to select AIs based on a combination of accuracy and neutrality, leaving each agency with some latitude to decide what that means, that might be more viable.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-encouraging-an-open-approach-to-ai"&gt;Encouraging an open approach to AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan aims to encourage the development and adoption of open AI models, which are free to download online, that are created with American values in mind. This largely seems to be a reaction to the rise of open AI models from Chinese AI labs, including DeepSeek and Alibaba’s Qwen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of his plan, Trump wants to ensure that startups and researchers working on open models have access to large computing clusters. These resources are expensive, and typically were only possible for tech companies that could strike million or billion-dollar contracts with cloud providers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump also says he wants to partner with leading AI model developers to increase the research community’s access to private AI models and data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;American AI companies and organizations that have taken an open approach — including Meta, AI2, and Hugging Face — could benefit from Trump’s embrace of open AI.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-safety-and-security"&gt;AI safety and security&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan includes some provisions to satisfy the AI safety community. One of those efforts includes launching a federal technological development program to research AI interpretability, AI control systems, and adversarial robustness. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s plan also instructs federal agencies including the Department of Defense and Department of Energy to host hackathons to test its AI systems for security vulnerabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s plan also acknowledges the risks of AI systems to contribute to cyberattacks, as well as the development of chemical and biological weapons. The plan asks frontier AI model developers to work with federal agencies to evaluate these risks, and how they could jeopardize America’s national security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Compared to Biden’s AI executive order, Trump’s plan puts less of a focus on requiring leading AI model developers to report safety and security standards. Many tech companies claim safety and security reporting is an “onerous” task, which Trump seems to want to limit.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-limiting-china"&gt;Limiting China&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps unsurprisingly, Trump is bringing his war on China into the AI race with his action plan. A large part of Trump’s AI Action Plan focuses on preventing “national security” threats from accessing advanced AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under Trump’s plan, federal agencies will work together to collect intelligence on foreign frontier AI projects that could threaten American national security. In one of those efforts, the Department of Commerce is tasked with evaluating Chinese AI models for alignment with Chinese Communist Party talking points and censorship.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These groups will also conduct assessments on the level of AI adoption among America’s adversaries.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-national-security"&gt;National security&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;“National security” was included 23 times in the AI Action Plan – more than data centers, jobs, science, and other key terms. The plan’s national security strategy is centered on integrating AI into the U.S. defense and intelligence apparatus, and even building out AI data centers for the DoD, while guarding against foreign threats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other things, the plan calls for the DOD and intelligence community to regularly assess how AI adoption in the U.S. compares to rivals like China and adapt accordingly, and to evaluate risks posed by both domestic and adversary AI systems. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within the DOD itself, the strategy emphasizes upskilling the military workforce, automating workflows, and securing preferential access to compute resources during national emergencies.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225249178.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration published its much-anticipated AI Action Plan on Wednesday, a document that takes a sharp shift away from former President Biden’s cautious approach to addressing the risks of AI,&amp;nbsp;and instead barrels ahead with plans to build out AI infrastructure, cut red tape for tech companies, shore up national security, and compete with China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The downstream effects of this shift will likely ripple throughout various industries and may even be felt by the average American consumer. For instance, the AI Action Plan downplays efforts to mitigate possible harms of AI and instead prioritizes building out data centers to power the AI industry, even if it means using federal lands or keeping them powered during critical energy grid periods.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Much of its effects, however, will depend on how the AI Action Plan is executed, and many of those details have yet to be sorted. The AI Action Plan is more blueprint for action than a step-by-step instruction book. But the direction is clear: Progress is king.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration positions this as the only way to “usher in a new golden age of human flourishing.” Its goal is to convince the American public that spending billions of taxpayer dollars on building data centers is in their best interest. Parts of the plan also include policy suggestions around upskilling workers and partnering with local governments to create jobs related to working in data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To secure our future, we must harness the full power of American innovation,” Trump said in a statement. “To do that, we will continue to reject radical climate dogma and bureaucratic red tape, as the Administration has done since Inauguration Day. Simply put, we need to ‘Build, Baby, Build!’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI Action Plan is authored by the Trump administration’s team of technology and AI specialists, many of whom come from Silicon Valley companies. This includes Office of Science and Technology Policy director Michael Kratsios; AI and crypto czar David Sacks; and assistant to the president for national security affairs Marco Rubio. More than 10,000 interest groups submitted public comments that were considered for the plan.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-deregulation-and-bringing-back-the-ai-moratorium"&gt;Deregulation and bringing back the AI moratorium&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At the start of this month, the Senate removed a controversial provision in the budget bill that would bar states from regulating AI for 10 years. That provision, if it had been included in the bill, would tie states’ federal broadband funding to compliance with the moratorium.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It appears that matter hasn’t been put to rest yet, as the AI Action Plan explores a new way to hinder states from regulating AI. As part of a broader mission to “unleash prosperity through deregulation,” the administration threatens to limit states’ federal funding based on their AI regulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The plan also directs the Federal Communications Commission to “evaluate whether state AI regulations interfere with the agency’s ability to carry out its obligations and authorities.” In other words, if state AI regulations touch on radio, TV, and internet — which many do — then the FCC can get involved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the federal level, the action plan directs the Office of Science and Technology Policy to ask businesses and the public about any current federal regulations that hinder AI innovation and adoption so that federal agencies can take appropriate action.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-cutting-red-tape-around-data-centers"&gt;Cutting red tape around data centers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s call for deregulation extends to how the administration hopes to accelerate the buildout of AI-related infrastructure, like data centers, semiconductor fabs, and power sources. The administration argues that existing environmental regulations — like NEPA, the Clean Air Act, and the Clean Water Act — are hindering America’s need to meet the rapid demands of the AI arms race.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s why Trump’s AI Action Plan places an emphasis on stabilizing America’s energy grid. At the same time, the plan asks the federal government to find new ways to ensure large power consumers — such as AI companies — can manage their power consumption during critical grid periods.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Certain companies, like xAI and Meta, have been criticized for concentrating pollution in vulnerable communities. Critics have accused xAI of bypassing environmental safeguards and exposing residents to harmful emissions from gas-powered turbines with its Memphis data center.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The action plan calls for creating categorical exclusions, streamlining permitting processes, and expanding the use of fast-track programs like FAST-41 to make it easier for companies to build critical AI infrastructure, especially on federal lands, which includes national parks, federally protected wilderness areas, and military bases.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tying back to other Trump themes of beating China, the strategy focuses on locking out foreign tech and emphasizing security protections to keep “adversarial technology” — like Chinese-made chips and hardware — out of the U.S. supply chain.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-trump-s-war-on-biased-ai"&gt;Trump’s war on “biased AI”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;One of the main standouts in Trump’s AI Action plan is a focus on protecting free speech and “American values,” in part by eliminating references to misinformation, DEI, and climate change from federal risk-assessment frameworks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is essential that these systems be built from the ground up with freedom of speech and expression in mind, and that U.S. government policy does not interfere with that objective,” the plan reads. “We must ensure that free speech flourishes in the era of AI and that AI procured by the Federal government objectively reflects truth rather than social engineering agendas.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the intention to ensure that government policy doesn’t interfere with freedom of speech, the AI Action Plan has the potential to do just that.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the recommended policy actions is to update federal procurement guidelines to ensure the government only contracts with frontier large language model developers who “ensure their systems are objective and free from top-down ideological bias.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That language is similar to what The Wall Street Journal reported would be in Trump’s executive order, which is expected to be released later today.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem is that achieving objectivity is hard, and the government has not yet defined how it plans to evaluate models on the basis of neutrality.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The only way to be neutral would be literal non-engagement,” Rumman Chowdhury, a data scientist, CEO of the tech nonprofit Humane Intelligence, and former U.S. science envoy for AI, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, xAI, Google, and OpenAI have all secured government contracts worth up to $200 million each to help integrate AI applications into the Department of Defense. The implications of Trump’s policy suggestion, and his impending executive order, could be far-reaching.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For instance, an order that says, ‘We won’t do any business, as to AI models or otherwise, with any company that produces a non-neutral AI model’ would likely violate the First Amendment,” Eugene Volokh, an American legal scholar who specializes in First Amendment and Second Amendment issues, said in an email. “An order that says, ‘We will only enter into contracts to buy models that are sufficiently neutral’ would be more constitutionally defensible, though of course implementing it effectively may be very difficult (partly because it’s so hard to know what’s ‘neutral’ in these situations).”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added: “If the order instructs agencies to select AIs based on a combination of accuracy and neutrality, leaving each agency with some latitude to decide what that means, that might be more viable.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-encouraging-an-open-approach-to-ai"&gt;Encouraging an open approach to AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan aims to encourage the development and adoption of open AI models, which are free to download online, that are created with American values in mind. This largely seems to be a reaction to the rise of open AI models from Chinese AI labs, including DeepSeek and Alibaba’s Qwen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of his plan, Trump wants to ensure that startups and researchers working on open models have access to large computing clusters. These resources are expensive, and typically were only possible for tech companies that could strike million or billion-dollar contracts with cloud providers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump also says he wants to partner with leading AI model developers to increase the research community’s access to private AI models and data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;American AI companies and organizations that have taken an open approach — including Meta, AI2, and Hugging Face — could benefit from Trump’s embrace of open AI.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-safety-and-security"&gt;AI safety and security&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s AI Action Plan includes some provisions to satisfy the AI safety community. One of those efforts includes launching a federal technological development program to research AI interpretability, AI control systems, and adversarial robustness. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s plan also instructs federal agencies including the Department of Defense and Department of Energy to host hackathons to test its AI systems for security vulnerabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trump’s plan also acknowledges the risks of AI systems to contribute to cyberattacks, as well as the development of chemical and biological weapons. The plan asks frontier AI model developers to work with federal agencies to evaluate these risks, and how they could jeopardize America’s national security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Compared to Biden’s AI executive order, Trump’s plan puts less of a focus on requiring leading AI model developers to report safety and security standards. Many tech companies claim safety and security reporting is an “onerous” task, which Trump seems to want to limit.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-limiting-china"&gt;Limiting China&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps unsurprisingly, Trump is bringing his war on China into the AI race with his action plan. A large part of Trump’s AI Action Plan focuses on preventing “national security” threats from accessing advanced AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under Trump’s plan, federal agencies will work together to collect intelligence on foreign frontier AI projects that could threaten American national security. In one of those efforts, the Department of Commerce is tasked with evaluating Chinese AI models for alignment with Chinese Communist Party talking points and censorship.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These groups will also conduct assessments on the level of AI adoption among America’s adversaries.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-national-security"&gt;National security&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;“National security” was included 23 times in the AI Action Plan – more than data centers, jobs, science, and other key terms. The plan’s national security strategy is centered on integrating AI into the U.S. defense and intelligence apparatus, and even building out AI data centers for the DoD, while guarding against foreign threats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other things, the plan calls for the DOD and intelligence community to regularly assess how AI adoption in the U.S. compares to rivals like China and adapt accordingly, and to evaluate risks posed by both domestic and adversary AI systems. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within the DOD itself, the strategy emphasizes upskilling the military workforce, automating workflows, and securing preferential access to compute resources during national emergencies.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/23/trumps-ai-strategy-trades-guardrails-for-growth-in-race-against-china/</guid><pubDate>Wed, 23 Jul 2025 16:57:21 +0000</pubDate></item></channel></rss>