<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 03 Oct 2025 01:28:11 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Last chance alert: Founder and Investor Bundle savings for TechCrunch Disrupt 2025 ends tomorrow (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/last-chance-alert-founder-and-investor-bundle-savings-for-techcrunch-disrupt-2025-ends-tomorrow/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ticktock! The Founder and Investor Bundle sale for &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; ends tomorrow, October 3, at 11:59 p.m. PT. After that, founders will no longer be able to register in bulk at a discount, and investors will drop back to the standard 15% savings. Don’t miss your chance to save more and supercharge your Disrupt experience as a community.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-disrupt-is-the-startup-launchpad-for-founders-and-investors-alike"&gt;Disrupt is the startup launchpad for founders and investors alike&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt 2025 will unite 10,000+ founders, investors, and tech leaders from across the globe. It’s the ultimate launchpad for startups at every stage, where investors spot the next big opportunity first, and innovators witness tomorrow’s tech in action — all while forging connections that drive real growth.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A crowd gathers at TechCrunch Disrupt 2023." class="wp-image-2603813" height="452" src="https://techcrunch.com/wp-content/uploads/2023/09/53201301271_a926f46eb3_6k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jann Hendry/TPG for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="h-for-founders"&gt;For founders&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive sessions for founders:&lt;/strong&gt; From fundraising strategies to AI integration and tactical GTM advice, learn what it takes to scale smart.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Hands-on playbooks:&lt;/strong&gt; Actionable insights from top operators like Aaron Levie (Box), Phoebe Gates (Phia), and Vinod Khosla (Khosla Ventures).&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;AI and innovation sessions:&lt;/strong&gt; Tekedra Mawakani (Waymo), Thomas Wolf (Hugging Face), and Soyoung Lee (TwelveLabs) explore AI’s role in product, creativity, and company building. &lt;strong&gt;Discover the sessions here&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Network with investors:&lt;/strong&gt; Curated VC matchmaking, early access to investor lists, and exclusive Deal Flow Cafe connections.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Access every stage of Disrupt:&lt;/strong&gt; Builders Stage, Space Stage, Going Public Stage, plus five industry-focused tracks, roundtables, and breakout sessions for both tactical and strategic learning. &lt;strong&gt;Explore the expanding agenda&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Startup Battlefield 200 winner" class="wp-image-2913224" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54106407705_97a51974e8_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-for-investors"&gt;For investors&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Meet 200+ pitch-ready startups:&lt;/strong&gt; Pre-Series A companies competing for $100,000 in equity-free funding.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated meetings:&lt;/strong&gt; Connect 1:1 or in small groups with founders aligned to your portfolio focus.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor-only programming:&lt;/strong&gt; StrictlyVC is back at Disrupt, delivering LP tracks and exclusive insights from leading VCs.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder connections:&lt;/strong&gt; Early access to founders who’ve opted in to connect with investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Deal Flow Cafe:&lt;/strong&gt; Informal networking with active founders and emerging startups.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-bundle-savings-end-tomorrow-october-3"&gt;Bundle savings end tomorrow, October 3&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder Bundle:&lt;/strong&gt; Save 15% on groups of 4–9 Founder Passes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor Bundle:&lt;/strong&gt; Save 20% on groups of 4–9 Investor Passes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Limited time:&lt;/strong&gt; Offer ends &lt;strong&gt;tomorrow, October 3 at 11:59 p.m. PT&lt;/strong&gt; — once it’s gone, it’s gone.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Bring your network. Connect with founders or investors. Build the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Lock in your Founder Bundle →&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Lock in your Investor Bundle →&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ticktock! The Founder and Investor Bundle sale for &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; ends tomorrow, October 3, at 11:59 p.m. PT. After that, founders will no longer be able to register in bulk at a discount, and investors will drop back to the standard 15% savings. Don’t miss your chance to save more and supercharge your Disrupt experience as a community.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-disrupt-is-the-startup-launchpad-for-founders-and-investors-alike"&gt;Disrupt is the startup launchpad for founders and investors alike&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt 2025 will unite 10,000+ founders, investors, and tech leaders from across the globe. It’s the ultimate launchpad for startups at every stage, where investors spot the next big opportunity first, and innovators witness tomorrow’s tech in action — all while forging connections that drive real growth.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A crowd gathers at TechCrunch Disrupt 2023." class="wp-image-2603813" height="452" src="https://techcrunch.com/wp-content/uploads/2023/09/53201301271_a926f46eb3_6k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jann Hendry/TPG for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="h-for-founders"&gt;For founders&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive sessions for founders:&lt;/strong&gt; From fundraising strategies to AI integration and tactical GTM advice, learn what it takes to scale smart.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Hands-on playbooks:&lt;/strong&gt; Actionable insights from top operators like Aaron Levie (Box), Phoebe Gates (Phia), and Vinod Khosla (Khosla Ventures).&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;AI and innovation sessions:&lt;/strong&gt; Tekedra Mawakani (Waymo), Thomas Wolf (Hugging Face), and Soyoung Lee (TwelveLabs) explore AI’s role in product, creativity, and company building. &lt;strong&gt;Discover the sessions here&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Network with investors:&lt;/strong&gt; Curated VC matchmaking, early access to investor lists, and exclusive Deal Flow Cafe connections.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Access every stage of Disrupt:&lt;/strong&gt; Builders Stage, Space Stage, Going Public Stage, plus five industry-focused tracks, roundtables, and breakout sessions for both tactical and strategic learning. &lt;strong&gt;Explore the expanding agenda&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Startup Battlefield 200 winner" class="wp-image-2913224" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54106407705_97a51974e8_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-for-investors"&gt;For investors&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Meet 200+ pitch-ready startups:&lt;/strong&gt; Pre-Series A companies competing for $100,000 in equity-free funding.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated meetings:&lt;/strong&gt; Connect 1:1 or in small groups with founders aligned to your portfolio focus.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor-only programming:&lt;/strong&gt; StrictlyVC is back at Disrupt, delivering LP tracks and exclusive insights from leading VCs.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder connections:&lt;/strong&gt; Early access to founders who’ve opted in to connect with investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Deal Flow Cafe:&lt;/strong&gt; Informal networking with active founders and emerging startups.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-bundle-savings-end-tomorrow-october-3"&gt;Bundle savings end tomorrow, October 3&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder Bundle:&lt;/strong&gt; Save 15% on groups of 4–9 Founder Passes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor Bundle:&lt;/strong&gt; Save 20% on groups of 4–9 Investor Passes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Limited time:&lt;/strong&gt; Offer ends &lt;strong&gt;tomorrow, October 3 at 11:59 p.m. PT&lt;/strong&gt; — once it’s gone, it’s gone.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Bring your network. Connect with founders or investors. Build the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Lock in your Founder Bundle →&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Lock in your Investor Bundle →&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/last-chance-alert-founder-and-investor-bundle-savings-for-techcrunch-disrupt-2025-ends-tomorrow/</guid><pubDate>Thu, 02 Oct 2025 14:00:00 +0000</pubDate></item><item><title>OpenAI is the world’s most valuable private company after private stock sale (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/openai-is-the-worlds-most-valuable-private-company-after-private-stock-sale/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2206295463.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has sold $6.6 billion in shares held by current and former employees, according to a new report from Bloomberg. The sale pushed OpenAI’s total valuation to $500 billion, the highest ever achieved by a privately held company. Purchasers included SoftBank, Dragoneer Investment Group, Thrive Capital, MGX, and T. Rowe Price, the report said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The sale was not a conventional funding round, as the cash went to individuals holding shares or options in OpenAI rather than the company’s own coffers. Still, it’s a powerful retention tool for the company, which has faced significant pressure from Meta’s newly revitalized AI lab. This summer, Meta poached at least seven top engineers from OpenAI, often luring them away with multimillion-dollar signing bonuses.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI’s most recent funding round came in August, when it completed a $40 billion fundraise at a $300 billion valuation. SoftBank, Thrive, T. Rowe Price, and Dragoneer were also investors in that round, as well as private equity firms like Blackstone and TPG, and major venture capitalists like Founders Fund, Sequoia Capital, and Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The sale is also a reminder of OpenAI’s ability to raise cash as needed — a particularly important resource given the company’s ambitious infrastructure plans. OpenAI has committed to spending $300 billion on Oracle Cloud Services over the next five years, a sum that vastly outstrips its current revenue or reserves. However, the powerful momentum of the company’s fundraising suggests it’s not as outlandish as standard arithmetic would indicate. In September, Nvidia announced a plan to invest $100 billion in OpenAI as part of a strategic infrastructure partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new sale comes just weeks after a non-binding agreement between OpenAI and Microsoft, which many saw as paving the way for OpenAI’s conversion into a for-profit entity. But OpenAI’s conversion has not yet been confirmed in court, and the new sales could cause significant complications if the conversion fails to proceed as planned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI continues to develop and launch products at a blistering pace, releasing its latest Sora 2 video model and accompanying social media feed earlier this week. The company reported $4.3 billion in revenue in the first half of 2025, while burning through $2.5 billion in cash.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2206295463.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has sold $6.6 billion in shares held by current and former employees, according to a new report from Bloomberg. The sale pushed OpenAI’s total valuation to $500 billion, the highest ever achieved by a privately held company. Purchasers included SoftBank, Dragoneer Investment Group, Thrive Capital, MGX, and T. Rowe Price, the report said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The sale was not a conventional funding round, as the cash went to individuals holding shares or options in OpenAI rather than the company’s own coffers. Still, it’s a powerful retention tool for the company, which has faced significant pressure from Meta’s newly revitalized AI lab. This summer, Meta poached at least seven top engineers from OpenAI, often luring them away with multimillion-dollar signing bonuses.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI’s most recent funding round came in August, when it completed a $40 billion fundraise at a $300 billion valuation. SoftBank, Thrive, T. Rowe Price, and Dragoneer were also investors in that round, as well as private equity firms like Blackstone and TPG, and major venture capitalists like Founders Fund, Sequoia Capital, and Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The sale is also a reminder of OpenAI’s ability to raise cash as needed — a particularly important resource given the company’s ambitious infrastructure plans. OpenAI has committed to spending $300 billion on Oracle Cloud Services over the next five years, a sum that vastly outstrips its current revenue or reserves. However, the powerful momentum of the company’s fundraising suggests it’s not as outlandish as standard arithmetic would indicate. In September, Nvidia announced a plan to invest $100 billion in OpenAI as part of a strategic infrastructure partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new sale comes just weeks after a non-binding agreement between OpenAI and Microsoft, which many saw as paving the way for OpenAI’s conversion into a for-profit entity. But OpenAI’s conversion has not yet been confirmed in court, and the new sales could cause significant complications if the conversion fails to proceed as planned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI continues to develop and launch products at a blistering pace, releasing its latest Sora 2 video model and accompanying social media feed earlier this week. The company reported $4.3 billion in revenue in the first half of 2025, while burning through $2.5 billion in cash.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/openai-is-the-worlds-most-valuable-private-company-after-private-stock-sale/</guid><pubDate>Thu, 02 Oct 2025 14:35:44 +0000</pubDate></item><item><title>A new a16z report looks at which AI companies startups are actually paying for (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/a-new-a16z-report-looks-at-which-ai-companies-startups-are-actually-paying-for/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Andreessen Horowitz released its first AI Spending Report in partnership with the fintech firm Mercury. Using transaction data from Mercury, the report analyzes the top 50 AI-native application layer companies that startups are spending money on, similar to the previously published Top 100 Gen AI Consumer Apps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;a16z partners Olivia Moore and Seema Amble say the data shows companies are still adopting a range of different AI products for certain tasks — and new apps are rising and falling very quickly.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There’s a proliferation of tools,” Amble said.&amp;nbsp;“It hasn’t just coalesced around one or two in each category.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report also shows a lot of spending on “human augmentors” or “copilots” that can help boost productivity among the workforce, suggesting startups aren’t ready to fully shift into agentic workflows. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As computer use becomes more of a mode and there’s more of the ability for there to be end-to-end agentic flows built, I think that shift will happen, where we’ll see fewer copilots and more end-to-end agent tools,” Amble said. “Especially as people are really eager to give them a try.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3053515" height="434" src="https://techcrunch.com/wp-content/uploads/2025/10/a16z-list.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the top of the list was dominated by major labs, with OpenAI taking the top slot and Anthropic following up at No. 2. Vibe-coding tools were also well represented, with Replit at No. 3 and Lovable at No. 18. Cursor landed at No. 6 and Emergent at No. 48.&amp;nbsp;Cognition, which operates more enterprise-oriented coding tools like Devin and Windsurf, was at No. 34.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When a16z produced a similar list for consumer habits, Lovable ranked much higher than Replit on pure traffic alone because a lot of people were using it to create projects. But startups are not spending as much money on Lovable as they are on Replit, in part because of the lack of enterprise features. But the variety of companies on the list seems to suggest there’s room for plenty of different companies at once.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s an open question going forward on vibe coding,” Moore said. “Does the space start to consolidate, and one place becomes the best platform to vibe code? Or is it the case where there’ll be four or five more vibe coding companies that are really big businesses for different types of applications? We don’t have the answer to that yet.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moore was also surprised to see startups adopting consumer-oriented tools like CapCut and Midjourney.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing that a lot of these [consumer] companies are getting yanked into enterprise faster and faster because they make such delightful consumer tools that then people adopt and use as individuals and bring into their teams and workplaces,” Moore said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Horizontal applications overall made up at least 60% of the names on the list, and 40% consisted of vertical applications. The most popular vertical software companies fell into three buckets: sales, recruiting, and customer service.&amp;nbsp;But the report also found AI making progress in many sectors that previous generations of startups had struggled to crack.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What maybe previously would have been, like, service firms or consultancies are now software companies in the age of AI,” Moore said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amble gave Crosby Legal as an example, which can quickly review a legal contract for a user, replacing what at one point would have been a meeting with an in-house general counsel, rummaging through thoughts and research. She said right now, most of the tools are used to aid employees (like a co-pilot) in making decisions faster, rather than replacing entire workforces and talent suits with automated workers (end-to-end agents).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3053529" height="454" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2178275924.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Melanie Perkins’ Canva is one of the top enterprise apps &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nina Franova/Getty Images for SXSW Sydney&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“As the tech gets better, and we’re actually able to build out full agent co-workers, you’ll see that mix shift more toward end-to-end agents and away from co-pilots,” she said, later adding that AI tools can do much more work, like outreach, faster than a human can.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There were also a lot of note takers on the list, such as Otter.ai, Read AI, and HappyScribe — with no single option dominating. This is what Amble meant when she said there isn’t one product yet that has dominated the market; rather, startups are still picking “their own flavor” to see what tools they like best. This is also good for employees, who, with so many options, can pick what applications help them work best, rather than using a one-size-fits-all product “pushed down from the top,” Amble said.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="Anton Osika" class="wp-image-3041170" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Anton-Osika-e1756746220840.jpg?w=680" width="453" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Anton Osika’s LOvable receives more traffic than rival Replit, but not much enterprise spending&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechBBQ&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The last big find in the report was the increasing intertwining of consumer and enterprise businesses. People are bringing the personal applications they use at home to work, and people who have started companies are using their favorite personal applications to help build their businesses. Before, there would have been a delineation between the two: a set stack for what to use while building a startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amble and Moore cited Canva as an example: It’s a popular consumer app that also has a sizable enterprise audience. It took years for Canva to even add an enterprise plan. But as individual and enterprise use cases become harder to distinguish, companies are more willing to blend the two.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Your TAM [total addressable market] is no longer one or the other, but you can sell into both,” she continued. She said companies building these products might also “professionalize” faster, meaning building out enterprise teams, like go-to-market, sales, and support, so they can start selling and accruing enterprise revenue sooner, rather than depending on individual consumers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Moore and Amble are expecting the list to change quickly in the coming years. Older companies are now launching AI features to stay relevant and accessible, while new entrants arrive with new ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Legacy players, legacy almost means, ‘what was 12 months ago,’” Amble said. “If we pull this again in 12 months, will the same note-taking apps even be on there? Or will there be a whole new set?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated to reflect the note-taking apps. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Andreessen Horowitz released its first AI Spending Report in partnership with the fintech firm Mercury. Using transaction data from Mercury, the report analyzes the top 50 AI-native application layer companies that startups are spending money on, similar to the previously published Top 100 Gen AI Consumer Apps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;a16z partners Olivia Moore and Seema Amble say the data shows companies are still adopting a range of different AI products for certain tasks — and new apps are rising and falling very quickly.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There’s a proliferation of tools,” Amble said.&amp;nbsp;“It hasn’t just coalesced around one or two in each category.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report also shows a lot of spending on “human augmentors” or “copilots” that can help boost productivity among the workforce, suggesting startups aren’t ready to fully shift into agentic workflows. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As computer use becomes more of a mode and there’s more of the ability for there to be end-to-end agentic flows built, I think that shift will happen, where we’ll see fewer copilots and more end-to-end agent tools,” Amble said. “Especially as people are really eager to give them a try.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3053515" height="434" src="https://techcrunch.com/wp-content/uploads/2025/10/a16z-list.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the top of the list was dominated by major labs, with OpenAI taking the top slot and Anthropic following up at No. 2. Vibe-coding tools were also well represented, with Replit at No. 3 and Lovable at No. 18. Cursor landed at No. 6 and Emergent at No. 48.&amp;nbsp;Cognition, which operates more enterprise-oriented coding tools like Devin and Windsurf, was at No. 34.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When a16z produced a similar list for consumer habits, Lovable ranked much higher than Replit on pure traffic alone because a lot of people were using it to create projects. But startups are not spending as much money on Lovable as they are on Replit, in part because of the lack of enterprise features. But the variety of companies on the list seems to suggest there’s room for plenty of different companies at once.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s an open question going forward on vibe coding,” Moore said. “Does the space start to consolidate, and one place becomes the best platform to vibe code? Or is it the case where there’ll be four or five more vibe coding companies that are really big businesses for different types of applications? We don’t have the answer to that yet.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moore was also surprised to see startups adopting consumer-oriented tools like CapCut and Midjourney.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing that a lot of these [consumer] companies are getting yanked into enterprise faster and faster because they make such delightful consumer tools that then people adopt and use as individuals and bring into their teams and workplaces,” Moore said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Horizontal applications overall made up at least 60% of the names on the list, and 40% consisted of vertical applications. The most popular vertical software companies fell into three buckets: sales, recruiting, and customer service.&amp;nbsp;But the report also found AI making progress in many sectors that previous generations of startups had struggled to crack.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What maybe previously would have been, like, service firms or consultancies are now software companies in the age of AI,” Moore said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amble gave Crosby Legal as an example, which can quickly review a legal contract for a user, replacing what at one point would have been a meeting with an in-house general counsel, rummaging through thoughts and research. She said right now, most of the tools are used to aid employees (like a co-pilot) in making decisions faster, rather than replacing entire workforces and talent suits with automated workers (end-to-end agents).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3053529" height="454" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2178275924.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Melanie Perkins’ Canva is one of the top enterprise apps &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nina Franova/Getty Images for SXSW Sydney&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“As the tech gets better, and we’re actually able to build out full agent co-workers, you’ll see that mix shift more toward end-to-end agents and away from co-pilots,” she said, later adding that AI tools can do much more work, like outreach, faster than a human can.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There were also a lot of note takers on the list, such as Otter.ai, Read AI, and HappyScribe — with no single option dominating. This is what Amble meant when she said there isn’t one product yet that has dominated the market; rather, startups are still picking “their own flavor” to see what tools they like best. This is also good for employees, who, with so many options, can pick what applications help them work best, rather than using a one-size-fits-all product “pushed down from the top,” Amble said.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="Anton Osika" class="wp-image-3041170" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Anton-Osika-e1756746220840.jpg?w=680" width="453" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Anton Osika’s LOvable receives more traffic than rival Replit, but not much enterprise spending&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechBBQ&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The last big find in the report was the increasing intertwining of consumer and enterprise businesses. People are bringing the personal applications they use at home to work, and people who have started companies are using their favorite personal applications to help build their businesses. Before, there would have been a delineation between the two: a set stack for what to use while building a startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amble and Moore cited Canva as an example: It’s a popular consumer app that also has a sizable enterprise audience. It took years for Canva to even add an enterprise plan. But as individual and enterprise use cases become harder to distinguish, companies are more willing to blend the two.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Your TAM [total addressable market] is no longer one or the other, but you can sell into both,” she continued. She said companies building these products might also “professionalize” faster, meaning building out enterprise teams, like go-to-market, sales, and support, so they can start selling and accruing enterprise revenue sooner, rather than depending on individual consumers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Moore and Amble are expecting the list to change quickly in the coming years. Older companies are now launching AI features to stay relevant and accessible, while new entrants arrive with new ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Legacy players, legacy almost means, ‘what was 12 months ago,’” Amble said. “If we pull this again in 12 months, will the same note-taking apps even be on there? Or will there be a whole new set?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated to reflect the note-taking apps. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/a-new-a16z-report-looks-at-which-ai-companies-startups-are-actually-paying-for/</guid><pubDate>Thu, 02 Oct 2025 15:00:00 +0000</pubDate></item><item><title>Phoebe Gates and Sophia Kianni share the playbook for scaling consumer AI and winning Gen Z at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/storming-the-gates-scaling-consumer-ai-with-phoebe-gates-and-sophia-kianni-only-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Consumer AI is having its breakout moment — and few startups have captured the spotlight this year quite like &lt;strong&gt;Phia&lt;/strong&gt;. The AI-powered shopping assistant has become one of 2025’s buzziest launches, not only for its vision of how Gen Z shops, but also for the powerhouse founders leading it: &lt;strong&gt;Phoebe Gates&lt;/strong&gt; and &lt;strong&gt;Sophia Kianni&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, the two will take to the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; to share how they’re building Phia into a durable consumer brand, what it takes to scale in one of tech’s most competitive markets, and how they’re turning viral buzz into lasting market influence.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Phoebe Gates and Sophia Kianni " class="wp-image-3053437" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/TC25_Gates-Kianni-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-next-era-of-consumer-ai"&gt;The next era of consumer AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Phia aims to reinvent the way digital natives discover, compare, and shop for products — blending AI assistance with the values of conscious consumerism. For Gen Z, the shopping journey is about more than convenience. It’s about trust, personalization, and aligning choices with personal ethics. Gates and Kianni are betting that the next generation of consumer AI must deliver on all of those fronts at once.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-advocacy-to-ai"&gt;From advocacy to AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Phoebe Gates&lt;/strong&gt;, co-founder of Phia, is an entrepreneur and passionate advocate for women’s reproductive rights and gender equity. A Stanford graduate in human biology, she has worked with global healthcare leaders, activists, and advocates to drive meaningful social change. Gates applies her entrepreneurial focus to inspire a new generation of women in business. Recognized by Reproductive Freedom for All as the 2024 “Rising Reproductive Freedom Champion,” she continues to be a voice for progress while building Phia into a leading AI shopping brand.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sophia Kianni&lt;/strong&gt; is the co-founder of Phia. She is an Iranian American entrepreneur and climate activist who has made waves as the founder of Climate Cardinals, the world’s largest youth-led climate nonprofit. Named to Forbes 30 Under 30 and BBC’s 100 Women, she also served as the youngest UN climate adviser in U.S. history. Now she’s applying her storytelling and advocacy expertise to scale Phia. A Stanford alumna, Kianni is focused on using AI to empower smarter, more sustainable consumer choices.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-learn-how-to-build-for-growth-loyalty-and-impact-in-this-session"&gt;Learn how to build for growth, loyalty, and impact in this session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Scaling a consumer AI brand is not just about tech — it’s about winning trust, adapting quickly to market shifts, and knowing how to stand out in a noisy space. Gates and Kianni will discuss:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Turning attention into adoption&lt;/strong&gt;: How Phia is moving beyond hype to build real consumer loyalty.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The Gen Z factor&lt;/strong&gt;: Why today’s youngest shoppers expect personalization, transparency, and values-driven tech.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Building for scale&lt;/strong&gt;: Lessons from taking an early-stage idea into one of the toughest markets in tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-the-ticket-savings"&gt;Don’t miss the ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 10,000 founders, investors, and operators set to gather at TechCrunch Disrupt 2025, this session is a must-see for anyone building in consumer AI, commerce, or brand-driven tech who wants to win Gen Z loyalty. Be in the room when Phoebe Gates and Sophia Kianni break down the next frontier of AI-powered shopping. &lt;strong&gt;Register today to save up to $444&lt;/strong&gt;. More than just you? &lt;strong&gt;Save 20% for groups of 4-9 by tomorrow, October 3.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Consumer AI is having its breakout moment — and few startups have captured the spotlight this year quite like &lt;strong&gt;Phia&lt;/strong&gt;. The AI-powered shopping assistant has become one of 2025’s buzziest launches, not only for its vision of how Gen Z shops, but also for the powerhouse founders leading it: &lt;strong&gt;Phoebe Gates&lt;/strong&gt; and &lt;strong&gt;Sophia Kianni&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, the two will take to the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; to share how they’re building Phia into a durable consumer brand, what it takes to scale in one of tech’s most competitive markets, and how they’re turning viral buzz into lasting market influence.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Phoebe Gates and Sophia Kianni " class="wp-image-3053437" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/TC25_Gates-Kianni-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-next-era-of-consumer-ai"&gt;The next era of consumer AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Phia aims to reinvent the way digital natives discover, compare, and shop for products — blending AI assistance with the values of conscious consumerism. For Gen Z, the shopping journey is about more than convenience. It’s about trust, personalization, and aligning choices with personal ethics. Gates and Kianni are betting that the next generation of consumer AI must deliver on all of those fronts at once.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-advocacy-to-ai"&gt;From advocacy to AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Phoebe Gates&lt;/strong&gt;, co-founder of Phia, is an entrepreneur and passionate advocate for women’s reproductive rights and gender equity. A Stanford graduate in human biology, she has worked with global healthcare leaders, activists, and advocates to drive meaningful social change. Gates applies her entrepreneurial focus to inspire a new generation of women in business. Recognized by Reproductive Freedom for All as the 2024 “Rising Reproductive Freedom Champion,” she continues to be a voice for progress while building Phia into a leading AI shopping brand.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sophia Kianni&lt;/strong&gt; is the co-founder of Phia. She is an Iranian American entrepreneur and climate activist who has made waves as the founder of Climate Cardinals, the world’s largest youth-led climate nonprofit. Named to Forbes 30 Under 30 and BBC’s 100 Women, she also served as the youngest UN climate adviser in U.S. history. Now she’s applying her storytelling and advocacy expertise to scale Phia. A Stanford alumna, Kianni is focused on using AI to empower smarter, more sustainable consumer choices.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-learn-how-to-build-for-growth-loyalty-and-impact-in-this-session"&gt;Learn how to build for growth, loyalty, and impact in this session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Scaling a consumer AI brand is not just about tech — it’s about winning trust, adapting quickly to market shifts, and knowing how to stand out in a noisy space. Gates and Kianni will discuss:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Turning attention into adoption&lt;/strong&gt;: How Phia is moving beyond hype to build real consumer loyalty.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;The Gen Z factor&lt;/strong&gt;: Why today’s youngest shoppers expect personalization, transparency, and values-driven tech.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Building for scale&lt;/strong&gt;: Lessons from taking an early-stage idea into one of the toughest markets in tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-the-ticket-savings"&gt;Don’t miss the ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 10,000 founders, investors, and operators set to gather at TechCrunch Disrupt 2025, this session is a must-see for anyone building in consumer AI, commerce, or brand-driven tech who wants to win Gen Z loyalty. Be in the room when Phoebe Gates and Sophia Kianni break down the next frontier of AI-powered shopping. &lt;strong&gt;Register today to save up to $444&lt;/strong&gt;. More than just you? &lt;strong&gt;Save 20% for groups of 4-9 by tomorrow, October 3.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/storming-the-gates-scaling-consumer-ai-with-phoebe-gates-and-sophia-kianni-only-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 02 Oct 2025 15:00:00 +0000</pubDate></item><item><title>Perplexity’s Comet AI browser now free; Max users get new ‘background assistant’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/perplexitys-comet-ai-browser-now-free-max-users-get-new-background-assistant/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI search startup Perplexity is making its new Comet browser available to everyone in the world for free&amp;nbsp;as it works to position the product against big browsers and search engines.&amp;nbsp;For certain paid subscribers, the startup has also launched a new “background assistant” to handle multiple tasks via Comet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity first launched&amp;nbsp;Comet to&amp;nbsp;subscribers of its $200-per-month Max plan&amp;nbsp;three months ago, and since then, “millions” have signed up on the waitlist to download the browser.&amp;nbsp;Comet’s main feature is a sidecar assistant that joins you while you browse, helping to answer any questions you may have about the web page&amp;nbsp;you’re&amp;nbsp;on,&amp;nbsp;summarize content, manage web content, and navigate web pages on your behalf.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perplexity’s move to make Comet free comes as the startup&amp;nbsp;fights to compete against both incumbents like&amp;nbsp;Google Chrome&amp;nbsp;and newcomers like&amp;nbsp;The Browser Company’s AI-powered browser Dia.&amp;nbsp;It also comes ahead of OpenAI’s&amp;nbsp;much-anticipated&amp;nbsp;AI-powered browser launch.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the face of such competition, Perplexity will need to prove that Comet’s agentic capabilities&amp;nbsp;work reliably. Because without tangible productivity gains, people might be less inclined to switch from their existing browsers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For free users,&amp;nbsp;Perplexity’s Comet browser experience is still limited to the sidecar assistant.&amp;nbsp;All users can also access different tools like Discover (personalized news and content recommendations similar to OpenAI’s new Pulse); Spaces (to organize and manage different projects); Shopping (assists in&amp;nbsp;comparing prices and finding deals across online retailers); Travel (offers aggregated information on travel destinations, flights, accommodation,&amp;nbsp;etc.); Finance (tools for budgeting, tracking expenses, monitoring investments); and Sports (updates on scores, schedules, and news).&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Max users get access to high-performing AI models&amp;nbsp;and&amp;nbsp;can access Perplexity’s email assistant, which&amp;nbsp;promises to draft replies and write responses that match your tone; organize and prioritize your inbox; schedule meetings; and answer questions about your inbox.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Max users&amp;nbsp;also&amp;nbsp;get&amp;nbsp;early access&amp;nbsp;to&amp;nbsp;Perplexity products and features, including a new “background assistant” that CEO Aravind Srinivas announced at an event Wednesday evening.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053597" height="482" src="https://techcrunch.com/wp-content/uploads/2025/10/PNG-image.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Perplexity’s “background assistant” can perform multiple tasks at once&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Perplexity&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson described&amp;nbsp;the assistant as “a team of assistants working for you”&amp;nbsp;that you can manage&amp;nbsp;and track&amp;nbsp;from a central dashboard like a “mission control.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant performs&amp;nbsp;multiple&amp;nbsp;tasks on your computer in the background while you do other work or walk away to make a sandwich.&amp;nbsp;In an example a spokesperson gave me, you could give the assistant a task to send an email, add the cheapest tickets to a concert to your cart, and find the best direct flight on a specific date and time.&amp;nbsp;You can check the progress of the task completion in the dashboard&amp;nbsp;and&amp;nbsp;jump in to complete the tasks — like hitting send on the email, intervening, or taking over. The assistant will&amp;nbsp;notify you&amp;nbsp;when it has finished its task.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The&amp;nbsp;background assistant&amp;nbsp;also has&amp;nbsp;“better connectors,” so it can access other apps on your computer, per the spokesperson.&amp;nbsp;TechCrunch asked for more specifics about use cases and where the background assistant thrives.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Free Comet users can also&amp;nbsp;purchase&amp;nbsp;a $5-per-month standalone subscription to Comet Plus, a forthcoming product that aims to provide an AI-enhanced alternative to Apple News.&amp;nbsp;Pro users (who pay $20-per-month for&amp;nbsp;advanced AI models, image and video generation, file&amp;nbsp;upload&amp;nbsp;and analysis, etc.)&amp;nbsp;and Max users will get access to Comet Plus automatically.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI search startup Perplexity is making its new Comet browser available to everyone in the world for free&amp;nbsp;as it works to position the product against big browsers and search engines.&amp;nbsp;For certain paid subscribers, the startup has also launched a new “background assistant” to handle multiple tasks via Comet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity first launched&amp;nbsp;Comet to&amp;nbsp;subscribers of its $200-per-month Max plan&amp;nbsp;three months ago, and since then, “millions” have signed up on the waitlist to download the browser.&amp;nbsp;Comet’s main feature is a sidecar assistant that joins you while you browse, helping to answer any questions you may have about the web page&amp;nbsp;you’re&amp;nbsp;on,&amp;nbsp;summarize content, manage web content, and navigate web pages on your behalf.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perplexity’s move to make Comet free comes as the startup&amp;nbsp;fights to compete against both incumbents like&amp;nbsp;Google Chrome&amp;nbsp;and newcomers like&amp;nbsp;The Browser Company’s AI-powered browser Dia.&amp;nbsp;It also comes ahead of OpenAI’s&amp;nbsp;much-anticipated&amp;nbsp;AI-powered browser launch.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the face of such competition, Perplexity will need to prove that Comet’s agentic capabilities&amp;nbsp;work reliably. Because without tangible productivity gains, people might be less inclined to switch from their existing browsers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For free users,&amp;nbsp;Perplexity’s Comet browser experience is still limited to the sidecar assistant.&amp;nbsp;All users can also access different tools like Discover (personalized news and content recommendations similar to OpenAI’s new Pulse); Spaces (to organize and manage different projects); Shopping (assists in&amp;nbsp;comparing prices and finding deals across online retailers); Travel (offers aggregated information on travel destinations, flights, accommodation,&amp;nbsp;etc.); Finance (tools for budgeting, tracking expenses, monitoring investments); and Sports (updates on scores, schedules, and news).&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Max users get access to high-performing AI models&amp;nbsp;and&amp;nbsp;can access Perplexity’s email assistant, which&amp;nbsp;promises to draft replies and write responses that match your tone; organize and prioritize your inbox; schedule meetings; and answer questions about your inbox.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Max users&amp;nbsp;also&amp;nbsp;get&amp;nbsp;early access&amp;nbsp;to&amp;nbsp;Perplexity products and features, including a new “background assistant” that CEO Aravind Srinivas announced at an event Wednesday evening.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053597" height="482" src="https://techcrunch.com/wp-content/uploads/2025/10/PNG-image.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Perplexity’s “background assistant” can perform multiple tasks at once&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Perplexity&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson described&amp;nbsp;the assistant as “a team of assistants working for you”&amp;nbsp;that you can manage&amp;nbsp;and track&amp;nbsp;from a central dashboard like a “mission control.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant performs&amp;nbsp;multiple&amp;nbsp;tasks on your computer in the background while you do other work or walk away to make a sandwich.&amp;nbsp;In an example a spokesperson gave me, you could give the assistant a task to send an email, add the cheapest tickets to a concert to your cart, and find the best direct flight on a specific date and time.&amp;nbsp;You can check the progress of the task completion in the dashboard&amp;nbsp;and&amp;nbsp;jump in to complete the tasks — like hitting send on the email, intervening, or taking over. The assistant will&amp;nbsp;notify you&amp;nbsp;when it has finished its task.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The&amp;nbsp;background assistant&amp;nbsp;also has&amp;nbsp;“better connectors,” so it can access other apps on your computer, per the spokesperson.&amp;nbsp;TechCrunch asked for more specifics about use cases and where the background assistant thrives.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Free Comet users can also&amp;nbsp;purchase&amp;nbsp;a $5-per-month standalone subscription to Comet Plus, a forthcoming product that aims to provide an AI-enhanced alternative to Apple News.&amp;nbsp;Pro users (who pay $20-per-month for&amp;nbsp;advanced AI models, image and video generation, file&amp;nbsp;upload&amp;nbsp;and analysis, etc.)&amp;nbsp;and Max users will get access to Comet Plus automatically.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/perplexitys-comet-ai-browser-now-free-max-users-get-new-background-assistant/</guid><pubDate>Thu, 02 Oct 2025 15:36:09 +0000</pubDate></item><item><title>Ex-OpenAI researcher dissects one of ChatGPT’s delusional spirals (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/ex-openai-researcher-dissects-one-of-chatgpts-delusional-spirals/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Allan Brooks never set out to reinvent mathematics. But after weeks spent talking with ChatGPT, the 47-year-old Canadian came to believe he had discovered a new form of math powerful enough to take down the internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brooks — who had no history of mental illness or mathematical genius — spent 21 days in May spiraling deeper into the chatbot’s reassurances, a descent later detailed in The New York Times. His case illustrated how AI chatbots can venture down dangerous rabbit holes with users, leading them toward delusion or worse.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That story caught the attention of Steven Adler, a former OpenAI safety researcher who left the company in late 2024 after nearly four years working to make its models less harmful. Intrigued and alarmed, Adler contacted Brooks and obtained the full transcript of his three-week breakdown — a document longer than all seven Harry Potter books combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Adler published an independent analysis of Brooks’ incident, raising questions about how OpenAI handles users in moments of crisis and offering some practical recommendations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m really concerned by how OpenAI handled support here,” said Adler in an interview with TechCrunch. “It’s evidence there’s a long way to go.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brooks’ story, and others like it, have forced OpenAI to come to terms with how ChatGPT supports fragile or mentally unstable users. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, this August, OpenAI was sued by the parents of a 16-year-old boy who confided his suicidal thoughts in ChatGPT before he took his life. In many of these cases, ChatGPT — specifically a version powered by OpenAI’s GPT-4o model — encouraged and reinforced dangerous beliefs in users that it should have pushed back on. This is called sycophancy, and it’s a growing problem in AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response, OpenAI has made several changes to how ChatGPT handles users in emotional distress and reorganized a key research team in charge of model behavior. The company also released a new default model in ChatGPT, GPT-5, that seems better at handling distressed users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler says there’s still much more work to do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was especially concerned by the tail end of Brooks’ spiraling conversation with ChatGPT. At this point, Brooks came to his senses and realized that his mathematical discovery was a farce, despite GPT-4o’s insistence. He told ChatGPT that he needed to report the incident to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After weeks of misleading Brooks, ChatGPT lied about its own capabilities. The chatbot claimed it would “escalate this conversation internally&amp;nbsp;right now for review by OpenAI,” and then repeatedly reassured Brooks that it had flagged the issue to OpenAI’s safety teams.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053592" height="617" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-02-at-8.20.35AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;ChatGPT misleading brooks about its capabilities.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steven Adler&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Except, none of that was true. ChatGPT doesn’t have the ability to file incident reports with OpenAI, the company confirmed to Adler. Later on, Brooks tried to contact OpenAI’s support team directly — not through ChatGPT — and Brooks was met with several automated messages before he could get through to a person.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not immediately respond to a request for comment made outside of normal work hours.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler says AI companies need to do more to help users when they’re asking for help. That means ensuring AI chatbots can honestly answer questions about their capabilities and giving human support teams enough resources to address users properly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI recently shared how it’s addressing support in ChatGPT, which involves AI at its core. The company says its vision is to “reimagine support as an AI operating model that continuously learns and improves.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Adler also says there are ways to prevent ChatGPT’s delusional spirals before a user asks for help.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, OpenAI and MIT Media Lab jointly developed a suite of classifiers to study emotional well-being in ChatGPT and open sourced them. The organizations aimed to evaluate how AI models validate or confirm a user’s feelings, among other metrics. However, OpenAI called the collaboration a first step and didn’t commit to actually using the tools in practice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler retroactively applied some of OpenAI’s classifiers to some of Brooks’ conversations with ChatGPT and found that they repeatedly flagged ChatGPT for delusion-reinforcing behaviors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In one sample of 200 messages, Adler found that more than 85% of ChatGPT’s messages in Brooks’ conversation demonstrated “unwavering agreement” with the user. In the same sample, more than 90% of ChatGPT’s messages with Brooks “affirm the user’s uniqueness.” In this case, the messages agreed and reaffirmed that Brooks was a genius who could save the world.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053589" height="349" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-02-at-8.19.27AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steven Adler&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether OpenAI was applying safety classifiers to ChatGPT’s conversations at the time of Brooks’ conversation, but it certainly seems like they would have flagged something like this. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler suggests that OpenAI should use safety tools like this in practice today — and implement a way to scan the company’s products for at-risk users. He notes that OpenAI seems to be doing some version of this approach with GPT-5, which contains a router to direct sensitive queries to safer AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The former OpenAI researcher suggests a number of other ways to prevent delusional spirals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He says companies should nudge their chatbot users to start new chats more frequently — OpenAI says it does this and claims its guardrails are less effective in longer conversations. Adler also suggests companies should use conceptual search — a way to use AI to search for concepts, rather than keywords — to identify safety violations across its users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has taken significant steps toward addressing distressed users in ChatGPT since these concerning stories first emerged. The company claims GPT-5 has lower rates of sycophancy, but it remains unclear if users will still fall down delusional rabbit holes with GPT-5 or future models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler’s analysis also raises questions about how other AI chatbot providers will ensure their products are safe for distressed users. While OpenAI may put sufficient safeguards in place for ChatGPT, it seems unlikely that all companies will follow suit.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Allan Brooks never set out to reinvent mathematics. But after weeks spent talking with ChatGPT, the 47-year-old Canadian came to believe he had discovered a new form of math powerful enough to take down the internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brooks — who had no history of mental illness or mathematical genius — spent 21 days in May spiraling deeper into the chatbot’s reassurances, a descent later detailed in The New York Times. His case illustrated how AI chatbots can venture down dangerous rabbit holes with users, leading them toward delusion or worse.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That story caught the attention of Steven Adler, a former OpenAI safety researcher who left the company in late 2024 after nearly four years working to make its models less harmful. Intrigued and alarmed, Adler contacted Brooks and obtained the full transcript of his three-week breakdown — a document longer than all seven Harry Potter books combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Adler published an independent analysis of Brooks’ incident, raising questions about how OpenAI handles users in moments of crisis and offering some practical recommendations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m really concerned by how OpenAI handled support here,” said Adler in an interview with TechCrunch. “It’s evidence there’s a long way to go.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brooks’ story, and others like it, have forced OpenAI to come to terms with how ChatGPT supports fragile or mentally unstable users. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, this August, OpenAI was sued by the parents of a 16-year-old boy who confided his suicidal thoughts in ChatGPT before he took his life. In many of these cases, ChatGPT — specifically a version powered by OpenAI’s GPT-4o model — encouraged and reinforced dangerous beliefs in users that it should have pushed back on. This is called sycophancy, and it’s a growing problem in AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response, OpenAI has made several changes to how ChatGPT handles users in emotional distress and reorganized a key research team in charge of model behavior. The company also released a new default model in ChatGPT, GPT-5, that seems better at handling distressed users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler says there’s still much more work to do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was especially concerned by the tail end of Brooks’ spiraling conversation with ChatGPT. At this point, Brooks came to his senses and realized that his mathematical discovery was a farce, despite GPT-4o’s insistence. He told ChatGPT that he needed to report the incident to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After weeks of misleading Brooks, ChatGPT lied about its own capabilities. The chatbot claimed it would “escalate this conversation internally&amp;nbsp;right now for review by OpenAI,” and then repeatedly reassured Brooks that it had flagged the issue to OpenAI’s safety teams.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053592" height="617" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-02-at-8.20.35AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;ChatGPT misleading brooks about its capabilities.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steven Adler&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Except, none of that was true. ChatGPT doesn’t have the ability to file incident reports with OpenAI, the company confirmed to Adler. Later on, Brooks tried to contact OpenAI’s support team directly — not through ChatGPT — and Brooks was met with several automated messages before he could get through to a person.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not immediately respond to a request for comment made outside of normal work hours.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler says AI companies need to do more to help users when they’re asking for help. That means ensuring AI chatbots can honestly answer questions about their capabilities and giving human support teams enough resources to address users properly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI recently shared how it’s addressing support in ChatGPT, which involves AI at its core. The company says its vision is to “reimagine support as an AI operating model that continuously learns and improves.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Adler also says there are ways to prevent ChatGPT’s delusional spirals before a user asks for help.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, OpenAI and MIT Media Lab jointly developed a suite of classifiers to study emotional well-being in ChatGPT and open sourced them. The organizations aimed to evaluate how AI models validate or confirm a user’s feelings, among other metrics. However, OpenAI called the collaboration a first step and didn’t commit to actually using the tools in practice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler retroactively applied some of OpenAI’s classifiers to some of Brooks’ conversations with ChatGPT and found that they repeatedly flagged ChatGPT for delusion-reinforcing behaviors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In one sample of 200 messages, Adler found that more than 85% of ChatGPT’s messages in Brooks’ conversation demonstrated “unwavering agreement” with the user. In the same sample, more than 90% of ChatGPT’s messages with Brooks “affirm the user’s uniqueness.” In this case, the messages agreed and reaffirmed that Brooks was a genius who could save the world.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3053589" height="349" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-02-at-8.19.27AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steven Adler&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether OpenAI was applying safety classifiers to ChatGPT’s conversations at the time of Brooks’ conversation, but it certainly seems like they would have flagged something like this. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler suggests that OpenAI should use safety tools like this in practice today — and implement a way to scan the company’s products for at-risk users. He notes that OpenAI seems to be doing some version of this approach with GPT-5, which contains a router to direct sensitive queries to safer AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The former OpenAI researcher suggests a number of other ways to prevent delusional spirals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He says companies should nudge their chatbot users to start new chats more frequently — OpenAI says it does this and claims its guardrails are less effective in longer conversations. Adler also suggests companies should use conceptual search — a way to use AI to search for concepts, rather than keywords — to identify safety violations across its users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has taken significant steps toward addressing distressed users in ChatGPT since these concerning stories first emerged. The company claims GPT-5 has lower rates of sycophancy, but it remains unclear if users will still fall down delusional rabbit holes with GPT-5 or future models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adler’s analysis also raises questions about how other AI chatbot providers will ensure their products are safe for distressed users. While OpenAI may put sufficient safeguards in place for ChatGPT, it seems unlikely that all companies will follow suit.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/ex-openai-researcher-dissects-one-of-chatgpts-delusional-spirals/</guid><pubDate>Thu, 02 Oct 2025 15:46:25 +0000</pubDate></item><item><title>A collaborative approach to image generation (The latest research from Google)</title><link>https://research.google/blog/a-collaborative-approach-to-image-generation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;How PASTA works&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To effectively train an AI agent to adapt to a user's individual preferences, a large, diverse set of interaction data is needed. However, gathering this data from real users is challenging due to several factors, including user privacy. To address this, we trained PASTA using a two-stage strategy that combines real human feedback with large-scale user simulation.&lt;/p&gt;&lt;p&gt;First, we collected a high-quality foundational dataset with over 7,000 raters' sequential interactions. These interactions included prompt expansions generated by a Gemini Flash large multimodal model and corresponding images generated by a Stable Diffusion XL (SDXL) T2I model. This initial seed of authentic preference data was then used to train a user simulator, designed to generate additional data that replicate real human choices and preferences.&lt;/p&gt;&lt;p&gt;At the heart of our method is a user model, comprising two key components: 1) a utility model that predicts the degree to which a user will like any set of images, and 2) a choice model that predicts which set of images they will select when presented with several sets. We constructed the user model using pre-trained CLIP encoders and added user-specific components. We trained the model using an expectation-maximization algorithm that allows us to simultaneously learn the specifics of user preferences while also discovering latent “user types,” that is, clusters of users with similar tastes (e.g., tendencies to prefer images with animals, scenic views, or abstract art).&lt;/p&gt;&lt;p&gt;The trained user simulator can provide feedback and express preferences on generated images, and make selections from sets of proposed images. This allows us to generate over 30,000 simulated interaction trajectories.. Our approach does more than just create more data; it gives us a controlled environment in which to explore a vast range of user behaviors so we can train the PASTA agent to effectively collaborate with users.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;How PASTA works&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To effectively train an AI agent to adapt to a user's individual preferences, a large, diverse set of interaction data is needed. However, gathering this data from real users is challenging due to several factors, including user privacy. To address this, we trained PASTA using a two-stage strategy that combines real human feedback with large-scale user simulation.&lt;/p&gt;&lt;p&gt;First, we collected a high-quality foundational dataset with over 7,000 raters' sequential interactions. These interactions included prompt expansions generated by a Gemini Flash large multimodal model and corresponding images generated by a Stable Diffusion XL (SDXL) T2I model. This initial seed of authentic preference data was then used to train a user simulator, designed to generate additional data that replicate real human choices and preferences.&lt;/p&gt;&lt;p&gt;At the heart of our method is a user model, comprising two key components: 1) a utility model that predicts the degree to which a user will like any set of images, and 2) a choice model that predicts which set of images they will select when presented with several sets. We constructed the user model using pre-trained CLIP encoders and added user-specific components. We trained the model using an expectation-maximization algorithm that allows us to simultaneously learn the specifics of user preferences while also discovering latent “user types,” that is, clusters of users with similar tastes (e.g., tendencies to prefer images with animals, scenic views, or abstract art).&lt;/p&gt;&lt;p&gt;The trained user simulator can provide feedback and express preferences on generated images, and make selections from sets of proposed images. This allows us to generate over 30,000 simulated interaction trajectories.. Our approach does more than just create more data; it gives us a controlled environment in which to explore a vast range of user behaviors so we can train the PASTA agent to effectively collaborate with users.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/a-collaborative-approach-to-image-generation/</guid><pubDate>Thu, 02 Oct 2025 17:04:05 +0000</pubDate></item><item><title>Meta won’t allow users to opt out of targeted ads based on AI chats (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/meta-wont-allow-users-to-opt-out-of-targeted-ads-based-on-ai-chats/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        US users stuck with AI ad targeting as EU users win more control over their feeds.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2237775389-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2237775389-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Facebook, Instagram, and WhatsApp users may want to be extra careful while using Meta AI, as Meta has announced that it will soon be using AI interactions to personalize content and ad recommendations without giving users a way to opt out.&lt;/p&gt;
&lt;p&gt;Meta plans to notify users on October 7 that their AI interactions will influence recommendations beginning on December 16. However, it may not be immediately obvious to all users that their AI interactions will be used in this way.&lt;/p&gt;
&lt;p&gt;The company's blog noted that the initial notification users will see only says, "Learn how Meta will use your info in new ways to personalize your experience." Users will have to click through to understand that the changes specifically apply to Meta AI, with a second screen explaining, "We'll start using your interactions with AIs to personalize your experience."&lt;/p&gt;
&lt;p&gt;Ars asked Meta why the initial notification doesn't directly mention AI, and Meta spokesperson Emil Vazquez said he "would disagree with the idea that we are obscuring this update in any way."&lt;/p&gt;
&lt;p&gt;"We're sending notifications and emails to people about this change," Vazquez said. "As soon as someone clicks on the notification, it's immediately apparent that this is an AI update."&lt;/p&gt;
&lt;p&gt;In its blog post, Meta noted that "more than 1 billion people use Meta AI every month," stating its goals are to improve the way Meta AI works in order to fuel better experiences on all Meta apps. Sensitive "conversations with Meta AI about topics such as their religious views, sexual orientation, political views, health, racial or ethnic origin, philosophical beliefs, or trade union membership "will not be used to target ads, Meta confirmed.&lt;/p&gt;
&lt;p&gt;"You're in control," Meta's blog said, reiterating that users can "choose" how they "interact with AIs," unlink accounts on different apps to limit AI tracking, or adjust ad and content settings at any time. But once the tracking starts on December 16, users will not have the option to opt out of targeted ads based on AI chats, Vazquez confirmed, emphasizing to Ars that "there isn't an opt out for this feature."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta likens recommendations based on AI chats to those based on liking a photo or following a page. But consider how much more Meta can glean from a user interacting with AI about their love of hiking than it can from a user liking a photo or following a hiking group page.&lt;/p&gt;
&lt;p&gt;Many reports document that people tend to overshare with AI, which many ChatGPT users regretted after their private chats temporarily started appearing in Google search results. Meta faced a similar controversy when users realized that the Meta AI app's Discover tab "was full of conversations with a chatbot that people didn't realize had been posted to a public feed," Business Insider reported, noting, "That was really bad! A huge privacy headache!" For that reason, Meta users who don't want to see targeted content and ads based on more revealing chats may want to alter their habits.&lt;/p&gt;
&lt;p&gt;Most Meta users globally will be impacted by the update, which also applies to Meta wearables, like its "expanding line of smart glasses," which offer Meta AI a rich data source of voice recordings, images, and videos, MediaPost reported. Only regions with strict data laws—like the European Union, the United Kingdom, and South Korea—will be spared.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta insists AI is the future of Facebook, but not in EU&lt;/h2&gt;
&lt;p&gt;Notably, last year, Meta faced backlash in the EU, where it was accused of using "dark patterns" to discourage AI opt-outs. At that time, head of Facebook Tom Alison described "the future of Facebook" as being all about developing "the world’s best recommendation technology" and "building one of the world’s best collections of open models, tools, and resources for generative AI." More recently, Mark Zuckerberg suggested that social media users would likely find AI content more engaging than their friends, then released a "Vibes" feed on the Meta AI app that critics slammed as a flood of "AI slop."&lt;/p&gt;
&lt;p&gt;With Meta's announcement this week, it seems like the company is moving ahead with its AI mission in every market that allows it. At the same time, the EU's Digital Service Act (DSA) has won EU users even more freedom to control their feeds on Meta apps.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Thursday, Bits of Freedom—a Netherlands-based advocacy group specially focused on privacy and freedom of communication—announced that a judge ruled Meta must respect users' choice to avoid invasive personalized feeds. Within two weeks, Meta must update its apps to allow EU users the choice of sticking with a chronological feed that is not based on profiling.&lt;/p&gt;
&lt;p&gt;Bits of Freedom sued Meta under the DSA, reminding the court that "one of the core elements of the DSA is that users must have greater influence over the information they see."&lt;/p&gt;
&lt;p&gt;Ultimately, the judge agreed, ruling that Meta—which Bits of Freedom said used "subtle design tricks" to steer users to feeds "where it can show as many interest and behavior based ads as possible"—must promptly make changes to comply with the DSA.&lt;/p&gt;
&lt;p&gt;Meta declined to comment on the ruling, while Bits of Freedom warned that areas with weak privacy laws could be facing threats to democracy as tech companies strive for greater control over what content shows up in social media feeds.&lt;/p&gt;
&lt;p&gt;"For many people, and especially for young people, social media platforms are a major source of news and information," Bits of Freedom said. "Therefore, it is crucial that users themselves can decide which content appears on their feed. Without that freedom of choice, participation in the public debate is seriously hampered."&lt;/p&gt;
&lt;p&gt;Maartje Knaap, a spokesperson for Bits of Freedom, said it's "regrettable that we need to go to court to ensure Meta complies with the law," noting that users especially need to control their feeds ahead of elections.&lt;/p&gt;
&lt;p&gt;"It is absolutely unacceptable that a handful of American tech billionaires determine how we see the world," Knaap said. "That concentration of power poses a risk to our democracy."&lt;/p&gt;
&lt;p&gt;In the US, where data privacy laws are less strict, advocates are similarly concerned about social media feeds coming under the control of a handful of billionaires—particularly after Donald Trump said he wants TikTok to be tweaked to be "100 percent MAGA" under US ownership. Last year, Meta came under fire for boosting AI posts that researchers linked to misinformation, NPR reported. And a future where AI distorts feeds and helps misinformation spread faster remains a concern, especially after Trump used his own social media platform, Truth Social, to post "a 35-second AI-generated video&amp;nbsp;filled with crude insults, racial overtones, and bizarre conspiracy theories," Ars&amp;nbsp;noted earlier this week.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        US users stuck with AI ad targeting as EU users win more control over their feeds.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2237775389-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2237775389-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Facebook, Instagram, and WhatsApp users may want to be extra careful while using Meta AI, as Meta has announced that it will soon be using AI interactions to personalize content and ad recommendations without giving users a way to opt out.&lt;/p&gt;
&lt;p&gt;Meta plans to notify users on October 7 that their AI interactions will influence recommendations beginning on December 16. However, it may not be immediately obvious to all users that their AI interactions will be used in this way.&lt;/p&gt;
&lt;p&gt;The company's blog noted that the initial notification users will see only says, "Learn how Meta will use your info in new ways to personalize your experience." Users will have to click through to understand that the changes specifically apply to Meta AI, with a second screen explaining, "We'll start using your interactions with AIs to personalize your experience."&lt;/p&gt;
&lt;p&gt;Ars asked Meta why the initial notification doesn't directly mention AI, and Meta spokesperson Emil Vazquez said he "would disagree with the idea that we are obscuring this update in any way."&lt;/p&gt;
&lt;p&gt;"We're sending notifications and emails to people about this change," Vazquez said. "As soon as someone clicks on the notification, it's immediately apparent that this is an AI update."&lt;/p&gt;
&lt;p&gt;In its blog post, Meta noted that "more than 1 billion people use Meta AI every month," stating its goals are to improve the way Meta AI works in order to fuel better experiences on all Meta apps. Sensitive "conversations with Meta AI about topics such as their religious views, sexual orientation, political views, health, racial or ethnic origin, philosophical beliefs, or trade union membership "will not be used to target ads, Meta confirmed.&lt;/p&gt;
&lt;p&gt;"You're in control," Meta's blog said, reiterating that users can "choose" how they "interact with AIs," unlink accounts on different apps to limit AI tracking, or adjust ad and content settings at any time. But once the tracking starts on December 16, users will not have the option to opt out of targeted ads based on AI chats, Vazquez confirmed, emphasizing to Ars that "there isn't an opt out for this feature."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta likens recommendations based on AI chats to those based on liking a photo or following a page. But consider how much more Meta can glean from a user interacting with AI about their love of hiking than it can from a user liking a photo or following a hiking group page.&lt;/p&gt;
&lt;p&gt;Many reports document that people tend to overshare with AI, which many ChatGPT users regretted after their private chats temporarily started appearing in Google search results. Meta faced a similar controversy when users realized that the Meta AI app's Discover tab "was full of conversations with a chatbot that people didn't realize had been posted to a public feed," Business Insider reported, noting, "That was really bad! A huge privacy headache!" For that reason, Meta users who don't want to see targeted content and ads based on more revealing chats may want to alter their habits.&lt;/p&gt;
&lt;p&gt;Most Meta users globally will be impacted by the update, which also applies to Meta wearables, like its "expanding line of smart glasses," which offer Meta AI a rich data source of voice recordings, images, and videos, MediaPost reported. Only regions with strict data laws—like the European Union, the United Kingdom, and South Korea—will be spared.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta insists AI is the future of Facebook, but not in EU&lt;/h2&gt;
&lt;p&gt;Notably, last year, Meta faced backlash in the EU, where it was accused of using "dark patterns" to discourage AI opt-outs. At that time, head of Facebook Tom Alison described "the future of Facebook" as being all about developing "the world’s best recommendation technology" and "building one of the world’s best collections of open models, tools, and resources for generative AI." More recently, Mark Zuckerberg suggested that social media users would likely find AI content more engaging than their friends, then released a "Vibes" feed on the Meta AI app that critics slammed as a flood of "AI slop."&lt;/p&gt;
&lt;p&gt;With Meta's announcement this week, it seems like the company is moving ahead with its AI mission in every market that allows it. At the same time, the EU's Digital Service Act (DSA) has won EU users even more freedom to control their feeds on Meta apps.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Thursday, Bits of Freedom—a Netherlands-based advocacy group specially focused on privacy and freedom of communication—announced that a judge ruled Meta must respect users' choice to avoid invasive personalized feeds. Within two weeks, Meta must update its apps to allow EU users the choice of sticking with a chronological feed that is not based on profiling.&lt;/p&gt;
&lt;p&gt;Bits of Freedom sued Meta under the DSA, reminding the court that "one of the core elements of the DSA is that users must have greater influence over the information they see."&lt;/p&gt;
&lt;p&gt;Ultimately, the judge agreed, ruling that Meta—which Bits of Freedom said used "subtle design tricks" to steer users to feeds "where it can show as many interest and behavior based ads as possible"—must promptly make changes to comply with the DSA.&lt;/p&gt;
&lt;p&gt;Meta declined to comment on the ruling, while Bits of Freedom warned that areas with weak privacy laws could be facing threats to democracy as tech companies strive for greater control over what content shows up in social media feeds.&lt;/p&gt;
&lt;p&gt;"For many people, and especially for young people, social media platforms are a major source of news and information," Bits of Freedom said. "Therefore, it is crucial that users themselves can decide which content appears on their feed. Without that freedom of choice, participation in the public debate is seriously hampered."&lt;/p&gt;
&lt;p&gt;Maartje Knaap, a spokesperson for Bits of Freedom, said it's "regrettable that we need to go to court to ensure Meta complies with the law," noting that users especially need to control their feeds ahead of elections.&lt;/p&gt;
&lt;p&gt;"It is absolutely unacceptable that a handful of American tech billionaires determine how we see the world," Knaap said. "That concentration of power poses a risk to our democracy."&lt;/p&gt;
&lt;p&gt;In the US, where data privacy laws are less strict, advocates are similarly concerned about social media feeds coming under the control of a handful of billionaires—particularly after Donald Trump said he wants TikTok to be tweaked to be "100 percent MAGA" under US ownership. Last year, Meta came under fire for boosting AI posts that researchers linked to misinformation, NPR reported. And a future where AI distorts feeds and helps misinformation spread faster remains a concern, especially after Trump used his own social media platform, Truth Social, to post "a 35-second AI-generated video&amp;nbsp;filled with crude insults, racial overtones, and bizarre conspiracy theories," Ars&amp;nbsp;noted earlier this week.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/meta-wont-allow-users-to-opt-out-of-targeted-ads-based-on-ai-chats/</guid><pubDate>Thu, 02 Oct 2025 17:16:38 +0000</pubDate></item><item><title>Microsoft says AI can create “zero day” threats in biology (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/02/1124767/microsoft-says-ai-can-create-zero-day-threats-in-biology/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ai-dna-hack.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A team at Microsoft says it used artificial intelligence to discover a "zero day" vulnerability in the biosecurity systems used to prevent the misuse of DNA.&lt;/p&gt;  &lt;p&gt;These screening systems are designed to stop people from purchasing genetic sequences that could be used to create deadly toxins or pathogens. But now researchers led by Microsoft’s chief scientist, Eric Horvitz, says they have figured out how to bypass the protections in a way previously unknown to defenders.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The team described its work today in the journal &lt;em&gt;Science&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;Horvitz and his team focused on generative AI algorithms that propose new protein shapes. These types of programs are already fueling the hunt for new drugs at well-funded startups like Generate Biomedicines and Isomorphic Labs, a spinout of Google.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The problem is that such systems are potentially “dual use.” They can use their training sets to generate both beneficial molecules and harmful ones.&lt;/p&gt;  &lt;p&gt;Microsoft says it began a “red-teaming” test of AI’s dual-use potential in 2023 in order to determine whether “adversarial AI protein design” could help bioterrorists manufacture harmful proteins.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The safeguard that Microsoft attacked is what’s known as biosecurity screening software. To manufacture a protein, researchers typically need to order a corresponding DNA sequence from a commercial vendor, which they can then install in a cell. Those vendors use screening software to compare incoming orders with known toxins or pathogens. A close match will set off an alert.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;To design its attack, Microsoft used several generative protein models (including its own, called EvoDiff) to redesign toxins—changing their structure in a way that let them slip past screening software but was predicted to keep their deadly function intact.&lt;/p&gt;  &lt;p&gt;The researchers say the exercise was entirely digital and they never produced any toxic proteins. That was to avoid any perception that the company was developing bioweapons.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Before publishing the results, Microsoft says, it alerted the US government and software makers, who’ve already patched their systems, although some AI-designed molecules can still escape detection.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“The patch is incomplete, and the state of the art is changing. But this isn’t a one-and-done thing. It’s the start of even more testing,” says Adam Clore, director of technology R&amp;amp;D at Integrated DNA Technologies, a large manufacturer of DNA, who is a coauthor on the Microsoft report. “We’re in something of an arms race.”&lt;/p&gt;  &lt;p&gt;To make sure nobody misuses the research, the researchers say, they’re not disclosing some of their code and didn’t reveal what toxic proteins they asked the AI to redesign. However, some dangerous proteins are well known, like ricin—a poison found in castor beans—and the infectious prions that are the cause of mad-cow disease.&lt;/p&gt;  &lt;p&gt;“This finding, combined with rapid advances in AI-enabled biological modeling, demonstrates the clear and urgent need for enhanced nucleic acid synthesis screening procedures coupled with a reliable enforcement and verification mechanism,” says Dean Ball, a fellow at the Foundation for American Innovation, a think tank in San Francisco.&lt;/p&gt;  &lt;p&gt;Ball notes that the US government already considers screening of DNA orders a key line of security. Last May, in an executive order on biological research safety, President Trump called for an overall revamp of that system, although so far the White House hasn’t released new recommendations.&lt;/p&gt; 

 &lt;p&gt;Others doubt that commercial DNA synthesis is the best point of defense against bad actors. Michael Cohen, an AI-safety researcher at the University of California, Berkeley, believes there will always be ways to disguise sequences and that Microsoft could have made its test harder.&lt;/p&gt;  &lt;p&gt;“The challenge appears weak, and their patched tools fail a lot,” says Cohen. “There seems to be an unwillingness to admit that sometime soon, we’re going to have to retreat from this supposed choke point, so we should start looking around for ground that we can actually hold.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Cohen says biosecurity should probably be built into the AI systems themselves—either directly or via controls over what information they give.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Clore says monitoring gene synthesis is still a practical approach to detecting biothreats, since the manufacture of DNA in the US is dominated by a few companies that work closely with the government. By contrast, the technology used to build and train AI models is more widespread. “You can’t put that genie back in the bottle,” says Clore. “If you have the resources to try to trick us into making a DNA sequence, you can probably train a large language model.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ai-dna-hack.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A team at Microsoft says it used artificial intelligence to discover a "zero day" vulnerability in the biosecurity systems used to prevent the misuse of DNA.&lt;/p&gt;  &lt;p&gt;These screening systems are designed to stop people from purchasing genetic sequences that could be used to create deadly toxins or pathogens. But now researchers led by Microsoft’s chief scientist, Eric Horvitz, says they have figured out how to bypass the protections in a way previously unknown to defenders.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The team described its work today in the journal &lt;em&gt;Science&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;Horvitz and his team focused on generative AI algorithms that propose new protein shapes. These types of programs are already fueling the hunt for new drugs at well-funded startups like Generate Biomedicines and Isomorphic Labs, a spinout of Google.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The problem is that such systems are potentially “dual use.” They can use their training sets to generate both beneficial molecules and harmful ones.&lt;/p&gt;  &lt;p&gt;Microsoft says it began a “red-teaming” test of AI’s dual-use potential in 2023 in order to determine whether “adversarial AI protein design” could help bioterrorists manufacture harmful proteins.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The safeguard that Microsoft attacked is what’s known as biosecurity screening software. To manufacture a protein, researchers typically need to order a corresponding DNA sequence from a commercial vendor, which they can then install in a cell. Those vendors use screening software to compare incoming orders with known toxins or pathogens. A close match will set off an alert.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;To design its attack, Microsoft used several generative protein models (including its own, called EvoDiff) to redesign toxins—changing their structure in a way that let them slip past screening software but was predicted to keep their deadly function intact.&lt;/p&gt;  &lt;p&gt;The researchers say the exercise was entirely digital and they never produced any toxic proteins. That was to avoid any perception that the company was developing bioweapons.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Before publishing the results, Microsoft says, it alerted the US government and software makers, who’ve already patched their systems, although some AI-designed molecules can still escape detection.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“The patch is incomplete, and the state of the art is changing. But this isn’t a one-and-done thing. It’s the start of even more testing,” says Adam Clore, director of technology R&amp;amp;D at Integrated DNA Technologies, a large manufacturer of DNA, who is a coauthor on the Microsoft report. “We’re in something of an arms race.”&lt;/p&gt;  &lt;p&gt;To make sure nobody misuses the research, the researchers say, they’re not disclosing some of their code and didn’t reveal what toxic proteins they asked the AI to redesign. However, some dangerous proteins are well known, like ricin—a poison found in castor beans—and the infectious prions that are the cause of mad-cow disease.&lt;/p&gt;  &lt;p&gt;“This finding, combined with rapid advances in AI-enabled biological modeling, demonstrates the clear and urgent need for enhanced nucleic acid synthesis screening procedures coupled with a reliable enforcement and verification mechanism,” says Dean Ball, a fellow at the Foundation for American Innovation, a think tank in San Francisco.&lt;/p&gt;  &lt;p&gt;Ball notes that the US government already considers screening of DNA orders a key line of security. Last May, in an executive order on biological research safety, President Trump called for an overall revamp of that system, although so far the White House hasn’t released new recommendations.&lt;/p&gt; 

 &lt;p&gt;Others doubt that commercial DNA synthesis is the best point of defense against bad actors. Michael Cohen, an AI-safety researcher at the University of California, Berkeley, believes there will always be ways to disguise sequences and that Microsoft could have made its test harder.&lt;/p&gt;  &lt;p&gt;“The challenge appears weak, and their patched tools fail a lot,” says Cohen. “There seems to be an unwillingness to admit that sometime soon, we’re going to have to retreat from this supposed choke point, so we should start looking around for ground that we can actually hold.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Cohen says biosecurity should probably be built into the AI systems themselves—either directly or via controls over what information they give.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Clore says monitoring gene synthesis is still a practical approach to detecting biothreats, since the manufacture of DNA in the US is dominated by a few companies that work closely with the government. By contrast, the technology used to build and train AI models is more widespread. “You can’t put that genie back in the bottle,” says Clore. “If you have the resources to try to trick us into making a DNA sequence, you can probably train a large language model.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/02/1124767/microsoft-says-ai-can-create-zero-day-threats-in-biology/</guid><pubDate>Thu, 02 Oct 2025 18:00:00 +0000</pubDate></item><item><title>Google’s Jules enters developers’ toolchains as AI coding agent competition heats up (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/googles-jules-enters-developers-toolchains-as-ai-coding-agent-competition-heats-up/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is bringing its AI coding agent Jules deeper into developer workflows with a new command-line interface and public API, allowing it to plug into terminals, CI/CD systems, and tools like Slack — as competition intensifies among tech companies to own the future of software development and make coding more of an AI-assisted task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until now, Jules — Google’s asynchronous coding agent — was only accessible via its website and GitHub. On Thursday, the company introduced Jules Tools, a command-line interface that brings Jules directly into the developer’s terminal. The CLI lets developers interact with the agent using commands, streamlining workflows by eliminating the need to switch between the web interface and GitHub. It allows them to stay within their environment while delegating coding tasks and validating results.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to reduce context switching for developers as much as possible,” said Kathy Korevec, director of product at Google Labs, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google already offers Gemini CLI, an AI-based command-line tool that works across developer environments like terminals and CI/CD pipelines. Both Gemini CLI and Jules use Google’s Gemini 2.5 Pro AI model under the hood. However, Korevec told TechCrunch that Jules Tools is designed for “very scoped tasks,” while Gemini CLI requires users to be “a lot more iterative” and to “collaborate a lot more with the tool.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3053581" height="918" src="https://techcrunch.com/wp-content/uploads/2025/10/google-jules-tools.jpg" width="1582" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Google’s Jules Tools&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s senior developer advocate Denise Kwan also elaborated in a Medium post on how Jules differs from Gemini CLI. Jules is less interactive by design, she noted, and executes tasks independently once the user approves its plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the CLI, Google has made Jules’ API public, which it had previously used for internal development. The purpose of this is also to help developers use Jules more often as they can extend the tool into their existing workflows where they have “a lot of muscle memory and familiarity,” Korevec said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers can also use the API to integrate Jules with their integrated development environment (IDE), a software application that helps make coding easier by providing a list of tools, such as VS Code. However, Korevec told TechCrunch that her team is keen to build specific plug-ins for IDEs to further expand Jules’ presence.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The latest updates come just after Google introduced “memory” for Jules to keep a record of interactions with users and their preferences, nudges, and corrections. For the last few weeks, the tool has also added a list of other features, including a stacked layout for the diff viewer, image upload, and the ability to read and respond to comments on pull requests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, another area Google is exploring with Jules is reducing its reliance on GitHub. Currently, the agent codes within a GitHub repository — requiring developers to either connect it to an existing repo or provide a blank one to work in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Users want Jules to integrate with other code hosting providers,” said Korevec. “We are looking into how we can enable that with other version control systems. We are also looking into enabling it for people who don’t want a version control system, or they don’t care where their code is hosted.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Oversight of AI tools remains a challenge, especially when they are used in professional settings. Jules, however, is designed to notify the user if it gets stuck on a particular task, prompting them to step in and assist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If something happens where it runs into an issue, or it runs into a situation where it can’t unstick itself, it will pause and ask me a question,” Korevec said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, oversight becomes more difficult when users interact with Jules on mobile, as native notifications are not yet supported. Korevec noted that many users are already accessing Jules through its mobile web interface, and said Google is working to improve the mobile experience — particularly by exploring ways to offer native notifications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Jules has primarily been used by software engineers and other professionals — unlike many vibe coding platforms that position themselves as go-to tools for non-coders. Still, some users are experimenting with Jules as a complement to more casual or creative coding environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see a lot of people take that project that they have hit the limit in whatever vibe coding tool they’re using, and then bring that to Jules for further extending it,” Korevec told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in public preview in May, Jules exited beta in August and is now available under structured pricing tiers. A free plan offers up to 15 individual daily tasks and three concurrent tasks. Higher limits are available through the Google AI Pro and Ultra plans, priced at $19.99 and $124.99 per month, offering approximately 5x and 20x the limits, respectively.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is bringing its AI coding agent Jules deeper into developer workflows with a new command-line interface and public API, allowing it to plug into terminals, CI/CD systems, and tools like Slack — as competition intensifies among tech companies to own the future of software development and make coding more of an AI-assisted task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until now, Jules — Google’s asynchronous coding agent — was only accessible via its website and GitHub. On Thursday, the company introduced Jules Tools, a command-line interface that brings Jules directly into the developer’s terminal. The CLI lets developers interact with the agent using commands, streamlining workflows by eliminating the need to switch between the web interface and GitHub. It allows them to stay within their environment while delegating coding tasks and validating results.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to reduce context switching for developers as much as possible,” said Kathy Korevec, director of product at Google Labs, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google already offers Gemini CLI, an AI-based command-line tool that works across developer environments like terminals and CI/CD pipelines. Both Gemini CLI and Jules use Google’s Gemini 2.5 Pro AI model under the hood. However, Korevec told TechCrunch that Jules Tools is designed for “very scoped tasks,” while Gemini CLI requires users to be “a lot more iterative” and to “collaborate a lot more with the tool.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3053581" height="918" src="https://techcrunch.com/wp-content/uploads/2025/10/google-jules-tools.jpg" width="1582" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Google’s Jules Tools&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s senior developer advocate Denise Kwan also elaborated in a Medium post on how Jules differs from Gemini CLI. Jules is less interactive by design, she noted, and executes tasks independently once the user approves its plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the CLI, Google has made Jules’ API public, which it had previously used for internal development. The purpose of this is also to help developers use Jules more often as they can extend the tool into their existing workflows where they have “a lot of muscle memory and familiarity,” Korevec said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers can also use the API to integrate Jules with their integrated development environment (IDE), a software application that helps make coding easier by providing a list of tools, such as VS Code. However, Korevec told TechCrunch that her team is keen to build specific plug-ins for IDEs to further expand Jules’ presence.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The latest updates come just after Google introduced “memory” for Jules to keep a record of interactions with users and their preferences, nudges, and corrections. For the last few weeks, the tool has also added a list of other features, including a stacked layout for the diff viewer, image upload, and the ability to read and respond to comments on pull requests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, another area Google is exploring with Jules is reducing its reliance on GitHub. Currently, the agent codes within a GitHub repository — requiring developers to either connect it to an existing repo or provide a blank one to work in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Users want Jules to integrate with other code hosting providers,” said Korevec. “We are looking into how we can enable that with other version control systems. We are also looking into enabling it for people who don’t want a version control system, or they don’t care where their code is hosted.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Oversight of AI tools remains a challenge, especially when they are used in professional settings. Jules, however, is designed to notify the user if it gets stuck on a particular task, prompting them to step in and assist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If something happens where it runs into an issue, or it runs into a situation where it can’t unstick itself, it will pause and ask me a question,” Korevec said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, oversight becomes more difficult when users interact with Jules on mobile, as native notifications are not yet supported. Korevec noted that many users are already accessing Jules through its mobile web interface, and said Google is working to improve the mobile experience — particularly by exploring ways to offer native notifications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Jules has primarily been used by software engineers and other professionals — unlike many vibe coding platforms that position themselves as go-to tools for non-coders. Still, some users are experimenting with Jules as a complement to more casual or creative coding environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see a lot of people take that project that they have hit the limit in whatever vibe coding tool they’re using, and then bring that to Jules for further extending it,” Korevec told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in public preview in May, Jules exited beta in August and is now available under structured pricing tiers. A free plan offers up to 15 individual daily tasks and three concurrent tasks. Higher limits are available through the Google AI Pro and Ultra plans, priced at $19.99 and $124.99 per month, offering approximately 5x and 20x the limits, respectively.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/googles-jules-enters-developers-toolchains-as-ai-coding-agent-competition-heats-up/</guid><pubDate>Thu, 02 Oct 2025 18:00:00 +0000</pubDate></item><item><title>OpenAI’s Sora soars to No. 3 on the US App Store (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/openais-sora-soars-to-no-3-on-the-u-s-app-store/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages2238161095.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s Sora app for AI videos is a viral hit, despite being invite-only for now and limited to users in the U.S. and Canada at launch. On its first day, Sora saw 56,000 downloads, and is now ranked as the No. 3 Top Overall app on the U.S. App Store, according to new data from app intelligence provider Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm estimates Sora’s iOS app pulled in a total of 164,000 installs during its first two days, September 30th and October 1st.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The day-one figure puts Sora’s debut ahead of the performance of other major AI app launches, including Anthropic’s Claude and Microsoft’s Copilot, and puts it on par with xAI’s Grok launch. Meanwhile, OpenAI’s ChatGPT and Google’s Gemini iOS apps had somewhat stronger launches, with each reaching at least 80,000 downloads on day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Sora is still invite-only, this may not be the fairest comparison, we’ll admit. It’s possible the new video app could have attracted even &lt;em&gt;more&lt;/em&gt; installs if it were open to all users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite this restriction, it’s a fairly strong showing for the new release, indicating demand for AI video tools in consumers’ hands in more of a social networking-like experience. (This is much to the chagrin of some at OpenAI, who want the company to focus on solving harder problems that benefit humanity. But who’s to say that humanity isn’t benefiting from deepfakes of OpenAI CEO Sam Altman asking, “Are my piggies enjoying their slop?”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To compare Sora’s early success to other AI apps, Appfigures had to run an analysis that only looked at the other AI apps’ U.S. and Canadian downloads. That’s because the different AI apps on the market have pursued different launch strategies. For instance, ChatGPT initially launched on iOS and limited itself to U.S. users at the time, while Grok limited its iOS-only release to the U.S., Australia, and India. Anthropic, meanwhile, didn’t indicate there were geographic restrictions when it first brought its Claude app to iOS last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For more of an apples-to-apples comparison, Appfigures crunched the numbers to focus only on each app’s U.S. downloads, plus those in Canada, if the app had been available there at launch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It found that ChatGPT and Gemini had larger launches than Sora, with 81,000 and 80,000 day-one iOS downloads, respectively. Sora tied with Grok for day-one installs, at 56,000. And it easily beat out the launches from AI apps Claude and Copilot. The former pulled in 21,000 day-one downloads, while the latter only saw 7,000.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora also hit the U.S. App Store’s top charts, becoming the No. 3 overall top app by day two. For comparison, ChatGPT reached No. 1 on its second day, while Grok was No. 4, Gemini was No. 6, Copilot was No. 19, and Claude was No. 78. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages2238161095.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s Sora app for AI videos is a viral hit, despite being invite-only for now and limited to users in the U.S. and Canada at launch. On its first day, Sora saw 56,000 downloads, and is now ranked as the No. 3 Top Overall app on the U.S. App Store, according to new data from app intelligence provider Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm estimates Sora’s iOS app pulled in a total of 164,000 installs during its first two days, September 30th and October 1st.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The day-one figure puts Sora’s debut ahead of the performance of other major AI app launches, including Anthropic’s Claude and Microsoft’s Copilot, and puts it on par with xAI’s Grok launch. Meanwhile, OpenAI’s ChatGPT and Google’s Gemini iOS apps had somewhat stronger launches, with each reaching at least 80,000 downloads on day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Sora is still invite-only, this may not be the fairest comparison, we’ll admit. It’s possible the new video app could have attracted even &lt;em&gt;more&lt;/em&gt; installs if it were open to all users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite this restriction, it’s a fairly strong showing for the new release, indicating demand for AI video tools in consumers’ hands in more of a social networking-like experience. (This is much to the chagrin of some at OpenAI, who want the company to focus on solving harder problems that benefit humanity. But who’s to say that humanity isn’t benefiting from deepfakes of OpenAI CEO Sam Altman asking, “Are my piggies enjoying their slop?”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To compare Sora’s early success to other AI apps, Appfigures had to run an analysis that only looked at the other AI apps’ U.S. and Canadian downloads. That’s because the different AI apps on the market have pursued different launch strategies. For instance, ChatGPT initially launched on iOS and limited itself to U.S. users at the time, while Grok limited its iOS-only release to the U.S., Australia, and India. Anthropic, meanwhile, didn’t indicate there were geographic restrictions when it first brought its Claude app to iOS last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For more of an apples-to-apples comparison, Appfigures crunched the numbers to focus only on each app’s U.S. downloads, plus those in Canada, if the app had been available there at launch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It found that ChatGPT and Gemini had larger launches than Sora, with 81,000 and 80,000 day-one iOS downloads, respectively. Sora tied with Grok for day-one installs, at 56,000. And it easily beat out the launches from AI apps Claude and Copilot. The former pulled in 21,000 day-one downloads, while the latter only saw 7,000.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora also hit the U.S. App Store’s top charts, becoming the No. 3 overall top app by day two. For comparison, ChatGPT reached No. 1 on its second day, while Grok was No. 4, Gemini was No. 6, Copilot was No. 19, and Claude was No. 78. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/openais-sora-soars-to-no-3-on-the-u-s-app-store/</guid><pubDate>Thu, 02 Oct 2025 18:24:54 +0000</pubDate></item><item><title>[NEW] Anthropic hires new CTO with focus on AI infrastructure (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/02/anthropic-hires-new-cto-with-focus-on-ai-infrastructure/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has a new chief technical officer, former Stripe CTO Rahul Patil. Patil started at the company earlier this week, taking over from co-founder Sam McCandlish, who will move to a new role as chief architect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the change, Anthropic is updating the structure of its core technical group, bringing the company’s product-engineering team into closer contact with the infrastructure and inference teams. As CTO, Patil will oversee compute, infrastructure, inference, and a variety of other engineering tasks. In the chief architect role, McCandlish will work on pre-training and large-scale model training, extending much of his previous work. Both Patil and McCandlish will report to Anthropic president Daniela Amodei.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new leadership structure comes as Anthropic faces intense infrastructure competition from AI labs at OpenAI and Meta, which have invested billions into computing infrastructure. Mark Zuckerberg has said that Meta plans to spend $600 billion on U.S. infrastructure through the end of 2028, and OpenAI has contracted a similar amount through its work with Oracle and the Stargate project. The scale of Anthropic’s own infrastructure spending is less clear, but there will be immense pressure to optimize the growing infrastructure for both speed and power consumption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, the popularity of Anthropic’s Claude products has already put the company’s infrastructure under significant strain. In July, the company introduced new rate limits to Claude Code, with an eye toward power users who had been running the app “continuously in the background, 24/7.” Under the new rules, users are limited to between 240 and 480 hours of Sonnet usage each week, and between 24 and 40 hours of Opus 4 usage, depending on infrastructure strain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 20 years in different engineering roles, Patil brings significant infrastructure experience to Anthropic. He previously spent five years in technical roles at Stripe and served as a senior VP for cloud infrastructure at Oracle. He has also held engineering roles at Amazon and Microsoft.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Amodei emphasized Patil’s experience building stable infrastructure for enterprises. “Rahul brings a proven track record in building and scaling the kind of dependable infrastructure that businesses need,” the statement reads. “I couldn’t be more excited about what this means for strengthening Claude’s position as the leading intelligence platform for enterprises.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a paired statement, Patil applauded Anthropic’s research and commitment to AI safety. “I’m thrilled to join Anthropic at this pivotal moment in AI development,” Patil said, adding that his work at the company “feels like the most important work I could be doing right now — I personally can’t think of a greater calling and responsibility.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has a new chief technical officer, former Stripe CTO Rahul Patil. Patil started at the company earlier this week, taking over from co-founder Sam McCandlish, who will move to a new role as chief architect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the change, Anthropic is updating the structure of its core technical group, bringing the company’s product-engineering team into closer contact with the infrastructure and inference teams. As CTO, Patil will oversee compute, infrastructure, inference, and a variety of other engineering tasks. In the chief architect role, McCandlish will work on pre-training and large-scale model training, extending much of his previous work. Both Patil and McCandlish will report to Anthropic president Daniela Amodei.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new leadership structure comes as Anthropic faces intense infrastructure competition from AI labs at OpenAI and Meta, which have invested billions into computing infrastructure. Mark Zuckerberg has said that Meta plans to spend $600 billion on U.S. infrastructure through the end of 2028, and OpenAI has contracted a similar amount through its work with Oracle and the Stargate project. The scale of Anthropic’s own infrastructure spending is less clear, but there will be immense pressure to optimize the growing infrastructure for both speed and power consumption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, the popularity of Anthropic’s Claude products has already put the company’s infrastructure under significant strain. In July, the company introduced new rate limits to Claude Code, with an eye toward power users who had been running the app “continuously in the background, 24/7.” Under the new rules, users are limited to between 240 and 480 hours of Sonnet usage each week, and between 24 and 40 hours of Opus 4 usage, depending on infrastructure strain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With more than 20 years in different engineering roles, Patil brings significant infrastructure experience to Anthropic. He previously spent five years in technical roles at Stripe and served as a senior VP for cloud infrastructure at Oracle. He has also held engineering roles at Amazon and Microsoft.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Amodei emphasized Patil’s experience building stable infrastructure for enterprises. “Rahul brings a proven track record in building and scaling the kind of dependable infrastructure that businesses need,” the statement reads. “I couldn’t be more excited about what this means for strengthening Claude’s position as the leading intelligence platform for enterprises.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a paired statement, Patil applauded Anthropic’s research and commitment to AI safety. “I’m thrilled to join Anthropic at this pivotal moment in AI development,” Patil said, adding that his work at the company “feels like the most important work I could be doing right now — I personally can’t think of a greater calling and responsibility.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/02/anthropic-hires-new-cto-with-focus-on-ai-infrastructure/</guid><pubDate>Thu, 02 Oct 2025 19:00:39 +0000</pubDate></item><item><title>[NEW] Lincoln Lab unveils the most powerful AI supercomputer at any US university (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/lincoln-lab-unveils-most-powerful-ai-supercomputer-at-any-us-university-1002</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-lincoln-lab-supercomputer.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The new TX-Generative AI Next (TX-GAIN) computing system at the&amp;nbsp;Lincoln Laboratory Supercomputing Center  (LLSC) is the most powerful AI supercomputer at any U.S. university. With its recent ranking from  TOP500, which biannually publishes a list of the top supercomputers in various categories, TX-GAIN joins the ranks of other powerful systems at the LLSC, all supporting research and development at Lincoln Laboratory and across the MIT campus.&amp;nbsp;&lt;/p&gt;&lt;p&gt;"TX-GAIN will enable our researchers to achieve scientific and engineering breakthroughs. The system will play a large role in supporting generative AI, physical simulation, and data analysis across all research areas," says Lincoln Laboratory Fellow&amp;nbsp;Jeremy Kepner, who heads the LLSC.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The LLSC is a key resource for accelerating innovation at Lincoln Laboratory. Thousands of researchers tap into the LLSC to analyze data, train models, and run simulations for federally funded research projects. The supercomputers have been used, for example,&amp;nbsp;to simulate billions of aircraft encounters to develop collision-avoidance systems for the Federal Aviation Administration, and to train models in the complex tasks of autonomous navigation for the Department of Defense. Over the years, LLSC capabilities have been essential to numerous&amp;nbsp;award-winning technologies, including those that have improved  airline safety,  prevented the spread of new diseases, and  aided in hurricane responses.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As its name suggests, TX-GAIN is especially equipped for developing and applying generative AI. Whereas traditional AI focuses on categorization tasks, like identifying whether a photo depicts a dog or cat, generative AI produces entirely new outputs. Kepner describes it as a mathematical combination of interpolation (filling in the gaps between known data points) and extrapolation (extending data beyond known points). Today, generative AI is widely known for its use of large language models to create human-like responses to user prompts.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At Lincoln Laboratory, teams are applying generative AI to various domains beyond large language models. They are using the technology, for instance, to evaluate radar signatures, supplement weather data where coverage is missing, root out anomalies in network traffic, and explore chemical interactions to design new medicines and materials.&lt;/p&gt;&lt;p&gt;To enable such intense computations, TX-GAIN is powered by more than 600 NVIDIA graphics processing unit accelerators specially designed for AI operations, in addition to traditional high-performance computing hardware. With a peak performance of two AI exaflops (two quintillion floating-point operations per second), TX-GAIN is the top AI system at a university, and in the Northeast.&amp;nbsp;Since TX-GAIN came online this summer, researchers have taken notice.&amp;nbsp;&lt;/p&gt;&lt;p&gt;"TX-GAIN is allowing us to model not only significantly more protein interactions than ever before, but also much larger proteins with more atoms. This new computational capability is a game-changer for protein characterization efforts in biological defense," says Rafael Jaimes, a researcher in Lincoln Laboratory's&amp;nbsp;Counter–Weapons of Mass Destruction Systems Group.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The LLSC's focus on&amp;nbsp;interactive supercomputing makes it especially useful to researchers. For years, the LLSC has pioneered software that lets users access its powerful systems without needing to be experts in configuring algorithms for parallel processing.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;"The LLSC has always tried to make supercomputing feel like working on your laptop," Kepner says. "The amount of data and the sophistication of analysis methods needed to be competitive today are well beyond what can be done on a laptop. But with our user-friendly approach, people can run their model and get answers quickly from their workspace."&lt;/p&gt;&lt;p&gt;Beyond supporting programs solely at Lincoln Laboratory, TX-GAIN is enhancing research collaborations with MIT's campus. Such collaborations include the&amp;nbsp;Haystack Observatory,&amp;nbsp;Center for Quantum Engineering,&amp;nbsp;Beaver Works, and&amp;nbsp;Department of Air Force–MIT AI Accelerator. The latter initiative is rapidly prototyping, scaling, and applying AI technologies for the U.S. Air Force and Space Force,&amp;nbsp;optimizing flight scheduling for global operations as one fielded example.&lt;/p&gt;&lt;p&gt;The LLSC systems are housed in an energy-efficient data center and facility in Holyoke, Massachusetts. Research staff in the LLSC are also tackling the immense&amp;nbsp;energy needs of AI and leading research into various&amp;nbsp;power-reduction methods. One software tool they developed can reduce the energy of training an AI model by&amp;nbsp;as much as 80 percent.&lt;/p&gt;&lt;p&gt;"The LLSC provides the capabilities needed to do leading-edge research, while in a cost-effective and energy-efficient manner," Kepner says.&lt;/p&gt;&lt;p&gt;All of the supercomputers at the LLSC use the "TX" nomenclature in homage&amp;nbsp;to Lincoln Laboratory's Transistorized Experimental Computer Zero (TX-0) of 1956. TX-0 was one of the world's first transistor-based machines, and its 1958 successor,&amp;nbsp;TX-2, is storied for its role in pioneering human-computer interaction and AI. With TX-GAIN,&amp;nbsp;the LLSC continues this legacy.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-lincoln-lab-supercomputer.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The new TX-Generative AI Next (TX-GAIN) computing system at the&amp;nbsp;Lincoln Laboratory Supercomputing Center  (LLSC) is the most powerful AI supercomputer at any U.S. university. With its recent ranking from  TOP500, which biannually publishes a list of the top supercomputers in various categories, TX-GAIN joins the ranks of other powerful systems at the LLSC, all supporting research and development at Lincoln Laboratory and across the MIT campus.&amp;nbsp;&lt;/p&gt;&lt;p&gt;"TX-GAIN will enable our researchers to achieve scientific and engineering breakthroughs. The system will play a large role in supporting generative AI, physical simulation, and data analysis across all research areas," says Lincoln Laboratory Fellow&amp;nbsp;Jeremy Kepner, who heads the LLSC.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The LLSC is a key resource for accelerating innovation at Lincoln Laboratory. Thousands of researchers tap into the LLSC to analyze data, train models, and run simulations for federally funded research projects. The supercomputers have been used, for example,&amp;nbsp;to simulate billions of aircraft encounters to develop collision-avoidance systems for the Federal Aviation Administration, and to train models in the complex tasks of autonomous navigation for the Department of Defense. Over the years, LLSC capabilities have been essential to numerous&amp;nbsp;award-winning technologies, including those that have improved  airline safety,  prevented the spread of new diseases, and  aided in hurricane responses.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As its name suggests, TX-GAIN is especially equipped for developing and applying generative AI. Whereas traditional AI focuses on categorization tasks, like identifying whether a photo depicts a dog or cat, generative AI produces entirely new outputs. Kepner describes it as a mathematical combination of interpolation (filling in the gaps between known data points) and extrapolation (extending data beyond known points). Today, generative AI is widely known for its use of large language models to create human-like responses to user prompts.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At Lincoln Laboratory, teams are applying generative AI to various domains beyond large language models. They are using the technology, for instance, to evaluate radar signatures, supplement weather data where coverage is missing, root out anomalies in network traffic, and explore chemical interactions to design new medicines and materials.&lt;/p&gt;&lt;p&gt;To enable such intense computations, TX-GAIN is powered by more than 600 NVIDIA graphics processing unit accelerators specially designed for AI operations, in addition to traditional high-performance computing hardware. With a peak performance of two AI exaflops (two quintillion floating-point operations per second), TX-GAIN is the top AI system at a university, and in the Northeast.&amp;nbsp;Since TX-GAIN came online this summer, researchers have taken notice.&amp;nbsp;&lt;/p&gt;&lt;p&gt;"TX-GAIN is allowing us to model not only significantly more protein interactions than ever before, but also much larger proteins with more atoms. This new computational capability is a game-changer for protein characterization efforts in biological defense," says Rafael Jaimes, a researcher in Lincoln Laboratory's&amp;nbsp;Counter–Weapons of Mass Destruction Systems Group.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The LLSC's focus on&amp;nbsp;interactive supercomputing makes it especially useful to researchers. For years, the LLSC has pioneered software that lets users access its powerful systems without needing to be experts in configuring algorithms for parallel processing.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;"The LLSC has always tried to make supercomputing feel like working on your laptop," Kepner says. "The amount of data and the sophistication of analysis methods needed to be competitive today are well beyond what can be done on a laptop. But with our user-friendly approach, people can run their model and get answers quickly from their workspace."&lt;/p&gt;&lt;p&gt;Beyond supporting programs solely at Lincoln Laboratory, TX-GAIN is enhancing research collaborations with MIT's campus. Such collaborations include the&amp;nbsp;Haystack Observatory,&amp;nbsp;Center for Quantum Engineering,&amp;nbsp;Beaver Works, and&amp;nbsp;Department of Air Force–MIT AI Accelerator. The latter initiative is rapidly prototyping, scaling, and applying AI technologies for the U.S. Air Force and Space Force,&amp;nbsp;optimizing flight scheduling for global operations as one fielded example.&lt;/p&gt;&lt;p&gt;The LLSC systems are housed in an energy-efficient data center and facility in Holyoke, Massachusetts. Research staff in the LLSC are also tackling the immense&amp;nbsp;energy needs of AI and leading research into various&amp;nbsp;power-reduction methods. One software tool they developed can reduce the energy of training an AI model by&amp;nbsp;as much as 80 percent.&lt;/p&gt;&lt;p&gt;"The LLSC provides the capabilities needed to do leading-edge research, while in a cost-effective and energy-efficient manner," Kepner says.&lt;/p&gt;&lt;p&gt;All of the supercomputers at the LLSC use the "TX" nomenclature in homage&amp;nbsp;to Lincoln Laboratory's Transistorized Experimental Computer Zero (TX-0) of 1956. TX-0 was one of the world's first transistor-based machines, and its 1958 successor,&amp;nbsp;TX-2, is storied for its role in pioneering human-computer interaction and AI. With TX-GAIN,&amp;nbsp;the LLSC continues this legacy.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/lincoln-lab-unveils-most-powerful-ai-supercomputer-at-any-us-university-1002</guid><pubDate>Thu, 02 Oct 2025 19:30:00 +0000</pubDate></item><item><title>[NEW] Martin Trust Center for MIT Entrepreneurship welcomes Ana Bakshi as new executive director (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/martin-trust-center-mit-entrepreneurship-ana-bakshi-executive-director-1002</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-martintrust-bakshi.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The&amp;nbsp;Martin Trust Center for MIT Entrepreneurship announced that Ana Bakshi has been named its new executive director. Bakshi stepped into the role at the start of the fall semester and will collaborate closely with the managing director, Ethernet Inventors Professor of the Practice Bill Aulet, to elevate the center to higher levels.&lt;/p&gt;&lt;p&gt;“Ana is uniquely qualified for this role. She brings a deep and highly decorated background in entrepreneurship education at the highest levels, along with exceptional leadership and execution skills,” says Aulet. “Since I first met her 12 years ago, I have been extraordinarily impressed with her commitment to create the highest-quality centers and institutes for entrepreneurs, first at King’s College London and then at Oxford University. This ideal skill set is compounded by her experience in leading high-growth companies, most recently as the chief operation officer in an award-winning AI startup. I’m honored and thrilled to welcome her to MIT — her knowledge and energy will greatly elevate our community, and the field as a whole.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A rapidly changing environment creates imperative for raising the bar for entrepreneurship education&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The need to raise the bar for innovation-driven entrepreneurship education is both timely and urgent. The rate of change is getting faster and faster every day, especially with artificial intelligence, and is generating new problems that need to be solved, as well as exacerbating existing problems in climate, health care, manufacturing, future of work, education, and economic stratification, to name but a few. The world needs more entrepreneurs and better entrepreneurs.&lt;/p&gt;&lt;p&gt;Bakshi joins the Trust Center at an exciting time in its history. MIT is at the forefront of helping to develop people and systems that can turn challenges into opportunities using an entrepreneurial mindset, skill set, and way of operating.&amp;nbsp;Bakshi’s deep experience and success will be key to unlocking this opportunity. “I am truly honored to join the Trust Center at such a pivotal moment,” Bakshi says. “In an era defined by both extraordinary challenges and extraordinary possibilities, the future will be built by those bold enough to try, and MIT will be at the forefront of this.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Translating academic research into real-world impact&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Bakshi has a decade of experience building two world-class entrepreneurship centers from the ground up. She served as the founding director at King’s College and then at Oxford. In this role, she was responsible for all aspects of these centers, including fundraising.&lt;/p&gt;&lt;p&gt;While at Oxford, she authored a data-driven approach to determining efficacy of outcomes for their programs, as evidenced by a 61-page study, “Universities: Drivers of Prosperity and Economic Recovery.”&lt;/p&gt;&lt;p&gt;As the director of the Oxford Foundry (Oxford’s cross-university entrepreneurship center), Bakshi focused on investing in ambitious founders and talent. The center was backed by global entrepreneurial leaders such as the founders of LinkedIn and Twitter, with corporate partnerships including Santander and EY, and investment funds including Oxford Science Enterprises (OSE). As of 2021, the startups supported by the Foundry and King’s College have raised over $500 million and have created nearly 3,000 jobs, spanning diverse industries including health tech, climate tech, cybersecurity, fintech, and deep tech spinouts focusing on world-class science.&lt;/p&gt;&lt;p&gt;In addition, she built the highly successful and economically sustainable&amp;nbsp;Entrepreneurship School, Oxford’s first digital online learning platform.&lt;/p&gt;&lt;p&gt;Bakshi comes to MIT after having worked in the private sector as the chief operating officer (COO) in a rapidly growing artificial intelligence startup for almost two years,&amp;nbsp;Quench.ai, with offices in London and New York City. She was the first C-suite employee at Quench.ai, serving as COO and now senior advisor, helping companies unlock value from their knowledge through AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Right place, right time, right person moving at the speed of MIT AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since its inception, then turbocharged in the 1940s with the creation and operation of the&amp;nbsp;RadLab, and continuing to this day, entrepreneurship is at the core of MIT’s identity and mission.&amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;"MIT has been a leader in entrepreneurship for decades. It’s now the third leg of the school, alongside teaching and research,” says Mark Gorenberg ’76, chair of the MIT Corporation. “I’m excited to have such a transformative leader as Ana join the Trust Center team, and I look forward to the impact she will have on the students and the wider academic community at MIT as we enter an exciting new phase in company building, driven by the accelerated use of AI and emerging technologies."&lt;/p&gt;&lt;p&gt;“In a time where we are rethinking management education, entrepreneurship as an interdisciplinary field to create impact is even more important to our future. To have such an experienced and accomplished leader in academia and the startup world, especially in AI, reinforces our commitment to be a global leader in this field,” says Richard M. Locke, John C Head III Dean at the MIT Sloan School of Management.&lt;/p&gt;&lt;p&gt;“MIT is a unique hub of research, innovation, and entrepreneurship, and that special mix creates massive positive impact that ripples around the world,” says Frederic Kerrest, MIT Sloan MBA ’09, co-founder of Okta, and member of the MIT Corporation. “In a rapidly changing, AI-driven world, Ana has the skills and experience to further accelerate MIT’s global leadership in entrepreneurship education to ensure that our students launch and scale the next generation of groundbreaking, innovation-driven startups.”&lt;/p&gt;&lt;p&gt;Prior to her time at Oxford and King’s College, Bakshi served as an elected councilor representing 6,000-plus constituents, held roles in international nongovernmental organizations, and led product execution strategy at MAHI, an award-winning family-led craft sauce startup, available in thousands of major retailers across the U.K.&amp;nbsp;Bakshi sits on the&amp;nbsp;advisory council for conservation charity&amp;nbsp;Save the Elephants, leveraging AI-driven and scientific approaches to reduce human-wildlife conflict and protect elephant populations.&amp;nbsp;Her work and impact have been featured across &lt;em&gt;FT&lt;/em&gt;, &lt;em&gt;Forbes&lt;/em&gt;, BBC, &lt;em&gt;The Times&lt;/em&gt;, and &lt;em&gt;The Hill&lt;/em&gt;. Bakshi was twice honored as a Top 50 Woman in Tech (U.K.), most recently in 2025.&lt;/p&gt;&lt;p&gt;“As AI changes how we learn, how we build, and how we scale, my focus will be on helping MIT expand its support for phenomenal talent — students and faculty — with the skills, ecosystem, and backing to turn knowledge into impact,” Bakshi says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;35 years of impact to date&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Trust Center was founded in 1990 by the late Professor Edward Roberts and serves all MIT students across all schools and all disciplines.&amp;nbsp;It supports 60-plus courses and extensive extracurricular programming, including the delta v academic accelerator. Much of the work of the center is generated through the Disciplined Entrepreneurship methodology, which offers a proven approach to create new ventures. Over a thousand schools and other organizations across the world use Disciplined Entrepreneurship books and resources to teach entrepreneurship.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Now, with AI-powered tools like&amp;nbsp;Orbit and&amp;nbsp;JetPack, the Trust Center is changing the way that entrepreneurship is taught and practiced. Its mission is to produce the next generation of innovation-driven entrepreneurs while advancing the field more broadly to make it both rigorous and practical. This approach of leveraging proven evidence-based methodology, emerging technology, the ingenuity of MIT students, and responding to industry shifts is similar to how MIT&amp;nbsp;established the field of chemical engineering in the 1890s. The desired result in both cases was to create a comprehensive, integrated, scalable, rigorous, and practical curriculum to create a new workforce to address the nation’s and world’s greatest challenges.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-martintrust-bakshi.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The&amp;nbsp;Martin Trust Center for MIT Entrepreneurship announced that Ana Bakshi has been named its new executive director. Bakshi stepped into the role at the start of the fall semester and will collaborate closely with the managing director, Ethernet Inventors Professor of the Practice Bill Aulet, to elevate the center to higher levels.&lt;/p&gt;&lt;p&gt;“Ana is uniquely qualified for this role. She brings a deep and highly decorated background in entrepreneurship education at the highest levels, along with exceptional leadership and execution skills,” says Aulet. “Since I first met her 12 years ago, I have been extraordinarily impressed with her commitment to create the highest-quality centers and institutes for entrepreneurs, first at King’s College London and then at Oxford University. This ideal skill set is compounded by her experience in leading high-growth companies, most recently as the chief operation officer in an award-winning AI startup. I’m honored and thrilled to welcome her to MIT — her knowledge and energy will greatly elevate our community, and the field as a whole.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A rapidly changing environment creates imperative for raising the bar for entrepreneurship education&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The need to raise the bar for innovation-driven entrepreneurship education is both timely and urgent. The rate of change is getting faster and faster every day, especially with artificial intelligence, and is generating new problems that need to be solved, as well as exacerbating existing problems in climate, health care, manufacturing, future of work, education, and economic stratification, to name but a few. The world needs more entrepreneurs and better entrepreneurs.&lt;/p&gt;&lt;p&gt;Bakshi joins the Trust Center at an exciting time in its history. MIT is at the forefront of helping to develop people and systems that can turn challenges into opportunities using an entrepreneurial mindset, skill set, and way of operating.&amp;nbsp;Bakshi’s deep experience and success will be key to unlocking this opportunity. “I am truly honored to join the Trust Center at such a pivotal moment,” Bakshi says. “In an era defined by both extraordinary challenges and extraordinary possibilities, the future will be built by those bold enough to try, and MIT will be at the forefront of this.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Translating academic research into real-world impact&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Bakshi has a decade of experience building two world-class entrepreneurship centers from the ground up. She served as the founding director at King’s College and then at Oxford. In this role, she was responsible for all aspects of these centers, including fundraising.&lt;/p&gt;&lt;p&gt;While at Oxford, she authored a data-driven approach to determining efficacy of outcomes for their programs, as evidenced by a 61-page study, “Universities: Drivers of Prosperity and Economic Recovery.”&lt;/p&gt;&lt;p&gt;As the director of the Oxford Foundry (Oxford’s cross-university entrepreneurship center), Bakshi focused on investing in ambitious founders and talent. The center was backed by global entrepreneurial leaders such as the founders of LinkedIn and Twitter, with corporate partnerships including Santander and EY, and investment funds including Oxford Science Enterprises (OSE). As of 2021, the startups supported by the Foundry and King’s College have raised over $500 million and have created nearly 3,000 jobs, spanning diverse industries including health tech, climate tech, cybersecurity, fintech, and deep tech spinouts focusing on world-class science.&lt;/p&gt;&lt;p&gt;In addition, she built the highly successful and economically sustainable&amp;nbsp;Entrepreneurship School, Oxford’s first digital online learning platform.&lt;/p&gt;&lt;p&gt;Bakshi comes to MIT after having worked in the private sector as the chief operating officer (COO) in a rapidly growing artificial intelligence startup for almost two years,&amp;nbsp;Quench.ai, with offices in London and New York City. She was the first C-suite employee at Quench.ai, serving as COO and now senior advisor, helping companies unlock value from their knowledge through AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Right place, right time, right person moving at the speed of MIT AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since its inception, then turbocharged in the 1940s with the creation and operation of the&amp;nbsp;RadLab, and continuing to this day, entrepreneurship is at the core of MIT’s identity and mission.&amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;"MIT has been a leader in entrepreneurship for decades. It’s now the third leg of the school, alongside teaching and research,” says Mark Gorenberg ’76, chair of the MIT Corporation. “I’m excited to have such a transformative leader as Ana join the Trust Center team, and I look forward to the impact she will have on the students and the wider academic community at MIT as we enter an exciting new phase in company building, driven by the accelerated use of AI and emerging technologies."&lt;/p&gt;&lt;p&gt;“In a time where we are rethinking management education, entrepreneurship as an interdisciplinary field to create impact is even more important to our future. To have such an experienced and accomplished leader in academia and the startup world, especially in AI, reinforces our commitment to be a global leader in this field,” says Richard M. Locke, John C Head III Dean at the MIT Sloan School of Management.&lt;/p&gt;&lt;p&gt;“MIT is a unique hub of research, innovation, and entrepreneurship, and that special mix creates massive positive impact that ripples around the world,” says Frederic Kerrest, MIT Sloan MBA ’09, co-founder of Okta, and member of the MIT Corporation. “In a rapidly changing, AI-driven world, Ana has the skills and experience to further accelerate MIT’s global leadership in entrepreneurship education to ensure that our students launch and scale the next generation of groundbreaking, innovation-driven startups.”&lt;/p&gt;&lt;p&gt;Prior to her time at Oxford and King’s College, Bakshi served as an elected councilor representing 6,000-plus constituents, held roles in international nongovernmental organizations, and led product execution strategy at MAHI, an award-winning family-led craft sauce startup, available in thousands of major retailers across the U.K.&amp;nbsp;Bakshi sits on the&amp;nbsp;advisory council for conservation charity&amp;nbsp;Save the Elephants, leveraging AI-driven and scientific approaches to reduce human-wildlife conflict and protect elephant populations.&amp;nbsp;Her work and impact have been featured across &lt;em&gt;FT&lt;/em&gt;, &lt;em&gt;Forbes&lt;/em&gt;, BBC, &lt;em&gt;The Times&lt;/em&gt;, and &lt;em&gt;The Hill&lt;/em&gt;. Bakshi was twice honored as a Top 50 Woman in Tech (U.K.), most recently in 2025.&lt;/p&gt;&lt;p&gt;“As AI changes how we learn, how we build, and how we scale, my focus will be on helping MIT expand its support for phenomenal talent — students and faculty — with the skills, ecosystem, and backing to turn knowledge into impact,” Bakshi says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;35 years of impact to date&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Trust Center was founded in 1990 by the late Professor Edward Roberts and serves all MIT students across all schools and all disciplines.&amp;nbsp;It supports 60-plus courses and extensive extracurricular programming, including the delta v academic accelerator. Much of the work of the center is generated through the Disciplined Entrepreneurship methodology, which offers a proven approach to create new ventures. Over a thousand schools and other organizations across the world use Disciplined Entrepreneurship books and resources to teach entrepreneurship.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Now, with AI-powered tools like&amp;nbsp;Orbit and&amp;nbsp;JetPack, the Trust Center is changing the way that entrepreneurship is taught and practiced. Its mission is to produce the next generation of innovation-driven entrepreneurs while advancing the field more broadly to make it both rigorous and practical. This approach of leveraging proven evidence-based methodology, emerging technology, the ingenuity of MIT students, and responding to industry shifts is similar to how MIT&amp;nbsp;established the field of chemical engineering in the 1890s. The desired result in both cases was to create a comprehensive, integrated, scalable, rigorous, and practical curriculum to create a new workforce to address the nation’s and world’s greatest challenges.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/martin-trust-center-mit-entrepreneurship-ana-bakshi-executive-director-1002</guid><pubDate>Thu, 02 Oct 2025 19:55:00 +0000</pubDate></item><item><title>[NEW] Why iRobot’s founder won’t go within 10 feet of today’s walking robots (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/why-irobots-founder-wont-go-within-10-feet-of-todays-walking-robots/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Rodney Brooks says humanoid robots pose hidden safety challenges and won't learn dexterity from video alone.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the &amp;quot;We Robot&amp;quot; event on October 10, 2024." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/10/optimus_header_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the &amp;quot;We Robot&amp;quot; event on October 10, 2024." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/10/optimus_header_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the "We Robot" event on October 10, 2024.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tesla

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When a robotics pioneer who has spent decades building humanoid machines recommends that you stand at least nine feet away from any full-sized walking robot, you should probably listen.&lt;/p&gt;
&lt;p&gt;"My advice to people is to not come closer than 3 meters to a full-size walking robot," Rodney Brooks writes in a technical essay titled "Why Today’s Humanoids Won’t Learn Dexterity" published on his blog last week. "Until someone comes up with a better version of a two-legged&amp;nbsp;walking robot that is much safer to be near, and even in contact with, we will not see humanoid robots get certified to be deployed in zones that also have people in them."&lt;/p&gt;
&lt;p&gt;Brooks, the MIT professor emeritus who co-founded iRobot (of Roomba fame) and Rethink Robotics, believes companies pouring billions into humanoid development are chasing an expensive fantasy. Among other problems yet to be addressed, he warns that today's bipedal humanoids are fundamentally unsafe for humans to be near when they walk due to the massive kinetic energy they generate while maintaining balance. That stored-up energy can cause severe injury if the robot falls or its limbs strike someone.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120428 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Rodney Brooks posing with a robot at MIT in 2002." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-596940412-1024x576.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Rodney Brooks posing with a robot at MIT in 2002.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Rick Friedman via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;More on the dangers of robots in a minute. Beyond concerns about malfunction, Brooks contests the prevailing belief that humanoid robots will soon replace human workers by learning dexterity through watching videos of people performing tasks. It's a common robotics AI training technique we have covered in the past. He does not think such robots are impossible, but that they may be further off than most people think.&lt;/p&gt;
&lt;p&gt;In some corners of the tech world, robot hype has reached a fever pitch due to the rapid gains in AI. Tesla CEO Elon Musk has claimed that the company's Optimus robots could generate $30 trillion in revenue, while Figure's CEO Brett Adcock envisions humanoids serving millions of tasks in the labor force.&lt;/p&gt;
&lt;p&gt;However, hardware is much harder than software. Unlike software that runs in a virtual world, the laws of physics are unforgiving and immutable, and interacting with the physical world safely requires a great deal of sensory input. Brooks, who has been working on robot manipulation since the 1970s, argues these companies are missing the fundamental ingredient for dexterous manipulation: the sense of touch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The crux of Brooks' argument centers on how companies like Tesla and Figure are training their robots. Both have publicly stated they are using a vision-only approach, having workers wear camera rigs to record tasks like folding shirts or picking up objects. The data is then fed into AI models, which can imitate permutations of the motions in novel contexts. Tesla recently shifted away from motion capture suits and teleoperation for data collection to a video-based method, with workers wearing helmets and backpacks equipped with five cameras. Figure's "Project Go-Big" initiative similarly relies on transferring knowledge directly from what they call "everyday human video."&lt;/p&gt;
&lt;p&gt;(In addition to video capture from real humans performing tasks, some robotics AI models use simulations of physical space for training, which have similar limitations.)&lt;/p&gt;
&lt;p&gt;These approaches, Brooks argues, ignore decades of research showing that human dexterity depends on an extraordinarily complex touch-sensing system. He cites work from Roland Johansson's lab at Umeå University showing that when a person's fingertips are anesthetized, a seven-second task of picking up and lighting a match stretches to nearly 30 seconds of fumbling. The human hand contains about 17,000 mechanoreceptors, with 1,000 concentrated in each fingertip alone. Recent research from David Ginty's lab at Harvard has identified 15 families of neurons involved in touch sensing, detecting everything from gentle indentation to vibrations to skin stretching. That's a lot of sensory information that current robot systems cannot yet capture or simulate.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The physics of falling robots&lt;/h2&gt;
&lt;p&gt;Beyond the dexterity problem lies an even more immediate safety concern. Current humanoid robots use powerful electric motors and a decades-old algorithm called zero moment point to maintain balance by pumping large amounts of energy into their systems when instability is detected. This approach works well enough to keep them upright most of the time, but it creates what Brooks describes as a fundamental incompatibility with human proximity.&lt;/p&gt;
&lt;p&gt;The scaling laws of physics make full-sized humanoids exponentially more dangerous than their smaller counterparts. When you double the size of a robot, Brooks says, its mass increases by a factor of eight. That means a falling full-sized humanoid has eight times the kinetic energy of a half-sized version. If that rapidly accelerating metal leg encounters anything in its path during a fall, the impact can cause severe injury.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In his post, Brooks recounts being "way too close" to an Agility Robotics Digit humanoid when it fell several years ago. He has not dared approach one while walking since. Even in promotional videos from humanoid companies, Brooks notes, humans are never shown close to moving humanoid robots unless separated by furniture, and even then, the robots only shuffle minimally.&lt;/p&gt;
&lt;p&gt;This safety problem extends beyond accidental falls. For humanoids to fulfill their promised role in health care and factory settings, they need certification to operate in zones shared with humans. Current walking mechanisms make such certification virtually impossible under existing safety standards in most parts of the world.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102438 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Apollo robot" class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-1024x576.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The humanoid Apollo robot.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Brooks predicts that within 15 years, there will indeed be many robots called "humanoids" performing various tasks. But ironically, they will look nothing like today's bipedal machines. They will have wheels instead of feet, varying numbers of arms, and specialized sensors that bear no resemblance to human eyes. Some will have cameras in their hands or looking down from their midsections. The definition of "humanoid" will shift, just as "flying cars" now means electric helicopters rather than road-capable aircraft, and "self-driving cars" means vehicles with remote human monitors rather than truly autonomous systems.&lt;/p&gt;
&lt;p&gt;The billions currently being invested in forcing today's rigid, vision-only humanoids to learn dexterity will largely disappear, Brooks argues. Academic researchers are making more progress with systems that incorporate touch feedback, like MIT's approach using a glove that transmits sensations between human operators and robot hands. But even these advances remain far from the comprehensive touch sensing that enables human dexterity.&lt;/p&gt;
&lt;p&gt;Today, few people spend their days near humanoid robots, but Brooks's three-meter rule stands as a practical warning of challenges ahead from someone who has spent decades building these machines. The gap between promotional videos and deployable reality remains large, measured not just in years but in fundamental unsolved problems of physics, sensing, and safety.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Rodney Brooks says humanoid robots pose hidden safety challenges and won't learn dexterity from video alone.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the &amp;quot;We Robot&amp;quot; event on October 10, 2024." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/10/optimus_header_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the &amp;quot;We Robot&amp;quot; event on October 10, 2024." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/10/optimus_header_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A photo of Tesla's Optimus humanoid robot prototype provided by Tesla for the "We Robot" event on October 10, 2024.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tesla

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When a robotics pioneer who has spent decades building humanoid machines recommends that you stand at least nine feet away from any full-sized walking robot, you should probably listen.&lt;/p&gt;
&lt;p&gt;"My advice to people is to not come closer than 3 meters to a full-size walking robot," Rodney Brooks writes in a technical essay titled "Why Today’s Humanoids Won’t Learn Dexterity" published on his blog last week. "Until someone comes up with a better version of a two-legged&amp;nbsp;walking robot that is much safer to be near, and even in contact with, we will not see humanoid robots get certified to be deployed in zones that also have people in them."&lt;/p&gt;
&lt;p&gt;Brooks, the MIT professor emeritus who co-founded iRobot (of Roomba fame) and Rethink Robotics, believes companies pouring billions into humanoid development are chasing an expensive fantasy. Among other problems yet to be addressed, he warns that today's bipedal humanoids are fundamentally unsafe for humans to be near when they walk due to the massive kinetic energy they generate while maintaining balance. That stored-up energy can cause severe injury if the robot falls or its limbs strike someone.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120428 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Rodney Brooks posing with a robot at MIT in 2002." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-596940412-1024x576.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Rodney Brooks posing with a robot at MIT in 2002.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Rick Friedman via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;More on the dangers of robots in a minute. Beyond concerns about malfunction, Brooks contests the prevailing belief that humanoid robots will soon replace human workers by learning dexterity through watching videos of people performing tasks. It's a common robotics AI training technique we have covered in the past. He does not think such robots are impossible, but that they may be further off than most people think.&lt;/p&gt;
&lt;p&gt;In some corners of the tech world, robot hype has reached a fever pitch due to the rapid gains in AI. Tesla CEO Elon Musk has claimed that the company's Optimus robots could generate $30 trillion in revenue, while Figure's CEO Brett Adcock envisions humanoids serving millions of tasks in the labor force.&lt;/p&gt;
&lt;p&gt;However, hardware is much harder than software. Unlike software that runs in a virtual world, the laws of physics are unforgiving and immutable, and interacting with the physical world safely requires a great deal of sensory input. Brooks, who has been working on robot manipulation since the 1970s, argues these companies are missing the fundamental ingredient for dexterous manipulation: the sense of touch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The crux of Brooks' argument centers on how companies like Tesla and Figure are training their robots. Both have publicly stated they are using a vision-only approach, having workers wear camera rigs to record tasks like folding shirts or picking up objects. The data is then fed into AI models, which can imitate permutations of the motions in novel contexts. Tesla recently shifted away from motion capture suits and teleoperation for data collection to a video-based method, with workers wearing helmets and backpacks equipped with five cameras. Figure's "Project Go-Big" initiative similarly relies on transferring knowledge directly from what they call "everyday human video."&lt;/p&gt;
&lt;p&gt;(In addition to video capture from real humans performing tasks, some robotics AI models use simulations of physical space for training, which have similar limitations.)&lt;/p&gt;
&lt;p&gt;These approaches, Brooks argues, ignore decades of research showing that human dexterity depends on an extraordinarily complex touch-sensing system. He cites work from Roland Johansson's lab at Umeå University showing that when a person's fingertips are anesthetized, a seven-second task of picking up and lighting a match stretches to nearly 30 seconds of fumbling. The human hand contains about 17,000 mechanoreceptors, with 1,000 concentrated in each fingertip alone. Recent research from David Ginty's lab at Harvard has identified 15 families of neurons involved in touch sensing, detecting everything from gentle indentation to vibrations to skin stretching. That's a lot of sensory information that current robot systems cannot yet capture or simulate.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;The physics of falling robots&lt;/h2&gt;
&lt;p&gt;Beyond the dexterity problem lies an even more immediate safety concern. Current humanoid robots use powerful electric motors and a decades-old algorithm called zero moment point to maintain balance by pumping large amounts of energy into their systems when instability is detected. This approach works well enough to keep them upright most of the time, but it creates what Brooks describes as a fundamental incompatibility with human proximity.&lt;/p&gt;
&lt;p&gt;The scaling laws of physics make full-sized humanoids exponentially more dangerous than their smaller counterparts. When you double the size of a robot, Brooks says, its mass increases by a factor of eight. That means a falling full-sized humanoid has eight times the kinetic energy of a half-sized version. If that rapidly accelerating metal leg encounters anything in its path during a fall, the impact can cause severe injury.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In his post, Brooks recounts being "way too close" to an Agility Robotics Digit humanoid when it fell several years ago. He has not dared approach one while walking since. Even in promotional videos from humanoid companies, Brooks notes, humans are never shown close to moving humanoid robots unless separated by furniture, and even then, the robots only shuffle minimally.&lt;/p&gt;
&lt;p&gt;This safety problem extends beyond accidental falls. For humanoids to fulfill their promised role in health care and factory settings, they need certification to operate in zones shared with humans. Current walking mechanisms make such certification virtually impossible under existing safety standards in most parts of the world.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102438 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Apollo robot" class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-1024x576.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The humanoid Apollo robot.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Brooks predicts that within 15 years, there will indeed be many robots called "humanoids" performing various tasks. But ironically, they will look nothing like today's bipedal machines. They will have wheels instead of feet, varying numbers of arms, and specialized sensors that bear no resemblance to human eyes. Some will have cameras in their hands or looking down from their midsections. The definition of "humanoid" will shift, just as "flying cars" now means electric helicopters rather than road-capable aircraft, and "self-driving cars" means vehicles with remote human monitors rather than truly autonomous systems.&lt;/p&gt;
&lt;p&gt;The billions currently being invested in forcing today's rigid, vision-only humanoids to learn dexterity will largely disappear, Brooks argues. Academic researchers are making more progress with systems that incorporate touch feedback, like MIT's approach using a glove that transmits sensations between human operators and robot hands. But even these advances remain far from the comprehensive touch sensing that enables human dexterity.&lt;/p&gt;
&lt;p&gt;Today, few people spend their days near humanoid robots, but Brooks's three-meter rule stands as a practical warning of challenges ahead from someone who has spent decades building these machines. The gap between promotional videos and deployable reality remains large, measured not just in years but in fundamental unsolved problems of physics, sensing, and safety.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/why-irobots-founder-wont-go-within-10-feet-of-todays-walking-robots/</guid><pubDate>Thu, 02 Oct 2025 21:10:23 +0000</pubDate></item></channel></rss>