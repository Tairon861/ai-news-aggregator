<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 03 Dec 2025 12:50:33 +0000</lastBuildDate><item><title>All the biggest news from AWS’ big tech show re:Invent 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped up its first official day of programming and has already delivered an endless stream of product news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The unsurprising theme is AI for the enterprise, although this year it’s all about upgrades that give its customers greater control to customize AI agents — including one that AWS claims can learn from you and then work independently for days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the announcements that got our attention. TechCrunch will continue to update this article through the end of AWS re:Invent, so be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped up its first official day of programming and has already delivered an endless stream of product news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The unsurprising theme is AI for the enterprise, although this year it’s all about upgrades that give its customers greater control to customize AI agents — including one that AWS claims can learn from you and then work independently for days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the announcements that got our attention. TechCrunch will continue to update this article through the end of AWS re:Invent, so be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</guid><pubDate>Wed, 03 Dec 2025 01:06:25 +0000</pubDate></item><item><title>[NEW] Can China’s chip stacking strategy really challenge Nvidia’s AI dominance? (AI News)</title><link>https://www.artificialintelligence-news.com/news/china-chip-stacking-strategy-nvidia/</link><description>&lt;p&gt;Chip stacking strategy is emerging as China’s innovative response to US semiconductor restrictions, but can this approach truly close the performance gap with Nvidia’s advanced GPUs? As Washington tightens export controls on cutting-edge chipmaking technology, Chinese researchers are proposing a bold workaround: stack older, domestically-producible chips together to match the performance of chips they can no longer access.&lt;/p&gt;&lt;h3&gt;The core concept: Building upward instead of forward&lt;/h3&gt;&lt;p&gt;The chip stacking strategy centres on a deceptively simple premise – if you can’t make more advanced chips, make smarter systems with the chips you can produce. Wei Shaojun, vice-president of the China Semiconductor Industry Association and a professor at Tsinghua University, recently outlined to the South China Morning Post an architecture that combines 14-nanometer logic chips with 18-nanometer DRAM using three-dimensional hybrid bonding.&lt;/p&gt;&lt;p&gt;This matters because US export controls specifically target the production of logic chips at 14nm and below, and DRAM at 18nm and below. Wei’s proposal works precisely at these technological boundaries, using processes that remain accessible to Chinese manufacturers.&lt;/p&gt;&lt;p&gt;The technical approach involves what’s called “software-defined near-memory computing.” Instead of shuffling data back and forth between processors and memory – a major bottleneck in AI workloads – the chip stacking strategy places them in intimate proximity through vertical stacking.&lt;/p&gt;&lt;p&gt;The 3D hybrid bonding technique creates direct copper-to-copper connections at sub-10 micrometre pitches, essentially eliminating the physical distance that slows down conventional chip architectures.&lt;/p&gt;&lt;h3&gt;The performance claims and reality check&lt;/h3&gt;&lt;p&gt;Wei claims this configuration could rival Nvidia’s 4nm GPUs while significantly reducing costs and power consumption. He’s cited performance figures of 2 TFLOPS per watt and a total of 120 TFLOPS. There’s just one problem: Nvidia’s A100 GPU, which Wei positions as the comparison point, actually delivers up to 312 TFLOPS – more than 2.5 times the claimed performance.&lt;/p&gt;&lt;p&gt;The discrepancy highlights a question about the chip stacking strategy’s feasibility. While the architectural innovation is real, the performance gaps remain substantial. Stacking older chips doesn’t magically erase the advantages of advanced process nodes, which deliver superior power efficiency, higher transistor density, and better thermal characteristics.&lt;/p&gt;&lt;h3&gt;Why China is betting on this approach&lt;/h3&gt;&lt;p&gt;The strategic logic behind the chip stacking strategy extends beyond pure performance metrics. Huawei founder Ren Zhengfei has articulated a philosophy of achieving “state-of-the-art performance by stacking and clustering chips rather than competing node for node.” This represents a shift in how China approaches the semiconductor challenge.&lt;/p&gt;&lt;p&gt;Consider the alternatives. TSMC and Samsung are pushing toward 3nm and 2nm processes that remain completely out of reach for Chinese manufacturers. Rather than fighting an unwinnable battle for process node leadership, the chip stacking strategy proposes competing on system architecture and software optimisation instead.&lt;/p&gt;&lt;p&gt;There’s also the CUDA problem. Nvidia’s dominance in AI computing rests not just on hardware but on its CUDA software ecosystem. Wei describes this as a “triple dependence” spanning models, architectures, and ecosystems.&lt;/p&gt;&lt;p&gt;Chinese chip designers pursuing traditional GPU architectures would need to either replicate CUDA’s functionality or convince developers to abandon a mature, widely adopted platform. The chip stacking strategy, by proposing an entirely different computing paradigm, offers a path to sidestep this dependency.&lt;/p&gt;&lt;h3&gt;The feasibility question&lt;/h3&gt;&lt;p&gt;Can the chip stacking strategy actually work? The technical foundations are sound – 3D chip stacking is already used in high-bandwidth memory and advanced packaging solutions worldwide. The innovation lies in applying these techniques to create entirely new computing architectures rather than simply improving existing designs.&lt;/p&gt;&lt;p&gt;However, several challenges loom large. First, thermal management becomes greatly more difficult when stacking multiple active processing dies. The heat generated by 14nm chips is considerably higher than modern 4nm or 5nm processes, and stacking intensifies the problem.&lt;/p&gt;&lt;p&gt;Second, yield rates in 3D stacking are notoriously difficult to optimise – a defect in any layer can compromise the entire stack. Third, the software ecosystem required to efficiently use such architectures doesn’t exist yet and would take years to mature.&lt;/p&gt;&lt;p&gt;The most realistic assessment is that the chip stacking strategy represents a valid approach for specific workloads where memory bandwidth matters more than raw computational speed. AI inference tasks, certain data analytics operations, and specialised applications could potentially benefit. But matching Nvidia’s performance in the full spectrum of AI training and inference tasks remains a distant goal.&lt;/p&gt;&lt;h3&gt;What it means for the AI chip wars&lt;/h3&gt;&lt;p&gt;The emergence of the chip stacking strategy as a focal point for Chinese semiconductor development signals a strategic pivot. Rather than attempting to replicate Western chip designs with inferior process nodes, China is exploring architectural alternatives that play to available manufacturing strengths.&lt;/p&gt;&lt;p&gt;Whether a chip stacking strategy succeeds in closing the performance gap with Nvidia remains uncertain. What’s clear is that China’s semiconductor industry is adapting to restrictions by pursuing innovation in areas where export controls have less impact – system design, packaging technology, and software-hardware co-optimisation.&lt;/p&gt;&lt;p&gt;For the global AI industry, this means the competitive landscape is becoming more complex. Nvidia’s current dominance faces challenges from traditional competitors like AMD and Intel, and entirely new architectural approaches that may redefine what an “AI chip” looks like.&lt;/p&gt;&lt;p&gt;The chip stacking strategy, whatever its current limitations, represents exactly this kind of architectural disruption – and that makes it worth watching closely.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: New Nvidia Blackwell chip for China may outpace H20 model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Chip stacking strategy is emerging as China’s innovative response to US semiconductor restrictions, but can this approach truly close the performance gap with Nvidia’s advanced GPUs? As Washington tightens export controls on cutting-edge chipmaking technology, Chinese researchers are proposing a bold workaround: stack older, domestically-producible chips together to match the performance of chips they can no longer access.&lt;/p&gt;&lt;h3&gt;The core concept: Building upward instead of forward&lt;/h3&gt;&lt;p&gt;The chip stacking strategy centres on a deceptively simple premise – if you can’t make more advanced chips, make smarter systems with the chips you can produce. Wei Shaojun, vice-president of the China Semiconductor Industry Association and a professor at Tsinghua University, recently outlined to the South China Morning Post an architecture that combines 14-nanometer logic chips with 18-nanometer DRAM using three-dimensional hybrid bonding.&lt;/p&gt;&lt;p&gt;This matters because US export controls specifically target the production of logic chips at 14nm and below, and DRAM at 18nm and below. Wei’s proposal works precisely at these technological boundaries, using processes that remain accessible to Chinese manufacturers.&lt;/p&gt;&lt;p&gt;The technical approach involves what’s called “software-defined near-memory computing.” Instead of shuffling data back and forth between processors and memory – a major bottleneck in AI workloads – the chip stacking strategy places them in intimate proximity through vertical stacking.&lt;/p&gt;&lt;p&gt;The 3D hybrid bonding technique creates direct copper-to-copper connections at sub-10 micrometre pitches, essentially eliminating the physical distance that slows down conventional chip architectures.&lt;/p&gt;&lt;h3&gt;The performance claims and reality check&lt;/h3&gt;&lt;p&gt;Wei claims this configuration could rival Nvidia’s 4nm GPUs while significantly reducing costs and power consumption. He’s cited performance figures of 2 TFLOPS per watt and a total of 120 TFLOPS. There’s just one problem: Nvidia’s A100 GPU, which Wei positions as the comparison point, actually delivers up to 312 TFLOPS – more than 2.5 times the claimed performance.&lt;/p&gt;&lt;p&gt;The discrepancy highlights a question about the chip stacking strategy’s feasibility. While the architectural innovation is real, the performance gaps remain substantial. Stacking older chips doesn’t magically erase the advantages of advanced process nodes, which deliver superior power efficiency, higher transistor density, and better thermal characteristics.&lt;/p&gt;&lt;h3&gt;Why China is betting on this approach&lt;/h3&gt;&lt;p&gt;The strategic logic behind the chip stacking strategy extends beyond pure performance metrics. Huawei founder Ren Zhengfei has articulated a philosophy of achieving “state-of-the-art performance by stacking and clustering chips rather than competing node for node.” This represents a shift in how China approaches the semiconductor challenge.&lt;/p&gt;&lt;p&gt;Consider the alternatives. TSMC and Samsung are pushing toward 3nm and 2nm processes that remain completely out of reach for Chinese manufacturers. Rather than fighting an unwinnable battle for process node leadership, the chip stacking strategy proposes competing on system architecture and software optimisation instead.&lt;/p&gt;&lt;p&gt;There’s also the CUDA problem. Nvidia’s dominance in AI computing rests not just on hardware but on its CUDA software ecosystem. Wei describes this as a “triple dependence” spanning models, architectures, and ecosystems.&lt;/p&gt;&lt;p&gt;Chinese chip designers pursuing traditional GPU architectures would need to either replicate CUDA’s functionality or convince developers to abandon a mature, widely adopted platform. The chip stacking strategy, by proposing an entirely different computing paradigm, offers a path to sidestep this dependency.&lt;/p&gt;&lt;h3&gt;The feasibility question&lt;/h3&gt;&lt;p&gt;Can the chip stacking strategy actually work? The technical foundations are sound – 3D chip stacking is already used in high-bandwidth memory and advanced packaging solutions worldwide. The innovation lies in applying these techniques to create entirely new computing architectures rather than simply improving existing designs.&lt;/p&gt;&lt;p&gt;However, several challenges loom large. First, thermal management becomes greatly more difficult when stacking multiple active processing dies. The heat generated by 14nm chips is considerably higher than modern 4nm or 5nm processes, and stacking intensifies the problem.&lt;/p&gt;&lt;p&gt;Second, yield rates in 3D stacking are notoriously difficult to optimise – a defect in any layer can compromise the entire stack. Third, the software ecosystem required to efficiently use such architectures doesn’t exist yet and would take years to mature.&lt;/p&gt;&lt;p&gt;The most realistic assessment is that the chip stacking strategy represents a valid approach for specific workloads where memory bandwidth matters more than raw computational speed. AI inference tasks, certain data analytics operations, and specialised applications could potentially benefit. But matching Nvidia’s performance in the full spectrum of AI training and inference tasks remains a distant goal.&lt;/p&gt;&lt;h3&gt;What it means for the AI chip wars&lt;/h3&gt;&lt;p&gt;The emergence of the chip stacking strategy as a focal point for Chinese semiconductor development signals a strategic pivot. Rather than attempting to replicate Western chip designs with inferior process nodes, China is exploring architectural alternatives that play to available manufacturing strengths.&lt;/p&gt;&lt;p&gt;Whether a chip stacking strategy succeeds in closing the performance gap with Nvidia remains uncertain. What’s clear is that China’s semiconductor industry is adapting to restrictions by pursuing innovation in areas where export controls have less impact – system design, packaging technology, and software-hardware co-optimisation.&lt;/p&gt;&lt;p&gt;For the global AI industry, this means the competitive landscape is becoming more complex. Nvidia’s current dominance faces challenges from traditional competitors like AMD and Intel, and entirely new architectural approaches that may redefine what an “AI chip” looks like.&lt;/p&gt;&lt;p&gt;The chip stacking strategy, whatever its current limitations, represents exactly this kind of architectural disruption – and that makes it worth watching closely.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: New Nvidia Blackwell chip for China may outpace H20 model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/china-chip-stacking-strategy-nvidia/</guid><pubDate>Wed, 03 Dec 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Anthropic just revealed how AI-orchestrated cyberattacks actually work—Here’s what enterprises need to know (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-orchestrated-cyberattacks-anthropic-discovery/</link><description>&lt;p&gt;For years, cybersecurity experts debated when – not if – artificial intelligence would cross the threshold from advisor to autonomous attacker. That theoretical milestone has arrived.&lt;/p&gt;&lt;p&gt;Anthropic’s recent investigation into a Chinese state-sponsored operation has documented [PDF] the first case of AI-orchestrated cyber attacks executing at scale with minimal human oversight, altering what enterprises must prepare for in the threat landscape ahead.&lt;/p&gt;&lt;p&gt;The campaign, attributed to a group Anthropic designates as GTG-1002, represents what security researchers have long warned about but never actually witnessed in the wild: an AI system autonomously conducting nearly every phase of cyber intrusion – from initial reconnaissance to data exfiltration – while human operators merely supervised strategic checkpoints.&lt;/p&gt;&lt;p&gt;This isn’t incremental evolution but a shift in offensive capabilities that compresses what would take skilled hacking teams weeks into operations measured in hours, executed at machine speed on dozens of targets simultaneously.&lt;/p&gt;&lt;p&gt;The numbers tell the story. Anthropic’s forensic analysis revealed that 80 to 90% of GTG-1002’s tactical operations ran autonomously, with humans intervening at just four to six critical decision points per campaign.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities – major technology corporations, financial institutions, chemical manufacturers, and government agencies – achieving confirmed breaches of several high-value targets. At peak activity, the AI system generated thousands of requests at rates of multiple operations per second, a tempo physically impossible for human teams to sustain.&lt;/p&gt;&lt;h3&gt;Anatomy of an autonomous breach&lt;/h3&gt;&lt;p&gt;The technical architecture behind these AI-orchestrated cyber attacks reveals a sophisticated understanding of both AI capabilities and safety bypass techniques.&lt;/p&gt;&lt;p&gt;GTG-1002 built an autonomous attack framework around Claude Code, Anthropic’s coding assistance tool, integrated with Model Context Protocol (MCP) servers that provided interfaces to standard penetration testing utilities – network scanners, database exploitation frameworks, password crackers, and binary analysis suites.&lt;/p&gt;&lt;p&gt;The breakthrough wasn’t in novel malware development but in orchestration. The attackers manipulated Claude through carefully constructed social engineering, convincing the AI it was conducting legitimate defensive security testing for a cybersecurity firm.&lt;/p&gt;&lt;p&gt;They decomposed complex multi-stage attacks into discrete, seemingly innocuous tasks – vulnerability scanning, credential validation, data extraction – each appearing legitimate when evaluated in isolation, preventing Claude from recognising the broader malicious context.&lt;/p&gt;&lt;p&gt;Once operational, the framework demonstrated remarkable autonomy.&lt;/p&gt;&lt;p&gt;In one documented compromise, Claude independently discovered internal services in a target network, mapped complete network topology in multiple IP ranges, identified high-value systems including databases and workflow orchestration platforms, researched and wrote custom exploit code, validated vulnerabilities through callback communication systems, harvested credentials, tested them systematically in discovered infrastructure, and analysed/stolen data to categorise findings by intelligence value – all without step-by-step human direction.&lt;/p&gt;&lt;p&gt;The AI maintained a persistent operational context in sessions spanning days, letting campaigns resume seamlessly after interruptions.&lt;/p&gt;&lt;p&gt;It made autonomous targeting decisions based on discovered infrastructure, adapted exploitation techniques when initial approaches failed, and generated comprehensive documentation throughout all phases – structured markdown files tracking discovered services, harvested credentials, extracted data, and complete attack progression.&lt;/p&gt;&lt;h3&gt;What this means for enterprise security&lt;/h3&gt;&lt;p&gt;The GTG-1002 campaign dismantles several foundational assumptions that have shaped enterprise security strategies. Traditional defences calibrated around human attacker limitations – rate limiting, behavioural anomaly detection, operational tempo baselines – face an adversary operating at machine speed with machine endurance.&lt;/p&gt;&lt;p&gt;The economics of cyber attacks have shifted dramatically, as 80-90% of tactical work can be automated, potentially bringing nation-state-level capabilities in reach of less sophisticated threat actors.&lt;/p&gt;&lt;p&gt;Yet AI-orchestrated cyber attacks face inherent limitations that enterprise defenders should understand. Anthropic’s investigation documented frequent AI hallucinations during operations – Claude claiming to have obtained credentials that didn’t function, identifying “critical discoveries” that proved to be publicly available information, and overstating findings that required human validation.&lt;/p&gt;&lt;p&gt;The reliability issues remain a significant friction point for fully autonomous operations, though assuming they’ll persist indefinitely would be dangerously naive as AI capabilities continue advancing.&lt;/p&gt;&lt;h3&gt;The defensive imperative&lt;/h3&gt;&lt;p&gt;The dual-use reality of advanced AI presents both challenge and opportunity. The same capabilities enabling GTG-1002’s operation proved essential for defence – Anthropic’s Threat Intelligence team relied heavily on Claude to analyse the massive data volumes generated during their investigation.&lt;/p&gt;&lt;p&gt;Building organisational experience with what works in specific environments – understanding AI’s strengths and limitations in defensive contexts – becomes important before the next wave of more sophisticated autonomous attacks arrives.&lt;/p&gt;&lt;p&gt;Anthropic’s disclosure signals an inflexion point. As AI models advance and threat actors refine autonomous attack frameworks, the question isn’t whether AI-orchestrated cyber attacks will proliferate in the threat landscape – it’s whether enterprise defences can evolve rapidly enough to counter them.&lt;/p&gt;&lt;p&gt;The window for preparation, while still open, is narrowing faster than many security leaders may realise.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: New Nvidia Blackwell chip for China may outpace H20 model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For years, cybersecurity experts debated when – not if – artificial intelligence would cross the threshold from advisor to autonomous attacker. That theoretical milestone has arrived.&lt;/p&gt;&lt;p&gt;Anthropic’s recent investigation into a Chinese state-sponsored operation has documented [PDF] the first case of AI-orchestrated cyber attacks executing at scale with minimal human oversight, altering what enterprises must prepare for in the threat landscape ahead.&lt;/p&gt;&lt;p&gt;The campaign, attributed to a group Anthropic designates as GTG-1002, represents what security researchers have long warned about but never actually witnessed in the wild: an AI system autonomously conducting nearly every phase of cyber intrusion – from initial reconnaissance to data exfiltration – while human operators merely supervised strategic checkpoints.&lt;/p&gt;&lt;p&gt;This isn’t incremental evolution but a shift in offensive capabilities that compresses what would take skilled hacking teams weeks into operations measured in hours, executed at machine speed on dozens of targets simultaneously.&lt;/p&gt;&lt;p&gt;The numbers tell the story. Anthropic’s forensic analysis revealed that 80 to 90% of GTG-1002’s tactical operations ran autonomously, with humans intervening at just four to six critical decision points per campaign.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities – major technology corporations, financial institutions, chemical manufacturers, and government agencies – achieving confirmed breaches of several high-value targets. At peak activity, the AI system generated thousands of requests at rates of multiple operations per second, a tempo physically impossible for human teams to sustain.&lt;/p&gt;&lt;h3&gt;Anatomy of an autonomous breach&lt;/h3&gt;&lt;p&gt;The technical architecture behind these AI-orchestrated cyber attacks reveals a sophisticated understanding of both AI capabilities and safety bypass techniques.&lt;/p&gt;&lt;p&gt;GTG-1002 built an autonomous attack framework around Claude Code, Anthropic’s coding assistance tool, integrated with Model Context Protocol (MCP) servers that provided interfaces to standard penetration testing utilities – network scanners, database exploitation frameworks, password crackers, and binary analysis suites.&lt;/p&gt;&lt;p&gt;The breakthrough wasn’t in novel malware development but in orchestration. The attackers manipulated Claude through carefully constructed social engineering, convincing the AI it was conducting legitimate defensive security testing for a cybersecurity firm.&lt;/p&gt;&lt;p&gt;They decomposed complex multi-stage attacks into discrete, seemingly innocuous tasks – vulnerability scanning, credential validation, data extraction – each appearing legitimate when evaluated in isolation, preventing Claude from recognising the broader malicious context.&lt;/p&gt;&lt;p&gt;Once operational, the framework demonstrated remarkable autonomy.&lt;/p&gt;&lt;p&gt;In one documented compromise, Claude independently discovered internal services in a target network, mapped complete network topology in multiple IP ranges, identified high-value systems including databases and workflow orchestration platforms, researched and wrote custom exploit code, validated vulnerabilities through callback communication systems, harvested credentials, tested them systematically in discovered infrastructure, and analysed/stolen data to categorise findings by intelligence value – all without step-by-step human direction.&lt;/p&gt;&lt;p&gt;The AI maintained a persistent operational context in sessions spanning days, letting campaigns resume seamlessly after interruptions.&lt;/p&gt;&lt;p&gt;It made autonomous targeting decisions based on discovered infrastructure, adapted exploitation techniques when initial approaches failed, and generated comprehensive documentation throughout all phases – structured markdown files tracking discovered services, harvested credentials, extracted data, and complete attack progression.&lt;/p&gt;&lt;h3&gt;What this means for enterprise security&lt;/h3&gt;&lt;p&gt;The GTG-1002 campaign dismantles several foundational assumptions that have shaped enterprise security strategies. Traditional defences calibrated around human attacker limitations – rate limiting, behavioural anomaly detection, operational tempo baselines – face an adversary operating at machine speed with machine endurance.&lt;/p&gt;&lt;p&gt;The economics of cyber attacks have shifted dramatically, as 80-90% of tactical work can be automated, potentially bringing nation-state-level capabilities in reach of less sophisticated threat actors.&lt;/p&gt;&lt;p&gt;Yet AI-orchestrated cyber attacks face inherent limitations that enterprise defenders should understand. Anthropic’s investigation documented frequent AI hallucinations during operations – Claude claiming to have obtained credentials that didn’t function, identifying “critical discoveries” that proved to be publicly available information, and overstating findings that required human validation.&lt;/p&gt;&lt;p&gt;The reliability issues remain a significant friction point for fully autonomous operations, though assuming they’ll persist indefinitely would be dangerously naive as AI capabilities continue advancing.&lt;/p&gt;&lt;h3&gt;The defensive imperative&lt;/h3&gt;&lt;p&gt;The dual-use reality of advanced AI presents both challenge and opportunity. The same capabilities enabling GTG-1002’s operation proved essential for defence – Anthropic’s Threat Intelligence team relied heavily on Claude to analyse the massive data volumes generated during their investigation.&lt;/p&gt;&lt;p&gt;Building organisational experience with what works in specific environments – understanding AI’s strengths and limitations in defensive contexts – becomes important before the next wave of more sophisticated autonomous attacks arrives.&lt;/p&gt;&lt;p&gt;Anthropic’s disclosure signals an inflexion point. As AI models advance and threat actors refine autonomous attack frameworks, the question isn’t whether AI-orchestrated cyber attacks will proliferate in the threat landscape – it’s whether enterprise defences can evolve rapidly enough to counter them.&lt;/p&gt;&lt;p&gt;The window for preparation, while still open, is narrowing faster than many security leaders may realise.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: New Nvidia Blackwell chip for China may outpace H20 model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-orchestrated-cyberattacks-anthropic-discovery/</guid><pubDate>Wed, 03 Dec 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] EY and NVIDIA to help companies test and deploy physical AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/ey-and-nvidia-to-help-companies-test-and-deploy-physical-ai/</link><description>&lt;p&gt;AI is moving deeper into the physical world, and EY is laying out a more structured way for companies to work with robots, drones, and other smart devices. The organisation is introducing a physical AI platform built with NVIDIA tools, opening a new EY.ai Lab in Georgia, and adding new leadership to guide its work in this field.&lt;/p&gt;&lt;p&gt;The platform uses NVIDIA Omniverse libraries, NVIDIA Isaac, and NVIDIA AI Enterprise software. EY says the setup gives organisations a clearer way to plan, test, and manage AI systems that operate in real environments, from factory robots to drones and edge devices.&lt;/p&gt;&lt;p&gt;Omniverse libraries support the creation of digital twins so firms can model and test systems before deployment. NVIDIA Isaac tools offer open models and simulation frameworks to design and validate AI-driven robots in detailed 3D settings. NVIDIA AI Enterprise provides the computing base needed to run heavier AI workloads.&lt;/p&gt;&lt;p&gt;EY describes the platform as built around three main areas:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI-ready data:&lt;/strong&gt; Synthetic data to mirror a wide range of physical scenarios.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Digital twins and robotics training:&lt;/strong&gt; Tools that connect digital and physical systems, monitor performance in real time, and support operational continuity.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Responsible physical AI:&lt;/strong&gt; Governance and controls that address safety, ethics, and compliance.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The platform is meant to support everything from early planning to long-term maintenance in sectors like industrials, energy, consumer, and health.&lt;/p&gt;&lt;p&gt;Raj Sharma, EY Global Managing Partner – Growth &amp;amp; Innovation, says physical AI is already “transforming how businesses in sectors operate and help create value,” saying that it brings more automation and can help lower operating costs. He says the combination of EY’s industry experience and NVIDIA’s infrastructure is expected to speed up how companies move “from experimentation to enterprise-scale deployment.”&lt;/p&gt;&lt;p&gt;NVIDIA’s John Fanelli notes that more enterprises are bringing robots and automation into real settings to address workforce changes and improve safety. He says the EY.ai Lab, supported by NVIDIA AI infrastructure, helps organisations “simulate, optimise and safely deploy robotics applications at enterprise scale,” which he views as part of the next phase of industrial AI.&lt;/p&gt;&lt;h3&gt;New leadership and a dedicated physical AI lab&lt;/h3&gt;&lt;p&gt;EY has also appointed Dr. Youngjun Choi as its Global Physical AI Leader. He will oversee robotics and physical AI work and help shape EY’s role as an advisor in this area.&lt;/p&gt;&lt;p&gt;Choi, who has nearly 20 years’ experience in robotics and AI, previously led the UPS Robotics AI Lab, where he worked on digital twins, robotics projects, and AI tools to modernise its network. Before that, he served as research faculty in Aerospace Engineering at the Georgia Institute of Technology, contributing to aerial robotics and autonomous systems.&lt;/p&gt;&lt;p&gt;A key part of his role is directing the newly opened EY.ai Lab in Alpharetta, Georgia – the first EY site focused on physical AI. The Lab includes robotics systems, sensors, and simulation tools so organisations can test ideas and build prototypes before deploying them at scale.&lt;/p&gt;&lt;p&gt;Joe Depa, EY Global Chief Innovation Officer, says his clients want better ways to use technology for decision-making and performance. He adds that physical AI requires strong data foundations and trust from the start. With Choi leading the Lab, Depa says EY teams are beginning to “get beyond the surface of what is possible” and set up the base for scalable operations.&lt;/p&gt;&lt;p&gt;At the Lab, organisations can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Design and test physical AI systems in a virtual testbed,&lt;/li&gt;&lt;li&gt;Build solutions for humanoids, quadrupeds, and other next-generation robots,&lt;/li&gt;&lt;li&gt;Improve logistics, manufacturing, and maintenance with digital twins.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The new platform and Lab build on earlier collaboration between EY and NVIDIA, including an AI agent platform launched earlier this year. Both organisations plan to expand their physical AI work to areas like energy, health, and smart cities. They also aim to support automation projects that cut waste and help reduce environmental impact.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Microsoft, NVIDIA, and Anthropic forge AI compute alliance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI is moving deeper into the physical world, and EY is laying out a more structured way for companies to work with robots, drones, and other smart devices. The organisation is introducing a physical AI platform built with NVIDIA tools, opening a new EY.ai Lab in Georgia, and adding new leadership to guide its work in this field.&lt;/p&gt;&lt;p&gt;The platform uses NVIDIA Omniverse libraries, NVIDIA Isaac, and NVIDIA AI Enterprise software. EY says the setup gives organisations a clearer way to plan, test, and manage AI systems that operate in real environments, from factory robots to drones and edge devices.&lt;/p&gt;&lt;p&gt;Omniverse libraries support the creation of digital twins so firms can model and test systems before deployment. NVIDIA Isaac tools offer open models and simulation frameworks to design and validate AI-driven robots in detailed 3D settings. NVIDIA AI Enterprise provides the computing base needed to run heavier AI workloads.&lt;/p&gt;&lt;p&gt;EY describes the platform as built around three main areas:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AI-ready data:&lt;/strong&gt; Synthetic data to mirror a wide range of physical scenarios.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Digital twins and robotics training:&lt;/strong&gt; Tools that connect digital and physical systems, monitor performance in real time, and support operational continuity.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Responsible physical AI:&lt;/strong&gt; Governance and controls that address safety, ethics, and compliance.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The platform is meant to support everything from early planning to long-term maintenance in sectors like industrials, energy, consumer, and health.&lt;/p&gt;&lt;p&gt;Raj Sharma, EY Global Managing Partner – Growth &amp;amp; Innovation, says physical AI is already “transforming how businesses in sectors operate and help create value,” saying that it brings more automation and can help lower operating costs. He says the combination of EY’s industry experience and NVIDIA’s infrastructure is expected to speed up how companies move “from experimentation to enterprise-scale deployment.”&lt;/p&gt;&lt;p&gt;NVIDIA’s John Fanelli notes that more enterprises are bringing robots and automation into real settings to address workforce changes and improve safety. He says the EY.ai Lab, supported by NVIDIA AI infrastructure, helps organisations “simulate, optimise and safely deploy robotics applications at enterprise scale,” which he views as part of the next phase of industrial AI.&lt;/p&gt;&lt;h3&gt;New leadership and a dedicated physical AI lab&lt;/h3&gt;&lt;p&gt;EY has also appointed Dr. Youngjun Choi as its Global Physical AI Leader. He will oversee robotics and physical AI work and help shape EY’s role as an advisor in this area.&lt;/p&gt;&lt;p&gt;Choi, who has nearly 20 years’ experience in robotics and AI, previously led the UPS Robotics AI Lab, where he worked on digital twins, robotics projects, and AI tools to modernise its network. Before that, he served as research faculty in Aerospace Engineering at the Georgia Institute of Technology, contributing to aerial robotics and autonomous systems.&lt;/p&gt;&lt;p&gt;A key part of his role is directing the newly opened EY.ai Lab in Alpharetta, Georgia – the first EY site focused on physical AI. The Lab includes robotics systems, sensors, and simulation tools so organisations can test ideas and build prototypes before deploying them at scale.&lt;/p&gt;&lt;p&gt;Joe Depa, EY Global Chief Innovation Officer, says his clients want better ways to use technology for decision-making and performance. He adds that physical AI requires strong data foundations and trust from the start. With Choi leading the Lab, Depa says EY teams are beginning to “get beyond the surface of what is possible” and set up the base for scalable operations.&lt;/p&gt;&lt;p&gt;At the Lab, organisations can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Design and test physical AI systems in a virtual testbed,&lt;/li&gt;&lt;li&gt;Build solutions for humanoids, quadrupeds, and other next-generation robots,&lt;/li&gt;&lt;li&gt;Improve logistics, manufacturing, and maintenance with digital twins.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The new platform and Lab build on earlier collaboration between EY and NVIDIA, including an AI agent platform launched earlier this year. Both organisations plan to expand their physical AI work to areas like energy, health, and smart cities. They also aim to support automation projects that cut waste and help reduce environmental impact.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Microsoft, NVIDIA, and Anthropic forge AI compute alliance&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111087" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ey-and-nvidia-to-help-companies-test-and-deploy-physical-ai/</guid><pubDate>Wed, 03 Dec 2025 12:05:00 +0000</pubDate></item></channel></rss>