<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 26 Jul 2025 06:33:02 +0000</lastBuildDate><item><title>OpenAI’s most capable AI model, GPT-5, may be coming in August (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/openais-most-capable-ai-model-gpt-5-may-be-coming-in-august/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sources say new model combines o3 reasoning with general GPT capabilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Verge reported that OpenAI is preparing to launch GPT-5 as early as August, according to sources familiar with the company's plans. The report comes five months after CEO Sam Altman first laid out a roadmap for the next-generation AI model that would unify the company's various AI capabilities. OpenAI CEO Sam Altman revealed in a post on X last week that the company plans to release GPT-5 "soon."&lt;/p&gt;
&lt;p&gt;According to The Verge's Tom Warren, Microsoft engineers began preparing server capacity for GPT-5 as early as late May, but testing and development challenges pushed the timeline back. During an appearance on Theo Von's podcast this week, Altman demonstrated the model's capabilities by having it answer a question he couldn't. "I put it in the model, this is GPT-5, and it answered it perfectly," Altman said, saying it gave him a "weird feeling" to see the AI model answer a question that he couldn't.&lt;/p&gt;
&lt;p&gt;GPT-5 has been a highly anticipated release since the launch of GPT-4 in March 2023. In fact, we first wrote about rumors of GPT-5's launch in March 2024, but it appears that GPT-5 did not materialize last year because the company saved the "GPT-5" name for a future release.&lt;/p&gt;
&lt;p&gt;The Verge reports that OpenAI plans to launch what is now called GPT-5 with "mini" and "nano" versions available through its API. The main version, which will combine a conventional large language model (LLM) and a simulated reasoning (SR) model, will be available through ChatGPT and OpenAI's API, while the nano version will reportedly only be accessible via the API.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;References to "gpt-5-reasoning-alpha-2025-07-13" have already been spotted on X, with code showing "reasoning_effort: high" in the model configuration. These sightings suggest the model has entered final testing phases, with testers getting their hands on the code and security experts doing red teaming on the model to test vulnerabilities.&lt;/p&gt;
&lt;h2&gt;Unifying OpenAI’s model lineup&lt;/h2&gt;
&lt;p&gt;The new model represents OpenAI's attempt to simplify its increasingly complex product lineup. As Altman explained in February, GPT-5 may integrate features from both the company's conventional GPT models and its reasoning-focused o-series models into a single system.&lt;/p&gt;
&lt;p&gt;"We're truly excited to not just make a net new great frontier model, we're also going to unify our two series," OpenAI's Head of Developer Experience Romain Huet said at a recent event. "The breakthrough of reasoning in the O-series and the breakthroughs in multi-modality in the GPT-series will be unified, and that will be GPT-5."&lt;/p&gt;
&lt;p&gt;According to The Information, GPT-5 is expected to be better at coding and more powerful overall, combining attributes of both traditional models and SR models such as o3.&lt;/p&gt;
&lt;p&gt;Before GPT-5 arrives, OpenAI still plans to release its first open-weights model since GPT-2 in 2019, which means others with the proper hardware will be able to download and run the AI model on their own machines. The Verge describes this model as "similar to o3 mini" with reasoning capabilities. However, Altman announced on July 11 that the open model needs additional safety testing, saying, "We are not yet sure how long it will take us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sources say new model combines o3 reasoning with general GPT capabilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Verge reported that OpenAI is preparing to launch GPT-5 as early as August, according to sources familiar with the company's plans. The report comes five months after CEO Sam Altman first laid out a roadmap for the next-generation AI model that would unify the company's various AI capabilities. OpenAI CEO Sam Altman revealed in a post on X last week that the company plans to release GPT-5 "soon."&lt;/p&gt;
&lt;p&gt;According to The Verge's Tom Warren, Microsoft engineers began preparing server capacity for GPT-5 as early as late May, but testing and development challenges pushed the timeline back. During an appearance on Theo Von's podcast this week, Altman demonstrated the model's capabilities by having it answer a question he couldn't. "I put it in the model, this is GPT-5, and it answered it perfectly," Altman said, saying it gave him a "weird feeling" to see the AI model answer a question that he couldn't.&lt;/p&gt;
&lt;p&gt;GPT-5 has been a highly anticipated release since the launch of GPT-4 in March 2023. In fact, we first wrote about rumors of GPT-5's launch in March 2024, but it appears that GPT-5 did not materialize last year because the company saved the "GPT-5" name for a future release.&lt;/p&gt;
&lt;p&gt;The Verge reports that OpenAI plans to launch what is now called GPT-5 with "mini" and "nano" versions available through its API. The main version, which will combine a conventional large language model (LLM) and a simulated reasoning (SR) model, will be available through ChatGPT and OpenAI's API, while the nano version will reportedly only be accessible via the API.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;References to "gpt-5-reasoning-alpha-2025-07-13" have already been spotted on X, with code showing "reasoning_effort: high" in the model configuration. These sightings suggest the model has entered final testing phases, with testers getting their hands on the code and security experts doing red teaming on the model to test vulnerabilities.&lt;/p&gt;
&lt;h2&gt;Unifying OpenAI’s model lineup&lt;/h2&gt;
&lt;p&gt;The new model represents OpenAI's attempt to simplify its increasingly complex product lineup. As Altman explained in February, GPT-5 may integrate features from both the company's conventional GPT models and its reasoning-focused o-series models into a single system.&lt;/p&gt;
&lt;p&gt;"We're truly excited to not just make a net new great frontier model, we're also going to unify our two series," OpenAI's Head of Developer Experience Romain Huet said at a recent event. "The breakthrough of reasoning in the O-series and the breakthroughs in multi-modality in the GPT-series will be unified, and that will be GPT-5."&lt;/p&gt;
&lt;p&gt;According to The Information, GPT-5 is expected to be better at coding and more powerful overall, combining attributes of both traditional models and SR models such as o3.&lt;/p&gt;
&lt;p&gt;Before GPT-5 arrives, OpenAI still plans to release its first open-weights model since GPT-2 in 2019, which means others with the proper hardware will be able to download and run the AI model on their own machines. The Verge describes this model as "similar to o3 mini" with reasoning capabilities. However, Altman announced on July 11 that the open model needs additional safety testing, saying, "We are not yet sure how long it will take us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/openais-most-capable-ai-model-gpt-5-may-be-coming-in-august/</guid><pubDate>Fri, 25 Jul 2025 19:59:37 +0000</pubDate></item><item><title>CoSyn: The open-source tool that’s making GPT-4V-level vision AI accessible to everyone (AI News | VentureBeat)</title><link>https://venturebeat.com/business/cosyn-the-open-source-tool-thats-making-gpt-4v-level-vision-ai-accessible-to-everyone/</link><description>&lt;p&gt;Researchers at the University of Pennsylvania and the Allen Institute for Artificial Intelligence have developed a groundbreaking tool that allows open-source AI systems to match or surpass the visual understanding capabilities of proprietary models like GPT-4V and Gemini 1.5 Flash, potentially reshaping the competitive landscape between open and closed AI development.&lt;/p&gt;



&lt;p&gt;The tool, called CoSyn (Code-Guided Synthesis), addresses a critical bottleneck in AI development: the scarcity of high-quality training data for teaching machines to understand complex visual information like scientific charts, medical diagrams, and financial documents. Rather than scraping millions of images from the internet — a practice fraught with copyright and ethical concerns — CoSyn leverages the coding abilities of existing language models to generate synthetic training data.&lt;/p&gt;



&lt;p&gt;“We have, we lack of such data to train the model. We lack of data, like documents, charts with rich annotations to train a vision language model to do question answering over those images,” explained Yue Yang, a recent Penn Engineering Ph.D. graduate and co-first author of the research, during an exclusive interview with VentureBeat. “Those images actually are more challenging to annotate, compared to natural photos, like a picture of a dog of a cat of a house.”&lt;/p&gt;



&lt;p&gt;The breakthrough comes as enterprises increasingly seek AI systems capable of understanding and reasoning about complex visual information — capabilities essential for everything from automated document processing to AI agents that can navigate digital interfaces independently. The work was conducted during Yang’s internship with the PRIOR team at the Allen Institute for AI and supported by the Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity, and the Defense Advanced Research Projects Agency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-generation-solves-ai-s-biggest-training-challenge"&gt;How synthetic data generation solves AI’s biggest training challenge&lt;/h2&gt;



&lt;p&gt;The challenge of training AI to understand text-rich images has long plagued the field. Unlike natural photographs, scientific figures, charts, and documents require extensive annotation work that is both time-consuming and expensive. Traditional approaches have relied on harvesting images and their alt-text descriptions from the internet, but this method produces training data that is often superficial and legally problematic.&lt;/p&gt;



&lt;p&gt;CoSyn takes a fundamentally different approach by recognizing that most text-rich images are originally created through code — Python scripts generate charts, LaTeX renders mathematical equations, HTML creates web interfaces. The research team’s insight was to reverse this process: use language models’ proven coding abilities to generate the underlying code, then execute that code to create realistic synthetic images.&lt;/p&gt;



&lt;p&gt;“One intuition is actually those images like charts documents. We render them from programs from code, like we use Python to generate charts. We use, like latex or word to write our documents,” Yang said. “So how about we go through the reverse way, like we generated the code because the text only language model has been proved very good at writing code.”&lt;/p&gt;



&lt;p&gt;Chris Callison-Burch, a computer science professor at Penn who co-advised the research, described the approach in simpler terms: “This is like taking a student who’s great at writing and asking them to teach someone how to draw, just by describing what the drawing should look like. We’re essentially transferring the strengths of open-source AI from text to vision.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cosyn-trained-models-outperform-gpt-4v-and-gemini-on-key-benchmarks"&gt;CoSyn-trained models outperform GPT-4V and Gemini on key benchmarks&lt;/h2&gt;



&lt;p&gt;The results are striking. Using their synthetic dataset of 400,000 images and 2.7 million instruction pairs, models trained with CoSyn achieved state-of-the-art performance among open-source systems and surpassed proprietary models on seven benchmark tests measuring text-rich image understanding.&lt;/p&gt;



&lt;p&gt;On average, their 7-billion parameter model scored 80.9% across the benchmark suite, outperforming the previous best open-source model (Llama 3.2 11B) by 3.9 percentage points. More remarkably, even their “zero-shot” model—trained without any examples from the evaluation datasets—outperformed most open and closed models, demonstrating the transferability of capabilities learned from synthetic data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014678" height="314" src="https://venturebeat.com/wp-content/uploads/2025/07/main_results.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoSyn-trained models outperformed GPT-4V and Gemini 1.5 Flash across seven text-rich image understanding benchmarks. (Credit: github.io/cosyn)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In one particularly compelling demonstration, the researchers created a new benchmark called NutritionQA, consisting of 100 questions about nutrition label photographs. Using just 7,000 synthetically generated nutrition labels for training, their model outperformed others trained on millions of real images. “Despite being trained on millions of images, we observe that open-source VLMs are not data-efficient and perform poorly on this novel task compared to GPT-4V,” the researchers wrote in their paper.&lt;/p&gt;



&lt;p&gt;Yang emphasized the significance: “Those big packs, they have so many resources to collecting data to run a lot of experiments, and I but I think open source models, we can give access to people, the model weights, the data we trained, or even the code, the training script, everything people can developers can build upon.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-companies-are-already-using-vision-ai-for-quality-control-and-automation"&gt;Real companies are already using vision AI for quality control and automation&lt;/h2&gt;



&lt;p&gt;The technology is already finding real-world applications across industries. Callison-Burch cited an example from one of his teaching assistants whose company uses vision-language models for cable installation quality assurance: “They have the workers on site who are doing the installation take photographs of the processes they’re doing it, and they use that to automatically validate that each step has been followed properly.”&lt;/p&gt;



&lt;p&gt;This type of specialized visual understanding could transform numerous enterprise workflows, from automated document processing in financial services to quality control in manufacturing. The ability to train models on specific visual tasks using synthetic data means companies can develop AI systems tailored to their particular needs without the massive data collection efforts traditionally required.&lt;/p&gt;



&lt;p&gt;For enterprise decision makers, the research suggests a shift in how to approach AI data strategies. “I think synthetic data is a very promising way to remove the effort for human annotation. It costs less money, and it will just automatically generate large scale data, and also can avoid some copyright issues,” Yang noted.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-persona-driven-approach-that-makes-ai-training-data-more-diverse"&gt;The persona-driven approach that makes AI training data more diverse&lt;/h2&gt;



&lt;p&gt;One of CoSyn’s key innovations is its approach to ensuring data diversity. To prevent the repetitive outputs common in AI-generated content, the system employs what the researchers call a “persona-driven mechanism.” Each time CoSyn generates a synthetic example, it pairs the request with a randomly sampled persona—a short description like “a sci-fi novelist constantly bouncing off ideas for new alien worlds” or “a chemistry teacher preparing lab materials.”&lt;/p&gt;



&lt;p&gt;“Every time we generate one syntax data, we will appear with a randomly sampled persona,” Yang explained. “This will diversify the content and styles of the examples we generated, because, like, if I provide the persona of like a PhD student, it will generate something more scientific or more about, something about academia.”&lt;/p&gt;



&lt;p&gt;This approach enables the system to generate content across nine different categories: charts, documents, math problems, tables, diagrams, vector graphics, music sheets, electrical circuits, and chemical structures. The researchers used 11 different rendering tools, from Python’s Matplotlib for charts to LaTeX for mathematical expressions, supported by 20 specialized generation pipelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-this-breakthrough-could-level-the-playing-field-between-open-source-and-big-tech"&gt;Why this breakthrough could level the playing field between open source and Big Tech&lt;/h2&gt;



&lt;p&gt;The implications for the broader AI industry are significant. Major technology companies like OpenAI and Google have invested billions in developing their proprietary vision-language capabilities, creating systems whose training methods and data sources remain trade secrets. CoSyn offers a path for open-source alternatives to compete without requiring similar resource investments.&lt;/p&gt;



&lt;p&gt;“Open source models still like, like behind those closed source models, but with all the efforts, all the resources from the open source community, everyone, like, we’ve had more efforts. We have more like energy, like from, from everyone. So I think finally we can catch up,” Yang said.&lt;/p&gt;



&lt;p&gt;The commitment to openness extends beyond just releasing the model. The complete CoSyn codebase, the 400,000-image dataset, and all training scripts are publicly available, enabling researchers and companies worldwide to build upon the work. “From the academia side, like a lot of research is built upon openness, like we need all access to the data, code, everything to discover new findings to support our claims in the papers,” Yang emphasized.&lt;/p&gt;



&lt;p&gt;This transparency addresses growing concerns about the black-box nature of proprietary AI systems. “If you only rely on the APIs for like open AI, this may not be reliable to prove your like scientific discoveries, because they may just. Something in the back end you never know,” Yang noted.&lt;/p&gt;







&lt;p&gt;Beyond static image understanding, CoSyn is pioneering capabilities crucial for the next generation of AI agents—systems that can autonomously navigate digital interfaces and perform complex tasks. The researchers developed synthetic “pointing data” that teaches models exactly where to click on screenshots, a fundamental requirement for web-based automation.&lt;/p&gt;



&lt;p&gt;Using 65,000 synthetic screenshots with click annotations, their model achieved state-of-the-art performance on ScreenSpot, a benchmark for click prediction, outperforming systems trained on 1.3 million real screenshots. “We only use like several 100k synthetic screenshot, we can outperform previous model on millions of screenshots,” Yang said.&lt;/p&gt;



&lt;p&gt;This capability is essential as the industry moves toward AI agents that can perform knowledge work autonomously. “There’s sort of like two prevailing models and how you might go about implementing agents,” Callison-Burch explained. One approach uses specialized APIs, while the other relies on agents that “literally just use web browsing capabilities in the same way that you and I do.”&lt;/p&gt;



&lt;p&gt;The vision-based approach, enabled by technologies like CoSyn, could prove more versatile: “You’re not just calling up software function, which is relatively straightforward, but you actually have to, like, take screenshots of the current state of the web browser. Reason about where to click, navigate your mouse to that location to click.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-sidesteps-the-growing-copyright-crisis-in-ai-training"&gt;How synthetic data sidesteps the growing copyright crisis in AI training&lt;/h2&gt;



&lt;p&gt;The synthetic data approach also provides a potential solution to mounting legal challenges around AI training data. With ongoing litigation over whether training on copyrighted materials constitutes fair use, synthetic data generation offers an alternative path that sidesteps many intellectual property concerns.&lt;/p&gt;



&lt;p&gt;Callison-Burch, who testified before Congress on AI and copyright in 2023, sees synthetic data as complementary to, rather than replacing, real-world training data: “I don’t think that synthetic data eliminates the need for having wide amounts of diverse training data like that’s still a core element to training AI systems, but it does allow you to extend their capabilities in really remarkable ways.”&lt;/p&gt;



&lt;p&gt;The approach demonstrates how existing knowledge can be transferred to new applications without directly using copyrighted materials. “The underlying thing that we’re relying on here is a large language model. Can write code that’s something that it learned from its original data. We’re now applying that to a totally different application, which is creation of new training data that is unlike any of the data that it was trained on.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-current-limits-of-synthetic-data-and-what-comes-next"&gt;The current limits of synthetic data and what comes next&lt;/h2&gt;



&lt;p&gt;Despite its promise, synthetic data generation faces important limitations. “One limitation is it may inherit the biases from the model that generates such synthetic data,” Yang acknowledged. The system can also struggle with diversity: “If you prompt a large network to generate some data among different runs, it may generate similar data.”&lt;/p&gt;



&lt;p&gt;The current research focuses on text-rich images rather than natural photographs, limiting its immediate applicability to some domains. “What about some real photos like some other like natural images? It is hard to generate synthetic data for those two males, or even like medical images, chest X rays,” Yang noted, though she indicated ongoing efforts to extend the approach to medical imaging.&lt;/p&gt;



&lt;p&gt;Looking ahead, Yang expects synthetic data generation to become standard practice: “In the future, in two or three years, and even for nothing, editor has been a very important component to teach model different capabilities.” However, she emphasized that optimal results will likely require combining synthetic and real-world data: “Real world data will reflect some real world distributions. Single data can be large scale. Can be more controllable.”&lt;/p&gt;







&lt;p&gt;Early adoption signals suggest the technology is already influencing industry practices. “I heard like companies, like meta, some teams also, like all Amazon, they are trying to using our data to train their model,” Yang revealed during the interview.&lt;/p&gt;



&lt;p&gt;For startups and smaller companies, the cost advantages could be particularly significant. “For some startups, it is cheaper to host, their host open model on their server, rather than just calling the APIs, which is less controllable,” Yang noted.&lt;/p&gt;



&lt;p&gt;The research team’s decision to make everything open source reflects a broader philosophy about AI development. As Yang prepares to join the Allen Institute full-time after completing her Ph.D., the commitment to open science remains central to their mission. “Currently, those vision language models are quite brittle. It just needs the right data to get the right capabilities,” she said. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vision-for-ai-that-acts-not-just-describes"&gt;The vision for AI that acts, not just describes&lt;/h2&gt;



&lt;p&gt;As the research moves from academic laboratories to real-world applications, the implications extend far beyond improved benchmark scores. Yang and her colleagues are already looking toward applications that could transform how people with disabilities interact with technology, from AI that understands sign language for the hearing impaired to systems that can describe complex medical images for those with visual impairments.&lt;/p&gt;



&lt;p&gt;“I have an idea to let the model to know how to understand the sign language or those people with hearing difficulties,” Yang said, describing potential future applications. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;p&gt;Callison-Burch sees even broader possibilities, particularly in robotics and scientific discovery: “Synthetic data opens up many possible applications that we don’t have naturally occurring data for. So one that Yang has also worked on at the Allen Institute is that. Ocean of creating simulated training data for robots.”&lt;/p&gt;



&lt;p&gt;The work represents more than just a technical achievement—it’s a demonstration that open-source AI development can compete with the well-funded efforts of major technology companies through innovative approaches to fundamental challenges. As Yang noted in reflecting on her decision to join the Allen Institute rather than accept higher-paying offers from companies like Meta: “I think it’s still a very early stage of those multimodal models, and there are not much resources, open resources, or knowledge to share to the community.”&lt;/p&gt;



&lt;p&gt;The message is clear: in the race to build AI that can truly see and understand the world, the advantage may not always go to those with the deepest pockets, but to those with the most creative solutions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;p&gt;Researchers at the University of Pennsylvania and the Allen Institute for Artificial Intelligence have developed a groundbreaking tool that allows open-source AI systems to match or surpass the visual understanding capabilities of proprietary models like GPT-4V and Gemini 1.5 Flash, potentially reshaping the competitive landscape between open and closed AI development.&lt;/p&gt;



&lt;p&gt;The tool, called CoSyn (Code-Guided Synthesis), addresses a critical bottleneck in AI development: the scarcity of high-quality training data for teaching machines to understand complex visual information like scientific charts, medical diagrams, and financial documents. Rather than scraping millions of images from the internet — a practice fraught with copyright and ethical concerns — CoSyn leverages the coding abilities of existing language models to generate synthetic training data.&lt;/p&gt;



&lt;p&gt;“We have, we lack of such data to train the model. We lack of data, like documents, charts with rich annotations to train a vision language model to do question answering over those images,” explained Yue Yang, a recent Penn Engineering Ph.D. graduate and co-first author of the research, during an exclusive interview with VentureBeat. “Those images actually are more challenging to annotate, compared to natural photos, like a picture of a dog of a cat of a house.”&lt;/p&gt;



&lt;p&gt;The breakthrough comes as enterprises increasingly seek AI systems capable of understanding and reasoning about complex visual information — capabilities essential for everything from automated document processing to AI agents that can navigate digital interfaces independently. The work was conducted during Yang’s internship with the PRIOR team at the Allen Institute for AI and supported by the Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity, and the Defense Advanced Research Projects Agency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-generation-solves-ai-s-biggest-training-challenge"&gt;How synthetic data generation solves AI’s biggest training challenge&lt;/h2&gt;



&lt;p&gt;The challenge of training AI to understand text-rich images has long plagued the field. Unlike natural photographs, scientific figures, charts, and documents require extensive annotation work that is both time-consuming and expensive. Traditional approaches have relied on harvesting images and their alt-text descriptions from the internet, but this method produces training data that is often superficial and legally problematic.&lt;/p&gt;



&lt;p&gt;CoSyn takes a fundamentally different approach by recognizing that most text-rich images are originally created through code — Python scripts generate charts, LaTeX renders mathematical equations, HTML creates web interfaces. The research team’s insight was to reverse this process: use language models’ proven coding abilities to generate the underlying code, then execute that code to create realistic synthetic images.&lt;/p&gt;



&lt;p&gt;“One intuition is actually those images like charts documents. We render them from programs from code, like we use Python to generate charts. We use, like latex or word to write our documents,” Yang said. “So how about we go through the reverse way, like we generated the code because the text only language model has been proved very good at writing code.”&lt;/p&gt;



&lt;p&gt;Chris Callison-Burch, a computer science professor at Penn who co-advised the research, described the approach in simpler terms: “This is like taking a student who’s great at writing and asking them to teach someone how to draw, just by describing what the drawing should look like. We’re essentially transferring the strengths of open-source AI from text to vision.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cosyn-trained-models-outperform-gpt-4v-and-gemini-on-key-benchmarks"&gt;CoSyn-trained models outperform GPT-4V and Gemini on key benchmarks&lt;/h2&gt;



&lt;p&gt;The results are striking. Using their synthetic dataset of 400,000 images and 2.7 million instruction pairs, models trained with CoSyn achieved state-of-the-art performance among open-source systems and surpassed proprietary models on seven benchmark tests measuring text-rich image understanding.&lt;/p&gt;



&lt;p&gt;On average, their 7-billion parameter model scored 80.9% across the benchmark suite, outperforming the previous best open-source model (Llama 3.2 11B) by 3.9 percentage points. More remarkably, even their “zero-shot” model—trained without any examples from the evaluation datasets—outperformed most open and closed models, demonstrating the transferability of capabilities learned from synthetic data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014678" height="314" src="https://venturebeat.com/wp-content/uploads/2025/07/main_results.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoSyn-trained models outperformed GPT-4V and Gemini 1.5 Flash across seven text-rich image understanding benchmarks. (Credit: github.io/cosyn)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In one particularly compelling demonstration, the researchers created a new benchmark called NutritionQA, consisting of 100 questions about nutrition label photographs. Using just 7,000 synthetically generated nutrition labels for training, their model outperformed others trained on millions of real images. “Despite being trained on millions of images, we observe that open-source VLMs are not data-efficient and perform poorly on this novel task compared to GPT-4V,” the researchers wrote in their paper.&lt;/p&gt;



&lt;p&gt;Yang emphasized the significance: “Those big packs, they have so many resources to collecting data to run a lot of experiments, and I but I think open source models, we can give access to people, the model weights, the data we trained, or even the code, the training script, everything people can developers can build upon.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-companies-are-already-using-vision-ai-for-quality-control-and-automation"&gt;Real companies are already using vision AI for quality control and automation&lt;/h2&gt;



&lt;p&gt;The technology is already finding real-world applications across industries. Callison-Burch cited an example from one of his teaching assistants whose company uses vision-language models for cable installation quality assurance: “They have the workers on site who are doing the installation take photographs of the processes they’re doing it, and they use that to automatically validate that each step has been followed properly.”&lt;/p&gt;



&lt;p&gt;This type of specialized visual understanding could transform numerous enterprise workflows, from automated document processing in financial services to quality control in manufacturing. The ability to train models on specific visual tasks using synthetic data means companies can develop AI systems tailored to their particular needs without the massive data collection efforts traditionally required.&lt;/p&gt;



&lt;p&gt;For enterprise decision makers, the research suggests a shift in how to approach AI data strategies. “I think synthetic data is a very promising way to remove the effort for human annotation. It costs less money, and it will just automatically generate large scale data, and also can avoid some copyright issues,” Yang noted.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-persona-driven-approach-that-makes-ai-training-data-more-diverse"&gt;The persona-driven approach that makes AI training data more diverse&lt;/h2&gt;



&lt;p&gt;One of CoSyn’s key innovations is its approach to ensuring data diversity. To prevent the repetitive outputs common in AI-generated content, the system employs what the researchers call a “persona-driven mechanism.” Each time CoSyn generates a synthetic example, it pairs the request with a randomly sampled persona—a short description like “a sci-fi novelist constantly bouncing off ideas for new alien worlds” or “a chemistry teacher preparing lab materials.”&lt;/p&gt;



&lt;p&gt;“Every time we generate one syntax data, we will appear with a randomly sampled persona,” Yang explained. “This will diversify the content and styles of the examples we generated, because, like, if I provide the persona of like a PhD student, it will generate something more scientific or more about, something about academia.”&lt;/p&gt;



&lt;p&gt;This approach enables the system to generate content across nine different categories: charts, documents, math problems, tables, diagrams, vector graphics, music sheets, electrical circuits, and chemical structures. The researchers used 11 different rendering tools, from Python’s Matplotlib for charts to LaTeX for mathematical expressions, supported by 20 specialized generation pipelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-this-breakthrough-could-level-the-playing-field-between-open-source-and-big-tech"&gt;Why this breakthrough could level the playing field between open source and Big Tech&lt;/h2&gt;



&lt;p&gt;The implications for the broader AI industry are significant. Major technology companies like OpenAI and Google have invested billions in developing their proprietary vision-language capabilities, creating systems whose training methods and data sources remain trade secrets. CoSyn offers a path for open-source alternatives to compete without requiring similar resource investments.&lt;/p&gt;



&lt;p&gt;“Open source models still like, like behind those closed source models, but with all the efforts, all the resources from the open source community, everyone, like, we’ve had more efforts. We have more like energy, like from, from everyone. So I think finally we can catch up,” Yang said.&lt;/p&gt;



&lt;p&gt;The commitment to openness extends beyond just releasing the model. The complete CoSyn codebase, the 400,000-image dataset, and all training scripts are publicly available, enabling researchers and companies worldwide to build upon the work. “From the academia side, like a lot of research is built upon openness, like we need all access to the data, code, everything to discover new findings to support our claims in the papers,” Yang emphasized.&lt;/p&gt;



&lt;p&gt;This transparency addresses growing concerns about the black-box nature of proprietary AI systems. “If you only rely on the APIs for like open AI, this may not be reliable to prove your like scientific discoveries, because they may just. Something in the back end you never know,” Yang noted.&lt;/p&gt;







&lt;p&gt;Beyond static image understanding, CoSyn is pioneering capabilities crucial for the next generation of AI agents—systems that can autonomously navigate digital interfaces and perform complex tasks. The researchers developed synthetic “pointing data” that teaches models exactly where to click on screenshots, a fundamental requirement for web-based automation.&lt;/p&gt;



&lt;p&gt;Using 65,000 synthetic screenshots with click annotations, their model achieved state-of-the-art performance on ScreenSpot, a benchmark for click prediction, outperforming systems trained on 1.3 million real screenshots. “We only use like several 100k synthetic screenshot, we can outperform previous model on millions of screenshots,” Yang said.&lt;/p&gt;



&lt;p&gt;This capability is essential as the industry moves toward AI agents that can perform knowledge work autonomously. “There’s sort of like two prevailing models and how you might go about implementing agents,” Callison-Burch explained. One approach uses specialized APIs, while the other relies on agents that “literally just use web browsing capabilities in the same way that you and I do.”&lt;/p&gt;



&lt;p&gt;The vision-based approach, enabled by technologies like CoSyn, could prove more versatile: “You’re not just calling up software function, which is relatively straightforward, but you actually have to, like, take screenshots of the current state of the web browser. Reason about where to click, navigate your mouse to that location to click.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-sidesteps-the-growing-copyright-crisis-in-ai-training"&gt;How synthetic data sidesteps the growing copyright crisis in AI training&lt;/h2&gt;



&lt;p&gt;The synthetic data approach also provides a potential solution to mounting legal challenges around AI training data. With ongoing litigation over whether training on copyrighted materials constitutes fair use, synthetic data generation offers an alternative path that sidesteps many intellectual property concerns.&lt;/p&gt;



&lt;p&gt;Callison-Burch, who testified before Congress on AI and copyright in 2023, sees synthetic data as complementary to, rather than replacing, real-world training data: “I don’t think that synthetic data eliminates the need for having wide amounts of diverse training data like that’s still a core element to training AI systems, but it does allow you to extend their capabilities in really remarkable ways.”&lt;/p&gt;



&lt;p&gt;The approach demonstrates how existing knowledge can be transferred to new applications without directly using copyrighted materials. “The underlying thing that we’re relying on here is a large language model. Can write code that’s something that it learned from its original data. We’re now applying that to a totally different application, which is creation of new training data that is unlike any of the data that it was trained on.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-current-limits-of-synthetic-data-and-what-comes-next"&gt;The current limits of synthetic data and what comes next&lt;/h2&gt;



&lt;p&gt;Despite its promise, synthetic data generation faces important limitations. “One limitation is it may inherit the biases from the model that generates such synthetic data,” Yang acknowledged. The system can also struggle with diversity: “If you prompt a large network to generate some data among different runs, it may generate similar data.”&lt;/p&gt;



&lt;p&gt;The current research focuses on text-rich images rather than natural photographs, limiting its immediate applicability to some domains. “What about some real photos like some other like natural images? It is hard to generate synthetic data for those two males, or even like medical images, chest X rays,” Yang noted, though she indicated ongoing efforts to extend the approach to medical imaging.&lt;/p&gt;



&lt;p&gt;Looking ahead, Yang expects synthetic data generation to become standard practice: “In the future, in two or three years, and even for nothing, editor has been a very important component to teach model different capabilities.” However, she emphasized that optimal results will likely require combining synthetic and real-world data: “Real world data will reflect some real world distributions. Single data can be large scale. Can be more controllable.”&lt;/p&gt;







&lt;p&gt;Early adoption signals suggest the technology is already influencing industry practices. “I heard like companies, like meta, some teams also, like all Amazon, they are trying to using our data to train their model,” Yang revealed during the interview.&lt;/p&gt;



&lt;p&gt;For startups and smaller companies, the cost advantages could be particularly significant. “For some startups, it is cheaper to host, their host open model on their server, rather than just calling the APIs, which is less controllable,” Yang noted.&lt;/p&gt;



&lt;p&gt;The research team’s decision to make everything open source reflects a broader philosophy about AI development. As Yang prepares to join the Allen Institute full-time after completing her Ph.D., the commitment to open science remains central to their mission. “Currently, those vision language models are quite brittle. It just needs the right data to get the right capabilities,” she said. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vision-for-ai-that-acts-not-just-describes"&gt;The vision for AI that acts, not just describes&lt;/h2&gt;



&lt;p&gt;As the research moves from academic laboratories to real-world applications, the implications extend far beyond improved benchmark scores. Yang and her colleagues are already looking toward applications that could transform how people with disabilities interact with technology, from AI that understands sign language for the hearing impaired to systems that can describe complex medical images for those with visual impairments.&lt;/p&gt;



&lt;p&gt;“I have an idea to let the model to know how to understand the sign language or those people with hearing difficulties,” Yang said, describing potential future applications. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;p&gt;Callison-Burch sees even broader possibilities, particularly in robotics and scientific discovery: “Synthetic data opens up many possible applications that we don’t have naturally occurring data for. So one that Yang has also worked on at the Allen Institute is that. Ocean of creating simulated training data for robots.”&lt;/p&gt;



&lt;p&gt;The work represents more than just a technical achievement—it’s a demonstration that open-source AI development can compete with the well-funded efforts of major technology companies through innovative approaches to fundamental challenges. As Yang noted in reflecting on her decision to join the Allen Institute rather than accept higher-paying offers from companies like Meta: “I think it’s still a very early stage of those multimodal models, and there are not much resources, open resources, or knowledge to share to the community.”&lt;/p&gt;



&lt;p&gt;The message is clear: in the race to build AI that can truly see and understand the world, the advantage may not always go to those with the deepest pockets, but to those with the most creative solutions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/business/cosyn-the-open-source-tool-thats-making-gpt-4v-level-vision-ai-accessible-to-everyone/</guid><pubDate>Fri, 25 Jul 2025 20:05:12 +0000</pubDate></item><item><title>AI referrals to top websites were up 357% year-over-year in June, reaching 1.13B (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/ai-referrals-to-top-websites-were-up-357-year-over-year-in-june-reaching-1-13b/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI referrals to websites still have a way to go to catch up to the traffic that Google Search provides, but they’re growing quickly. According to new data from market intelligence provider Similarweb, AI platforms in June generated over 1.13 billion referrals to the top 1,000 websites globally, a figure that’s up 357% since June 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google Search still accounts for the majority of traffic to these sites, accounting for 191 billion referrals during the same period of June 2025. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One particular category of interest these days is news and media. Online publishers are seeing traffic declines and are preparing for a day they’re calling “Google Zero,” when Google stops sending traffic to websites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, The Wall Street Journal recently reported on data that showed how AI overviews were killing traffic to news sites. Plus, a Pew Research Center study out this week found that in a survey of 900 U.S. Google users, 18% of some 69,000 searches showed AI Overviews, which led to users clicking links 8% of the time. When there was no AI summary, users clicked links nearly twice as much, or 15% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarweb found that June’s AI referrals to news and media websites were up 770% since June 2024. Some sites will naturally rank higher than others that are blocking access to AI platforms, as The New York Times does, as a result of its lawsuit with OpenAI over the use of its articles to train its models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the news media category, Yahoo led with 2.3 million AI referrals in June 2025, followed by Yahoo Japan (1.9M), Reuters (1.8M), The Guardian (1.7M), India Times (1.2M), and Business Insider (1.0M). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of methodology, Similarweb counts AI referrals as web referrals to a domain from an AI platform like ChatGPT, Gemini, DeepSeek, Grok, Perplexity, Claude, and Liner. ChatGPT dominates here, accounting for more than 80% of the AI referrals to the top 1,000 domains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s analysis also looked at other categories beyond news, like e-commerce, science and education, tech/search/social media, arts and entertainment, business, and others. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031349" height="614" src="https://techcrunch.com/wp-content/uploads/2025/07/top-ai-referrals-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In e-commerce, Amazon was followed by Etsy and eBay when it came to those sites seeing the most referrals, at 4.5M, 2.0M, and 1.8M, respectively, during June. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the top tech and social sites, Google, not surprisingly, was at the top of the list, with 53.1 million referrals in June, followed by Reddit (11.1M), Facebook (11.0M), Github (7.4M), Microsoft (5.1M), Canva (5.0M), Instagram (4.7M), LinkedIn (4.4M), Bing (3.1M), and Pinterest (2.5M). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The analysis excluded the OpenAI website because so many of its referrals were from ChatGPT, pointing to its services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Across all other domains, the No. 1 site by AI referrals for each category included YouTube (31.2M), Research Gate (3.6M), Zillow (776.2K), Europa.eu (992.9K), Wikipedia (10.8M), NIH.gov (5.2M), Investing.com (1.2M), Home Depot (1.2M), Kayak (456.5K), and Zara (325.6K). &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI referrals to websites still have a way to go to catch up to the traffic that Google Search provides, but they’re growing quickly. According to new data from market intelligence provider Similarweb, AI platforms in June generated over 1.13 billion referrals to the top 1,000 websites globally, a figure that’s up 357% since June 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google Search still accounts for the majority of traffic to these sites, accounting for 191 billion referrals during the same period of June 2025. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One particular category of interest these days is news and media. Online publishers are seeing traffic declines and are preparing for a day they’re calling “Google Zero,” when Google stops sending traffic to websites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, The Wall Street Journal recently reported on data that showed how AI overviews were killing traffic to news sites. Plus, a Pew Research Center study out this week found that in a survey of 900 U.S. Google users, 18% of some 69,000 searches showed AI Overviews, which led to users clicking links 8% of the time. When there was no AI summary, users clicked links nearly twice as much, or 15% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarweb found that June’s AI referrals to news and media websites were up 770% since June 2024. Some sites will naturally rank higher than others that are blocking access to AI platforms, as The New York Times does, as a result of its lawsuit with OpenAI over the use of its articles to train its models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the news media category, Yahoo led with 2.3 million AI referrals in June 2025, followed by Yahoo Japan (1.9M), Reuters (1.8M), The Guardian (1.7M), India Times (1.2M), and Business Insider (1.0M). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of methodology, Similarweb counts AI referrals as web referrals to a domain from an AI platform like ChatGPT, Gemini, DeepSeek, Grok, Perplexity, Claude, and Liner. ChatGPT dominates here, accounting for more than 80% of the AI referrals to the top 1,000 domains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s analysis also looked at other categories beyond news, like e-commerce, science and education, tech/search/social media, arts and entertainment, business, and others. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031349" height="614" src="https://techcrunch.com/wp-content/uploads/2025/07/top-ai-referrals-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In e-commerce, Amazon was followed by Etsy and eBay when it came to those sites seeing the most referrals, at 4.5M, 2.0M, and 1.8M, respectively, during June. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the top tech and social sites, Google, not surprisingly, was at the top of the list, with 53.1 million referrals in June, followed by Reddit (11.1M), Facebook (11.0M), Github (7.4M), Microsoft (5.1M), Canva (5.0M), Instagram (4.7M), LinkedIn (4.4M), Bing (3.1M), and Pinterest (2.5M). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The analysis excluded the OpenAI website because so many of its referrals were from ChatGPT, pointing to its services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Across all other domains, the No. 1 site by AI referrals for each category included YouTube (31.2M), Research Gate (3.6M), Zillow (776.2K), Europa.eu (992.9K), Wikipedia (10.8M), NIH.gov (5.2M), Investing.com (1.2M), Home Depot (1.2M), Kayak (456.5K), and Zara (325.6K). &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/ai-referrals-to-top-websites-were-up-357-year-over-year-in-june-reaching-1-13b/</guid><pubDate>Fri, 25 Jul 2025 20:11:08 +0000</pubDate></item><item><title>Meta names Shengjia Zhao as chief scientist of AI superintelligence unit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg announced Friday that former OpenAI researcher Shengjia Zhao will lead research efforts at the company’s new AI unit, Meta Superintelligence Labs (MSL). Zhao contributed to several of OpenAI’s largest breakthroughs, including ChatGPT, GPT-4, and the company’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m excited to share that Shengjia Zhao will be the Chief Scientist of Meta Superintelligence Labs,” Zuckerberg said in a post on Threads Friday. “Shengjia co-founded the new lab and has been our lead scientist from day one. Now that our recruiting is going well and our team is coming together, we have decided to formalize his leadership role.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhao will set a research agenda for MSL under the leadership of Alexandr Wang, the former CEO of Scale AI who was recently hired to lead the new unit.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We are excited to announce that @shengjia_zhao will be the Chief Scientist of Meta Superintelligence Labs!&lt;/p&gt;&lt;p&gt;Shengjia is a brilliant scientist who most recently pioneered a new scaling paradigm in his research. He will lead our scientific direction for our team.&lt;/p&gt;&lt;p&gt;Let's go 🚀 pic.twitter.com/D93KQWIvFl&lt;/p&gt;— Alexandr Wang (@alexandr_wang) July 25, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who does not have a research background, was viewed as a somewhat unconventional choice to lead an AI lab. The addition of Zhao, who is a reputable research leader known for developing frontier AI models, rounds out the leadership team. To further fill out the unit, Meta has hired several high-level researchers from OpenAI, Google DeepMind, Safe Superintelligence, Apple, and Anthropic, as well as pulling researchers from Meta’s existing Fundamental AI Research (FAIR) lab and generative AI unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg notes in his post that Zhao has pioneered several breakthroughs, including a “new scaling paradigm.” The Meta CEO is likely referencing Zhao’s work on OpenAI’s reasoning model, o1, in which he is listed as a foundational contributor alongside OpenAI co-founder Ilya Sutskever. Meta currently doesn’t offer a competitor to o1, so AI reasoning models are a key area of focus for MSL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Information reported in June that Zhao would be joining Meta Superintelligence Labs, alongside three other influential OpenAI researchers — Jiahui Yu, Shuchao Bi, and Hongyu Ren. Meta has also recruited&amp;nbsp;Trapit Bansal, another OpenAI researcher who worked on AI reasoning models with Zhao, as well as three employees from OpenAI’s Zurich office who worked on multimodality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has gone to great lengths to set MSL up for success. The Meta CEO has been on a recruiting spree to staff up his AI superintelligence lab, which has entailed sending personal emails to researchers and inviting prospects to his Lake Tahoe estate. Meta has reportedly offered some researchers eight- and nine-figure compensation packages, some of which are “exploding offers” that expire in a matter of days.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also upped its investment in cloud computing infrastructure, which should help MSL conduct the massive training runs required to create competitive frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By 2026, Zhao and MSL’s researchers should have access to Meta’s 1 gigawatt cloud computing cluster, Prometheus, located in Ohio. Once online, Meta will be one of the first technology companies with an AI training cluster of Prometheus’ size — 1 gigawatt is enough energy to power more than 750,000 homes. That should help Meta conduct the massive training runs required to create frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Zhao, Meta now has two chief AI scientists, including Yann LeCun, the leader of Meta’s FAIR lab. Unlike MSL, FAIR is designed to focus on long-term AI research — techniques that may be used five to 10 years from now. How exactly Meta’s three AI units will work together remains to be seen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nevertheless, Meta now seems to have a formidable AI leadership team to compete with OpenAI and Google.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg announced Friday that former OpenAI researcher Shengjia Zhao will lead research efforts at the company’s new AI unit, Meta Superintelligence Labs (MSL). Zhao contributed to several of OpenAI’s largest breakthroughs, including ChatGPT, GPT-4, and the company’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m excited to share that Shengjia Zhao will be the Chief Scientist of Meta Superintelligence Labs,” Zuckerberg said in a post on Threads Friday. “Shengjia co-founded the new lab and has been our lead scientist from day one. Now that our recruiting is going well and our team is coming together, we have decided to formalize his leadership role.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhao will set a research agenda for MSL under the leadership of Alexandr Wang, the former CEO of Scale AI who was recently hired to lead the new unit.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We are excited to announce that @shengjia_zhao will be the Chief Scientist of Meta Superintelligence Labs!&lt;/p&gt;&lt;p&gt;Shengjia is a brilliant scientist who most recently pioneered a new scaling paradigm in his research. He will lead our scientific direction for our team.&lt;/p&gt;&lt;p&gt;Let's go 🚀 pic.twitter.com/D93KQWIvFl&lt;/p&gt;— Alexandr Wang (@alexandr_wang) July 25, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who does not have a research background, was viewed as a somewhat unconventional choice to lead an AI lab. The addition of Zhao, who is a reputable research leader known for developing frontier AI models, rounds out the leadership team. To further fill out the unit, Meta has hired several high-level researchers from OpenAI, Google DeepMind, Safe Superintelligence, Apple, and Anthropic, as well as pulling researchers from Meta’s existing Fundamental AI Research (FAIR) lab and generative AI unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg notes in his post that Zhao has pioneered several breakthroughs, including a “new scaling paradigm.” The Meta CEO is likely referencing Zhao’s work on OpenAI’s reasoning model, o1, in which he is listed as a foundational contributor alongside OpenAI co-founder Ilya Sutskever. Meta currently doesn’t offer a competitor to o1, so AI reasoning models are a key area of focus for MSL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Information reported in June that Zhao would be joining Meta Superintelligence Labs, alongside three other influential OpenAI researchers — Jiahui Yu, Shuchao Bi, and Hongyu Ren. Meta has also recruited&amp;nbsp;Trapit Bansal, another OpenAI researcher who worked on AI reasoning models with Zhao, as well as three employees from OpenAI’s Zurich office who worked on multimodality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has gone to great lengths to set MSL up for success. The Meta CEO has been on a recruiting spree to staff up his AI superintelligence lab, which has entailed sending personal emails to researchers and inviting prospects to his Lake Tahoe estate. Meta has reportedly offered some researchers eight- and nine-figure compensation packages, some of which are “exploding offers” that expire in a matter of days.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also upped its investment in cloud computing infrastructure, which should help MSL conduct the massive training runs required to create competitive frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By 2026, Zhao and MSL’s researchers should have access to Meta’s 1 gigawatt cloud computing cluster, Prometheus, located in Ohio. Once online, Meta will be one of the first technology companies with an AI training cluster of Prometheus’ size — 1 gigawatt is enough energy to power more than 750,000 homes. That should help Meta conduct the massive training runs required to create frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Zhao, Meta now has two chief AI scientists, including Yann LeCun, the leader of Meta’s FAIR lab. Unlike MSL, FAIR is designed to focus on long-term AI research — techniques that may be used five to 10 years from now. How exactly Meta’s three AI units will work together remains to be seen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nevertheless, Meta now seems to have a formidable AI leadership team to compete with OpenAI and Google.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/</guid><pubDate>Fri, 25 Jul 2025 20:58:37 +0000</pubDate></item><item><title>New AI architecture delivers 100x faster reasoning than LLMs with just 1,000 training examples (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/</link><description>&lt;p&gt;Singapore-based AI startup Sapient Intelligence has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient.&lt;/p&gt;&lt;p&gt;The architecture, &lt;span&gt;known as the&amp;nbsp;Hierarchical Reasoning Model&amp;nbsp;(HRM), is inspired by how the human brain utilizes distinct&lt;/span&gt; systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited.&lt;/p&gt;&lt;p&gt;When faced with a complex problem, current LLMs largely rely on chain-of-thought (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution.&lt;/p&gt;&lt;p&gt;While CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their paper, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language.&lt;/p&gt;



&lt;p&gt;As the researchers note, “A more efficient approach is needed to minimize these data requirements.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-hierarchical-approach-inspired-by-the-brain"&gt;A hierarchical approach inspired by the brain&lt;/h2&gt;



&lt;p&gt;To move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.”&lt;/p&gt;



&lt;p&gt;However, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="hierarchical reasoning model" class="wp-image-3014691" height="508" src="https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png" width="778" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Seeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.”&lt;/p&gt;



&lt;p&gt;Inspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014692" height="202" src="https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;According to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data.&lt;/p&gt;



&lt;p&gt;A natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes yield correct answers with incorrect reasoning steps, and vice versa. “It remains essentially a black box.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014693" height="130" src="https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Example of how HRM reasons over a maze problem across different compute cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-hrm-in-action"&gt;HRM in action&lt;/h2&gt;



&lt;p&gt;To test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the Abstraction and Reasoning Corpus (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks.&lt;/p&gt;



&lt;p&gt;The results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task.&lt;/p&gt;



&lt;p&gt;On the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger o3-mini-high (34.5%) and Claude 3.7 Sonnet (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014694" height="310" src="https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM outperforms large models on complex reasoning tasks Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;While solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained.&lt;/p&gt;



&lt;p&gt;For the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite.&lt;/p&gt;



&lt;p&gt;Looking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Singapore-based AI startup Sapient Intelligence has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient.&lt;/p&gt;&lt;p&gt;The architecture, &lt;span&gt;known as the&amp;nbsp;Hierarchical Reasoning Model&amp;nbsp;(HRM), is inspired by how the human brain utilizes distinct&lt;/span&gt; systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited.&lt;/p&gt;&lt;p&gt;When faced with a complex problem, current LLMs largely rely on chain-of-thought (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution.&lt;/p&gt;&lt;p&gt;While CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their paper, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language.&lt;/p&gt;



&lt;p&gt;As the researchers note, “A more efficient approach is needed to minimize these data requirements.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-hierarchical-approach-inspired-by-the-brain"&gt;A hierarchical approach inspired by the brain&lt;/h2&gt;



&lt;p&gt;To move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.”&lt;/p&gt;



&lt;p&gt;However, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="hierarchical reasoning model" class="wp-image-3014691" height="508" src="https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png" width="778" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Seeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.”&lt;/p&gt;



&lt;p&gt;Inspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014692" height="202" src="https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;According to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data.&lt;/p&gt;



&lt;p&gt;A natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes yield correct answers with incorrect reasoning steps, and vice versa. “It remains essentially a black box.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014693" height="130" src="https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Example of how HRM reasons over a maze problem across different compute cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-hrm-in-action"&gt;HRM in action&lt;/h2&gt;



&lt;p&gt;To test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the Abstraction and Reasoning Corpus (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks.&lt;/p&gt;



&lt;p&gt;The results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task.&lt;/p&gt;



&lt;p&gt;On the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger o3-mini-high (34.5%) and Claude 3.7 Sonnet (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014694" height="310" src="https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM outperforms large models on complex reasoning tasks Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;While solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained.&lt;/p&gt;



&lt;p&gt;For the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite.&lt;/p&gt;



&lt;p&gt;Looking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/</guid><pubDate>Fri, 25 Jul 2025 23:27:42 +0000</pubDate></item><item><title>Meta announces its Superintelligence Labs Chief Scientist: former OpenAI GPT-4 co-creator Shengjia Zhao (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/meta-announces-its-superintelligence-labs-chief-scientist-former-openai-gpt-4-co-creator-shengjia-zhao/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Meta has appointed &lt;strong&gt;Shengjia Zhao&lt;/strong&gt;, a former OpenAI researcher and co‑creator of GPT‑4, as the Chief Scientist of its newly created &lt;strong&gt;Meta Superintelligence Labs (MSL)&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;The announcement was made Friday by Mark Zuckerberg on Threads, noting Zhao will lead the lab’s scientific agenda alongside him and Alexandr Wang, the former CEO of Scale AI who Meta recently brought onboard as Chief AI Officer.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;“I am very excited to take up the role of chief scientist for meta super-intelligence labs. Looking forward to building asi [artificial superintelligence] and aligning it to empower people with the amazing team here. Let’s build!”&lt;/em&gt; Zhao wrote in his own Threads post.&lt;/p&gt;



&lt;p&gt;“Artificial superintelligence” is a nebulous term used in the AI industry to describe systems more powerful and capable than any today, beyond even the smartest humans, making them difficult to control. &lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-zhao-s-strong-commercial-ai-background"&gt;Zhao’s strong commercial AI background&lt;/h2&gt;



&lt;p&gt;Zhao, who previously worked at OpenAI, played a key role in the development of foundational models like GPT-4 and GPT-4o, according to arXiv system cards and research papers listing him as a co-author. He’s also known for his academic work on generative models and fair representations, with widely cited papers in venues like NeurIPS, ICML, and ICLR.&lt;/p&gt;



&lt;p&gt;Zhao joins Meta amid a high-stakes hiring blitz across the AI industry. Over the past few months, Meta has poached researchers from OpenAI, Apple, Google, and Anthropic as part of a multibillion-dollar bet on superintelligence as CNN reported. &lt;/p&gt;



&lt;p&gt;Meta recently invested $14.3 billion in Scale AI, acquiring a 49% stake and bringing on Wang to lead the superintelligence effort. Former GitHub CEO Nat Friedman also joined the team. &lt;/p&gt;



&lt;p&gt;The company has reportedly offered compensation packages worth as much as &lt;strong&gt;$100 million to $300 million over four years&lt;/strong&gt; to lure top AI talent, according to multiple reports. One claim from a rival AI startup founder alleged Meta offered &lt;strong&gt;$1.25 billion over four years&lt;/strong&gt;—approximately &lt;strong&gt;$312 million per year&lt;/strong&gt;—to a single candidate who declined. &lt;/p&gt;



&lt;p&gt;Other insiders say Meta’s most senior AI scientists may be receiving &lt;strong&gt;$10 million+ per year&lt;/strong&gt;, while first-year comp for some new hires reportedly reached &lt;strong&gt;$100 million&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aspirations-of-leading-the-ai-frontier"&gt;Aspirations of leading the AI frontier&lt;/h2&gt;



&lt;p&gt;Zuckerberg has made no secret of his ambition to make Meta a leader in AI’s next frontier, repeatedly stating that the company plans to “invest hundreds of billions of dollars into compute to build superintelligence” using its own business-generated capital. &lt;/p&gt;



&lt;p&gt;He said the Llama 4 rollout underscored the importance of elite talent: “You can have hundreds of thousands of GPUs, but if you don’t have the right team developing the model, it doesn’t matter.”&lt;/p&gt;



&lt;p&gt;Meta’s fundamental AI research group (FAIR), still led by acclaimed scientist Yann LeCun, will remain separate from the new lab. &lt;/p&gt;



&lt;p&gt;The creation of Meta Superintelligence Labs signals a more product- and mission-focused arm of Meta’s AI efforts, centered on building and aligning ASI with human interests.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-up-for-the-mixed-reception-of-llama-4"&gt;Making up for the mixed reception of Llama 4&lt;/h2&gt;



&lt;p&gt;However, Meta’s push into superintelligence has come on the heels of a bumpy rollout of its latest open-source foundation models. &lt;/p&gt;



&lt;p&gt;The company released its Llama 4 model family in April 2025, positioning it as a leap forward in multimodal reasoning and long-context understanding. But the release has struggled to gain traction amid the rise of powerful Chinese open-source rivals like DeepSeek and Qwen. &lt;/p&gt;



&lt;p&gt;Meta faced public criticism from researchers and developers who cited poor real-world performance, confusion around benchmark results, and inconsistent quality across deployments. &lt;/p&gt;



&lt;p&gt;Some accused the company of “benchmark gamesmanship” and using unreleased optimized versions of Llama 4 to boost public perception—a claim Meta has denied. &lt;/p&gt;



&lt;p&gt;Internal sources blamed fast rollout timelines and bugs for the issues, but the episode has cast a shadow over Meta’s generative AI credibility just as it embarks on its most ambitious effort yet. &lt;/p&gt;



&lt;p&gt;Jim Fan, a former Stanford colleague of Zhao and now Nvidia’s Director of Robotics and Distinguished Scientist, offered his endorsement on X: “Shengjia is one of the brightest, humblest, and most passionate scientists I know. Very bullish on MSL!”&lt;/p&gt;



&lt;p&gt;The move underscores Meta’s strategy of spending aggressively now to secure a dominant position in what it views as the next foundational technology platform — one that could eclipse the mobile internet. As Zuckerberg sees it, ASI isn’t a moonshot — it’s the next frontier, and Meta intends to lead.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Meta has appointed &lt;strong&gt;Shengjia Zhao&lt;/strong&gt;, a former OpenAI researcher and co‑creator of GPT‑4, as the Chief Scientist of its newly created &lt;strong&gt;Meta Superintelligence Labs (MSL)&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;The announcement was made Friday by Mark Zuckerberg on Threads, noting Zhao will lead the lab’s scientific agenda alongside him and Alexandr Wang, the former CEO of Scale AI who Meta recently brought onboard as Chief AI Officer.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;“I am very excited to take up the role of chief scientist for meta super-intelligence labs. Looking forward to building asi [artificial superintelligence] and aligning it to empower people with the amazing team here. Let’s build!”&lt;/em&gt; Zhao wrote in his own Threads post.&lt;/p&gt;



&lt;p&gt;“Artificial superintelligence” is a nebulous term used in the AI industry to describe systems more powerful and capable than any today, beyond even the smartest humans, making them difficult to control. &lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-zhao-s-strong-commercial-ai-background"&gt;Zhao’s strong commercial AI background&lt;/h2&gt;



&lt;p&gt;Zhao, who previously worked at OpenAI, played a key role in the development of foundational models like GPT-4 and GPT-4o, according to arXiv system cards and research papers listing him as a co-author. He’s also known for his academic work on generative models and fair representations, with widely cited papers in venues like NeurIPS, ICML, and ICLR.&lt;/p&gt;



&lt;p&gt;Zhao joins Meta amid a high-stakes hiring blitz across the AI industry. Over the past few months, Meta has poached researchers from OpenAI, Apple, Google, and Anthropic as part of a multibillion-dollar bet on superintelligence as CNN reported. &lt;/p&gt;



&lt;p&gt;Meta recently invested $14.3 billion in Scale AI, acquiring a 49% stake and bringing on Wang to lead the superintelligence effort. Former GitHub CEO Nat Friedman also joined the team. &lt;/p&gt;



&lt;p&gt;The company has reportedly offered compensation packages worth as much as &lt;strong&gt;$100 million to $300 million over four years&lt;/strong&gt; to lure top AI talent, according to multiple reports. One claim from a rival AI startup founder alleged Meta offered &lt;strong&gt;$1.25 billion over four years&lt;/strong&gt;—approximately &lt;strong&gt;$312 million per year&lt;/strong&gt;—to a single candidate who declined. &lt;/p&gt;



&lt;p&gt;Other insiders say Meta’s most senior AI scientists may be receiving &lt;strong&gt;$10 million+ per year&lt;/strong&gt;, while first-year comp for some new hires reportedly reached &lt;strong&gt;$100 million&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aspirations-of-leading-the-ai-frontier"&gt;Aspirations of leading the AI frontier&lt;/h2&gt;



&lt;p&gt;Zuckerberg has made no secret of his ambition to make Meta a leader in AI’s next frontier, repeatedly stating that the company plans to “invest hundreds of billions of dollars into compute to build superintelligence” using its own business-generated capital. &lt;/p&gt;



&lt;p&gt;He said the Llama 4 rollout underscored the importance of elite talent: “You can have hundreds of thousands of GPUs, but if you don’t have the right team developing the model, it doesn’t matter.”&lt;/p&gt;



&lt;p&gt;Meta’s fundamental AI research group (FAIR), still led by acclaimed scientist Yann LeCun, will remain separate from the new lab. &lt;/p&gt;



&lt;p&gt;The creation of Meta Superintelligence Labs signals a more product- and mission-focused arm of Meta’s AI efforts, centered on building and aligning ASI with human interests.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-up-for-the-mixed-reception-of-llama-4"&gt;Making up for the mixed reception of Llama 4&lt;/h2&gt;



&lt;p&gt;However, Meta’s push into superintelligence has come on the heels of a bumpy rollout of its latest open-source foundation models. &lt;/p&gt;



&lt;p&gt;The company released its Llama 4 model family in April 2025, positioning it as a leap forward in multimodal reasoning and long-context understanding. But the release has struggled to gain traction amid the rise of powerful Chinese open-source rivals like DeepSeek and Qwen. &lt;/p&gt;



&lt;p&gt;Meta faced public criticism from researchers and developers who cited poor real-world performance, confusion around benchmark results, and inconsistent quality across deployments. &lt;/p&gt;



&lt;p&gt;Some accused the company of “benchmark gamesmanship” and using unreleased optimized versions of Llama 4 to boost public perception—a claim Meta has denied. &lt;/p&gt;



&lt;p&gt;Internal sources blamed fast rollout timelines and bugs for the issues, but the episode has cast a shadow over Meta’s generative AI credibility just as it embarks on its most ambitious effort yet. &lt;/p&gt;



&lt;p&gt;Jim Fan, a former Stanford colleague of Zhao and now Nvidia’s Director of Robotics and Distinguished Scientist, offered his endorsement on X: “Shengjia is one of the brightest, humblest, and most passionate scientists I know. Very bullish on MSL!”&lt;/p&gt;



&lt;p&gt;The move underscores Meta’s strategy of spending aggressively now to secure a dominant position in what it views as the next foundational technology platform — one that could eclipse the mobile internet. As Zuckerberg sees it, ASI isn’t a moonshot — it’s the next frontier, and Meta intends to lead.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/meta-announces-its-superintelligence-labs-chief-scientist-former-openai-gpt-4-co-creator-shengjia-zhao/</guid><pubDate>Sat, 26 Jul 2025 00:58:24 +0000</pubDate></item></channel></rss>