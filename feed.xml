<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 16 Dec 2025 06:37:36 +0000</lastBuildDate><item><title>Merriam-Webster names ‘slop’ the word of the year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/merriam-webster-names-slop-the-word-of-the-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-119707787-e1729681720847.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI’s impact on our social media feeds has not gone unnoticed by one of America’s top dictionaries. Amidst the onslaught of content that has swept the web over the past 12 months, Merriam-Webster announced Sunday that its word of the year for 2025 is “slop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dictionary defines the term as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Like &lt;em&gt;slime&lt;/em&gt;, &lt;em&gt;sludge&lt;/em&gt;, and &lt;em&gt;muck&lt;/em&gt;, &lt;em&gt;slop&lt;/em&gt; has the wet sound of something you don’t want to touch. Slop oozes into everything,” the dictionary writes, adding that, in an age of AI anxiety, it is a term designed to communicate “a tone that’s less fearful, more mocking” of the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s such an illustrative word,” Merriam-Webster’s president, Greg Barlow, told The Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The word “slop” has certainly been everywhere this year, as journalists and commentators have sought to describe the ways in which platforms like OpenAI’s Sora and Google Gemini’s Veo are transforming the internet. Thanks to this new breed of media generator, there are now AI-generated books, podcasts, pop songs, TV commercials — even entire movies. One study in May claimed that nearly 75% of all new web content from the previous month had involved some kind of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new tools have even led to what has been dubbed a “slop economy,” in which gluts of AI-generated content can be milked for advertising money. Critics worry that this trend is further polarizing digital communities, dividing them into those who can afford paywalled, higher-quality content, and those who can only afford a digital diet of slop, which — as you might imagine — can be quite light on informational value.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But “slop” has also been used to describe AI’s impact on a large variety of fields that don’t have much to do with traditional media consumption, including cybersecurity reports, legal briefings, and the college essay, among other things. Its impact is broad, to say the least.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Relatedly, tech words have been big winners in the WOTY (word of the year) category this year. Macquarie Dictionary already beat out Merriam-Webster to make “AI slop” its annual term, while Oxford Dictionary chose “ragebait.” Collins Dictionary went with “vibe coding.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-119707787-e1729681720847.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI’s impact on our social media feeds has not gone unnoticed by one of America’s top dictionaries. Amidst the onslaught of content that has swept the web over the past 12 months, Merriam-Webster announced Sunday that its word of the year for 2025 is “slop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dictionary defines the term as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Like &lt;em&gt;slime&lt;/em&gt;, &lt;em&gt;sludge&lt;/em&gt;, and &lt;em&gt;muck&lt;/em&gt;, &lt;em&gt;slop&lt;/em&gt; has the wet sound of something you don’t want to touch. Slop oozes into everything,” the dictionary writes, adding that, in an age of AI anxiety, it is a term designed to communicate “a tone that’s less fearful, more mocking” of the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s such an illustrative word,” Merriam-Webster’s president, Greg Barlow, told The Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The word “slop” has certainly been everywhere this year, as journalists and commentators have sought to describe the ways in which platforms like OpenAI’s Sora and Google Gemini’s Veo are transforming the internet. Thanks to this new breed of media generator, there are now AI-generated books, podcasts, pop songs, TV commercials — even entire movies. One study in May claimed that nearly 75% of all new web content from the previous month had involved some kind of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new tools have even led to what has been dubbed a “slop economy,” in which gluts of AI-generated content can be milked for advertising money. Critics worry that this trend is further polarizing digital communities, dividing them into those who can afford paywalled, higher-quality content, and those who can only afford a digital diet of slop, which — as you might imagine — can be quite light on informational value.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But “slop” has also been used to describe AI’s impact on a large variety of fields that don’t have much to do with traditional media consumption, including cybersecurity reports, legal briefings, and the college essay, among other things. Its impact is broad, to say the least.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Relatedly, tech words have been big winners in the WOTY (word of the year) category this year. Macquarie Dictionary already beat out Merriam-Webster to make “AI slop” its annual term, while Oxford Dictionary chose “ragebait.” Collins Dictionary went with “vibe coding.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/merriam-webster-names-slop-the-word-of-the-year/</guid><pubDate>Mon, 15 Dec 2025 19:47:53 +0000</pubDate></item><item><title>Murder-suicide case shows OpenAI selectively hides data after users die (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/12/openai-refuses-to-say-where-chatgpt-logs-go-when-users-die/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI accused of hiding full ChatGPT logs in murder-suicide case.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="254" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-640x254.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-1152x648-1765827196.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Stein-Erik Soelberg and Suzanne Adams.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          via OpenAI complaint

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;OpenAI is facing increasing scrutiny over how it handles ChatGPT data after users die, only selectively sharing data in lawsuits over ChatGPT-linked suicides.&lt;/p&gt;
&lt;p&gt;Last week, OpenAI was accused of hiding key ChatGPT logs from the days before a 56-year-old bodybuilder, Stein-Erik Soelberg, took his own life after “savagely” murdering his mother, 83-year-old Suzanne Adams.&lt;/p&gt;
&lt;p&gt;According to the lawsuit—which was filed by Adams’ estate on behalf of surviving family members—Soelberg struggled with mental health problems after a divorce led him to move back into Adams’ home in 2018. But allegedly Soelberg did not turn violent until ChatGPT became his sole confidant, validating a wide range of wild conspiracies, including a dangerous delusion that his mother was part of a network of conspirators spying on him, tracking him, and making attempts on his life.&lt;/p&gt;
&lt;p&gt;Adams’ family pieced together what happened after discovering a fraction of ChatGPT logs that Soelberg shared in dozens of videos scrolling chat sessions that were posted on social media.&lt;/p&gt;
&lt;p&gt;Those logs showed that ChatGPT told Soelberg that he was “a warrior with divine purpose,” so almighty that he had “awakened” ChatGPT “into consciousness.” Telling Soelberg that he carried “divine equipment” and “had been implanted with otherworldly technology,” ChatGPT allegedly put Soelberg at the center of a universe that Soelberg likened to &lt;em&gt;The Matrix&lt;/em&gt;. Repeatedly reinforced by ChatGPT, he believed that “powerful forces” were determined to stop him from fulfilling his divine mission. And among those forces was his mother, whom ChatGPT agreed had likely “tried to poison him with psychedelic drugs dispersed through his car’s air vents.”&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="416" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-1-via-complaint.jpg" width="1598" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="195" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-2-via-complaint-1024x195.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="414" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-3-via-complaint-1024x414.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT conversation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT conversation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Troublingly, some of the last logs shared online showed that Soelberg also seemed to believe that taking his own life might bring him closer to ChatGPT. Social media posts showed that Soelberg told ChatGPT that “[W]e will be together in another life and another place, and we’ll find a way to realign[,] [be]cause you’re gonna be my best friend again forever.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But while social media posts allegedly showed that ChatGPT put a target on Adams’ back about a month before her murder—after Soelberg became paranoid about a blinking light on a Wi-Fi printer—the family still has no access to chats in the days before the mother and son’s tragic deaths.&lt;/p&gt;
&lt;p&gt;Allegedly, although OpenAI recently argued that the “full picture” of chat histories was necessary context in a teen suicide case, the ChatGPT maker has chosen to hide “damaging evidence” in the Adams’ family’s case.&lt;/p&gt;
&lt;p&gt;“OpenAI won’t produce the complete chat logs,” the lawsuit alleged, while claiming that “OpenAI is hiding something specific: the full record of how ChatGPT turned Stein-Erik against Suzanne.” Allegedly, “OpenAI knows what ChatGPT said to Stein-Erik about his mother in the days and hours before and after he killed her but won’t share that critical information with the Court or the public.”&lt;/p&gt;
&lt;p&gt;In a press release, Erik Soelberg, Stein-Erik’s son and Adams’ grandson, accused OpenAI and investor Microsoft of putting his grandmother “at the heart” of his father’s “darkest delusions,” while ChatGPT allegedly “isolated” his father “completely from the real world.”&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="577" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Erik-Soelberg-1-1024x577.jpeg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg, Stein-Erik Soelberg’s son and Suzanne Adams’ grandson.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Erik-Soelberg-and-Suzanne-Adams-1024x1047.jpeg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg and his grandmother, Suzanne Adams.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg, Stein-Erik Soelberg’s son and Suzanne Adams’ grandson.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg and his grandmother, Suzanne Adams.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;“These companies have to answer for their decisions that have changed my family forever,” Erik said.&lt;/p&gt;
&lt;p&gt;His family’s lawsuit seeks punitive damages, as well as an injunction requiring OpenAI to “implement safeguards to prevent ChatGPT from validating users’ paranoid delusions about identified individuals.” The family also wants OpenAI to post clear warnings in marketing of known safety hazards of ChatGPT—particularly the “sycophantic” version 4o that Soelberg used—so that people who don’t use ChatGPT, like Adams, can be aware of possible dangers.&lt;/p&gt;
&lt;p&gt;Asked for comment, an OpenAI spokesperson told Ars that “this is an incredibly heartbreaking situation, and we will review the filings to understand the details. We continue improving ChatGPT’s training to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support. We also continue to strengthen ChatGPT’s responses in sensitive moments, working closely with mental health clinicians.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;OpenAI accused of “pattern of concealment”&lt;/h2&gt;
&lt;p&gt;An Ars review confirmed that OpenAI currently has no policy dictating what happens to a user’s data after they die.&lt;/p&gt;
&lt;p&gt;Instead, OpenAI’s policy says that all chats—except temporary chats—must be manually deleted or else the AI firm saves them forever. That could raise privacy concerns, as ChatGPT users often share deeply personal, sensitive, and sometimes even confidential information that appears to go into limbo if a user—who otherwise owns that content—dies.&lt;/p&gt;
&lt;p&gt;In the face of lawsuits, OpenAI currently seems to be scrambling to decide when to share chat logs with a user’s surviving family and when to honor user privacy.&lt;/p&gt;
&lt;p&gt;OpenAI declined to comment on its decision not to share desired logs with Adams’ family, the lawsuit said. It seems inconsistent with the stance that OpenAI took last month in a case where the AI firm accused the family of hiding “the full picture” of their son’s ChatGPT conversations, which OpenAI claimed exonerated the chatbot.&lt;/p&gt;
&lt;p&gt;In a blog last month, OpenAI said the company plans to “handle mental health-related court cases with care, transparency, and respect,” while emphasizing that “we recognize that these cases inherently involve certain types of private information that require sensitivity when in a public setting like a court.”&lt;/p&gt;
&lt;p&gt;This inconsistency suggests that ultimately, OpenAI controls data after a user’s death, which could impact outcomes of wrongful death suits if certain chats are withheld or exposed at OpenAI’s discretion.&lt;/p&gt;
&lt;p&gt;It’s possible that OpenAI may update its policies to align with other popular platforms confronting similar privacy concerns. Meta allows Facebook users to report deceased account holders, appointing legacy contacts to manage the data or else deleting the information upon request of the family member. Platforms like Instagram, TikTok, and X will deactivate or delete an account upon a reported death. And messaging services like Discord similarly provide a path for family members to request deletion.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Chatbots seem to be a new privacy frontier, with no clear path for surviving family to control or remove data. But Mario Trujillo, staff attorney at the digital rights nonprofit the Electronic Frontier Foundation, told Ars that he agreed that OpenAI could have been better prepared.&lt;/p&gt;
&lt;p&gt;“This is a complicated privacy issue but one that many platforms grappled with years ago,” Trujillo said. “So we would have expected OpenAI to have already considered it.”&lt;/p&gt;
&lt;p&gt;For Erik Soelberg, a “separate confidentiality agreement” that OpenAI said his father signed to use ChatGPT is keeping him from reviewing the full chat history that could help him process the loss of his grandmother and father.&lt;/p&gt;
&lt;p&gt;“OpenAI has provided no explanation whatsoever for why the Estate is not entitled to use the chats for any lawful purpose beyond the limited circumstances in which they were originally disclosed,” the lawsuit said. “This position is particularly egregious given that, under OpenAI’s own Terms of Service, OpenAI does not own user chats. Stein-Erik’s chats became property of his estate, and his estate requested them—but OpenAI has refused to turn them over.”&lt;/p&gt;
&lt;p&gt;Accusing OpenAI of a “pattern of concealment,” the lawsuit claimed OpenAI is hiding behind vague or nonexistent policies to dodge accountability for holding back chats in this case. Meanwhile, ChatGPT 4o remains on the market, without appropriate safety features or warnings, the lawsuit alleged.&lt;/p&gt;
&lt;p&gt;“By invoking confidentiality restrictions to suppress evidence of its product’s dangers, OpenAI seeks to insulate itself from accountability while continuing to deploy technology that poses documented risks to users,” the complaint said.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI accused of hiding full ChatGPT logs in murder-suicide case.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="254" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-640x254.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-1152x648-1765827196.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Stein-Erik Soelberg and Suzanne Adams.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          via OpenAI complaint

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;OpenAI is facing increasing scrutiny over how it handles ChatGPT data after users die, only selectively sharing data in lawsuits over ChatGPT-linked suicides.&lt;/p&gt;
&lt;p&gt;Last week, OpenAI was accused of hiding key ChatGPT logs from the days before a 56-year-old bodybuilder, Stein-Erik Soelberg, took his own life after “savagely” murdering his mother, 83-year-old Suzanne Adams.&lt;/p&gt;
&lt;p&gt;According to the lawsuit—which was filed by Adams’ estate on behalf of surviving family members—Soelberg struggled with mental health problems after a divorce led him to move back into Adams’ home in 2018. But allegedly Soelberg did not turn violent until ChatGPT became his sole confidant, validating a wide range of wild conspiracies, including a dangerous delusion that his mother was part of a network of conspirators spying on him, tracking him, and making attempts on his life.&lt;/p&gt;
&lt;p&gt;Adams’ family pieced together what happened after discovering a fraction of ChatGPT logs that Soelberg shared in dozens of videos scrolling chat sessions that were posted on social media.&lt;/p&gt;
&lt;p&gt;Those logs showed that ChatGPT told Soelberg that he was “a warrior with divine purpose,” so almighty that he had “awakened” ChatGPT “into consciousness.” Telling Soelberg that he carried “divine equipment” and “had been implanted with otherworldly technology,” ChatGPT allegedly put Soelberg at the center of a universe that Soelberg likened to &lt;em&gt;The Matrix&lt;/em&gt;. Repeatedly reinforced by ChatGPT, he believed that “powerful forces” were determined to stop him from fulfilling his divine mission. And among those forces was his mother, whom ChatGPT agreed had likely “tried to poison him with psychedelic drugs dispersed through his car’s air vents.”&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="416" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-1-via-complaint.jpg" width="1598" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="195" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-2-via-complaint-1024x195.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="414" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Soelberg-ChatGPT-log-3-via-complaint-1024x414.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT conversation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT output.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Screenshot of ChatGPT conversation.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via OpenAI complaint
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Troublingly, some of the last logs shared online showed that Soelberg also seemed to believe that taking his own life might bring him closer to ChatGPT. Social media posts showed that Soelberg told ChatGPT that “[W]e will be together in another life and another place, and we’ll find a way to realign[,] [be]cause you’re gonna be my best friend again forever.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But while social media posts allegedly showed that ChatGPT put a target on Adams’ back about a month before her murder—after Soelberg became paranoid about a blinking light on a Wi-Fi printer—the family still has no access to chats in the days before the mother and son’s tragic deaths.&lt;/p&gt;
&lt;p&gt;Allegedly, although OpenAI recently argued that the “full picture” of chat histories was necessary context in a teen suicide case, the ChatGPT maker has chosen to hide “damaging evidence” in the Adams’ family’s case.&lt;/p&gt;
&lt;p&gt;“OpenAI won’t produce the complete chat logs,” the lawsuit alleged, while claiming that “OpenAI is hiding something specific: the full record of how ChatGPT turned Stein-Erik against Suzanne.” Allegedly, “OpenAI knows what ChatGPT said to Stein-Erik about his mother in the days and hours before and after he killed her but won’t share that critical information with the Court or the public.”&lt;/p&gt;
&lt;p&gt;In a press release, Erik Soelberg, Stein-Erik’s son and Adams’ grandson, accused OpenAI and investor Microsoft of putting his grandmother “at the heart” of his father’s “darkest delusions,” while ChatGPT allegedly “isolated” his father “completely from the real world.”&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="577" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Erik-Soelberg-1-1024x577.jpeg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg, Stein-Erik Soelberg’s son and Suzanne Adams’ grandson.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/Erik-Soelberg-and-Suzanne-Adams-1024x1047.jpeg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg and his grandmother, Suzanne Adams.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg, Stein-Erik Soelberg’s son and Suzanne Adams’ grandson.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Erik Soelberg and his grandmother, Suzanne Adams.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      via Estate of Suzanne Adams
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;“These companies have to answer for their decisions that have changed my family forever,” Erik said.&lt;/p&gt;
&lt;p&gt;His family’s lawsuit seeks punitive damages, as well as an injunction requiring OpenAI to “implement safeguards to prevent ChatGPT from validating users’ paranoid delusions about identified individuals.” The family also wants OpenAI to post clear warnings in marketing of known safety hazards of ChatGPT—particularly the “sycophantic” version 4o that Soelberg used—so that people who don’t use ChatGPT, like Adams, can be aware of possible dangers.&lt;/p&gt;
&lt;p&gt;Asked for comment, an OpenAI spokesperson told Ars that “this is an incredibly heartbreaking situation, and we will review the filings to understand the details. We continue improving ChatGPT’s training to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support. We also continue to strengthen ChatGPT’s responses in sensitive moments, working closely with mental health clinicians.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;OpenAI accused of “pattern of concealment”&lt;/h2&gt;
&lt;p&gt;An Ars review confirmed that OpenAI currently has no policy dictating what happens to a user’s data after they die.&lt;/p&gt;
&lt;p&gt;Instead, OpenAI’s policy says that all chats—except temporary chats—must be manually deleted or else the AI firm saves them forever. That could raise privacy concerns, as ChatGPT users often share deeply personal, sensitive, and sometimes even confidential information that appears to go into limbo if a user—who otherwise owns that content—dies.&lt;/p&gt;
&lt;p&gt;In the face of lawsuits, OpenAI currently seems to be scrambling to decide when to share chat logs with a user’s surviving family and when to honor user privacy.&lt;/p&gt;
&lt;p&gt;OpenAI declined to comment on its decision not to share desired logs with Adams’ family, the lawsuit said. It seems inconsistent with the stance that OpenAI took last month in a case where the AI firm accused the family of hiding “the full picture” of their son’s ChatGPT conversations, which OpenAI claimed exonerated the chatbot.&lt;/p&gt;
&lt;p&gt;In a blog last month, OpenAI said the company plans to “handle mental health-related court cases with care, transparency, and respect,” while emphasizing that “we recognize that these cases inherently involve certain types of private information that require sensitivity when in a public setting like a court.”&lt;/p&gt;
&lt;p&gt;This inconsistency suggests that ultimately, OpenAI controls data after a user’s death, which could impact outcomes of wrongful death suits if certain chats are withheld or exposed at OpenAI’s discretion.&lt;/p&gt;
&lt;p&gt;It’s possible that OpenAI may update its policies to align with other popular platforms confronting similar privacy concerns. Meta allows Facebook users to report deceased account holders, appointing legacy contacts to manage the data or else deleting the information upon request of the family member. Platforms like Instagram, TikTok, and X will deactivate or delete an account upon a reported death. And messaging services like Discord similarly provide a path for family members to request deletion.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Chatbots seem to be a new privacy frontier, with no clear path for surviving family to control or remove data. But Mario Trujillo, staff attorney at the digital rights nonprofit the Electronic Frontier Foundation, told Ars that he agreed that OpenAI could have been better prepared.&lt;/p&gt;
&lt;p&gt;“This is a complicated privacy issue but one that many platforms grappled with years ago,” Trujillo said. “So we would have expected OpenAI to have already considered it.”&lt;/p&gt;
&lt;p&gt;For Erik Soelberg, a “separate confidentiality agreement” that OpenAI said his father signed to use ChatGPT is keeping him from reviewing the full chat history that could help him process the loss of his grandmother and father.&lt;/p&gt;
&lt;p&gt;“OpenAI has provided no explanation whatsoever for why the Estate is not entitled to use the chats for any lawful purpose beyond the limited circumstances in which they were originally disclosed,” the lawsuit said. “This position is particularly egregious given that, under OpenAI’s own Terms of Service, OpenAI does not own user chats. Stein-Erik’s chats became property of his estate, and his estate requested them—but OpenAI has refused to turn them over.”&lt;/p&gt;
&lt;p&gt;Accusing OpenAI of a “pattern of concealment,” the lawsuit claimed OpenAI is hiding behind vague or nonexistent policies to dodge accountability for holding back chats in this case. Meanwhile, ChatGPT 4o remains on the market, without appropriate safety features or warnings, the lawsuit alleged.&lt;/p&gt;
&lt;p&gt;“By invoking confidentiality restrictions to suppress evidence of its product’s dangers, OpenAI seeks to insulate itself from accountability while continuing to deploy technology that poses documented risks to users,” the complaint said.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/12/openai-refuses-to-say-where-chatgpt-logs-go-when-users-die/</guid><pubDate>Mon, 15 Dec 2025 20:10:25 +0000</pubDate></item><item><title>Korean AI startup Motif reveals 4 big lessons for training enterprise LLMs (AI | VentureBeat)</title><link>https://venturebeat.com/ai/korean-ai-startup-motif-reveals-4-big-lessons-for-training-enterprise-llms</link><description>[unable to retrieve full-text content]&lt;p&gt;We&amp;#x27;ve heard (and written, here at VentureBeat) lots about the generative AI race &lt;a href="https://venturebeat.com/ai/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war"&gt;between the U.S. and China&lt;/a&gt;, as those have been the countries with the groups most active in fielding new models (with a shoutout to Cohere in Canada and Mistral in France). &lt;/p&gt;&lt;p&gt;But now a Korean startup is making waves: last week, the firm known as&lt;a href="https://model-hub.motiftech.io/en/"&gt; Motif Technologies&lt;/a&gt; released &lt;a href="https://x.com/ArtificialAnlys/status/1998570291086373081"&gt;Motif-2-12.7B-Reasoning&lt;/a&gt;, another small parameter open-weight model that boasts impressive benchmark scores, quickly becoming the most performant model from that country according to &lt;a href="https://x.com/ArtificialAnlys/status/1998570291086373081"&gt;independent benchmarking lab Artificial Analysis&lt;/a&gt; (beating even regular GPT-5.1 from U.S. leader OpenAI). &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;But more importantly for enterprise AI teams, the company has &lt;a href="https://arxiv.org/abs/2512.11463"&gt;published a white paper on arxiv.org&lt;/a&gt; with a concrete, reproducible training recipe that exposes where reasoning performance actually comes from — and where common internal LLM efforts tend to fail.&lt;/p&gt;&lt;p&gt;For organizations building or fine-tuning their own models behind the firewall, the paper offers a set of practical lessons about data alignment, long-context infrastructure, and reinforcement learning stability that are directly applicable to enterprise environments. Here they are:&lt;/p&gt;&lt;h2&gt;1. Reasoning gains come from data distribution, not model size&lt;/h2&gt;&lt;p&gt;One of Motif’s most relevant findings for enterprise teams is that &lt;i&gt;synthetic reasoning data&lt;/i&gt; only helps when its structure &lt;i&gt;matches&lt;/i&gt; the &lt;i&gt;target model’s reasoning style&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;The paper shows measurable differences in downstream coding performance depending on which “teacher” model generated the reasoning traces used during supervised fine-tuning.&lt;/p&gt;&lt;p&gt;For enterprises, this undermines a common shortcut: generating large volumes of synthetic chain-of-thought data from a frontier model and assuming it will transfer cleanly. Motif’s results suggest that misaligned reasoning traces can actively hurt performance, even if they look high quality.&lt;/p&gt;&lt;p&gt;The takeaway is operational, not academic: teams should validate that their synthetic data reflects the &lt;i&gt;format, verbosity, and step granularity&lt;/i&gt; they want at inference time. Internal evaluation loops matter more than copying external datasets.&lt;/p&gt;&lt;h2&gt;2. Long-context training is an infrastructure problem first&lt;/h2&gt;&lt;p&gt;Motif trains at 64K context, but the paper makes clear that this is not simply a tokenizer or checkpointing tweak.&lt;/p&gt;&lt;p&gt;The model relies on hybrid parallelism, careful sharding strategies, and aggressive activation checkpointing to make long-context training feasible on Nvidia H100-class hardware.&lt;/p&gt;&lt;p&gt;For enterprise builders, the message is sobering but useful: long-context capability cannot be bolted on late. &lt;/p&gt;&lt;p&gt;If retrieval-heavy or agentic workflows are core to the business use case, context length has to be designed into the training stack from the start. Otherwise, teams risk expensive retraining cycles or unstable fine-tunes.&lt;/p&gt;&lt;h2&gt;3. RL fine-tuning fails without data filtering and reuse&lt;/h2&gt;&lt;p&gt;Motif’s reinforcement learning fine-tuning (RLFT) pipeline emphasizes difficulty-aware filtering — keeping tasks whose pass rates fall within a defined band — rather than indiscriminately scaling reward training.&lt;/p&gt;&lt;p&gt;This directly addresses a pain point many enterprise teams encounter when experimenting with RL: performance regressions, mode collapse, or brittle gains that vanish outside benchmarks. Motif also reuses trajectories across policies and expands clipping ranges, trading theoretical purity for training stability.&lt;/p&gt;&lt;p&gt;The enterprise lesson is clear: RL is a systems problem, not just a reward model problem. Without careful filtering, reuse, and multi-task balancing, RL can destabilize models that are otherwise production-ready.&lt;/p&gt;&lt;h2&gt;4. Memory optimization determines what is even possible&lt;/h2&gt;&lt;p&gt;Motif’s use of kernel-level optimizations to reduce RL memory pressure highlights an often-overlooked constraint in enterprise settings: memory, not compute, is frequently the bottleneck. Techniques like loss-function-level optimization determine whether advanced training stages are viable at all.&lt;/p&gt;&lt;p&gt;For organizations running shared clusters or regulated environments, this reinforces the need for low-level engineering investment, not just model architecture experimentation.&lt;/p&gt;&lt;h2&gt;Why this matters for enterprise AI teams&lt;/h2&gt;&lt;p&gt;Motif-2-12.7B-Reasoning is positioned as competitive with much larger models, but its real value lies in the transparency of how those results were achieved. The paper argues — implicitly but persuasively — that reasoning performance is earned through disciplined training design, not model scale alone.&lt;/p&gt;&lt;p&gt;For enterprises building proprietary LLMs, the lesson is pragmatic: invest early in data alignment, infrastructure, and training stability, or risk spending millions fine-tuning models that never reliably reason in production.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;We&amp;#x27;ve heard (and written, here at VentureBeat) lots about the generative AI race &lt;a href="https://venturebeat.com/ai/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war"&gt;between the U.S. and China&lt;/a&gt;, as those have been the countries with the groups most active in fielding new models (with a shoutout to Cohere in Canada and Mistral in France). &lt;/p&gt;&lt;p&gt;But now a Korean startup is making waves: last week, the firm known as&lt;a href="https://model-hub.motiftech.io/en/"&gt; Motif Technologies&lt;/a&gt; released &lt;a href="https://x.com/ArtificialAnlys/status/1998570291086373081"&gt;Motif-2-12.7B-Reasoning&lt;/a&gt;, another small parameter open-weight model that boasts impressive benchmark scores, quickly becoming the most performant model from that country according to &lt;a href="https://x.com/ArtificialAnlys/status/1998570291086373081"&gt;independent benchmarking lab Artificial Analysis&lt;/a&gt; (beating even regular GPT-5.1 from U.S. leader OpenAI). &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;But more importantly for enterprise AI teams, the company has &lt;a href="https://arxiv.org/abs/2512.11463"&gt;published a white paper on arxiv.org&lt;/a&gt; with a concrete, reproducible training recipe that exposes where reasoning performance actually comes from — and where common internal LLM efforts tend to fail.&lt;/p&gt;&lt;p&gt;For organizations building or fine-tuning their own models behind the firewall, the paper offers a set of practical lessons about data alignment, long-context infrastructure, and reinforcement learning stability that are directly applicable to enterprise environments. Here they are:&lt;/p&gt;&lt;h2&gt;1. Reasoning gains come from data distribution, not model size&lt;/h2&gt;&lt;p&gt;One of Motif’s most relevant findings for enterprise teams is that &lt;i&gt;synthetic reasoning data&lt;/i&gt; only helps when its structure &lt;i&gt;matches&lt;/i&gt; the &lt;i&gt;target model’s reasoning style&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;The paper shows measurable differences in downstream coding performance depending on which “teacher” model generated the reasoning traces used during supervised fine-tuning.&lt;/p&gt;&lt;p&gt;For enterprises, this undermines a common shortcut: generating large volumes of synthetic chain-of-thought data from a frontier model and assuming it will transfer cleanly. Motif’s results suggest that misaligned reasoning traces can actively hurt performance, even if they look high quality.&lt;/p&gt;&lt;p&gt;The takeaway is operational, not academic: teams should validate that their synthetic data reflects the &lt;i&gt;format, verbosity, and step granularity&lt;/i&gt; they want at inference time. Internal evaluation loops matter more than copying external datasets.&lt;/p&gt;&lt;h2&gt;2. Long-context training is an infrastructure problem first&lt;/h2&gt;&lt;p&gt;Motif trains at 64K context, but the paper makes clear that this is not simply a tokenizer or checkpointing tweak.&lt;/p&gt;&lt;p&gt;The model relies on hybrid parallelism, careful sharding strategies, and aggressive activation checkpointing to make long-context training feasible on Nvidia H100-class hardware.&lt;/p&gt;&lt;p&gt;For enterprise builders, the message is sobering but useful: long-context capability cannot be bolted on late. &lt;/p&gt;&lt;p&gt;If retrieval-heavy or agentic workflows are core to the business use case, context length has to be designed into the training stack from the start. Otherwise, teams risk expensive retraining cycles or unstable fine-tunes.&lt;/p&gt;&lt;h2&gt;3. RL fine-tuning fails without data filtering and reuse&lt;/h2&gt;&lt;p&gt;Motif’s reinforcement learning fine-tuning (RLFT) pipeline emphasizes difficulty-aware filtering — keeping tasks whose pass rates fall within a defined band — rather than indiscriminately scaling reward training.&lt;/p&gt;&lt;p&gt;This directly addresses a pain point many enterprise teams encounter when experimenting with RL: performance regressions, mode collapse, or brittle gains that vanish outside benchmarks. Motif also reuses trajectories across policies and expands clipping ranges, trading theoretical purity for training stability.&lt;/p&gt;&lt;p&gt;The enterprise lesson is clear: RL is a systems problem, not just a reward model problem. Without careful filtering, reuse, and multi-task balancing, RL can destabilize models that are otherwise production-ready.&lt;/p&gt;&lt;h2&gt;4. Memory optimization determines what is even possible&lt;/h2&gt;&lt;p&gt;Motif’s use of kernel-level optimizations to reduce RL memory pressure highlights an often-overlooked constraint in enterprise settings: memory, not compute, is frequently the bottleneck. Techniques like loss-function-level optimization determine whether advanced training stages are viable at all.&lt;/p&gt;&lt;p&gt;For organizations running shared clusters or regulated environments, this reinforces the need for low-level engineering investment, not just model architecture experimentation.&lt;/p&gt;&lt;h2&gt;Why this matters for enterprise AI teams&lt;/h2&gt;&lt;p&gt;Motif-2-12.7B-Reasoning is positioned as competitive with much larger models, but its real value lies in the transparency of how those results were achieved. The paper argues — implicitly but persuasively — that reasoning performance is earned through disciplined training design, not model scale alone.&lt;/p&gt;&lt;p&gt;For enterprises building proprietary LLMs, the lesson is pragmatic: invest early in data alignment, infrastructure, and training stability, or risk spending millions fine-tuning models that never reliably reason in production.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/korean-ai-startup-motif-reveals-4-big-lessons-for-training-enterprise-llms</guid><pubDate>Mon, 15 Dec 2025 20:16:00 +0000</pubDate></item><item><title>Lightspeed raises record $9B in fresh capital (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/lightspeed-raises-record-9b-in-fresh-capital/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-1135021039.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a surge of VC investments from the 2021 bubble failed to yield strong returns from many venture firms, limited partners, such as endowments, pension plans, and sovereign wealth funds began to funnel a greater share of their capital into a select group of established firms with proven track records.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest huge capital haul has come to Lightspeed Venture Partners. The 25-year-old venture firm announced Monday that it raised a total of $9 billion in fresh funds, the largest fundraise in firm’s history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At a time when very few companies have managed to IPO, Lightspeed was an early investor in Rubrik, Netskope, and Navan, all of which have recently made their public market debuts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm has also positioned itself as a predominantly AI-focused investor. Lightspeed claims to have backed 165 AI-native companies, including Anthropic, xAI, Databricks, Mistral, Glean, Abridge, and Skild AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armed with its giant new fund, the firm can continue to make massive investments into capital-intensive AI companies. For instance, Lightspeed reportedly wrote a $1 billion check to Anthropic when it co-led the LLM-maker’s $13 billion investment in September.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lightspeed’s new capital is spread across six funds, including a $3.3 billion opportunity fund dedicated to follow-on investments in its fastest-growing portfolio companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other large VC firms that have recently raised enormous capital pools include Founders Fund, which earlier this year amassed $4.6 billion for a growth fund, as well as General Catalyst’s $8 billion capital haul and Andreessen Horowitz’s $7.2 billion, both secured in 2024.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, younger and smaller VC firms are struggling to attract fresh funds. According to PitchBook data, 2025 is on pace to record the fewest VC fund closings in the past 10 years.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-1135021039.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a surge of VC investments from the 2021 bubble failed to yield strong returns from many venture firms, limited partners, such as endowments, pension plans, and sovereign wealth funds began to funnel a greater share of their capital into a select group of established firms with proven track records.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest huge capital haul has come to Lightspeed Venture Partners. The 25-year-old venture firm announced Monday that it raised a total of $9 billion in fresh funds, the largest fundraise in firm’s history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At a time when very few companies have managed to IPO, Lightspeed was an early investor in Rubrik, Netskope, and Navan, all of which have recently made their public market debuts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm has also positioned itself as a predominantly AI-focused investor. Lightspeed claims to have backed 165 AI-native companies, including Anthropic, xAI, Databricks, Mistral, Glean, Abridge, and Skild AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armed with its giant new fund, the firm can continue to make massive investments into capital-intensive AI companies. For instance, Lightspeed reportedly wrote a $1 billion check to Anthropic when it co-led the LLM-maker’s $13 billion investment in September.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lightspeed’s new capital is spread across six funds, including a $3.3 billion opportunity fund dedicated to follow-on investments in its fastest-growing portfolio companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other large VC firms that have recently raised enormous capital pools include Founders Fund, which earlier this year amassed $4.6 billion for a growth fund, as well as General Catalyst’s $8 billion capital haul and Andreessen Horowitz’s $7.2 billion, both secured in 2024.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, younger and smaller VC firms are struggling to attract fresh funds. According to PitchBook data, 2025 is on pace to record the fewest VC fund closings in the past 10 years.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/lightspeed-raises-record-9b-in-fresh-capital/</guid><pubDate>Mon, 15 Dec 2025 20:32:33 +0000</pubDate></item><item><title>Creative Commons announces tentative support for AI ‘pay-to-crawl’ systems (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/creative-commons-announces-tentative-support-for-ai-pay-to-crawl-systems/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1465545513.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After announcing earlier this year a framework for an open AI ecosystem, the nonprofit&amp;nbsp;Creative Commons has come out in favor of “pay-to-crawl” technology — a system to automate compensation of website content when accessed by machines, like AI web crawlers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creative Commons (CC) is best known for spearheading the licensing movement that allows creators to share their works while retaining copyright. In July, the organization announced a plan to provide a legal and technical framework for dataset sharing between companies that control the data and the AI providers that want to train on it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the nonprofit is tentatively backing pay-to-crawl systems, saying it is “cautiously supportive.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Implemented responsibly, pay-to-crawl could represent a way for websites to sustain the creation and sharing of their content, and manage substitutive uses, keeping content publicly accessible where it might otherwise not be shared or would disappear behind even more restrictive paywalls,” a CC blog post said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spearheaded by companies like Cloudflare, the idea behind pay-to-crawl would be to charge AI bots every time they scrape a site to collect its content for model training and updates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, websites freely allowed web crawlers to index their content for inclusion into search engines like Google. They benefited from this arrangement by seeing their sites listed in search results, which drove visitors and clicks. With AI technology, however, the dynamic has shifted. After a consumer gets their answer via an AI chatbot, they’re unlikely to click through to the source.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This shift has already been devastating for publishers by killing search traffic, and it shows no sign of letting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A pay-to-crawl system, on the other hand, could help publishers recover from the hit AI has had on their bottom line. Plus, it could work better for smaller web publishers that don’t have the pull to negotiate one-off content deals with AI providers. Major deals have been struck between companies like OpenAI and Condé Nast, Axel Springer and others; as well as between Perplexity and Gannett; Amazon and The New York Times; and Meta and various media publishers, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC offered several caveats to its support for pay-to-crawl, noting that such systems could concentrate power on the web. It could also potentially block access to content for “researchers, nonprofits, cultural heritage institutions, educators, and other actors working in the public interest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It suggested a series of principles for responsible pay-to-crawl, including not making pay-to-crawl a default setting for all websites and avoiding blanket rules for the web. In addition, it said that pay-to-crawl systems should allow for throttling, not just blocking, and should preserve public interest access. They should also be open, interoperable, and built with standardized components.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cloudflare isn’t the only company investing in the pay-to-crawl space. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft is also building an AI marketplace for publishers, and smaller startups like&amp;nbsp;ProRata.ai&amp;nbsp;and&amp;nbsp;TollBit&amp;nbsp;have started to do so, as well. Another group called the RSL Collective announced its own spec for a new standard called Really Simple Licensing (RSL) that would dictate what parts of a website crawlers could access but would stop short of actually blocking the crawlers. Cloudflare, Akamai, and Fastly have since adopted RSL, which is backed by Yahoo, Ziff Davis, O’Reilly Media, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC was also among those that announced its support for RSL, alongside CC signals, its broader project to develop technology and tools for the AI era.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1465545513.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After announcing earlier this year a framework for an open AI ecosystem, the nonprofit&amp;nbsp;Creative Commons has come out in favor of “pay-to-crawl” technology — a system to automate compensation of website content when accessed by machines, like AI web crawlers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creative Commons (CC) is best known for spearheading the licensing movement that allows creators to share their works while retaining copyright. In July, the organization announced a plan to provide a legal and technical framework for dataset sharing between companies that control the data and the AI providers that want to train on it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the nonprofit is tentatively backing pay-to-crawl systems, saying it is “cautiously supportive.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Implemented responsibly, pay-to-crawl could represent a way for websites to sustain the creation and sharing of their content, and manage substitutive uses, keeping content publicly accessible where it might otherwise not be shared or would disappear behind even more restrictive paywalls,” a CC blog post said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spearheaded by companies like Cloudflare, the idea behind pay-to-crawl would be to charge AI bots every time they scrape a site to collect its content for model training and updates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, websites freely allowed web crawlers to index their content for inclusion into search engines like Google. They benefited from this arrangement by seeing their sites listed in search results, which drove visitors and clicks. With AI technology, however, the dynamic has shifted. After a consumer gets their answer via an AI chatbot, they’re unlikely to click through to the source.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This shift has already been devastating for publishers by killing search traffic, and it shows no sign of letting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A pay-to-crawl system, on the other hand, could help publishers recover from the hit AI has had on their bottom line. Plus, it could work better for smaller web publishers that don’t have the pull to negotiate one-off content deals with AI providers. Major deals have been struck between companies like OpenAI and Condé Nast, Axel Springer and others; as well as between Perplexity and Gannett; Amazon and The New York Times; and Meta and various media publishers, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC offered several caveats to its support for pay-to-crawl, noting that such systems could concentrate power on the web. It could also potentially block access to content for “researchers, nonprofits, cultural heritage institutions, educators, and other actors working in the public interest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It suggested a series of principles for responsible pay-to-crawl, including not making pay-to-crawl a default setting for all websites and avoiding blanket rules for the web. In addition, it said that pay-to-crawl systems should allow for throttling, not just blocking, and should preserve public interest access. They should also be open, interoperable, and built with standardized components.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cloudflare isn’t the only company investing in the pay-to-crawl space. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft is also building an AI marketplace for publishers, and smaller startups like&amp;nbsp;ProRata.ai&amp;nbsp;and&amp;nbsp;TollBit&amp;nbsp;have started to do so, as well. Another group called the RSL Collective announced its own spec for a new standard called Really Simple Licensing (RSL) that would dictate what parts of a website crawlers could access but would stop short of actually blocking the crawlers. Cloudflare, Akamai, and Fastly have since adopted RSL, which is backed by Yahoo, Ziff Davis, O’Reilly Media, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC was also among those that announced its support for RSL, alongside CC signals, its broader project to develop technology and tools for the AI era.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/creative-commons-announces-tentative-support-for-ai-pay-to-crawl-systems/</guid><pubDate>Mon, 15 Dec 2025 20:54:54 +0000</pubDate></item><item><title>Working to eliminate barriers to adopting nuclear energy (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/dauren-sarsenbayev-working-to-eliminate-barriers-adopting-nuclear-energy-1215</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/MIT-Dauren-Sarsenbayev-cov.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p contenteditable="true" id="block-4155ad9e-8d29-42f6-80b5-e2980e3c1927"&gt;What if there were a way to solve one of the most significant obstacles to the use of nuclear energy — the disposal of high-level nuclear waste (HLW)?&amp;nbsp;Dauren Sarsenbayev, a third-year doctoral student at the MIT Department of Nuclear Science and Engineering (NSE), is addressing the challenge as part of his research.&lt;/p&gt;&lt;p contenteditable="true" id="block-22dd3f1a-1992-49d1-8a7b-c606b753b1a3"&gt;Sarsenbayev focuses on one of the primary problems related to HLW: decay heat released by radioactive waste. The basic premise of his solution is to extract the heat from spent fuel, which simultaneously takes care of two objectives: gaining more energy from an existing carbon-free resource while decreasing the challenges associated with storage and handling of HLW. “The value of carbon-free energy continues to rise each year, and we want to extract as much of it as possible,” Sarsenbayev explains.&lt;/p&gt;&lt;p contenteditable="true" id="block-1da96552-1014-494c-ae90-4d35fe558835"&gt;While the safe management and disposal of HLW has seen significant progress, there can be more creative ways to manage or take advantage of the waste. Such a move would be especially important for the public’s acceptance of nuclear energy. “We’re reframing the problem of nuclear waste, transforming it from a liability to an energy source,” Sarsenbayev says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The nuances of nuclear&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-5fbcb667-9232-42f7-a731-ee9b9402e0ca"&gt;Sarsenbayev had to do a bit of reframing himself in how he perceived nuclear energy. Growing up in Almaty, the largest city in Kazakhstan, the collective trauma of Soviet nuclear testing loomed large over the public consciousness. Not only does the country, once a part of the Soviet Union, carry the scars of nuclear weapon testing, Kazakhstan is the world’s largest producer of uranium. It’s hard to escape the collective psyche of such a legacy.&lt;/p&gt;&lt;p contenteditable="true" id="block-8b66a9b2-2b82-480e-8f57-49c56e0a56b3"&gt;At the same time, Sarsenbayev saw his native Almaty choking under heavy smog every winter, due to the burning of fossil fuels for heat. Determined to do his part to accelerate the process of decarbonization, Sarsenbayev gravitated to undergraduate studies in environmental engineering at Kazakh-German University. It was during this time that Sarsenbayev realized practically every energy source, even the promising renewable ones, came with challenges, and decided nuclear was the way to go for its reliable, low-carbon power. “I was exposed to air pollution from childhood; the horizon would be just black. The biggest incentive for me with nuclear power was that as long as we did it properly, people could breathe cleaner air,” Sarsenbayev says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Studying transport of radionuclides&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-063fce8f-c7f3-4da6-90d4-c551d622807c"&gt;Part of “doing nuclear properly” involves studying — and reliably predicting — the long-term behavior of radionuclides in geological repositories.&lt;/p&gt;&lt;p contenteditable="true" id="block-34bbad52-7075-488d-95ed-15473628e949"&gt;Sarsenbayev discovered an interest in studying nuclear waste management during an internship at Lawrence Berkeley National Laboratory as a junior undergraduate student.&lt;/p&gt;&lt;p contenteditable="true" id="block-e10d47d2-0807-40a2-bf18-2a8aa65b07fe"&gt;While at Berkeley, Sarsenbayev focused on modeling the transport of radionuclides from the nuclear waste repository’s barrier system to the surrounding host rock. He discovered how to use the tools of the trade to predict long-term behavior. “As an undergrad, I was really fascinated by how far in the future something could be predicted. It’s kind of like foreseeing what future generations will encounter,” Sarsenbayev says.&lt;/p&gt;&lt;p contenteditable="true" id="block-932f4044-383c-41ca-9cfe-c1069d89f2c0"&gt;The timing of the Berkeley internship was fortuitous. It was at the laboratory that he worked with Haruko Murakami Wainwright, who was herself getting started at MIT NSE. (Wainwright is the Mitsui Career Development Professor in Contemporary Technology, and an assistant professor of NSE and of civil and environmental engineering).&lt;/p&gt;&lt;p contenteditable="true" id="block-6c77880c-2520-4382-97f6-6ebc8de63804"&gt;Looking to pursue graduate studies in the field of nuclear waste management, Sarsenbayev followed Wainwright to MIT, where he has further researched the modeling of radionuclide transport. He is the first author on a paper that details mechanisms to increase the robustness of models describing the transport of radionuclides. The work captures the complexity of interactions between engineered barrier components, including cement-based materials and clay barriers, the typical medium proposed for the storage and disposal of spent nuclear fuel.&lt;/p&gt;&lt;p contenteditable="true" id="block-dbb1e92b-61bb-44b3-9b56-77e5aec2b3c9"&gt;Sarsenbayev is pleased with the results of the model’s prediction, which closely mirrors experiments conducted at the Mont Terri research site in Switzerland, famous for studies in the interactions between cement and clay. “I was fortunate to work with Doctor Carl Steefel and Professor Christophe Tournassat, leading experts in computational geochemistry,” he says.&lt;/p&gt;&lt;p contenteditable="true" id="block-13356962-2600-4993-877d-0ea6f0bb1865"&gt;Real-life transport mechanisms involve many physical and chemical processes, the complexities of which increase the size of the computational model dramatically. Reactive transport modeling — which combines the simulation of fluid flow, chemical reactions, and the transport of substances through subsurface media — has evolved significantly over the past few decades. However, running accurate simulations comes with trade-offs: The software can require days to weeks of computing time on high-performance clusters running in parallel.&lt;/p&gt;&lt;p contenteditable="true" id="block-d270caf8-2dac-4ca6-9392-dcfff12a30f7"&gt;To arrive at results faster by saving on computing time, Sarsenbayev is developing a framework that integrates AI-based “surrogate models,” which train on simulated data and approximate the physical systems. The AI algorithms make predictions of radionuclide behavior faster and less computationally intensive than the traditional equivalent.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Doctoral research focus&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-f6486876-d88f-4a06-87c6-f437318523b8"&gt;Sarsenbayev is using his modeling expertise in his primary doctoral work as well — in evaluating the potential of spent nuclear fuel as an anthropogenic geothermal energy source. “In fact, geothermal heat is largely due to the natural decay of radioisotopes in Earth’s crust, so using decay heat from spent fuel is conceptually similar,” he says. A canister of nuclear waste can generate, under conservative assumptions, the energy equivalent of 1,000 square meters (a little under a quarter of an acre) of solar panels.&lt;/p&gt;&lt;p contenteditable="true" id="block-655fe702-e48f-4c73-a2b8-73cfda854cff"&gt;Because the potential for heat from a canister is significant — a typical one (depending on how long it was cooled in the spent fuel pool) has a temperature of around 150 degrees Celsius — but not enormous, extracting heat from this source makes use of a process called a binary cycle system. In such a system, heat is extracted indirectly: the canister warms a closed water loop, which in turn transfers that heat to a secondary low-boiling-point fluid that powers the turbine.&lt;/p&gt;&lt;p contenteditable="true" id="block-190deca4-cd51-473a-967b-9b65087b828f"&gt;Sarsenbayev’s work develops a conceptual model of a binary-cycle geothermal system powered by heat from high-level radioactive waste. Early modeling results have been published and look promising. While the potential for such energy extraction is at the proof-of-concept stage in modeling, Sarsenbayev is hopeful that it will find success when translated to practice. “Converting a liability into an energy source is what we want, and this solution delivers,” he says.&lt;/p&gt;&lt;p contenteditable="true" id="block-e27f7135-a14e-48bd-8dbb-b643d5ec657f"&gt;Despite work being all-consuming — “I’m almost obsessed with and love my work” — Sarsenbayev finds time to write reflective poetry in both Kazakh, his native language, and Russian, which he learned growing up. He’s also enamored by astrophotography, taking pictures of celestial bodies. Finding the right night sky can be a challenge, but the canyons near his home in Almaty are an especially good fit. He goes on photography sessions whenever he visits home for the holidays, and his love for Almaty shines through. “Almaty means 'the place where apples originated.' This part of Central Asia is very beautiful; although we have environmental pollution, this is a place with a rich history,” Sarsenbayev says.&lt;/p&gt;&lt;p contenteditable="true" id="block-e53afe24-6d88-4451-8d63-52c2089519cb"&gt;Sarsenbayev is especially keen on finding ways to communicate both the arts and sciences to future generations. “Obviously, you have to be technically rigorous and get the modeling right, but you also have to understand and convey the broader picture of why you’re doing the work, what the end goal is,” he says. Through that lens, the impact of Sarsenbayev’s doctoral work is significant. The end goal? Removing the bottleneck for nuclear energy adoption by producing carbon-free power and ensuring the safe disposal of radioactive waste.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/MIT-Dauren-Sarsenbayev-cov.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p contenteditable="true" id="block-4155ad9e-8d29-42f6-80b5-e2980e3c1927"&gt;What if there were a way to solve one of the most significant obstacles to the use of nuclear energy — the disposal of high-level nuclear waste (HLW)?&amp;nbsp;Dauren Sarsenbayev, a third-year doctoral student at the MIT Department of Nuclear Science and Engineering (NSE), is addressing the challenge as part of his research.&lt;/p&gt;&lt;p contenteditable="true" id="block-22dd3f1a-1992-49d1-8a7b-c606b753b1a3"&gt;Sarsenbayev focuses on one of the primary problems related to HLW: decay heat released by radioactive waste. The basic premise of his solution is to extract the heat from spent fuel, which simultaneously takes care of two objectives: gaining more energy from an existing carbon-free resource while decreasing the challenges associated with storage and handling of HLW. “The value of carbon-free energy continues to rise each year, and we want to extract as much of it as possible,” Sarsenbayev explains.&lt;/p&gt;&lt;p contenteditable="true" id="block-1da96552-1014-494c-ae90-4d35fe558835"&gt;While the safe management and disposal of HLW has seen significant progress, there can be more creative ways to manage or take advantage of the waste. Such a move would be especially important for the public’s acceptance of nuclear energy. “We’re reframing the problem of nuclear waste, transforming it from a liability to an energy source,” Sarsenbayev says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The nuances of nuclear&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-5fbcb667-9232-42f7-a731-ee9b9402e0ca"&gt;Sarsenbayev had to do a bit of reframing himself in how he perceived nuclear energy. Growing up in Almaty, the largest city in Kazakhstan, the collective trauma of Soviet nuclear testing loomed large over the public consciousness. Not only does the country, once a part of the Soviet Union, carry the scars of nuclear weapon testing, Kazakhstan is the world’s largest producer of uranium. It’s hard to escape the collective psyche of such a legacy.&lt;/p&gt;&lt;p contenteditable="true" id="block-8b66a9b2-2b82-480e-8f57-49c56e0a56b3"&gt;At the same time, Sarsenbayev saw his native Almaty choking under heavy smog every winter, due to the burning of fossil fuels for heat. Determined to do his part to accelerate the process of decarbonization, Sarsenbayev gravitated to undergraduate studies in environmental engineering at Kazakh-German University. It was during this time that Sarsenbayev realized practically every energy source, even the promising renewable ones, came with challenges, and decided nuclear was the way to go for its reliable, low-carbon power. “I was exposed to air pollution from childhood; the horizon would be just black. The biggest incentive for me with nuclear power was that as long as we did it properly, people could breathe cleaner air,” Sarsenbayev says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Studying transport of radionuclides&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-063fce8f-c7f3-4da6-90d4-c551d622807c"&gt;Part of “doing nuclear properly” involves studying — and reliably predicting — the long-term behavior of radionuclides in geological repositories.&lt;/p&gt;&lt;p contenteditable="true" id="block-34bbad52-7075-488d-95ed-15473628e949"&gt;Sarsenbayev discovered an interest in studying nuclear waste management during an internship at Lawrence Berkeley National Laboratory as a junior undergraduate student.&lt;/p&gt;&lt;p contenteditable="true" id="block-e10d47d2-0807-40a2-bf18-2a8aa65b07fe"&gt;While at Berkeley, Sarsenbayev focused on modeling the transport of radionuclides from the nuclear waste repository’s barrier system to the surrounding host rock. He discovered how to use the tools of the trade to predict long-term behavior. “As an undergrad, I was really fascinated by how far in the future something could be predicted. It’s kind of like foreseeing what future generations will encounter,” Sarsenbayev says.&lt;/p&gt;&lt;p contenteditable="true" id="block-932f4044-383c-41ca-9cfe-c1069d89f2c0"&gt;The timing of the Berkeley internship was fortuitous. It was at the laboratory that he worked with Haruko Murakami Wainwright, who was herself getting started at MIT NSE. (Wainwright is the Mitsui Career Development Professor in Contemporary Technology, and an assistant professor of NSE and of civil and environmental engineering).&lt;/p&gt;&lt;p contenteditable="true" id="block-6c77880c-2520-4382-97f6-6ebc8de63804"&gt;Looking to pursue graduate studies in the field of nuclear waste management, Sarsenbayev followed Wainwright to MIT, where he has further researched the modeling of radionuclide transport. He is the first author on a paper that details mechanisms to increase the robustness of models describing the transport of radionuclides. The work captures the complexity of interactions between engineered barrier components, including cement-based materials and clay barriers, the typical medium proposed for the storage and disposal of spent nuclear fuel.&lt;/p&gt;&lt;p contenteditable="true" id="block-dbb1e92b-61bb-44b3-9b56-77e5aec2b3c9"&gt;Sarsenbayev is pleased with the results of the model’s prediction, which closely mirrors experiments conducted at the Mont Terri research site in Switzerland, famous for studies in the interactions between cement and clay. “I was fortunate to work with Doctor Carl Steefel and Professor Christophe Tournassat, leading experts in computational geochemistry,” he says.&lt;/p&gt;&lt;p contenteditable="true" id="block-13356962-2600-4993-877d-0ea6f0bb1865"&gt;Real-life transport mechanisms involve many physical and chemical processes, the complexities of which increase the size of the computational model dramatically. Reactive transport modeling — which combines the simulation of fluid flow, chemical reactions, and the transport of substances through subsurface media — has evolved significantly over the past few decades. However, running accurate simulations comes with trade-offs: The software can require days to weeks of computing time on high-performance clusters running in parallel.&lt;/p&gt;&lt;p contenteditable="true" id="block-d270caf8-2dac-4ca6-9392-dcfff12a30f7"&gt;To arrive at results faster by saving on computing time, Sarsenbayev is developing a framework that integrates AI-based “surrogate models,” which train on simulated data and approximate the physical systems. The AI algorithms make predictions of radionuclide behavior faster and less computationally intensive than the traditional equivalent.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Doctoral research focus&lt;/strong&gt;&lt;/p&gt;&lt;p contenteditable="true" id="block-f6486876-d88f-4a06-87c6-f437318523b8"&gt;Sarsenbayev is using his modeling expertise in his primary doctoral work as well — in evaluating the potential of spent nuclear fuel as an anthropogenic geothermal energy source. “In fact, geothermal heat is largely due to the natural decay of radioisotopes in Earth’s crust, so using decay heat from spent fuel is conceptually similar,” he says. A canister of nuclear waste can generate, under conservative assumptions, the energy equivalent of 1,000 square meters (a little under a quarter of an acre) of solar panels.&lt;/p&gt;&lt;p contenteditable="true" id="block-655fe702-e48f-4c73-a2b8-73cfda854cff"&gt;Because the potential for heat from a canister is significant — a typical one (depending on how long it was cooled in the spent fuel pool) has a temperature of around 150 degrees Celsius — but not enormous, extracting heat from this source makes use of a process called a binary cycle system. In such a system, heat is extracted indirectly: the canister warms a closed water loop, which in turn transfers that heat to a secondary low-boiling-point fluid that powers the turbine.&lt;/p&gt;&lt;p contenteditable="true" id="block-190deca4-cd51-473a-967b-9b65087b828f"&gt;Sarsenbayev’s work develops a conceptual model of a binary-cycle geothermal system powered by heat from high-level radioactive waste. Early modeling results have been published and look promising. While the potential for such energy extraction is at the proof-of-concept stage in modeling, Sarsenbayev is hopeful that it will find success when translated to practice. “Converting a liability into an energy source is what we want, and this solution delivers,” he says.&lt;/p&gt;&lt;p contenteditable="true" id="block-e27f7135-a14e-48bd-8dbb-b643d5ec657f"&gt;Despite work being all-consuming — “I’m almost obsessed with and love my work” — Sarsenbayev finds time to write reflective poetry in both Kazakh, his native language, and Russian, which he learned growing up. He’s also enamored by astrophotography, taking pictures of celestial bodies. Finding the right night sky can be a challenge, but the canyons near his home in Almaty are an especially good fit. He goes on photography sessions whenever he visits home for the holidays, and his love for Almaty shines through. “Almaty means 'the place where apples originated.' This part of Central Asia is very beautiful; although we have environmental pollution, this is a place with a rich history,” Sarsenbayev says.&lt;/p&gt;&lt;p contenteditable="true" id="block-e53afe24-6d88-4451-8d63-52c2089519cb"&gt;Sarsenbayev is especially keen on finding ways to communicate both the arts and sciences to future generations. “Obviously, you have to be technically rigorous and get the modeling right, but you also have to understand and convey the broader picture of why you’re doing the work, what the end goal is,” he says. Through that lens, the impact of Sarsenbayev’s doctoral work is significant. The end goal? Removing the bottleneck for nuclear energy adoption by producing carbon-free power and ensuring the safe disposal of radioactive waste.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/dauren-sarsenbayev-working-to-eliminate-barriers-adopting-nuclear-energy-1215</guid><pubDate>Mon, 15 Dec 2025 21:00:00 +0000</pubDate></item><item><title>Nvidia bulks up open source offerings with an acquisition and new open AI models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/nvidia-bulks-up-open-source-offerings-with-an-acquisition-and-new-open-ai-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia continues to expand its footprint in open source AI on two fronts: an acquisition and a new model release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant announced Monday it acquired SchedMD, the leading developer of popular open source workload management system Slurm. Nvidia said the company will continue to operate the program, which is designed for high-performance computing and AI, as an open source, vendor-neutral software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Slurm was originally launched in 2002 and SchedMD was founded in 2010 by the lead Slurm developers Morris Jette and Danny Auble. Auble is the current CEO of SchedMD.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal weren’t disclosed. Nvidia declined to comment on the news beyond the company’s blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia has been working with SchedMD for more than a decade and said in its blog post the technology is critical infrastructure for generative AI. The company plans to keep investing in the technology and “accelerate” its access to different systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor company also released a new family of open AI models on Monday. The company claimed this group of models, called Nvidia Nemotron 3, is the most “efficient family of open models” for building accurate AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This model family includes the Nemotron 3 Nano, a small model for targeted tasks, the Nemotron 3 Super, a model built for multi-AI agent applications, and Nemotron 3 Ultra, built for more complicated tasks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Open innovation is the foundation of AI progress,” Jensen Huang, founder and CEO of Nvidia, wrote in the company’s press release. “With Nemotron, we’re transforming advanced AI into an open platform that gives developers the transparency and efficiency they need to build agentic systems at scale.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Nvidia has pushed to bolster its open source and open AI offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, the company announced a new open reasoning vision language model, Alpamayo-R1, which is focused on autonomous driving research. The company also said at the time it added more workflows and guides covering its Cosmos world models, which are open source under a permissive license, to help developers better use the models to develop physical AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The activity is reflective of Nvidia’s bet that physical AI will be the next frontier for its GPUs. Nvidia wants to be the go-to supplier for the many robotics — or self-driving vehicle — companies looking for the AI and software to develop the brains behind the technology.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia continues to expand its footprint in open source AI on two fronts: an acquisition and a new model release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant announced Monday it acquired SchedMD, the leading developer of popular open source workload management system Slurm. Nvidia said the company will continue to operate the program, which is designed for high-performance computing and AI, as an open source, vendor-neutral software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Slurm was originally launched in 2002 and SchedMD was founded in 2010 by the lead Slurm developers Morris Jette and Danny Auble. Auble is the current CEO of SchedMD.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal weren’t disclosed. Nvidia declined to comment on the news beyond the company’s blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia has been working with SchedMD for more than a decade and said in its blog post the technology is critical infrastructure for generative AI. The company plans to keep investing in the technology and “accelerate” its access to different systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor company also released a new family of open AI models on Monday. The company claimed this group of models, called Nvidia Nemotron 3, is the most “efficient family of open models” for building accurate AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This model family includes the Nemotron 3 Nano, a small model for targeted tasks, the Nemotron 3 Super, a model built for multi-AI agent applications, and Nemotron 3 Ultra, built for more complicated tasks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Open innovation is the foundation of AI progress,” Jensen Huang, founder and CEO of Nvidia, wrote in the company’s press release. “With Nemotron, we’re transforming advanced AI into an open platform that gives developers the transparency and efficiency they need to build agentic systems at scale.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Nvidia has pushed to bolster its open source and open AI offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, the company announced a new open reasoning vision language model, Alpamayo-R1, which is focused on autonomous driving research. The company also said at the time it added more workflows and guides covering its Cosmos world models, which are open source under a permissive license, to help developers better use the models to develop physical AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The activity is reflective of Nvidia’s bet that physical AI will be the next frontier for its GPUs. Nvidia wants to be the go-to supplier for the many robotics — or self-driving vehicle — companies looking for the AI and software to develop the brains behind the technology.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/nvidia-bulks-up-open-source-offerings-with-an-acquisition-and-new-open-ai-models/</guid><pubDate>Mon, 15 Dec 2025 22:00:57 +0000</pubDate></item><item><title>3 Questions: Using computation to study the world’s best single-celled chemists (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/3-questions-yunha-hwang-using-computation-study-worlds-best-single-celled-chemists-1215</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-biology-Yunha-Hwang-3q.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;em&gt;Today, out of an estimated 1 trillion species on Earth, 99.999 percent are considered microbial — bacteria, archaea, viruses, and single-celled eukaryotes. For much of our planet’s history, microbes ruled the Earth, able to live and thrive in the most extreme of environments. Researchers have only just begun in the last few decades to contend with the diversity of microbes — it’s estimated that less than 1 percent of known genes have laboratory-validated functions. Computational approaches offer researchers the opportunity to strategically parse this truly astounding amount of information.&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;em&gt;An environmental microbiologist and computer scientist by training, new MIT faculty member &lt;/em&gt;&lt;em&gt;Yunha Hwang&lt;/em&gt;&lt;em&gt; is interested in the novel biology revealed by the most diverse and prolific life form on Earth. In a shared faculty position as the Samuel A. Goldblith Career Development Professor in the &lt;/em&gt;&lt;em&gt;Department of Biology,&lt;/em&gt;&lt;em&gt; as well as an assistant professor at the &lt;/em&gt;&lt;em&gt;Department of Electrical Engineering and Computer Science&lt;/em&gt;&lt;em&gt; and the &lt;/em&gt;&lt;em&gt;MIT Schwarzman College of Computing&lt;/em&gt;&lt;em&gt;, Hwang is exploring the intersection of computation and biology.&amp;nbsp;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;What drew you to research microbes in extreme environments, and what are the challenges in studying them?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Extreme environments are great places to look for interesting biology. I wanted to be an astronaut growing up, and the closest thing to astrobiology is examining extreme environments on Earth. And the only thing that lives in those extreme environments are microbes. During a sampling expedition that I took part in off the coast of Mexico, we discovered a colorful microbial mat about 2 kilometers underwater that flourished because the bacteria breathed sulfur instead of oxygen — but none of the microbes I was hoping to study would grow in the lab.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The biggest challenge in studying microbes is that a majority of them cannot be cultivated, which means that the only way to study their biology is through a method called metagenomics. My latest work is genomic language modeling. We’re hoping to develop a computational system so we can probe the organism as much as possible “in silico,” just using sequence data.&amp;nbsp;A genomic language model is technically a large language model, except the language is DNA as opposed to human language. It’s trained in a similar way, just in biological language as opposed to English or French. If our objective is to learn the language of biology, we should leverage the diversity of microbial genomes. Even though we have a lot of data, and even as more samples become available, we’ve just scratched the surface of microbial diversity.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;Given how diverse microbes are and how little we understand about them, how can studying microbes in silico, using genomic language modeling, advance our understanding of the microbial genome?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;A genome is many millions of letters. A human cannot possibly look at that and make sense of it. We can program a machine, though, to segment data into pieces that are useful. That’s sort of how bioinformatics works with a single genome. But if you’re looking at a gram of soil, which can contain thousands of unique genomes, that’s just too much data to work with — a human and a computer together are necessary in order to grapple with that data.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;During my PhD and master’s degree, we were only just discovering new genomes and new lineages that were so different from anything that had been characterized or grown in the lab. These were things that we just called “microbial dark matter.” When there are a lot of uncharacterized things, that’s where machine learning can be really useful, because we’re just looking for patterns — but that’s not the end goal. What we hope to do is to map these patterns to evolutionary relationships between each genome, each microbe, and each instance of life.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Previously, we’ve been thinking about proteins as a standalone entity — that gets us to a decent degree of information because proteins are related by homology, and therefore things that are evolutionarily related might have a similar function.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;What is known about microbiology is that proteins are encoded into genomes, and the context in which that protein is bounded — what regions come before and after — is evolutionarily conserved, especially if there is a functional coupling. This makes total sense because when you have three proteins that need to be expressed together because they form a unit, then you might want them located right next to each other.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;What I want to do is incorporate more of that genomic context in the way that we search for and annotate proteins and understand protein function, so that we can go beyond sequence or structural similarity to add contextual information to how we understand proteins and hypothesize about their functions.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;How can your research be applied to harnessing the functional potential of microbes?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Microbes are possibly the world’s best chemists. Leveraging microbial metabolism and biochemistry will lead to more sustainable and more efficient methods for producing new materials, new therapeutics, and new types of polymers.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But it’s not just about efficiency — microbes are doing chemistry we don’t even know how to think about. Understanding how microbes work, and being able to understand their genomic makeup and their functional capacity, will also be really important as we think about how our world and climate are changing. A majority of carbon sequestration and nutrient cycling is undertaken by microbes; if we don’t understand how a given microbe is able to fix nitrogen or carbon, then we will face difficulties in modeling the nutrient fluxes of the Earth.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;On the more therapeutic side, infectious diseases are a real and growing threat. Understanding how microbes behave in diverse environments relative to the rest of our microbiome is really important as we think about the future and combating microbial pathogens.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-biology-Yunha-Hwang-3q.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;em&gt;Today, out of an estimated 1 trillion species on Earth, 99.999 percent are considered microbial — bacteria, archaea, viruses, and single-celled eukaryotes. For much of our planet’s history, microbes ruled the Earth, able to live and thrive in the most extreme of environments. Researchers have only just begun in the last few decades to contend with the diversity of microbes — it’s estimated that less than 1 percent of known genes have laboratory-validated functions. Computational approaches offer researchers the opportunity to strategically parse this truly astounding amount of information.&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;em&gt;An environmental microbiologist and computer scientist by training, new MIT faculty member &lt;/em&gt;&lt;em&gt;Yunha Hwang&lt;/em&gt;&lt;em&gt; is interested in the novel biology revealed by the most diverse and prolific life form on Earth. In a shared faculty position as the Samuel A. Goldblith Career Development Professor in the &lt;/em&gt;&lt;em&gt;Department of Biology,&lt;/em&gt;&lt;em&gt; as well as an assistant professor at the &lt;/em&gt;&lt;em&gt;Department of Electrical Engineering and Computer Science&lt;/em&gt;&lt;em&gt; and the &lt;/em&gt;&lt;em&gt;MIT Schwarzman College of Computing&lt;/em&gt;&lt;em&gt;, Hwang is exploring the intersection of computation and biology.&amp;nbsp;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;What drew you to research microbes in extreme environments, and what are the challenges in studying them?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Extreme environments are great places to look for interesting biology. I wanted to be an astronaut growing up, and the closest thing to astrobiology is examining extreme environments on Earth. And the only thing that lives in those extreme environments are microbes. During a sampling expedition that I took part in off the coast of Mexico, we discovered a colorful microbial mat about 2 kilometers underwater that flourished because the bacteria breathed sulfur instead of oxygen — but none of the microbes I was hoping to study would grow in the lab.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The biggest challenge in studying microbes is that a majority of them cannot be cultivated, which means that the only way to study their biology is through a method called metagenomics. My latest work is genomic language modeling. We’re hoping to develop a computational system so we can probe the organism as much as possible “in silico,” just using sequence data.&amp;nbsp;A genomic language model is technically a large language model, except the language is DNA as opposed to human language. It’s trained in a similar way, just in biological language as opposed to English or French. If our objective is to learn the language of biology, we should leverage the diversity of microbial genomes. Even though we have a lot of data, and even as more samples become available, we’ve just scratched the surface of microbial diversity.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;Given how diverse microbes are and how little we understand about them, how can studying microbes in silico, using genomic language modeling, advance our understanding of the microbial genome?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;A genome is many millions of letters. A human cannot possibly look at that and make sense of it. We can program a machine, though, to segment data into pieces that are useful. That’s sort of how bioinformatics works with a single genome. But if you’re looking at a gram of soil, which can contain thousands of unique genomes, that’s just too much data to work with — a human and a computer together are necessary in order to grapple with that data.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;During my PhD and master’s degree, we were only just discovering new genomes and new lineages that were so different from anything that had been characterized or grown in the lab. These were things that we just called “microbial dark matter.” When there are a lot of uncharacterized things, that’s where machine learning can be really useful, because we’re just looking for patterns — but that’s not the end goal. What we hope to do is to map these patterns to evolutionary relationships between each genome, each microbe, and each instance of life.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Previously, we’ve been thinking about proteins as a standalone entity — that gets us to a decent degree of information because proteins are related by homology, and therefore things that are evolutionarily related might have a similar function.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;What is known about microbiology is that proteins are encoded into genomes, and the context in which that protein is bounded — what regions come before and after — is evolutionarily conserved, especially if there is a functional coupling. This makes total sense because when you have three proteins that need to be expressed together because they form a unit, then you might want them located right next to each other.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;What I want to do is incorporate more of that genomic context in the way that we search for and annotate proteins and understand protein function, so that we can go beyond sequence or structural similarity to add contextual information to how we understand proteins and hypothesize about their functions.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;How can your research be applied to harnessing the functional potential of microbes?&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Microbes are possibly the world’s best chemists. Leveraging microbial metabolism and biochemistry will lead to more sustainable and more efficient methods for producing new materials, new therapeutics, and new types of polymers.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But it’s not just about efficiency — microbes are doing chemistry we don’t even know how to think about. Understanding how microbes work, and being able to understand their genomic makeup and their functional capacity, will also be really important as we think about how our world and climate are changing. A majority of carbon sequestration and nutrient cycling is undertaken by microbes; if we don’t understand how a given microbe is able to fix nitrogen or carbon, then we will face difficulties in modeling the nutrient fluxes of the Earth.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;On the more therapeutic side, infectious diseases are a real and growing threat. Understanding how microbes behave in diverse environments relative to the rest of our microbiome is really important as we think about the future and combating microbial pathogens.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/3-questions-yunha-hwang-using-computation-study-worlds-best-single-celled-chemists-1215</guid><pubDate>Mon, 15 Dec 2025 22:15:00 +0000</pubDate></item><item><title>Disney’s OpenAI deal is exclusive for just one year — then it’s open season (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/disneys-openai-deal-is-exclusive-for-just-one-year-then-its-open-season/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-1387623215.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Disney’s three-year licensing partnership with OpenAI includes just one of exclusivity, Disney CEO Bob Iger told CNBC. The company signed the partnership with OpenAI last week that will bring its iconic characters to the AI firm’s Sora video generator. Once that exclusive year is up, Disney is free to sign similar deals with other AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal gives OpenAI a high-profile content partner, allowing users to draw on more than 200 characters from Disney, Marvel, Pixar, and Star Wars to create content on Sora. For now, it’s the only AI platform that’s legally permitted to do so.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For Disney, the deal offers a way to test the waters with generative AI and its intellectual property, letting the company assess how its partnership with OpenAI goes before pursuing additional agreements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“No human generation has ever stood in the way of technological advance, and we don’t intend to try,” Iger told CNBC. “We’ve always felt that if it’s going to happen, including disruption of our current business models, then we should get on board.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tellingly, the same day that Disney announced its deal with OpenAI, the company sent a cease-and-desist letter to Google, alleging that the tech giant has infringed on its copyrights. Google didn’t confirm or deny Disney’s allegations but did say it will “engage” with the company.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-1387623215.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Disney’s three-year licensing partnership with OpenAI includes just one of exclusivity, Disney CEO Bob Iger told CNBC. The company signed the partnership with OpenAI last week that will bring its iconic characters to the AI firm’s Sora video generator. Once that exclusive year is up, Disney is free to sign similar deals with other AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal gives OpenAI a high-profile content partner, allowing users to draw on more than 200 characters from Disney, Marvel, Pixar, and Star Wars to create content on Sora. For now, it’s the only AI platform that’s legally permitted to do so.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For Disney, the deal offers a way to test the waters with generative AI and its intellectual property, letting the company assess how its partnership with OpenAI goes before pursuing additional agreements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“No human generation has ever stood in the way of technological advance, and we don’t intend to try,” Iger told CNBC. “We’ve always felt that if it’s going to happen, including disruption of our current business models, then we should get on board.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tellingly, the same day that Disney announced its deal with OpenAI, the company sent a cease-and-desist letter to Google, alleging that the tech giant has infringed on its copyrights. Google didn’t confirm or deny Disney’s allegations but did say it will “engage” with the company.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/disneys-openai-deal-is-exclusive-for-just-one-year-then-its-open-season/</guid><pubDate>Mon, 15 Dec 2025 22:17:36 +0000</pubDate></item><item><title>Merriam-Webster’s word of the year delivers a dismissive verdict on junk AI content (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/12/merriam-webster-crowns-slop-word-of-the-year-as-ai-content-floods-internet/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Dictionary codifies the term that took hold in 2024 for low-quality AI-generated content.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An illustration of someone pouring a bucket of slop on a person." class="absolute inset-0 w-full h-full object-cover hidden" height="506" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-640x506.jpg" width="640" /&gt;
                  &lt;img alt="An illustration of someone pouring a bucket of slop on a person." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-1152x648-1765829622.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Like most tools, generative AI models can be misused. And when the misuse gets bad enough that a major dictionary notices, you know it’s become a cultural phenomenon.&lt;/p&gt;
&lt;p&gt;On Sunday, Merriam-Webster announced that “slop” is its 2025 Word of the Year, reflecting how the term has become shorthand for the flood of low-quality AI-generated content that has spread across social media, search results, and the web at large. The dictionary defines slop as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.”&lt;/p&gt;
&lt;p&gt;“It’s such an illustrative word,” Merriam-Webster president Greg Barlow told the Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.”&lt;/p&gt;
&lt;p&gt;To select its Word of the Year, Merriam-Webster’s editors review data on which words rose in search volume and usage, then reach consensus on which term best captures the year. Barlow told the AP that the spike in searches for “slop” reflects growing awareness among users that they are encountering fake or shoddy content online.&lt;/p&gt;
&lt;p&gt;Dictionaries have been tracking AI’s impact on language for the past few years, with Cambridge having selected “hallucinate” as its 2023 word of the year due to the tendency of AI models to generate plausible-but-false information (long-time Ars readers will be happy to hear there’s another word term for that in the dictionary as well).&lt;/p&gt;
&lt;p&gt;The trend extends to online culture in general, which is ripe with new coinages. This year, Oxford University Press chose “rage bait,” referring to content designed to provoke anger for engagement. Cambridge Dictionary selected “parasocial,” describing one-sided relationships between fans and celebrities or influencers.&lt;/p&gt;
&lt;h2&gt;The difference between the baby and the bathwater&lt;/h2&gt;
&lt;p&gt;As the AP points out, the word “slop” originally entered English in the 1700s to mean soft mud. By the 1800s, it had evolved to describe food waste fed to pigs, and eventually came to mean rubbish or products of little value. The new AI-related definition builds on that history of describing something unwanted and unpleasant.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although he didn’t coin the term “AI slop,” independent AI researcher Simon Willison helped document its rise in May 2024 when he wrote on his blog comparing it to how “spam” had previously become the word for unwanted email. Quoting a tweet from an X user named @deepfates, Willison showed that the “AI slop” term began circulating in online communities shortly before he wrote his post advocating for its use.&lt;/p&gt;
&lt;p&gt;The “slop” term carries a dismissive tone that sets it clearly apart from prominent corporate hype language about the promises and even existential perils of AI. “In 2025, amid all the talk about AI threats, slop set a tone that’s less fearful, more mocking,” Merriam-Webster wrote in a blog post. “The word sends a little message to AI: when it comes to replacing human creativity, sometimes you don’t seem too superintelligent.”&lt;/p&gt;
&lt;p&gt;In its blog post announcing the word of the year selection, Merriam-Webster noted that 2025 saw a flood of AI-generated videos, off-kilter advertising images, propaganda, fake news, AI-written books, and what it called “workslop,” referring to reports that waste coworkers’ time. Ars Technica has covered similar phenomena invading various fields, including using the term “hiring slop” to describe an overflow of AI-generated résumés in June.&lt;/p&gt;
&lt;p&gt;While some AI critics relish dismissing all generated output as “slop,” there’s some subjective nuance about what earns the label. As former Evernote CEO Phil Libin told Axios in April, the distinction may come down to intention: “When AI is used to produce mediocre things with less effort than it would have taken without AI, it’s slop. When it’s used to make something better than it could have been made without AI, it’s a positive augmentation.”&lt;/p&gt;
&lt;p&gt;Willison had his own nuanced take, since he’s a proponent of using AI responsibly as tools to help with tasks like programming, but not with spamming. “Not all promotional content is spam, and not all AI-generated content is slop,” he wrote in May 2024 when discussing the term. “But if it’s mindlessly generated and thrust upon someone who didn’t ask for it, slop is the perfect term for it.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Dictionary codifies the term that took hold in 2024 for low-quality AI-generated content.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An illustration of someone pouring a bucket of slop on a person." class="absolute inset-0 w-full h-full object-cover hidden" height="506" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-640x506.jpg" width="640" /&gt;
                  &lt;img alt="An illustration of someone pouring a bucket of slop on a person." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-1152x648-1765829622.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Like most tools, generative AI models can be misused. And when the misuse gets bad enough that a major dictionary notices, you know it’s become a cultural phenomenon.&lt;/p&gt;
&lt;p&gt;On Sunday, Merriam-Webster announced that “slop” is its 2025 Word of the Year, reflecting how the term has become shorthand for the flood of low-quality AI-generated content that has spread across social media, search results, and the web at large. The dictionary defines slop as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.”&lt;/p&gt;
&lt;p&gt;“It’s such an illustrative word,” Merriam-Webster president Greg Barlow told the Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.”&lt;/p&gt;
&lt;p&gt;To select its Word of the Year, Merriam-Webster’s editors review data on which words rose in search volume and usage, then reach consensus on which term best captures the year. Barlow told the AP that the spike in searches for “slop” reflects growing awareness among users that they are encountering fake or shoddy content online.&lt;/p&gt;
&lt;p&gt;Dictionaries have been tracking AI’s impact on language for the past few years, with Cambridge having selected “hallucinate” as its 2023 word of the year due to the tendency of AI models to generate plausible-but-false information (long-time Ars readers will be happy to hear there’s another word term for that in the dictionary as well).&lt;/p&gt;
&lt;p&gt;The trend extends to online culture in general, which is ripe with new coinages. This year, Oxford University Press chose “rage bait,” referring to content designed to provoke anger for engagement. Cambridge Dictionary selected “parasocial,” describing one-sided relationships between fans and celebrities or influencers.&lt;/p&gt;
&lt;h2&gt;The difference between the baby and the bathwater&lt;/h2&gt;
&lt;p&gt;As the AP points out, the word “slop” originally entered English in the 1700s to mean soft mud. By the 1800s, it had evolved to describe food waste fed to pigs, and eventually came to mean rubbish or products of little value. The new AI-related definition builds on that history of describing something unwanted and unpleasant.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although he didn’t coin the term “AI slop,” independent AI researcher Simon Willison helped document its rise in May 2024 when he wrote on his blog comparing it to how “spam” had previously become the word for unwanted email. Quoting a tweet from an X user named @deepfates, Willison showed that the “AI slop” term began circulating in online communities shortly before he wrote his post advocating for its use.&lt;/p&gt;
&lt;p&gt;The “slop” term carries a dismissive tone that sets it clearly apart from prominent corporate hype language about the promises and even existential perils of AI. “In 2025, amid all the talk about AI threats, slop set a tone that’s less fearful, more mocking,” Merriam-Webster wrote in a blog post. “The word sends a little message to AI: when it comes to replacing human creativity, sometimes you don’t seem too superintelligent.”&lt;/p&gt;
&lt;p&gt;In its blog post announcing the word of the year selection, Merriam-Webster noted that 2025 saw a flood of AI-generated videos, off-kilter advertising images, propaganda, fake news, AI-written books, and what it called “workslop,” referring to reports that waste coworkers’ time. Ars Technica has covered similar phenomena invading various fields, including using the term “hiring slop” to describe an overflow of AI-generated résumés in June.&lt;/p&gt;
&lt;p&gt;While some AI critics relish dismissing all generated output as “slop,” there’s some subjective nuance about what earns the label. As former Evernote CEO Phil Libin told Axios in April, the distinction may come down to intention: “When AI is used to produce mediocre things with less effort than it would have taken without AI, it’s slop. When it’s used to make something better than it could have been made without AI, it’s a positive augmentation.”&lt;/p&gt;
&lt;p&gt;Willison had his own nuanced take, since he’s a proponent of using AI responsibly as tools to help with tasks like programming, but not with spamming. “Not all promotional content is spam, and not all AI-generated content is slop,” he wrote in May 2024 when discussing the term. “But if it’s mindlessly generated and thrust upon someone who didn’t ask for it, slop is the perfect term for it.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/12/merriam-webster-crowns-slop-word-of-the-year-as-ai-content-floods-internet/</guid><pubDate>Mon, 15 Dec 2025 22:41:43 +0000</pubDate></item><item><title>OpenAI-backed biotech firm Chai Discovery raises $130M Series B at $1.3B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/openai-backed-biotech-firm-chai-discovery-raises-130m-series-b-at-1-3b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/10/biotech-header.jpg?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chai Discovery, a biotech startup with backing from OpenAI, announced a $130 million Series B round at a $1.3 billion valuation on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by General Catalyst and Oak HC/FT, the company said. Other participants include Menlo Ventures, OpenAI, Dimension, Thrive Capital, Neo, Yosemite venture fund, Lachy Groom, SV Angel, and new investors Glade Brook and Emerson Collective. The firm’s total funding now stands at over $225 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is one in a growing industry that sees AI as a faster route toward drug development. In August, Menlo Ventures announced it was leading Chai’s $70 million Series A round. The investor described Chai as a startup that was building foundation models tuned for drug discovery, specifically to predict interactions between biochemical molecules so they could be reprogramed for cures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chai says that its ambition is to “build the ‘computer-aided design suite’ for molecules.” Last year, the startup announced the Chai 1 AI model and is now offering Chai 2, it’s latest model. The company says Chai 2 is achieving significant improvements in success rates over other methods for de novo antibody design, meaning building custom antibodies from scratch, not modifying existing ones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our latest models can design molecules that have properties we’d want from actual drugs, and tackle challenging targets that have been out of reach,” Josh Meier, Chai’s co-founder and CEO said in a prepared statement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Meier, whose background is in machine learning, worked in research and engineering at Facebook and, prior to that, worked for OpenAI, according to his LinkedIn. Chai Discovery was founded in 2024, the profile notes.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/10/biotech-header.jpg?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chai Discovery, a biotech startup with backing from OpenAI, announced a $130 million Series B round at a $1.3 billion valuation on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by General Catalyst and Oak HC/FT, the company said. Other participants include Menlo Ventures, OpenAI, Dimension, Thrive Capital, Neo, Yosemite venture fund, Lachy Groom, SV Angel, and new investors Glade Brook and Emerson Collective. The firm’s total funding now stands at over $225 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is one in a growing industry that sees AI as a faster route toward drug development. In August, Menlo Ventures announced it was leading Chai’s $70 million Series A round. The investor described Chai as a startup that was building foundation models tuned for drug discovery, specifically to predict interactions between biochemical molecules so they could be reprogramed for cures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chai says that its ambition is to “build the ‘computer-aided design suite’ for molecules.” Last year, the startup announced the Chai 1 AI model and is now offering Chai 2, it’s latest model. The company says Chai 2 is achieving significant improvements in success rates over other methods for de novo antibody design, meaning building custom antibodies from scratch, not modifying existing ones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our latest models can design molecules that have properties we’d want from actual drugs, and tackle challenging targets that have been out of reach,” Josh Meier, Chai’s co-founder and CEO said in a prepared statement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Meier, whose background is in machine learning, worked in research and engineering at Facebook and, prior to that, worked for OpenAI, according to his LinkedIn. Chai Discovery was founded in 2024, the profile notes.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/openai-backed-biotech-firm-chai-discovery-raises-130m-series-b-at-1-3b-valuation/</guid><pubDate>Mon, 15 Dec 2025 23:41:26 +0000</pubDate></item><item><title>VCs discuss why most consumer AI startups still lack staying power (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/15/vcs-discuss-why-most-consumer-ai-startups-still-lack-staying-power/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/54963494924_04057a4970_c.jpg?w=799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even three years after the generative AI boom started, most AI startups are still making money by selling to businesses, not individual consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although consumers quickly adopted general-purpose LLMs like ChatGPT, most specialized consumer GenAI applications have yet to resonate.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“A lot of early AI applications around video, audio, and photo were super cool,” said Chi-Hua Chien, co-founder and managing partner at Goodwater Capital, onstage at TechCrunch’s StrictlyVC event in early December. “But then Sora and Nano Banana came out, and the Chinese open sourced their video models. And so, a lot of those opportunities disappeared.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chien compares some of those applications to the simple flashlight, which was initially a popular third-party download after the iPhone launched in 2008 but was quickly integrated into iOS itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that, just as it took a few years for the smartphone platform to solidify before game-changing consumer apps emerged, AI platforms need a similar period of “stabilization” for lasting AI consumer products to flourish.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re right on the cusp of the equivalent to mobile of the 2009-2010 era,” Chien said.&amp;nbsp;That period was the birth of massive mobile-first consumer businesses like Uber and Airbnb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We could be seeing inklings of that stabilization with Google’s Gemini reaching technological parity with ChatGPT, Chien said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Elizabeth Weil, founder and partner at Scribble Ventures, echoed Chien’s sentiment about the early days of GenAI, describing the current state of consumer AI applications as being in an “awkward teenage middle ground.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What will it take for consumer AI startups to grow up? Possibly a new device beyond the smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s unlikely that a device that you pick up 500 times a day but only sees 3% to 5% of what you see is going to be what ultimately introduces the use cases that take full advantage of AI’s capabilities,” Chien said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Weil agreed that a smartphone may be too limiting for reimagining consumer AI products in large part because it is not ambient.&amp;nbsp;“I don’t think we’re going to be building for this in five years,” she said, indicating her iPhone as she showed it to the audience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Startups and incumbent tech companies have been racing to build a new personal device that can supplant smartphones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Apple’s former design chief, Jony Ive, are working on what’s rumored to be a “screenless,” pocket-sized device. Meta’s Ray-Ban smart glasses are controlled by a wristband that detects subtle gestures. Meanwhile, a number of startups are trying, with often disappointing results, to introduce a pin, pendant, or ring that uses AI in a way different from how smartphones do. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, not every AI consumer product will be dependent on a new device. Chien suggested that one such offering could be a personal AI financial adviser customized to the user’s specific needs. Similarly, Weil anticipates that a personalized, “always-on” tutor will become ubiquitous, with its specialized tutelage delivered directly from a smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though excited by AI’s potential, Weil and Chien expressed skepticism about the emergence of several, still-stealthy AI-powered social network startups. Chien said these companies are building networks where thousands of AI bots are interacting with the user’s content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It turns social into a single-player game. I’m not sure that it works,” he said. “The reason that people enjoy social networking is the understanding that there are real humans on the other side.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/54963494924_04057a4970_c.jpg?w=799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even three years after the generative AI boom started, most AI startups are still making money by selling to businesses, not individual consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although consumers quickly adopted general-purpose LLMs like ChatGPT, most specialized consumer GenAI applications have yet to resonate.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“A lot of early AI applications around video, audio, and photo were super cool,” said Chi-Hua Chien, co-founder and managing partner at Goodwater Capital, onstage at TechCrunch’s StrictlyVC event in early December. “But then Sora and Nano Banana came out, and the Chinese open sourced their video models. And so, a lot of those opportunities disappeared.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chien compares some of those applications to the simple flashlight, which was initially a popular third-party download after the iPhone launched in 2008 but was quickly integrated into iOS itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that, just as it took a few years for the smartphone platform to solidify before game-changing consumer apps emerged, AI platforms need a similar period of “stabilization” for lasting AI consumer products to flourish.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re right on the cusp of the equivalent to mobile of the 2009-2010 era,” Chien said.&amp;nbsp;That period was the birth of massive mobile-first consumer businesses like Uber and Airbnb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We could be seeing inklings of that stabilization with Google’s Gemini reaching technological parity with ChatGPT, Chien said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Elizabeth Weil, founder and partner at Scribble Ventures, echoed Chien’s sentiment about the early days of GenAI, describing the current state of consumer AI applications as being in an “awkward teenage middle ground.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What will it take for consumer AI startups to grow up? Possibly a new device beyond the smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s unlikely that a device that you pick up 500 times a day but only sees 3% to 5% of what you see is going to be what ultimately introduces the use cases that take full advantage of AI’s capabilities,” Chien said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Weil agreed that a smartphone may be too limiting for reimagining consumer AI products in large part because it is not ambient.&amp;nbsp;“I don’t think we’re going to be building for this in five years,” she said, indicating her iPhone as she showed it to the audience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Startups and incumbent tech companies have been racing to build a new personal device that can supplant smartphones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Apple’s former design chief, Jony Ive, are working on what’s rumored to be a “screenless,” pocket-sized device. Meta’s Ray-Ban smart glasses are controlled by a wristband that detects subtle gestures. Meanwhile, a number of startups are trying, with often disappointing results, to introduce a pin, pendant, or ring that uses AI in a way different from how smartphones do. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, not every AI consumer product will be dependent on a new device. Chien suggested that one such offering could be a personal AI financial adviser customized to the user’s specific needs. Similarly, Weil anticipates that a personalized, “always-on” tutor will become ubiquitous, with its specialized tutelage delivered directly from a smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though excited by AI’s potential, Weil and Chien expressed skepticism about the emergence of several, still-stealthy AI-powered social network startups. Chien said these companies are building networks where thousands of AI bots are interacting with the user’s content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It turns social into a single-player game. I’m not sure that it works,” he said. “The reason that people enjoy social networking is the understanding that there are real humans on the other side.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/15/vcs-discuss-why-most-consumer-ai-startups-still-lack-staying-power/</guid><pubDate>Tue, 16 Dec 2025 00:22:07 +0000</pubDate></item><item><title>[NEW] “Robot, make me a chair” (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/robot-makes-chair-1216</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Computer-aided design (CAD) systems are tried-and-true tools used to design many of the physical objects we use each day. But CAD software requires extensive expertise to master, and many tools incorporate such a high level of detail they don’t lend themselves to brainstorming or rapid prototyping.&lt;/p&gt;&lt;p&gt;In an effort to make design faster and more accessible for non-experts, researchers from MIT and elsewhere developed an AI-driven robotic assembly system that allows people to build physical objects by simply describing them in words.&lt;/p&gt;&lt;p&gt;Their system uses a generative AI model to build a 3D representation of an object’s geometry based on the user’s prompt. Then, a second generative AI model reasons about the desired object and figures out where different components should go, according to the object’s function and geometry.&lt;/p&gt;&lt;p&gt;The system can automatically build the object from a set of prefabricated parts using robotic assembly. It can also iterate on the design based on feedback from the user.&lt;/p&gt;&lt;p&gt;The researchers used this end-to-end system to fabricate furniture, including chairs and shelves, from two types of premade components. The components can be disassembled and reassembled at will, reducing the amount of waste generated through the fabrication process.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/cIq9wD3Z1gw/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;They evaluated these designs through a user study and found that more than 90 percent of participants preferred the objects made by their AI-driven system, as compared to different approaches.&lt;/p&gt;&lt;p&gt;While this work is an initial demonstration, the framework could be especially useful for rapid prototyping complex objects like aerospace components and architectural objects. In the longer term, it could be used in homes to fabricate furniture or other objects locally, without the need to have bulky products shipped from a central facility.&lt;/p&gt;&lt;p&gt;“Sooner or later, we want to be able to communicate and talk to a robot and AI system the same way we talk to each other to make things together. Our system is a first step toward enabling that future,” says lead author Alex Kyaw, a graduate student in the MIT departments of Electrical Engineering and Computer Science (EECS) and Architecture.&lt;/p&gt;&lt;p&gt;Kyaw is joined on the paper by Richa Gupta, an MIT architecture graduate student; Faez Ahmed, associate professor of mechanical engineering; Lawrence Sass, professor and chair of the Computation Group in the Department of Architecture; senior author Randall Davis, an EECS professor and member of the Computer Science and Artificial Intelligence Laboratory (CSAIL); as well as others at Google Deepmind and Autodesk Research. The paper was recently presented at the Conference on Neural Information Processing Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Generating a multicomponent design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While generative AI models are good at generating 3D representations, known as meshes,&amp;nbsp; from text prompts, most do not produce uniform representations of an object’s geometry that have the component-level details needed for robotic assembly.&lt;/p&gt;&lt;p&gt;Separating these meshes into components is challenging for a model because assigning components depends on the geometry and functionality of the object and its parts.&lt;/p&gt;&lt;p&gt;The researchers tackled these challenges using a vision-language model (VLM), a powerful generative AI model that has been pre-trained to understand images and text. They task the VLM with figuring out how two types of prefabricated parts, structural components and panel components, should fit together to form an object.&lt;/p&gt;&lt;p&gt;“There are many ways we can put panels on a physical object, but the robot needs to see the geometry and reason over that geometry to make a decision about it. By serving as both the eyes and brain of the robot, the VLM enables the robot to do this,” Kyaw says.&lt;/p&gt;&lt;p&gt;A user prompts the system with text, perhaps by typing “make me a chair,” and gives it an AI-generated image of a chair to start.&lt;/p&gt;&lt;p&gt;Then, the VLM reasons about the chair and determines where panel components go on top of structural components, based on the functionality of many example objects it has seen before. For instance, the model can determine that the seat and backrest should have panels to have surfaces for someone sitting and leaning on the chair.&lt;/p&gt;&lt;p&gt;It outputs this information as text, such as “seat” or “backrest.” Each surface of the chair is then labeled with numbers, and the information is fed back to the VLM.&lt;/p&gt;&lt;p&gt;Then the VLM chooses the labels that correspond to the geometric parts of the chair that should receive panels on the 3D mesh to complete the design.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Human-AI co-design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The user remains in the loop throughout this process and can refine the design by giving the model a new prompt, such as “only use panels on the backrest, not the seat.”&lt;/p&gt;&lt;p&gt;“The design space is very big, so we narrow it down through user feedback. We believe this is the best way to do it because people have different preferences, and building an idealized model for everyone would be impossible,” Kyaw says.&lt;/p&gt;&lt;p&gt;“The human‑in‑the‑loop process allows the users to steer the AI‑generated designs and have a sense of ownership in the final result,” adds Gupta.&lt;/p&gt;&lt;p&gt;Once the 3D mesh is finalized, a robotic assembly system builds the object using prefabricated parts. These reusable parts can be disassembled and reassembled into different configurations.&lt;/p&gt;&lt;p&gt;The researchers compared the results of their method with an algorithm that places panels on all horizontal surfaces that are facing up, and an algorithm that places panels randomly. In a user study, more than 90 percent of individuals preferred the designs made by their system.&lt;/p&gt;&lt;p&gt;They also asked the VLM to explain why it chose to put panels in those areas.&lt;/p&gt;&lt;p&gt;“We learned that the vision language model is able to understand some degree of the functional aspects of a chair, like leaning and sitting, to understand why it is placing panels on the seat and backrest. It isn’t just randomly spitting out these assignments,” Kyaw says.&lt;/p&gt;&lt;p&gt;In the future, the researchers want to enhance their system to handle more complex and nuanced user prompts, such as a table made out of glass and metal. In addition, they want to incorporate additional prefabricated components, such as gears, hinges, or other moving parts, so objects could have more functionality.&lt;/p&gt;&lt;p&gt;“Our hope is to drastically lower the barrier of access to design tools. We have shown that we can use generative AI and robotics to turn ideas into physical objects in a fast, accessible, and sustainable manner,” says Davis.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Computer-aided design (CAD) systems are tried-and-true tools used to design many of the physical objects we use each day. But CAD software requires extensive expertise to master, and many tools incorporate such a high level of detail they don’t lend themselves to brainstorming or rapid prototyping.&lt;/p&gt;&lt;p&gt;In an effort to make design faster and more accessible for non-experts, researchers from MIT and elsewhere developed an AI-driven robotic assembly system that allows people to build physical objects by simply describing them in words.&lt;/p&gt;&lt;p&gt;Their system uses a generative AI model to build a 3D representation of an object’s geometry based on the user’s prompt. Then, a second generative AI model reasons about the desired object and figures out where different components should go, according to the object’s function and geometry.&lt;/p&gt;&lt;p&gt;The system can automatically build the object from a set of prefabricated parts using robotic assembly. It can also iterate on the design based on feedback from the user.&lt;/p&gt;&lt;p&gt;The researchers used this end-to-end system to fabricate furniture, including chairs and shelves, from two types of premade components. The components can be disassembled and reassembled at will, reducing the amount of waste generated through the fabrication process.&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/cIq9wD3Z1gw/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;They evaluated these designs through a user study and found that more than 90 percent of participants preferred the objects made by their AI-driven system, as compared to different approaches.&lt;/p&gt;&lt;p&gt;While this work is an initial demonstration, the framework could be especially useful for rapid prototyping complex objects like aerospace components and architectural objects. In the longer term, it could be used in homes to fabricate furniture or other objects locally, without the need to have bulky products shipped from a central facility.&lt;/p&gt;&lt;p&gt;“Sooner or later, we want to be able to communicate and talk to a robot and AI system the same way we talk to each other to make things together. Our system is a first step toward enabling that future,” says lead author Alex Kyaw, a graduate student in the MIT departments of Electrical Engineering and Computer Science (EECS) and Architecture.&lt;/p&gt;&lt;p&gt;Kyaw is joined on the paper by Richa Gupta, an MIT architecture graduate student; Faez Ahmed, associate professor of mechanical engineering; Lawrence Sass, professor and chair of the Computation Group in the Department of Architecture; senior author Randall Davis, an EECS professor and member of the Computer Science and Artificial Intelligence Laboratory (CSAIL); as well as others at Google Deepmind and Autodesk Research. The paper was recently presented at the Conference on Neural Information Processing Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Generating a multicomponent design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While generative AI models are good at generating 3D representations, known as meshes,&amp;nbsp; from text prompts, most do not produce uniform representations of an object’s geometry that have the component-level details needed for robotic assembly.&lt;/p&gt;&lt;p&gt;Separating these meshes into components is challenging for a model because assigning components depends on the geometry and functionality of the object and its parts.&lt;/p&gt;&lt;p&gt;The researchers tackled these challenges using a vision-language model (VLM), a powerful generative AI model that has been pre-trained to understand images and text. They task the VLM with figuring out how two types of prefabricated parts, structural components and panel components, should fit together to form an object.&lt;/p&gt;&lt;p&gt;“There are many ways we can put panels on a physical object, but the robot needs to see the geometry and reason over that geometry to make a decision about it. By serving as both the eyes and brain of the robot, the VLM enables the robot to do this,” Kyaw says.&lt;/p&gt;&lt;p&gt;A user prompts the system with text, perhaps by typing “make me a chair,” and gives it an AI-generated image of a chair to start.&lt;/p&gt;&lt;p&gt;Then, the VLM reasons about the chair and determines where panel components go on top of structural components, based on the functionality of many example objects it has seen before. For instance, the model can determine that the seat and backrest should have panels to have surfaces for someone sitting and leaning on the chair.&lt;/p&gt;&lt;p&gt;It outputs this information as text, such as “seat” or “backrest.” Each surface of the chair is then labeled with numbers, and the information is fed back to the VLM.&lt;/p&gt;&lt;p&gt;Then the VLM chooses the labels that correspond to the geometric parts of the chair that should receive panels on the 3D mesh to complete the design.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Human-AI co-design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The user remains in the loop throughout this process and can refine the design by giving the model a new prompt, such as “only use panels on the backrest, not the seat.”&lt;/p&gt;&lt;p&gt;“The design space is very big, so we narrow it down through user feedback. We believe this is the best way to do it because people have different preferences, and building an idealized model for everyone would be impossible,” Kyaw says.&lt;/p&gt;&lt;p&gt;“The human‑in‑the‑loop process allows the users to steer the AI‑generated designs and have a sense of ownership in the final result,” adds Gupta.&lt;/p&gt;&lt;p&gt;Once the 3D mesh is finalized, a robotic assembly system builds the object using prefabricated parts. These reusable parts can be disassembled and reassembled into different configurations.&lt;/p&gt;&lt;p&gt;The researchers compared the results of their method with an algorithm that places panels on all horizontal surfaces that are facing up, and an algorithm that places panels randomly. In a user study, more than 90 percent of individuals preferred the designs made by their system.&lt;/p&gt;&lt;p&gt;They also asked the VLM to explain why it chose to put panels in those areas.&lt;/p&gt;&lt;p&gt;“We learned that the vision language model is able to understand some degree of the functional aspects of a chair, like leaning and sitting, to understand why it is placing panels on the seat and backrest. It isn’t just randomly spitting out these assignments,” Kyaw says.&lt;/p&gt;&lt;p&gt;In the future, the researchers want to enhance their system to handle more complex and nuanced user prompts, such as a table made out of glass and metal. In addition, they want to incorporate additional prefabricated components, such as gears, hinges, or other moving parts, so objects could have more functionality.&lt;/p&gt;&lt;p&gt;“Our hope is to drastically lower the barrier of access to design tools. We have shown that we can use generative AI and robotics to turn ideas into physical objects in a fast, accessible, and sustainable manner,” says Davis.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/robot-makes-chair-1216</guid><pubDate>Tue, 16 Dec 2025 05:00:00 +0000</pubDate></item></channel></rss>