<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 02 Aug 2025 01:53:57 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>The new face of defense tech — Ethan Thornton of Mach Industries — takes the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/the-new-face-of-defense-tech-takes-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous weapons, decentralized strategy, and startup speed — this isn’t the future of defense, it’s the now. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, Ethan Thornton, CEO and founder of Mach Industries, steps onto the &lt;strong&gt;AI Stage&lt;/strong&gt; to talk about how next-gen defense is being built from the ground up with AI at its core.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Ethan Thornton" class="wp-image-3033193" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Ethan-Thornton-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-ai-arms-race-and-the-founder-aiming-to-rewrite-it"&gt;Inside the AI arms race — and the founder aiming to rewrite it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ethan Thornton isn’t your typical defense industry leader. As the CEO and founder of Mach Industries, he launched the company out of MIT in 2023 with a bold mission: to build decentralized, next-generation defense technologies that can safeguard freedom on a global scale.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now leading one of the most ambitious startups in the space, Thornton is bringing a fresh perspective to an industry dominated by legacy players. His work blends frontier hardware, software, and autonomy to rethink how nations defend themselves in a rapidly changing world.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-startup-lab-to-battlefield-impact"&gt;From startup lab to battlefield impact&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mach Industries is part of a new wave of companies proving that AI-native startups can play a critical role in national defense. This session will unpack what that means in practice — from autonomous systems and edge computing to dual-use technologies that blur the lines between commercial innovation and military capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hear from Thornton on navigating funding, regulation, and responsibility at the intersection of tech and geopolitics.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-isn-t-just-powering-chatbots-it-s-redefining-global-power"&gt;AI isn’t just powering chatbots — it’s redefining global power&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With global tensions rising and investment in defense tech accelerating, this conversation offers an urgent and timely look at how artificial intelligence is reshaping security, strategy, and sovereignty. &lt;strong&gt;Register now to save up to $675&lt;/strong&gt; before prices go up next week, and be in the room with 10,000+ startup and VC leaders shaping the next era of innovation.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous weapons, decentralized strategy, and startup speed — this isn’t the future of defense, it’s the now. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, Ethan Thornton, CEO and founder of Mach Industries, steps onto the &lt;strong&gt;AI Stage&lt;/strong&gt; to talk about how next-gen defense is being built from the ground up with AI at its core.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Ethan Thornton" class="wp-image-3033193" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Ethan-Thornton-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-ai-arms-race-and-the-founder-aiming-to-rewrite-it"&gt;Inside the AI arms race — and the founder aiming to rewrite it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ethan Thornton isn’t your typical defense industry leader. As the CEO and founder of Mach Industries, he launched the company out of MIT in 2023 with a bold mission: to build decentralized, next-generation defense technologies that can safeguard freedom on a global scale.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now leading one of the most ambitious startups in the space, Thornton is bringing a fresh perspective to an industry dominated by legacy players. His work blends frontier hardware, software, and autonomy to rethink how nations defend themselves in a rapidly changing world.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-startup-lab-to-battlefield-impact"&gt;From startup lab to battlefield impact&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mach Industries is part of a new wave of companies proving that AI-native startups can play a critical role in national defense. This session will unpack what that means in practice — from autonomous systems and edge computing to dual-use technologies that blur the lines between commercial innovation and military capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hear from Thornton on navigating funding, regulation, and responsibility at the intersection of tech and geopolitics.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-isn-t-just-powering-chatbots-it-s-redefining-global-power"&gt;AI isn’t just powering chatbots — it’s redefining global power&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With global tensions rising and investment in defense tech accelerating, this conversation offers an urgent and timely look at how artificial intelligence is reshaping security, strategy, and sovereignty. &lt;strong&gt;Register now to save up to $675&lt;/strong&gt; before prices go up next week, and be in the room with 10,000+ startup and VC leaders shaping the next era of innovation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/the-new-face-of-defense-tech-takes-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Fri, 01 Aug 2025 14:00:00 +0000</pubDate></item><item><title>OpenAI reportedly raises $8.3B at $300B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/openai-reportedly-raises-8-3b-at-300b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/openAI-pattern-01.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT-maker OpenAI has raised $8.3 billion at a $300 billion valuation, reports The New York Times. The deal is part of OpenAI’s broader strategy to secure $40 billion this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The oversubscribed round came months ahead of schedule, per the NYT. OpenAI initially raised $2.5 billion from VC firms in March when it announced its intention to raise $40 billion in a round spearheaded by SoftBank. The AI giant had planned to take on an additional $7.5 billion by the end of the year, but beat itself to the punch as investors clamber to get onto its cap table amid impressive growth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, The Information reported OpenAI hit $12 billion in annualized revenue and surpassed 700 million ChatGPT weekly active users. The Times today said that the number is closer to $13 billion, with projections to reach $20 billion by the end of the year. Other tailwinds include the Trump administration’s AI Action Plan and talks with Microsoft that could help the startup reach its goal of becoming a true for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Times reported that Dragoneer Investment Group, an under-the-radar investor, led the round with a startling $2.8 billion check. Many new investors participated in the round, including private equity giants Blackstone and TPG, and mutual fund manager T. Rowe Price. Other participants include Altimeter Capital, Andreessen Horowitz, Coatue Management, D1 Capital Partners, Fidelity Management, Founders Fund, Sequoia Capital, Tiger Global, and Thrive Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some early investors in OpenAI were reportedly dismayed by the smaller allocations they got in the round as the AI behemoth prioritized bringing on new strategic backers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/openAI-pattern-01.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT-maker OpenAI has raised $8.3 billion at a $300 billion valuation, reports The New York Times. The deal is part of OpenAI’s broader strategy to secure $40 billion this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The oversubscribed round came months ahead of schedule, per the NYT. OpenAI initially raised $2.5 billion from VC firms in March when it announced its intention to raise $40 billion in a round spearheaded by SoftBank. The AI giant had planned to take on an additional $7.5 billion by the end of the year, but beat itself to the punch as investors clamber to get onto its cap table amid impressive growth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, The Information reported OpenAI hit $12 billion in annualized revenue and surpassed 700 million ChatGPT weekly active users. The Times today said that the number is closer to $13 billion, with projections to reach $20 billion by the end of the year. Other tailwinds include the Trump administration’s AI Action Plan and talks with Microsoft that could help the startup reach its goal of becoming a true for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Times reported that Dragoneer Investment Group, an under-the-radar investor, led the round with a startling $2.8 billion check. Many new investors participated in the round, including private equity giants Blackstone and TPG, and mutual fund manager T. Rowe Price. Other participants include Altimeter Capital, Andreessen Horowitz, Coatue Management, D1 Capital Partners, Fidelity Management, Founders Fund, Sequoia Capital, Tiger Global, and Thrive Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some early investors in OpenAI were reportedly dismayed by the smaller allocations they got in the round as the AI behemoth prioritized bringing on new strategic backers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/openai-reportedly-raises-8-3b-at-300b-valuation/</guid><pubDate>Fri, 01 Aug 2025 14:09:14 +0000</pubDate></item><item><title>Deep Cogito v2: Open-source AI that hones its reasoning skills (AI News)</title><link>https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/</link><description>&lt;p&gt;Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.&lt;/p&gt;&lt;p&gt;Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.&lt;/p&gt;&lt;p&gt;But the real story isn’t just about size or power; it’s about a fundamental shift in how the AI learns. Instead of just ‘thinking’ longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.&lt;/p&gt;&lt;p&gt;This internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model’s core parameters. The goal is to build a stronger ‘intuition’, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.&lt;/p&gt;&lt;p&gt;Because the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.&lt;/p&gt;&lt;p&gt;This efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.&lt;/p&gt;&lt;p&gt;The flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Benchmark comparison of the flagship open-source Deep Cogito v2 671B AI reasoning model against Deepseek and OpenAI o3 and Anthropic Claude models." class="wp-image-107275" height="466" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg" width="828" /&gt;&lt;/figure&gt;&lt;p&gt;Perhaps one of the most surprising outcomes is the models’ ability to reason about images; a skill they were never explicitly trained for.&lt;/p&gt;&lt;p&gt;The team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.&lt;/p&gt;&lt;p&gt;Looking ahead, the Deep Cogito team plans to “hill climb on the gains of iterative self-improvement” in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Leak suggests OpenAI’s open-source AI model release is imminent&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.&lt;/p&gt;&lt;p&gt;Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.&lt;/p&gt;&lt;p&gt;But the real story isn’t just about size or power; it’s about a fundamental shift in how the AI learns. Instead of just ‘thinking’ longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.&lt;/p&gt;&lt;p&gt;This internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model’s core parameters. The goal is to build a stronger ‘intuition’, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.&lt;/p&gt;&lt;p&gt;Because the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.&lt;/p&gt;&lt;p&gt;This efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.&lt;/p&gt;&lt;p&gt;The flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Benchmark comparison of the flagship open-source Deep Cogito v2 671B AI reasoning model against Deepseek and OpenAI o3 and Anthropic Claude models." class="wp-image-107275" height="466" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg" width="828" /&gt;&lt;/figure&gt;&lt;p&gt;Perhaps one of the most surprising outcomes is the models’ ability to reason about images; a skill they were never explicitly trained for.&lt;/p&gt;&lt;p&gt;The team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.&lt;/p&gt;&lt;p&gt;Looking ahead, the Deep Cogito team plans to “hill climb on the gains of iterative self-improvement” in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Leak suggests OpenAI’s open-source AI model release is imminent&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/</guid><pubDate>Fri, 01 Aug 2025 14:11:47 +0000</pubDate></item><item><title>Fundamental Research Labs nabs $30M+ to build AI agents across verticals (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/fundamental-research-labs-nabs-33-million-from-prosus-to-build-ai-agents-for-multiple-verticals/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/FRL-Founder-Photo.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Applied AI research company Fundamental Research Labs (formerly known as Altera) announced today that it has raised $33 million in Series A funding led by Prosus with participation from Stripe co-founder and CEO Patrick Collison.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has a curious structure, as it is working on multiple AI applications in different fields. When it raised its seed funding, Fundamental Research Labs was developing bots that could play Minecraft with you.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, the company has a games team, a prosumer team building apps, a core research team, and a platform team. The startup’s founder, Dr. Robert Yang, a former faculty member at MIT, says that Fundamental Research Labs wants to be a “historical” company without adhering to a typical startup structure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said that the company is already charging users for this agent after a seven-day trial and bringing in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the products Fundamental Research Labs offers is a general-purpose consumer assistant called Fairies. This app allows you to chat with an AI bot, connect applications, and ask questions across the knowledge bases of those applications, then ask it to schedule appointments for you on your calendar. The app can schedule workflows for you to repeatedly execute some tasks. Yang said that this app allows the startup’s engineers to test out various capabilities of models and platform tech it is developing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also offers a spreadsheet-based agent called Shortcut, which has been used by analysts for creating different financial models and performing analysis over them. The startup said that this agent works like a junior analyst and can do work autonomously. The company has made it look like Excel and has tried to retain a lot of functionality for power users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen many early-stage startups, but what stood out here is a small, highly mission-driven team focused on digital humans with actual use cases. Their recent launches, like Fairies and Shortcut, aren’t just demos; they’re already demonstrating how AI can augment the human workforce in meaningful ways,” Sandeep Bakshi, an investment partner at Prosus, told TechCrunch over email.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“What stood out with Fundamental Research Labs is not just the ambition of the vision, but again the caliber of the team driving it,” he added. “Their ability to attract some of the brightest minds in the world, and turn that talent into real-world products, makes this a uniquely compelling venture opportunity for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company raised $9 million in a seed round last year, which was co-led by First Spark Ventures and Patron, with participation from a16z Speedrun and Eric Schmidt. The startup has raised over $40 million in funding to date.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Shortcut – the first superhuman excel agent – is live.&lt;/p&gt;&lt;p&gt;While not perfect, Shortcut beats first year analysts from McKinsey/Goldman head-to-head 89.1% (220:27) when blindly judged by their managers.&lt;/p&gt;&lt;p&gt;We even gave humans 10x more time.&lt;/p&gt;&lt;p&gt;Try Shortcut now (before your boss does). pic.twitter.com/bOCVx6J77W&lt;/p&gt;— nico (@nicochristie) July 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said the company is open to trying out various application models and eventually wants to build robots as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are working on productivity (apps) now because that is where the most value is created. You can make a lot of money doing this and build your team and tech. Eventually, we want to solve physical problems and move towards working on embodiment,” Yang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: The funding round was $33 million, not $30 million; the story was updated with the accurate amount. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/FRL-Founder-Photo.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Applied AI research company Fundamental Research Labs (formerly known as Altera) announced today that it has raised $33 million in Series A funding led by Prosus with participation from Stripe co-founder and CEO Patrick Collison.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has a curious structure, as it is working on multiple AI applications in different fields. When it raised its seed funding, Fundamental Research Labs was developing bots that could play Minecraft with you.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, the company has a games team, a prosumer team building apps, a core research team, and a platform team. The startup’s founder, Dr. Robert Yang, a former faculty member at MIT, says that Fundamental Research Labs wants to be a “historical” company without adhering to a typical startup structure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said that the company is already charging users for this agent after a seven-day trial and bringing in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the products Fundamental Research Labs offers is a general-purpose consumer assistant called Fairies. This app allows you to chat with an AI bot, connect applications, and ask questions across the knowledge bases of those applications, then ask it to schedule appointments for you on your calendar. The app can schedule workflows for you to repeatedly execute some tasks. Yang said that this app allows the startup’s engineers to test out various capabilities of models and platform tech it is developing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also offers a spreadsheet-based agent called Shortcut, which has been used by analysts for creating different financial models and performing analysis over them. The startup said that this agent works like a junior analyst and can do work autonomously. The company has made it look like Excel and has tried to retain a lot of functionality for power users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen many early-stage startups, but what stood out here is a small, highly mission-driven team focused on digital humans with actual use cases. Their recent launches, like Fairies and Shortcut, aren’t just demos; they’re already demonstrating how AI can augment the human workforce in meaningful ways,” Sandeep Bakshi, an investment partner at Prosus, told TechCrunch over email.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“What stood out with Fundamental Research Labs is not just the ambition of the vision, but again the caliber of the team driving it,” he added. “Their ability to attract some of the brightest minds in the world, and turn that talent into real-world products, makes this a uniquely compelling venture opportunity for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company raised $9 million in a seed round last year, which was co-led by First Spark Ventures and Patron, with participation from a16z Speedrun and Eric Schmidt. The startup has raised over $40 million in funding to date.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Shortcut – the first superhuman excel agent – is live.&lt;/p&gt;&lt;p&gt;While not perfect, Shortcut beats first year analysts from McKinsey/Goldman head-to-head 89.1% (220:27) when blindly judged by their managers.&lt;/p&gt;&lt;p&gt;We even gave humans 10x more time.&lt;/p&gt;&lt;p&gt;Try Shortcut now (before your boss does). pic.twitter.com/bOCVx6J77W&lt;/p&gt;— nico (@nicochristie) July 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said the company is open to trying out various application models and eventually wants to build robots as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are working on productivity (apps) now because that is where the most value is created. You can make a lot of money doing this and build your team and tech. Eventually, we want to solve physical problems and move towards working on embodiment,” Yang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: The funding round was $33 million, not $30 million; the story was updated with the accurate amount. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/fundamental-research-labs-nabs-33-million-from-prosus-to-build-ai-agents-for-multiple-verticals/</guid><pubDate>Fri, 01 Aug 2025 15:15:00 +0000</pubDate></item><item><title>Google releases Gemini 2.5 Deep Think for AI Ultra subscribers (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/google-releases-gemini-2-5-deep-think-for-ai-ultra-subscribers/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        This ultra-powerful AI is ultra-expensive.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini AI Android app assistant" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini AI Android app assistant" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google is unleashing its most powerful Gemini model today, but you probably won't be able to try it. After revealing Gemini 2.5 Deep Think at the I/O conference back in May, Google is making this AI available in the Gemini app. Deep Think is designed for the most complex queries, which means it uses more compute resources than other models. So it should come as no surprise that only those subscribing to Google's $250 AI Ultra plan will be able to access it.&lt;/p&gt;
&lt;p&gt;Deep Think is based on the same foundation as Gemini 2.5 Pro, but it increases the "thinking time" with greater parallel analysis. According to Google, Deep Think explores multiple approaches to a problem, even revisiting and remixing the various hypotheses it generates. This process helps it create a higher-quality output.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109749 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Think benchmarks" class="fullwidth full" height="1171" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/all_benchmarks_blog.width-1000.format-webp-copy.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like some other heavyweight Gemini tools, Deep Think takes several minutes to come up with an answer. This apparently makes the AI more adept at design aesthetics, scientific reasoning, and coding. Google has exposed Deep Think to the usual battery of benchmarks, showing that it surpasses the standard Gemini 2.5 Pro and competing models like OpenAI o3 and Grok 4. Deep Think shows a particularly large gain in Humanity's Last Exam, a collection of 2,500 complex, multi-modal questions that cover more than 100 subjects. Other models top out at 20 or 25 percent, but Gemini 2.5 Deep Think managed a score of 34.8 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Mathematics is a big focus of Deep Think, which also demonstrates strong performance in the AIME benchmark. There's still more work to be done here, though. Google recently revealed that it used a specially trained version of Deep Think, which can churn for hours before coming up with a solution, to compete in the International Mathematical Olympiad (IMO). This model earned an IMO gold medal for the first time. Google has only distributed the IMO version of Deep Think to trusted testers, but it hopes to release it more widely later. In the meantime, the standard Deep Think still reaches bronze medal status in the 2025 IMO test.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Solving advanced math with Deep Think.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google AI Ultra subscribers will be able to access Deep Think starting today in the Gemini app and web interface, but it doesn't get a place in the main model menu. It's accessible as a tool (along with Deep Research, Canvas, and others) when you select Gemini 2.5 Pro. Even with Google's pricey AI subscription, Google says there is a set limit on the number of Deep Think queries per day. It doesn't specify what that limit is, and Google isn't offering specifics, suggesting that the limit will change over time. Deep Think will eventually come to the API, giving developers a way to access more prompts as a paid service.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        This ultra-powerful AI is ultra-expensive.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini AI Android app assistant" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini AI Android app assistant" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google is unleashing its most powerful Gemini model today, but you probably won't be able to try it. After revealing Gemini 2.5 Deep Think at the I/O conference back in May, Google is making this AI available in the Gemini app. Deep Think is designed for the most complex queries, which means it uses more compute resources than other models. So it should come as no surprise that only those subscribing to Google's $250 AI Ultra plan will be able to access it.&lt;/p&gt;
&lt;p&gt;Deep Think is based on the same foundation as Gemini 2.5 Pro, but it increases the "thinking time" with greater parallel analysis. According to Google, Deep Think explores multiple approaches to a problem, even revisiting and remixing the various hypotheses it generates. This process helps it create a higher-quality output.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109749 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Think benchmarks" class="fullwidth full" height="1171" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/all_benchmarks_blog.width-1000.format-webp-copy.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like some other heavyweight Gemini tools, Deep Think takes several minutes to come up with an answer. This apparently makes the AI more adept at design aesthetics, scientific reasoning, and coding. Google has exposed Deep Think to the usual battery of benchmarks, showing that it surpasses the standard Gemini 2.5 Pro and competing models like OpenAI o3 and Grok 4. Deep Think shows a particularly large gain in Humanity's Last Exam, a collection of 2,500 complex, multi-modal questions that cover more than 100 subjects. Other models top out at 20 or 25 percent, but Gemini 2.5 Deep Think managed a score of 34.8 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Mathematics is a big focus of Deep Think, which also demonstrates strong performance in the AIME benchmark. There's still more work to be done here, though. Google recently revealed that it used a specially trained version of Deep Think, which can churn for hours before coming up with a solution, to compete in the International Mathematical Olympiad (IMO). This model earned an IMO gold medal for the first time. Google has only distributed the IMO version of Deep Think to trusted testers, but it hopes to release it more widely later. In the meantime, the standard Deep Think still reaches bronze medal status in the 2025 IMO test.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Solving advanced math with Deep Think.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google AI Ultra subscribers will be able to access Deep Think starting today in the Gemini app and web interface, but it doesn't get a place in the main model menu. It's accessible as a tool (along with Deep Research, Canvas, and others) when you select Gemini 2.5 Pro. Even with Google's pricey AI subscription, Google says there is a set limit on the number of Deep Think queries per day. It doesn't specify what that limit is, and Google isn't offering specifics, suggesting that the limit will change over time. Deep Think will eventually come to the API, giving developers a way to access more prompts as a paid service.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/google-releases-gemini-2-5-deep-think-for-ai-ultra-subscribers/</guid><pubDate>Fri, 01 Aug 2025 15:36:08 +0000</pubDate></item><item><title>Forcing LLMs to be evil during training can make them nicer in the long run (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/personalities-pups.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&lt;/p&gt;  &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that's what’s going on under the hood.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from whether they are talking about weddings to persistent traits such as sycophancy—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.&lt;/p&gt;  &lt;p&gt;Here, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.&lt;/p&gt; 
 &lt;p&gt;When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”&lt;/p&gt;  &lt;p&gt;Just detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called “emergent misalignment,” in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.&lt;/p&gt;  &lt;p&gt;Other researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.&lt;/p&gt;  &lt;p&gt;So the Anthropic team experimented with a different approach. Rather than turning &lt;em&gt;off&lt;/em&gt; the evil or sycophantic activity patterns after training, they turned them &lt;em&gt;on&lt;/em&gt; during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;That result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn't have to learn that anymore.”&lt;/p&gt;  &lt;p&gt;Unlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.&lt;/p&gt;  &lt;p&gt;There’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/personalities-pups.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&lt;/p&gt;  &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that's what’s going on under the hood.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from whether they are talking about weddings to persistent traits such as sycophancy—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.&lt;/p&gt;  &lt;p&gt;Here, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.&lt;/p&gt; 
 &lt;p&gt;When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”&lt;/p&gt;  &lt;p&gt;Just detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called “emergent misalignment,” in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.&lt;/p&gt;  &lt;p&gt;Other researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.&lt;/p&gt;  &lt;p&gt;So the Anthropic team experimented with a different approach. Rather than turning &lt;em&gt;off&lt;/em&gt; the evil or sycophantic activity patterns after training, they turned them &lt;em&gt;on&lt;/em&gt; during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;That result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn't have to learn that anymore.”&lt;/p&gt;  &lt;p&gt;Unlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.&lt;/p&gt;  &lt;p&gt;There’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/</guid><pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate></item><item><title>More details emerge on how Windsurf’s VCs and founders got paid from the Google deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225304419.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Weeks after the revelation that Google paid Windsurf $2.4 billion to license its technology, while simultaneously hiring away its CEO and top talent, the deal’s implications are still rattling some founders and startup employees across Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s payment to the startup was effectively split in two equal parts, according to two people familiar with the deal. Investors’ portion was $1.2 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The other half was in the form of compensation packages for approximately 40 Windsurf employees hired by the tech giant with a substantial portion of that $1.2 billion going to the startup’s co-founders, Varun Mohan and Douglas Chen, sources say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transaction was a good outcome for VCs, which included Greenoaks, Kleiner Perkins, and General Catalyst. Windsurf raised a total of about $243 million as of its last raise in 2024 that valued the company at $1.25 billion, which means the total return to investors was about 4x their original funding.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greenoaks, which led Windsurf’s seed and Series A financings and owned 20% of the company, returned about $500 million on their $65 million investment in the startup, according to a person familiar with the matter. Kleiner Perkins, which led Windsurf’s Series B, returned about 3x its invested capital, according to another person familiar with the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Kleiner Perkins, and Greenoaks declined to comment. General Catalyst, Varun Mohan, and Douglas Chen didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, most investors were aiming for a more significant win from the company.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In February, TechCrunch reported that Kleiner Perkins was in talks to lead a fresh round of funding, valuing the startup, which was then known as Codeium, at $2.85 billion. That deal didn’t happen, according to a person familiar with the matter, because Windsurf had instead agreed to be purchased by OpenAI for $3 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we all know now, the OpenAI acquisition unraveled and Google swooped in with its deal structured to offer investor returns and obtain talent and IP without acquiring stock.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what’s rattling the Valley is this: While Google’s deal was good for the co-founders and VCs, it didn’t benefit a large portion of Windsurf’s approximately 250 employees, especially after they were expecting a payout from the sale to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a typical acquisition, employees would get money for the shares they owned and would often have their vesting schedule accelerated. However, Windsurf employees who were hired over the last year didn’t receive a payout from the deal, these people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Google deal was especially unsettling to approximately 200 Windsurf employees not hired by the search giant.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of siphoning every penny of Google’s payment into their own pockets, investors opted to leave the company with over $100 million in capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One source says this was entirely funded by VCs, meaning their total payout was about $1.1 billion. However, another person said that the founders equally chipped in to leave the company with a nest egg from the Google payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple people said that the money left for the company would have been sufficient to pay all remaining employees proceeds at the Google deal’s per-share valuation, regardless of how long they had been with the company.&amp;nbsp; However, to have done that immediately would have been problematic, leaving the company with less cash to operate and — with founders and key people gone — with no investors ready to finance a new raise. The remaining leadership would likely have had to shut down after making such cash distributions, one of the people said. Meanwhile, another person claimed that the company had enough capital to pay out employees and continue to operate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That difference of opinion is only part of the reason the deal became so controversial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, at least some of the employees Google did hire, despite attractive pay and benefits, saw their stock grants revoked and their vesting timelines restarted. That meant they’d have to wait an additional four years for their total payout in Google stock, according to people familiar with the deal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some top VCs condemned the 3-year-old startup’s co-founders for not sharing their windfall with all the people who helped build the company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Windsurf and others are really bad examples of founders leaving their teams behind and not even sharing the proceeds with their team,” wrote Vinod Khosla on X. “I definitely would not work with their founders next time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After several days of limbo following the announcement of the Google deal, Windsurf’s remaining entity, under the leadership of interim CEO Jeff Wang, managed to sell itself to Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition acquired Windsurf’s IP and product and brought on all staff not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the exact deal terms of that sale were not disclosed, the acquisition allowed every employee to financially gain from the sale, according to a blog published by Cognition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two other sources estimated to TechCrunch that Cognition paid $250 million to acquire Windsurf’s remaining entity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition didn’t respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225304419.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Weeks after the revelation that Google paid Windsurf $2.4 billion to license its technology, while simultaneously hiring away its CEO and top talent, the deal’s implications are still rattling some founders and startup employees across Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s payment to the startup was effectively split in two equal parts, according to two people familiar with the deal. Investors’ portion was $1.2 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The other half was in the form of compensation packages for approximately 40 Windsurf employees hired by the tech giant with a substantial portion of that $1.2 billion going to the startup’s co-founders, Varun Mohan and Douglas Chen, sources say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transaction was a good outcome for VCs, which included Greenoaks, Kleiner Perkins, and General Catalyst. Windsurf raised a total of about $243 million as of its last raise in 2024 that valued the company at $1.25 billion, which means the total return to investors was about 4x their original funding.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greenoaks, which led Windsurf’s seed and Series A financings and owned 20% of the company, returned about $500 million on their $65 million investment in the startup, according to a person familiar with the matter. Kleiner Perkins, which led Windsurf’s Series B, returned about 3x its invested capital, according to another person familiar with the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Kleiner Perkins, and Greenoaks declined to comment. General Catalyst, Varun Mohan, and Douglas Chen didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, most investors were aiming for a more significant win from the company.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In February, TechCrunch reported that Kleiner Perkins was in talks to lead a fresh round of funding, valuing the startup, which was then known as Codeium, at $2.85 billion. That deal didn’t happen, according to a person familiar with the matter, because Windsurf had instead agreed to be purchased by OpenAI for $3 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we all know now, the OpenAI acquisition unraveled and Google swooped in with its deal structured to offer investor returns and obtain talent and IP without acquiring stock.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what’s rattling the Valley is this: While Google’s deal was good for the co-founders and VCs, it didn’t benefit a large portion of Windsurf’s approximately 250 employees, especially after they were expecting a payout from the sale to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a typical acquisition, employees would get money for the shares they owned and would often have their vesting schedule accelerated. However, Windsurf employees who were hired over the last year didn’t receive a payout from the deal, these people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Google deal was especially unsettling to approximately 200 Windsurf employees not hired by the search giant.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of siphoning every penny of Google’s payment into their own pockets, investors opted to leave the company with over $100 million in capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One source says this was entirely funded by VCs, meaning their total payout was about $1.1 billion. However, another person said that the founders equally chipped in to leave the company with a nest egg from the Google payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple people said that the money left for the company would have been sufficient to pay all remaining employees proceeds at the Google deal’s per-share valuation, regardless of how long they had been with the company.&amp;nbsp; However, to have done that immediately would have been problematic, leaving the company with less cash to operate and — with founders and key people gone — with no investors ready to finance a new raise. The remaining leadership would likely have had to shut down after making such cash distributions, one of the people said. Meanwhile, another person claimed that the company had enough capital to pay out employees and continue to operate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That difference of opinion is only part of the reason the deal became so controversial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, at least some of the employees Google did hire, despite attractive pay and benefits, saw their stock grants revoked and their vesting timelines restarted. That meant they’d have to wait an additional four years for their total payout in Google stock, according to people familiar with the deal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some top VCs condemned the 3-year-old startup’s co-founders for not sharing their windfall with all the people who helped build the company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Windsurf and others are really bad examples of founders leaving their teams behind and not even sharing the proceeds with their team,” wrote Vinod Khosla on X. “I definitely would not work with their founders next time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After several days of limbo following the announcement of the Google deal, Windsurf’s remaining entity, under the leadership of interim CEO Jeff Wang, managed to sell itself to Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition acquired Windsurf’s IP and product and brought on all staff not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the exact deal terms of that sale were not disclosed, the acquisition allowed every employee to financially gain from the sale, according to a blog published by Cognition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two other sources estimated to TechCrunch that Cognition paid $250 million to acquire Windsurf’s remaining entity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition didn’t respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/</guid><pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate></item><item><title>From Meta’s massive offers to Anthropic’s massive valuation, does AI have a ceiling? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/from-metas-massive-offers-to-anthropics-massive-valuation-does-ai-have-a-ceiling/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2154160973-e1723115200227.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Meta is still going all-in on the AI talent war, with Mark Zuckerberg reportedly reaching out to top recruits himself, throwing around jaw-dropping compensation packages that top $1 billion over multiple years. And Meta’s latest target? Mira Murati’s new startup, Thinking Machines Lab. It’s a bold play in an already overheated market.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;While Zuck eyes new talent, Anthropic is preparing to raise a massive round of its own at a staggering $170 billion valuation, nearly tripling its worth in just months. On paper, it looks like the AI cash floodgates are wide open. But all this endless money raises some serious questions about sustainability.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff unpack the reality behind these eye-popping figures. With compensation packages skyrocketing and funding rounds swelling, how long can this race actually last?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2154160973-e1723115200227.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Meta is still going all-in on the AI talent war, with Mark Zuckerberg reportedly reaching out to top recruits himself, throwing around jaw-dropping compensation packages that top $1 billion over multiple years. And Meta’s latest target? Mira Murati’s new startup, Thinking Machines Lab. It’s a bold play in an already overheated market.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;While Zuck eyes new talent, Anthropic is preparing to raise a massive round of its own at a staggering $170 billion valuation, nearly tripling its worth in just months. On paper, it looks like the AI cash floodgates are wide open. But all this endless money raises some serious questions about sustainability.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff unpack the reality behind these eye-popping figures. With compensation packages skyrocketing and funding rounds swelling, how long can this race actually last?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/from-metas-massive-offers-to-anthropics-massive-valuation-does-ai-have-a-ceiling/</guid><pubDate>Fri, 01 Aug 2025 16:12:39 +0000</pubDate></item><item><title>Amazon is considering shoving ads into Alexa+ conversations (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/amazon-is-considering-shoving-ads-into-alexa-conversations/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Amazon has failed to make Alexa profitable thus far.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alexa+ signage during an unveiling event in New York, US, on Wednesday, Feb. 26, 2025. Amazon has rebooted Alexa with artificial intelligence, marking the biggest overhaul of the voice-activated assistant since its introduction over a decade ago. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Michael Nagle/Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Since 2023, Amazon has been framing Alexa+ as a monumental evolution of Amazon’s voice assistant that will make it more conversational, capable, and, for Amazon, lucrative. Amazon said in a press release on Thursday that it has given early access of the generative AI voice assistant to “millions” of people. The product isn’t publicly available yet, and some advertised features are still unavailable, but Amazon’s CEO is already considering loading the chatbot up with ads.&lt;/p&gt;
&lt;p&gt;During an investors call yesterday, as reported by TechCrunch, Andy Jassy noted that Alexa+ started rolling out as early access to some customers in the US and that a broader rollout, including internationally, should happen later this year. An analyst on the call asked Amazon executives about Alexa+'s potential for “increasing engagement” long term.&lt;/p&gt;
&lt;p&gt;Per a transcript of the call, Jassy responded by saying, in part, "I think over time, there will be opportunities, you know, as people are engaging in more multi-turn conversations to have advertising play a role to help people find discovery and also as a lever to drive revenue."&lt;/p&gt;
&lt;p&gt;Like other voice assistants, Alexa has yet to monetize users. Amazon is hoping to finally make money off the service through Alexa+, which is eventually slated to play a bigger role in e-commerce, including by booking restaurant reservations, keeping track of and ordering groceries, and recommending streaming content based on stated interests. But with Alexa reportedly costing Amazon $25 billion across four years, Amazon is eyeing additional routes to profitability.&lt;/p&gt;
&lt;p&gt;Echo Show devices already show ads, and Echo speaker users may hear ads when listening to music. Advertisers have shown interest in advertising with Alexa+, but the inclusion of ads in a new offering like Alexa+ could drive people away.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Joel Daly, co-founder of marketing agency Artemis Ward, told Digiday in March:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;They [Amazon] recognize the risk of alienating audiences who have yet to see the full potential of voice assistants, which have yet to be fully realized, not to mention privacy concerns. The combination of tailored advertising with the perceived invasiveness of always-listening voice devices can discourage adoption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Even though Jassy framed Alexa+ ads as a way to help users find stuff they're interested in, ads seem more aimed at solving Amazon's financial problems with voice assistants than helping customers find relevant information quickly and reliably. Notably, though, Amazon isn't the only chatbot maker exploring ads: Google's AI Overview, for example, already has ads, and Google has been testing ads in AI Mode. OpenAI CEO Sam Altman hasn't ruled out ads in ChatGPT.&lt;/p&gt;
&lt;p&gt;But Alexa+ is still in the early stages, meaning that Amazon's bigger priorities are catching up with the competition, rolling out more of Alexa+'s promised features, and making the chatbot publicly available.&lt;/p&gt;
&lt;p&gt;Beyond ads, Jassy is mulling additional ways to prevent Alexa+ from being the financial failure of its predecessor. The service is still only available as early access to Echo Show 8, 15, and 21 owners in the US, but once it reaches public availability, it will be free for Amazon Prime subscribers (Prime starts at $15 per month) or $20/month if you don’t have Prime. During yesterday’s earnings call, Jassy pointed to the potential for charging extra for Alexa+ features as they are made available.&lt;/p&gt;
&lt;p&gt;"It’s still very early days, but we’re very encouraged by the experience we’re providing, and you can bet we’re gonna be iterating on it constantly,” he said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Amazon has failed to make Alexa profitable thus far.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alexa+ signage during an unveiling event in New York, US, on Wednesday, Feb. 26, 2025. Amazon has rebooted Alexa with artificial intelligence, marking the biggest overhaul of the voice-activated assistant since its introduction over a decade ago. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Michael Nagle/Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Since 2023, Amazon has been framing Alexa+ as a monumental evolution of Amazon’s voice assistant that will make it more conversational, capable, and, for Amazon, lucrative. Amazon said in a press release on Thursday that it has given early access of the generative AI voice assistant to “millions” of people. The product isn’t publicly available yet, and some advertised features are still unavailable, but Amazon’s CEO is already considering loading the chatbot up with ads.&lt;/p&gt;
&lt;p&gt;During an investors call yesterday, as reported by TechCrunch, Andy Jassy noted that Alexa+ started rolling out as early access to some customers in the US and that a broader rollout, including internationally, should happen later this year. An analyst on the call asked Amazon executives about Alexa+'s potential for “increasing engagement” long term.&lt;/p&gt;
&lt;p&gt;Per a transcript of the call, Jassy responded by saying, in part, "I think over time, there will be opportunities, you know, as people are engaging in more multi-turn conversations to have advertising play a role to help people find discovery and also as a lever to drive revenue."&lt;/p&gt;
&lt;p&gt;Like other voice assistants, Alexa has yet to monetize users. Amazon is hoping to finally make money off the service through Alexa+, which is eventually slated to play a bigger role in e-commerce, including by booking restaurant reservations, keeping track of and ordering groceries, and recommending streaming content based on stated interests. But with Alexa reportedly costing Amazon $25 billion across four years, Amazon is eyeing additional routes to profitability.&lt;/p&gt;
&lt;p&gt;Echo Show devices already show ads, and Echo speaker users may hear ads when listening to music. Advertisers have shown interest in advertising with Alexa+, but the inclusion of ads in a new offering like Alexa+ could drive people away.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Joel Daly, co-founder of marketing agency Artemis Ward, told Digiday in March:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;They [Amazon] recognize the risk of alienating audiences who have yet to see the full potential of voice assistants, which have yet to be fully realized, not to mention privacy concerns. The combination of tailored advertising with the perceived invasiveness of always-listening voice devices can discourage adoption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Even though Jassy framed Alexa+ ads as a way to help users find stuff they're interested in, ads seem more aimed at solving Amazon's financial problems with voice assistants than helping customers find relevant information quickly and reliably. Notably, though, Amazon isn't the only chatbot maker exploring ads: Google's AI Overview, for example, already has ads, and Google has been testing ads in AI Mode. OpenAI CEO Sam Altman hasn't ruled out ads in ChatGPT.&lt;/p&gt;
&lt;p&gt;But Alexa+ is still in the early stages, meaning that Amazon's bigger priorities are catching up with the competition, rolling out more of Alexa+'s promised features, and making the chatbot publicly available.&lt;/p&gt;
&lt;p&gt;Beyond ads, Jassy is mulling additional ways to prevent Alexa+ from being the financial failure of its predecessor. The service is still only available as early access to Echo Show 8, 15, and 21 owners in the US, but once it reaches public availability, it will be free for Amazon Prime subscribers (Prime starts at $15 per month) or $20/month if you don’t have Prime. During yesterday’s earnings call, Jassy pointed to the potential for charging extra for Alexa+ features as they are made available.&lt;/p&gt;
&lt;p&gt;"It’s still very early days, but we’re very encouraged by the experience we’re providing, and you can bet we’re gonna be iterating on it constantly,” he said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/amazon-is-considering-shoving-ads-into-alexa-conversations/</guid><pubDate>Fri, 01 Aug 2025 17:04:39 +0000</pubDate></item><item><title>Google bets on STAN, an Indian social gaming platform (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/google-bets-on-stan-an-indian-social-gaming-platform/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has backed STAN, an Indian social gaming platform that connects gamers with creators, communities, and publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s investment comes as part of an $8.5 million equity funding round, which also saw investment from Japanese gaming giants Bandai Namco Entertainment, Square Enix, and Reazon Holdings. Aptos Labs and King River Capital, as well as existing backers General Catalyst and GFR Fund, also participated. Google joined the round via its AI Futures Fund, which launched in May to support startups building with its AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different. STAN lets users earn in-app currency called “Gems” by winning games like Krafton’s Battlegrounds Mobile India, Garena’s Free Fire Max, Minecraft, Call of Duty, or casual titles like Ludo and Snakes &amp;amp; Ladders. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app also lets creators set up chat rooms called Clubs, which are channels tailored for each game on the platform. While anyone can join these Clubs, they need to pay a social currency to access the “gaming experiences” that creators offer. The startup takes a commission from these transactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The primary attraction seems to be the in-app currency, however, as it can be redeemed for vouchers on various e-commerce platforms like Amazon, PhonePe, and Flipkart. Users can also earn currency via referrals, a spin-to-win wheel, and daily rewards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears STAN’s monetization model is what sets it apart: Users can earn rewards through interactions, unlike on Discord, where chatting or participating in communities doesn’t earn users much, apart from clout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, STAN wants to shadow Discord. The company claims it has already garnered over 25 million downloads on the Play Store and App Store altogether, and it has around 5.5 million monthly active users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3032909" height="1300" src="https://techcrunch.com/wp-content/uploads/2025/07/stan-communities.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;STAN&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“STAN is the hangout place for gamers. It’s a place where gamers come and make friends, play with each other, talk to each other, sort of a fusion of social and gaming,” said Parth Chadha, co-founder and CEO of STAN, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chadha credits the platform’s features for its traction so far. Initially, creators had to contact the company’s team to start streaming, but last year, the startup opened the platform to user-generated content, allowing anyone to go live. That shift helped drive both downloads and engagement, the CEO said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN also works with game publishers, studios, and developers, including Krafton, Garena, and Roblox, who pay the startup to connect them with gamers and creators on the platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Chadha told TechCrunch that in the past two quarters, nearly 100 game publishers, studios, and developers have joined the platform, and it is bringing more than 20 on board each month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That is turning into a very interesting business stream as we speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Looking ahead, STAN plans to leverage Google’s backing to use AI to improve moderation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently 70% to 80% of moderation on STAN is already handled by AI, Chadha said. A human moderation team manages the rest, but the startup plans to reduce that further by using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, STAN aims to bring AI-powered toolkits for creators, including the ability to produce avatars and memes, as well as tools for quick replies and filtering out chats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are a lot of interesting plug-and-play models, which we and the Google team are working together to leverage and scale the business,” he stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN isn’t the first Indian startup to be backed by Google’s AI Futures Fund. That distinction goes to Toonsutra, a startup using AI to power an immersive comic-reading experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it has invested over $5.5 billion in India to date, including in startups Toonsutra, STAN, Pixxel, and Adda247.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although STAN’s app is currently geo-restricted to India, the platform still sees 5% to 6% of its engagement coming from users abroad, who often access it using Indian phone numbers and accounts. Over the next year, the startup plans to expand internationally, starting with the Indian subcontinent, and will later target Southeast Asia and Latin America.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was profitable for a few months, the CEO said, but decided to spend some money to scale. Now it aims to achieve profitability in 2027, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup employs about 40 people; less than 30 of them work in product engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With this raise, STAN’s total equity funding now stands at around $15 million.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has backed STAN, an Indian social gaming platform that connects gamers with creators, communities, and publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s investment comes as part of an $8.5 million equity funding round, which also saw investment from Japanese gaming giants Bandai Namco Entertainment, Square Enix, and Reazon Holdings. Aptos Labs and King River Capital, as well as existing backers General Catalyst and GFR Fund, also participated. Google joined the round via its AI Futures Fund, which launched in May to support startups building with its AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different. STAN lets users earn in-app currency called “Gems” by winning games like Krafton’s Battlegrounds Mobile India, Garena’s Free Fire Max, Minecraft, Call of Duty, or casual titles like Ludo and Snakes &amp;amp; Ladders. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app also lets creators set up chat rooms called Clubs, which are channels tailored for each game on the platform. While anyone can join these Clubs, they need to pay a social currency to access the “gaming experiences” that creators offer. The startup takes a commission from these transactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The primary attraction seems to be the in-app currency, however, as it can be redeemed for vouchers on various e-commerce platforms like Amazon, PhonePe, and Flipkart. Users can also earn currency via referrals, a spin-to-win wheel, and daily rewards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears STAN’s monetization model is what sets it apart: Users can earn rewards through interactions, unlike on Discord, where chatting or participating in communities doesn’t earn users much, apart from clout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, STAN wants to shadow Discord. The company claims it has already garnered over 25 million downloads on the Play Store and App Store altogether, and it has around 5.5 million monthly active users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3032909" height="1300" src="https://techcrunch.com/wp-content/uploads/2025/07/stan-communities.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;STAN&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“STAN is the hangout place for gamers. It’s a place where gamers come and make friends, play with each other, talk to each other, sort of a fusion of social and gaming,” said Parth Chadha, co-founder and CEO of STAN, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chadha credits the platform’s features for its traction so far. Initially, creators had to contact the company’s team to start streaming, but last year, the startup opened the platform to user-generated content, allowing anyone to go live. That shift helped drive both downloads and engagement, the CEO said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN also works with game publishers, studios, and developers, including Krafton, Garena, and Roblox, who pay the startup to connect them with gamers and creators on the platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Chadha told TechCrunch that in the past two quarters, nearly 100 game publishers, studios, and developers have joined the platform, and it is bringing more than 20 on board each month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That is turning into a very interesting business stream as we speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Looking ahead, STAN plans to leverage Google’s backing to use AI to improve moderation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently 70% to 80% of moderation on STAN is already handled by AI, Chadha said. A human moderation team manages the rest, but the startup plans to reduce that further by using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, STAN aims to bring AI-powered toolkits for creators, including the ability to produce avatars and memes, as well as tools for quick replies and filtering out chats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are a lot of interesting plug-and-play models, which we and the Google team are working together to leverage and scale the business,” he stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN isn’t the first Indian startup to be backed by Google’s AI Futures Fund. That distinction goes to Toonsutra, a startup using AI to power an immersive comic-reading experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it has invested over $5.5 billion in India to date, including in startups Toonsutra, STAN, Pixxel, and Adda247.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although STAN’s app is currently geo-restricted to India, the platform still sees 5% to 6% of its engagement coming from users abroad, who often access it using Indian phone numbers and accounts. Over the next year, the startup plans to expand internationally, starting with the Indian subcontinent, and will later target Southeast Asia and Latin America.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was profitable for a few months, the CEO said, but decided to spend some money to scale. Now it aims to achieve profitability in 2027, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup employs about 40 people; less than 30 of them work in product engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With this raise, STAN’s total equity funding now stands at around $15 million.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/google-bets-on-stan-an-indian-social-gaming-platform/</guid><pubDate>Fri, 01 Aug 2025 17:05:45 +0000</pubDate></item><item><title>ChatGPT users shocked to learn their chats were in Google search results (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/chatgpt-users-shocked-to-learn-their-chats-were-in-google-search-results/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI scrambles to remove personal ChatGPT conversations from Google results.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tim Robberts | Photodisc

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Faced with mounting backlash, OpenAI removed a controversial ChatGPT feature that caused some users to unintentionally allow their private—and highly personal—chats to appear in search results.&lt;/p&gt;
&lt;p&gt;Fast Company exposed the privacy issue on Wednesday, reporting that thousands of ChatGPT conversations were found in Google search results and likely only represented a sample of chats "visible to millions." While the indexing did not include identifying information about the ChatGPT users, some of their chats did share personal details—like highly specific descriptions of interpersonal relationships with friends and family members—perhaps making it possible to identify them, Fast Company found.&lt;/p&gt;
&lt;p&gt;OpenAI's chief information security officer, Dane Stuckey, explained on X that all users whose chats were exposed opted in to indexing their chats by clicking a box after choosing to share a chat.&lt;/p&gt;
&lt;p&gt;Fast Company noted that users often share chats on WhatsApp or select the option to save a link to visit the chat later. But as Fast Company explained, users may have been misled into sharing chats due to how the text was formatted:&lt;/p&gt;
&lt;p&gt;"When users clicked 'Share,' they were presented with an option to tick a box labeled 'Make this chat discoverable.' Beneath that, in smaller, lighter text, was a caveat explaining that the chat could then appear in search engine results."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109797 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none medium" height="452" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ChatGPT-Share-box-via-Dane-Stuckey-on-X-640x452.jpeg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          ChatGPT Share box via Dane Stuckey on X

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At first, OpenAI defended the labeling as "sufficiently clear," Fast Company reported Thursday. But Stuckey confirmed that "ultimately," the AI company decided that the feature "introduced too many opportunities for folks to accidentally share things they didn't intend to." According to Fast Company, that included chats about their drug use, sex lives, mental health, and traumatic experiences.&lt;/p&gt;
&lt;p&gt;Carissa Veliz, an AI ethicist at the University of Oxford, told Fast Company she was "shocked" that Google was logging "these extremely sensitive conversations."&lt;/p&gt;
&lt;h2&gt;OpenAI promises to remove Google search results&lt;/h2&gt;
&lt;p&gt;Stuckey called the feature a "short-lived experiment" that OpenAI launched "to help people discover useful conversations." He confirmed that the decision to remove the feature also included an effort to "remove indexed content from the relevant search engine" through Friday morning.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google did not respond to Fast Company's reporting, which left it unclear what role it played in how chats were displayed in search results. But a spokesperson told Ars that OpenAI was fully responsible for the indexing, clarifying that "neither Google nor any other search engine controls what pages are made public on the web. Publishers of these pages have full control over whether they are indexed by search engines."&lt;/p&gt;
&lt;p&gt;OpenAI is seemingly also solely responsible for removing the chats, perhaps most quickly by using a tool that Google provides to block pages from appearing in search results. But that tool does not stop pages from being indexed by other search engines, so it's possible chats will disappear sooner in Google results than other search engines.&lt;/p&gt;
&lt;p&gt;Véliz told Fast Company that even a "short-lived" experiment like this is "troubling," noting that "tech companies use the general population as guinea pigs," attracting swarms of users with new AI products and waiting to see what consequences they may face for invasive design choices.&lt;/p&gt;
&lt;p&gt;"They do something, they try it out on the population, and see if somebody complains," Véliz said.&lt;/p&gt;
&lt;p&gt;To check if private chats are still being indexed, a Fast Company explanation suggests that users who still have access to their shared links can try inputting the "part of the link created when someone proactively clicks 'Share' on ChatGPT [to] uncover conversations" that may still be discoverable on Google.&lt;/p&gt;
&lt;p&gt;OpenAI declined Ars' request to comment, but Stuckey's statement suggested that the company knows it has to earn back trust after the misstep.&lt;/p&gt;
&lt;p&gt;"Security and privacy are paramount for us, and we'll keep working to maximally reflect that in our products and features," Stuckey said.&lt;/p&gt;
&lt;p&gt;The scandal notably comes after OpenAI vowed to fight a court order that requires it to preserve all deleted chats "indefinitely," which worries ChatGPT users who previously felt assured their temporary and deleted chats were not being saved. OpenAI has so far lost that fight, and those chats will likely be searchable soon in that lawsuit. But while OpenAI CEO Sam Altman considered the possibility that users' most private chats could be searched to be "screwed up," Fast Company noted that Altman did not seem to be as transparently critical about the potential for OpenAI's own practices to expose private user chats on Google and other search engines.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI scrambles to remove personal ChatGPT conversations from Google results.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tim Robberts | Photodisc

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Faced with mounting backlash, OpenAI removed a controversial ChatGPT feature that caused some users to unintentionally allow their private—and highly personal—chats to appear in search results.&lt;/p&gt;
&lt;p&gt;Fast Company exposed the privacy issue on Wednesday, reporting that thousands of ChatGPT conversations were found in Google search results and likely only represented a sample of chats "visible to millions." While the indexing did not include identifying information about the ChatGPT users, some of their chats did share personal details—like highly specific descriptions of interpersonal relationships with friends and family members—perhaps making it possible to identify them, Fast Company found.&lt;/p&gt;
&lt;p&gt;OpenAI's chief information security officer, Dane Stuckey, explained on X that all users whose chats were exposed opted in to indexing their chats by clicking a box after choosing to share a chat.&lt;/p&gt;
&lt;p&gt;Fast Company noted that users often share chats on WhatsApp or select the option to save a link to visit the chat later. But as Fast Company explained, users may have been misled into sharing chats due to how the text was formatted:&lt;/p&gt;
&lt;p&gt;"When users clicked 'Share,' they were presented with an option to tick a box labeled 'Make this chat discoverable.' Beneath that, in smaller, lighter text, was a caveat explaining that the chat could then appear in search engine results."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109797 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none medium" height="452" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ChatGPT-Share-box-via-Dane-Stuckey-on-X-640x452.jpeg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          ChatGPT Share box via Dane Stuckey on X

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At first, OpenAI defended the labeling as "sufficiently clear," Fast Company reported Thursday. But Stuckey confirmed that "ultimately," the AI company decided that the feature "introduced too many opportunities for folks to accidentally share things they didn't intend to." According to Fast Company, that included chats about their drug use, sex lives, mental health, and traumatic experiences.&lt;/p&gt;
&lt;p&gt;Carissa Veliz, an AI ethicist at the University of Oxford, told Fast Company she was "shocked" that Google was logging "these extremely sensitive conversations."&lt;/p&gt;
&lt;h2&gt;OpenAI promises to remove Google search results&lt;/h2&gt;
&lt;p&gt;Stuckey called the feature a "short-lived experiment" that OpenAI launched "to help people discover useful conversations." He confirmed that the decision to remove the feature also included an effort to "remove indexed content from the relevant search engine" through Friday morning.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google did not respond to Fast Company's reporting, which left it unclear what role it played in how chats were displayed in search results. But a spokesperson told Ars that OpenAI was fully responsible for the indexing, clarifying that "neither Google nor any other search engine controls what pages are made public on the web. Publishers of these pages have full control over whether they are indexed by search engines."&lt;/p&gt;
&lt;p&gt;OpenAI is seemingly also solely responsible for removing the chats, perhaps most quickly by using a tool that Google provides to block pages from appearing in search results. But that tool does not stop pages from being indexed by other search engines, so it's possible chats will disappear sooner in Google results than other search engines.&lt;/p&gt;
&lt;p&gt;Véliz told Fast Company that even a "short-lived" experiment like this is "troubling," noting that "tech companies use the general population as guinea pigs," attracting swarms of users with new AI products and waiting to see what consequences they may face for invasive design choices.&lt;/p&gt;
&lt;p&gt;"They do something, they try it out on the population, and see if somebody complains," Véliz said.&lt;/p&gt;
&lt;p&gt;To check if private chats are still being indexed, a Fast Company explanation suggests that users who still have access to their shared links can try inputting the "part of the link created when someone proactively clicks 'Share' on ChatGPT [to] uncover conversations" that may still be discoverable on Google.&lt;/p&gt;
&lt;p&gt;OpenAI declined Ars' request to comment, but Stuckey's statement suggested that the company knows it has to earn back trust after the misstep.&lt;/p&gt;
&lt;p&gt;"Security and privacy are paramount for us, and we'll keep working to maximally reflect that in our products and features," Stuckey said.&lt;/p&gt;
&lt;p&gt;The scandal notably comes after OpenAI vowed to fight a court order that requires it to preserve all deleted chats "indefinitely," which worries ChatGPT users who previously felt assured their temporary and deleted chats were not being saved. OpenAI has so far lost that fight, and those chats will likely be searchable soon in that lawsuit. But while OpenAI CEO Sam Altman considered the possibility that users' most private chats could be searched to be "screwed up," Fast Company noted that Altman did not seem to be as transparently critical about the potential for OpenAI's own practices to expose private user chats on Google and other search engines.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/chatgpt-users-shocked-to-learn-their-chats-were-in-google-search-results/</guid><pubDate>Fri, 01 Aug 2025 17:21:54 +0000</pubDate></item><item><title>[NEW] Delta denies using AI to come up with inflated, personalized prices (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/delta-denies-using-ai-to-come-up-with-inflated-personalized-prices/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Delta finally explains how its AI pricing works amid ongoing backlash.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Delta spent July dealing with backlash over what the airline company claims is widespread public confusion over its AI pricing system.&lt;/p&gt;
&lt;p&gt;Now, Delta has finally come forward to break down precisely how the AI pricing works to dispute what it claims are "incorrect" characterizations by consumer watchdogs, lawmakers, and media outlets.&lt;/p&gt;
&lt;p&gt;In a letter to lawmakers who accused Delta of using AI to spy on customers' personal data in order to "jack up" prices, Delta insisted that "there is no fare product Delta has ever used, is testing, or plans to use that targets customers with individualized prices based on personal data."&lt;/p&gt;
&lt;p&gt;Confusion arose after Delta Air Lines President Glen William Hauenstein discussed the AI pricing on a summer earnings call. Hauenstein hyped the AI pricing as working to propel revenue, confirming that about 3 percent of domestic flights were sold using the AI pricing system over the past six months and that Delta planned to expand that to 20 percent of tickets by the end of the year.&lt;/p&gt;
&lt;p&gt;Critics demanded transparency, raising concerns that Delta's AI pricing could lead to discriminatory pricing based on a customer's search history or prior purchases. But Delta did not rush to clarify how its AI pricing actually works until lawmakers sent a letter probing Delta's AI practices. Those lawmakers had just announced the Stop AI Price Gouging and Wage Fixing Act, with a press release that called out Delta among companies whose AI pricing models needed to be banned to prevent surveillance pricing that lawmakers fear will disproportionately disrupt fair pricing for the least wealthy.&lt;/p&gt;
&lt;p&gt;Responding, Delta's chief external affairs officer, Peter Carter, thanked lawmakers for their "thoughtful questions regarding Delta’s use of AI," then cautioned them against making assumptions about Delta's AI pricing.&lt;/p&gt;
&lt;p&gt;"Your letter presupposes that we are using, and intend to use, AI for 'individualized' pricing or 'surveillance' pricing, leveraging consumer-specific personal data, such as sensitive personal circumstances or prior purchasing activity to set individualized prices," Carter said. "To clarify, this is incorrect and this assumption, unfortunately, has created confusion and misinformation in the public discourse."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Delta scandal highlights value of transparency&lt;/h2&gt;
&lt;p&gt;According to Delta, the company has "zero tolerance for discriminatory or predatory pricing" and only feeds its AI system aggregated data "to enhance our existing fare pricing processes."&lt;/p&gt;
&lt;p&gt;Rather than basing fare prices on customers' personal information, Carter clarified that "all customers have access to the same fares and offers based on objective criteria provided by the customer such as origin and destination, advance purchase, length of stay, refundability, and travel experience selected."&lt;/p&gt;
&lt;p&gt;The AI use can result in higher or lower prices, but not personalized fares for different customers, Carter said. Instead, Delta plans to use AI pricing to "enhance market competitiveness and drive sales, benefiting both our customers and our business."&lt;/p&gt;
&lt;p&gt;Factors weighed by the AI system, Carter explained, include "customer demand for seats and purchasing data at an aggregated level, competitive offers and schedules, route performance, and cost of providing the service inclusive of jet fuel." That could potentially mean a rival's promotion or schedule change could trigger the AI system to lower prices to stay competitive, or it might increase prices based on rising fuel costs to help increase revenue or meet business goals.&lt;/p&gt;
&lt;p&gt;"Given the tens of millions of fares and hundreds of thousands of routes for sale at any given time, the use of new technology like AI promises to streamline the process by which we analyze existing data and the speed and scale at which we can respond to changing market dynamics," Carter wrote.&lt;/p&gt;
&lt;p&gt;He explained the AI system helps Delta aggregate purchasing data for specific routes and flights, adapt to new market conditions, and factor in "thousands of variables simultaneously." AI could also eventually be used to assist with crew scheduling, improve flight availability, or help reservation specialists answer complex questions or resolve disputes.&lt;/p&gt;
&lt;p&gt;But "to reiterate, prices are not targeted to individual consumers," Carter emphasized.&lt;/p&gt;
&lt;p&gt;Delta further pointed out that the company does not require customers to log in to search for tickets, which means customers can search for flights without sharing any personal information.&lt;/p&gt;
&lt;p&gt;For AI companies paying attention to the Delta backlash, there may be a lesson about the value of transparency in Delta's scandal. Critics noted Delta was among the first to admit it was using AI to influence pricing, but the vague explanation on the earnings call stoked confusion over how, as Delta seemed to drag its feet amid calls by groups like Consumer Watchdog for more transparency.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Delta finally explains how its AI pricing works amid ongoing backlash.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1166089759-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Delta spent July dealing with backlash over what the airline company claims is widespread public confusion over its AI pricing system.&lt;/p&gt;
&lt;p&gt;Now, Delta has finally come forward to break down precisely how the AI pricing works to dispute what it claims are "incorrect" characterizations by consumer watchdogs, lawmakers, and media outlets.&lt;/p&gt;
&lt;p&gt;In a letter to lawmakers who accused Delta of using AI to spy on customers' personal data in order to "jack up" prices, Delta insisted that "there is no fare product Delta has ever used, is testing, or plans to use that targets customers with individualized prices based on personal data."&lt;/p&gt;
&lt;p&gt;Confusion arose after Delta Air Lines President Glen William Hauenstein discussed the AI pricing on a summer earnings call. Hauenstein hyped the AI pricing as working to propel revenue, confirming that about 3 percent of domestic flights were sold using the AI pricing system over the past six months and that Delta planned to expand that to 20 percent of tickets by the end of the year.&lt;/p&gt;
&lt;p&gt;Critics demanded transparency, raising concerns that Delta's AI pricing could lead to discriminatory pricing based on a customer's search history or prior purchases. But Delta did not rush to clarify how its AI pricing actually works until lawmakers sent a letter probing Delta's AI practices. Those lawmakers had just announced the Stop AI Price Gouging and Wage Fixing Act, with a press release that called out Delta among companies whose AI pricing models needed to be banned to prevent surveillance pricing that lawmakers fear will disproportionately disrupt fair pricing for the least wealthy.&lt;/p&gt;
&lt;p&gt;Responding, Delta's chief external affairs officer, Peter Carter, thanked lawmakers for their "thoughtful questions regarding Delta’s use of AI," then cautioned them against making assumptions about Delta's AI pricing.&lt;/p&gt;
&lt;p&gt;"Your letter presupposes that we are using, and intend to use, AI for 'individualized' pricing or 'surveillance' pricing, leveraging consumer-specific personal data, such as sensitive personal circumstances or prior purchasing activity to set individualized prices," Carter said. "To clarify, this is incorrect and this assumption, unfortunately, has created confusion and misinformation in the public discourse."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Delta scandal highlights value of transparency&lt;/h2&gt;
&lt;p&gt;According to Delta, the company has "zero tolerance for discriminatory or predatory pricing" and only feeds its AI system aggregated data "to enhance our existing fare pricing processes."&lt;/p&gt;
&lt;p&gt;Rather than basing fare prices on customers' personal information, Carter clarified that "all customers have access to the same fares and offers based on objective criteria provided by the customer such as origin and destination, advance purchase, length of stay, refundability, and travel experience selected."&lt;/p&gt;
&lt;p&gt;The AI use can result in higher or lower prices, but not personalized fares for different customers, Carter said. Instead, Delta plans to use AI pricing to "enhance market competitiveness and drive sales, benefiting both our customers and our business."&lt;/p&gt;
&lt;p&gt;Factors weighed by the AI system, Carter explained, include "customer demand for seats and purchasing data at an aggregated level, competitive offers and schedules, route performance, and cost of providing the service inclusive of jet fuel." That could potentially mean a rival's promotion or schedule change could trigger the AI system to lower prices to stay competitive, or it might increase prices based on rising fuel costs to help increase revenue or meet business goals.&lt;/p&gt;
&lt;p&gt;"Given the tens of millions of fares and hundreds of thousands of routes for sale at any given time, the use of new technology like AI promises to streamline the process by which we analyze existing data and the speed and scale at which we can respond to changing market dynamics," Carter wrote.&lt;/p&gt;
&lt;p&gt;He explained the AI system helps Delta aggregate purchasing data for specific routes and flights, adapt to new market conditions, and factor in "thousands of variables simultaneously." AI could also eventually be used to assist with crew scheduling, improve flight availability, or help reservation specialists answer complex questions or resolve disputes.&lt;/p&gt;
&lt;p&gt;But "to reiterate, prices are not targeted to individual consumers," Carter emphasized.&lt;/p&gt;
&lt;p&gt;Delta further pointed out that the company does not require customers to log in to search for tickets, which means customers can search for flights without sharing any personal information.&lt;/p&gt;
&lt;p&gt;For AI companies paying attention to the Delta backlash, there may be a lesson about the value of transparency in Delta's scandal. Critics noted Delta was among the first to admit it was using AI to influence pricing, but the vague explanation on the earnings call stoked confusion over how, as Delta seemed to drag its feet amid calls by groups like Consumer Watchdog for more transparency.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/delta-denies-using-ai-to-come-up-with-inflated-personalized-prices/</guid><pubDate>Fri, 01 Aug 2025 19:07:48 +0000</pubDate></item><item><title>[NEW] A backlog at the Commerce Department is reportedly stalling Nvidia’s H20 chip licenses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/a-backlog-at-the-commerce-department-is-reportedly-stalling-nvidias-h20-chip-licenses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier in July, U.S. Secretary of Commerce Howard Lutnick gave chipmakers like Nvidia the green light to start selling certain AI chips in China again, but his department is said to be holding things up. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from Reuters, Nvidia has yet to receive a license to sell its H20 AI chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is currently sitting on a backlog of licensing applications due to turmoil within the department, in large part because of a loss of staff and a breakdown in communications with the industry, per Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This holdup comes as national security experts are urging the Trump administration to restrict Nvidia from selling its H20 AI chips to China on national security grounds.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier in July, U.S. Secretary of Commerce Howard Lutnick gave chipmakers like Nvidia the green light to start selling certain AI chips in China again, but his department is said to be holding things up. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from Reuters, Nvidia has yet to receive a license to sell its H20 AI chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is currently sitting on a backlog of licensing applications due to turmoil within the department, in large part because of a loss of staff and a breakdown in communications with the industry, per Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This holdup comes as national security experts are urging the Trump administration to restrict Nvidia from selling its H20 AI chips to China on national security grounds.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/a-backlog-at-the-commerce-department-is-reportedly-stalling-nvidias-h20-chip-licenses/</guid><pubDate>Fri, 01 Aug 2025 20:30:14 +0000</pubDate></item><item><title>[NEW] At $250 million, top AI salaries dwarf those of the Manhattan Project and the Space Race (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand holding lots of dollar notes" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand holding lots of dollar notes" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Paper Boat Creative via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Silicon Valley's AI talent war just reached a compensation milestone that makes even the most legendary scientific achievements of the past look financially modest. When Meta recently offered AI researcher Matt Deitke $250 million over four years (an average of $62.5 million per year)—with potentially $100 million in the first year alone—it shattered every historical precedent for scientific and technical compensation we can find on record. That includes salaries during the development of major scientific milestones of the 20th century.&lt;/p&gt;
&lt;p&gt;The New York Times reported that Deitke had cofounded a startup called Vercept and previously led the development of Molmo, a multimodal AI system, at the Allen Institute for Artificial Intelligence. His expertise in systems that juggle images, sounds, and text—exactly the kind of technology Meta wants to build—made him a prime target for recruitment. But he's not alone: Meta CEO Mark Zuckerberg reportedly also offered an unnamed AI engineer $1 billion in compensation to be paid out over several years. What's going on?&lt;/p&gt;
&lt;p&gt;These astronomical sums reflect what tech companies believe is at stake: a race to create artificial general intelligence (AGI) or superintelligence—machines capable of performing intellectual tasks at or beyond the human level. Meta, Google, OpenAI, and others are betting that whoever achieves this breakthrough first could dominate markets worth trillions. Whether this vision is realistic or merely Silicon Valley hype, it's driving compensation to unprecedented levels.&lt;/p&gt;
&lt;p&gt;To put these salaries in a historical perspective: J. Robert Oppenheimer, who led the Manhattan Project that ended World War II, earned approximately $10,000 per year in 1943. Adjusted for inflation using the US Government's CPI Inflation Calculator, that's about $190,865 in today's dollars—roughly what a senior software engineer makes today. The 24-year-old Deitke, who recently dropped out of a PhD program, will earn approximately 327 times what Oppenheimer made while developing the atomic bomb.&lt;/p&gt;
&lt;p&gt;Many top athletes can't compete with these numbers. The New York Times noted that Steph Curry's most recent four-year contract with the Golden State Warriors was $35 million less than Deitke's Meta deal (although soccer superstar Cristiano Ronaldo will make $275 million this year as the highest-paid professional athlete in the world).&amp;nbsp; The comparison prompted observers to call this an "NBA-style" talent market—except the AI researchers are making more than NBA stars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Racing toward “superintelligence”&lt;/h2&gt;
&lt;p&gt;Mark Zuckerberg recently told investors that Meta plans to continue throwing money at AI talent "because we have conviction that superintelligence is going to improve every aspect of what we do." In a recent open letter, he described superintelligent AI as technology that would "begin an exciting new era of individual empowerment," despite declining to define what superintelligence actually is.&lt;/p&gt;
&lt;p&gt;This vision explains why companies treat AI researchers like irreplaceable assets rather than well-compensated professionals. If these companies are correct, the first to achieve artificial general intelligence or superintelligence won't just have a better product—they'll have technology that could invent endless new products or automate away millions of knowledge-worker jobs and transform the global economy. The company that controls that kind of technology could become the richest company in history by far.&lt;/p&gt;
&lt;p&gt;So perhaps it's not surprising that even the highest salaries of employees from the early tech era pale in comparison to today's AI researcher salaries. Thomas Watson Sr., IBM's legendary CEO, received $517,221 in 1941—the third-highest salary in America at the time (about $11.8 million in 2025 dollars). The modern AI researcher's package represents more than five times Watson's peak compensation, despite Watson building one of the 20th century's most dominant technology companies.&lt;/p&gt;
&lt;p&gt;The contrast becomes even more stark when considering the collaborative nature of past scientific achievements. During Bell Labs' golden age of innovation—when researchers developed the transistor, information theory, and other foundational technologies—the lab's director made about 12 times what the lowest-paid worker earned.&amp;nbsp; Meanwhile, Claude Shannon, who created information theory at Bell Labs in 1948, worked on a standard professional salary while creating the mathematical foundation for all modern communication.&lt;/p&gt;
&lt;p&gt;The "Traitorous Eight" who left William Shockley to found Fairchild Semiconductor—the company that essentially birthed Silicon Valley—split ownership of just 800 shares out of 1,325 total when they started. Their seed funding of $1.38 million (about $16.1 million today) for the entire company is a fraction of what a single AI researcher now commands.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Even Space Race salaries were far cheaper&lt;/h2&gt;
&lt;p&gt;The Apollo program offers another striking comparison. Neil Armstrong, the first human to walk on the moon, earned about $27,000 annually—roughly $244,639 in today's money. His crewmates Buzz Aldrin and Michael Collins made even less, earning the equivalent of $168,737 and $155,373, respectively, in today's dollars. Current NASA astronauts earn between $104,898 and $161,141 per year. Meta's AI researcher will make more in three days than Armstrong made in a year for taking "one giant leap for mankind."&lt;/p&gt;
&lt;p&gt;The engineers who designed the rockets and mission control systems for the Apollo program also earned modest salaries by modern standards. A 1970 NASA technical report provides a window into these earnings by analyzing salary data for the entire engineering profession. The report, which used data from the Engineering Manpower Commission, noted that these industry-wide salary curves corresponded directly to the government's General Schedule (GS) pay scale on which NASA's own employees were paid.&lt;/p&gt;
&lt;p&gt;According to a chart in the 1970 report, a newly graduated engineer in 1966 started with an annual salary of between $8,500 and $10,000 (about $84,622 to $99,555 today). A typical engineer with a decade of experience earned around $17,000 annually ($169,244 today). Even the most elite, top-performing engineers with 20 years of experience peaked at a salary of around $278,000 per year in today's dollars—a sum that a top AI researcher like Deitke can now earn in just a few days.&lt;/p&gt;
&lt;h2&gt;Why the AI talent market is different&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2103443 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An image of a faceless human silhouette (chest up) with exposed microchip contacts and circuitry erupting from its open head. This visual metaphor explores transhumanism, AI integration, or the erosion of organic thought in the digital age. The stark contrast between the biological silhouette and mechanical components highlights themes of technological dependence or posthuman evolution. Ideal for articles on neural implants, futurism, or the ethics of human augmentation." class="center large" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2214539478-1024x640.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Boris Zhitkov via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn't the first time technical talent has commanded premium prices. In 2012, after three University of Toronto academics published AI research, they auctioned themselves to Google for $44 million (about $62.6 million in today's dollars). By 2014, a Microsoft executive was comparing AI researcher salaries to NFL quarterback contracts. But today's numbers dwarf even those precedents.&lt;/p&gt;
&lt;p&gt;Several factors explain this unprecedented compensation explosion. We're in a new realm of industrial wealth concentration unseen since the Gilded Age of the late 19th century. Unlike previous scientific endeavors, today's AI race features multiple companies with trillion-dollar valuations competing for an extremely limited talent pool. Only a small number of researchers have the specific expertise needed to work on the most capable AI systems, particularly in areas like multimodal AI, which Deitke specializes in. And AI hype is currently off the charts as "the next big thing" in technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The economics also differ fundamentally from past projects. The Manhattan Project cost $1.9 billion total (about $34.4 billion adjusted for inflation), while Meta alone plans to spend tens of billions annually on AI infrastructure. For a company approaching a $2 trillion market cap, the potential payoff from achieving AGI first dwarfs Deitke's compensation package.&lt;/p&gt;
&lt;p&gt;One executive put it bluntly to The New York Times: "If I'm Zuck and I'm spending $80 billion in one year on capital expenditures alone, is it worth kicking in another $5 billion or more to acquire a truly world-class team to bring the company to the next level? The answer is obviously yes."&lt;/p&gt;
&lt;p&gt;Young researchers maintain private chat groups on Slack and Discord to share offer details and negotiation strategies. Some hire unofficial agents. Companies not only offer massive cash and stock packages but also computing resources—the NYT reported that some potential hires were told they would be allotted 30,000 GPUs, the specialized chips that power AI development.&lt;/p&gt;
&lt;p&gt;Also, tech companies believe they're engaged in an arms race where the winner could reshape civilization. Unlike the Manhattan Project or Apollo program, which had specific, limited goals, the race for artificial general intelligence ostensibly has no ceiling. A machine that can match human intelligence could theoretically improve itself, creating what researchers call an "intelligence explosion" that could potentially offer cascading discoveries—if it actually comes to pass.&lt;/p&gt;
&lt;p&gt;Whether these companies are building humanity's ultimate labor replacement technology or merely chasing hype remains an open question, but we've certainly traveled a long way from the $8 per diem that Neil Armstrong received for his moon mission—about $70.51 in today's dollars—before deductions for the "accommodations" NASA provided on the spacecraft. After Deitke accepted Meta's offer, Vercept co-founder Kiana Ehsani joked on social media, "We look forward to joining Matt on his private island next year."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand holding lots of dollar notes" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand holding lots of dollar notes" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/robot_money_hand-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Paper Boat Creative via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Silicon Valley's AI talent war just reached a compensation milestone that makes even the most legendary scientific achievements of the past look financially modest. When Meta recently offered AI researcher Matt Deitke $250 million over four years (an average of $62.5 million per year)—with potentially $100 million in the first year alone—it shattered every historical precedent for scientific and technical compensation we can find on record. That includes salaries during the development of major scientific milestones of the 20th century.&lt;/p&gt;
&lt;p&gt;The New York Times reported that Deitke had cofounded a startup called Vercept and previously led the development of Molmo, a multimodal AI system, at the Allen Institute for Artificial Intelligence. His expertise in systems that juggle images, sounds, and text—exactly the kind of technology Meta wants to build—made him a prime target for recruitment. But he's not alone: Meta CEO Mark Zuckerberg reportedly also offered an unnamed AI engineer $1 billion in compensation to be paid out over several years. What's going on?&lt;/p&gt;
&lt;p&gt;These astronomical sums reflect what tech companies believe is at stake: a race to create artificial general intelligence (AGI) or superintelligence—machines capable of performing intellectual tasks at or beyond the human level. Meta, Google, OpenAI, and others are betting that whoever achieves this breakthrough first could dominate markets worth trillions. Whether this vision is realistic or merely Silicon Valley hype, it's driving compensation to unprecedented levels.&lt;/p&gt;
&lt;p&gt;To put these salaries in a historical perspective: J. Robert Oppenheimer, who led the Manhattan Project that ended World War II, earned approximately $10,000 per year in 1943. Adjusted for inflation using the US Government's CPI Inflation Calculator, that's about $190,865 in today's dollars—roughly what a senior software engineer makes today. The 24-year-old Deitke, who recently dropped out of a PhD program, will earn approximately 327 times what Oppenheimer made while developing the atomic bomb.&lt;/p&gt;
&lt;p&gt;Many top athletes can't compete with these numbers. The New York Times noted that Steph Curry's most recent four-year contract with the Golden State Warriors was $35 million less than Deitke's Meta deal (although soccer superstar Cristiano Ronaldo will make $275 million this year as the highest-paid professional athlete in the world).&amp;nbsp; The comparison prompted observers to call this an "NBA-style" talent market—except the AI researchers are making more than NBA stars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Racing toward “superintelligence”&lt;/h2&gt;
&lt;p&gt;Mark Zuckerberg recently told investors that Meta plans to continue throwing money at AI talent "because we have conviction that superintelligence is going to improve every aspect of what we do." In a recent open letter, he described superintelligent AI as technology that would "begin an exciting new era of individual empowerment," despite declining to define what superintelligence actually is.&lt;/p&gt;
&lt;p&gt;This vision explains why companies treat AI researchers like irreplaceable assets rather than well-compensated professionals. If these companies are correct, the first to achieve artificial general intelligence or superintelligence won't just have a better product—they'll have technology that could invent endless new products or automate away millions of knowledge-worker jobs and transform the global economy. The company that controls that kind of technology could become the richest company in history by far.&lt;/p&gt;
&lt;p&gt;So perhaps it's not surprising that even the highest salaries of employees from the early tech era pale in comparison to today's AI researcher salaries. Thomas Watson Sr., IBM's legendary CEO, received $517,221 in 1941—the third-highest salary in America at the time (about $11.8 million in 2025 dollars). The modern AI researcher's package represents more than five times Watson's peak compensation, despite Watson building one of the 20th century's most dominant technology companies.&lt;/p&gt;
&lt;p&gt;The contrast becomes even more stark when considering the collaborative nature of past scientific achievements. During Bell Labs' golden age of innovation—when researchers developed the transistor, information theory, and other foundational technologies—the lab's director made about 12 times what the lowest-paid worker earned.&amp;nbsp; Meanwhile, Claude Shannon, who created information theory at Bell Labs in 1948, worked on a standard professional salary while creating the mathematical foundation for all modern communication.&lt;/p&gt;
&lt;p&gt;The "Traitorous Eight" who left William Shockley to found Fairchild Semiconductor—the company that essentially birthed Silicon Valley—split ownership of just 800 shares out of 1,325 total when they started. Their seed funding of $1.38 million (about $16.1 million today) for the entire company is a fraction of what a single AI researcher now commands.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Even Space Race salaries were far cheaper&lt;/h2&gt;
&lt;p&gt;The Apollo program offers another striking comparison. Neil Armstrong, the first human to walk on the moon, earned about $27,000 annually—roughly $244,639 in today's money. His crewmates Buzz Aldrin and Michael Collins made even less, earning the equivalent of $168,737 and $155,373, respectively, in today's dollars. Current NASA astronauts earn between $104,898 and $161,141 per year. Meta's AI researcher will make more in three days than Armstrong made in a year for taking "one giant leap for mankind."&lt;/p&gt;
&lt;p&gt;The engineers who designed the rockets and mission control systems for the Apollo program also earned modest salaries by modern standards. A 1970 NASA technical report provides a window into these earnings by analyzing salary data for the entire engineering profession. The report, which used data from the Engineering Manpower Commission, noted that these industry-wide salary curves corresponded directly to the government's General Schedule (GS) pay scale on which NASA's own employees were paid.&lt;/p&gt;
&lt;p&gt;According to a chart in the 1970 report, a newly graduated engineer in 1966 started with an annual salary of between $8,500 and $10,000 (about $84,622 to $99,555 today). A typical engineer with a decade of experience earned around $17,000 annually ($169,244 today). Even the most elite, top-performing engineers with 20 years of experience peaked at a salary of around $278,000 per year in today's dollars—a sum that a top AI researcher like Deitke can now earn in just a few days.&lt;/p&gt;
&lt;h2&gt;Why the AI talent market is different&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2103443 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An image of a faceless human silhouette (chest up) with exposed microchip contacts and circuitry erupting from its open head. This visual metaphor explores transhumanism, AI integration, or the erosion of organic thought in the digital age. The stark contrast between the biological silhouette and mechanical components highlights themes of technological dependence or posthuman evolution. Ideal for articles on neural implants, futurism, or the ethics of human augmentation." class="center large" height="640" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2214539478-1024x640.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Boris Zhitkov via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn't the first time technical talent has commanded premium prices. In 2012, after three University of Toronto academics published AI research, they auctioned themselves to Google for $44 million (about $62.6 million in today's dollars). By 2014, a Microsoft executive was comparing AI researcher salaries to NFL quarterback contracts. But today's numbers dwarf even those precedents.&lt;/p&gt;
&lt;p&gt;Several factors explain this unprecedented compensation explosion. We're in a new realm of industrial wealth concentration unseen since the Gilded Age of the late 19th century. Unlike previous scientific endeavors, today's AI race features multiple companies with trillion-dollar valuations competing for an extremely limited talent pool. Only a small number of researchers have the specific expertise needed to work on the most capable AI systems, particularly in areas like multimodal AI, which Deitke specializes in. And AI hype is currently off the charts as "the next big thing" in technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The economics also differ fundamentally from past projects. The Manhattan Project cost $1.9 billion total (about $34.4 billion adjusted for inflation), while Meta alone plans to spend tens of billions annually on AI infrastructure. For a company approaching a $2 trillion market cap, the potential payoff from achieving AGI first dwarfs Deitke's compensation package.&lt;/p&gt;
&lt;p&gt;One executive put it bluntly to The New York Times: "If I'm Zuck and I'm spending $80 billion in one year on capital expenditures alone, is it worth kicking in another $5 billion or more to acquire a truly world-class team to bring the company to the next level? The answer is obviously yes."&lt;/p&gt;
&lt;p&gt;Young researchers maintain private chat groups on Slack and Discord to share offer details and negotiation strategies. Some hire unofficial agents. Companies not only offer massive cash and stock packages but also computing resources—the NYT reported that some potential hires were told they would be allotted 30,000 GPUs, the specialized chips that power AI development.&lt;/p&gt;
&lt;p&gt;Also, tech companies believe they're engaged in an arms race where the winner could reshape civilization. Unlike the Manhattan Project or Apollo program, which had specific, limited goals, the race for artificial general intelligence ostensibly has no ceiling. A machine that can match human intelligence could theoretically improve itself, creating what researchers call an "intelligence explosion" that could potentially offer cascading discoveries—if it actually comes to pass.&lt;/p&gt;
&lt;p&gt;Whether these companies are building humanity's ultimate labor replacement technology or merely chasing hype remains an open question, but we've certainly traveled a long way from the $8 per diem that Neil Armstrong received for his moon mission—about $70.51 in today's dollars—before deductions for the "accommodations" NASA provided on the spacecraft. After Deitke accepted Meta's offer, Vercept co-founder Kiana Ehsani joked on social media, "We look forward to joining Matt on his private island next year."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/</guid><pubDate>Fri, 01 Aug 2025 21:23:42 +0000</pubDate></item></channel></rss>