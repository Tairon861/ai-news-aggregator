<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 26 Feb 2026 18:56:26 +0000</lastBuildDate><item><title>America was winning the race to find Martian life. Then China jumped in. (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/26/1133584/america-china-mars-sample-return-space-race-nasa/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;To most people, rocks are just rocks. To geologists, they are much, much more: crystal-filled time capsules with the power to reveal the state of the planet at the very moment they were forged.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, NASA had been on a time capsule hunt like none other—one across Mars. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Its rovers have journeyed around a nightmarish ocher desert that, billions of years ago, was home to rivers, lakes, perhaps even seas and oceans. They’ve been seeking to answer a momentous question: Once upon a time, did microbial life wriggle across its surface?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Then, in July 2024, after more than three years on the planet, the Perseverance rover came across a peculiar rocky outcrop. Instead of the usual crystals or layers of sediment, this one had spots. Two kinds, in fact: one that looked like poppy seeds, and another that resembled those on a leopard. It’s possible that run-of-the-mill chemical reactions could have cooked up these odd features. But on Earth, these marks are almost always produced by microbial life.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;To put it plainly: Holy crap.&lt;/p&gt;  &lt;p&gt;Sure, those specks are not definitive proof of alien life. But they are the best hint yet that life may not be a one-off event in the cosmos. And they meant the most existential question of all—&lt;em&gt;Are we alone&lt;/em&gt;?—might soon be addressed. “If you do it, then human history is never the same,” says Casey Dreier, chief of space policy at the Planetary Society, a nonprofit that promotes planetary exploration and defense and the search for extraterrestrial life.&lt;/p&gt; 
 &lt;p&gt;But the only way to confirm whether these seeds and spots are the fossilized imprint of alien biology is to bring a sample of that rock home to study.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Perseverance was the first stage of an ambitious scheme to do just that—in effect, to pull off a space heist. The mission—called Mars Sample Return and planned by the US, along with its European partners—would send a Rube Goldberg–like series of robotic missions to the planet to capture pristine rocks. The rover’s job was to find the most promising stones and extract samples; then it would pass them to another robot—the getaway driver—to take them off Mars and deliver them to Earth.&lt;/p&gt; 
 &lt;p&gt;But now, just over a year and a half later, the project is on life support, with zero funding flowing in 2026 and little backing left in Congress. As a result, those oh-so-promising rocks may be stuck out there forever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;“We’ve spent 50 years preparing to get these samples back. We’re ready to do that,” says Philip Christensen, a planetary scientist at Arizona State University who works closely with NASA. “Now we’re two feet from the finish line—&lt;em&gt;Oh, sorry, we’re not going to complete the job&lt;/em&gt;.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;This also means that, in the race to find evidence of alien life, America has effectively ceded its pole position to its greatest geopolitical rival: China. The superpower is moving full steam ahead with its own version of MSR. It’s leaner than America and Europe’s mission, and the rock samples it will snatch from Mars will likely not be as high quality. But that won’t be the headline people remember—the one in the scientific journals and the history books. “At the rate we’re going, there’s a very good chance they’ll do it before we do,” laments Christensen. “Being there first is what matters.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Of course, any finding of extraterrestrial life advances human knowledge writ large, no matter the identity of the discoverers. But there is the not-so-small issue of pride in an already heated nationalistic competition, not to mention the fact that many scientists in America (to say nothing of US lawmakers) don’t necessarily want their future research and scientific progress subject to a foreign gatekeeper. And even for those not especially concerned about potentially unearthing alien microbes, MSR and the comparable Chinese mission are technological stepping stones toward a long-held dream shared by many beyond Elon Musk: getting astronauts onto the Red Planet and, eventually, setting up long-term bases for astronauts there. It’d be a huge blow to show up only after a competitor had already set up shop … or not to get there at all.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If we can’t do this, how do we think we’re gonna send humans there and get back safely?” says Victoria Hamilton, a planetary geologist at the Southwest Research Institute in Boulder, Colorado, who is also the chair of the NASA-affiliated Mars Exploration Program Analysis Group.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Or as Paul Byrne, a planetary scientist from the Washington University in St. Louis, puts it: “If you’re going to bring humans back from Mars, you sure as shit have to figure out how to bring the samples back first.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Nearly a dozen project insiders and scientists in both the US and China shared with me the story of how America blew its lead in the new space race. It’s full of wild dreams and promising discoveries—as well as mismanagement, eye-watering costs, and, ultimately, anger and disappointment.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“I spent most of my career studying Mars,” says Christensen. There are countless things about it that bewitch him. But by examining it, he suspects, we’ll get further than ever in the Homeric investigation of how life began.&lt;/p&gt;  &lt;p&gt;Sure, the Mars of today is a postapocalyptic wasteland, an arid and cold desert bathed in lethal radiation. But billions of years ago, water lapped up against the slopes of fiery volcanoes that erupted under a clement sky. Then its geologic interior cooled down so quickly, changing everything. Its global magnetic field collapsed like a deflating balloon, and its protective atmosphere was stripped away by the sun.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133607" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GettyImages-57337107.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;NASA first touched down on Mars in 1976 with two Viking landers. The Mars Odyssey spacecraft has been orbiting the planet since 2001 and produced this image of Valles Marineris, which is 10 times longer, 5 times deeper, and 20 times wider than the Grand Canyon. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/ARIZONA STATE UNIVERSITY VIA GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Its surface is now remarkably hostile to life as we know it. But deep below ground, where it’s shielded from space, and where it’s warmer and wetter, there could maybe be microbes inching about.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Scientists have long possessed several Martian meteorites that have been flung our way, but none of them are pristine; they were all damaged by cosmic radiation midflight, before getting scorched in Earth’s atmosphere. Plus, there’s another problem: “We currently have no rocks from Mars that are sedimentary, the rock type likely to contain fossils,” says Sara Russell, a planetary scientist at London’s Natural History Museum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For those, humans (or robots) would need to get on the ground.&lt;/p&gt;  &lt;p&gt;NASA first made the stuff of sci-fi films a reality 50 years ago, when two Viking landers touched down on the planet in 1976. One of their experiments dropped some radioactively tagged nutrients into soil samples, the idea being that if any microbes were present, they’d gobble up the nutrients and burp out some radioactive waste gas that the landers could detect. Tantalizingly, this experiment hinted that something microbe-like was interacting with those nutrients—but the result was inconclusive (and today most scientists don’t suspect biology was responsible).&lt;/p&gt;  &lt;p&gt;Still, it was enough to elevate scientists’ curiosity about the genuine possibility of Martian life. Over the coming decades, America sent an ever-expanding fleet of robots to Mars—orbiting spacecraft, landers, and wheeled rovers. But no matter how hard they studied their adoptive planet’s rocks, they weren’t designed to &lt;em&gt;definitively&lt;/em&gt; detect signs of life. For that, promising-looking rocks would need to be captured and, somehow, shuttled back to labs on Earth in carefully sealed containers.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133610" height="1667" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/PIA25857orig.jpg?w=3000" width="3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;A 2023 plan from NASA and the European Space Agency to safely transport pristine samples received from Mars.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This became a top priority for the US planetary science community in 2003, following the publication of the first Planetary Decadal Survey, a census conducted at NASA’s request. The scientific case for the mission was clear—even to the people who &lt;em&gt;didn’t&lt;/em&gt; think they’d find signs of life. “I bet there isn’t life on Mars. But if there is, or was, that would be an incredibly important discovery,” says Christensen. And if not, “Why not?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “We may understand more about why life started on Earth by understanding why it may not have started on Mars. What was that key difference between those two planets?”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And so, MSR was born. America went all in, and the European Space Agency joined the team. Over the next decade or so, a complex plan was drawn up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;First, a NASA rover would land on Mars in a spot that once was potentially habitable—later determined to be Jezero Crater. It would zip about, look for layered rocks of the sort that you’d find in lakes and riverbeds, extract cores of them, and cache them in sealed containers. Then a second NASA spacecraft would land on Mars, receive the rover’s sample tubes (in one of several different ways), and transfer the samples to a rocket that would launch them into Martian orbit. A European-provided orbiter would catch that rocket like a baseball glove before returning home and dropping the rocks into Earth’s atmosphere, where they would be guided, via parachute, to eagerly awaiting scientists no later than the mid-2030s.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-full"&gt;&lt;img alt="alt" class="wp-image-1133612" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP21054854805249.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;Two messages were encoded on the 70-foot parachute used by the Perseverance rover as it descended toward Mars. This annotated image shows how NASA systems engineer Ian Clark used a binary code to spell out “Dare Mighty Things” in the orange and white strips; he also included the GPS coordinates for the mission’s headquarters at the Jet Propulsion Laboratory.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“Put simply, this is the most scientifically careful sample collection mission possible, conducted in one of the most promising places on Mars to look for signs of past life,” says Jonathan Lunine, the chief scientist at NASA’s Jet Propulsion Laboratory in California. “And, of course, should evidence of life be found in the sediments, that would be an historic discovery.”&lt;/p&gt;  &lt;p&gt;It got off to an auspicious start. On July 30, 2020, in the throes of the covid-19 pandemic, NASA’s Perseverance rover launched atop a rocket from Florida’s Cape Canaveral. The NASA administrator at the time, Jim Bridenstine, didn’t mince words: “We are in extraordinary times right now,” he told reporters, “yet we have in fact persevered, and we have protected this mission because it is so important.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But just earlier that same month, the mission to Mars had turned into a &lt;em&gt;race&lt;/em&gt;. China was now prepping its own sample return spacecraft.&lt;/p&gt;  &lt;p&gt;And that’s when things for MSR started to unravel.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-1133682" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image2_final.jpg?w=1500" width="1500" /&gt;&lt;div class="image-credit"&gt;XINMEI LIU&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;China was comparatively late to develop a competitive space program, but once it began doing so, it wasted no time. In 2003, it first sent one of its astronauts into space, via its own bespoke rocket; in the two decades since, it has launched its own space station and sent multiple uncrewed spacecraft to the moon—first orbiters, then landers—as part of its Chang’e Project, named after a lunar goddess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But a real turning point for China’s interplanetary ambitions came in 2020, the same year as Perseverance’s launch to Mars.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That December, Chang’e-5 touched down in the moon’s Ocean of Storms, a realm of frozen lava 1,600 miles long. It grabbed some 2-billion-year-old rocks, put them in a rocket, and blasted them into the firmament. The samples were captured by a small orbiting spacecraft; crucially, the idea was not all that dissimilar from how MSR imagined catching its own samples, baseball-glove style. China’s lunar haul was then dropped off back on Earth just before Christmas. It marked the first time since 1976 that samples had been returned from the moon, and the mission was seamless.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="two labelled vials of soil next to a small ruler for scale" class="wp-image-1133692" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Change-5_soil_samples.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;China brought back soil samples from the moon’s Ocean of Storms during its Chang’e-5 mission, marking the first time since 1976 that samples had been returned from the moon.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;WIKIMEDIA COMMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;That same year, China made its first foray toward Mars. The project was called Tianwen-1, meaning “Questions to Heaven”—the first in a new series of audacious space missions to the Red Planet and orbiting asteroids. While its success was far from guaranteed, China was willing to kick into high gear immediately,&amp;nbsp;sending both an orbiting spacecraft and a rover to Mars at the same time. No other country had ever managed to perform this act of spaceflight acrobatics on its first try.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Just as China ramped up its space schemes, some people in the scientific community began to wonder if NASA was (inadvertently) promising too much with MSR—and whether the heist would be worth the cost.&lt;/p&gt;  &lt;p&gt;In 2020, the price tag for the program had jumped from an already expensive $5.3 billion to an estimated $7 billion. (For context, NASA’s Near-Earth Object Surveyor mission, which is currently being pieced together, has a price tag of around $1.2 billion. This space observatory is designed to find Earthbound asteroids and is tasked with defending all 8 billion of us from a catastrophic impact.)&lt;/p&gt;  &lt;p&gt;But Perseverance was already on its way to Mars. It wasn’t as if this expensive train could go back to the station. The project’s advocates just hoped it’d actually make it there in one piece.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While the US had previously entered Martian orbit successfully, several other entry, descent, and landing attempts on the planet had ended in explosive disaster; the primary antagonist is the Martian atmosphere, which can cause spacecraft to tumble wildly out of control or heat up and ignite. Perseverance would be traveling at nearly 12,500 miles per hour as it entered Mars’s airspace, and to land it’d need to decelerate, deploy a parachute, fire several rockets, and pilot itself to the skies above Jezero Crater—before a levitating crane would drop off the actual rover.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Thankfully, Perseverance’s deployment went off without a hitch. On February 18, 2021, Mars became its new home—and the rover’s makers hugged, high-fived, and whooped for joy in NASA’s flight control room.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Lori Glaze, then director of&amp;nbsp;NASA’s planetary science division,&amp;nbsp;said at the time, “Now the fun really starts.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133603" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/NHQ202102180066orig.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Members of NASA’s Perseverance rover team at the Jet Propulsion Laboratory in Pasadena, California, celebrate after receiving confirmation that the spacecraft successfully touched down on Mars in February 2021.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/BILL INGALLS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;That very same month, China arrived at Mars’s doorstep for the first time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On February 10, 2021, Tianwen-1 began to orbit the planet. Then, on May 14, it slipped a drop shipment through the spacecraft-frying atmosphere to deliver a rover onto an expansive landscape called Utopia Planitia—giving Perseverance a neighbor, albeit one 1,200 miles away.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;This explorer was nowhere near as sophisticated as Perseverance, and its assignment was a far cry from a sample return mission. It had some cameras and scientific instruments for studying its environment, making it comparable to one of NASA’s older rovers. It was also supposed to operate for just three months (though it ended up persisting for an entire year before being fatally smothered by pernicious Martian dust).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, Tianwen-1 was a remarkable achievement for China, one that the US couldn’t help but applaud. “This is a really big deal,” said Roger Launius, then NASA’s chief historian.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;And even if grabbing pieces of Mars was increasingly likely in China’s future, it was &lt;em&gt;already happening&lt;/em&gt; in the present for the US. The race, the Americans thought, was over before it had even begun … right?&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Over the next few years, Perseverance went on an extraterrestrial joyride. It meandered through frozen flows of lava and journeyed over fans of sediment once washed about by copious liquid water. It pulled out rocks that preserved salty, muddy layers—exactly the environment that, on Earth, would be teeming with microorganisms and organic matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Jezero Crater clearly meets the astrobiological criterion for a sampling site where life may once have existed,” says Lunine from NASA’s Jet Propulsion Lab. “Rocks of broadly similar age and setting on Earth contain some of the earliest evidence for life on our own planet.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133618" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP21250588944004.jpg?w=1458" /&gt;&lt;figcaption class="wp-element-caption"&gt;The Perseverance rover has been on an extraterrestrial joyride since 2021, drilling holes in promising looking space rocks that it hopes could be teeming with microorganisms and organic matter. &lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Then, in September 2023, as Perseverance was trundling across the ruins of what may once have been a microbial metropolis, an independent panel of researchers published a report that made it clear, in no uncertain terms, that MSR was the opposite of okay.&lt;/p&gt;  &lt;p&gt;They found that the project was too decentralized among the nation’s plethora of NASA centers, leaving confusion as to who was actually in charge. And at its current pace, MSR wouldn’t get its Mars rocks back home until the 2040s at the earliest—as much as a whole decade later than initial estimates. And it would cost as much as $11 billion, more than doubling the initial tab.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“MSR was established with unrealistic budget and schedule expectations from the beginning,” the report reads. “MSR was also organized under an unwieldy structure. As a result, there is currently no credible, congruent technical, nor properly margined schedule, cost, and technical baseline that can be accomplished with the likely available funding.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;Members of Congress started to wonder aloud whether MSR should be canceled outright, and the scientific community that had once so enthusiastically supported the mission faced a moment of reckoning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Byrne, the planetary scientist from the Washington University in St. Louis, had always been something of a rebel, never really a fan of NASA’s multi-decadal, over-the-top fascination with Mars. The solar system, he argued, is filled with curious worlds to explore—especially Venus, another nearby rocky world that was once rather Earth-like. Couldn’t we spare some of NASA’s budget to make sure we explore Venus, too?&lt;/p&gt;  &lt;p&gt;Still, like many other critical colleagues, Byrne did not want to see MSR put down. The report’s findings didn’t change the fact that Perseverance was dutifully working around the clock to accomplish the mission’s opening stages. What would be the point of gathering all those samples if they were going to be left to stay on Mars? The community, Byrne explains, just needed to answer one question: “How do you do this in a way that’s faster and cheaper?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In April 2024, NASA publicly sought help from its industry partners in the space sector: Could anyone come up with a way to save MSR? Various players with spaceflight experience, like Lockheed Martin, sent in proposals for consideration.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt; &lt;p&gt;Then, just a few months later in July 2024, Perseverance came in clutch, finding those special leopard-spotted and speckled rocks in an old river valley—a sign of hope that NASA had been desperately seeking. Now the agency’s request for help was all the more urgent—these rocks had to get home. After various panels assessed plans that could effectively save MSR, two potential options for a faster, leaner, less expensive version were previewed at a January 2025 press briefing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One option brought in tried-and-tested tech: Since Perseverance had been safely deployed onto the surface of Mars using a hovering platform known as a sky crane, it was proposed that the sample-gathering lander for MSR could also be dropped off using a sky crane, which would simplify this step and reduce the overall cost of the program. The other suggestion was that the lander could be delivered to Mars via a spaceship from a commercial spaceflight company. The lander design itself could also be streamlined, and tweaks could be made to the rocket that would launch the samples back into space.&lt;/p&gt;  &lt;p&gt;The proposals needed greater study, but everyone’s spirits were lifted by the fact these plans &lt;em&gt;could&lt;/em&gt;, at least theoretically, get samples back in the 2030s, not the 2040s. And, crucially, “it was possible to get the cost down,” says Jack Mustard, an Earth and planetary scientist at Brown University and a member of one of the two proposal-reviewing panels. Still, it didn’t save a lot: They could do MSR for $8 billion.&lt;/p&gt;  &lt;p&gt;“What we came up with was very reasonable, rational, much simpler,” says Christensen, who was part of the same review panel. “And $8 billion is about the right amount it would take to guarantee that it’s going to work.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_29"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-1133683" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image3_final.jpg?w=2500" width="2500" /&gt;&lt;div class="image-credit"&gt;XINMEI LIU&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;While the US became increasingly consumed with its own interplanetary woes, China was riding high.&lt;/p&gt;  &lt;p&gt;In June 2024, the sixth installment in the Chang’e project made history. It was another lunar sample return mission, but this one did something nobody had ever done in the history of spaceflight: It landed on the difficult-to-reach, out-of-view far side of the moon and snagged samples from it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China made it look effortless when a capsule containing matter from this previously untouched region safely landed in Inner Mongolia. Long Xiao, a planetary geoscientist at the China University of Geosciences, told reporters at the time that the mission’s success was “a cause for celebration for all humanity.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it was also effectively a bombshell for NASA. Yes, the moon is much closer to Earth, and it doesn’t have a spaceship-destroying atmosphere like Mars. But China was speedrunning through the race while America was largely looking the other way.&lt;/p&gt;  &lt;p&gt;Then, in May 2025, China launched Tianwen-2. Its destination was not Mars but a near-Earth asteroid. The plan is that it will scoop up some of the space rock’s primordial pebbles later this year and deliver them back to Earth in late 2027. In light of China’s past successes, many suspect it’ll nail this project, too.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Tianwen-2 on the launchpad" class="wp-image-1133598" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP25149225181672.jpg?w=2923" width="2923" /&gt;&lt;figcaption class="wp-element-caption"&gt;China’s Tianwen missions, meaning “Questions to Heaven,” aim to explore both Mars and orbiting asteroids. The Tianwen-2 probe blasted off in May 2025, headed toward a near-Earth asteroid for a sample-return mission.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;VCG/VCG VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;But perhaps the biggest blow to the US came in June 2025: China revealed its formal designs on returning samples from Mars—and potentially addressing the existence of life elsewhere in the cosmos. Chinese researchers outlined a bold plan for Tianwen-3 in the journal &lt;em&gt;Nature Astronomy&lt;/em&gt;. “Searching for signs of life, or astrobiology studies, are the first priority,” says Yuqi Qian, a lunar geologist at the University of Hong Kong. And while many observers had long been cognizant of this ambition, seeing it so clearly spelled out in academic writing made it &lt;em&gt;real&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_31"&gt; &lt;p&gt;“The selection of the landing site is still ongoing,” says&lt;strong&gt; &lt;/strong&gt;Li Yiliang, an astrobiologist at the University of Hong Kong, an author of the Tianwen-3 study, and a member of the spacecraft’s landing site selection team. But the paper notes, in no uncertain terms, that the mission will move at a breakneck pace. “The aim of China’s Mars sample return mission, known as Tianwen-3, is to collect at least 500g of samples from Mars and return them to Earth around 2031.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;2031&lt;/em&gt;. Even on its original, speedier timeline, America’s MSR plan wouldn’t get samples back by that date. So how is China planning to pull it off?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_33"&gt; &lt;p&gt;Qian explains that Tianwen-3 is building on the success of the lunar sample return program. Doing something similar for Mars is a rather giant technological leap (requiring two rockets, not one)—but, he argues, “the technologies here are similar.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The plan is for a duet of rockets to blast off from Earth in 2028. The first will contain the lander-ascender combination, or LAC. The second is the orbiter-returner combination, or ORC. The LAC will get to Mars and deploy a lander as well as a small helicopter, which will scout promising locations around the landing site while using a claw to bring several small samples back to the lander.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133599" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Zhurong-with-lander-selfie.png?w=1818" /&gt;&lt;figcaption class="wp-element-caption"&gt;China’s Tianwen-3 mission is searching for signs of Martian life with an eye toward having samples back home sometime in 2031.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;中国新闻社 VIA WIKIMEDIA COMMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The LAC will then travel to the most promising site. The lander’s drill, which can get down to around seven feet below the surface, is the most important part of the mission. At that depth, there are greater odds of capturing signs of past life. When at least 500 grams of pristine rocks have been loaded aboard the lander, the samples will be launched into space, where the orbiter will be waiting to capture them and send them back home sometime in 2031.&lt;/p&gt;  &lt;p&gt;“The returned samples will be quarantined strictly in an under-planning facility near Hefei city,” says Yiliang. And there, in those bio-secure labs, scientists might very well find the first clear signs of alien life, past or present.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;The very same month that Chinese researchers published their daring plans for returning Mars samples, the new Trump administration released a draconian NASA budget for Congress to consider—one that sparked panic across the planetary science community.&lt;/p&gt;  &lt;p&gt;If enacted, it would have been a historic catastrophe for the venerable space agency, giving NASA its smallest budget since 1961. This would have forced it to let go of a huge number of staffers, slash its science program budget in half, and terminate 19 missions currently in operation. MSR was in the crosshairs, too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Grim is the word,” says Dreier of the Planetary Society.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Over the next few months, Congress pushed back on the potential gutting of NASA, but largely to save ongoing solar system exploration missions. MSR was not considered an active effort; Perseverance was effectively a scientific scout acting independently by this point. A counterproposal by the House offered up $300 million for MSR, but no policymaker was cheerleading for it. (The US Office of Management and Budget, the House Committee on Science, Space, and Technology, and the office of Sen. Ted Cruz of Texas, who chairs the Senate Committee on Commerce, Science, and Transportation did not respond to requests for comment.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_36"&gt; &lt;p&gt;“Mars Sample Return doesn’t seem to have very many advocates right now,” says Byrne. The project “isn’t featuring in anyone’s conversation at the moment, with all of the existential shit that’s happening to NASA.” Everyone working on a NASA mission hoped that they, and their spacecraft, would survive the onslaught. As Byrne adds: “[People are] just trying to keep their heads down.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_38"&gt; &lt;p&gt;Researchers in America suddenly found themselves at an inflection point. “The attack on science, and the attack on NASA science, has been very successful, in that it has completely demoralized the science community,” says Christensen. “Everyone’s in a state of shock.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I contacted NASA in July about the state of MSR, which was then in the middle of a months-long limbo, I was told that experts weren’t available to comment. Roxana Bardan, a spokesperson, instead sent a statement: “Under President Trump’s America First agenda, NASA is committed to sustained U.S. space leadership. We will continue to innovate, explore, and excel to ensure American preeminence in space.” (The agency did not respond to a follow-up request for comment.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That notion stood in direct contrast to what Christensen told me around the same time.&amp;nbsp;“The US … has led the exploration of Mars for 50 years,” he said. “And as we approach one of the key discovery points, we’re about to concede that leadership to someone else.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;From China’s perspective, the fumbling of MSR is more confusing than anything else. “NASA has so well prepared for her MSR mission in both technology and science, and I and my colleagues have learned so much from NASA’s scientific communities,” says Yiliang.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And if China wins the race because America decided to shoot itself in the foot? “This is sad,” he says. “If this comes true, I believe the Chinese will not be that happy to win the race in this way.”&lt;/p&gt;  &lt;p&gt;Tianwen-3 will still have to overcome many of the same hurdles as MSR. Nobody, for example, has autonomously launched a rocket of any kind off the surface of Mars. But many believe the Chinese can succeed, even at their program’s superspeed. Christensen, for one, fully expected several of their past robotic missions to the moon and Mars to fail—but “the fact that they pulled it off the first time really says a lot about their engineering capability,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Mustard agrees: “They know how to land; they know how to leave. I have a lot of confidence that they’ve learned enough from the lunar work that they’ll be able to do it.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_40"&gt; &lt;p&gt;Plus, Tianwen-3’s architecture is simpler than the US-European mission. It has fewer components, and fewer points of potential failure. This also means, though, that the quality of the loot will be somewhat lacking. Tianwen-3 will sample from only one small patch of Mars. Conversely, Perseverance is roving around a vast and geologically diverse landscape, sampling as it goes, which would translate to “literally orders of magnitude more science than what will come from the Chinese samples,” says Christensen.&lt;/p&gt;  &lt;p&gt;But China could serendipitously land on a biologically rich patch of the planet. As the Southwest Research Institute’s Hamilton says, the mission could “pick up something entirely unexpected and, you know, miraculous.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_42"&gt; &lt;p&gt;The likeliest outcome is still that neither nation finds fossilized microbes, but that China brings back rocks from Mars first. At the end of the day, that’s what Americans (and Europeans) will hear: “You’re second. You lost,” says Mustard.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="fullWidthImage"&gt;&lt;div class="fullWidthImage__imageWrapper--713fbd99308fe950febff06b694edeaa is-style-full-bleed"&gt;&lt;figure class="wp-block-image"&gt;&lt;source media="(max-width: 39.3749rem)" /&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image4_final.jpg" /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;div class="fullWidthImage__credit--d43dc7ec3d50859db7eb8d2def69081a image-credit"&gt;Xinmei Liu&lt;/div&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_44"&gt; &lt;p&gt;Like many of his colleagues, Christensen is irked by the thought of losing the race to Mars, because it would be such an own goal. The US has been sending robots over there for decades and investing billions in forging the technology that would be required to make MSR a success. And suddenly “the Chinese come along and say, &lt;em&gt;Thank you very much, we’ll take all of that information—we’ll build one mission and go and do what you guys did the groundwork for&lt;/em&gt;,” Christensen says. “As a taxpayer, I’m like: It just seems foolish to me.”&lt;/p&gt;  &lt;p&gt;Even the MSR skeptics concede that this kind of loss would have sweeping ramifications. Byrne worries that if something like MSR can be snuffed out so easily, what’s to say the next big mission—to Jupiter, Saturn, and beyond—won’t suffer the same ignoble fate? In other words, the death of MSR would severely damage “the ability of the planetary community to dream big,” he says. “If we don’t pull this off, what does that mean? Are we not going to do big, expensive, difficult things?”&lt;/p&gt;  &lt;p&gt;Another big, expensive, difficult thing? Putting humans on Mars. Both critics and advocates of MSR largely agree it is an invaluable dress rehearsal. Making sure you can safely launch a rocket off Mars is a necessary prerequisite to ensuring that an array of equipment can survive for a long time on the planet’s lethal surface.&lt;/p&gt;  &lt;p&gt;China, too, has explicitly acknowledged this. As one of the first lines of the Tianwen-3 study states, “Mars is the most promising planet for humanity’s expansion beyond Earth, with its potential for future habitability and accessible resources.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Though such expansion is still of course a far-future dream, it’s not hard to see how losing the race here would put the US at a huge disadvantage. Members of America’s planetary science community say that to try to sway politicians in their favor, they have framed MSR as a national security issue. But they haven’t had much luck. “We’ve been in discussions with decision-makers who have never heard that perspective before,” says the Planetary Society’s Dreier.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_46"&gt;&lt;p&gt;“It is surprising that doesn’t have more weight,” adds Mustard.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite months of purgatory, it still stung when the coup de grâce arrived in January. In the draft for a must-pass spending bill, House and Senate appropriators spared NASA from the harshest proposed cuts, thereby saving dozens of spaceflight missions and preserving much of the agency’s planetary science output. But the bill provided absolutely zero political or financial support for MSR. There it was, in black and white: America’s plans to perform a history-making heist on Mars were dead. The bill became law in January and Perseverance, it seems, is now destined to rove alone on the Red Planet until its nuclear battery burns out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This austere reality clashes with the soaring aspirations outlined in the first Planetary Decadal Survey, written just over two decades ago. It stated that the US exploration of the solar system “has a proud past, a productive present, and an auspicious future.” It also noted that “answers to profound questions about our origins and our future may be within our grasp.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now the answers have all but slipped away. Even though Perseverance continues to roam, it’s increasingly likely we’ll never see those promising bespeckled rocks with human eyes, let alone any other rocks the rover finds intriguing. It is far easier to imagine that in the near future, perhaps in the early 2030s, Perseverance will point its camera up at the night sky above Jezero Crater. It will catch a small glimmer: Tianwen-3’s orbiter, preparing to send ancient rocks back to Earth. Meanwhile, Perseverance’s own sample tubes—perhaps some containing signs of life—will be trapped on the Martian surface, gathering dust.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133605" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/PIA25738orig.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;Sample tubes collected by the Perseverance rover may never make it home from the Martian surface.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH/MSSS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;It is a sobering thought for Christensen. “We’ll wake up one day and go: What the hell?” he says. “How did we let this happen?”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Robin George Andrews is an award-winning science journalist and doctor of volcanoes based in London. He regularly writes about the Earth, space, and planetary sciences, and is the author of two critically acclaimed books:&amp;nbsp;&lt;/em&gt;Super Volcanoes&lt;em&gt;&amp;nbsp;(2021) and&amp;nbsp;&lt;/em&gt;How to Kill An Asteroid&amp;nbsp;&lt;em&gt;(2024).&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;To most people, rocks are just rocks. To geologists, they are much, much more: crystal-filled time capsules with the power to reveal the state of the planet at the very moment they were forged.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, NASA had been on a time capsule hunt like none other—one across Mars. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Its rovers have journeyed around a nightmarish ocher desert that, billions of years ago, was home to rivers, lakes, perhaps even seas and oceans. They’ve been seeking to answer a momentous question: Once upon a time, did microbial life wriggle across its surface?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Then, in July 2024, after more than three years on the planet, the Perseverance rover came across a peculiar rocky outcrop. Instead of the usual crystals or layers of sediment, this one had spots. Two kinds, in fact: one that looked like poppy seeds, and another that resembled those on a leopard. It’s possible that run-of-the-mill chemical reactions could have cooked up these odd features. But on Earth, these marks are almost always produced by microbial life.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;To put it plainly: Holy crap.&lt;/p&gt;  &lt;p&gt;Sure, those specks are not definitive proof of alien life. But they are the best hint yet that life may not be a one-off event in the cosmos. And they meant the most existential question of all—&lt;em&gt;Are we alone&lt;/em&gt;?—might soon be addressed. “If you do it, then human history is never the same,” says Casey Dreier, chief of space policy at the Planetary Society, a nonprofit that promotes planetary exploration and defense and the search for extraterrestrial life.&lt;/p&gt; 
 &lt;p&gt;But the only way to confirm whether these seeds and spots are the fossilized imprint of alien biology is to bring a sample of that rock home to study.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Perseverance was the first stage of an ambitious scheme to do just that—in effect, to pull off a space heist. The mission—called Mars Sample Return and planned by the US, along with its European partners—would send a Rube Goldberg–like series of robotic missions to the planet to capture pristine rocks. The rover’s job was to find the most promising stones and extract samples; then it would pass them to another robot—the getaway driver—to take them off Mars and deliver them to Earth.&lt;/p&gt; 
 &lt;p&gt;But now, just over a year and a half later, the project is on life support, with zero funding flowing in 2026 and little backing left in Congress. As a result, those oh-so-promising rocks may be stuck out there forever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;“We’ve spent 50 years preparing to get these samples back. We’re ready to do that,” says Philip Christensen, a planetary scientist at Arizona State University who works closely with NASA. “Now we’re two feet from the finish line—&lt;em&gt;Oh, sorry, we’re not going to complete the job&lt;/em&gt;.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;This also means that, in the race to find evidence of alien life, America has effectively ceded its pole position to its greatest geopolitical rival: China. The superpower is moving full steam ahead with its own version of MSR. It’s leaner than America and Europe’s mission, and the rock samples it will snatch from Mars will likely not be as high quality. But that won’t be the headline people remember—the one in the scientific journals and the history books. “At the rate we’re going, there’s a very good chance they’ll do it before we do,” laments Christensen. “Being there first is what matters.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Of course, any finding of extraterrestrial life advances human knowledge writ large, no matter the identity of the discoverers. But there is the not-so-small issue of pride in an already heated nationalistic competition, not to mention the fact that many scientists in America (to say nothing of US lawmakers) don’t necessarily want their future research and scientific progress subject to a foreign gatekeeper. And even for those not especially concerned about potentially unearthing alien microbes, MSR and the comparable Chinese mission are technological stepping stones toward a long-held dream shared by many beyond Elon Musk: getting astronauts onto the Red Planet and, eventually, setting up long-term bases for astronauts there. It’d be a huge blow to show up only after a competitor had already set up shop … or not to get there at all.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If we can’t do this, how do we think we’re gonna send humans there and get back safely?” says Victoria Hamilton, a planetary geologist at the Southwest Research Institute in Boulder, Colorado, who is also the chair of the NASA-affiliated Mars Exploration Program Analysis Group.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Or as Paul Byrne, a planetary scientist from the Washington University in St. Louis, puts it: “If you’re going to bring humans back from Mars, you sure as shit have to figure out how to bring the samples back first.”&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Nearly a dozen project insiders and scientists in both the US and China shared with me the story of how America blew its lead in the new space race. It’s full of wild dreams and promising discoveries—as well as mismanagement, eye-watering costs, and, ultimately, anger and disappointment.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“I spent most of my career studying Mars,” says Christensen. There are countless things about it that bewitch him. But by examining it, he suspects, we’ll get further than ever in the Homeric investigation of how life began.&lt;/p&gt;  &lt;p&gt;Sure, the Mars of today is a postapocalyptic wasteland, an arid and cold desert bathed in lethal radiation. But billions of years ago, water lapped up against the slopes of fiery volcanoes that erupted under a clement sky. Then its geologic interior cooled down so quickly, changing everything. Its global magnetic field collapsed like a deflating balloon, and its protective atmosphere was stripped away by the sun.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133607" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GettyImages-57337107.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;NASA first touched down on Mars in 1976 with two Viking landers. The Mars Odyssey spacecraft has been orbiting the planet since 2001 and produced this image of Valles Marineris, which is 10 times longer, 5 times deeper, and 20 times wider than the Grand Canyon. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/ARIZONA STATE UNIVERSITY VIA GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Its surface is now remarkably hostile to life as we know it. But deep below ground, where it’s shielded from space, and where it’s warmer and wetter, there could maybe be microbes inching about.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Scientists have long possessed several Martian meteorites that have been flung our way, but none of them are pristine; they were all damaged by cosmic radiation midflight, before getting scorched in Earth’s atmosphere. Plus, there’s another problem: “We currently have no rocks from Mars that are sedimentary, the rock type likely to contain fossils,” says Sara Russell, a planetary scientist at London’s Natural History Museum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For those, humans (or robots) would need to get on the ground.&lt;/p&gt;  &lt;p&gt;NASA first made the stuff of sci-fi films a reality 50 years ago, when two Viking landers touched down on the planet in 1976. One of their experiments dropped some radioactively tagged nutrients into soil samples, the idea being that if any microbes were present, they’d gobble up the nutrients and burp out some radioactive waste gas that the landers could detect. Tantalizingly, this experiment hinted that something microbe-like was interacting with those nutrients—but the result was inconclusive (and today most scientists don’t suspect biology was responsible).&lt;/p&gt;  &lt;p&gt;Still, it was enough to elevate scientists’ curiosity about the genuine possibility of Martian life. Over the coming decades, America sent an ever-expanding fleet of robots to Mars—orbiting spacecraft, landers, and wheeled rovers. But no matter how hard they studied their adoptive planet’s rocks, they weren’t designed to &lt;em&gt;definitively&lt;/em&gt; detect signs of life. For that, promising-looking rocks would need to be captured and, somehow, shuttled back to labs on Earth in carefully sealed containers.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133610" height="1667" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/PIA25857orig.jpg?w=3000" width="3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;A 2023 plan from NASA and the European Space Agency to safely transport pristine samples received from Mars.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This became a top priority for the US planetary science community in 2003, following the publication of the first Planetary Decadal Survey, a census conducted at NASA’s request. The scientific case for the mission was clear—even to the people who &lt;em&gt;didn’t&lt;/em&gt; think they’d find signs of life. “I bet there isn’t life on Mars. But if there is, or was, that would be an incredibly important discovery,” says Christensen. And if not, “Why not?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “We may understand more about why life started on Earth by understanding why it may not have started on Mars. What was that key difference between those two planets?”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And so, MSR was born. America went all in, and the European Space Agency joined the team. Over the next decade or so, a complex plan was drawn up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;First, a NASA rover would land on Mars in a spot that once was potentially habitable—later determined to be Jezero Crater. It would zip about, look for layered rocks of the sort that you’d find in lakes and riverbeds, extract cores of them, and cache them in sealed containers. Then a second NASA spacecraft would land on Mars, receive the rover’s sample tubes (in one of several different ways), and transfer the samples to a rocket that would launch them into Martian orbit. A European-provided orbiter would catch that rocket like a baseball glove before returning home and dropping the rocks into Earth’s atmosphere, where they would be guided, via parachute, to eagerly awaiting scientists no later than the mid-2030s.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-full"&gt;&lt;img alt="alt" class="wp-image-1133612" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP21054854805249.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;Two messages were encoded on the 70-foot parachute used by the Perseverance rover as it descended toward Mars. This annotated image shows how NASA systems engineer Ian Clark used a binary code to spell out “Dare Mighty Things” in the orange and white strips; he also included the GPS coordinates for the mission’s headquarters at the Jet Propulsion Laboratory.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“Put simply, this is the most scientifically careful sample collection mission possible, conducted in one of the most promising places on Mars to look for signs of past life,” says Jonathan Lunine, the chief scientist at NASA’s Jet Propulsion Laboratory in California. “And, of course, should evidence of life be found in the sediments, that would be an historic discovery.”&lt;/p&gt;  &lt;p&gt;It got off to an auspicious start. On July 30, 2020, in the throes of the covid-19 pandemic, NASA’s Perseverance rover launched atop a rocket from Florida’s Cape Canaveral. The NASA administrator at the time, Jim Bridenstine, didn’t mince words: “We are in extraordinary times right now,” he told reporters, “yet we have in fact persevered, and we have protected this mission because it is so important.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But just earlier that same month, the mission to Mars had turned into a &lt;em&gt;race&lt;/em&gt;. China was now prepping its own sample return spacecraft.&lt;/p&gt;  &lt;p&gt;And that’s when things for MSR started to unravel.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-1133682" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image2_final.jpg?w=1500" width="1500" /&gt;&lt;div class="image-credit"&gt;XINMEI LIU&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;China was comparatively late to develop a competitive space program, but once it began doing so, it wasted no time. In 2003, it first sent one of its astronauts into space, via its own bespoke rocket; in the two decades since, it has launched its own space station and sent multiple uncrewed spacecraft to the moon—first orbiters, then landers—as part of its Chang’e Project, named after a lunar goddess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But a real turning point for China’s interplanetary ambitions came in 2020, the same year as Perseverance’s launch to Mars.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That December, Chang’e-5 touched down in the moon’s Ocean of Storms, a realm of frozen lava 1,600 miles long. It grabbed some 2-billion-year-old rocks, put them in a rocket, and blasted them into the firmament. The samples were captured by a small orbiting spacecraft; crucially, the idea was not all that dissimilar from how MSR imagined catching its own samples, baseball-glove style. China’s lunar haul was then dropped off back on Earth just before Christmas. It marked the first time since 1976 that samples had been returned from the moon, and the mission was seamless.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="two labelled vials of soil next to a small ruler for scale" class="wp-image-1133692" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Change-5_soil_samples.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;China brought back soil samples from the moon’s Ocean of Storms during its Chang’e-5 mission, marking the first time since 1976 that samples had been returned from the moon.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;WIKIMEDIA COMMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;That same year, China made its first foray toward Mars. The project was called Tianwen-1, meaning “Questions to Heaven”—the first in a new series of audacious space missions to the Red Planet and orbiting asteroids. While its success was far from guaranteed, China was willing to kick into high gear immediately,&amp;nbsp;sending both an orbiting spacecraft and a rover to Mars at the same time. No other country had ever managed to perform this act of spaceflight acrobatics on its first try.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Just as China ramped up its space schemes, some people in the scientific community began to wonder if NASA was (inadvertently) promising too much with MSR—and whether the heist would be worth the cost.&lt;/p&gt;  &lt;p&gt;In 2020, the price tag for the program had jumped from an already expensive $5.3 billion to an estimated $7 billion. (For context, NASA’s Near-Earth Object Surveyor mission, which is currently being pieced together, has a price tag of around $1.2 billion. This space observatory is designed to find Earthbound asteroids and is tasked with defending all 8 billion of us from a catastrophic impact.)&lt;/p&gt;  &lt;p&gt;But Perseverance was already on its way to Mars. It wasn’t as if this expensive train could go back to the station. The project’s advocates just hoped it’d actually make it there in one piece.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While the US had previously entered Martian orbit successfully, several other entry, descent, and landing attempts on the planet had ended in explosive disaster; the primary antagonist is the Martian atmosphere, which can cause spacecraft to tumble wildly out of control or heat up and ignite. Perseverance would be traveling at nearly 12,500 miles per hour as it entered Mars’s airspace, and to land it’d need to decelerate, deploy a parachute, fire several rockets, and pilot itself to the skies above Jezero Crater—before a levitating crane would drop off the actual rover.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Thankfully, Perseverance’s deployment went off without a hitch. On February 18, 2021, Mars became its new home—and the rover’s makers hugged, high-fived, and whooped for joy in NASA’s flight control room.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Lori Glaze, then director of&amp;nbsp;NASA’s planetary science division,&amp;nbsp;said at the time, “Now the fun really starts.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133603" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/NHQ202102180066orig.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Members of NASA’s Perseverance rover team at the Jet Propulsion Laboratory in Pasadena, California, celebrate after receiving confirmation that the spacecraft successfully touched down on Mars in February 2021.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/BILL INGALLS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;That very same month, China arrived at Mars’s doorstep for the first time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On February 10, 2021, Tianwen-1 began to orbit the planet. Then, on May 14, it slipped a drop shipment through the spacecraft-frying atmosphere to deliver a rover onto an expansive landscape called Utopia Planitia—giving Perseverance a neighbor, albeit one 1,200 miles away.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;This explorer was nowhere near as sophisticated as Perseverance, and its assignment was a far cry from a sample return mission. It had some cameras and scientific instruments for studying its environment, making it comparable to one of NASA’s older rovers. It was also supposed to operate for just three months (though it ended up persisting for an entire year before being fatally smothered by pernicious Martian dust).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, Tianwen-1 was a remarkable achievement for China, one that the US couldn’t help but applaud. “This is a really big deal,” said Roger Launius, then NASA’s chief historian.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;And even if grabbing pieces of Mars was increasingly likely in China’s future, it was &lt;em&gt;already happening&lt;/em&gt; in the present for the US. The race, the Americans thought, was over before it had even begun … right?&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Over the next few years, Perseverance went on an extraterrestrial joyride. It meandered through frozen flows of lava and journeyed over fans of sediment once washed about by copious liquid water. It pulled out rocks that preserved salty, muddy layers—exactly the environment that, on Earth, would be teeming with microorganisms and organic matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Jezero Crater clearly meets the astrobiological criterion for a sampling site where life may once have existed,” says Lunine from NASA’s Jet Propulsion Lab. “Rocks of broadly similar age and setting on Earth contain some of the earliest evidence for life on our own planet.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133618" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP21250588944004.jpg?w=1458" /&gt;&lt;figcaption class="wp-element-caption"&gt;The Perseverance rover has been on an extraterrestrial joyride since 2021, drilling holes in promising looking space rocks that it hopes could be teeming with microorganisms and organic matter. &lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Then, in September 2023, as Perseverance was trundling across the ruins of what may once have been a microbial metropolis, an independent panel of researchers published a report that made it clear, in no uncertain terms, that MSR was the opposite of okay.&lt;/p&gt;  &lt;p&gt;They found that the project was too decentralized among the nation’s plethora of NASA centers, leaving confusion as to who was actually in charge. And at its current pace, MSR wouldn’t get its Mars rocks back home until the 2040s at the earliest—as much as a whole decade later than initial estimates. And it would cost as much as $11 billion, more than doubling the initial tab.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“MSR was established with unrealistic budget and schedule expectations from the beginning,” the report reads. “MSR was also organized under an unwieldy structure. As a result, there is currently no credible, congruent technical, nor properly margined schedule, cost, and technical baseline that can be accomplished with the likely available funding.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;Members of Congress started to wonder aloud whether MSR should be canceled outright, and the scientific community that had once so enthusiastically supported the mission faced a moment of reckoning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Byrne, the planetary scientist from the Washington University in St. Louis, had always been something of a rebel, never really a fan of NASA’s multi-decadal, over-the-top fascination with Mars. The solar system, he argued, is filled with curious worlds to explore—especially Venus, another nearby rocky world that was once rather Earth-like. Couldn’t we spare some of NASA’s budget to make sure we explore Venus, too?&lt;/p&gt;  &lt;p&gt;Still, like many other critical colleagues, Byrne did not want to see MSR put down. The report’s findings didn’t change the fact that Perseverance was dutifully working around the clock to accomplish the mission’s opening stages. What would be the point of gathering all those samples if they were going to be left to stay on Mars? The community, Byrne explains, just needed to answer one question: “How do you do this in a way that’s faster and cheaper?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In April 2024, NASA publicly sought help from its industry partners in the space sector: Could anyone come up with a way to save MSR? Various players with spaceflight experience, like Lockheed Martin, sent in proposals for consideration.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt; &lt;p&gt;Then, just a few months later in July 2024, Perseverance came in clutch, finding those special leopard-spotted and speckled rocks in an old river valley—a sign of hope that NASA had been desperately seeking. Now the agency’s request for help was all the more urgent—these rocks had to get home. After various panels assessed plans that could effectively save MSR, two potential options for a faster, leaner, less expensive version were previewed at a January 2025 press briefing.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One option brought in tried-and-tested tech: Since Perseverance had been safely deployed onto the surface of Mars using a hovering platform known as a sky crane, it was proposed that the sample-gathering lander for MSR could also be dropped off using a sky crane, which would simplify this step and reduce the overall cost of the program. The other suggestion was that the lander could be delivered to Mars via a spaceship from a commercial spaceflight company. The lander design itself could also be streamlined, and tweaks could be made to the rocket that would launch the samples back into space.&lt;/p&gt;  &lt;p&gt;The proposals needed greater study, but everyone’s spirits were lifted by the fact these plans &lt;em&gt;could&lt;/em&gt;, at least theoretically, get samples back in the 2030s, not the 2040s. And, crucially, “it was possible to get the cost down,” says Jack Mustard, an Earth and planetary scientist at Brown University and a member of one of the two proposal-reviewing panels. Still, it didn’t save a lot: They could do MSR for $8 billion.&lt;/p&gt;  &lt;p&gt;“What we came up with was very reasonable, rational, much simpler,” says Christensen, who was part of the same review panel. “And $8 billion is about the right amount it would take to guarantee that it’s going to work.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_29"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-1133683" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image3_final.jpg?w=2500" width="2500" /&gt;&lt;div class="image-credit"&gt;XINMEI LIU&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;While the US became increasingly consumed with its own interplanetary woes, China was riding high.&lt;/p&gt;  &lt;p&gt;In June 2024, the sixth installment in the Chang’e project made history. It was another lunar sample return mission, but this one did something nobody had ever done in the history of spaceflight: It landed on the difficult-to-reach, out-of-view far side of the moon and snagged samples from it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China made it look effortless when a capsule containing matter from this previously untouched region safely landed in Inner Mongolia. Long Xiao, a planetary geoscientist at the China University of Geosciences, told reporters at the time that the mission’s success was “a cause for celebration for all humanity.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it was also effectively a bombshell for NASA. Yes, the moon is much closer to Earth, and it doesn’t have a spaceship-destroying atmosphere like Mars. But China was speedrunning through the race while America was largely looking the other way.&lt;/p&gt;  &lt;p&gt;Then, in May 2025, China launched Tianwen-2. Its destination was not Mars but a near-Earth asteroid. The plan is that it will scoop up some of the space rock’s primordial pebbles later this year and deliver them back to Earth in late 2027. In light of China’s past successes, many suspect it’ll nail this project, too.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Tianwen-2 on the launchpad" class="wp-image-1133598" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP25149225181672.jpg?w=2923" width="2923" /&gt;&lt;figcaption class="wp-element-caption"&gt;China’s Tianwen missions, meaning “Questions to Heaven,” aim to explore both Mars and orbiting asteroids. The Tianwen-2 probe blasted off in May 2025, headed toward a near-Earth asteroid for a sample-return mission.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;VCG/VCG VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;But perhaps the biggest blow to the US came in June 2025: China revealed its formal designs on returning samples from Mars—and potentially addressing the existence of life elsewhere in the cosmos. Chinese researchers outlined a bold plan for Tianwen-3 in the journal &lt;em&gt;Nature Astronomy&lt;/em&gt;. “Searching for signs of life, or astrobiology studies, are the first priority,” says Yuqi Qian, a lunar geologist at the University of Hong Kong. And while many observers had long been cognizant of this ambition, seeing it so clearly spelled out in academic writing made it &lt;em&gt;real&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_31"&gt; &lt;p&gt;“The selection of the landing site is still ongoing,” says&lt;strong&gt; &lt;/strong&gt;Li Yiliang, an astrobiologist at the University of Hong Kong, an author of the Tianwen-3 study, and a member of the spacecraft’s landing site selection team. But the paper notes, in no uncertain terms, that the mission will move at a breakneck pace. “The aim of China’s Mars sample return mission, known as Tianwen-3, is to collect at least 500g of samples from Mars and return them to Earth around 2031.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;2031&lt;/em&gt;. Even on its original, speedier timeline, America’s MSR plan wouldn’t get samples back by that date. So how is China planning to pull it off?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_33"&gt; &lt;p&gt;Qian explains that Tianwen-3 is building on the success of the lunar sample return program. Doing something similar for Mars is a rather giant technological leap (requiring two rockets, not one)—but, he argues, “the technologies here are similar.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The plan is for a duet of rockets to blast off from Earth in 2028. The first will contain the lander-ascender combination, or LAC. The second is the orbiter-returner combination, or ORC. The LAC will get to Mars and deploy a lander as well as a small helicopter, which will scout promising locations around the landing site while using a claw to bring several small samples back to the lander.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1133599" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Zhurong-with-lander-selfie.png?w=1818" /&gt;&lt;figcaption class="wp-element-caption"&gt;China’s Tianwen-3 mission is searching for signs of Martian life with an eye toward having samples back home sometime in 2031.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;中国新闻社 VIA WIKIMEDIA COMMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The LAC will then travel to the most promising site. The lander’s drill, which can get down to around seven feet below the surface, is the most important part of the mission. At that depth, there are greater odds of capturing signs of past life. When at least 500 grams of pristine rocks have been loaded aboard the lander, the samples will be launched into space, where the orbiter will be waiting to capture them and send them back home sometime in 2031.&lt;/p&gt;  &lt;p&gt;“The returned samples will be quarantined strictly in an under-planning facility near Hefei city,” says Yiliang. And there, in those bio-secure labs, scientists might very well find the first clear signs of alien life, past or present.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;The very same month that Chinese researchers published their daring plans for returning Mars samples, the new Trump administration released a draconian NASA budget for Congress to consider—one that sparked panic across the planetary science community.&lt;/p&gt;  &lt;p&gt;If enacted, it would have been a historic catastrophe for the venerable space agency, giving NASA its smallest budget since 1961. This would have forced it to let go of a huge number of staffers, slash its science program budget in half, and terminate 19 missions currently in operation. MSR was in the crosshairs, too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Grim is the word,” says Dreier of the Planetary Society.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Over the next few months, Congress pushed back on the potential gutting of NASA, but largely to save ongoing solar system exploration missions. MSR was not considered an active effort; Perseverance was effectively a scientific scout acting independently by this point. A counterproposal by the House offered up $300 million for MSR, but no policymaker was cheerleading for it. (The US Office of Management and Budget, the House Committee on Science, Space, and Technology, and the office of Sen. Ted Cruz of Texas, who chairs the Senate Committee on Commerce, Science, and Transportation did not respond to requests for comment.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_36"&gt; &lt;p&gt;“Mars Sample Return doesn’t seem to have very many advocates right now,” says Byrne. The project “isn’t featuring in anyone’s conversation at the moment, with all of the existential shit that’s happening to NASA.” Everyone working on a NASA mission hoped that they, and their spacecraft, would survive the onslaught. As Byrne adds: “[People are] just trying to keep their heads down.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_38"&gt; &lt;p&gt;Researchers in America suddenly found themselves at an inflection point. “The attack on science, and the attack on NASA science, has been very successful, in that it has completely demoralized the science community,” says Christensen. “Everyone’s in a state of shock.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I contacted NASA in July about the state of MSR, which was then in the middle of a months-long limbo, I was told that experts weren’t available to comment. Roxana Bardan, a spokesperson, instead sent a statement: “Under President Trump’s America First agenda, NASA is committed to sustained U.S. space leadership. We will continue to innovate, explore, and excel to ensure American preeminence in space.” (The agency did not respond to a follow-up request for comment.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That notion stood in direct contrast to what Christensen told me around the same time.&amp;nbsp;“The US … has led the exploration of Mars for 50 years,” he said. “And as we approach one of the key discovery points, we’re about to concede that leadership to someone else.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;From China’s perspective, the fumbling of MSR is more confusing than anything else. “NASA has so well prepared for her MSR mission in both technology and science, and I and my colleagues have learned so much from NASA’s scientific communities,” says Yiliang.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And if China wins the race because America decided to shoot itself in the foot? “This is sad,” he says. “If this comes true, I believe the Chinese will not be that happy to win the race in this way.”&lt;/p&gt;  &lt;p&gt;Tianwen-3 will still have to overcome many of the same hurdles as MSR. Nobody, for example, has autonomously launched a rocket of any kind off the surface of Mars. But many believe the Chinese can succeed, even at their program’s superspeed. Christensen, for one, fully expected several of their past robotic missions to the moon and Mars to fail—but “the fact that they pulled it off the first time really says a lot about their engineering capability,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Mustard agrees: “They know how to land; they know how to leave. I have a lot of confidence that they’ve learned enough from the lunar work that they’ll be able to do it.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_40"&gt; &lt;p&gt;Plus, Tianwen-3’s architecture is simpler than the US-European mission. It has fewer components, and fewer points of potential failure. This also means, though, that the quality of the loot will be somewhat lacking. Tianwen-3 will sample from only one small patch of Mars. Conversely, Perseverance is roving around a vast and geologically diverse landscape, sampling as it goes, which would translate to “literally orders of magnitude more science than what will come from the Chinese samples,” says Christensen.&lt;/p&gt;  &lt;p&gt;But China could serendipitously land on a biologically rich patch of the planet. As the Southwest Research Institute’s Hamilton says, the mission could “pick up something entirely unexpected and, you know, miraculous.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_42"&gt; &lt;p&gt;The likeliest outcome is still that neither nation finds fossilized microbes, but that China brings back rocks from Mars first. At the end of the day, that’s what Americans (and Europeans) will hear: “You’re second. You lost,” says Mustard.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="fullWidthImage"&gt;&lt;div class="fullWidthImage__imageWrapper--713fbd99308fe950febff06b694edeaa is-style-full-bleed"&gt;&lt;figure class="wp-block-image"&gt;&lt;source media="(max-width: 39.3749rem)" /&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/260225_xinmei_TR_RacetoMars_image4_final.jpg" /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;div class="fullWidthImage__credit--d43dc7ec3d50859db7eb8d2def69081a image-credit"&gt;Xinmei Liu&lt;/div&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_44"&gt; &lt;p&gt;Like many of his colleagues, Christensen is irked by the thought of losing the race to Mars, because it would be such an own goal. The US has been sending robots over there for decades and investing billions in forging the technology that would be required to make MSR a success. And suddenly “the Chinese come along and say, &lt;em&gt;Thank you very much, we’ll take all of that information—we’ll build one mission and go and do what you guys did the groundwork for&lt;/em&gt;,” Christensen says. “As a taxpayer, I’m like: It just seems foolish to me.”&lt;/p&gt;  &lt;p&gt;Even the MSR skeptics concede that this kind of loss would have sweeping ramifications. Byrne worries that if something like MSR can be snuffed out so easily, what’s to say the next big mission—to Jupiter, Saturn, and beyond—won’t suffer the same ignoble fate? In other words, the death of MSR would severely damage “the ability of the planetary community to dream big,” he says. “If we don’t pull this off, what does that mean? Are we not going to do big, expensive, difficult things?”&lt;/p&gt;  &lt;p&gt;Another big, expensive, difficult thing? Putting humans on Mars. Both critics and advocates of MSR largely agree it is an invaluable dress rehearsal. Making sure you can safely launch a rocket off Mars is a necessary prerequisite to ensuring that an array of equipment can survive for a long time on the planet’s lethal surface.&lt;/p&gt;  &lt;p&gt;China, too, has explicitly acknowledged this. As one of the first lines of the Tianwen-3 study states, “Mars is the most promising planet for humanity’s expansion beyond Earth, with its potential for future habitability and accessible resources.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Though such expansion is still of course a far-future dream, it’s not hard to see how losing the race here would put the US at a huge disadvantage. Members of America’s planetary science community say that to try to sway politicians in their favor, they have framed MSR as a national security issue. But they haven’t had much luck. “We’ve been in discussions with decision-makers who have never heard that perspective before,” says the Planetary Society’s Dreier.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_46"&gt;&lt;p&gt;“It is surprising that doesn’t have more weight,” adds Mustard.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite months of purgatory, it still stung when the coup de grâce arrived in January. In the draft for a must-pass spending bill, House and Senate appropriators spared NASA from the harshest proposed cuts, thereby saving dozens of spaceflight missions and preserving much of the agency’s planetary science output. But the bill provided absolutely zero political or financial support for MSR. There it was, in black and white: America’s plans to perform a history-making heist on Mars were dead. The bill became law in January and Perseverance, it seems, is now destined to rove alone on the Red Planet until its nuclear battery burns out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This austere reality clashes with the soaring aspirations outlined in the first Planetary Decadal Survey, written just over two decades ago. It stated that the US exploration of the solar system “has a proud past, a productive present, and an auspicious future.” It also noted that “answers to profound questions about our origins and our future may be within our grasp.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now the answers have all but slipped away. Even though Perseverance continues to roam, it’s increasingly likely we’ll never see those promising bespeckled rocks with human eyes, let alone any other rocks the rover finds intriguing. It is far easier to imagine that in the near future, perhaps in the early 2030s, Perseverance will point its camera up at the night sky above Jezero Crater. It will catch a small glimmer: Tianwen-3’s orbiter, preparing to send ancient rocks back to Earth. Meanwhile, Perseverance’s own sample tubes—perhaps some containing signs of life—will be trapped on the Martian surface, gathering dust.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133605" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/PIA25738orig.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;Sample tubes collected by the Perseverance rover may never make it home from the Martian surface.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;NASA/JPL-CALTECH/MSSS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;It is a sobering thought for Christensen. “We’ll wake up one day and go: What the hell?” he says. “How did we let this happen?”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Robin George Andrews is an award-winning science journalist and doctor of volcanoes based in London. He regularly writes about the Earth, space, and planetary sciences, and is the author of two critically acclaimed books:&amp;nbsp;&lt;/em&gt;Super Volcanoes&lt;em&gt;&amp;nbsp;(2021) and&amp;nbsp;&lt;/em&gt;How to Kill An Asteroid&amp;nbsp;&lt;em&gt;(2024).&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/26/1133584/america-china-mars-sample-return-space-race-nasa/</guid><pubDate>Thu, 26 Feb 2026 10:00:00 +0000</pubDate></item><item><title>This company claims a battery breakthrough. Now they need to prove it. (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/26/1133722/solid-state-batteries-donut-lab/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Donut-Solid-State-Battery-Hero-2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When a company claims to have created what’s essentially the holy grail of batteries, there are bound to be some questions.&lt;/p&gt;  &lt;p&gt;Interest has been swirling since Donut Lab, a Finnish company, announced last month that it had a new solid-state battery technology, one that was ready for large-scale production. The company said its batteries can charge super-fast and have a high energy density that would translate to ultra-long-range EVs. What’s more, it claimed the cells can operate safely in the extreme heat and cold, contain “green and abundant materials,” and would cost less than lithium-ion batteries do today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It sounded amazing—this sort of technology could transform the EV industry. But many quickly wondered if it was all too good to be true. Now, Donut Lab is releasing a series of videos that it says will prove its technology has the secret sauce. Let’s dig into why this company is making news, why many experts are skeptical, and what it all means for the battery industry right now.&lt;/p&gt;  &lt;p&gt;Solid-state batteries could deliver the next generation of EVs. In place of a liquid electrolyte (the material that ions move through inside a battery), the cells use a solid material, so they can be more compact. That means a significantly longer range, which could get more people excited to drive EVs.&lt;/p&gt; 
 &lt;p&gt;The problem is, getting these batteries to work and making them at the large scale required for the EV industry hasn’t been a simple task. Some of the world’s most powerful automakers and battery companies have been trying for years to get the technology off the ground. (Toyota at one point said it would have solid-state batteries in cars by 2020. Now it’s shooting for 2027 or 2028.)&lt;/p&gt;  &lt;p&gt;While it’s been a long time coming, it does feel as if solid-state batteries are closer than ever. Much of the progress so far has been on semi-solid-state batteries, which use materials like gels for electrolytes. But some companies, including several in China, are getting closer to true solid state. The world’s largest battery company, CATL, plans to manufacture small quantities in 2027. Another major Chinese automaker, Changan, plans to start testing installation of all-solid-state batteries in vehicles this year, with mass production expected to begin next year.&lt;/p&gt; 
 &lt;p&gt;Still, Donut Lab surprised the battery industry when, in a video released in early January ahead of the Consumer Electronics Show in Las Vegas, the company claimed it would put the world’s first all-solid-state battery into production vehicles.&lt;/p&gt;  &lt;p&gt;One of the splashiest claims in the announcement was that cells would have an energy density of 400 watt-hours per kilogram (the top commercial lithium-ion batteries today sit at about 250 to 300 Wh/kg). It was also claimed that the cells could charge in as little as five minutes, last 100,000 cycles, and retain 99% of capacity at high and low temperatures—while costing less than lithium-ion cells and being made from “100% green and abundant materials with global availability.”&lt;/p&gt;  &lt;p&gt;Many experts were immediately skeptical. “In the solid-state field, the technical barriers are very high,” said Shirley Meng, a professor of molecular engineering at the University of Chicago, when I spoke with her last month. She’d recently attended CES and visited Donut Lab’s booth. “They had zero demo, so I don’t believe it,” she says. “Call me conservative, but I would rather be careful than be sorry later.”&lt;/p&gt;  &lt;p&gt;“It’s one of those things where nobody knows—they’ve never heard of it,” said Eric Wachsman, a professor at the University of Maryland and cofounder of the solid-state battery company Ion Storage Systems, in a January interview. “They came out of nowhere.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Donut Lab has shared very little about what, exactly, this technology might be. It’s not uncommon for battery companies (or any startup, for that matter) to be quiet about technical details before they can get patents filed to protect their technology. But the combination of claims didn’t seem to line up with any known chemistries, leaving experts speculating and, in many cases, doubting Donut Lab’s claims.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“All the parameters are contradictory,” said Yang Hongxin, chairman and CEO of the Chinese battery giant Svolt Energy, in remarks to news outlets in January. For example, there’s often a trade-off between high energy density, which requires thicker electrodes that can store more energy, and fast charging, which requires ions to move quickly through cells. High-performance batteries are also expected to be costly, but Donut Lab claims its technology will be cheaper than lithium-ion technology.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a new video released last week, Donut Lab cofounder and CEO Marko Lehtimäki announced the company would be releasing a video series, called “I Donut Believe,” that would provide evidence for their claims. As a header on the accompanying website reads: “Fair enough. Here you go.”&lt;/p&gt;  &lt;p&gt;When the website went up last week, it included a countdown timer to Monday February 23, when the company released results from its first third-party testing: a fast charging test. The test showed that a single cell could charge from 0% to 80% capacity in about four and a half minutes—incredibly quick and quite impressive results. (One potential caveat to note is that the cells heated up quite a bit, so thermal management could be important in designing vehicles that use these batteries.)&lt;/p&gt; 

 &lt;p&gt;Even as we see the first technical test results, I’m still left with a lot of questions. How many cycles could this battery do at this charging speed? Can this same cell meet the company’s other performance claims? (I’ve reached out to Donut Lab several times over the past month, both to the company’s press email and to leadership on LinkedIn, but I haven’t gotten a response yet.)&lt;/p&gt;  &lt;p&gt;The company has certainly drummed up a lot of interest and attention with its rollout, and the theatrics aren’t over yet. There’s another countdown timer on Donut Lab’s site, which ends on Monday, March 2.&lt;/p&gt;  &lt;p&gt;I’m the first one to get excited about a new battery technology. But there’s a sentiment I’ve seen pop up a lot recently online, and one I can’t get out of my head as I continue to follow this story: “Extraordinary claims require extraordinary proof.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Donut-Solid-State-Battery-Hero-2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When a company claims to have created what’s essentially the holy grail of batteries, there are bound to be some questions.&lt;/p&gt;  &lt;p&gt;Interest has been swirling since Donut Lab, a Finnish company, announced last month that it had a new solid-state battery technology, one that was ready for large-scale production. The company said its batteries can charge super-fast and have a high energy density that would translate to ultra-long-range EVs. What’s more, it claimed the cells can operate safely in the extreme heat and cold, contain “green and abundant materials,” and would cost less than lithium-ion batteries do today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It sounded amazing—this sort of technology could transform the EV industry. But many quickly wondered if it was all too good to be true. Now, Donut Lab is releasing a series of videos that it says will prove its technology has the secret sauce. Let’s dig into why this company is making news, why many experts are skeptical, and what it all means for the battery industry right now.&lt;/p&gt;  &lt;p&gt;Solid-state batteries could deliver the next generation of EVs. In place of a liquid electrolyte (the material that ions move through inside a battery), the cells use a solid material, so they can be more compact. That means a significantly longer range, which could get more people excited to drive EVs.&lt;/p&gt; 
 &lt;p&gt;The problem is, getting these batteries to work and making them at the large scale required for the EV industry hasn’t been a simple task. Some of the world’s most powerful automakers and battery companies have been trying for years to get the technology off the ground. (Toyota at one point said it would have solid-state batteries in cars by 2020. Now it’s shooting for 2027 or 2028.)&lt;/p&gt;  &lt;p&gt;While it’s been a long time coming, it does feel as if solid-state batteries are closer than ever. Much of the progress so far has been on semi-solid-state batteries, which use materials like gels for electrolytes. But some companies, including several in China, are getting closer to true solid state. The world’s largest battery company, CATL, plans to manufacture small quantities in 2027. Another major Chinese automaker, Changan, plans to start testing installation of all-solid-state batteries in vehicles this year, with mass production expected to begin next year.&lt;/p&gt; 
 &lt;p&gt;Still, Donut Lab surprised the battery industry when, in a video released in early January ahead of the Consumer Electronics Show in Las Vegas, the company claimed it would put the world’s first all-solid-state battery into production vehicles.&lt;/p&gt;  &lt;p&gt;One of the splashiest claims in the announcement was that cells would have an energy density of 400 watt-hours per kilogram (the top commercial lithium-ion batteries today sit at about 250 to 300 Wh/kg). It was also claimed that the cells could charge in as little as five minutes, last 100,000 cycles, and retain 99% of capacity at high and low temperatures—while costing less than lithium-ion cells and being made from “100% green and abundant materials with global availability.”&lt;/p&gt;  &lt;p&gt;Many experts were immediately skeptical. “In the solid-state field, the technical barriers are very high,” said Shirley Meng, a professor of molecular engineering at the University of Chicago, when I spoke with her last month. She’d recently attended CES and visited Donut Lab’s booth. “They had zero demo, so I don’t believe it,” she says. “Call me conservative, but I would rather be careful than be sorry later.”&lt;/p&gt;  &lt;p&gt;“It’s one of those things where nobody knows—they’ve never heard of it,” said Eric Wachsman, a professor at the University of Maryland and cofounder of the solid-state battery company Ion Storage Systems, in a January interview. “They came out of nowhere.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Donut Lab has shared very little about what, exactly, this technology might be. It’s not uncommon for battery companies (or any startup, for that matter) to be quiet about technical details before they can get patents filed to protect their technology. But the combination of claims didn’t seem to line up with any known chemistries, leaving experts speculating and, in many cases, doubting Donut Lab’s claims.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“All the parameters are contradictory,” said Yang Hongxin, chairman and CEO of the Chinese battery giant Svolt Energy, in remarks to news outlets in January. For example, there’s often a trade-off between high energy density, which requires thicker electrodes that can store more energy, and fast charging, which requires ions to move quickly through cells. High-performance batteries are also expected to be costly, but Donut Lab claims its technology will be cheaper than lithium-ion technology.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a new video released last week, Donut Lab cofounder and CEO Marko Lehtimäki announced the company would be releasing a video series, called “I Donut Believe,” that would provide evidence for their claims. As a header on the accompanying website reads: “Fair enough. Here you go.”&lt;/p&gt;  &lt;p&gt;When the website went up last week, it included a countdown timer to Monday February 23, when the company released results from its first third-party testing: a fast charging test. The test showed that a single cell could charge from 0% to 80% capacity in about four and a half minutes—incredibly quick and quite impressive results. (One potential caveat to note is that the cells heated up quite a bit, so thermal management could be important in designing vehicles that use these batteries.)&lt;/p&gt; 

 &lt;p&gt;Even as we see the first technical test results, I’m still left with a lot of questions. How many cycles could this battery do at this charging speed? Can this same cell meet the company’s other performance claims? (I’ve reached out to Donut Lab several times over the past month, both to the company’s press email and to leadership on LinkedIn, but I haven’t gotten a response yet.)&lt;/p&gt;  &lt;p&gt;The company has certainly drummed up a lot of interest and attention with its rollout, and the theatrics aren’t over yet. There’s another countdown timer on Donut Lab’s site, which ends on Monday, March 2.&lt;/p&gt;  &lt;p&gt;I’m the first one to get excited about a new battery technology. But there’s a sentiment I’ve seen pop up a lot recently online, and one I can’t get out of my head as I continue to follow this story: “Extraordinary claims require extraordinary proof.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/26/1133722/solid-state-batteries-donut-lab/</guid><pubDate>Thu, 26 Feb 2026 11:00:00 +0000</pubDate></item><item><title>[NEW] The Download: how America lost its lead in the hunt for alien life, and ambitious battery claims (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/26/1133734/the-download-how-america-lost-its-lead-in-the-hunt-for-alien-life-and-ambitious-battery-claims/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;America was winning the race to find Martian life. Then China jumped in.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In July 2024, NASA’s Perseverance rover came across a peculiar rocky outcrop on Mars covered in strange spots. On Earth, these marks are almost always produced by microbial life.&lt;/p&gt;  &lt;p&gt;Sure, those specks are not definitive proof of alien life. But they are the best hint yet that life may not be a one-off event in the cosmos.&lt;/p&gt;&lt;p&gt;But the only way to know for sure is to bring a sample of that rock home to study.&lt;/p&gt;&lt;p&gt;Now, just over a year and a half later, the project to do so is on life support, with zero funding flowing in 2026 and little backing left in Congress. As a result, those oh-so-promising rocks may be stuck out there forever.&lt;/p&gt;&lt;p&gt;This also means that, in the race to find evidence of alien life, America has effectively ceded its pole position to its greatest geopolitical rival: China. The superpower is moving full steam ahead with its own version of the mission to bring the rock samples home. It’s leaner than America and Europe’s mission, and the rock samples it will snatch from Mars will likely not be as high quality. But that won’t be the headline people remember—the one in the scientific journals and the history books.&lt;/p&gt;&lt;p&gt;Nearly a dozen project insiders and scientists in both the US and China shared with me the story of how America blew its lead in the new space race. It’s full of wild dreams and promising discoveries—as well as mismanagement, eye-watering costs, and, ultimately, anger and disappointment. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Robin George Andrews&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is also part of the Big Story series: &lt;em&gt;MIT Technology Review&lt;/em&gt;’s most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/strong&gt;&lt;strong&gt;Check out the rest of them here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This company claims a battery breakthrough. Now they need to prove it.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When a company claims to have created what’s essentially the holy grail of batteries, there are bound to be some questions.&lt;/p&gt;  &lt;p&gt;Interest has been swirling since Donut Lab, a Finnish company, announced last month that it had a new solid-state battery technology, one that was ready for large-scale production. The company said its batteries can charge super-fast and have a high energy density that would translate to ultra-long-range EVs. What’s more, it claimed the cells can operate safely in the extreme heat and cold, contain “green and abundant materials,” and would cost less than lithium-ion batteries do today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;It sounded amazing—this sort of technology could transform the EV industry. But many quickly wondered if it was all too good to be true. Let’s dig into why this company is making news, why many experts are skeptical, and what it all means for the battery industry right now.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Chinese law enforcement tried to get ChatGPT to discredit Japan’s prime minister&lt;/strong&gt;&lt;br /&gt;OpenAI claims the chatbot refused to help plan an online smear campaign. (Axios)&lt;br /&gt;+ &lt;em&gt;The user asked ChatGPT to edit status reports on covert influence operations. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Meta’s AI is sending junk tips to child abuse investigators&lt;/strong&gt;&lt;br /&gt;Not only are they a serious drain on resources—they’re hindering investigations. (The Guardian)&lt;br /&gt;+ &lt;em&gt;US investigators are using AI to detect child abuse images made by AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A judge has dismissed xAI’s lawsuit against OpenAI&lt;/strong&gt;&lt;br /&gt;Elon Musk’s startup has failed to prove that its rival committed any misconduct. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;xAI had accused former employees of taking trade secrets to OpenAI. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;It could refile, but would need to modify its claims. &lt;/em&gt;(The Verge)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 China appears to be masking regular drone flights&lt;br /&gt;In what could be rehearsals for a potential invasion of Taiwan. (Reuters)&lt;br /&gt;+ &lt;em&gt;Taiwan’s “silicon shield” could be weakening. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Pro-AI super PACs are raising huge sums ahead of the US midterm elections&lt;br /&gt;They’re making significantly higher sums than their pro-regulation counterparts. (FT $)&lt;br /&gt;+ &lt;em&gt;Anthropic is backing a regulation-friendly PAC group called Public First Action. &lt;/em&gt;(NYT $&lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Experts are worried about AI slop videos’ effects on child development&lt;br /&gt;&lt;/strong&gt;The nonsensical clips tend to lack structure and confuse children.(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Around 400 million people are living with long covid&lt;br /&gt;&lt;/strong&gt;And its effects are rippling far beyond its physical symptoms. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Scientists are finding signals of long covid in blood. They could lead to new treatments. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Tech bros are opting out of interviews with mainstream media&lt;br /&gt;&lt;/strong&gt;And gravitating toward much less critical online streams. (New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The ISS is surprisingly vulnerable&lt;/strong&gt;&lt;br /&gt;There’s a major gap in its critical defenses. (Wired $)&lt;br /&gt;+ &lt;em&gt;Data centers are heading to space, and our laws aren’t ready. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;Meet the astronaut training tourists to fly in the world’s first commercial space station. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;strong&gt;10 We’ve lost our appetite for fake meat 🍔&lt;/strong&gt;&lt;br /&gt;Even plant-based meat makers are admitting some products don’t taste great. (Economist $)&lt;br /&gt;+ &lt;em&gt;The price of (real) beef has soared recently. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Here’s what a lab-grown burger tastes like. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We are using carrots and sticks.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Seth Besmertnik, chief executive of digital marketing startup Conductor, explains his approach to vigorously vetting his workers’ AI literacy to the Wall Street Journal.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133736" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_e4dd46.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Tiny faux organs could crack the mystery of menstruation&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;No one is entirely sure how—or why—the human body choreographs menstruation; the monthly dance of cellular birth, maturation, and death. Many people desperately need treatments to make their period more manageable, but it’s difficult for scientists to design medications without understanding how menstruation really works.&lt;/p&gt;&lt;p&gt;That understanding could be in the works, thanks to endometrial organoids—biomedical tools made from bits of the tissue that lines the uterus, called the endometrium. Organoids have already provided insights into how endometrial cells communicate and coordinate, and why menstruation is routine for some people and fraught for others—and some researchers are hopeful that these early results mark the dawn of a new era. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Saima Sidik&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The crazy but true story about the&lt;em&gt; Elder Scrolls III &lt;/em&gt;fans who built a world the size of a small country into it.&lt;br /&gt;+ How to master the tricky art of making the perfect sourdough loaf.&lt;br /&gt;+ This adorable Pika is the real-life inspiration for Pikachu.&lt;br /&gt;+&amp;nbsp; How many of these animated classics have you seen?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;America was winning the race to find Martian life. Then China jumped in.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In July 2024, NASA’s Perseverance rover came across a peculiar rocky outcrop on Mars covered in strange spots. On Earth, these marks are almost always produced by microbial life.&lt;/p&gt;  &lt;p&gt;Sure, those specks are not definitive proof of alien life. But they are the best hint yet that life may not be a one-off event in the cosmos.&lt;/p&gt;&lt;p&gt;But the only way to know for sure is to bring a sample of that rock home to study.&lt;/p&gt;&lt;p&gt;Now, just over a year and a half later, the project to do so is on life support, with zero funding flowing in 2026 and little backing left in Congress. As a result, those oh-so-promising rocks may be stuck out there forever.&lt;/p&gt;&lt;p&gt;This also means that, in the race to find evidence of alien life, America has effectively ceded its pole position to its greatest geopolitical rival: China. The superpower is moving full steam ahead with its own version of the mission to bring the rock samples home. It’s leaner than America and Europe’s mission, and the rock samples it will snatch from Mars will likely not be as high quality. But that won’t be the headline people remember—the one in the scientific journals and the history books.&lt;/p&gt;&lt;p&gt;Nearly a dozen project insiders and scientists in both the US and China shared with me the story of how America blew its lead in the new space race. It’s full of wild dreams and promising discoveries—as well as mismanagement, eye-watering costs, and, ultimately, anger and disappointment. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Robin George Andrews&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is also part of the Big Story series: &lt;em&gt;MIT Technology Review&lt;/em&gt;’s most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/strong&gt;&lt;strong&gt;Check out the rest of them here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This company claims a battery breakthrough. Now they need to prove it.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;When a company claims to have created what’s essentially the holy grail of batteries, there are bound to be some questions.&lt;/p&gt;  &lt;p&gt;Interest has been swirling since Donut Lab, a Finnish company, announced last month that it had a new solid-state battery technology, one that was ready for large-scale production. The company said its batteries can charge super-fast and have a high energy density that would translate to ultra-long-range EVs. What’s more, it claimed the cells can operate safely in the extreme heat and cold, contain “green and abundant materials,” and would cost less than lithium-ion batteries do today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;It sounded amazing—this sort of technology could transform the EV industry. But many quickly wondered if it was all too good to be true. Let’s dig into why this company is making news, why many experts are skeptical, and what it all means for the battery industry right now.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Chinese law enforcement tried to get ChatGPT to discredit Japan’s prime minister&lt;/strong&gt;&lt;br /&gt;OpenAI claims the chatbot refused to help plan an online smear campaign. (Axios)&lt;br /&gt;+ &lt;em&gt;The user asked ChatGPT to edit status reports on covert influence operations. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Meta’s AI is sending junk tips to child abuse investigators&lt;/strong&gt;&lt;br /&gt;Not only are they a serious drain on resources—they’re hindering investigations. (The Guardian)&lt;br /&gt;+ &lt;em&gt;US investigators are using AI to detect child abuse images made by AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A judge has dismissed xAI’s lawsuit against OpenAI&lt;/strong&gt;&lt;br /&gt;Elon Musk’s startup has failed to prove that its rival committed any misconduct. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;xAI had accused former employees of taking trade secrets to OpenAI. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;It could refile, but would need to modify its claims. &lt;/em&gt;(The Verge)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 China appears to be masking regular drone flights&lt;br /&gt;In what could be rehearsals for a potential invasion of Taiwan. (Reuters)&lt;br /&gt;+ &lt;em&gt;Taiwan’s “silicon shield” could be weakening. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Pro-AI super PACs are raising huge sums ahead of the US midterm elections&lt;br /&gt;They’re making significantly higher sums than their pro-regulation counterparts. (FT $)&lt;br /&gt;+ &lt;em&gt;Anthropic is backing a regulation-friendly PAC group called Public First Action. &lt;/em&gt;(NYT $&lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Experts are worried about AI slop videos’ effects on child development&lt;br /&gt;&lt;/strong&gt;The nonsensical clips tend to lack structure and confuse children.(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Around 400 million people are living with long covid&lt;br /&gt;&lt;/strong&gt;And its effects are rippling far beyond its physical symptoms. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Scientists are finding signals of long covid in blood. They could lead to new treatments. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Tech bros are opting out of interviews with mainstream media&lt;br /&gt;&lt;/strong&gt;And gravitating toward much less critical online streams. (New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The ISS is surprisingly vulnerable&lt;/strong&gt;&lt;br /&gt;There’s a major gap in its critical defenses. (Wired $)&lt;br /&gt;+ &lt;em&gt;Data centers are heading to space, and our laws aren’t ready. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;Meet the astronaut training tourists to fly in the world’s first commercial space station. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;strong&gt;10 We’ve lost our appetite for fake meat 🍔&lt;/strong&gt;&lt;br /&gt;Even plant-based meat makers are admitting some products don’t taste great. (Economist $)&lt;br /&gt;+ &lt;em&gt;The price of (real) beef has soared recently. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Here’s what a lab-grown burger tastes like. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We are using carrots and sticks.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Seth Besmertnik, chief executive of digital marketing startup Conductor, explains his approach to vigorously vetting his workers’ AI literacy to the Wall Street Journal.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133736" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_e4dd46.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Tiny faux organs could crack the mystery of menstruation&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;No one is entirely sure how—or why—the human body choreographs menstruation; the monthly dance of cellular birth, maturation, and death. Many people desperately need treatments to make their period more manageable, but it’s difficult for scientists to design medications without understanding how menstruation really works.&lt;/p&gt;&lt;p&gt;That understanding could be in the works, thanks to endometrial organoids—biomedical tools made from bits of the tissue that lines the uterus, called the endometrium. Organoids have already provided insights into how endometrial cells communicate and coordinate, and why menstruation is routine for some people and fraught for others—and some researchers are hopeful that these early results mark the dawn of a new era. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Saima Sidik&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The crazy but true story about the&lt;em&gt; Elder Scrolls III &lt;/em&gt;fans who built a world the size of a small country into it.&lt;br /&gt;+ How to master the tricky art of making the perfect sourdough loaf.&lt;br /&gt;+ This adorable Pika is the real-life inspiration for Pikachu.&lt;br /&gt;+&amp;nbsp; How many of these animated classics have you seen?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/26/1133734/the-download-how-america-lost-its-lead-in-the-hunt-for-alien-life-and-ambitious-battery-claims/</guid><pubDate>Thu, 26 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] Trace raises $3M to solve the AI agent adoption problem in enterprise (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/trace-raises-3-million-to-solve-the-agent-adoption-problem/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Trace_TechCrunch.jpg?resize=1200,961" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For all their potential, AI agents have been slow to make an impact in the enterprise, and one new startup is betting that the reason they haven’t is a lack of context. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched as part of Y Combinator’s 2025 summer cohort, Trace is a workflow orchestration startup aimed at filling that gap. The company maps complex corporate environments and processes so that agents have the context they need to scale quickly.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“OpenAI and Anthropic are building these brilliant interns that can be leveraged within the company,” says Trace CEO Tim Cherkasov, referring to the AI labs’ tools. “We’re building the manager that knows where to put them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, the London-based company said it had raised $3 million in seed funding from Y Combinator, Zeno Ventures, Transpose Platform Management, Goodwater Capital, Formosa Capital, and WeFunder. Angel investors Benjamin Bryant and Kevin Moore also invested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trace’s system starts by building a knowledge graph from a company’s existing tools — systems like email, Slack, and Airtable that shape the day-to-day working life of the firm. With that context in place, users can prompt the system with a high-level task — like “We need to design a new microsite” or “Let’s develop our 2027 sales plan” — and Trace will come back with a step-by-step workflow, delegating some tasks to AI agents and assigning others to human workers. When the system does invoke an AI agent, it will prompt it with the specific data needed to complete its sub-task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea is to automate away the delicate work of on-boarding AI agents, one of the biggest blockers for actual deployment within companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With so many companies focused on agentic AI, Trace will have plenty of competition. Earlier this week, Anthropic launched its own take on enterprise agents, focused on pre-built plug-ins for specific departmental functions. And many of the workplace productivity services Trace will be drawing from, like Atlassian’s Jira, are launching their own agents, which will potentially compete with the startup’s system.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But Trace’s founders believe their knowledge-graph approach will be the key to success, as they can build context engineering deep into the structure of agentic deployment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“2024 and 2025 was still about prompt engineering. Now we’ve moved from prompt engineering to context engineering,” says CTO Artur Romanov. “Whoever provides the best context at the right time is going to be the infrastructure on top of which the AI-first companies will be built. And we hope to be that infrastructure.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Trace_TechCrunch.jpg?resize=1200,961" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For all their potential, AI agents have been slow to make an impact in the enterprise, and one new startup is betting that the reason they haven’t is a lack of context. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched as part of Y Combinator’s 2025 summer cohort, Trace is a workflow orchestration startup aimed at filling that gap. The company maps complex corporate environments and processes so that agents have the context they need to scale quickly.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“OpenAI and Anthropic are building these brilliant interns that can be leveraged within the company,” says Trace CEO Tim Cherkasov, referring to the AI labs’ tools. “We’re building the manager that knows where to put them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, the London-based company said it had raised $3 million in seed funding from Y Combinator, Zeno Ventures, Transpose Platform Management, Goodwater Capital, Formosa Capital, and WeFunder. Angel investors Benjamin Bryant and Kevin Moore also invested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trace’s system starts by building a knowledge graph from a company’s existing tools — systems like email, Slack, and Airtable that shape the day-to-day working life of the firm. With that context in place, users can prompt the system with a high-level task — like “We need to design a new microsite” or “Let’s develop our 2027 sales plan” — and Trace will come back with a step-by-step workflow, delegating some tasks to AI agents and assigning others to human workers. When the system does invoke an AI agent, it will prompt it with the specific data needed to complete its sub-task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea is to automate away the delicate work of on-boarding AI agents, one of the biggest blockers for actual deployment within companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With so many companies focused on agentic AI, Trace will have plenty of competition. Earlier this week, Anthropic launched its own take on enterprise agents, focused on pre-built plug-ins for specific departmental functions. And many of the workplace productivity services Trace will be drawing from, like Atlassian’s Jira, are launching their own agents, which will potentially compete with the startup’s system.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But Trace’s founders believe their knowledge-graph approach will be the key to success, as they can build context engineering deep into the structure of agentic deployment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“2024 and 2025 was still about prompt engineering. Now we’ve moved from prompt engineering to context engineering,” says CTO Artur Romanov. “Whoever provides the best context at the right time is going to be the infrastructure on top of which the AI-first companies will be built. And we hope to be that infrastructure.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/trace-raises-3-million-to-solve-the-agent-adoption-problem/</guid><pubDate>Thu, 26 Feb 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Figma partners with OpenAI to bake in support for Codex (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/figma-partners-with-openai-to-bake-in-support-for-codex/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Codex-to-Figma-feat.jpg?w=1049" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Figma is integrating OpenAI’s AI coding tool, Codex, to let users create and tweak designs from within their coding environments. The move comes a week after the design company struck a similar partnership with Anthropic to integrate Claude Code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This integration lets users start working with a design in Figma or code in Codex, and move between the two platforms easily using Figma’s MCP (Model Context Protocol) server.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Previously, users could bring details from Figma design files, Figma Make, or FigJam into Codex for code-based implementation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With this integration, teams can build on their best ideas — not just their first idea — by combining the best of code with the creativity, collaboration, and craft that comes with Figma’s infinite canvas,” Loredana Crisan, Figma’s chief design officer, said.&lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30973171"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The integration makes Codex powerful for a much broader range of builders and businesses because it doesn’t assume you’re ‘a designer’ or ‘an engineer’ first. Engineers can iterate visually without leaving their flow, and designers can work closer to real implementation without becoming full-time coders,” Codex product lead Alexander Embiricos said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI first launched Codex as a command-line coding assistant last year to compete with Anthropic’s much lauded Claude Code. Later, the company built the coding tool into ChatGPT, and earlier this month launched a dedicated MacOS app for Codex. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The MacOS app was downloaded a million times within the first week of release. The company also released two new Codex models just days afterwards. OpenAI said that over a million users are using Codex weekly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Figma has been a prominent partner for OpenAI, and it was one of the first companies to launch an app in ChatGPT in October 2025. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Codex-to-Figma-feat.jpg?w=1049" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Figma is integrating OpenAI’s AI coding tool, Codex, to let users create and tweak designs from within their coding environments. The move comes a week after the design company struck a similar partnership with Anthropic to integrate Claude Code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This integration lets users start working with a design in Figma or code in Codex, and move between the two platforms easily using Figma’s MCP (Model Context Protocol) server.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Previously, users could bring details from Figma design files, Figma Make, or FigJam into Codex for code-based implementation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With this integration, teams can build on their best ideas — not just their first idea — by combining the best of code with the creativity, collaboration, and craft that comes with Figma’s infinite canvas,” Loredana Crisan, Figma’s chief design officer, said.&lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30973171"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The integration makes Codex powerful for a much broader range of builders and businesses because it doesn’t assume you’re ‘a designer’ or ‘an engineer’ first. Engineers can iterate visually without leaving their flow, and designers can work closer to real implementation without becoming full-time coders,” Codex product lead Alexander Embiricos said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI first launched Codex as a command-line coding assistant last year to compete with Anthropic’s much lauded Claude Code. Later, the company built the coding tool into ChatGPT, and earlier this month launched a dedicated MacOS app for Codex. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The MacOS app was downloaded a million times within the first week of release. The company also released two new Codex models just days afterwards. OpenAI said that over a million users are using Codex weekly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Figma has been a prominent partner for OpenAI, and it was one of the first companies to launch an app in ChatGPT in October 2025. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/figma-partners-with-openai-to-bake-in-support-for-codex/</guid><pubDate>Thu, 26 Feb 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Exhibit in Boston’s startup ecosystem at TechCrunch Founder Summit 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/exhibit-in-bostons-startup-ecosystem-at-techcrunch-founder-summit-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On June 9, over 1,000 founders, investors, and decision-makers will gather for &lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;. This isn’t just foot traffic. It’s a full day of concentrated deal flow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An exhibit table turns that energy into measurable growth. You&amp;nbsp;don’t&amp;nbsp;need more awareness. You need customers, capital, and strategic partners.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Secure your exhibit table&lt;/strong&gt;&amp;nbsp;and put your startup&amp;nbsp;at the center of the startup universe.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Early Stage 2024 exhibit" class="wp-image-2973590" height="400" src="https://techcrunch.com/wp-content/uploads/2025/01/Exhibit-Early-Stage_2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-nbsp-exhibiting-nbsp-drives-real-growth"&gt;Why&amp;nbsp;exhibiting&amp;nbsp;drives real growth&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Direct access to buyers:&lt;/strong&gt; The Expo Hall is where founders and operators actively source tools and partners. Capture leads instantly through the event app and start building your pipeline on the spot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where handshakes replace cold pitches:&lt;/strong&gt; Move from cold outreach to face-to-face conversations. With access to roundtables, breakouts, and curated networking, your team can turn visibility into velocity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Credibility that compounds: &lt;/strong&gt;Your startup is featured across the Founder Summit website, app, sponsor directory, announcements, and closing ceremony — reinforcing trust with customers and investors alike.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Multi-channel ROI:&lt;/strong&gt; Lead-gen tools, sponsor listings, and team-wide passes mean you’re not just exhibiting. You’re executing across sales, marketing, and fundraising at the same time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Deploy your team strategically:&lt;/strong&gt; With five total passes, you can split focus across sales, partnerships, hiring, and curated meetings to maximize every hour onsite.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-nbsp-included-in-the-tc-founder-summit-exhibitor-package"&gt;What’s&amp;nbsp;included in the TC Founder Summit exhibitor package&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Dedicated 6′ x 3′ exhibit space&lt;/strong&gt;&amp;nbsp;with a 6-foot table, 2 chairs, and table linen&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Branded tabletop sign&lt;/strong&gt;&amp;nbsp;(11” x 14”) featuring your&amp;nbsp;sponsor logo&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lead-generation tools&lt;/strong&gt;&amp;nbsp;to capture meaningful leads&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;5 event tickets&lt;/strong&gt;&amp;nbsp;for your team or guests&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Company logo featured&lt;/strong&gt;&amp;nbsp;in the&amp;nbsp;sponsor&amp;nbsp;section of the TC Founder Summit event page&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Company profile&lt;/strong&gt;&amp;nbsp;listed in the&amp;nbsp;event app&amp;nbsp;for added visibility&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;On-site signage&lt;/strong&gt;&amp;nbsp;across the venue&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Complimentary access to partner Wi-Fi&lt;/strong&gt;&amp;nbsp;for seamless networking&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-first-come-first-served-book-now"&gt;First come, first served — book now&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Spots are limited and first come, first served.&amp;nbsp;If&amp;nbsp;you’re&amp;nbsp;ready to turn three days into months of pipeline,&amp;nbsp;&lt;strong&gt;reserve your exhibit table now&lt;/strong&gt;&amp;nbsp;before your competitor does.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit 2026, June 9, 2026" class="wp-image-3094672" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/16x9_GeneralArticleImageHeader_FS26_V2.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On June 9, over 1,000 founders, investors, and decision-makers will gather for &lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;. This isn’t just foot traffic. It’s a full day of concentrated deal flow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An exhibit table turns that energy into measurable growth. You&amp;nbsp;don’t&amp;nbsp;need more awareness. You need customers, capital, and strategic partners.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Secure your exhibit table&lt;/strong&gt;&amp;nbsp;and put your startup&amp;nbsp;at the center of the startup universe.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Early Stage 2024 exhibit" class="wp-image-2973590" height="400" src="https://techcrunch.com/wp-content/uploads/2025/01/Exhibit-Early-Stage_2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-nbsp-exhibiting-nbsp-drives-real-growth"&gt;Why&amp;nbsp;exhibiting&amp;nbsp;drives real growth&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Direct access to buyers:&lt;/strong&gt; The Expo Hall is where founders and operators actively source tools and partners. Capture leads instantly through the event app and start building your pipeline on the spot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where handshakes replace cold pitches:&lt;/strong&gt; Move from cold outreach to face-to-face conversations. With access to roundtables, breakouts, and curated networking, your team can turn visibility into velocity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Credibility that compounds: &lt;/strong&gt;Your startup is featured across the Founder Summit website, app, sponsor directory, announcements, and closing ceremony — reinforcing trust with customers and investors alike.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Multi-channel ROI:&lt;/strong&gt; Lead-gen tools, sponsor listings, and team-wide passes mean you’re not just exhibiting. You’re executing across sales, marketing, and fundraising at the same time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Deploy your team strategically:&lt;/strong&gt; With five total passes, you can split focus across sales, partnerships, hiring, and curated meetings to maximize every hour onsite.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-nbsp-included-in-the-tc-founder-summit-exhibitor-package"&gt;What’s&amp;nbsp;included in the TC Founder Summit exhibitor package&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Dedicated 6′ x 3′ exhibit space&lt;/strong&gt;&amp;nbsp;with a 6-foot table, 2 chairs, and table linen&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Branded tabletop sign&lt;/strong&gt;&amp;nbsp;(11” x 14”) featuring your&amp;nbsp;sponsor logo&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lead-generation tools&lt;/strong&gt;&amp;nbsp;to capture meaningful leads&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;5 event tickets&lt;/strong&gt;&amp;nbsp;for your team or guests&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Company logo featured&lt;/strong&gt;&amp;nbsp;in the&amp;nbsp;sponsor&amp;nbsp;section of the TC Founder Summit event page&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Company profile&lt;/strong&gt;&amp;nbsp;listed in the&amp;nbsp;event app&amp;nbsp;for added visibility&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;On-site signage&lt;/strong&gt;&amp;nbsp;across the venue&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Complimentary access to partner Wi-Fi&lt;/strong&gt;&amp;nbsp;for seamless networking&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-first-come-first-served-book-now"&gt;First come, first served — book now&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Spots are limited and first come, first served.&amp;nbsp;If&amp;nbsp;you’re&amp;nbsp;ready to turn three days into months of pipeline,&amp;nbsp;&lt;strong&gt;reserve your exhibit table now&lt;/strong&gt;&amp;nbsp;before your competitor does.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit 2026, June 9, 2026" class="wp-image-3094672" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/16x9_GeneralArticleImageHeader_FS26_V2.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/exhibit-in-bostons-startup-ecosystem-at-techcrunch-founder-summit-2026/</guid><pubDate>Thu, 26 Feb 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Horror Awakens in the Cloud: GeForce NOW Unleashes Capcom’s ‘Resident Evil Requiem’ (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-resident-evil-requiem/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;GeForce NOW’s anniversary celebration reaches a chilling crescendo as Capcom’s &lt;i&gt;Resident Evil: Requiem &lt;/i&gt;creeps into the cloud — and the horrors look better than ever on a GeForce NOW Ultimate membership.&lt;/p&gt;
&lt;p&gt;To mark the occasion, a special launch bundle rises from the shadows, pairing the game with a yearlong Ultimate membership for a limited time.&lt;/p&gt;
&lt;p&gt;It’s not a celebration party without treats. GeForce NOW is also offering members a new reward to use in &lt;i&gt;Delta Force&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;Suit up and grab it alongside 11 new games joining the cloud this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Nightmare Returns in the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;A new era of survival horror dawns with &lt;i&gt;Resident Evil: Requiem&lt;/i&gt;, the iconic Capcom series’ most immersive entry yet. Follow FBI analyst Grace Ashcroft and veteran agent Leon S. Kennedy as their stories and playstyles intertwine in a chilling, emotional fight for survival.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90211"&gt;&lt;img alt="alt" class="size-large wp-image-90211" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/gfn-social-rtx-5080-spotlights-resident-evil-requiem-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90211"&gt;&lt;em&gt;The city has been waiting — and it remembers.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Return to Raccoon City, the ruined heart of a 1998 bioweapon disaster now buried in government secrecy. Grace investigates her mother’s mysterious death while Leon, hardened by years of battling outbreaks, uncovers a new bioterror threat spreading through the Midwest. Classic &lt;i&gt;Resident Evil&lt;/i&gt; survival horror returns with tense combat and clever puzzles — now enhanced with seamless switching between first‑ and third‑person views for a more personal nightmare.&lt;/p&gt;
&lt;p&gt;With GeForce RTX 5080-class power in the cloud, experience &lt;i&gt;Requiem &lt;/i&gt;with lifelike lighting, full path tracing, ray‑traced reflections and cinematic realism at up to 5K resolution with high dynamic range, plus NVIDIA DLSS 4 with Multi Frame Generation for maximum performance. The Ultimate membership keeps every encounter smooth and immersive when streaming from powerful GPUs in the cloud.&lt;/p&gt;
&lt;p&gt;To celebrate GeForce NOW’s sixth anniversary, a special launch offer emerges from the fog: For a limited time, &lt;i&gt;Resident Evil: Requiem&lt;/i&gt; is included with the purchase of a 12‑month Ultimate membership. It’s the perfect way to return to the city of disaster and despair, now more haunting and beautiful than ever.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Priority Package&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;GeForce NOW marks six epic years in the cloud, and the party lands on the &lt;i&gt;Delta Force&lt;/i&gt; frontline with a new reward drop.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90203"&gt;&lt;img alt="Delta Force reward on GeForce NOW" class="wp-image-90203 size-large" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday_Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90203"&gt;&lt;em&gt;What a drop.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Being a GeForce NOW member is rewarding. All members can get an edge in the &lt;i&gt;Delta Force&lt;/i&gt; extraction and warfare game modes with a reward bundle packed with standard gear tickets, premium weapon XP tokens and armament vouchers to fine-tune loadouts and push every op further.&lt;/p&gt;
&lt;p&gt;Performance and Ultimate members gain even more battlefield muscle with an early unlock of the PP‑19 Bizon, a weapon that brings close-quarters stopping power to every mission.&lt;/p&gt;
&lt;p&gt;This special sixth-anniversary reward is available through Thursday, March 26, while supplies last. Redeem now and deploy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Ready, Set, Stream&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;This week, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;TCG Card Shop Simulator &lt;/i&gt;(New release on Xbox, available on Game Pass, Feb. 24)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blizzard Arcade Collection &lt;/i&gt;(New release on Ubisoft Connect, Feb. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo II: Resurrected &lt;/i&gt;(New release on Ubisoft Connect, Feb. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Spellcasters Chronicles &lt;/i&gt;(New release on Steam, Feb. 26, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Resident Evil: Requiem&lt;/i&gt; (New release on Steam, Feb. 27, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Anno: Mutationem &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ARC Raiders &lt;/i&gt;(Xbox, available on the Microsoft Store, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DEVOUR &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Galactic Civilizations 3 &lt;/i&gt;(Xbox, available on the Microsoft Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;MotoGP22 &lt;/i&gt;(Xbox, available on the Microsoft Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;What's your bragging rights? 🏅 Share the latest achievement you got in a game.&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) February 23, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;GeForce NOW’s anniversary celebration reaches a chilling crescendo as Capcom’s &lt;i&gt;Resident Evil: Requiem &lt;/i&gt;creeps into the cloud — and the horrors look better than ever on a GeForce NOW Ultimate membership.&lt;/p&gt;
&lt;p&gt;To mark the occasion, a special launch bundle rises from the shadows, pairing the game with a yearlong Ultimate membership for a limited time.&lt;/p&gt;
&lt;p&gt;It’s not a celebration party without treats. GeForce NOW is also offering members a new reward to use in &lt;i&gt;Delta Force&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;Suit up and grab it alongside 11 new games joining the cloud this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Nightmare Returns in the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;A new era of survival horror dawns with &lt;i&gt;Resident Evil: Requiem&lt;/i&gt;, the iconic Capcom series’ most immersive entry yet. Follow FBI analyst Grace Ashcroft and veteran agent Leon S. Kennedy as their stories and playstyles intertwine in a chilling, emotional fight for survival.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90211"&gt;&lt;img alt="alt" class="size-large wp-image-90211" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/gfn-social-rtx-5080-spotlights-resident-evil-requiem-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90211"&gt;&lt;em&gt;The city has been waiting — and it remembers.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Return to Raccoon City, the ruined heart of a 1998 bioweapon disaster now buried in government secrecy. Grace investigates her mother’s mysterious death while Leon, hardened by years of battling outbreaks, uncovers a new bioterror threat spreading through the Midwest. Classic &lt;i&gt;Resident Evil&lt;/i&gt; survival horror returns with tense combat and clever puzzles — now enhanced with seamless switching between first‑ and third‑person views for a more personal nightmare.&lt;/p&gt;
&lt;p&gt;With GeForce RTX 5080-class power in the cloud, experience &lt;i&gt;Requiem &lt;/i&gt;with lifelike lighting, full path tracing, ray‑traced reflections and cinematic realism at up to 5K resolution with high dynamic range, plus NVIDIA DLSS 4 with Multi Frame Generation for maximum performance. The Ultimate membership keeps every encounter smooth and immersive when streaming from powerful GPUs in the cloud.&lt;/p&gt;
&lt;p&gt;To celebrate GeForce NOW’s sixth anniversary, a special launch offer emerges from the fog: For a limited time, &lt;i&gt;Resident Evil: Requiem&lt;/i&gt; is included with the purchase of a 12‑month Ultimate membership. It’s the perfect way to return to the city of disaster and despair, now more haunting and beautiful than ever.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Priority Package&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;GeForce NOW marks six epic years in the cloud, and the party lands on the &lt;i&gt;Delta Force&lt;/i&gt; frontline with a new reward drop.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90203"&gt;&lt;img alt="Delta Force reward on GeForce NOW" class="wp-image-90203 size-large" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday_Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90203"&gt;&lt;em&gt;What a drop.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Being a GeForce NOW member is rewarding. All members can get an edge in the &lt;i&gt;Delta Force&lt;/i&gt; extraction and warfare game modes with a reward bundle packed with standard gear tickets, premium weapon XP tokens and armament vouchers to fine-tune loadouts and push every op further.&lt;/p&gt;
&lt;p&gt;Performance and Ultimate members gain even more battlefield muscle with an early unlock of the PP‑19 Bizon, a weapon that brings close-quarters stopping power to every mission.&lt;/p&gt;
&lt;p&gt;This special sixth-anniversary reward is available through Thursday, March 26, while supplies last. Redeem now and deploy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Ready, Set, Stream&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;This week, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;TCG Card Shop Simulator &lt;/i&gt;(New release on Xbox, available on Game Pass, Feb. 24)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blizzard Arcade Collection &lt;/i&gt;(New release on Ubisoft Connect, Feb. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo II: Resurrected &lt;/i&gt;(New release on Ubisoft Connect, Feb. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Spellcasters Chronicles &lt;/i&gt;(New release on Steam, Feb. 26, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Resident Evil: Requiem&lt;/i&gt; (New release on Steam, Feb. 27, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Anno: Mutationem &lt;/i&gt;(Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;ARC Raiders &lt;/i&gt;(Xbox, available on the Microsoft Store, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DEVOUR &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Galactic Civilizations 3 &lt;/i&gt;(Xbox, available on the Microsoft Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;MotoGP22 &lt;/i&gt;(Xbox, available on the Microsoft Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;What's your bragging rights? 🏅 Share the latest achievement you got in a game.&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) February 23, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-resident-evil-requiem/</guid><pubDate>Thu, 26 Feb 2026 14:00:48 +0000</pubDate></item><item><title>[NEW] 2 days left: Lock in the best discounts for TechCrunch Disrupt 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/2-days-left-lock-in-the-best-discounts-for-techcrunch-disrupt-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Super Early Bird pricing ends &lt;strong&gt;tomorrow, February 27, at 11:59 p.m. PT&lt;/strong&gt;. After that, prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt; go up. Miss this, and you’ll be paying more for the same access to one of the most anticipated tech events of the year. &lt;strong&gt;Register now&lt;/strong&gt; to secure discounts of up to $680 on your pass, or up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2026 2 days left" class="wp-image-3094855" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/TCD26_2Days-16X9-dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-your-launchpad-in-the-tech-ecosystem"&gt;Disrupt: Your launchpad in the tech ecosystem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to raise capital, hire top talent, launch your startup, or discover your next portfolio company, don’t miss&amp;nbsp;&lt;strong&gt;Disrupt&lt;/strong&gt;, taking place October 13–15 at San Francisco’s Moscone West.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s&amp;nbsp;what&amp;nbsp;you’ll&amp;nbsp;gain by attending:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Actionable insights&amp;nbsp;from builders, operators, and VCs actively shaping today’s market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Direct access to the right investors&amp;nbsp;for your next round, or founders aligned with your portfolio&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Early visibility into breakthrough innovations&amp;nbsp;before they hit the broader market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Connections that drive real impact, from partnerships to funding to career opportunities&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-2539741" height="383" src="https://techcrunch.com/wp-content/uploads/2023/05/ac_crowd.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-how-disrupt-nbsp-delivers-nbsp-value"&gt;How Disrupt&amp;nbsp;delivers&amp;nbsp;value&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access to&amp;nbsp;10,000+&amp;nbsp;founders, operators, and VCs&amp;nbsp;with targeted programming&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Tactical, real-world&amp;nbsp;onstage discussions&amp;nbsp;with&amp;nbsp;250+&amp;nbsp;of&amp;nbsp;today’s market leaders&amp;nbsp;spanning multiple industry stages, roundtables, and breakout sessions&lt;/li&gt;
&lt;/ul&gt;





&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;20,000+ curated&amp;nbsp;1:1 or small-group&amp;nbsp;networking&amp;nbsp;designed for&amp;nbsp;real, actionable results&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;80+ Side Events across the Bay Area&amp;nbsp;for networking, workshops, and social connections&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-exclusive-nbsp-programming-for-founders-and-investors"&gt;Exclusive&amp;nbsp;programming for founders and investors&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Accelerate growth with the right insights, tools, and connections. Meet investors aligned with your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Discover standout startups and expand your portfolio with curated access. Use matchmaking tools to make every conversation count.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-nbsp-miss-disrupt-at-the-biggest-discounts"&gt;Don’t&amp;nbsp;miss Disrupt at the biggest discounts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This window to the lowest ticket rates of the year is closing after tomorrow&amp;nbsp;ends.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to secure your ticket with&amp;nbsp;up to a&amp;nbsp;$680 discount.&amp;nbsp;Or save up to 30%&amp;nbsp;with&amp;nbsp;&lt;strong&gt;community passes&lt;/strong&gt;&amp;nbsp;of 4+.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Super Early Bird pricing ends &lt;strong&gt;tomorrow, February 27, at 11:59 p.m. PT&lt;/strong&gt;. After that, prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt; go up. Miss this, and you’ll be paying more for the same access to one of the most anticipated tech events of the year. &lt;strong&gt;Register now&lt;/strong&gt; to secure discounts of up to $680 on your pass, or up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2026 2 days left" class="wp-image-3094855" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/TCD26_2Days-16X9-dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-your-launchpad-in-the-tech-ecosystem"&gt;Disrupt: Your launchpad in the tech ecosystem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to raise capital, hire top talent, launch your startup, or discover your next portfolio company, don’t miss&amp;nbsp;&lt;strong&gt;Disrupt&lt;/strong&gt;, taking place October 13–15 at San Francisco’s Moscone West.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s&amp;nbsp;what&amp;nbsp;you’ll&amp;nbsp;gain by attending:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Actionable insights&amp;nbsp;from builders, operators, and VCs actively shaping today’s market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Direct access to the right investors&amp;nbsp;for your next round, or founders aligned with your portfolio&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Early visibility into breakthrough innovations&amp;nbsp;before they hit the broader market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Connections that drive real impact, from partnerships to funding to career opportunities&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-2539741" height="383" src="https://techcrunch.com/wp-content/uploads/2023/05/ac_crowd.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-how-disrupt-nbsp-delivers-nbsp-value"&gt;How Disrupt&amp;nbsp;delivers&amp;nbsp;value&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access to&amp;nbsp;10,000+&amp;nbsp;founders, operators, and VCs&amp;nbsp;with targeted programming&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Tactical, real-world&amp;nbsp;onstage discussions&amp;nbsp;with&amp;nbsp;250+&amp;nbsp;of&amp;nbsp;today’s market leaders&amp;nbsp;spanning multiple industry stages, roundtables, and breakout sessions&lt;/li&gt;
&lt;/ul&gt;





&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;20,000+ curated&amp;nbsp;1:1 or small-group&amp;nbsp;networking&amp;nbsp;designed for&amp;nbsp;real, actionable results&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;80+ Side Events across the Bay Area&amp;nbsp;for networking, workshops, and social connections&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-exclusive-nbsp-programming-for-founders-and-investors"&gt;Exclusive&amp;nbsp;programming for founders and investors&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Accelerate growth with the right insights, tools, and connections. Meet investors aligned with your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Discover standout startups and expand your portfolio with curated access. Use matchmaking tools to make every conversation count.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-nbsp-miss-disrupt-at-the-biggest-discounts"&gt;Don’t&amp;nbsp;miss Disrupt at the biggest discounts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This window to the lowest ticket rates of the year is closing after tomorrow&amp;nbsp;ends.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to secure your ticket with&amp;nbsp;up to a&amp;nbsp;$680 discount.&amp;nbsp;Or save up to 30%&amp;nbsp;with&amp;nbsp;&lt;strong&gt;community passes&lt;/strong&gt;&amp;nbsp;of 4+.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/2-days-left-lock-in-the-best-discounts-for-techcrunch-disrupt-2026/</guid><pubDate>Thu, 26 Feb 2026 15:00:00 +0000</pubDate></item><item><title>[NEW] Finding value with AI and Industry 5.0 transformation (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;EY&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment human potential, not just automate work, and enhance environmental sustainability.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1133715" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_EY3_V8-revCoverPage.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Industry 5.0 has ushered in a radically new level of collaboration between humans and machines, one that removes data silos and optimizes infrastructure, operations, and resource use to disrupt business models and create new forms of enterprise value. But without discipline in tracking value creation, investments risk being wasted on incremental efficiency gains rather than strategic growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“To realize the promise of Industry 5.0, companies must move beyond cost and efficiency to focus on growth, resilience, and human-centric outcomes,” says Sachin Lulla, EY Americas industrials and energy transformation leader. “This requires not just new technologies, but new ways of working—where people and machines collaborate, and where value is measured not just in dollars saved, but in new opportunities created.”&lt;/p&gt;  &lt;p&gt;An MIT Technology Review Insights survey of 250 industry leaders from around the world reveals most industrial investments still target efficiency. And while the data shows human-centric and sustainable use cases deliver higher value, they are underfunded. The research shows most organizations are not realizing the full value potential of Industry 5.0 due to a combination of:&lt;/p&gt; 
 &lt;p&gt;• Culture, skills, and collaboration barriers.&lt;br /&gt;• Tactical and misaligned technology investments.&lt;br /&gt;• Use-case prioritization focused on efficiency over growth, sustainability, and well-being.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133717" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR_V1_EY32026SocialsCard3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;The barrier to achieving Industry 5.0 transformation is not only about fixing the technology, according to research from EY and Saïd Business School at the University of Oxford, it is also about bolstering human-centric elements like strategy, culture, and leadership. Companies are investing heavily in digital transformation, but not always in ways that unlock the full human potential of Industry 5.0.&lt;/p&gt; 
 &lt;p&gt;“We’re not just doing digital work for work’s sake, what I call ‘chasing the digital fairies,’” says Chris Ware, general manager, iron ore digital, Rio Tinto. “We have to be very clear on what pieces of work we go after and why. Every domain has a unique roadmap about how to deliver the best value.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;EY&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment human potential, not just automate work, and enhance environmental sustainability.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1133715" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_EY3_V8-revCoverPage.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Industry 5.0 has ushered in a radically new level of collaboration between humans and machines, one that removes data silos and optimizes infrastructure, operations, and resource use to disrupt business models and create new forms of enterprise value. But without discipline in tracking value creation, investments risk being wasted on incremental efficiency gains rather than strategic growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“To realize the promise of Industry 5.0, companies must move beyond cost and efficiency to focus on growth, resilience, and human-centric outcomes,” says Sachin Lulla, EY Americas industrials and energy transformation leader. “This requires not just new technologies, but new ways of working—where people and machines collaborate, and where value is measured not just in dollars saved, but in new opportunities created.”&lt;/p&gt;  &lt;p&gt;An MIT Technology Review Insights survey of 250 industry leaders from around the world reveals most industrial investments still target efficiency. And while the data shows human-centric and sustainable use cases deliver higher value, they are underfunded. The research shows most organizations are not realizing the full value potential of Industry 5.0 due to a combination of:&lt;/p&gt; 
 &lt;p&gt;• Culture, skills, and collaboration barriers.&lt;br /&gt;• Tactical and misaligned technology investments.&lt;br /&gt;• Use-case prioritization focused on efficiency over growth, sustainability, and well-being.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133717" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR_V1_EY32026SocialsCard3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;The barrier to achieving Industry 5.0 transformation is not only about fixing the technology, according to research from EY and Saïd Business School at the University of Oxford, it is also about bolstering human-centric elements like strategy, culture, and leadership. Companies are investing heavily in digital transformation, but not always in ways that unlock the full human potential of Industry 5.0.&lt;/p&gt; 
 &lt;p&gt;“We’re not just doing digital work for work’s sake, what I call ‘chasing the digital fairies,’” says Chris Ware, general manager, iron ore digital, Rio Tinto. “We have to be very clear on what pieces of work we go after and why. Every domain has a unique roadmap about how to deliver the best value.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/</guid><pubDate>Thu, 26 Feb 2026 15:00:59 +0000</pubDate></item><item><title>[NEW] Google launches Nano Banana 2 model with faster image generation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/google-launches-nano-banana-2-model-with-faster-image-generation/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google today announced the latest version of its popular image generation model, Nano Banana 2. The new model, which is technically Gemini 3.1 Flash Image, can create more realistic images than its predecessor. The model will also now become the default in the Gemini app for its Fast, Thinking, and Pro modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company first released Nano Banana in August 2025, prompting people to generate millions of images in the Gemini app, especially in countries like India. In November, the company released Nano Banana Pro, which allows users to create more detailed and high-quality images.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A comparison of image generation between Nano Banana Pro and Nano Banana 2" class="wp-image-3097378" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Museum.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3097382" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Multi-Input.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the launch, Nano Banana 2 will become the default model for image generation across all apps in the Gemini app. The company is also making it the default model for image generation in its video editing tool, Flow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Search, Nano Banana 2 will become the default for Google Search results via Google Lens and in AI Mode across 141 countries on the Google app and on the web across desktop and mobile.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google’s higher-end plans, Google AI Pro and Ultra, subscribers can continue to use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097380" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Translation.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For developers, Nano Banana 2 will be available in preview through the Gemini API, Gemini CLI, and the Vertex API. It will also be available through AI Studio and the company’s development tool Antigravity, which was released last November. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that all images created through the new model will have a SynthID watermark, which is Google’s mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials, created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the SynthID verification in the Gemini app in November, people have used it over 20 million times.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google today announced the latest version of its popular image generation model, Nano Banana 2. The new model, which is technically Gemini 3.1 Flash Image, can create more realistic images than its predecessor. The model will also now become the default in the Gemini app for its Fast, Thinking, and Pro modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company first released Nano Banana in August 2025, prompting people to generate millions of images in the Gemini app, especially in countries like India. In November, the company released Nano Banana Pro, which allows users to create more detailed and high-quality images.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A comparison of image generation between Nano Banana Pro and Nano Banana 2" class="wp-image-3097378" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Museum.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3097382" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Multi-Input.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the launch, Nano Banana 2 will become the default model for image generation across all apps in the Gemini app. The company is also making it the default model for image generation in its video editing tool, Flow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Search, Nano Banana 2 will become the default for Google Search results via Google Lens and in AI Mode across 141 countries on the Google app and on the web across desktop and mobile.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google’s higher-end plans, Google AI Pro and Ultra, subscribers can continue to use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097380" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Translation.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For developers, Nano Banana 2 will be available in preview through the Gemini API, Gemini CLI, and the Vertex API. It will also be available through AI Studio and the company’s development tool Antigravity, which was released last November. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that all images created through the new model will have a SynthID watermark, which is Google’s mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials, created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the SynthID verification in the Gemini app in November, people have used it over 20 million times.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/google-launches-nano-banana-2-model-with-faster-image-generation/</guid><pubDate>Thu, 26 Feb 2026 16:00:00 +0000</pubDate></item><item><title>[NEW] Nano Banana 2: Combining Pro capabilities with lightning-fast speed (Google DeepMind News)</title><link>https://deepmind.google/blog/nano-banana-2-combining-pro-capabilities-with-lightning-fast-speed/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Nano Banana 2 text with AI generated images around it" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NB2_Hero.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Nano Banana 2: Combining Pro capabilities with lightning\u002Dfast speed"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83457_umbriel_2026_02_26_18_47_29.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;In August of last year, our Gemini Image model, Nano Banana, became a viral sensation, redefining image generation and editing. Then in November, we released Nano Banana Pro, offering users advanced intelligence and studio-quality creative control. Today, we’re bringing the best of both worlds to users across Google.&lt;/p&gt;&lt;p&gt;Introducing Nano Banana 2 (Gemini 3.1 Flash Image), our latest state-of-the-art image model. Now you can get the advanced world knowledge, quality and reasoning you love in Nano Banana Pro, at lightning-fast speed.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence and visual quality at Flash speed&lt;/h2&gt;&lt;p&gt;Nano Banana 2 brings the high-speed intelligence of Gemini Flash to visual generation, making rapid edits and iteration possible. It makes once-exclusive Pro features accessible to a wider audience, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Advanced world knowledge:&lt;/b&gt; The model pulls from Gemini’s real-world knowledge base, and is powered by real-time information and images from web search to more accurately render specific subjects. This deep understanding also helps you create infographics, turn notes into diagrams and generate data visualizations.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precision text rendering and translation&lt;/b&gt;: Nano Banana 2 allows you to generate accurate, legible text for marketing mockups or greeting cards. You can even translate and localize text within an image to share your ideas globally.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;A flat lay infographic depicting the water cycle&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Triptych infographic comparing cloud types&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Museum Clos Lucé in Synthetic Cubism style&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Localized "Native Wildlife" sign&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Water Cycle&lt;/i&gt;



  &lt;sup&gt;1&lt;/sup&gt;

&lt;i&gt;, Cloud Infographic&lt;/i&gt;



  &lt;sup&gt;2&lt;/sup&gt;

&lt;i&gt;, Cubism&lt;/i&gt;



  &lt;sup&gt;3&lt;/sup&gt;

&lt;i&gt;, Wildlife Sign&lt;/i&gt;



  &lt;sup&gt;4&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Enhanced creative control&lt;/h2&gt;&lt;p&gt;Nano Banana 2 also dramatically closes the gap between speed and visual fidelity, delivering high-quality, photorealistic imagery. Here’s what our newest model offers and has improved on from the original Nano Banana:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Subject consistency:&lt;/b&gt; Maintain character resemblance of up to five characters and the fidelity of up to 14 objects in a single workflow, allowing you to storyboard and build narratives without altering the appearance of your inputs.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precise instruction following:&lt;/b&gt; With enhanced instruction following, the model adheres more strictly to your complex requests, capturing the specific nuances of your idea so the image you get is the image you asked for.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Production-ready specs&lt;/b&gt;: Make attention grabbing assets with full control of various aspect ratios and resolutions from 512px to 4K, ensuring your visuals stay sharp whether they are for a vertical social post or a wide-screen backdrop.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Visual fidelity upgrade:&lt;/b&gt; Nano Banana 2 delivers vibrant lighting, richer textures and sharper details, maintaining high-quality aesthetics at the speed expected from Flash.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Joyful characters and items at a farm&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Fluffy friends building a treehouse&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Misty panoramic aerial shot of a verdant valley&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Highly stylized pop-art fashion portrait in different aspect ratios&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Farm&lt;/i&gt;



  &lt;sup&gt;5&lt;/sup&gt;

&lt;i&gt;, Treehouse&lt;/i&gt;



  &lt;sup&gt;6&lt;/sup&gt;

&lt;i&gt;, Valley&lt;/i&gt;



  &lt;sup&gt;7&lt;/sup&gt;

&lt;i&gt;, Portrait&lt;/i&gt;



  &lt;sup&gt;8&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try Nano Banana 2 today&lt;/h2&gt;&lt;p&gt;Whatever your needs, we now offer the perfect tool for every workflow: Nano Banana Pro for high-fidelity tasks requiring maximum factual accuracy, or Nano Banana 2 for rapid generation, precise instruction following and integrated image-search grounding.&lt;/p&gt;&lt;p&gt;Nano Banana 2 is rolling out today across Google products, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Gemini app:&lt;/b&gt; Nano Banana 2 will replace Nano Banana Pro across the Fast, Thinking and Pro models. Google AI Pro and Ultra subscribers will keep access to Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Search:&lt;/b&gt; In AI Mode and Lens, through the Google app as well as mobile and desktop browsers. View availability here, including 141 new countries and territories and eight additional languages.&lt;/li&gt;&lt;li&gt;&lt;b&gt;AI Studio + API:&lt;/b&gt; Available in preview in AI Studio and Gemini API. Pricing here. Also available in Google Antigravity.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Cloud:&lt;/b&gt; Available in preview with the Gemini API in Vertex AI.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Flow:&lt;/b&gt; Nano Banana 2 is the new default image generation model in Flow, available to all Flow users for zero credits.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Ads:&lt;/b&gt; Nano Banana is available in Ads, powering suggestions while creating campaigns.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Try Nano Banana 2 in the Gemini app, using the new templates feature.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;World knowledge from Nano Banana 2 in AI Mode in Search.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Subject preservation from Nano Banana 2 in Flow.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Read the prompts: AI Mode in Search



  &lt;sup&gt;9&lt;/sup&gt;

, Flow



  &lt;sup&gt;10&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Robust provenance: marking and verification&lt;/h2&gt;&lt;p&gt;As generative media evolves, so must the tools we use to identify and understand it. We continue to deepen our provenance approach, by coupling our state-of-the-art SynthID technology with interoperable C2PA Content Credentials, we provide users with a more holistic and contextual view of not just if AI was used, but how.&lt;/p&gt;&lt;p&gt;Our provenance tools are already making an impact. Since its launch in November, our SynthID verification feature in Gemini app has been used over 20 million times across various languages, helping people identify Google AI-generated images, video and audio. We’ll soon be bringing C2PA verification to the Gemini app, too.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    

  
    





&lt;div class="newsletter-form article-newsletter-form"&gt;
  &lt;div class="newsletter-form__container"&gt;
    &lt;div class="newsletter-form__envelope"&gt;
      &lt;div class="envelope-back"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-back.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-approved"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-approved.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-google"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-google.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-front"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-front.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__error"&gt;&lt;/div&gt;
    &lt;div class="newsletter-form__form-container" id="newsletter-form--form"&gt;
      &lt;form class="newsletter-form__form"&gt;
        &lt;h2 class="newsletter-form__title" id="subscribe_box_label"&gt;
          &lt;span class="newsletter-form__title--sr-visible"&gt;Get more stories from Google in your inbox.&lt;/span&gt;
          &lt;span&gt;Get more &lt;span class="newsletter-form__title--highlight"&gt;stories from Google&lt;/span&gt; in your inbox.&lt;/span&gt;
        &lt;/h2&gt;
        &lt;div class="newsletter-form__controls-container"&gt;
          &lt;div class="newsletter-form__input-container"&gt;
            &lt;div class="kw-form-input"&gt;
  &lt;input autocomplete="email" class="kw-form-input__field uni_subscribe_email" id="uni_subscribe_email" name="email" required="required" type="text" /&gt;
  &lt;label class="kw-form-input__label" for="uni_subscribe_email"&gt;
    Email address
  &lt;/label&gt;
  &lt;div class="kw-form-input__error uni_subscribe_email--error"&gt;&lt;/div&gt;
&lt;/div&gt;

          &lt;/div&gt;
          &lt;p class="newsletter-form__info-paragraph"&gt;
            Your information will be used in accordance with
            Google's privacy policy.
          &lt;/p&gt;
          &lt;button class="kw-button kw-button--high-emphasis newsletter-form__submit"&gt;
              Subscribe
          &lt;/button&gt;
        &lt;/div&gt;
      &lt;/form&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__loading"&gt;
      &lt;div class="newsletter-form__loader"&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__success"&gt;
      &lt;div class="newsletter-form__success-text"&gt;
        &lt;p class="newsletter-form__success-text--intro newsletter-form__success-text--done-text" tabindex="-1"&gt;
          Done. Just one step more.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--confirmation uni-headline-4"&gt;
          Check your inbox to confirm your subscription.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--subscribed uni-headline-4"&gt;You are already subscribed to our newsletter.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p class="newsletter-form__success-final-text"&gt;
        You can also subscribe with a
        &lt;button class="newsletter-form__different-email"&gt;different email address&lt;/button&gt;
        &lt;span&gt;
        .
        &lt;/span&gt;
      &lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Nano Banana 2 text with AI generated images around it" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NB2_Hero.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Nano Banana 2: Combining Pro capabilities with lightning\u002Dfast speed"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83457_umbriel_2026_02_26_18_47_29.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;In August of last year, our Gemini Image model, Nano Banana, became a viral sensation, redefining image generation and editing. Then in November, we released Nano Banana Pro, offering users advanced intelligence and studio-quality creative control. Today, we’re bringing the best of both worlds to users across Google.&lt;/p&gt;&lt;p&gt;Introducing Nano Banana 2 (Gemini 3.1 Flash Image), our latest state-of-the-art image model. Now you can get the advanced world knowledge, quality and reasoning you love in Nano Banana Pro, at lightning-fast speed.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence and visual quality at Flash speed&lt;/h2&gt;&lt;p&gt;Nano Banana 2 brings the high-speed intelligence of Gemini Flash to visual generation, making rapid edits and iteration possible. It makes once-exclusive Pro features accessible to a wider audience, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Advanced world knowledge:&lt;/b&gt; The model pulls from Gemini’s real-world knowledge base, and is powered by real-time information and images from web search to more accurately render specific subjects. This deep understanding also helps you create infographics, turn notes into diagrams and generate data visualizations.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precision text rendering and translation&lt;/b&gt;: Nano Banana 2 allows you to generate accurate, legible text for marketing mockups or greeting cards. You can even translate and localize text within an image to share your ideas globally.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;A flat lay infographic depicting the water cycle&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Triptych infographic comparing cloud types&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Museum Clos Lucé in Synthetic Cubism style&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Localized "Native Wildlife" sign&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Water Cycle&lt;/i&gt;



  &lt;sup&gt;1&lt;/sup&gt;

&lt;i&gt;, Cloud Infographic&lt;/i&gt;



  &lt;sup&gt;2&lt;/sup&gt;

&lt;i&gt;, Cubism&lt;/i&gt;



  &lt;sup&gt;3&lt;/sup&gt;

&lt;i&gt;, Wildlife Sign&lt;/i&gt;



  &lt;sup&gt;4&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Enhanced creative control&lt;/h2&gt;&lt;p&gt;Nano Banana 2 also dramatically closes the gap between speed and visual fidelity, delivering high-quality, photorealistic imagery. Here’s what our newest model offers and has improved on from the original Nano Banana:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Subject consistency:&lt;/b&gt; Maintain character resemblance of up to five characters and the fidelity of up to 14 objects in a single workflow, allowing you to storyboard and build narratives without altering the appearance of your inputs.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precise instruction following:&lt;/b&gt; With enhanced instruction following, the model adheres more strictly to your complex requests, capturing the specific nuances of your idea so the image you get is the image you asked for.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Production-ready specs&lt;/b&gt;: Make attention grabbing assets with full control of various aspect ratios and resolutions from 512px to 4K, ensuring your visuals stay sharp whether they are for a vertical social post or a wide-screen backdrop.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Visual fidelity upgrade:&lt;/b&gt; Nano Banana 2 delivers vibrant lighting, richer textures and sharper details, maintaining high-quality aesthetics at the speed expected from Flash.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Joyful characters and items at a farm&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Fluffy friends building a treehouse&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Misty panoramic aerial shot of a verdant valley&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Highly stylized pop-art fashion portrait in different aspect ratios&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Farm&lt;/i&gt;



  &lt;sup&gt;5&lt;/sup&gt;

&lt;i&gt;, Treehouse&lt;/i&gt;



  &lt;sup&gt;6&lt;/sup&gt;

&lt;i&gt;, Valley&lt;/i&gt;



  &lt;sup&gt;7&lt;/sup&gt;

&lt;i&gt;, Portrait&lt;/i&gt;



  &lt;sup&gt;8&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try Nano Banana 2 today&lt;/h2&gt;&lt;p&gt;Whatever your needs, we now offer the perfect tool for every workflow: Nano Banana Pro for high-fidelity tasks requiring maximum factual accuracy, or Nano Banana 2 for rapid generation, precise instruction following and integrated image-search grounding.&lt;/p&gt;&lt;p&gt;Nano Banana 2 is rolling out today across Google products, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Gemini app:&lt;/b&gt; Nano Banana 2 will replace Nano Banana Pro across the Fast, Thinking and Pro models. Google AI Pro and Ultra subscribers will keep access to Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Search:&lt;/b&gt; In AI Mode and Lens, through the Google app as well as mobile and desktop browsers. View availability here, including 141 new countries and territories and eight additional languages.&lt;/li&gt;&lt;li&gt;&lt;b&gt;AI Studio + API:&lt;/b&gt; Available in preview in AI Studio and Gemini API. Pricing here. Also available in Google Antigravity.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Cloud:&lt;/b&gt; Available in preview with the Gemini API in Vertex AI.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Flow:&lt;/b&gt; Nano Banana 2 is the new default image generation model in Flow, available to all Flow users for zero credits.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Ads:&lt;/b&gt; Nano Banana is available in Ads, powering suggestions while creating campaigns.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Try Nano Banana 2 in the Gemini app, using the new templates feature.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;World knowledge from Nano Banana 2 in AI Mode in Search.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Subject preservation from Nano Banana 2 in Flow.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Read the prompts: AI Mode in Search



  &lt;sup&gt;9&lt;/sup&gt;

, Flow



  &lt;sup&gt;10&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Robust provenance: marking and verification&lt;/h2&gt;&lt;p&gt;As generative media evolves, so must the tools we use to identify and understand it. We continue to deepen our provenance approach, by coupling our state-of-the-art SynthID technology with interoperable C2PA Content Credentials, we provide users with a more holistic and contextual view of not just if AI was used, but how.&lt;/p&gt;&lt;p&gt;Our provenance tools are already making an impact. Since its launch in November, our SynthID verification feature in Gemini app has been used over 20 million times across various languages, helping people identify Google AI-generated images, video and audio. We’ll soon be bringing C2PA verification to the Gemini app, too.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    

  
    





&lt;div class="newsletter-form article-newsletter-form"&gt;
  &lt;div class="newsletter-form__container"&gt;
    &lt;div class="newsletter-form__envelope"&gt;
      &lt;div class="envelope-back"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-back.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-approved"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-approved.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-google"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-google.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-front"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-front.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__error"&gt;&lt;/div&gt;
    &lt;div class="newsletter-form__form-container" id="newsletter-form--form"&gt;
      &lt;form class="newsletter-form__form"&gt;
        &lt;h2 class="newsletter-form__title" id="subscribe_box_label"&gt;
          &lt;span class="newsletter-form__title--sr-visible"&gt;Get more stories from Google in your inbox.&lt;/span&gt;
          &lt;span&gt;Get more &lt;span class="newsletter-form__title--highlight"&gt;stories from Google&lt;/span&gt; in your inbox.&lt;/span&gt;
        &lt;/h2&gt;
        &lt;div class="newsletter-form__controls-container"&gt;
          &lt;div class="newsletter-form__input-container"&gt;
            &lt;div class="kw-form-input"&gt;
  &lt;input autocomplete="email" class="kw-form-input__field uni_subscribe_email" id="uni_subscribe_email" name="email" required="required" type="text" /&gt;
  &lt;label class="kw-form-input__label" for="uni_subscribe_email"&gt;
    Email address
  &lt;/label&gt;
  &lt;div class="kw-form-input__error uni_subscribe_email--error"&gt;&lt;/div&gt;
&lt;/div&gt;

          &lt;/div&gt;
          &lt;p class="newsletter-form__info-paragraph"&gt;
            Your information will be used in accordance with
            Google's privacy policy.
          &lt;/p&gt;
          &lt;button class="kw-button kw-button--high-emphasis newsletter-form__submit"&gt;
              Subscribe
          &lt;/button&gt;
        &lt;/div&gt;
      &lt;/form&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__loading"&gt;
      &lt;div class="newsletter-form__loader"&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__success"&gt;
      &lt;div class="newsletter-form__success-text"&gt;
        &lt;p class="newsletter-form__success-text--intro newsletter-form__success-text--done-text" tabindex="-1"&gt;
          Done. Just one step more.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--confirmation uni-headline-4"&gt;
          Check your inbox to confirm your subscription.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--subscribed uni-headline-4"&gt;You are already subscribed to our newsletter.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p class="newsletter-form__success-final-text"&gt;
        You can also subscribe with a
        &lt;button class="newsletter-form__different-email"&gt;different email address&lt;/button&gt;
        &lt;span&gt;
        .
        &lt;/span&gt;
      &lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/nano-banana-2-combining-pro-capabilities-with-lightning-fast-speed/</guid><pubDate>Thu, 26 Feb 2026 16:01:50 +0000</pubDate></item><item><title>[NEW] Bumble adds AI-powered photo feedback and profile guidance tools (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/bumble-adds-ai-powered-photo-feedback-and-profile-guidance-tools/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/bumble-app.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bumble announced on Thursday that it’s adding a series of AI-driven features intended to help turn matches into lasting connections, including those that offer feedback and guidance on users’ bios, photos, and prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dating app’s new AI-suggested profile guidance tool will roll out globally and give “personalized, actionable feedback” on users’ bios and prompts. For users in the U.S., the profile guidance feature can be augmented with an AI photo feedback tool, which can “help you choose the best photos and show up as your most authentic self.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Bumble’s blog post explaining these features, it doesn’t seem like the insights from these AI tools are particularly groundbreaking — for example, Bumble says that its AI photo tool might encourage you to ditch photos where you’re wearing sunglasses that cover your face, and add a wider variety of photos, like ones taken outdoors or with friends. It’s advice you could’ve easily gotten from a friend 10 years ago, but it’s still new information to many users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Canada, Bumble is testing another, non-AI feature called “Suggest a Date.” When a conversation stalls, a user can signal that they are open to meeting in person, which the company says is “a simple way to signal that they’re ready to connect offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, another way for people to “signal that they’re ready to connect offline” is to literally ask someone on a date. But realistically, it doesn’t seem like users are taking the plunge, so having an in-app way to indicate interest may motivate some potential couples to move their conversation IRL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Suggest a Date, we’re creating a clear expression of intent and giving members a way to bypass the traditional back-and-forth and move toward meeting in real life,” Bumble CTO Vivek Sagi said in a statement. “When we reduce friction at the moments that matter most, we help people connect with clarity and confidence, and increase the likelihood of meaningful relationships forming offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble and other popular dating apps, like Match Group’s Tinder and Hinge, have all embraced AI-powered features in recent months. For instance, in December, Hinge introduced a tool to help generate more interesting conversation starters than “How are you?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tinder may take things a step further. In Australia, Tinder is piloting a tool called Chemistry, which asks users to provide the app with access to their camera roll, which is a concerning amount of data to feed into an AI tool. Based on a user’s camera roll and answers to a series of questions, the AI can learn more about someone’s interests and personality to supposedly reduce “swipe fatigue” and suggest better matches. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Facebook Dating tool does something similar — in October, it launched a feature that asks to use its AI on photos in your camera roll&amp;nbsp;that you haven’t yet shared in order to suggest AI edits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As these companies try to come up with new ways to keep users happy, some young people have thrown in the towel on online dating altogether, instead seeking more real-world experiences that are not intermediated by an app.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/bumble-app.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bumble announced on Thursday that it’s adding a series of AI-driven features intended to help turn matches into lasting connections, including those that offer feedback and guidance on users’ bios, photos, and prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dating app’s new AI-suggested profile guidance tool will roll out globally and give “personalized, actionable feedback” on users’ bios and prompts. For users in the U.S., the profile guidance feature can be augmented with an AI photo feedback tool, which can “help you choose the best photos and show up as your most authentic self.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Bumble’s blog post explaining these features, it doesn’t seem like the insights from these AI tools are particularly groundbreaking — for example, Bumble says that its AI photo tool might encourage you to ditch photos where you’re wearing sunglasses that cover your face, and add a wider variety of photos, like ones taken outdoors or with friends. It’s advice you could’ve easily gotten from a friend 10 years ago, but it’s still new information to many users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Canada, Bumble is testing another, non-AI feature called “Suggest a Date.” When a conversation stalls, a user can signal that they are open to meeting in person, which the company says is “a simple way to signal that they’re ready to connect offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, another way for people to “signal that they’re ready to connect offline” is to literally ask someone on a date. But realistically, it doesn’t seem like users are taking the plunge, so having an in-app way to indicate interest may motivate some potential couples to move their conversation IRL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Suggest a Date, we’re creating a clear expression of intent and giving members a way to bypass the traditional back-and-forth and move toward meeting in real life,” Bumble CTO Vivek Sagi said in a statement. “When we reduce friction at the moments that matter most, we help people connect with clarity and confidence, and increase the likelihood of meaningful relationships forming offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble and other popular dating apps, like Match Group’s Tinder and Hinge, have all embraced AI-powered features in recent months. For instance, in December, Hinge introduced a tool to help generate more interesting conversation starters than “How are you?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tinder may take things a step further. In Australia, Tinder is piloting a tool called Chemistry, which asks users to provide the app with access to their camera roll, which is a concerning amount of data to feed into an AI tool. Based on a user’s camera roll and answers to a series of questions, the AI can learn more about someone’s interests and personality to supposedly reduce “swipe fatigue” and suggest better matches. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Facebook Dating tool does something similar — in October, it launched a feature that asks to use its AI on photos in your camera roll&amp;nbsp;that you haven’t yet shared in order to suggest AI edits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As these companies try to come up with new ways to keep users happy, some young people have thrown in the towel on online dating altogether, instead seeking more real-world experiences that are not intermediated by an app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/bumble-adds-ai-powered-photo-feedback-and-profile-guidance-tools/</guid><pubDate>Thu, 26 Feb 2026 16:38:59 +0000</pubDate></item><item><title>[NEW] Read AI launches an email-based ‘digital twin’ to help you with schedules and answers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/read-ai-launches-an-email-based-digital-twin-to-help-you-with-schedules-and-answers/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meeting notetaker Read AI on Thursday launched an AI-powered email-based assistant called Ada, saying it helps users manage their schedules, answer questions based on a company’s knowledge base, and reply to out-of-office emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is calling Ada a “digital twin” that handles tasks for you around the clock. Read AI said that the assistant will be available to all users, and they can start configuring it by sending an email to “ada@read.ai” and writing “Get me started.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When you ask Ada to find a time to meet with someone, it replies to the other person in the thread with your availability. If the other person replies that they are unavailable at those times and would like a different time slot, Ada responds with new options. While Ada has access to your calendar through Read AI, it does not reveal the nature of those meetings with other people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ada can also answer questions using a company’s knowledge base, topics discussed in your prior meetings, and public internet searches. For instance, you can ask, “Ada, can you provide an update on how we are tracking for Q1 goals?” to get information.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If someone else asks a question in a thread, Ada will prepare a response for you and help you refine it before it is sent to the other person. The startup said that Ada doesn’t reveal any sensitive information without your permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s VP of Product, Justin Farris, said that the new feature doesn’t rely on MCPs (model context protocols, a technical standard for connecting AI tools to external services), and instead builds a knowledge graph based on meeting data and connected services for more contextual answers. He added that over time, the assistant will also take proactive actions for you. For instance, if you mentioned a follow-up item in a meeting, Ada will ask you to set that up after the meeting with contextual data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way I describe our solution is that when you are bringing on a new employee, you train them. When you add Ada to your workflow and connect more services to give more context, it starts to ramp up and handle more tasks for you,” CEO David Shim told TechCrunch. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097385" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Read-AI-Ada-Capabilities.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Read AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that while Ada currently works via email, it will soon be available on Slack and Teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the sidelines of Web Summit Qatar earlier this month, Shim told TechCrunch that the company now has over 5 million monthly active users and plans to grow that number to 10 million. He mentioned that the company sees 50,000 sign-ups every day and has a broader base of 100,000 users who consume Read AI’s content, like meeting summaries, without creating an account.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Read AI, the U.S. remains the largest market with strong international growth. While 60% of users are outside the U.S., the revenue is split roughly equally. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company, which has raised over $81 million in funding, is increasingly adding AI-powered tools to its suite. Last year, it launched Search Copilot for knowledge discovery for users, and last month it added the ability to update customer-service relationship software, send custom emails from within a meeting report, and stay up to date on topics based on internal and web knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other meeting notetakers are also offering new tools to extract more insights and actions from meeting notes. Last September, Granola added “recipes” in the form of repeatable prompts to surface knowledge from meeting data. Quill, which came out of stealth with a $6.5 million funding round this week, also connects to various tools like Linear, Notion, and CRMs, and aims to automate tasks.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meeting notetaker Read AI on Thursday launched an AI-powered email-based assistant called Ada, saying it helps users manage their schedules, answer questions based on a company’s knowledge base, and reply to out-of-office emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is calling Ada a “digital twin” that handles tasks for you around the clock. Read AI said that the assistant will be available to all users, and they can start configuring it by sending an email to “ada@read.ai” and writing “Get me started.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When you ask Ada to find a time to meet with someone, it replies to the other person in the thread with your availability. If the other person replies that they are unavailable at those times and would like a different time slot, Ada responds with new options. While Ada has access to your calendar through Read AI, it does not reveal the nature of those meetings with other people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ada can also answer questions using a company’s knowledge base, topics discussed in your prior meetings, and public internet searches. For instance, you can ask, “Ada, can you provide an update on how we are tracking for Q1 goals?” to get information.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If someone else asks a question in a thread, Ada will prepare a response for you and help you refine it before it is sent to the other person. The startup said that Ada doesn’t reveal any sensitive information without your permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s VP of Product, Justin Farris, said that the new feature doesn’t rely on MCPs (model context protocols, a technical standard for connecting AI tools to external services), and instead builds a knowledge graph based on meeting data and connected services for more contextual answers. He added that over time, the assistant will also take proactive actions for you. For instance, if you mentioned a follow-up item in a meeting, Ada will ask you to set that up after the meeting with contextual data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way I describe our solution is that when you are bringing on a new employee, you train them. When you add Ada to your workflow and connect more services to give more context, it starts to ramp up and handle more tasks for you,” CEO David Shim told TechCrunch. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097385" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Read-AI-Ada-Capabilities.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Read AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that while Ada currently works via email, it will soon be available on Slack and Teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the sidelines of Web Summit Qatar earlier this month, Shim told TechCrunch that the company now has over 5 million monthly active users and plans to grow that number to 10 million. He mentioned that the company sees 50,000 sign-ups every day and has a broader base of 100,000 users who consume Read AI’s content, like meeting summaries, without creating an account.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Read AI, the U.S. remains the largest market with strong international growth. While 60% of users are outside the U.S., the revenue is split roughly equally. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company, which has raised over $81 million in funding, is increasingly adding AI-powered tools to its suite. Last year, it launched Search Copilot for knowledge discovery for users, and last month it added the ability to update customer-service relationship software, send custom emails from within a meeting report, and stay up to date on topics based on internal and web knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other meeting notetakers are also offering new tools to extract more insights and actions from meeting notes. Last September, Granola added “recipes” in the form of repeatable prompts to surface knowledge from meeting data. Quill, which came out of stealth with a $6.5 million funding round this week, also connects to various tools like Linear, Notion, and CRMs, and aims to automate tasks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/read-ai-launches-an-email-based-digital-twin-to-help-you-with-schedules-and-answers/</guid><pubDate>Thu, 26 Feb 2026 17:00:00 +0000</pubDate></item><item><title>[NEW] CORPGEN advances AI agents for real work (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/</link><description>&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="decorative icons in white on a blue and green gradient background" class="wp-image-1162851" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/CORPGEN-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Today’s AI agent benchmarks test one task at a time, while real workplace productivity requires managing dozens of interdependent tasks at once. To reflect this, we created a setting called Multi-Horizon Task Environments (MHTEs).&lt;/li&gt;



&lt;li&gt;Under multi-task loads, leading computer-using agents degrade sharply, with completion rates dropping from 16.7% to 8.7%.&lt;/li&gt;



&lt;li&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;, with hierarchical planning, memory isolation, and experiential learning, delivering up to 3.5 times higher completion rates than baselines across three independent agent backends.&lt;/li&gt;



&lt;li&gt;Because CORPGEN is architecture-agnostic and modular, its gains come from system design rather than any single base model, and it benefits directly as underlying models improve.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;By mid-morning, a typical knowledge worker is already juggling a client report, a budget spreadsheet, a slide deck, and an email backlog, all interdependent and all demanding attention at once. For AI agents to be genuinely useful in that environment, they will need to operate the same way, but today’s best models are evaluated one task at a time, not dozens at once.&lt;/p&gt;



&lt;p&gt;In our paper, “CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments,” we propose an agent framework that equips AI with the memory, planning, and learning capabilities to close that gap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="introducing-multi-horizon-task-environments"&gt;Introducing Multi-Horizon Task Environments&lt;/h2&gt;



&lt;p&gt;Replicating the reality of workplace multitasking requires a new kind of evaluation environment. In response, we developed Multi-Horizon Task Environments (MHTEs), settings where an agent must manage multiple complex tasks simultaneously. Each task requires 10 to 30 dependent steps within a single session spanning five hours.&lt;/p&gt;



&lt;p&gt;To determine what a benchmark would need to test, we ran MHTEs at scale on some of today’s leading AI agents, exposing four weaknesses. First, memory fills up. An agent cannot hold details for multiple active tasks at once. Second, information from one task interferes with reasoning about another. Third, tasks don’t depend on each other in simple sequences. They form complex webs where an agent must constantly check whether upstream work is finished before it can move forward on anything downstream. Fourth, every action cycle requires reprioritizing across all active tasks, not simply resuming where the agent left off.&lt;/p&gt;



&lt;p&gt;We also tested three independent agent systems under increasing loads. As the number of concurrent tasks rose from 12 to 46, completion rates fell from 16.7% to 8.7% across all systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="corpgen-s-architecture"&gt;CORPGEN’s architecture&lt;/h2&gt;



&lt;p&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;: LLM-powered AI agents with persistent identities, role-specific expertise, and realistic work schedules. They operate Microsoft Office applications through GUI automation and perform consistently within MHTEs over hours of continuous activity. Figure 1 illustrates how a digital employee moves through a full workday.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Diagram showing a digital employee's workday in three phases. Day Init on the left, where the agent loads memory and generates a daily plan. Execution Cycles in the center, where the agent repeatedly retrieves context, reasons and acts through a ReAct loop, and persists results across 50+ interleaved tasks. Day End on the right, where the agent generates a reflection and consolidates experience into long-term memory. Below the diagram, labels show the tiered memory architecture and experiential learning components." class="wp-image-1162865" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/day_in_life_color_AH-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Each day begins with a structured plan and memory loaded from previous sessions. The agent then works through overlapping tasks in repeated cycles, storing key outcomes at day’s end to inform the next session.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CORPGEN addresses each of the four weaknesses of concurrent task execution—memory overload, cross-task interference, dependency complexity, and reprioritization—in a targeted way. Hierarchical planning breaks objectives into daily goals and then into moment-to-moment decisions, allowing the agent to act from a structured plan instead of reviewing all available tasks before each step.&lt;/p&gt;



&lt;p&gt;Subagents perform complex operations like web research in isolated contexts, preventing cross-task contamination. A tiered memory system enables selective recall of task-related information rather than retaining everything in active context. Adaptive summarization compresses routine observations while preserving critical information, keeping memory growth controlled. &lt;/p&gt;



&lt;p&gt;Because these mechanisms are not tied to a specific base model, we tested CORPGEN across three different agents. In each case, we observed consistent gains. The improvements came from the architecture, not from the strength of any particular model. Figure 2 shows how they fit together within CORPGEN’s architecture.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Architecture diagram of the CORPGEN framework. At center is the Digital Employee with persistent identity, execution engine, cognitive tools, sub-agents, and context management. On the left, Hierarchical Planning decomposes strategic objectives into tactical plans and operational actions. On the right, Sub-Agents as Tools shows a Research Agent and Computer-Use agent (UFO2) operating in isolated contexts. At the bottom, the Tiered Memory Architecture spans working memory, structured long-term memory, and semantic memory via Mem0. Experiential Learning in the bottom right captures successful trajectories and routes feedback to UFO2. Multi-Employee Collaboration at the top shows async communication via Email and Teams with no shared state." class="wp-image-1162863" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/corpgen_arch_color_AH2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Four mechanisms support concurrent task execution in CORPGEN: hierarchical planning, isolated subagents, tiered memory, and adaptive summarization.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-digital-employees-collaborate"&gt;How digital employees collaborate&lt;/h2&gt;



&lt;p&gt;When multiple digital employees operate in the same environment, collaboration takes shape through standard communication channels, without predefined coordination rules. One employee sends an email requesting data; another picks it up in the next cycle, uses its memory to process it, and responds. This exchange mirrors real workplace communication.&lt;/p&gt;



&lt;p&gt;There is no shared internal state between agents. Coordination occurs entirely through email and Microsoft Teams, the same channels many workers use. Over time, these independent exchanges form recognizable organizational patterns. Some agents take on leadership roles; others provide support; shared documents become the connective tissue.&lt;/p&gt;



&lt;p&gt;When a communication path breaks, such as an email delivery error, agents reroute messages through alternate channels to keep work moving. The result is a virtual organization that behaves like a real one without being explicitly programmed to do so.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluating-corpgen"&gt;Evaluating CORPGEN&lt;/h2&gt;



&lt;p&gt;We evaluated CORPGEN on a multi-task benchmark that combined up to 46 tasks into a single six-hour session. Three findings stood out.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Baselines degrade as load increases; CORPGEN does not.&lt;/strong&gt; All three baseline agent systems showed steady performance declines as task load rose. CORPGEN, by contrast, maintained or improved its completion rates at higher loads. At 46 tasks, CORPGEN completed 15.2% of tasks, compared with 4.3% for the baselines, roughly 3.5 times more.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Experiential learning drives the largest gains.&lt;/strong&gt; We introduced CORPGEN’s components sequentially: first the orchestration layer, then cognitive tools, and finally experiential learning. The first two produced moderate improvements. Experiential learning, in which agents store records of completed tasks and reuse them when they encounter structurally similar work, produced the largest increase, raising completion rates from 8.7% to 15.2%.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evaluation methodology changes the picture.&lt;/strong&gt; When we inspected the actual output files produced by agents, the results agreed with human judgements roughly 90% of the time. Evaluation based on screenshots and action logs agreed only about 40% of the time. This gap suggests that common evaluation approaches may underestimate what agents actually accomplish in practice.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;video series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;On Second Thought&lt;/h2&gt;
				
								&lt;p class="large" id="on-second-thought"&gt;A video series with Sinead Bovell built around the questions everyone’s asking about AI. With expert voices from across Microsoft, we break down the tension and promise of this rapidly changing technology, exploring what’s evolving and what’s possible.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="implications-and-looking-forward"&gt;Implications and looking forward&lt;/h2&gt;



&lt;p&gt;The results suggest that memory and retrieval, not just raw model capability, may be a key bottleneck in getting agents to work in the real world. The largest gains came from experiential learning. Agents that learn from prior successes and apply those patterns to structurally similar tasks build an advantage over systems that respond to each task in isolation.&lt;/p&gt;



&lt;p&gt;CORPGEN also opens a new lens on how AI agents collaborate. Next steps include testing whether agents can maintain memory across multiple workdays and how they coordinate when working in teams. We are also exploring ways to make agents faster and more reliable by combining different methods of interacting with software.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" /&gt;



&lt;h2 class="wp-block-heading" id="acknowledgments"&gt;Acknowledgments&lt;/h2&gt;



&lt;p&gt;This work is a result of a collaboration between the Office of the CTO at Microsoft and the Microsoft AI Development Accelerator Program (MAIDAP). We would like to thank the Microsoft Security Research team for providing resources that supported this research. We also thank the members of the Microsoft UFO2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team and the Mem0&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; project for their open-source contributions, which enabled key components of the CORPGEN architecture, and the OSWorld team for the benchmark that served as the foundation for our multi-task evaluation.&lt;/p&gt;



&lt;p&gt;Finally, we thank the many contributors to this research: Anjel Shaileshbhai Patel, Dayquan Julienne, Charlotte Siska, Manuel Raúl Meléndez Luján, Anthony Twum-Barimah, Mauricio Velazco, and Tianwei Chen.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="decorative icons in white on a blue and green gradient background" class="wp-image-1162851" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/CORPGEN-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Today’s AI agent benchmarks test one task at a time, while real workplace productivity requires managing dozens of interdependent tasks at once. To reflect this, we created a setting called Multi-Horizon Task Environments (MHTEs).&lt;/li&gt;



&lt;li&gt;Under multi-task loads, leading computer-using agents degrade sharply, with completion rates dropping from 16.7% to 8.7%.&lt;/li&gt;



&lt;li&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;, with hierarchical planning, memory isolation, and experiential learning, delivering up to 3.5 times higher completion rates than baselines across three independent agent backends.&lt;/li&gt;



&lt;li&gt;Because CORPGEN is architecture-agnostic and modular, its gains come from system design rather than any single base model, and it benefits directly as underlying models improve.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;By mid-morning, a typical knowledge worker is already juggling a client report, a budget spreadsheet, a slide deck, and an email backlog, all interdependent and all demanding attention at once. For AI agents to be genuinely useful in that environment, they will need to operate the same way, but today’s best models are evaluated one task at a time, not dozens at once.&lt;/p&gt;



&lt;p&gt;In our paper, “CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments,” we propose an agent framework that equips AI with the memory, planning, and learning capabilities to close that gap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="introducing-multi-horizon-task-environments"&gt;Introducing Multi-Horizon Task Environments&lt;/h2&gt;



&lt;p&gt;Replicating the reality of workplace multitasking requires a new kind of evaluation environment. In response, we developed Multi-Horizon Task Environments (MHTEs), settings where an agent must manage multiple complex tasks simultaneously. Each task requires 10 to 30 dependent steps within a single session spanning five hours.&lt;/p&gt;



&lt;p&gt;To determine what a benchmark would need to test, we ran MHTEs at scale on some of today’s leading AI agents, exposing four weaknesses. First, memory fills up. An agent cannot hold details for multiple active tasks at once. Second, information from one task interferes with reasoning about another. Third, tasks don’t depend on each other in simple sequences. They form complex webs where an agent must constantly check whether upstream work is finished before it can move forward on anything downstream. Fourth, every action cycle requires reprioritizing across all active tasks, not simply resuming where the agent left off.&lt;/p&gt;



&lt;p&gt;We also tested three independent agent systems under increasing loads. As the number of concurrent tasks rose from 12 to 46, completion rates fell from 16.7% to 8.7% across all systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="corpgen-s-architecture"&gt;CORPGEN’s architecture&lt;/h2&gt;



&lt;p&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;: LLM-powered AI agents with persistent identities, role-specific expertise, and realistic work schedules. They operate Microsoft Office applications through GUI automation and perform consistently within MHTEs over hours of continuous activity. Figure 1 illustrates how a digital employee moves through a full workday.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Diagram showing a digital employee's workday in three phases. Day Init on the left, where the agent loads memory and generates a daily plan. Execution Cycles in the center, where the agent repeatedly retrieves context, reasons and acts through a ReAct loop, and persists results across 50+ interleaved tasks. Day End on the right, where the agent generates a reflection and consolidates experience into long-term memory. Below the diagram, labels show the tiered memory architecture and experiential learning components." class="wp-image-1162865" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/day_in_life_color_AH-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Each day begins with a structured plan and memory loaded from previous sessions. The agent then works through overlapping tasks in repeated cycles, storing key outcomes at day’s end to inform the next session.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CORPGEN addresses each of the four weaknesses of concurrent task execution—memory overload, cross-task interference, dependency complexity, and reprioritization—in a targeted way. Hierarchical planning breaks objectives into daily goals and then into moment-to-moment decisions, allowing the agent to act from a structured plan instead of reviewing all available tasks before each step.&lt;/p&gt;



&lt;p&gt;Subagents perform complex operations like web research in isolated contexts, preventing cross-task contamination. A tiered memory system enables selective recall of task-related information rather than retaining everything in active context. Adaptive summarization compresses routine observations while preserving critical information, keeping memory growth controlled. &lt;/p&gt;



&lt;p&gt;Because these mechanisms are not tied to a specific base model, we tested CORPGEN across three different agents. In each case, we observed consistent gains. The improvements came from the architecture, not from the strength of any particular model. Figure 2 shows how they fit together within CORPGEN’s architecture.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Architecture diagram of the CORPGEN framework. At center is the Digital Employee with persistent identity, execution engine, cognitive tools, sub-agents, and context management. On the left, Hierarchical Planning decomposes strategic objectives into tactical plans and operational actions. On the right, Sub-Agents as Tools shows a Research Agent and Computer-Use agent (UFO2) operating in isolated contexts. At the bottom, the Tiered Memory Architecture spans working memory, structured long-term memory, and semantic memory via Mem0. Experiential Learning in the bottom right captures successful trajectories and routes feedback to UFO2. Multi-Employee Collaboration at the top shows async communication via Email and Teams with no shared state." class="wp-image-1162863" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/corpgen_arch_color_AH2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Four mechanisms support concurrent task execution in CORPGEN: hierarchical planning, isolated subagents, tiered memory, and adaptive summarization.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-digital-employees-collaborate"&gt;How digital employees collaborate&lt;/h2&gt;



&lt;p&gt;When multiple digital employees operate in the same environment, collaboration takes shape through standard communication channels, without predefined coordination rules. One employee sends an email requesting data; another picks it up in the next cycle, uses its memory to process it, and responds. This exchange mirrors real workplace communication.&lt;/p&gt;



&lt;p&gt;There is no shared internal state between agents. Coordination occurs entirely through email and Microsoft Teams, the same channels many workers use. Over time, these independent exchanges form recognizable organizational patterns. Some agents take on leadership roles; others provide support; shared documents become the connective tissue.&lt;/p&gt;



&lt;p&gt;When a communication path breaks, such as an email delivery error, agents reroute messages through alternate channels to keep work moving. The result is a virtual organization that behaves like a real one without being explicitly programmed to do so.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluating-corpgen"&gt;Evaluating CORPGEN&lt;/h2&gt;



&lt;p&gt;We evaluated CORPGEN on a multi-task benchmark that combined up to 46 tasks into a single six-hour session. Three findings stood out.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Baselines degrade as load increases; CORPGEN does not.&lt;/strong&gt; All three baseline agent systems showed steady performance declines as task load rose. CORPGEN, by contrast, maintained or improved its completion rates at higher loads. At 46 tasks, CORPGEN completed 15.2% of tasks, compared with 4.3% for the baselines, roughly 3.5 times more.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Experiential learning drives the largest gains.&lt;/strong&gt; We introduced CORPGEN’s components sequentially: first the orchestration layer, then cognitive tools, and finally experiential learning. The first two produced moderate improvements. Experiential learning, in which agents store records of completed tasks and reuse them when they encounter structurally similar work, produced the largest increase, raising completion rates from 8.7% to 15.2%.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evaluation methodology changes the picture.&lt;/strong&gt; When we inspected the actual output files produced by agents, the results agreed with human judgements roughly 90% of the time. Evaluation based on screenshots and action logs agreed only about 40% of the time. This gap suggests that common evaluation approaches may underestimate what agents actually accomplish in practice.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;video series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;On Second Thought&lt;/h2&gt;
				
								&lt;p class="large" id="on-second-thought"&gt;A video series with Sinead Bovell built around the questions everyone’s asking about AI. With expert voices from across Microsoft, we break down the tension and promise of this rapidly changing technology, exploring what’s evolving and what’s possible.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="implications-and-looking-forward"&gt;Implications and looking forward&lt;/h2&gt;



&lt;p&gt;The results suggest that memory and retrieval, not just raw model capability, may be a key bottleneck in getting agents to work in the real world. The largest gains came from experiential learning. Agents that learn from prior successes and apply those patterns to structurally similar tasks build an advantage over systems that respond to each task in isolation.&lt;/p&gt;



&lt;p&gt;CORPGEN also opens a new lens on how AI agents collaborate. Next steps include testing whether agents can maintain memory across multiple workdays and how they coordinate when working in teams. We are also exploring ways to make agents faster and more reliable by combining different methods of interacting with software.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" /&gt;



&lt;h2 class="wp-block-heading" id="acknowledgments"&gt;Acknowledgments&lt;/h2&gt;



&lt;p&gt;This work is a result of a collaboration between the Office of the CTO at Microsoft and the Microsoft AI Development Accelerator Program (MAIDAP). We would like to thank the Microsoft Security Research team for providing resources that supported this research. We also thank the members of the Microsoft UFO2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team and the Mem0&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; project for their open-source contributions, which enabled key components of the CORPGEN architecture, and the OSWorld team for the benchmark that served as the foundation for our multi-task evaluation.&lt;/p&gt;



&lt;p&gt;Finally, we thank the many contributors to this research: Anjel Shaileshbhai Patel, Dayquan Julienne, Charlotte Siska, Manuel Raúl Meléndez Luján, Anthony Twum-Barimah, Mauricio Velazco, and Tianwei Chen.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/</guid><pubDate>Thu, 26 Feb 2026 17:06:34 +0000</pubDate></item><item><title>[NEW] Google reveals Nano Banana 2 AI image model, coming to Gemini today (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/google-releases-nano-banana-2-ai-image-generator-promises-pro-results-with-flash-speed/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s new image model replaces the previous versions immediately.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana 2" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-640x361.png" width="640" /&gt;
                  &lt;img alt="Nano Banana 2" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The last year has been big for Google’s AI efforts. Its rapid-fire model releases have brought it to parity with the likes of OpenAI and Anthropic and, in some cases, pushed it into the lead. The Nano Banana image generator was emblematic of that trend when it debuted last year, and subsequent updates only made it better. Now, Google has announced yet another update to its image model with Nano Banana 2, which is available starting today.&lt;/p&gt;
&lt;p&gt;Nano Banana 2 is more accurately known as Gemini 3.1 Flash Image—the previous Nano Banana models were based on the 3.0 branch. According to Google, the new release can deliver results similar to Nano Banana Pro but with the speed of the non-pro Flash variant.&lt;/p&gt;
&lt;p&gt;Google promises the new image generator will have more advanced world knowledge pulled from the Internet by the Gemini 3.1 LLM. This apparently gives it the necessary information to render objects with greater fidelity and create more accurate infographics. The days of squiggly AI text were already ending, but Google says Nano Banana 2 has Pro-like text accuracy in image outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;With Nano Banana 2, Google promises consistency for up to five characters at a time, along with accurate rendering of as many as 14 different objects per workflow. This, along with richer textures and “vibrant” lighting will aid in visual storytelling with Nano Banana 2. Google is also expanding the range of available aspect ratios and resolutions, from 512px square up to 4K widescreen.&lt;/p&gt;
&lt;p&gt;So what can you do with Nano Banana 2? Google has provided some example images with associated prompts. These are, of course, handpicked images, but Nano Banana has been a popular image model for good reason. This degree of improvement seems believable based on past iterations of Nano Banana.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142698 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google AI infographic" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Infographic-1.png" width="1376" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: High-quality flat lay photography creating a DIY infographic that simply explains how the water cycle works, arranged on a clean, light gray textured background. The visual story flows from left to right in clear steps. Simple, clean black arrows are hand-drawn onto the background to guide the viewer’s eye. The overall mood is educational, modern, and easy to understand. The image is shot from a top-down, bird’s-eye view with soft, even lighting that minimizes shadows and keeps the focus on the process.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142712 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI museum comparison" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Museum.png" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image of Museum Clos Lucé. In the style of bright colored Synthetic Cubism. No text. Your plan is to first search for visual references, and generate after. Aspect ratio 16:9.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142702 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI farm image" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Multi-Input.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Create an image of these 14 characters and items having fun at the farm. The overall atmosphere is fun, silly and joyful. It is strictly important to keep identity consistent of all the 14 characters and items.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google must be pretty confident in this model’s capabilities because it will be the only one available going forward. Starting now, Nano Banana 2 will replace both the standard and Pro variants of Nano Banana across the Gemini app, search, AI Studio, Vertex AI, and Flow.&lt;/p&gt;
&lt;p&gt;In the Gemini app and on the website, Nano Banana 2 will be the image generator for the Fast, Thinking, and Pro settings. It’s possible there will eventually be a Nano Banana 2 Pro—Google tends to release elements of new model families one at a time. For now, it’s all “Flash” Image.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s new image model replaces the previous versions immediately.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana 2" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-640x361.png" width="640" /&gt;
                  &lt;img alt="Nano Banana 2" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The last year has been big for Google’s AI efforts. Its rapid-fire model releases have brought it to parity with the likes of OpenAI and Anthropic and, in some cases, pushed it into the lead. The Nano Banana image generator was emblematic of that trend when it debuted last year, and subsequent updates only made it better. Now, Google has announced yet another update to its image model with Nano Banana 2, which is available starting today.&lt;/p&gt;
&lt;p&gt;Nano Banana 2 is more accurately known as Gemini 3.1 Flash Image—the previous Nano Banana models were based on the 3.0 branch. According to Google, the new release can deliver results similar to Nano Banana Pro but with the speed of the non-pro Flash variant.&lt;/p&gt;
&lt;p&gt;Google promises the new image generator will have more advanced world knowledge pulled from the Internet by the Gemini 3.1 LLM. This apparently gives it the necessary information to render objects with greater fidelity and create more accurate infographics. The days of squiggly AI text were already ending, but Google says Nano Banana 2 has Pro-like text accuracy in image outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;With Nano Banana 2, Google promises consistency for up to five characters at a time, along with accurate rendering of as many as 14 different objects per workflow. This, along with richer textures and “vibrant” lighting will aid in visual storytelling with Nano Banana 2. Google is also expanding the range of available aspect ratios and resolutions, from 512px square up to 4K widescreen.&lt;/p&gt;
&lt;p&gt;So what can you do with Nano Banana 2? Google has provided some example images with associated prompts. These are, of course, handpicked images, but Nano Banana has been a popular image model for good reason. This degree of improvement seems believable based on past iterations of Nano Banana.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142698 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google AI infographic" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Infographic-1.png" width="1376" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: High-quality flat lay photography creating a DIY infographic that simply explains how the water cycle works, arranged on a clean, light gray textured background. The visual story flows from left to right in clear steps. Simple, clean black arrows are hand-drawn onto the background to guide the viewer’s eye. The overall mood is educational, modern, and easy to understand. The image is shot from a top-down, bird’s-eye view with soft, even lighting that minimizes shadows and keeps the focus on the process.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142712 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI museum comparison" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Museum.png" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image of Museum Clos Lucé. In the style of bright colored Synthetic Cubism. No text. Your plan is to first search for visual references, and generate after. Aspect ratio 16:9.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142702 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI farm image" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Multi-Input.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Create an image of these 14 characters and items having fun at the farm. The overall atmosphere is fun, silly and joyful. It is strictly important to keep identity consistent of all the 14 characters and items.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google must be pretty confident in this model’s capabilities because it will be the only one available going forward. Starting now, Nano Banana 2 will replace both the standard and Pro variants of Nano Banana across the Gemini app, search, AI Studio, Vertex AI, and Flow.&lt;/p&gt;
&lt;p&gt;In the Gemini app and on the website, Nano Banana 2 will be the image generator for the Fast, Thinking, and Pro settings. It’s possible there will eventually be a Nano Banana 2 Pro—Google tends to release elements of new model families one at a time. For now, it’s all “Flash” Image.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/google-releases-nano-banana-2-ai-image-generator-promises-pro-results-with-flash-speed/</guid><pubDate>Thu, 26 Feb 2026 17:12:10 +0000</pubDate></item></channel></rss>