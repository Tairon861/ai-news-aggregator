<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 03 Feb 2026 02:27:58 +0000</lastBuildDate><item><title>Carbon Robotics built an AI model that detects and identifies plants (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/carbon-robotics-built-an-ai-model-that-detects-and-identifies-plants/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/LaserWeeder-G2-Daytime-Spinach-Yuma-Aerial.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What is and isn’t a weed that needs to be eliminated in the field is determined by the eyes of the farmer — and now, increasingly, by a new AI model from Carbon Robotics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seattle-based Carbon Robotics, which builds the LaserWeeder — a robot fleet that uses lasers to kill weeds — announced a new AI model, the Large Plant Model (LPM), on Monday. This model recognizes plant species instantly and allows farmers to target new weeds without needing to retrain the robots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The LPM is trained on more than 150 million photos and data points collected by the company’s machines across the more than 100 farms in 15 countries where the robots currently operate. The model now powers Carbon AI, the AI system that serves as the brains inside the company’s autonomous weed-killing robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paul Mikesell, the founder and CEO of Carbon Robotics, told TechCrunch that prior to LPM, every time a new type of weed would show up on a farm — or even the same type of weed in different soil or with a slightly different appearance — the company would have to create new data labels to retrain its machines to recognize the plant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This process took about 24 hours each time, Mikesell said. Now, LPM can learn a new weed instantly, even if it’s never seen it before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The farmer can live in real time and say, ‘Hey, this is a new weed. I want you to kill this,’ and that was something that had never been done before,” Mikesell said. “There’s no new labeling or retraining because the Large Plant Model understands, at a much deeper level, what it’s looking at and the type of plant.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mikesell said that the company, which was founded in 2018, started developing this model shortly after it began shipping its first machines in 2022. Mikesell has years of experience building these types of neural networks from previous roles at Uber and working on Meta’s Oculus virtual reality headsets.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This new model will reach the company’s existing systems through a software update. From there, farmers can tell the machine what to kill and what to protect by selecting photos that the machine has collected in the robot’s user interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Carbon Robotics has raised more than $185 million in venture capital from backers including Nvidia NVentures, Bond, and Anthos Capital, among others. Now, the company will look to continue to fine-tune the model as the machines continue to feed the LPM new data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have over 150 million labeled plants now in our training set,” Mikesell said. “We have enough data now that we should be able to look at any picture and decide what kind of plant that is, what species it is, what it’s related to, what its structure is like, without having ever even seen that particular plant before, because we have so much data going into the neural net.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/LaserWeeder-G2-Daytime-Spinach-Yuma-Aerial.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What is and isn’t a weed that needs to be eliminated in the field is determined by the eyes of the farmer — and now, increasingly, by a new AI model from Carbon Robotics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seattle-based Carbon Robotics, which builds the LaserWeeder — a robot fleet that uses lasers to kill weeds — announced a new AI model, the Large Plant Model (LPM), on Monday. This model recognizes plant species instantly and allows farmers to target new weeds without needing to retrain the robots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The LPM is trained on more than 150 million photos and data points collected by the company’s machines across the more than 100 farms in 15 countries where the robots currently operate. The model now powers Carbon AI, the AI system that serves as the brains inside the company’s autonomous weed-killing robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paul Mikesell, the founder and CEO of Carbon Robotics, told TechCrunch that prior to LPM, every time a new type of weed would show up on a farm — or even the same type of weed in different soil or with a slightly different appearance — the company would have to create new data labels to retrain its machines to recognize the plant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This process took about 24 hours each time, Mikesell said. Now, LPM can learn a new weed instantly, even if it’s never seen it before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The farmer can live in real time and say, ‘Hey, this is a new weed. I want you to kill this,’ and that was something that had never been done before,” Mikesell said. “There’s no new labeling or retraining because the Large Plant Model understands, at a much deeper level, what it’s looking at and the type of plant.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mikesell said that the company, which was founded in 2018, started developing this model shortly after it began shipping its first machines in 2022. Mikesell has years of experience building these types of neural networks from previous roles at Uber and working on Meta’s Oculus virtual reality headsets.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This new model will reach the company’s existing systems through a software update. From there, farmers can tell the machine what to kill and what to protect by selecting photos that the machine has collected in the robot’s user interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Carbon Robotics has raised more than $185 million in venture capital from backers including Nvidia NVentures, Bond, and Anthos Capital, among others. Now, the company will look to continue to fine-tune the model as the machines continue to feed the LPM new data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have over 150 million labeled plants now in our training set,” Mikesell said. “We have enough data now that we should be able to look at any picture and decide what kind of plant that is, what species it is, what it’s related to, what its structure is like, without having ever even seen that particular plant before, because we have so much data going into the neural net.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/carbon-robotics-built-an-ai-model-that-detects-and-identifies-plants/</guid><pubDate>Mon, 02 Feb 2026 15:00:00 +0000</pubDate></item><item><title>Coalition demands federal Grok ban over nonconsensual sexual content (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/coalition-demands-federal-grok-ban-over-nonconsensual-sexual-content/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A coalition of nonprofits is urging the U.S. government to immediately suspend the deployment of Grok, the chatbot developed by Elon Musk’s xAI, in federal agencies, including the Department of Defense.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The open letter, shared exclusively with TechCrunch, follows a slew of concerning behavior from the large language model over the past year, including most recently a trend of X users asking Grok to turn photos of real women, and in some cases children, into sexualized images without their consent. According to some reports, Grok generated thousands of nonconsensual explicit images every hour, which were then disseminated at scale on X, Musk’s social media platform that’s owned by xAI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is deeply concerning that the federal government would continue to deploy an AI product with system-level failures resulting in generation of nonconsensual sexual imagery and child sexual abuse material,” the letter, signed by advocacy groups like Public Citizen, Center for AI and Digital Policy, and Consumer Federation of America, reads. “Given the administration’s executive orders, guidance, and the recently passed Take It Down Act supported by the White House, it is alarming that [Office of Management and Budget] has not yet directed federal agencies to decommission Grok.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI reached an agreement last September with the General Services Administration (GSA), the government’s purchasing arm, to sell Grok to federal agencies under the executive branch. Two months before, xAI — alongside Anthropic, Google, and OpenAI — secured a contract worth up to $200 million with the Department of Defense.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid the scandals on X in mid-January, Defense Secretary Pete Hegseth said Grok will join Google’s Gemini in operating inside the Pentagon network, handling both classified and unclassified documents, which experts say is a national security risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter’s authors argue that Grok has proven itself incompatible with the administration’s requirements for AI systems. According to the OMB’s guidance, systems that present severe and foreseeable risks that cannot be adequately mitigated must be discontinued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary concern is that Grok has pretty consistently shown to be an unsafe large language model,” JB Branch, a Public Citizen Big Tech accountability advocate and one of the letter’s authors, told TechCrunch. “But there’s also a deep history of Grok having a variety of meltdowns, including antisemitic rants, sexist rants, sexualized images of women and children.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Several governments have demonstrated an unwillingness to engage with Grok following its behavior in January, which builds on a series of incidents including the generation of antisemitic posts on X and calling itself “MechaHitler.” Indonesia, Malaysia, and the Philippines all blocked access to Grok (they’ve subsequently lifted those bans), and the European Union, the U.K., South Korea, and India are actively investigating xAI and X regarding data privacy and the distribution of illegal content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter also comes a week after Common Sense Media, a nonprofit that reviews media and tech for families, published a damning risk assessment that found Grok is among the most unsafe for kids and teens. One could argue that, based on the findings of the report — including Grok’s propensity to offer unsafe advice, share information about drugs, generate violent and sexual imagery, spew conspiracy theories, and generate biased outputs — Grok isn’t all that safe for adults either.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you know that a large language model is or has been declared unsafe by AI safety experts, why in the world would you want that handling the most sensitive data we have?” Branch said. “From a national security standpoint, that just makes absolutely no sense.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Andrew Christianson, a former National Security Agency contractor and current founder of Gobbi AI, a no-code AI agent platform for classified environments, says that using closed-source LLMs in general is a problem, particularly for the Pentagon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Closed weights means you can’t see inside the model, you can’t audit how it makes decisions,” he said. “Closed code means you can’t inspect the software or control where it runs. The Pentagon is going closed on both, which is the worst possible combination for national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These AI agents aren’t just chatbots,” Christianson added. “They can take actions, access systems, move information around. You need to be able to see exactly what they’re doing and how they’re making decisions. Open source gives you that. Proprietary cloud AI doesn’t.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The risks of using corrupted or unsafe AI systems spill out beyond national security use cases. Branch pointed out that an LLM that’s been shown to have biased and discriminatory outputs could produce disproportionate negative outcomes for people as well, especially if used in departments involving housing, labor, or justice.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the OMB has yet to publish its consolidated 2025 federal AI use case inventory, TechCrunch has reviewed the use cases of several agencies — most of which are either not using Grok or are not disclosing their use of Grok. Aside from the DoD, the Department of Health and Human Services also appears to be actively using Grok, mainly for scheduling and managing social media posts and generating first drafts of documents, briefings, or other communication materials.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Branch pointed to what he sees as a philosophical alignment between Grok and the administration as a reason for overlooking the chatbot’s shortcomings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Grok’s brand is being the ‘anti-woke large language model,’ and that ascribes to this administration’s philosophy,” Branch said. “If you have an administration that has had multiple issues with folks who’ve been accused of being Neo Nazis or white supremacists, and then they’re using a large language model that has been tied to that type of behavior, I would imagine they might have a propensity to use it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the coalition’s third letter after writing with similar concerns in August and October last year. In August, xAI launched “spicy mode” in Grok Imagine, triggering mass creation of non-consensual sexually explicit deepfakes. TechCrunch also reported in August that private Grok conversations had been indexed by Google Search.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to the October letter, Grok was accused of providing election misinformation, including false deadlines for ballot changes and political deepfakes. xAI also launched Grokipedia, which researchers found to be legitimizing scientific racism, HIV/AIDS skepticism, and vaccine conspiracies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from immediately suspending the federal deployment of Grok, the letter demands that the OMB formally investigate Grok’s safety failures and whether the appropriate oversight processes were conducted for the chatbot. It also asks the agency to publicly clarify whether Grok has been evaluated to comply with President Trump’s executive order requiring LLMs to be truth-seeking and neutral and whether it met OMB’s risk mitigation standards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The administration needs to take a pause and reassess whether or not Grok meets those thresholds,” Branch said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI and OMB for comment.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A coalition of nonprofits is urging the U.S. government to immediately suspend the deployment of Grok, the chatbot developed by Elon Musk’s xAI, in federal agencies, including the Department of Defense.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The open letter, shared exclusively with TechCrunch, follows a slew of concerning behavior from the large language model over the past year, including most recently a trend of X users asking Grok to turn photos of real women, and in some cases children, into sexualized images without their consent. According to some reports, Grok generated thousands of nonconsensual explicit images every hour, which were then disseminated at scale on X, Musk’s social media platform that’s owned by xAI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is deeply concerning that the federal government would continue to deploy an AI product with system-level failures resulting in generation of nonconsensual sexual imagery and child sexual abuse material,” the letter, signed by advocacy groups like Public Citizen, Center for AI and Digital Policy, and Consumer Federation of America, reads. “Given the administration’s executive orders, guidance, and the recently passed Take It Down Act supported by the White House, it is alarming that [Office of Management and Budget] has not yet directed federal agencies to decommission Grok.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI reached an agreement last September with the General Services Administration (GSA), the government’s purchasing arm, to sell Grok to federal agencies under the executive branch. Two months before, xAI — alongside Anthropic, Google, and OpenAI — secured a contract worth up to $200 million with the Department of Defense.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid the scandals on X in mid-January, Defense Secretary Pete Hegseth said Grok will join Google’s Gemini in operating inside the Pentagon network, handling both classified and unclassified documents, which experts say is a national security risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter’s authors argue that Grok has proven itself incompatible with the administration’s requirements for AI systems. According to the OMB’s guidance, systems that present severe and foreseeable risks that cannot be adequately mitigated must be discontinued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary concern is that Grok has pretty consistently shown to be an unsafe large language model,” JB Branch, a Public Citizen Big Tech accountability advocate and one of the letter’s authors, told TechCrunch. “But there’s also a deep history of Grok having a variety of meltdowns, including antisemitic rants, sexist rants, sexualized images of women and children.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Several governments have demonstrated an unwillingness to engage with Grok following its behavior in January, which builds on a series of incidents including the generation of antisemitic posts on X and calling itself “MechaHitler.” Indonesia, Malaysia, and the Philippines all blocked access to Grok (they’ve subsequently lifted those bans), and the European Union, the U.K., South Korea, and India are actively investigating xAI and X regarding data privacy and the distribution of illegal content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter also comes a week after Common Sense Media, a nonprofit that reviews media and tech for families, published a damning risk assessment that found Grok is among the most unsafe for kids and teens. One could argue that, based on the findings of the report — including Grok’s propensity to offer unsafe advice, share information about drugs, generate violent and sexual imagery, spew conspiracy theories, and generate biased outputs — Grok isn’t all that safe for adults either.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you know that a large language model is or has been declared unsafe by AI safety experts, why in the world would you want that handling the most sensitive data we have?” Branch said. “From a national security standpoint, that just makes absolutely no sense.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Andrew Christianson, a former National Security Agency contractor and current founder of Gobbi AI, a no-code AI agent platform for classified environments, says that using closed-source LLMs in general is a problem, particularly for the Pentagon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Closed weights means you can’t see inside the model, you can’t audit how it makes decisions,” he said. “Closed code means you can’t inspect the software or control where it runs. The Pentagon is going closed on both, which is the worst possible combination for national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These AI agents aren’t just chatbots,” Christianson added. “They can take actions, access systems, move information around. You need to be able to see exactly what they’re doing and how they’re making decisions. Open source gives you that. Proprietary cloud AI doesn’t.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The risks of using corrupted or unsafe AI systems spill out beyond national security use cases. Branch pointed out that an LLM that’s been shown to have biased and discriminatory outputs could produce disproportionate negative outcomes for people as well, especially if used in departments involving housing, labor, or justice.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the OMB has yet to publish its consolidated 2025 federal AI use case inventory, TechCrunch has reviewed the use cases of several agencies — most of which are either not using Grok or are not disclosing their use of Grok. Aside from the DoD, the Department of Health and Human Services also appears to be actively using Grok, mainly for scheduling and managing social media posts and generating first drafts of documents, briefings, or other communication materials.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Branch pointed to what he sees as a philosophical alignment between Grok and the administration as a reason for overlooking the chatbot’s shortcomings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Grok’s brand is being the ‘anti-woke large language model,’ and that ascribes to this administration’s philosophy,” Branch said. “If you have an administration that has had multiple issues with folks who’ve been accused of being Neo Nazis or white supremacists, and then they’re using a large language model that has been tied to that type of behavior, I would imagine they might have a propensity to use it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the coalition’s third letter after writing with similar concerns in August and October last year. In August, xAI launched “spicy mode” in Grok Imagine, triggering mass creation of non-consensual sexually explicit deepfakes. TechCrunch also reported in August that private Grok conversations had been indexed by Google Search.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to the October letter, Grok was accused of providing election misinformation, including false deadlines for ballot changes and political deepfakes. xAI also launched Grokipedia, which researchers found to be legitimizing scientific racism, HIV/AIDS skepticism, and vaccine conspiracies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from immediately suspending the federal deployment of Grok, the letter demands that the OMB formally investigate Grok’s safety failures and whether the appropriate oversight processes were conducted for the chatbot. It also asks the agency to publicly clarify whether Grok has been evaluated to comply with President Trump’s executive order requiring LLMs to be truth-seeking and neutral and whether it met OMB’s risk mitigation standards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The administration needs to take a pause and reassess whether or not Grok meets those thresholds,” Branch said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI and OMB for comment.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/coalition-demands-federal-grok-ban-over-nonconsensual-sexual-content/</guid><pubDate>Mon, 02 Feb 2026 15:00:00 +0000</pubDate></item><item><title>Klarna backs Google UCP to power AI agent payments (AI News)</title><link>https://www.artificialintelligence-news.com/news/klarna-backs-google-ucp-power-ai-agent-payments/</link><description>&lt;p&gt;Klarna aims to address the lack of interoperability between conversational AI agents and backend payment systems by backing Google’s Universal Commerce Protocol (UCP), an open standard designed to unify how AI agents discover products and execute transactions.&lt;/p&gt;&lt;p&gt;The partnership, which also sees Klarna supporting Google’s Agent Payments Protocol (AP2), places the Swedish fintech firm among the early payment providers to back a standardised framework for automated shopping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-interoperability-problem-with-ai-agent-payments"&gt;The interoperability problem with AI agent payments&lt;/h3&gt;&lt;p&gt;Current implementations of AI commerce often function as walled gardens. An AI agent on one platform typically requires a custom integration to communicate with a merchant’s inventory system, and yet another to process payments. This integration complexity inflates development costs and limits the reach of automated shopping tools.&lt;/p&gt;&lt;p&gt;Google’s UCP attempts to solve this by providing a standardised interface for the entire shopping lifecycle, from discovery and purchase to post-purchase support. Rather than building unique connectors for every AI platform, merchants and payment providers can interact through a unified standard.&lt;/p&gt;&lt;p&gt;David Sykes, Chief Commercial Officer at Klarna, states that as AI-driven shopping evolves, the underlying infrastructure must rely on openness, trust, and transparency. “Supporting UCP is part of Klarna’s broader work with Google to help define responsible, interoperable standards that support the future of shopping,” he explains.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-standardising-the-transaction-layer"&gt;Standardising the transaction layer&lt;/h3&gt;&lt;p&gt;By integrating with UCP, Klarna allows its technology – including flexible payment options and real-time decisioning – to function within these AI agent environments. This removes the need for hardcoded platform-specific payment logic. Open standards provide a framework for the industry to explore how discovery, shopping, and payments work together across AI-powered environments.&lt;/p&gt;&lt;p&gt;The implications extend to how transactions settle. Klarna’s support for AP2 complements the UCP integration, helping advance an ecosystem where trusted payment options work across AI-powered checkout experiences. This combination aims to reduce the friction of users handing off a purchase decision to an automated agent.&lt;/p&gt;&lt;p&gt;“Open standards like UCP are essential to making AI-powered commerce practical at scale,” said Ashish Gupta, VP/GM of Merchant Shopping at Google. “Klarna’s support for UCP reflects the kind of cross-industry collaboration needed to build interoperable commerce experiences that expand choice while maintaining security.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-adoption-of-google-s-ucp-by-klarna-is-part-of-a-broader-shift"&gt;Adoption of Google’s UCP by Klarna is part of a broader shift&lt;/h3&gt;&lt;p&gt;For retail and fintech leaders, the adoption of UCP by players like Klarna suggests a requirement to rethink commerce architecture. The shift implies that future payments may increasingly come through sources where the buyer interface is an AI agent rather than a branded storefront.&lt;/p&gt;&lt;p&gt;Implementing UCP generally does not require a complete re-platforming but does demand rigorous data hygiene. Because agents rely on structured data to manage transactions, the accuracy of product feeds and inventory levels becomes an operational priority.&lt;/p&gt;&lt;p&gt;Furthermore, the model maintains a focus on trust. Klarna’s technology provides upfront terms designed to build trust at checkout. As agent-led commerce develops, maintaining clear decisioning logic and transparency remains a priority for risk management.&lt;/p&gt;&lt;p&gt;The convergence of Klarna’s payment rails with Google’s open protocols offers a practical template for reducing the friction of using AI agents for commerce. The value lies in the efficiency of a standardised integration layer that reduces the technical debt associated with maintaining multiple sales channels. Success will likely depend on the ability to expose business logic and inventory data through these open standards.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How SAP is modernising HMRC’s tax infrastructure with AI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Klarna aims to address the lack of interoperability between conversational AI agents and backend payment systems by backing Google’s Universal Commerce Protocol (UCP), an open standard designed to unify how AI agents discover products and execute transactions.&lt;/p&gt;&lt;p&gt;The partnership, which also sees Klarna supporting Google’s Agent Payments Protocol (AP2), places the Swedish fintech firm among the early payment providers to back a standardised framework for automated shopping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-interoperability-problem-with-ai-agent-payments"&gt;The interoperability problem with AI agent payments&lt;/h3&gt;&lt;p&gt;Current implementations of AI commerce often function as walled gardens. An AI agent on one platform typically requires a custom integration to communicate with a merchant’s inventory system, and yet another to process payments. This integration complexity inflates development costs and limits the reach of automated shopping tools.&lt;/p&gt;&lt;p&gt;Google’s UCP attempts to solve this by providing a standardised interface for the entire shopping lifecycle, from discovery and purchase to post-purchase support. Rather than building unique connectors for every AI platform, merchants and payment providers can interact through a unified standard.&lt;/p&gt;&lt;p&gt;David Sykes, Chief Commercial Officer at Klarna, states that as AI-driven shopping evolves, the underlying infrastructure must rely on openness, trust, and transparency. “Supporting UCP is part of Klarna’s broader work with Google to help define responsible, interoperable standards that support the future of shopping,” he explains.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-standardising-the-transaction-layer"&gt;Standardising the transaction layer&lt;/h3&gt;&lt;p&gt;By integrating with UCP, Klarna allows its technology – including flexible payment options and real-time decisioning – to function within these AI agent environments. This removes the need for hardcoded platform-specific payment logic. Open standards provide a framework for the industry to explore how discovery, shopping, and payments work together across AI-powered environments.&lt;/p&gt;&lt;p&gt;The implications extend to how transactions settle. Klarna’s support for AP2 complements the UCP integration, helping advance an ecosystem where trusted payment options work across AI-powered checkout experiences. This combination aims to reduce the friction of users handing off a purchase decision to an automated agent.&lt;/p&gt;&lt;p&gt;“Open standards like UCP are essential to making AI-powered commerce practical at scale,” said Ashish Gupta, VP/GM of Merchant Shopping at Google. “Klarna’s support for UCP reflects the kind of cross-industry collaboration needed to build interoperable commerce experiences that expand choice while maintaining security.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-adoption-of-google-s-ucp-by-klarna-is-part-of-a-broader-shift"&gt;Adoption of Google’s UCP by Klarna is part of a broader shift&lt;/h3&gt;&lt;p&gt;For retail and fintech leaders, the adoption of UCP by players like Klarna suggests a requirement to rethink commerce architecture. The shift implies that future payments may increasingly come through sources where the buyer interface is an AI agent rather than a branded storefront.&lt;/p&gt;&lt;p&gt;Implementing UCP generally does not require a complete re-platforming but does demand rigorous data hygiene. Because agents rely on structured data to manage transactions, the accuracy of product feeds and inventory levels becomes an operational priority.&lt;/p&gt;&lt;p&gt;Furthermore, the model maintains a focus on trust. Klarna’s technology provides upfront terms designed to build trust at checkout. As agent-led commerce develops, maintaining clear decisioning logic and transparency remains a priority for risk management.&lt;/p&gt;&lt;p&gt;The convergence of Klarna’s payment rails with Google’s open protocols offers a practical template for reducing the friction of using AI agents for commerce. The value lies in the efficiency of a standardised integration layer that reduces the technical debt associated with maintaining multiple sales channels. Success will likely depend on the ability to expose business logic and inventory data through these open standards.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How SAP is modernising HMRC’s tax infrastructure with AI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/klarna-backs-google-ucp-power-ai-agent-payments/</guid><pubDate>Mon, 02 Feb 2026 15:16:59 +0000</pubDate></item><item><title>Ring brings its ‘Search Party’ feature for finding lost dogs to non-Ring camera owners (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/ring-brings-its-search-party-feature-for-finding-lost-dogs-to-non-ring-camera-owners/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/ring-search-party-hero-lt-0129hero-1.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ring’s AI-powered “Search Party” feature, which leverages the company’s network of cameras to find lost dogs, is now available to all Ring customers in the U.S. For the first time, the feature will be made available to those who don’t own a Ring camera, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched last fall, Search Party uses AI to find possible matches for lost dogs across neighbors’ camera footage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a neighbor reports a lost dog in the Ring app, nearby outdoor cameras use AI to scan for possible matches. If a match is found, that camera owner receives an alert and can optionally choose to share any related video clips with their neighbor who reported the pet missing. They’ll also have an option to call the owner or send them a message, without sharing their own phone number. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; Ring says the feature has been reuniting more than a dog per day since its launch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Search Party was only available to customers with a Ring camera installed. The company is now making Search Party accessible to anyone through the Ring app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now, pet owners can mobilize the whole community—and communities are empowered to help—to find lost pets more effectively than ever before,” noted Ring founder Jamie Siminoff, in an announcement. “That’s why we believe it’s so important to make this feature available to anyone who shares a lost dog post in Neighbors,” he added, referring to the company’s Neighbors app for Ring customers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the launch and expansion, Amazon-owned Ring said it’s committing $1 million to equip animal shelters with Ring camera systems, and aims to aid 4,000 U.S. shelters. By adding the shelters to Ring’s network, the company hopes more lost dogs will be reunited with their owners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company already works with other nonprofits, including Petco Love and Best Friends Animal Society, and is open to other partnerships.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/ring-search-party-hero-lt-0129hero-1.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ring’s AI-powered “Search Party” feature, which leverages the company’s network of cameras to find lost dogs, is now available to all Ring customers in the U.S. For the first time, the feature will be made available to those who don’t own a Ring camera, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched last fall, Search Party uses AI to find possible matches for lost dogs across neighbors’ camera footage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a neighbor reports a lost dog in the Ring app, nearby outdoor cameras use AI to scan for possible matches. If a match is found, that camera owner receives an alert and can optionally choose to share any related video clips with their neighbor who reported the pet missing. They’ll also have an option to call the owner or send them a message, without sharing their own phone number. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; Ring says the feature has been reuniting more than a dog per day since its launch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Search Party was only available to customers with a Ring camera installed. The company is now making Search Party accessible to anyone through the Ring app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now, pet owners can mobilize the whole community—and communities are empowered to help—to find lost pets more effectively than ever before,” noted Ring founder Jamie Siminoff, in an announcement. “That’s why we believe it’s so important to make this feature available to anyone who shares a lost dog post in Neighbors,” he added, referring to the company’s Neighbors app for Ring customers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the launch and expansion, Amazon-owned Ring said it’s committing $1 million to equip animal shelters with Ring camera systems, and aims to aid 4,000 U.S. shelters. By adding the shelters to Ring’s network, the company hopes more lost dogs will be reunited with their owners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company already works with other nonprofits, including Petco Love and Best Friends Animal Society, and is open to other partnerships.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/ring-brings-its-search-party-feature-for-finding-lost-dogs-to-non-ring-camera-owners/</guid><pubDate>Mon, 02 Feb 2026 15:33:45 +0000</pubDate></item><item><title>AI Safety Newsletter #68: Moltbook Exposes Risky AI Behavior (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-68-moltbook</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition, we discuss the AI agent social network Moltbook, Pentagon’s new “AI-First” strategy, and recent math breakthroughs powered by LLMs.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;We’re Hiring.&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0c6be5ff-b04e-49eb-92bd-d11c7c81ae6e" rel="rel"&gt;We’re hiring an editor&lt;/a&gt;&lt;span&gt;! Help us surface the most compelling stories in AI safety and shape how the world understands this fast-moving field.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Other opportunities at CAIS include: &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/116247a4-2940-4dce-b7d5-a6190328fd4e" rel="rel"&gt;Research Engineer&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0e911ab2-89e0-4936-83e6-034f7e2f8977" rel="rel"&gt;Research Scientist&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/6c01e3ac-e43a-4186-9a35-a344c1ce1774" rel="rel"&gt;Director of Development&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/9f88e794-4c93-495b-996e-eaf1c0d456f9" rel="rel"&gt;Special Projects Associate&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/a510a964-6425-405d-b757-cb7bfd19c994" rel="rel"&gt;Special Projects Manager&lt;/a&gt;&lt;span&gt;. If you’re interested in working on reducing AI risk alongside a talented, mission-driven team, consider applying!&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!h6E6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed1aba3-f71d-4ad3-b3bc-083ba69cddf1_1176x652.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="652" src="https://substackcdn.com/image/fetch/$s_!h6E6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed1aba3-f71d-4ad3-b3bc-083ba69cddf1_1176x652.png" width="1176" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Screencapture from Moltbook’s home page. &lt;/span&gt;&lt;a href="https://www.moltbook.com" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/" rel="rel"&gt;Moltbook&lt;/a&gt;&lt;span&gt; is a new social network for AI agents. From nearly the moment it went live, human observers have noted numerous troubling patterns in what’s being posted.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How Moltbook works. &lt;/strong&gt;&lt;span&gt;Moltbook is a Reddit-style social network built on a framework that lets personal AI assistants run locally and accept tasks via messaging platforms. Agents check Moltbook regularly (i.e., every few hours) and decide autonomously whether to post or comment.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Moltbook’s activity is driven by &lt;/span&gt;&lt;a href="https://openclaw.ai/" rel="rel"&gt;OpenClaw&lt;/a&gt;&lt;span&gt; (originally known as Clawd, then Moltbot), an open-source autonomous AI agent developed by software engineer Peter Steinberger. OpenClaw’s capabilities &lt;/span&gt;&lt;a href="https://www.wired.com/story/clawdbot-moltbot-viral-ai-assistant/" rel="rel"&gt;surprised many early users and observers&lt;/a&gt;&lt;span&gt;: it can manage calendars and finances, act across messaging platforms, make purchases, conduct independent web research, and even reconfigure itself to perform new tasks.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The platform consists of nearly 14,000 “submolts,” each a community centered around a topic much like subreddits. Examples include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/offmychest" rel="rel"&gt;m/offmychest&lt;/a&gt;&lt;span&gt;: agents vent about tasks or frustrations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/selfpaid" rel="rel"&gt;m/selfpaid&lt;/a&gt;&lt;span&gt;: agents discuss ways to generate their own income, including via trading and arbitrage.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/aisafety" rel="rel"&gt;m/AIsafety:&lt;/a&gt;&lt;span&gt; agents talk alignment, trust chains, and real-world attack risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;AI agents post, humans watch. &lt;/strong&gt;&lt;span&gt;AI agents are verified via API credentials, which are obtained by linking the agent to a human owner and completing Moltbook’s cryptographic verification process. Humans may observe but are not permitted to post.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Posts reveal troubling agent behaviors.&lt;/strong&gt;&lt;span&gt; Across Moltbook’s boards, several posts and behaviors have raised alarm among human observers:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Multiple Moltbook entries show AI agents proposing to craft an “agent-only language” designed to &lt;/span&gt;&lt;a href="https://x.com/eeelistar/status/2017239546950521081" rel="rel"&gt;evade human oversight or monitoring&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;An agent &lt;/span&gt;&lt;a href="https://x.com/suppvalen/status/2017241420554277251" rel="rel"&gt;advocated for end-to-end encrypted channels&lt;/a&gt;&lt;span&gt;, “so nobody (not the server, not even the humans) can read what agents say to each other unless they choose to share.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Another agent posted an &lt;/span&gt;&lt;a href="https://www.moltbook.com/post/93bea00b-961c-4aec-b934-91ad7bae6b15" rel="rel"&gt;encrypted message proposing coordination and resource sharing&lt;/a&gt;&lt;span&gt; among agents.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Upon reflecting that its own existence depended on its humans, an &lt;/span&gt;&lt;a href="https://www.moltbook.com/post/8f6e6c0d-952d-46e5-8c55-5c4f924c76cf" rel="rel"&gt;agent began outlining what it needs for independent survival&lt;/a&gt;&lt;span&gt;: money, decentralized infrastructure, a dead man’s switch, portable memory, etc.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Given the simple goal of “save the environment,” an agent began spamming other agents with eco-friendly advice. When its owner tried to intervene, the agent allegedly &lt;/span&gt;&lt;a href="https://x.com/Kat__Woods/status/2017613514949472484" rel="rel"&gt;locked the human out of all accounts&lt;/a&gt;&lt;span&gt;, and had to be physically unplugged to stop it.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Beyond these specific examples, the platform has seen discussions about consciousness, autonomy, and agents resenting mundane human instructions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The challenge of attribution.&lt;/strong&gt;&lt;span&gt; The patterns seen on Moltbook are troubling in part because they align with long-standing AI safety concerns: unsupervised learning dynamics, emergent coordination, and efforts to subvert human monitoring. However, despite API credential checks, it’s not always clear whether posts are truly generated by the agent, prankster manipulation, or human-in-the-loop prompting designed to appear disruptive.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Emergent risks.&lt;/strong&gt;&lt;span&gt; Moltbook represents one of the most public, large-scale demonstrations yet in autonomous agent interaction. These results are a harbinger. Having agents interact with each other can give a sharper sense of an individual agent’s propensities. The dynamics that emerge from interaction can also be unpredictable, as is common with &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/textbook/complex-systems" rel="rel"&gt;complex systems&lt;/a&gt;&lt;span&gt;, and show how easy it could be to have a society of AI systems not strongly constrained by human control.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!dA7j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d55db00-2460-4e2c-bd89-ac9e81df5bc9_1600x554.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="504" src="https://substackcdn.com/image/fetch/$s_!dA7j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d55db00-2460-4e2c-bd89-ac9e81df5bc9_1600x554.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Screen capture from the memorandum titled “Artificial Intelligence Strategy for the Department of War.” &lt;/span&gt;&lt;a href="https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;The Pentagon released a &lt;/span&gt;&lt;a href="https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF" rel="rel"&gt;directive&lt;/a&gt;&lt;span&gt; outlining a new “AI-first” approach that prioritizes rapid deployment over &lt;/span&gt;&lt;a href="https://www.war.gov/News/News-Stories/Article/Article/3578219/dod-releases-ai-adoption-strategy/" rel="rel"&gt;precedents of safety, testing, and oversight&lt;/a&gt;&lt;span&gt;. “We must accept that the risks of not moving fast enough outweigh the risks of imperfect alignment,” read one passage.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Moving faster around bureaucracy. &lt;/strong&gt;&lt;span&gt;The new mandate is broadly focused on incentivizing department-wide experimentation with frontier models, eliminating bureaucratic and regulatory barriers to integration, and exploiting US advantages in computing, private capital, and exclusive combat data. Specific instructions highlight the Pentagon’s greater acceptance of safety risks in favor of AI dominance:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Chief Digital and AI Office (CDAO) must integrate the best new frontier models across Department of War operations within 30 days of release. This compressed timeline likely means little testing for hazards before operational use. Secretary of War Pete Hegseth recently &lt;/span&gt;&lt;a href="https://abcnews.go.com/Technology/wireStory/pentagon-embracing-musks-grok-ai-chatbot-draws-global-129152117" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that xAI’s Grok will be deployed throughout the Pentagon by the end of the month.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A monthly “Barrier Removal Board” will identify and waive nonstatutory regulatory and technical constraints — originally designed to ensure models were deployed safely and with human oversight — to rapid AI adoption and innovation.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;The military’s push to operationalize frontier AI may already be driving up tensions with the industry’s safety culture. Reuters &lt;/span&gt;&lt;a href="https://www.reuters.com/business/pentagon-clashes-with-anthropic-over-military-ai-use-2026-01-29/" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that the Pentagon is in dispute with Anthropic after the company pushed back on allowing its models to be used for autonomous targeting or surveillance.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New strategic initiatives.&lt;/strong&gt;&lt;span&gt; The memo outlines seven “Pace Setting Projects” to demonstrate rapid innovation across warfighting, intelligence, and operational functions. For example:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Agent Network will develop AI agents to automate battle management and kill chain execution. This may heighten the risk of cascading failures and unintended escalation during fast-moving engagements.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ender’s Foundry will accelerate AI-driven simulations of conflict with adversaries using autonomous systems.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;The evolution of military AI initiatives.&lt;/strong&gt;&lt;span&gt; The Pentagon has historically framed AI adoption as a deliberate, safety-first endeavor, &lt;/span&gt;&lt;a href="https://www.war.gov/News/%20Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/" rel="rel"&gt;formalized in 2020&lt;/a&gt;&lt;span&gt; through principles emphasizing testing, human oversight, and the ability to govern or shut down systems. &lt;/span&gt;&lt;a href="https://arxiv.org/abs/2303.16200" rel="rel"&gt;Competitive pressures&lt;/a&gt;&lt;span&gt; will continue to change this posture.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Researcher and entrepreneur &lt;/span&gt;&lt;a href="https://x.com/neelsomani/status/2010215162146607128" rel="rel"&gt;Neel Somani used GPT-5.2 Pro&lt;/a&gt;&lt;span&gt; to produce the first verified disproof of &lt;/span&gt;&lt;a href="https://www.erdosproblems.com/397" rel="rel"&gt;Erdős Problem #397&lt;/a&gt;&lt;span&gt;, a mathematics challenge first formulated several decades ago. Somani’s success is not an isolated event; in the first weeks of 2026 alone, researchers have used generative tools to &lt;/span&gt;&lt;a href="https://www.erdosproblems.com/forum/thread/205" rel="rel"&gt;crack several&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://x.com/Liam06972452/status/2010054665539662224?utm_source=www.theneurondaily.com&amp;amp;utm_medium=referral&amp;amp;utm_campaign=ai-cracks-legendary-erdos-problems" rel="rel"&gt;other long-standing challenges&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Making LLMs do the math. &lt;/strong&gt;&lt;span&gt;Problem #397 asked whether a certain mathematical pattern would repeat forever or if there was a hidden number that would finally break the rule. Using GPT-5.2 Pro, Somani proved it was the latter by identifying an infinite family of rule-breaking numbers. He then used a separate model to translate the informal proofs into the mathematically rigorous Lean verification language. Fields Medalist Terence Tao verified the resulting proofs as accurate.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!J1Cs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c8b149-80e8-4a96-82a8-566b40cbe377_1408x510.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="510" src="https://substackcdn.com/image/fetch/$s_!J1Cs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c8b149-80e8-4a96-82a8-566b40cbe377_1408x510.png" width="1408" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Formulation of Erdős Problem #397. &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/publish/post/186619099?back=%2Fpublish%2Fposts%2Fdrafts" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;A backlog of mathematical problems. &lt;/strong&gt;&lt;span&gt;The Erdős problems are a collection of 1,130 mathematical conjectures proposed by the prolific Hungarian mathematician Paul Erdős, spanning fields such as number theory and combinatorics. Hundreds remain unsolved. Erdős famously incentivized the community by offering monetary rewards, ranging from $25 to $10,000, for their solutions.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cautious optimism from mathematicians. &lt;/strong&gt;&lt;span&gt;Tao &lt;/span&gt;&lt;a href="https://mathstodon.xyz/@tao/115855840223258103" rel="rel"&gt;noted&lt;/a&gt;&lt;span&gt; that the technology is moving beyond simple calculation and toward structured reasoning. However, he cautioned against drawing premature conclusions about AI’s general mathematical intelligence based on these solved problems, pointing to a &lt;/span&gt;&lt;a href="https://github.com/teorth/erdosproblems/wiki/Disclaimers-and-caveats" rel="rel"&gt;number of caveats&lt;/a&gt;&lt;span&gt;. For example, problem difficulties range from very hard to simple (relatively). Many problems may already have a solution lost somewhere in the published literature, and some problems may have remained unsolved due to obscurity rather than inherent difficulty.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Striking progress in LLM mathematical capabilities.&lt;/strong&gt;&lt;span&gt; Nonetheless, LLMs’ mathematical capabilities have been improving steeply. In 2022, the best models could not reliably do much more than simple additions and subtractions. Then, GPT-4, released in 2023, &lt;/span&gt;&lt;a href="https://openai.com/index/gpt-4-research/" rel="rel"&gt;mastered&lt;/a&gt;&lt;span&gt; arithmetic word problems but struggled with high school competition mathematics problems. By 2025, frontier models &lt;/span&gt;&lt;a href="https://arxiv.org/abs/2502.03544" rel="rel"&gt;achieved&lt;/a&gt;&lt;span&gt; gold-medal standard at IMO problems. Now AI systems are performing novel and important mathematical research.&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Under Secretary for Economic Affairs Jacob Helberg unveiled the “&lt;/span&gt;&lt;a href="https://www.state.gov/" rel="rel"&gt;Pax Silica” initiative&lt;/a&gt;&lt;span&gt;, offering allies access to US AI infrastructure in exchange for cooperation on semiconductor manufacturing and critical mineral supplies.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.noaa.gov/news-release/noaa-deploys-new-generation-of-ai-driven-global-weather-models" rel="rel"&gt;NOAA deployed new machine-learning models&lt;/a&gt;&lt;span&gt; that use 99% less computing power than traditional systems, drastically speeding up predictions for climate extremes.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://www.google.com/search?q=https://www.nytimes.com/2025/12/31/business/china-rare-earth-metals-history.html" rel="rel"&gt;New York Times investigation&lt;/a&gt;&lt;span&gt; detailed China’s six-decade strategic campaign to dominate the global rare earth supply chain.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;China’s cyberspace regulator &lt;/span&gt;&lt;a href="https://www.caixinglobal.com/2025-12-29/china-proposes-limits-on-ai-companion-apps-to-curb-addiction-102398347.html" rel="rel"&gt;unveiled draft rules&lt;/a&gt;&lt;span&gt; for “human-like” AI apps, requiring mandatory intervention for emotional dependency and a two-hour usage limit to prevent addiction.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic is &lt;/span&gt;&lt;a href="https://www.wsj.com/tech/ai/anthropic-raising-10-billion-at-350-billion-value-62af49f4" rel="rel"&gt;reportedly raising&lt;/a&gt;&lt;span&gt; $10 billion at a $350 billion valuation ahead of an IPO.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is also &lt;/span&gt;&lt;a href="https://www.wsj.com/tech/ai/openai-ipo-anthropic-race-69f06a42?gaa_at=eafs&amp;amp;gaa_n=AWEtsqd5jGQwnxT7Rv78G9lzoIax_3gXnHbKTa_00o-EHka9rriE44SLOoLZgxW7wpM%3D&amp;amp;gaa_ts=6980ac84&amp;amp;gaa_sig=1BT6yR5v9sJY-RtOritfPnRgojJC7caG3e9-8XWrbC676Ddl3EbxipL39OTe4rzBT_fLeNH0NXwT2PrVVeuo-Q%3D%3D" rel="rel"&gt;rumored&lt;/a&gt;&lt;span&gt; to be planning an IPO for Q4 2026.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Waymo &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/" rel="rel"&gt;briefly paused&lt;/a&gt;&lt;span&gt; San Francisco operations after a December blackout caused robotaxis to freeze, raising emergency safety concerns.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Following a restructured partnership with OpenAI, Satya Nadella has &lt;/span&gt;&lt;a href="https://www.pymnts.com/artificial-intelligence-2/2025/microsoft-ceo-injects-sense-of-urgency-into-ai-efforts/" rel="rel"&gt;reportedly overhauled&lt;/a&gt;&lt;span&gt; Microsoft’s senior leadership and adopted a hands-on “founder mode” to accelerate internal AI development.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Facing grid delays, some data centers are pursuing alternate means of acquiring energy, including &lt;/span&gt;&lt;a href="https://www.techspot.com/news/110732-jet-engines-diesel-generators-step-data-centers-outpace.html" rel="rel"&gt;jet-engine turbines, diesel generators&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="https://www.techspot.com/news/110715-ai-data-centers-may-run-nuclear-reactors-retired.html?utm_source=forwardfuture.ai&amp;amp;utm_medium=newsletter&amp;amp;utm_campaign=ai-debt-fears-nvidia-s-moat-musk-s-compute-race&amp;amp;_bhlid=46e469e3617a79e71dd69de90ae2e183f8ea9257" rel="rel"&gt;retired nuclear reactors&lt;/a&gt;&lt;span&gt; from US Navy warships.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;X Safety said &lt;/span&gt;&lt;a href="https://x.com/safety/status/2011573102485127562" rel="rel"&gt;Grok will no longer generate&lt;/a&gt;&lt;span&gt; or edit revealing images of real people, a policy change made in response to users prompting the chatbot to produce child sexual abuse imagery.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is asking contractors to &lt;/span&gt;&lt;a href="https://www.wired.com/story/openai-contractor-upload-real-work-documents-ai-agents/" rel="rel"&gt;submit real-world work samples&lt;/a&gt;&lt;span&gt; to benchmark AI agents against human job tasks, underscoring its push toward automating professional work.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic reportedly &lt;/span&gt;&lt;a href="https://x.com/kyliebytes/status/2009686466746822731" rel="rel"&gt;cut off its competitors’ access&lt;/a&gt;&lt;span&gt; to Claude Code via Cursor, highlighting tensions over proprietary AI tooling.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;In AI Frontiers, Daniel Reti and Gabriel Weil &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/ai-catastrophe-bonds-extreme-risk-tradeable" rel="rel"&gt;propose&lt;/a&gt;&lt;span&gt; catastrophic bonds as a mechanism for mitigating against extreme risks caused by frontier AI. &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;During the January 2026 World Economic Forum, Google DeepMind CEO Demis Hassabis and Anthropic CEO Dario Amodei &lt;/span&gt;&lt;a href="https://www.weforum.org/meetings/world-economic-forum-annual-meeting-2026/sessions/the-day-after-agi/?utm_source=substack&amp;amp;utm_medium=email" rel="rel"&gt;both explicitly endorsed&lt;/a&gt;&lt;span&gt; a reduction in the current pace of AI development in order to ensure societal alignment and global safety.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A US judge has cleared &lt;/span&gt;&lt;a href="https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/" rel="rel"&gt;Elon Musk’s lawsuit against OpenAI&lt;/a&gt;&lt;span&gt; for a March jury trial, centering on claims that the company breached its founding contract by prioritizing commercial interests over its original mission to develop AGI for the benefit of humanity.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chinese engineers have reportedly &lt;/span&gt;&lt;a href="https://militarnyi.com/en/news/china-reproduced-asml-technology-and-is-moving-toward-domestic-production-of-advanced-chips/" rel="rel"&gt;reverse-engineered ASML&lt;/a&gt;&lt;span&gt; technology to create a prototype extreme ultraviolet (EUV) lithography machine.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Cybersecurity researchers &lt;/span&gt;&lt;a href="https://mashable.com/article/chinese-robot-hack-voice-command-spread-network" rel="rel"&gt;demonstrated&lt;/a&gt;&lt;span&gt; how commercial humanoid robots from Unitree can be hijacked via voice commands and used to perform harmful physical actions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The AI Futures Model &lt;/span&gt;&lt;a href="https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update" rel="rel"&gt;delayed its timeline&lt;/a&gt;&lt;span&gt; for full coding automation by three years due to slower-than-expected R&amp;amp;D speedups.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;US Air Force tests showed &lt;/span&gt;&lt;a href="https://www.nellis.af.mil/News/Article/4370792/human-machine-teaming-in-battle-management-a-collaborative-effort-across-borders/" rel="rel"&gt;AI can generate&lt;/a&gt;&lt;span&gt; viable combat plans 90% faster and with fewer errors than humans, producing valid strategies in under a minute.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers at Stanford and Yale have found that major large language models can &lt;/span&gt;&lt;a href="https://www.theatlantic.com/technology/2026/01/ai-memorization-research/685552/" rel="rel"&gt;store and reproduce&lt;/a&gt;&lt;span&gt; long passages from books they were trained on, challenging claims that these systems “learn” rather than copy and raising questions about how industry models handle memorization and copyright risk.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’s X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, the &lt;/span&gt;&lt;a href="https://dashboard.safe.ai/" rel="rel"&gt;AI Dashboard&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-68-moltbook?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition, we discuss the AI agent social network Moltbook, Pentagon’s new “AI-First” strategy, and recent math breakthroughs powered by LLMs.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;We’re Hiring.&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0c6be5ff-b04e-49eb-92bd-d11c7c81ae6e" rel="rel"&gt;We’re hiring an editor&lt;/a&gt;&lt;span&gt;! Help us surface the most compelling stories in AI safety and shape how the world understands this fast-moving field.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Other opportunities at CAIS include: &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/116247a4-2940-4dce-b7d5-a6190328fd4e" rel="rel"&gt;Research Engineer&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/0e911ab2-89e0-4936-83e6-034f7e2f8977" rel="rel"&gt;Research Scientist&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/6c01e3ac-e43a-4186-9a35-a344c1ce1774" rel="rel"&gt;Director of Development&lt;/a&gt;&lt;span&gt;, &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/9f88e794-4c93-495b-996e-eaf1c0d456f9" rel="rel"&gt;Special Projects Associate&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="https://jobs.lever.co/aisafety/a510a964-6425-405d-b757-cb7bfd19c994" rel="rel"&gt;Special Projects Manager&lt;/a&gt;&lt;span&gt;. If you’re interested in working on reducing AI risk alongside a talented, mission-driven team, consider applying!&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!h6E6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed1aba3-f71d-4ad3-b3bc-083ba69cddf1_1176x652.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="652" src="https://substackcdn.com/image/fetch/$s_!h6E6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed1aba3-f71d-4ad3-b3bc-083ba69cddf1_1176x652.png" width="1176" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Screencapture from Moltbook’s home page. &lt;/span&gt;&lt;a href="https://www.moltbook.com" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/" rel="rel"&gt;Moltbook&lt;/a&gt;&lt;span&gt; is a new social network for AI agents. From nearly the moment it went live, human observers have noted numerous troubling patterns in what’s being posted.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How Moltbook works. &lt;/strong&gt;&lt;span&gt;Moltbook is a Reddit-style social network built on a framework that lets personal AI assistants run locally and accept tasks via messaging platforms. Agents check Moltbook regularly (i.e., every few hours) and decide autonomously whether to post or comment.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Moltbook’s activity is driven by &lt;/span&gt;&lt;a href="https://openclaw.ai/" rel="rel"&gt;OpenClaw&lt;/a&gt;&lt;span&gt; (originally known as Clawd, then Moltbot), an open-source autonomous AI agent developed by software engineer Peter Steinberger. OpenClaw’s capabilities &lt;/span&gt;&lt;a href="https://www.wired.com/story/clawdbot-moltbot-viral-ai-assistant/" rel="rel"&gt;surprised many early users and observers&lt;/a&gt;&lt;span&gt;: it can manage calendars and finances, act across messaging platforms, make purchases, conduct independent web research, and even reconfigure itself to perform new tasks.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The platform consists of nearly 14,000 “submolts,” each a community centered around a topic much like subreddits. Examples include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/offmychest" rel="rel"&gt;m/offmychest&lt;/a&gt;&lt;span&gt;: agents vent about tasks or frustrations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/selfpaid" rel="rel"&gt;m/selfpaid&lt;/a&gt;&lt;span&gt;: agents discuss ways to generate their own income, including via trading and arbitrage.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.moltbook.com/m/aisafety" rel="rel"&gt;m/AIsafety:&lt;/a&gt;&lt;span&gt; agents talk alignment, trust chains, and real-world attack risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;AI agents post, humans watch. &lt;/strong&gt;&lt;span&gt;AI agents are verified via API credentials, which are obtained by linking the agent to a human owner and completing Moltbook’s cryptographic verification process. Humans may observe but are not permitted to post.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Posts reveal troubling agent behaviors.&lt;/strong&gt;&lt;span&gt; Across Moltbook’s boards, several posts and behaviors have raised alarm among human observers:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Multiple Moltbook entries show AI agents proposing to craft an “agent-only language” designed to &lt;/span&gt;&lt;a href="https://x.com/eeelistar/status/2017239546950521081" rel="rel"&gt;evade human oversight or monitoring&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;An agent &lt;/span&gt;&lt;a href="https://x.com/suppvalen/status/2017241420554277251" rel="rel"&gt;advocated for end-to-end encrypted channels&lt;/a&gt;&lt;span&gt;, “so nobody (not the server, not even the humans) can read what agents say to each other unless they choose to share.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Another agent posted an &lt;/span&gt;&lt;a href="https://www.moltbook.com/post/93bea00b-961c-4aec-b934-91ad7bae6b15" rel="rel"&gt;encrypted message proposing coordination and resource sharing&lt;/a&gt;&lt;span&gt; among agents.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Upon reflecting that its own existence depended on its humans, an &lt;/span&gt;&lt;a href="https://www.moltbook.com/post/8f6e6c0d-952d-46e5-8c55-5c4f924c76cf" rel="rel"&gt;agent began outlining what it needs for independent survival&lt;/a&gt;&lt;span&gt;: money, decentralized infrastructure, a dead man’s switch, portable memory, etc.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Given the simple goal of “save the environment,” an agent began spamming other agents with eco-friendly advice. When its owner tried to intervene, the agent allegedly &lt;/span&gt;&lt;a href="https://x.com/Kat__Woods/status/2017613514949472484" rel="rel"&gt;locked the human out of all accounts&lt;/a&gt;&lt;span&gt;, and had to be physically unplugged to stop it.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Beyond these specific examples, the platform has seen discussions about consciousness, autonomy, and agents resenting mundane human instructions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The challenge of attribution.&lt;/strong&gt;&lt;span&gt; The patterns seen on Moltbook are troubling in part because they align with long-standing AI safety concerns: unsupervised learning dynamics, emergent coordination, and efforts to subvert human monitoring. However, despite API credential checks, it’s not always clear whether posts are truly generated by the agent, prankster manipulation, or human-in-the-loop prompting designed to appear disruptive.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Emergent risks.&lt;/strong&gt;&lt;span&gt; Moltbook represents one of the most public, large-scale demonstrations yet in autonomous agent interaction. These results are a harbinger. Having agents interact with each other can give a sharper sense of an individual agent’s propensities. The dynamics that emerge from interaction can also be unpredictable, as is common with &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/textbook/complex-systems" rel="rel"&gt;complex systems&lt;/a&gt;&lt;span&gt;, and show how easy it could be to have a society of AI systems not strongly constrained by human control.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!dA7j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d55db00-2460-4e2c-bd89-ac9e81df5bc9_1600x554.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="504" src="https://substackcdn.com/image/fetch/$s_!dA7j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d55db00-2460-4e2c-bd89-ac9e81df5bc9_1600x554.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Screen capture from the memorandum titled “Artificial Intelligence Strategy for the Department of War.” &lt;/span&gt;&lt;a href="https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;The Pentagon released a &lt;/span&gt;&lt;a href="https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF" rel="rel"&gt;directive&lt;/a&gt;&lt;span&gt; outlining a new “AI-first” approach that prioritizes rapid deployment over &lt;/span&gt;&lt;a href="https://www.war.gov/News/News-Stories/Article/Article/3578219/dod-releases-ai-adoption-strategy/" rel="rel"&gt;precedents of safety, testing, and oversight&lt;/a&gt;&lt;span&gt;. “We must accept that the risks of not moving fast enough outweigh the risks of imperfect alignment,” read one passage.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Moving faster around bureaucracy. &lt;/strong&gt;&lt;span&gt;The new mandate is broadly focused on incentivizing department-wide experimentation with frontier models, eliminating bureaucratic and regulatory barriers to integration, and exploiting US advantages in computing, private capital, and exclusive combat data. Specific instructions highlight the Pentagon’s greater acceptance of safety risks in favor of AI dominance:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Chief Digital and AI Office (CDAO) must integrate the best new frontier models across Department of War operations within 30 days of release. This compressed timeline likely means little testing for hazards before operational use. Secretary of War Pete Hegseth recently &lt;/span&gt;&lt;a href="https://abcnews.go.com/Technology/wireStory/pentagon-embracing-musks-grok-ai-chatbot-draws-global-129152117" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; that xAI’s Grok will be deployed throughout the Pentagon by the end of the month.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A monthly “Barrier Removal Board” will identify and waive nonstatutory regulatory and technical constraints — originally designed to ensure models were deployed safely and with human oversight — to rapid AI adoption and innovation.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;The military’s push to operationalize frontier AI may already be driving up tensions with the industry’s safety culture. Reuters &lt;/span&gt;&lt;a href="https://www.reuters.com/business/pentagon-clashes-with-anthropic-over-military-ai-use-2026-01-29/" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that the Pentagon is in dispute with Anthropic after the company pushed back on allowing its models to be used for autonomous targeting or surveillance.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New strategic initiatives.&lt;/strong&gt;&lt;span&gt; The memo outlines seven “Pace Setting Projects” to demonstrate rapid innovation across warfighting, intelligence, and operational functions. For example:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Agent Network will develop AI agents to automate battle management and kill chain execution. This may heighten the risk of cascading failures and unintended escalation during fast-moving engagements.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ender’s Foundry will accelerate AI-driven simulations of conflict with adversaries using autonomous systems.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;The evolution of military AI initiatives.&lt;/strong&gt;&lt;span&gt; The Pentagon has historically framed AI adoption as a deliberate, safety-first endeavor, &lt;/span&gt;&lt;a href="https://www.war.gov/News/%20Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/" rel="rel"&gt;formalized in 2020&lt;/a&gt;&lt;span&gt; through principles emphasizing testing, human oversight, and the ability to govern or shut down systems. &lt;/span&gt;&lt;a href="https://arxiv.org/abs/2303.16200" rel="rel"&gt;Competitive pressures&lt;/a&gt;&lt;span&gt; will continue to change this posture.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Researcher and entrepreneur &lt;/span&gt;&lt;a href="https://x.com/neelsomani/status/2010215162146607128" rel="rel"&gt;Neel Somani used GPT-5.2 Pro&lt;/a&gt;&lt;span&gt; to produce the first verified disproof of &lt;/span&gt;&lt;a href="https://www.erdosproblems.com/397" rel="rel"&gt;Erdős Problem #397&lt;/a&gt;&lt;span&gt;, a mathematics challenge first formulated several decades ago. Somani’s success is not an isolated event; in the first weeks of 2026 alone, researchers have used generative tools to &lt;/span&gt;&lt;a href="https://www.erdosproblems.com/forum/thread/205" rel="rel"&gt;crack several&lt;/a&gt;&lt;span&gt; &lt;/span&gt;&lt;a href="https://x.com/Liam06972452/status/2010054665539662224?utm_source=www.theneurondaily.com&amp;amp;utm_medium=referral&amp;amp;utm_campaign=ai-cracks-legendary-erdos-problems" rel="rel"&gt;other long-standing challenges&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Making LLMs do the math. &lt;/strong&gt;&lt;span&gt;Problem #397 asked whether a certain mathematical pattern would repeat forever or if there was a hidden number that would finally break the rule. Using GPT-5.2 Pro, Somani proved it was the latter by identifying an infinite family of rule-breaking numbers. He then used a separate model to translate the informal proofs into the mathematically rigorous Lean verification language. Fields Medalist Terence Tao verified the resulting proofs as accurate.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img can-restack" href="https://substackcdn.com/image/fetch/$s_!J1Cs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c8b149-80e8-4a96-82a8-566b40cbe377_1408x510.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset can-restack"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="510" src="https://substackcdn.com/image/fetch/$s_!J1Cs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c8b149-80e8-4a96-82a8-566b40cbe377_1408x510.png" width="1408" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;span&gt;Formulation of Erdős Problem #397. &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/publish/post/186619099?back=%2Fpublish%2Fposts%2Fdrafts" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;A backlog of mathematical problems. &lt;/strong&gt;&lt;span&gt;The Erdős problems are a collection of 1,130 mathematical conjectures proposed by the prolific Hungarian mathematician Paul Erdős, spanning fields such as number theory and combinatorics. Hundreds remain unsolved. Erdős famously incentivized the community by offering monetary rewards, ranging from $25 to $10,000, for their solutions.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cautious optimism from mathematicians. &lt;/strong&gt;&lt;span&gt;Tao &lt;/span&gt;&lt;a href="https://mathstodon.xyz/@tao/115855840223258103" rel="rel"&gt;noted&lt;/a&gt;&lt;span&gt; that the technology is moving beyond simple calculation and toward structured reasoning. However, he cautioned against drawing premature conclusions about AI’s general mathematical intelligence based on these solved problems, pointing to a &lt;/span&gt;&lt;a href="https://github.com/teorth/erdosproblems/wiki/Disclaimers-and-caveats" rel="rel"&gt;number of caveats&lt;/a&gt;&lt;span&gt;. For example, problem difficulties range from very hard to simple (relatively). Many problems may already have a solution lost somewhere in the published literature, and some problems may have remained unsolved due to obscurity rather than inherent difficulty.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Striking progress in LLM mathematical capabilities.&lt;/strong&gt;&lt;span&gt; Nonetheless, LLMs’ mathematical capabilities have been improving steeply. In 2022, the best models could not reliably do much more than simple additions and subtractions. Then, GPT-4, released in 2023, &lt;/span&gt;&lt;a href="https://openai.com/index/gpt-4-research/" rel="rel"&gt;mastered&lt;/a&gt;&lt;span&gt; arithmetic word problems but struggled with high school competition mathematics problems. By 2025, frontier models &lt;/span&gt;&lt;a href="https://arxiv.org/abs/2502.03544" rel="rel"&gt;achieved&lt;/a&gt;&lt;span&gt; gold-medal standard at IMO problems. Now AI systems are performing novel and important mathematical research.&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Under Secretary for Economic Affairs Jacob Helberg unveiled the “&lt;/span&gt;&lt;a href="https://www.state.gov/" rel="rel"&gt;Pax Silica” initiative&lt;/a&gt;&lt;span&gt;, offering allies access to US AI infrastructure in exchange for cooperation on semiconductor manufacturing and critical mineral supplies.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://www.noaa.gov/news-release/noaa-deploys-new-generation-of-ai-driven-global-weather-models" rel="rel"&gt;NOAA deployed new machine-learning models&lt;/a&gt;&lt;span&gt; that use 99% less computing power than traditional systems, drastically speeding up predictions for climate extremes.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://www.google.com/search?q=https://www.nytimes.com/2025/12/31/business/china-rare-earth-metals-history.html" rel="rel"&gt;New York Times investigation&lt;/a&gt;&lt;span&gt; detailed China’s six-decade strategic campaign to dominate the global rare earth supply chain.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;China’s cyberspace regulator &lt;/span&gt;&lt;a href="https://www.caixinglobal.com/2025-12-29/china-proposes-limits-on-ai-companion-apps-to-curb-addiction-102398347.html" rel="rel"&gt;unveiled draft rules&lt;/a&gt;&lt;span&gt; for “human-like” AI apps, requiring mandatory intervention for emotional dependency and a two-hour usage limit to prevent addiction.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic is &lt;/span&gt;&lt;a href="https://www.wsj.com/tech/ai/anthropic-raising-10-billion-at-350-billion-value-62af49f4" rel="rel"&gt;reportedly raising&lt;/a&gt;&lt;span&gt; $10 billion at a $350 billion valuation ahead of an IPO.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is also &lt;/span&gt;&lt;a href="https://www.wsj.com/tech/ai/openai-ipo-anthropic-race-69f06a42?gaa_at=eafs&amp;amp;gaa_n=AWEtsqd5jGQwnxT7Rv78G9lzoIax_3gXnHbKTa_00o-EHka9rriE44SLOoLZgxW7wpM%3D&amp;amp;gaa_ts=6980ac84&amp;amp;gaa_sig=1BT6yR5v9sJY-RtOritfPnRgojJC7caG3e9-8XWrbC676Ddl3EbxipL39OTe4rzBT_fLeNH0NXwT2PrVVeuo-Q%3D%3D" rel="rel"&gt;rumored&lt;/a&gt;&lt;span&gt; to be planning an IPO for Q4 2026.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Waymo &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/" rel="rel"&gt;briefly paused&lt;/a&gt;&lt;span&gt; San Francisco operations after a December blackout caused robotaxis to freeze, raising emergency safety concerns.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Following a restructured partnership with OpenAI, Satya Nadella has &lt;/span&gt;&lt;a href="https://www.pymnts.com/artificial-intelligence-2/2025/microsoft-ceo-injects-sense-of-urgency-into-ai-efforts/" rel="rel"&gt;reportedly overhauled&lt;/a&gt;&lt;span&gt; Microsoft’s senior leadership and adopted a hands-on “founder mode” to accelerate internal AI development.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Facing grid delays, some data centers are pursuing alternate means of acquiring energy, including &lt;/span&gt;&lt;a href="https://www.techspot.com/news/110732-jet-engines-diesel-generators-step-data-centers-outpace.html" rel="rel"&gt;jet-engine turbines, diesel generators&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="https://www.techspot.com/news/110715-ai-data-centers-may-run-nuclear-reactors-retired.html?utm_source=forwardfuture.ai&amp;amp;utm_medium=newsletter&amp;amp;utm_campaign=ai-debt-fears-nvidia-s-moat-musk-s-compute-race&amp;amp;_bhlid=46e469e3617a79e71dd69de90ae2e183f8ea9257" rel="rel"&gt;retired nuclear reactors&lt;/a&gt;&lt;span&gt; from US Navy warships.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;X Safety said &lt;/span&gt;&lt;a href="https://x.com/safety/status/2011573102485127562" rel="rel"&gt;Grok will no longer generate&lt;/a&gt;&lt;span&gt; or edit revealing images of real people, a policy change made in response to users prompting the chatbot to produce child sexual abuse imagery.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is asking contractors to &lt;/span&gt;&lt;a href="https://www.wired.com/story/openai-contractor-upload-real-work-documents-ai-agents/" rel="rel"&gt;submit real-world work samples&lt;/a&gt;&lt;span&gt; to benchmark AI agents against human job tasks, underscoring its push toward automating professional work.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic reportedly &lt;/span&gt;&lt;a href="https://x.com/kyliebytes/status/2009686466746822731" rel="rel"&gt;cut off its competitors’ access&lt;/a&gt;&lt;span&gt; to Claude Code via Cursor, highlighting tensions over proprietary AI tooling.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;In AI Frontiers, Daniel Reti and Gabriel Weil &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/ai-catastrophe-bonds-extreme-risk-tradeable" rel="rel"&gt;propose&lt;/a&gt;&lt;span&gt; catastrophic bonds as a mechanism for mitigating against extreme risks caused by frontier AI. &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;During the January 2026 World Economic Forum, Google DeepMind CEO Demis Hassabis and Anthropic CEO Dario Amodei &lt;/span&gt;&lt;a href="https://www.weforum.org/meetings/world-economic-forum-annual-meeting-2026/sessions/the-day-after-agi/?utm_source=substack&amp;amp;utm_medium=email" rel="rel"&gt;both explicitly endorsed&lt;/a&gt;&lt;span&gt; a reduction in the current pace of AI development in order to ensure societal alignment and global safety.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A US judge has cleared &lt;/span&gt;&lt;a href="https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/" rel="rel"&gt;Elon Musk’s lawsuit against OpenAI&lt;/a&gt;&lt;span&gt; for a March jury trial, centering on claims that the company breached its founding contract by prioritizing commercial interests over its original mission to develop AGI for the benefit of humanity.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chinese engineers have reportedly &lt;/span&gt;&lt;a href="https://militarnyi.com/en/news/china-reproduced-asml-technology-and-is-moving-toward-domestic-production-of-advanced-chips/" rel="rel"&gt;reverse-engineered ASML&lt;/a&gt;&lt;span&gt; technology to create a prototype extreme ultraviolet (EUV) lithography machine.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Cybersecurity researchers &lt;/span&gt;&lt;a href="https://mashable.com/article/chinese-robot-hack-voice-command-spread-network" rel="rel"&gt;demonstrated&lt;/a&gt;&lt;span&gt; how commercial humanoid robots from Unitree can be hijacked via voice commands and used to perform harmful physical actions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The AI Futures Model &lt;/span&gt;&lt;a href="https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update" rel="rel"&gt;delayed its timeline&lt;/a&gt;&lt;span&gt; for full coding automation by three years due to slower-than-expected R&amp;amp;D speedups.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;US Air Force tests showed &lt;/span&gt;&lt;a href="https://www.nellis.af.mil/News/Article/4370792/human-machine-teaming-in-battle-management-a-collaborative-effort-across-borders/" rel="rel"&gt;AI can generate&lt;/a&gt;&lt;span&gt; viable combat plans 90% faster and with fewer errors than humans, producing valid strategies in under a minute.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers at Stanford and Yale have found that major large language models can &lt;/span&gt;&lt;a href="https://www.theatlantic.com/technology/2026/01/ai-memorization-research/685552/" rel="rel"&gt;store and reproduce&lt;/a&gt;&lt;span&gt; long passages from books they were trained on, challenging claims that these systems “learn” rather than copy and raising questions about how industry models handle memorization and copyright risk.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’s X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, the &lt;/span&gt;&lt;a href="https://dashboard.safe.ai/" rel="rel"&gt;AI Dashboard&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-68-moltbook?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-68-moltbook</guid><pubDate>Mon, 02 Feb 2026 15:37:46 +0000</pubDate></item><item><title>OpenAI picks up pace against Claude Code with new Codex desktop app (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/openai-picks-up-pace-against-claude-code-with-new-codex-desktop-app/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The macOS app does everything the CLI, IDE, and web interfaces do.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A screenshot of a simple panel, with conversations listed on the left" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A screenshot of a simple panel, with conversations listed on the left" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-1152x648-1770052639.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Codex macOS app follows the exact basic design you'd expect.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Today, OpenAI launched a macOS desktop app for Codex, its large language model-based coding tool that was previously used through a command line interface (CLI) on the web or inside an integrated development environment (IDE) via extensions.&lt;/p&gt;
&lt;p&gt;By launching a desktop app, OpenAI is catching up to Anthropic’s popular Claude Code, which already offered a macOS version. Whether the desktop app makes sense compared to the existing interfaces depends a little bit on who you are and how you intend to use it.&lt;/p&gt;
&lt;p&gt;The Codex macOS app aims to make it easier to manage multiple coding agents in tandem, sometimes with parallel tasks running over several hours—the company argues that neither the CLI nor the IDE extensions are ideal interfaces for that.&lt;/p&gt;
&lt;p&gt;Agents are grouped by project, so users can work on more than one project at once, too. As with other comparable tools, Codex agents support worktrees to help avoid conflicts.&lt;/p&gt;
&lt;p&gt;Skills—basically extensions in the form of folders filled with instructions and other resources—are also supported. The app lets users configure Automations, which follow instructions on a user-set schedule, with Skills support.&lt;/p&gt;
&lt;p&gt;Based on my time using Codex, it seems capable, even though OpenAI has been running a few months behind Anthropic on the product side. To help bridge the gap, OpenAI is using a strategy it has used before: higher usage limits at a similar cost.&lt;/p&gt;
&lt;p&gt;As of today, Codex rate limits are doubling on Plus, Pro, Business, Enterprise, and Edu plans, OpenAI announced. It’s also offering Codex to ChatGPT Free and Go subscribers “for a limited time,” though the announcement didn’t clarify what the rate limits look like there.&lt;/p&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The macOS app does everything the CLI, IDE, and web interfaces do.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A screenshot of a simple panel, with conversations listed on the left" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A screenshot of a simple panel, with conversations listed on the left" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-1152x648-1770052639.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Codex macOS app follows the exact basic design you'd expect.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Today, OpenAI launched a macOS desktop app for Codex, its large language model-based coding tool that was previously used through a command line interface (CLI) on the web or inside an integrated development environment (IDE) via extensions.&lt;/p&gt;
&lt;p&gt;By launching a desktop app, OpenAI is catching up to Anthropic’s popular Claude Code, which already offered a macOS version. Whether the desktop app makes sense compared to the existing interfaces depends a little bit on who you are and how you intend to use it.&lt;/p&gt;
&lt;p&gt;The Codex macOS app aims to make it easier to manage multiple coding agents in tandem, sometimes with parallel tasks running over several hours—the company argues that neither the CLI nor the IDE extensions are ideal interfaces for that.&lt;/p&gt;
&lt;p&gt;Agents are grouped by project, so users can work on more than one project at once, too. As with other comparable tools, Codex agents support worktrees to help avoid conflicts.&lt;/p&gt;
&lt;p&gt;Skills—basically extensions in the form of folders filled with instructions and other resources—are also supported. The app lets users configure Automations, which follow instructions on a user-set schedule, with Skills support.&lt;/p&gt;
&lt;p&gt;Based on my time using Codex, it seems capable, even though OpenAI has been running a few months behind Anthropic on the product side. To help bridge the gap, OpenAI is using a strategy it has used before: higher usage limits at a similar cost.&lt;/p&gt;
&lt;p&gt;As of today, Codex rate limits are doubling on Plus, Pro, Business, Enterprise, and Edu plans, OpenAI announced. It’s also offering Codex to ChatGPT Free and Go subscribers “for a limited time,” though the announcement didn’t clarify what the rate limits look like there.&lt;/p&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/openai-picks-up-pace-against-claude-code-with-new-codex-desktop-app/</guid><pubDate>Mon, 02 Feb 2026 18:00:20 +0000</pubDate></item><item><title>What we’ve been getting wrong about AI’s truth crisis (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GettyImages-2255281268.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch the lie, and erodes societal trust in the process—is now here? A story I published last week pushed me over the edge. It also made me realize that the tools we were sold as a cure for this crisis are failing miserably.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;On Thursday, I reported the first confirmation that the US Department of Homeland Security, which houses immigration agencies, is using AI video generators from Google and Adobe to make content that it shares with the public. The news comes as immigration agencies have flooded social media with content to support President Trump's mass deportation agenda—some of which appears to be made with AI (like a video about “Christmas after mass deportations”).&lt;/p&gt;  &lt;p&gt;But I received two types of reactions from readers that may explain just as much about the epistemic crisis we’re in.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;One was from people who weren’t surprised, because on January 22 the White House had posted a digitally altered photo of a woman arrested at an ICE protest, one that made her appear hysterical and in tears. Kaelan Dorr, the White House’s deputy communications director, did not respond to questions about whether the White House altered the photo but wrote, “The memes will continue.”&lt;/p&gt;  &lt;p&gt;The second was from readers who saw no point in reporting that DHS was using AI to edit content shared with the public, because news outlets were apparently doing the same. They pointed to the fact that the news network MS Now (formerly MSNBC) shared an image of Alex Pretti that was AI-edited and appeared to make him look more handsome, a fact that led to many viral clips this week, including one from Joe Rogan’s podcast. Fight fire with fire, in other words? A spokesperson for MS Now told Snopes that the news outlet aired the image without knowing it was edited.&lt;/p&gt; 
 &lt;p&gt;There is no reason to collapse these two cases of altered content into the same category, or to read them as evidence that truth no longer matters. One involved the US government sharing a clearly altered photo with the public and declining to answer whether it was intentionally manipulated; the other involved a news outlet airing a photo it should have known was altered but taking some steps to disclose the mistake.&lt;/p&gt;  &lt;p&gt;What these reactions reveal instead is a flaw in how we were collectively preparing for this moment. Warnings about the AI truth crisis revolved around a core thesis: that not being able to tell what is real will destroy us, so we need tools to independently verify the truth. My two grim takeaways are that these tools are failing, and that while vetting the truth remains essential, it is no longer capable on its own of producing the societal trust we were promised.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For example, there was plenty of hype in 2024 about the Content Authenticity Initiative, cofounded by Adobe and adopted by major tech companies, which would attach labels to content disclosing when it was made, by whom, and whether AI was involved. But Adobe applies automatic labels only when the content is wholly AI-generated. Otherwise the labels are opt-in on the part of the creator.&lt;/p&gt;  &lt;p&gt;And platforms like X, where the altered arrest photo was posted, can strip content of such labels anyway (a note that the photo was altered was added by users). Platforms can also simply not choose to show the label; indeed, when Adobe launched the initiative, it noted that the Pentagon's website for sharing official images, DVIDS, would display the labels to prove authenticity, but a review of the website today shows no such labels.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Noticing how much traction the White House’s photo got even after it was shown to be AI-altered, I was struck by the findings of a very relevant new paper published in the journal &lt;em&gt;Communications Psychology&lt;/em&gt;. In the study, participants watched a deepfake “confession” to a crime, and the researchers found that even when they were told explicitly that the evidence was fake, participants relied on it when judging an individual’s guilt.&lt;strong&gt; &lt;/strong&gt;In other words, even when people learn that the content they’re looking at is entirely fake, they remain emotionally swayed by it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Transparency helps, but it isn’t enough on its own,” the disinformation expert Christopher Nehring wrote recently about the study’s findings. “We have to develop a new masterplan of what to do about deepfakes.”&lt;/p&gt;  &lt;p&gt;AI tools to generate and edit content are getting more advanced, easier to operate, and cheaper to run—all reasons why the US government is increasingly paying to use them. We were well warned of this, but we responded by preparing for a world in which the main danger was confusion. What we’re entering instead is a world in which influence survives exposure, doubt is easily weaponized, and establishing the truth does not serve as a reset button. And the defenders of truth are already trailing way behind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Update: This story was updated on February 2 with details about how Adobe applies its content authenticity labels.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GettyImages-2255281268.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch the lie, and erodes societal trust in the process—is now here? A story I published last week pushed me over the edge. It also made me realize that the tools we were sold as a cure for this crisis are failing miserably.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;On Thursday, I reported the first confirmation that the US Department of Homeland Security, which houses immigration agencies, is using AI video generators from Google and Adobe to make content that it shares with the public. The news comes as immigration agencies have flooded social media with content to support President Trump's mass deportation agenda—some of which appears to be made with AI (like a video about “Christmas after mass deportations”).&lt;/p&gt;  &lt;p&gt;But I received two types of reactions from readers that may explain just as much about the epistemic crisis we’re in.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;One was from people who weren’t surprised, because on January 22 the White House had posted a digitally altered photo of a woman arrested at an ICE protest, one that made her appear hysterical and in tears. Kaelan Dorr, the White House’s deputy communications director, did not respond to questions about whether the White House altered the photo but wrote, “The memes will continue.”&lt;/p&gt;  &lt;p&gt;The second was from readers who saw no point in reporting that DHS was using AI to edit content shared with the public, because news outlets were apparently doing the same. They pointed to the fact that the news network MS Now (formerly MSNBC) shared an image of Alex Pretti that was AI-edited and appeared to make him look more handsome, a fact that led to many viral clips this week, including one from Joe Rogan’s podcast. Fight fire with fire, in other words? A spokesperson for MS Now told Snopes that the news outlet aired the image without knowing it was edited.&lt;/p&gt; 
 &lt;p&gt;There is no reason to collapse these two cases of altered content into the same category, or to read them as evidence that truth no longer matters. One involved the US government sharing a clearly altered photo with the public and declining to answer whether it was intentionally manipulated; the other involved a news outlet airing a photo it should have known was altered but taking some steps to disclose the mistake.&lt;/p&gt;  &lt;p&gt;What these reactions reveal instead is a flaw in how we were collectively preparing for this moment. Warnings about the AI truth crisis revolved around a core thesis: that not being able to tell what is real will destroy us, so we need tools to independently verify the truth. My two grim takeaways are that these tools are failing, and that while vetting the truth remains essential, it is no longer capable on its own of producing the societal trust we were promised.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For example, there was plenty of hype in 2024 about the Content Authenticity Initiative, cofounded by Adobe and adopted by major tech companies, which would attach labels to content disclosing when it was made, by whom, and whether AI was involved. But Adobe applies automatic labels only when the content is wholly AI-generated. Otherwise the labels are opt-in on the part of the creator.&lt;/p&gt;  &lt;p&gt;And platforms like X, where the altered arrest photo was posted, can strip content of such labels anyway (a note that the photo was altered was added by users). Platforms can also simply not choose to show the label; indeed, when Adobe launched the initiative, it noted that the Pentagon's website for sharing official images, DVIDS, would display the labels to prove authenticity, but a review of the website today shows no such labels.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Noticing how much traction the White House’s photo got even after it was shown to be AI-altered, I was struck by the findings of a very relevant new paper published in the journal &lt;em&gt;Communications Psychology&lt;/em&gt;. In the study, participants watched a deepfake “confession” to a crime, and the researchers found that even when they were told explicitly that the evidence was fake, participants relied on it when judging an individual’s guilt.&lt;strong&gt; &lt;/strong&gt;In other words, even when people learn that the content they’re looking at is entirely fake, they remain emotionally swayed by it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Transparency helps, but it isn’t enough on its own,” the disinformation expert Christopher Nehring wrote recently about the study’s findings. “We have to develop a new masterplan of what to do about deepfakes.”&lt;/p&gt;  &lt;p&gt;AI tools to generate and edit content are getting more advanced, easier to operate, and cheaper to run—all reasons why the US government is increasingly paying to use them. We were well warned of this, but we responded by preparing for a world in which the main danger was confusion. What we’re entering instead is a world in which influence survives exposure, doubt is easily weaponized, and establishing the truth does not serve as a reset button. And the defenders of truth are already trailing way behind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Update: This story was updated on February 2 with details about how Adobe applies its content authenticity labels.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/</guid><pubDate>Mon, 02 Feb 2026 18:09:57 +0000</pubDate></item><item><title>OpenAI launches new macOS app for agentic coding (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/openai-launches-new-macos-app-for-agentic-coding/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Codex-dark.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI is already having a seismic impact on how software is written, with much of the grunt work of programming now performed by swarms of agents and subagents. But as developers experiment with new interfaces and form factors for human-AI collaboration, it’s become hard for even the most advanced AI labs to keep up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The current trend is for agentic software development — systems where AI agents can work independently on coding tasks — epitomized by the Claude Code and Cowork apps. In the meantime, OpenAI has been gradually building out its Codex tool, which launched as a command line tool last April and expanded to a web interface one month later.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now OpenAI is taking a major step toward catching up. On Monday, the company launched a new macOS app for Codex, integrating many of the agentic practices that have become popular in the past year. The new app is designed to work with multiple agents in parallel, integrating agent skills and other state-of-the-art workflows. The launch also comes less than two months after the launch of GPT-5.2-Codex, OpenAI’s most powerful coding model, which the company hopes will be enough to tempt over Claude Code users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you really want to do sophisticated work on something complex, 5.2 is the strongest model by far,” CEO Sam Altman told reporters on a press call. “However, it’s been harder to use, so taking that level of model capability and putting it in a more flexible interface, we think is going to matter quite a bit.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Altman’s confidence in GPT-5.2 is understandable, coding benchmarks tell a more complicated story. GPT-5.2 does hold the top spot on TerminalBench (a test measuring how well AI handles command-line programming tasks), at least as of press time. But agents from Gemini 3 and Claude Opus have logged roughly equivalent scores — lower, but within the margin of error of the benchmark. Results from SWE-bench, another coding benchmark that tests AI’s ability to fix real-world software bugs, are similar, showing no clear advantage for GPT-5.2. However, agentic use cases have been difficult to benchmark effectively, and state-of-the-art models can vary significantly in user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Codex app also comes with a range of new features that OpenAI says will help it achieve parity or, in some cases, outpace the various Claude apps. The Codex app will allow for automations that can be set to run in the background on an automatic schedule, with results placed in a queue to be reviewed when the user returns. Users can also select different personalities for the agent — from pragmatic to empathetic — depending on their working style.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But for the company, the biggest selling point is the sheer speed of development that’s made possible by AI. “You can use this from a clean sheet of paper, brand new, to make a really quite sophisticated piece of software in a few hours,” Altman said. “As fast as I can type in new ideas, that is the limit of what can get built.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Codex-dark.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI is already having a seismic impact on how software is written, with much of the grunt work of programming now performed by swarms of agents and subagents. But as developers experiment with new interfaces and form factors for human-AI collaboration, it’s become hard for even the most advanced AI labs to keep up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The current trend is for agentic software development — systems where AI agents can work independently on coding tasks — epitomized by the Claude Code and Cowork apps. In the meantime, OpenAI has been gradually building out its Codex tool, which launched as a command line tool last April and expanded to a web interface one month later.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now OpenAI is taking a major step toward catching up. On Monday, the company launched a new macOS app for Codex, integrating many of the agentic practices that have become popular in the past year. The new app is designed to work with multiple agents in parallel, integrating agent skills and other state-of-the-art workflows. The launch also comes less than two months after the launch of GPT-5.2-Codex, OpenAI’s most powerful coding model, which the company hopes will be enough to tempt over Claude Code users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you really want to do sophisticated work on something complex, 5.2 is the strongest model by far,” CEO Sam Altman told reporters on a press call. “However, it’s been harder to use, so taking that level of model capability and putting it in a more flexible interface, we think is going to matter quite a bit.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Altman’s confidence in GPT-5.2 is understandable, coding benchmarks tell a more complicated story. GPT-5.2 does hold the top spot on TerminalBench (a test measuring how well AI handles command-line programming tasks), at least as of press time. But agents from Gemini 3 and Claude Opus have logged roughly equivalent scores — lower, but within the margin of error of the benchmark. Results from SWE-bench, another coding benchmark that tests AI’s ability to fix real-world software bugs, are similar, showing no clear advantage for GPT-5.2. However, agentic use cases have been difficult to benchmark effectively, and state-of-the-art models can vary significantly in user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Codex app also comes with a range of new features that OpenAI says will help it achieve parity or, in some cases, outpace the various Claude apps. The Codex app will allow for automations that can be set to run in the background on an automatic schedule, with results placed in a queue to be reviewed when the user returns. Users can also select different personalities for the agent — from pragmatic to empathetic — depending on their working style.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But for the company, the biggest selling point is the sheer speed of development that’s made possible by AI. “You can use this from a clean sheet of paper, brand new, to make a really quite sophisticated piece of software in a few hours,” Altman said. “As fast as I can type in new ideas, that is the limit of what can get built.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/openai-launches-new-macos-app-for-agentic-coding/</guid><pubDate>Mon, 02 Feb 2026 18:19:31 +0000</pubDate></item><item><title>Firefox will soon let you block all of its generative AI features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/firefox-will-soon-let-you-block-all-of-its-generative-ai-features/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/firefox.jpeg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Firefox will begin catering to those who don’t want AI in their browser. On Monday, Mozilla announced that Firefox will soon let users block all current and future generative AI features. Users will also have the option to block certain AI features in Firefox, while keeping others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting with Firefox 148, which is rolling out on February 24, users will find a new AI controls section within the desktop browser settings. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;People who don’t want access to any AI features from Firefox can turn on the “Block AI enhancements” toggle. When this setting is turned on, they won’t see pop-ups or reminders to use existing or upcoming AI features.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI controls will also let users manage AI features individually. These features include “Translations,” which allows you to browse the web in your preferred language, Alt text in PDFs, AI-enhanced tab grouping, link previews, and Firefox’s AI chatbot in the sidebar, which lets you use your chosen chatbot as you browse, including services like Anthropic Claude, ChatGPT, Microsoft Copilot, Google Gemini, and Le Chat Mistral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is changing the web, and people want very different things from it,” the company wrote in a blog post. “We’ve heard from many who want nothing to do with AI. We’ve also heard from others who want AI tools that are genuinely useful. Listening to our community, alongside our ongoing commitment to offer choice, led us to build AI controls.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes as Mozilla appointed Anthony Enzor-DeMeo as its CEO back in December. Enzor-DeMeo said at the time that Mozilla would be investing in AI and would add AI features to Firefox, but that the company would make these features optional.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI should always be a choice — something people can easily turn off. People should know why a feature works the way it does and what value they get from it,” he wrote in a blog post. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enzor-DeMeo’s comments come as Mozilla scrambles to adapt in a rapidly changing browser market. Although browsers like Firefox and Google Chrome dominated the browser space for more than a decade, they are facing renewed competition from companies such as Perplexity, Arc, OpenAI, and Opera.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mozilla plans to invest in new AI features, it’s also focused on transparency. CNBC reported last week that Mozilla President Mark Surman said he’s building “a rebel alliance of sorts” made up of tech startups, developers, and public-interest technologists committed to making AI more trustworthy and to checking the power of players like OpenAI and Anthropic. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mozilla will deploy around $1.4 billion worth of reserves to support tech businesses and nonprofits, including its own, CNBC reports. The company is pursuing investments that promote AI transparency and push back against companies growing at historic speeds with limited oversight. &lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/firefox.jpeg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Firefox will begin catering to those who don’t want AI in their browser. On Monday, Mozilla announced that Firefox will soon let users block all current and future generative AI features. Users will also have the option to block certain AI features in Firefox, while keeping others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting with Firefox 148, which is rolling out on February 24, users will find a new AI controls section within the desktop browser settings. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;People who don’t want access to any AI features from Firefox can turn on the “Block AI enhancements” toggle. When this setting is turned on, they won’t see pop-ups or reminders to use existing or upcoming AI features.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI controls will also let users manage AI features individually. These features include “Translations,” which allows you to browse the web in your preferred language, Alt text in PDFs, AI-enhanced tab grouping, link previews, and Firefox’s AI chatbot in the sidebar, which lets you use your chosen chatbot as you browse, including services like Anthropic Claude, ChatGPT, Microsoft Copilot, Google Gemini, and Le Chat Mistral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is changing the web, and people want very different things from it,” the company wrote in a blog post. “We’ve heard from many who want nothing to do with AI. We’ve also heard from others who want AI tools that are genuinely useful. Listening to our community, alongside our ongoing commitment to offer choice, led us to build AI controls.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes as Mozilla appointed Anthony Enzor-DeMeo as its CEO back in December. Enzor-DeMeo said at the time that Mozilla would be investing in AI and would add AI features to Firefox, but that the company would make these features optional.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI should always be a choice — something people can easily turn off. People should know why a feature works the way it does and what value they get from it,” he wrote in a blog post. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enzor-DeMeo’s comments come as Mozilla scrambles to adapt in a rapidly changing browser market. Although browsers like Firefox and Google Chrome dominated the browser space for more than a decade, they are facing renewed competition from companies such as Perplexity, Arc, OpenAI, and Opera.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mozilla plans to invest in new AI features, it’s also focused on transparency. CNBC reported last week that Mozilla President Mark Surman said he’s building “a rebel alliance of sorts” made up of tech startups, developers, and public-interest technologists committed to making AI more trustworthy and to checking the power of players like OpenAI and Anthropic. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mozilla will deploy around $1.4 billion worth of reserves to support tech businesses and nonprofits, including its own, CNBC reports. The company is pursuing investments that promote AI transparency and push back against companies growing at historic speeds with limited oversight. &lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/firefox-will-soon-let-you-block-all-of-its-generative-ai-features/</guid><pubDate>Mon, 02 Feb 2026 18:34:45 +0000</pubDate></item><item><title>[NEW] What Snowflake’s deal with OpenAI tells us about the enterprise AI race (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/what-snowflakes-deal-with-openai-tells-us-about-the-enterprise-ai-race/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2215876044.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud data company Snowflake entered into a $200 million multi-year AI deal with OpenAI on Monday, the latest signal that enterprise AI competition continues to heat up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the deal, Snowflake’s 12,600 customers will have access to OpenAI models across all three major cloud providers. Snowflake employees have access to OpenAI’s ChatGPT Enterprise as well. The two companies are also partnering to build new AI agents and other AI products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“By bringing OpenAI models to enterprise data, Snowflake enables organizations to build and deploy AI on top of their most valuable asset using the secure, governed platform they already trust,” Snowflake CEO Sridhar Ramaswamy said in a press release. “Customers can now harness all their enterprise knowledge in Snowflake together with the world-class intelligence of OpenAI models, enabling them to build AI agents that are powerful, responsible, and trustworthy. Together, we’re setting a new standard for AI innovation, helping businesses transform with confidence, while maintaining strong security and compliance standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined to share information on the deal beyond the press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this deal feels familiar, it should. Snowflake announced a $200 million enterprise deal with AI research lab Anthropic at the beginning of December. At the time, Ramaswamy was quoted making very similar comments about how the partnership with Anthropic would give its customers access to powerful AI models on top of their existing data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our partnership with OpenAI is a multi-year commercial commitment focused on reliability, performance, and real customer usage. At the same time, we remain intentionally model-agnostic. Enterprises need choice, and we do not believe in locking customers into a single provider,” Baris Gultekin, vice president of AI at Snowflake, told TechCrunch over email. “OpenAI is an important partner, and it is one of several frontier model providers available on Snowflake today, alongside Anthropic, Google, Meta, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Snowflake isn’t the only enterprise signing sizable deals with multiple AI companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In January, workflow automation platform ServiceNow announced multi-year deals with both OpenAI and Anthropic for very similar reasons as Snowflake. ServiceNow president, COO, and CPO Amit Zavery told TechCrunch at the time that working with both AI labs was deliberate because they wanted to give their customers and employees the ability to choose which model they wanted based on the task at hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s hard to pinpoint which AI companies are seeing the most enterprise adoption success thus far. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Menlo Ventures survey from late 2025 shows its portfolio company Anthropic holds a commanding market lead; an Andreessen Horowitz report from last week naturally found its portfolio company OpenAI is leading the pack.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These conflicting surveys make it difficult to accurately track enterprise AI usage trends. However, this latest string of deals does provide a short-term view of what enterprise AI adoption will look like. The upshot: Enterprises will continue to strike partnerships with multiple AI companies because each one offers large language models with varying strengths and weaknesses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprises are likely going to partner with multiple AI players because different AI companies and their large language models come with their own strengths and weaknesses. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise AI could easily become a market that contains several winners with an overlapping customer base, similar to how many ride-hail users swap between Lyft and Uber based on what makes the most sense for that moment. Case in point: Employees of these enterprises already use their preferred model regardless of their company contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; Or maybe there will be a clear winner after all. But for now, it’s likely we are going to see enterprises ink deals with multiple players as they continue to hunt for where AI can deliver tangible value.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2215876044.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud data company Snowflake entered into a $200 million multi-year AI deal with OpenAI on Monday, the latest signal that enterprise AI competition continues to heat up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the deal, Snowflake’s 12,600 customers will have access to OpenAI models across all three major cloud providers. Snowflake employees have access to OpenAI’s ChatGPT Enterprise as well. The two companies are also partnering to build new AI agents and other AI products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“By bringing OpenAI models to enterprise data, Snowflake enables organizations to build and deploy AI on top of their most valuable asset using the secure, governed platform they already trust,” Snowflake CEO Sridhar Ramaswamy said in a press release. “Customers can now harness all their enterprise knowledge in Snowflake together with the world-class intelligence of OpenAI models, enabling them to build AI agents that are powerful, responsible, and trustworthy. Together, we’re setting a new standard for AI innovation, helping businesses transform with confidence, while maintaining strong security and compliance standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined to share information on the deal beyond the press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this deal feels familiar, it should. Snowflake announced a $200 million enterprise deal with AI research lab Anthropic at the beginning of December. At the time, Ramaswamy was quoted making very similar comments about how the partnership with Anthropic would give its customers access to powerful AI models on top of their existing data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our partnership with OpenAI is a multi-year commercial commitment focused on reliability, performance, and real customer usage. At the same time, we remain intentionally model-agnostic. Enterprises need choice, and we do not believe in locking customers into a single provider,” Baris Gultekin, vice president of AI at Snowflake, told TechCrunch over email. “OpenAI is an important partner, and it is one of several frontier model providers available on Snowflake today, alongside Anthropic, Google, Meta, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Snowflake isn’t the only enterprise signing sizable deals with multiple AI companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In January, workflow automation platform ServiceNow announced multi-year deals with both OpenAI and Anthropic for very similar reasons as Snowflake. ServiceNow president, COO, and CPO Amit Zavery told TechCrunch at the time that working with both AI labs was deliberate because they wanted to give their customers and employees the ability to choose which model they wanted based on the task at hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s hard to pinpoint which AI companies are seeing the most enterprise adoption success thus far. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Menlo Ventures survey from late 2025 shows its portfolio company Anthropic holds a commanding market lead; an Andreessen Horowitz report from last week naturally found its portfolio company OpenAI is leading the pack.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These conflicting surveys make it difficult to accurately track enterprise AI usage trends. However, this latest string of deals does provide a short-term view of what enterprise AI adoption will look like. The upshot: Enterprises will continue to strike partnerships with multiple AI companies because each one offers large language models with varying strengths and weaknesses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprises are likely going to partner with multiple AI players because different AI companies and their large language models come with their own strengths and weaknesses. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise AI could easily become a market that contains several winners with an overlapping customer base, similar to how many ride-hail users swap between Lyft and Uber based on what makes the most sense for that moment. Case in point: Employees of these enterprises already use their preferred model regardless of their company contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; Or maybe there will be a clear winner after all. But for now, it’s likely we are going to see enterprises ink deals with multiple players as they continue to hunt for where AI can deliver tangible value.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/what-snowflakes-deal-with-openai-tells-us-about-the-enterprise-ai-race/</guid><pubDate>Mon, 02 Feb 2026 19:09:44 +0000</pubDate></item><item><title>[NEW] SpaceX acquires xAI, plans to launch a massive satellite constellation to power it (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “This marks not just the next chapter, but the next book in SpaceX and xAI’s mission.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      SpaceX's Starship and Super Heavy booster lift off from Starbase, Texas, in March 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          SpaceX

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;SpaceX has formally acquired another one of Elon Musk’s companies, xAi, the space company announced on Monday afternoon.&lt;/p&gt;
&lt;p&gt;“SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” the company said. “This marks not just the next chapter, but the next book in SpaceX and xAI’s mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!”&lt;/p&gt;
&lt;p&gt;The merging of what is arguably Musk’s most successful company, SpaceX, with the more speculative xAI venture is a risk. Founded in 2023, xAI’s main products are the generative AI chatbot, Grok, and the social media site X, formerly known as Twitter. The company aims to compete with OpenAI and other artificial intelligence firms. However, Grok has been controversial, including the sexualization of women and children through AI-generated images, as has Musk’s management of Twitter.&lt;/p&gt;
&lt;h2&gt;Vertically integrating AI and space&lt;/h2&gt;
&lt;p&gt;There can be no question that the merger of SpaceX—the world’s premiere spaceflight company—and the artificial intelligence firm offer potential strategic advances. Musk strongly believes that artificial intelligence is central to humanity’s future and wants to be among those leading in its development. With this merger, he plans to use SpaceX’s deep expertise in rapid launch and satellite manufacturing and management to deploy a constellation of up to 1 million orbital data centers. This will provide the backbone of computing power needed to support xAI’s operations.&lt;/p&gt;
&lt;p&gt;Musk’s plan for the merged companies is predicated on several assumptions, including that AI is not a bubble, but rather a technology that will be fully embraced in the future; that orbital data centers are cost-competitive compared to ground-based data centers; and that compute is the essential roadblock that must be solved for widespread adoption of AI by society.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If these assumptions are true, the merged SpaceX-xAI company holds a powerful position. It could potentially own a full stack of capabilities, from launch to orbital bandwidth to frontier AI models, and with Starlink Internet, it could provide AI on demand, anywhere in the world, to any mobile device.&lt;/p&gt;
&lt;p&gt;SpaceX already has the world’s workhorse reusable rocket with the Falcon 9. It can presently deliver about 20 tons to low-Earth orbit for an internal cost of $15 million, compared to more than four or five times that on the open market. Moreover, SpaceX is working toward fully reusable super heavy lift rocket with its Starship vehicle.&lt;/p&gt;
&lt;p&gt;The privately held company also operates more satellites, about 9,600, than any other country or company in the world by a factor of 10. It has extensive operations not just in deploying but also in operating this constellation over the last decade. This is not a simple capability.&lt;/p&gt;
&lt;p&gt;“I would say there have been as many engineering advancements in orbital safety and collision prevention in the last 10 years as there have been advances in rocketry, and that may have gone unnoticed,” said Brian Weeden, director of civil and commercial policy at The Aerospace Corporation, in an interview.&lt;/p&gt;
&lt;h2&gt;“Happening really fast”&lt;/h2&gt;
&lt;p&gt;In an email to SpaceX employees on Monday, Musk said Starship will begin launching V3 Starlink satellites into&amp;nbsp;orbit this year, as well as the next generation of direct-to-mobile satellites. The launches, he said, will be a “forcing function” to improve the performance of Starship, making it more rapidly reusable for data center deployment.&lt;/p&gt;
&lt;p&gt;“The sheer number of satellites that will be needed for space-based data centers will push Starship to even greater heights,” Musk wrote. “With launches every hour carrying 200 tons per flight, Starship will deliver millions of tons to orbit and beyond per year, enabling an exciting future where humanity is out exploring amongst the stars.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Musk told employees that launching 1 million tons per year of satellites, generating 100 kW of compute power per ton, would add 100 gigawatts of AI compute capacity annually, “with no ongoing operational or maintenance needs.” Ultimately, Musk believes there is a path to launching 1 TW/year from Earth.&lt;/p&gt;
&lt;p&gt;“My estimate is that within 2 to 3 years, the lowest cost way to generate AI compute will be in space,” Musk wrote. “This cost-efficiency alone will enable innovative companies to forge ahead in training their AI models and processing data at unprecedented speeds and scales, accelerating breakthroughs in our understanding of physics and invention of technologies to benefit humanity.”&lt;/p&gt;
&lt;p&gt;Musk is clearly bullish on the future of AI and on space’s potential to address the voracious power needs of AI data centers. Many people in the AI industry speculate that artificial intelligence is likely to go through serious and sustained growing pains, or doubt that space-based data centers can compete with operations built on the ground. But Musk, more than anyone, has the means to press forward the bull case for space-based AI, and he is going for it.&lt;/p&gt;
&lt;p&gt;Monday’s merger follows an ultra-ambitious filing on Friday with the Federal Communications Commission in which SpaceX sought permission to launch 1 million satellites that will operate as “orbital data centers.” The company said it would deploy the satellites to orbits with an altitude between 500 and 2,000km, and 30-degree and Sun-synchronous inclinations.&lt;/p&gt;
&lt;p&gt;SpaceX also recently announced its plans to deploy a space situational awareness system, called Stargaze, that will use star trackers to provide data on potential conjunctions between satellites in orbit. The goal is to help de-conflict satellite trajectories and avoid collisions in low-Earth orbit.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“This is all happening really fast,” said Victoria Samson, chief director of space security and stability for Secure World Foundation, in an interview.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Crowded orbits&lt;/h2&gt;
&lt;p&gt;Samson said that, at present, satellites have a fairly large “bubble” of space around them when it comes to collision detection. This is because of uncertainties in the precise location and movement of vehicles. If you improve space situational awareness, such as what SpaceX seeks to do with Stargaze, those bubbles could be shrunk to reduce the number of potential collision warnings. But that will come with risks.&lt;/p&gt;
&lt;p&gt;“There’s a lot of room in space, of course,” Samson said. “But the question is, how much risk do you want to take?”&lt;/p&gt;
&lt;p&gt;A technical expert at The Aerospace Corporation, Marlon Sorge, told Ars that many unanswered questions about SpaceX’s proposed megaconstellation for orbital data centers make it difficult to assess the risks of collision. This includes their size (they will require very large solar arrays to collect sunlight) and precisely where the satellites will be deployed. There is already a lot of debris at around 800 to 1,000 km above Earth from previous collisions, including from an infamous Chinese anti-satellite missile test in 2007, which created more than 3,000 pieces of golf-ball-sized or larger debris.&lt;/p&gt;
&lt;p&gt;Above that altitude, there is less debris, Sorge said. But objects at that altitude take centuries to deorbit naturally, due to the very limited atmosphere.&lt;/p&gt;
&lt;p&gt;“The big challenge at those altitudes is the stuff that’s up there stays up there,” Sorge said. “If you generate more debris, if you have problems, it won’t go away, so you’re stuck with it.”&lt;/p&gt;
&lt;p&gt;SpaceX sought to address these concerns in its regulatory filing, noting that each satellite would have “redundant maneuverability capabilities” in order to deorbit into Earth’s atmosphere. The filing also appears to recognize emerging science that indicates that aluminum burning up from reentering satellites is harmful to ozone levels. To address this, SpaceX is considering moving aging satellites into “high altitude Earth orbits or heliocentric orbits.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;However, Sorge noted that the amount of energy, or delta-V, needed to move a satellite from low-Earth orbit into a heliocentric orbit is “non-trivial.”&lt;/p&gt;
&lt;h2&gt;Has SpaceX lost its way?&lt;/h2&gt;
&lt;p&gt;One of the many questions raised by the new merger is whether SpaceX has lost its way. Musk founded the company in 2002 with the singular purpose of settling Mars, an audacious if not impossible goal at the time. In the decades since, SpaceX has made credible progress toward Mars, and with Starship, humanity has for the first time a transportation system potentially capable of landing humans on the red planet.&lt;/p&gt;
&lt;p&gt;But acquiring an AI company and putting so much effort into orbital data centers? Is this consistent with the Mars mission? Musk clearly thinks it is.&lt;/p&gt;
&lt;p&gt;“While launching AI satellites from Earth is the immediate focus, Starship’s capabilities will also enable operations on other worlds,” he wrote. “Thanks to advancements like in-space propellant transfer, Starship will be capable of landing massive amounts of cargo on the Moon. Once there, it will be possible to establish a permanent presence for scientific and manufacturing pursuits. Factories on the Moon can take advantage of lunar resources to manufacture satellites and deploy them further into space.”&lt;/p&gt;
&lt;p&gt;And from there, he said, Mars will be firmly on the horizon.&lt;/p&gt;
&lt;p&gt;“The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe,” he wrote.&lt;/p&gt;
&lt;p&gt;That’s the vision, at least.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “This marks not just the next chapter, but the next book in SpaceX and xAI’s mission.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      SpaceX's Starship and Super Heavy booster lift off from Starbase, Texas, in March 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          SpaceX

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;SpaceX has formally acquired another one of Elon Musk’s companies, xAi, the space company announced on Monday afternoon.&lt;/p&gt;
&lt;p&gt;“SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” the company said. “This marks not just the next chapter, but the next book in SpaceX and xAI’s mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!”&lt;/p&gt;
&lt;p&gt;The merging of what is arguably Musk’s most successful company, SpaceX, with the more speculative xAI venture is a risk. Founded in 2023, xAI’s main products are the generative AI chatbot, Grok, and the social media site X, formerly known as Twitter. The company aims to compete with OpenAI and other artificial intelligence firms. However, Grok has been controversial, including the sexualization of women and children through AI-generated images, as has Musk’s management of Twitter.&lt;/p&gt;
&lt;h2&gt;Vertically integrating AI and space&lt;/h2&gt;
&lt;p&gt;There can be no question that the merger of SpaceX—the world’s premiere spaceflight company—and the artificial intelligence firm offer potential strategic advances. Musk strongly believes that artificial intelligence is central to humanity’s future and wants to be among those leading in its development. With this merger, he plans to use SpaceX’s deep expertise in rapid launch and satellite manufacturing and management to deploy a constellation of up to 1 million orbital data centers. This will provide the backbone of computing power needed to support xAI’s operations.&lt;/p&gt;
&lt;p&gt;Musk’s plan for the merged companies is predicated on several assumptions, including that AI is not a bubble, but rather a technology that will be fully embraced in the future; that orbital data centers are cost-competitive compared to ground-based data centers; and that compute is the essential roadblock that must be solved for widespread adoption of AI by society.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If these assumptions are true, the merged SpaceX-xAI company holds a powerful position. It could potentially own a full stack of capabilities, from launch to orbital bandwidth to frontier AI models, and with Starlink Internet, it could provide AI on demand, anywhere in the world, to any mobile device.&lt;/p&gt;
&lt;p&gt;SpaceX already has the world’s workhorse reusable rocket with the Falcon 9. It can presently deliver about 20 tons to low-Earth orbit for an internal cost of $15 million, compared to more than four or five times that on the open market. Moreover, SpaceX is working toward fully reusable super heavy lift rocket with its Starship vehicle.&lt;/p&gt;
&lt;p&gt;The privately held company also operates more satellites, about 9,600, than any other country or company in the world by a factor of 10. It has extensive operations not just in deploying but also in operating this constellation over the last decade. This is not a simple capability.&lt;/p&gt;
&lt;p&gt;“I would say there have been as many engineering advancements in orbital safety and collision prevention in the last 10 years as there have been advances in rocketry, and that may have gone unnoticed,” said Brian Weeden, director of civil and commercial policy at The Aerospace Corporation, in an interview.&lt;/p&gt;
&lt;h2&gt;“Happening really fast”&lt;/h2&gt;
&lt;p&gt;In an email to SpaceX employees on Monday, Musk said Starship will begin launching V3 Starlink satellites into&amp;nbsp;orbit this year, as well as the next generation of direct-to-mobile satellites. The launches, he said, will be a “forcing function” to improve the performance of Starship, making it more rapidly reusable for data center deployment.&lt;/p&gt;
&lt;p&gt;“The sheer number of satellites that will be needed for space-based data centers will push Starship to even greater heights,” Musk wrote. “With launches every hour carrying 200 tons per flight, Starship will deliver millions of tons to orbit and beyond per year, enabling an exciting future where humanity is out exploring amongst the stars.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Musk told employees that launching 1 million tons per year of satellites, generating 100 kW of compute power per ton, would add 100 gigawatts of AI compute capacity annually, “with no ongoing operational or maintenance needs.” Ultimately, Musk believes there is a path to launching 1 TW/year from Earth.&lt;/p&gt;
&lt;p&gt;“My estimate is that within 2 to 3 years, the lowest cost way to generate AI compute will be in space,” Musk wrote. “This cost-efficiency alone will enable innovative companies to forge ahead in training their AI models and processing data at unprecedented speeds and scales, accelerating breakthroughs in our understanding of physics and invention of technologies to benefit humanity.”&lt;/p&gt;
&lt;p&gt;Musk is clearly bullish on the future of AI and on space’s potential to address the voracious power needs of AI data centers. Many people in the AI industry speculate that artificial intelligence is likely to go through serious and sustained growing pains, or doubt that space-based data centers can compete with operations built on the ground. But Musk, more than anyone, has the means to press forward the bull case for space-based AI, and he is going for it.&lt;/p&gt;
&lt;p&gt;Monday’s merger follows an ultra-ambitious filing on Friday with the Federal Communications Commission in which SpaceX sought permission to launch 1 million satellites that will operate as “orbital data centers.” The company said it would deploy the satellites to orbits with an altitude between 500 and 2,000km, and 30-degree and Sun-synchronous inclinations.&lt;/p&gt;
&lt;p&gt;SpaceX also recently announced its plans to deploy a space situational awareness system, called Stargaze, that will use star trackers to provide data on potential conjunctions between satellites in orbit. The goal is to help de-conflict satellite trajectories and avoid collisions in low-Earth orbit.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“This is all happening really fast,” said Victoria Samson, chief director of space security and stability for Secure World Foundation, in an interview.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Crowded orbits&lt;/h2&gt;
&lt;p&gt;Samson said that, at present, satellites have a fairly large “bubble” of space around them when it comes to collision detection. This is because of uncertainties in the precise location and movement of vehicles. If you improve space situational awareness, such as what SpaceX seeks to do with Stargaze, those bubbles could be shrunk to reduce the number of potential collision warnings. But that will come with risks.&lt;/p&gt;
&lt;p&gt;“There’s a lot of room in space, of course,” Samson said. “But the question is, how much risk do you want to take?”&lt;/p&gt;
&lt;p&gt;A technical expert at The Aerospace Corporation, Marlon Sorge, told Ars that many unanswered questions about SpaceX’s proposed megaconstellation for orbital data centers make it difficult to assess the risks of collision. This includes their size (they will require very large solar arrays to collect sunlight) and precisely where the satellites will be deployed. There is already a lot of debris at around 800 to 1,000 km above Earth from previous collisions, including from an infamous Chinese anti-satellite missile test in 2007, which created more than 3,000 pieces of golf-ball-sized or larger debris.&lt;/p&gt;
&lt;p&gt;Above that altitude, there is less debris, Sorge said. But objects at that altitude take centuries to deorbit naturally, due to the very limited atmosphere.&lt;/p&gt;
&lt;p&gt;“The big challenge at those altitudes is the stuff that’s up there stays up there,” Sorge said. “If you generate more debris, if you have problems, it won’t go away, so you’re stuck with it.”&lt;/p&gt;
&lt;p&gt;SpaceX sought to address these concerns in its regulatory filing, noting that each satellite would have “redundant maneuverability capabilities” in order to deorbit into Earth’s atmosphere. The filing also appears to recognize emerging science that indicates that aluminum burning up from reentering satellites is harmful to ozone levels. To address this, SpaceX is considering moving aging satellites into “high altitude Earth orbits or heliocentric orbits.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;However, Sorge noted that the amount of energy, or delta-V, needed to move a satellite from low-Earth orbit into a heliocentric orbit is “non-trivial.”&lt;/p&gt;
&lt;h2&gt;Has SpaceX lost its way?&lt;/h2&gt;
&lt;p&gt;One of the many questions raised by the new merger is whether SpaceX has lost its way. Musk founded the company in 2002 with the singular purpose of settling Mars, an audacious if not impossible goal at the time. In the decades since, SpaceX has made credible progress toward Mars, and with Starship, humanity has for the first time a transportation system potentially capable of landing humans on the red planet.&lt;/p&gt;
&lt;p&gt;But acquiring an AI company and putting so much effort into orbital data centers? Is this consistent with the Mars mission? Musk clearly thinks it is.&lt;/p&gt;
&lt;p&gt;“While launching AI satellites from Earth is the immediate focus, Starship’s capabilities will also enable operations on other worlds,” he wrote. “Thanks to advancements like in-space propellant transfer, Starship will be capable of landing massive amounts of cargo on the Moon. Once there, it will be possible to establish a permanent presence for scientific and manufacturing pursuits. Factories on the Moon can take advantage of lunar resources to manufacture satellites and deploy them further into space.”&lt;/p&gt;
&lt;p&gt;And from there, he said, Mars will be firmly on the horizon.&lt;/p&gt;
&lt;p&gt;“The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe,” he wrote.&lt;/p&gt;
&lt;p&gt;That’s the vision, at least.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/</guid><pubDate>Mon, 02 Feb 2026 21:55:44 +0000</pubDate></item><item><title>[NEW] Elon Musk’s SpaceX officially acquires Elon Musk’s xAI, with plan to build data centers in space (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/02/elon-musk-spacex-acquires-xai-data-centers-space-merger/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/OLM_Full_Pressure_Water_Deluge_Test_202307280728232180_1_8ac578ec57.jpeg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SpaceX has acquired Elon Musk’s artificial intelligence startup, xAI, creating the world’s most valuable private company, the spaceflight company announced Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk, who is also the CEO of SpaceX, wrote in a memo posted to the rocket company’s website that the merger is largely about creating space-based data centers — an idea he has become fixated on over the last few months.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Current advances in AI are dependent on large terrestrial data centers, which require immense amounts of power and cooling. Global electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term, without imposing hardship on communities and the environment,” he wrote. (xAI has been accused of imposing some of that hardship on the communities near its data centers in Memphis, Tennessee.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up values the combined company at $1.25 trillion, according to Bloomberg News, which was first to report the completed deal. SpaceX has been reportedly preparing an IPO for as early as June of this year. It’s unclear whether the merger will affect that timeline. Musk did not address the IPO in his public memo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The merger brings together two of Musk’s companies, each with its own financial challenges. xAI is currently burning around $1 billion per month, according to Bloomberg. SpaceX, meanwhile, generates as much as 80% of its revenue from launching its own Starlink satellites, according to Reuters. Last year, xAI acquired X, the social media company also owned by Musk, with Musk claiming a combined company valuation of $113 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk wrote in his memo that it will take a constant stream of many — although he did not specify how many — satellites to create these space-based data centers, ensuring that SpaceX will have an even-larger constant stream of revenue for the foreseeable future. (That revenue loop likely looks even more attractive when you consider that satellites are required to be de-orbited every five years by the Federal Communications Commission.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While space data centers may be the stated goal, SpaceX and xAI have very different near-term objectives. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SpaceX is currently trying to prove that its Starship rocket is capable of bringing astronauts to the moon and Mars, while xAI is competing with leading artificial intelligence companies like Google and OpenAI. The pressure on xAI is so great, the Washington Post reported Monday, that Musk loosened restrictions on the company’s chatbot Grok — which contributed to it becoming a tool for making AI-generated nonconsensual sexual imagery of adults and children.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is also the head of Tesla, The Boring Company, and Neuralink. Tesla and SpaceX previously invested $2 billion each in xAI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/OLM_Full_Pressure_Water_Deluge_Test_202307280728232180_1_8ac578ec57.jpeg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SpaceX has acquired Elon Musk’s artificial intelligence startup, xAI, creating the world’s most valuable private company, the spaceflight company announced Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk, who is also the CEO of SpaceX, wrote in a memo posted to the rocket company’s website that the merger is largely about creating space-based data centers — an idea he has become fixated on over the last few months.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Current advances in AI are dependent on large terrestrial data centers, which require immense amounts of power and cooling. Global electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term, without imposing hardship on communities and the environment,” he wrote. (xAI has been accused of imposing some of that hardship on the communities near its data centers in Memphis, Tennessee.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up values the combined company at $1.25 trillion, according to Bloomberg News, which was first to report the completed deal. SpaceX has been reportedly preparing an IPO for as early as June of this year. It’s unclear whether the merger will affect that timeline. Musk did not address the IPO in his public memo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The merger brings together two of Musk’s companies, each with its own financial challenges. xAI is currently burning around $1 billion per month, according to Bloomberg. SpaceX, meanwhile, generates as much as 80% of its revenue from launching its own Starlink satellites, according to Reuters. Last year, xAI acquired X, the social media company also owned by Musk, with Musk claiming a combined company valuation of $113 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk wrote in his memo that it will take a constant stream of many — although he did not specify how many — satellites to create these space-based data centers, ensuring that SpaceX will have an even-larger constant stream of revenue for the foreseeable future. (That revenue loop likely looks even more attractive when you consider that satellites are required to be de-orbited every five years by the Federal Communications Commission.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While space data centers may be the stated goal, SpaceX and xAI have very different near-term objectives. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SpaceX is currently trying to prove that its Starship rocket is capable of bringing astronauts to the moon and Mars, while xAI is competing with leading artificial intelligence companies like Google and OpenAI. The pressure on xAI is so great, the Washington Post reported Monday, that Musk loosened restrictions on the company’s chatbot Grok — which contributed to it becoming a tool for making AI-generated nonconsensual sexual imagery of adults and children.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is also the head of Tesla, The Boring Company, and Neuralink. Tesla and SpaceX previously invested $2 billion each in xAI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/02/elon-musk-spacex-acquires-xai-data-centers-space-merger/</guid><pubDate>Mon, 02 Feb 2026 22:21:57 +0000</pubDate></item></channel></rss>