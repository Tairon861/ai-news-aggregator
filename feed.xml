<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 18 Nov 2025 06:33:18 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>One Giant Leap for AI Physics: NVIDIA Apollo Unveiled as Open Model Family for Scientific Simulation (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/apollo-open-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-Apollo.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA Apollo — a family of open models for accelerating industrial and computational engineering — was introduced today at the SC25 conference in St. Louis.&lt;/p&gt;
&lt;p&gt;Accelerated by NVIDIA AI infrastructure, the new AI physics models will enable developers to integrate real-time capabilities into their simulation software across a broad range of industries.&lt;/p&gt;
&lt;p&gt;The NVIDIA Apollo family will include physics-optimized models — each developed for scalability, performance and accuracy — for fields including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Electronic device automation and semiconductors&lt;/b&gt;: Defect detection, computational lithography, electrothermal and mechanical design.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Structural mechanics&lt;/b&gt;: Structural analysis for automotive, consumer electronics and aerospace.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Weather and climate: &lt;/b&gt;Global and regional forecasting, downscaling, data assimilation and weather simulation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Computational fluid dynamics&lt;/b&gt;: Simulations for manufacturing, automotive, aerospace and energy.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electromagnetics&lt;/b&gt;: Simulation of wireless communication, radar sensing and high-speed optical data.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Multiphysics&lt;/b&gt;: Nuclear fusion, plasma simulations and fluids structure interaction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The family of open models harness the latest developments in AI physics, incorporating best-in-class machine learning architectures, such as neural operators, transformers and diffusion methods, with domain-specific knowledge.&lt;/p&gt;
&lt;p&gt;NVIDIA Apollo will provide pretrained checkpoints and reference workflows for training, inference and benchmarking, allowing developers to integrate and customize the models for their specific needs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Industry Leaders Tap Into NVIDIA AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Applied Materials, Cadence, LAM Research Corp., Luminary Cloud, KLA, PhysicsX, Rescale, Siemens and Synopsys are among the industry leaders that intend to train, fine-tune and deploy their AI technologies using the new open models. These companies are already using NVIDIA AI models and infrastructure to bolster their applications.&lt;/p&gt;
&lt;p&gt;Applied Materials is developing new materials and manufacturing processes with NVIDIA AI physics to improve the power efficiency of both the manufacturing process and the final product, directly addressing the most significant limiter in scaling semiconductor manufacturing capacity.&lt;/p&gt;
&lt;p&gt;With NVIDIA GPUs and the CUDA framework, Applied has achieved up to 35x acceleration in modules of its ACE+ multi-physics software, enabling faster exploration and optimization of the semiconductor processes. Using ACE+ physics data, Applied has built AI models for key material modification technologies, enabling near-real-time flow, plasma and thermal modeling of advanced semiconductor process chambers using surrogate models — AI models trained on data from conventional simulations that can predict new cases in just seconds — and digital twins.&lt;/p&gt;
&lt;p&gt;Cadence used its Fidelity Charles Solver, which is part of its Fidelity CFD software and is accelerated using the NVIDIA-powered Millennium M2000 Supercomputer, to produce a high-quality dataset of thousands of detailed, time-dependent full aircraft simulations. This data was used to train an AI physics model that enabled a real-time digital twin of a full aircraft, which was showcased last month at NVIDIA GTC Washington, D.C.&lt;/p&gt;
&lt;p&gt;LAM Research is working with NVIDIA to accelerate plasma reactor simulation using NVIDIA AI physics. Plasma reactors are critical for etching and deposition processes in semiconductor manufacturing.&lt;/p&gt;
&lt;p&gt;KLA will explore using NVIDIA Apollo models to accelerate a range of simulations. Faster, more accurate simulations will build on KLA’s existing capabilities and accelerate its development of new semiconductor process control solutions.&lt;/p&gt;
&lt;p&gt;Northrop Grumman and Luminary Cloud are also using NVIDIA AI physics models to accelerate spacecraft thruster nozzle design. Harnessing NVIDIA CUDA-X libraries to accelerate its CFD solver, Northrop Grumman generated a large training dataset to build a surrogate model for nozzle simulation on Luminary Cloud’s platform, which is powered by NVIDIA AI physics models. This AI physics model will enable Northrop Grumman’s engineers to rapidly explore thousands of designs in record time.&lt;/p&gt;
&lt;p&gt;PhysicsX’s AI-native platform supports the complete AI lifecycle, from simulation and data management to model training, fine-tuning and deployment, seamlessly integrating with NVIDIA AI physics infrastructure and simulation software like Siemens Simcenter X. For customers in automotive, aerospace, energy and more, the PhysicsX platform dramatically reduces product development cycles and accelerates time to market.&lt;/p&gt;
&lt;p&gt;Rescale is accelerating engineering innovation by integrating NVIDIA Apollo models into its industry-leading AI physics operating system. This enhancement to Rescale’s complete, end-to-end stack will allow engineers to seamlessly blend high-fidelity, first-principles simulations with high-speed AI surrogates. By using the advanced capabilities of NVIDIA Apollo models within the Rescale framework, customers will be able to explore vast design spaces orders of magnitude faster and achieve real-time inference results while maintaining the accuracy of traditional simulation methods.&lt;/p&gt;
&lt;p&gt;Siemens is integrating NVIDIA AI physics into its flagship fluid simulation tools like Simcenter STAR-CCM+. This integration allows designers to blend high-fidelity first principles simulations with high-speed AI surrogates. This allows exploration of design options orders of magnitude faster than previously possible.&lt;/p&gt;
&lt;p&gt;Synopsys is using NVIDIA AI physics to multiply GPU acceleration and achieve up to 500x speedups in computational engineering. The runtime of NVIDIA GPU-accelerated fluid simulation tools like Ansys Fluent can be greatly reduced by initializing the simulation with AI physics surrogates. This approach is faster than initializing simulations with traditional methods.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;NVIDIA Apollo models are coming soon to &lt;/i&gt;&lt;i&gt;build.nvidia.com&lt;/i&gt;&lt;i&gt;, HuggingFace and as &lt;/i&gt;&lt;i&gt;NVIDIA NIM&lt;/i&gt;&lt;i&gt; microservices. &lt;span&gt;Sign up to be notified&lt;/span&gt;&lt;span&gt; when they’re available.&lt;/span&gt;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-Apollo.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA Apollo — a family of open models for accelerating industrial and computational engineering — was introduced today at the SC25 conference in St. Louis.&lt;/p&gt;
&lt;p&gt;Accelerated by NVIDIA AI infrastructure, the new AI physics models will enable developers to integrate real-time capabilities into their simulation software across a broad range of industries.&lt;/p&gt;
&lt;p&gt;The NVIDIA Apollo family will include physics-optimized models — each developed for scalability, performance and accuracy — for fields including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Electronic device automation and semiconductors&lt;/b&gt;: Defect detection, computational lithography, electrothermal and mechanical design.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Structural mechanics&lt;/b&gt;: Structural analysis for automotive, consumer electronics and aerospace.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Weather and climate: &lt;/b&gt;Global and regional forecasting, downscaling, data assimilation and weather simulation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Computational fluid dynamics&lt;/b&gt;: Simulations for manufacturing, automotive, aerospace and energy.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electromagnetics&lt;/b&gt;: Simulation of wireless communication, radar sensing and high-speed optical data.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Multiphysics&lt;/b&gt;: Nuclear fusion, plasma simulations and fluids structure interaction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The family of open models harness the latest developments in AI physics, incorporating best-in-class machine learning architectures, such as neural operators, transformers and diffusion methods, with domain-specific knowledge.&lt;/p&gt;
&lt;p&gt;NVIDIA Apollo will provide pretrained checkpoints and reference workflows for training, inference and benchmarking, allowing developers to integrate and customize the models for their specific needs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Industry Leaders Tap Into NVIDIA AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Applied Materials, Cadence, LAM Research Corp., Luminary Cloud, KLA, PhysicsX, Rescale, Siemens and Synopsys are among the industry leaders that intend to train, fine-tune and deploy their AI technologies using the new open models. These companies are already using NVIDIA AI models and infrastructure to bolster their applications.&lt;/p&gt;
&lt;p&gt;Applied Materials is developing new materials and manufacturing processes with NVIDIA AI physics to improve the power efficiency of both the manufacturing process and the final product, directly addressing the most significant limiter in scaling semiconductor manufacturing capacity.&lt;/p&gt;
&lt;p&gt;With NVIDIA GPUs and the CUDA framework, Applied has achieved up to 35x acceleration in modules of its ACE+ multi-physics software, enabling faster exploration and optimization of the semiconductor processes. Using ACE+ physics data, Applied has built AI models for key material modification technologies, enabling near-real-time flow, plasma and thermal modeling of advanced semiconductor process chambers using surrogate models — AI models trained on data from conventional simulations that can predict new cases in just seconds — and digital twins.&lt;/p&gt;
&lt;p&gt;Cadence used its Fidelity Charles Solver, which is part of its Fidelity CFD software and is accelerated using the NVIDIA-powered Millennium M2000 Supercomputer, to produce a high-quality dataset of thousands of detailed, time-dependent full aircraft simulations. This data was used to train an AI physics model that enabled a real-time digital twin of a full aircraft, which was showcased last month at NVIDIA GTC Washington, D.C.&lt;/p&gt;
&lt;p&gt;LAM Research is working with NVIDIA to accelerate plasma reactor simulation using NVIDIA AI physics. Plasma reactors are critical for etching and deposition processes in semiconductor manufacturing.&lt;/p&gt;
&lt;p&gt;KLA will explore using NVIDIA Apollo models to accelerate a range of simulations. Faster, more accurate simulations will build on KLA’s existing capabilities and accelerate its development of new semiconductor process control solutions.&lt;/p&gt;
&lt;p&gt;Northrop Grumman and Luminary Cloud are also using NVIDIA AI physics models to accelerate spacecraft thruster nozzle design. Harnessing NVIDIA CUDA-X libraries to accelerate its CFD solver, Northrop Grumman generated a large training dataset to build a surrogate model for nozzle simulation on Luminary Cloud’s platform, which is powered by NVIDIA AI physics models. This AI physics model will enable Northrop Grumman’s engineers to rapidly explore thousands of designs in record time.&lt;/p&gt;
&lt;p&gt;PhysicsX’s AI-native platform supports the complete AI lifecycle, from simulation and data management to model training, fine-tuning and deployment, seamlessly integrating with NVIDIA AI physics infrastructure and simulation software like Siemens Simcenter X. For customers in automotive, aerospace, energy and more, the PhysicsX platform dramatically reduces product development cycles and accelerates time to market.&lt;/p&gt;
&lt;p&gt;Rescale is accelerating engineering innovation by integrating NVIDIA Apollo models into its industry-leading AI physics operating system. This enhancement to Rescale’s complete, end-to-end stack will allow engineers to seamlessly blend high-fidelity, first-principles simulations with high-speed AI surrogates. By using the advanced capabilities of NVIDIA Apollo models within the Rescale framework, customers will be able to explore vast design spaces orders of magnitude faster and achieve real-time inference results while maintaining the accuracy of traditional simulation methods.&lt;/p&gt;
&lt;p&gt;Siemens is integrating NVIDIA AI physics into its flagship fluid simulation tools like Simcenter STAR-CCM+. This integration allows designers to blend high-fidelity first principles simulations with high-speed AI surrogates. This allows exploration of design options orders of magnitude faster than previously possible.&lt;/p&gt;
&lt;p&gt;Synopsys is using NVIDIA AI physics to multiply GPU acceleration and achieve up to 500x speedups in computational engineering. The runtime of NVIDIA GPU-accelerated fluid simulation tools like Ansys Fluent can be greatly reduced by initializing the simulation with AI physics surrogates. This approach is faster than initializing simulations with traditional methods.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;NVIDIA Apollo models are coming soon to &lt;/i&gt;&lt;i&gt;build.nvidia.com&lt;/i&gt;&lt;i&gt;, HuggingFace and as &lt;/i&gt;&lt;i&gt;NVIDIA NIM&lt;/i&gt;&lt;i&gt; microservices. &lt;span&gt;Sign up to be notified&lt;/span&gt;&lt;span&gt; when they’re available.&lt;/span&gt;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/apollo-open-models/</guid><pubDate>Mon, 17 Nov 2025 22:30:25 +0000</pubDate></item><item><title>NVIDIA Accelerated Computing Enables Scientific Breakthroughs for Materials Discovery (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-science-materials-discovery-sc25/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To power future technologies including liquid-cooled data centers, high-resolution digital displays and long-lasting batteries, scientists are searching for novel chemicals and materials optimized for factors like energy use, durability and efficacy.&lt;/p&gt;
&lt;p&gt;New NVIDIA-accelerated data processing pipelines and AI microservices unveiled at the SC25 conference in St. Louis are advancing chemistry and material science to support this research, with potential applications in industries such as aerospace, energy and manufacturing.&lt;/p&gt;
&lt;p&gt;A demo in the NVIDIA booth showcases work by the U.S. Department of Energy’s Brookhaven National Laboratory using the NVIDIA Holoscan AI sensor processing platform to visualize materials at under 10 nanometer-resolution.&lt;/p&gt;
&lt;p&gt;Another demo highlights a pair of microservices coming to NVIDIA NIM that will provide efficient, high-throughput simulations for batched conformer search and batched molecular dynamics — processes necessary to predict and simulate the properties of materials at an atomic level. The NIM microservices are part of NVIDIA ALCHEMI, a suite of microservices and toolkits for chemistry and materials science.&lt;/p&gt;
&lt;p&gt;Japanese energy company ENEOS and New Jersey-based OLED display technology company Universal Display Corporation are among the early-access users of the NVIDIA ALCHEMI NIM microservices.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Brookhaven National Laboratory&lt;/b&gt;&lt;b&gt; Accelerates Nanoscale Imaging With NVIDIA Holoscan&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Brookhaven National Laboratory is driving materials science research with the National Synchrotron Light Source II (NSLS-II), a facility that houses dozens of beamlines that help scientists investigate material properties using a powerful X-ray source.&lt;/p&gt;
&lt;p&gt;NSLS-II is capable of imaging complex material systems like battery, microelectronic and nanoparticle superlattices at nanometer resolution. These experiments generate large volumes of data that must be processed using advanced computational methods before scientists can extract meaningful insights from them.&lt;/p&gt;
&lt;p&gt;NSLS-II researchers are using the NVIDIA Holoscan platform for high-bandwidth, high-throughput edge processing of streaming data in real time. The Holoscan-accelerated processing pipeline enables researchers to receive near-instant feedback on their experiments, helping them run imaging workflows more efficiently.&lt;/p&gt;
&lt;p&gt;“By collaborating with NVIDIA to integrate Holoscan into our pipeline, we can now see results right away as we conduct a scan, instead of waiting for each scan to finish,” said Hanfei Yan, lead beamline scientist for the Hard X-ray Nanoprobe at NSLS-II. “This capability enables us to identify regions of interest on the fly and to observe the evolution of properties during measurements, which is critical for decisionmaking in experiments.”&lt;/p&gt;
&lt;p&gt;Boosting image processing efficiency is more than a time-saver for researchers — it helps optimize the operating costs of expensive instruments like the NSLS-II.&lt;/p&gt;
&lt;p&gt;“If we can run our experiments more efficiently, we can support more users, which in turn means we can do more science,” said Daniel Allan, group leader of data engineering at NSLS-II. “We also see the potential to use this pipeline for AI-assisted operation — integrating AI models for both imaging tasks and controls to conduct autonomous experiments.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;ENEOS &lt;/b&gt;&lt;b&gt;Innovates With Immersion Cooling Fluids, Catalysts for Energy Conversion&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;ENEOS is applying NVIDIA ALCHEMI NIM microservices to two critical energy applications: discovering new liquids for immersion cooling in next-generation data centers, and identifying catalysts that can be used for processes like hydrogen fuel production.&lt;/p&gt;
&lt;p&gt;NVIDIA ALCHEMI NIM microservices for conformer search and molecular dynamics enable ENEOS scientists to prescreen molecular candidates through computational experiments, narrowing down options so only the most promising materials are tested in real-world experiments. This optimization saves research and development costs while accelerating the path to commercialization.&lt;/p&gt;
&lt;p&gt;By adopting ALCHEMI, the team found they could evaluate about 10 million liquid-immersion candidates and 100 million oxygen evolution reaction candidates within a few weeks — at least 10x more than they could with prior methods.&lt;/p&gt;
&lt;p&gt;“We hadn’t considered running searches at the 10-100 million scale before, but NVIDIA ALCHEMI made it surprisingly easy to sample extensively and achieve more physically realistic results,” said Takeshi Ibuka, general manager of the AI innovation department at ENEOS Holdings, Inc. “Because the calculations finish so quickly, we can spend more time productively analyzing results instead of doing just calculation tasks.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Universal Display Corporation&lt;/b&gt;&lt;b&gt; Advances the Next Generation of OLED Screens&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Universal Display Corporation (UDC) invents, develops and commercializes energy-efficient organic light emitting diode (OLED) materials for displays in everyday products including watches, smartphones, laptops, computer monitors, televisions, cars and virtual-reality headsets.&lt;/p&gt;
&lt;p&gt;With NVIDIA ALCHEMI, UDC’s scientists are predicting properties of potential new OLED materials to power displays with better performance, greater energy efficiency and more precise color tuning.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87478"&gt;&lt;img alt="alt" class="size-large wp-image-87478" height="1200" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/Aurora-flexible-OLED-panel_2-1680x1200.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87478"&gt;OLED panel image courtesy of UDC.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Finding the right OLED material involves searching a universe of possibilities: The number of possible molecules UDC could make for an OLED is vast, around 10 to the 100th power. With the ALCHEMI NIM microservice for AI-accelerated conformer search, UDC can evaluate billions of candidate molecules up to 10,000x faster than traditional computational methods.&lt;/p&gt;
&lt;p&gt;“Early on, our work relied on conventional CPU machines that limited how broadly we could explore at any given time, and required us to prioritize the most promising areas of chemistry using our expertise and chemical intuition,” said Julie Brown, executive vice president and chief technical officer at UDC.&lt;/p&gt;
&lt;p&gt;“By using GPU-accelerated computing and NVIDIA ALCHEMI together with our in-house expertise, we can completely change the scale and speed of discovery,” said Brown. “This&amp;nbsp; enables us to uncover opportunities and fast-track new materials quicker than we ever could before.”&lt;/p&gt;
&lt;p&gt;The most promising compounds discovered in this initial search are next simulated using the ALCHEMI NIM for molecular dynamics, which accelerates the process by up to 10x for a single simulation. By running their workloads across multiple NVIDIA GPUs in parallel, the UDC team is further amplifying the speedup, reducing simulation time from days to seconds.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87486"&gt;&lt;img alt="alt" class="wp-image-87486 size-large" height="531" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/UDC_OLED-1680x531.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87486"&gt;Images courtesy of UDC.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;UDC is applying NVIDIA ALCHEMI NIM microservices to research projects including the development of blue phosphorescent OLEDs that could meaningfully improve energy efficiency and device performance.&lt;/p&gt;
&lt;p&gt;“The NVIDIA ALCHEMI microservices enable more creativity for individual scientists by removing any concerns that we have about capacity and throughput limitations, and giving us immediate feedback on new chemistry,” said Brown. “Through this collaboration with NVIDIA, we can amplify the impact of our scientific insight and significantly increase the pace at which new materials are discovered and developed. These efforts don’t just push the boundaries of what OLED can do — they set the stage for more sustainable and energy-efficient displays worldwide.”&lt;/p&gt;
&lt;p&gt;NVIDIA ALCHEMI is among over 150 NVIDIA CUDA-X libraries and frameworks speeding up real-world problem-solving across science and engineering.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about &lt;/i&gt;&lt;i&gt;NVIDIA Holoscan&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA ALCHEMI&lt;/i&gt;&lt;i&gt;, and watch the &lt;/i&gt;&lt;i&gt;SC25 fireside chat by Ian Buck&lt;/i&gt;&lt;i&gt;, vice president of hyperscale and high-performance computing at NVIDIA.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To power future technologies including liquid-cooled data centers, high-resolution digital displays and long-lasting batteries, scientists are searching for novel chemicals and materials optimized for factors like energy use, durability and efficacy.&lt;/p&gt;
&lt;p&gt;New NVIDIA-accelerated data processing pipelines and AI microservices unveiled at the SC25 conference in St. Louis are advancing chemistry and material science to support this research, with potential applications in industries such as aerospace, energy and manufacturing.&lt;/p&gt;
&lt;p&gt;A demo in the NVIDIA booth showcases work by the U.S. Department of Energy’s Brookhaven National Laboratory using the NVIDIA Holoscan AI sensor processing platform to visualize materials at under 10 nanometer-resolution.&lt;/p&gt;
&lt;p&gt;Another demo highlights a pair of microservices coming to NVIDIA NIM that will provide efficient, high-throughput simulations for batched conformer search and batched molecular dynamics — processes necessary to predict and simulate the properties of materials at an atomic level. The NIM microservices are part of NVIDIA ALCHEMI, a suite of microservices and toolkits for chemistry and materials science.&lt;/p&gt;
&lt;p&gt;Japanese energy company ENEOS and New Jersey-based OLED display technology company Universal Display Corporation are among the early-access users of the NVIDIA ALCHEMI NIM microservices.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Brookhaven National Laboratory&lt;/b&gt;&lt;b&gt; Accelerates Nanoscale Imaging With NVIDIA Holoscan&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Brookhaven National Laboratory is driving materials science research with the National Synchrotron Light Source II (NSLS-II), a facility that houses dozens of beamlines that help scientists investigate material properties using a powerful X-ray source.&lt;/p&gt;
&lt;p&gt;NSLS-II is capable of imaging complex material systems like battery, microelectronic and nanoparticle superlattices at nanometer resolution. These experiments generate large volumes of data that must be processed using advanced computational methods before scientists can extract meaningful insights from them.&lt;/p&gt;
&lt;p&gt;NSLS-II researchers are using the NVIDIA Holoscan platform for high-bandwidth, high-throughput edge processing of streaming data in real time. The Holoscan-accelerated processing pipeline enables researchers to receive near-instant feedback on their experiments, helping them run imaging workflows more efficiently.&lt;/p&gt;
&lt;p&gt;“By collaborating with NVIDIA to integrate Holoscan into our pipeline, we can now see results right away as we conduct a scan, instead of waiting for each scan to finish,” said Hanfei Yan, lead beamline scientist for the Hard X-ray Nanoprobe at NSLS-II. “This capability enables us to identify regions of interest on the fly and to observe the evolution of properties during measurements, which is critical for decisionmaking in experiments.”&lt;/p&gt;
&lt;p&gt;Boosting image processing efficiency is more than a time-saver for researchers — it helps optimize the operating costs of expensive instruments like the NSLS-II.&lt;/p&gt;
&lt;p&gt;“If we can run our experiments more efficiently, we can support more users, which in turn means we can do more science,” said Daniel Allan, group leader of data engineering at NSLS-II. “We also see the potential to use this pipeline for AI-assisted operation — integrating AI models for both imaging tasks and controls to conduct autonomous experiments.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;ENEOS &lt;/b&gt;&lt;b&gt;Innovates With Immersion Cooling Fluids, Catalysts for Energy Conversion&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;ENEOS is applying NVIDIA ALCHEMI NIM microservices to two critical energy applications: discovering new liquids for immersion cooling in next-generation data centers, and identifying catalysts that can be used for processes like hydrogen fuel production.&lt;/p&gt;
&lt;p&gt;NVIDIA ALCHEMI NIM microservices for conformer search and molecular dynamics enable ENEOS scientists to prescreen molecular candidates through computational experiments, narrowing down options so only the most promising materials are tested in real-world experiments. This optimization saves research and development costs while accelerating the path to commercialization.&lt;/p&gt;
&lt;p&gt;By adopting ALCHEMI, the team found they could evaluate about 10 million liquid-immersion candidates and 100 million oxygen evolution reaction candidates within a few weeks — at least 10x more than they could with prior methods.&lt;/p&gt;
&lt;p&gt;“We hadn’t considered running searches at the 10-100 million scale before, but NVIDIA ALCHEMI made it surprisingly easy to sample extensively and achieve more physically realistic results,” said Takeshi Ibuka, general manager of the AI innovation department at ENEOS Holdings, Inc. “Because the calculations finish so quickly, we can spend more time productively analyzing results instead of doing just calculation tasks.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Universal Display Corporation&lt;/b&gt;&lt;b&gt; Advances the Next Generation of OLED Screens&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Universal Display Corporation (UDC) invents, develops and commercializes energy-efficient organic light emitting diode (OLED) materials for displays in everyday products including watches, smartphones, laptops, computer monitors, televisions, cars and virtual-reality headsets.&lt;/p&gt;
&lt;p&gt;With NVIDIA ALCHEMI, UDC’s scientists are predicting properties of potential new OLED materials to power displays with better performance, greater energy efficiency and more precise color tuning.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87478"&gt;&lt;img alt="alt" class="size-large wp-image-87478" height="1200" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/Aurora-flexible-OLED-panel_2-1680x1200.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87478"&gt;OLED panel image courtesy of UDC.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Finding the right OLED material involves searching a universe of possibilities: The number of possible molecules UDC could make for an OLED is vast, around 10 to the 100th power. With the ALCHEMI NIM microservice for AI-accelerated conformer search, UDC can evaluate billions of candidate molecules up to 10,000x faster than traditional computational methods.&lt;/p&gt;
&lt;p&gt;“Early on, our work relied on conventional CPU machines that limited how broadly we could explore at any given time, and required us to prioritize the most promising areas of chemistry using our expertise and chemical intuition,” said Julie Brown, executive vice president and chief technical officer at UDC.&lt;/p&gt;
&lt;p&gt;“By using GPU-accelerated computing and NVIDIA ALCHEMI together with our in-house expertise, we can completely change the scale and speed of discovery,” said Brown. “This&amp;nbsp; enables us to uncover opportunities and fast-track new materials quicker than we ever could before.”&lt;/p&gt;
&lt;p&gt;The most promising compounds discovered in this initial search are next simulated using the ALCHEMI NIM for molecular dynamics, which accelerates the process by up to 10x for a single simulation. By running their workloads across multiple NVIDIA GPUs in parallel, the UDC team is further amplifying the speedup, reducing simulation time from days to seconds.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87486"&gt;&lt;img alt="alt" class="wp-image-87486 size-large" height="531" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/UDC_OLED-1680x531.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87486"&gt;Images courtesy of UDC.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;UDC is applying NVIDIA ALCHEMI NIM microservices to research projects including the development of blue phosphorescent OLEDs that could meaningfully improve energy efficiency and device performance.&lt;/p&gt;
&lt;p&gt;“The NVIDIA ALCHEMI microservices enable more creativity for individual scientists by removing any concerns that we have about capacity and throughput limitations, and giving us immediate feedback on new chemistry,” said Brown. “Through this collaboration with NVIDIA, we can amplify the impact of our scientific insight and significantly increase the pace at which new materials are discovered and developed. These efforts don’t just push the boundaries of what OLED can do — they set the stage for more sustainable and energy-efficient displays worldwide.”&lt;/p&gt;
&lt;p&gt;NVIDIA ALCHEMI is among over 150 NVIDIA CUDA-X libraries and frameworks speeding up real-world problem-solving across science and engineering.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about &lt;/i&gt;&lt;i&gt;NVIDIA Holoscan&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA ALCHEMI&lt;/i&gt;&lt;i&gt;, and watch the &lt;/i&gt;&lt;i&gt;SC25 fireside chat by Ian Buck&lt;/i&gt;&lt;i&gt;, vice president of hyperscale and high-performance computing at NVIDIA.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-science-materials-discovery-sc25/</guid><pubDate>Mon, 17 Nov 2025 22:30:54 +0000</pubDate></item><item><title>NVIDIA Accelerates AI for Over 80 New Science Systems Worldwide (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/sc25-new-science-systems-worldwide/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across quantum physics, digital biology and climate research, the world’s researchers are harnessing a universal scientific instrument to chart new frontiers of discovery: accelerated computing.&lt;/p&gt;
&lt;p&gt;At this week’s SC25 conference in St. Louis, Missouri, NVIDIA announced that over 80 new scientific systems powered by the NVIDIA accelerated computing platform have been unveiled around the globe in the last year, contributing to a combined total of 4,500 exaflops of AI performance.&lt;/p&gt;
&lt;p&gt;Newest among them is America’s largest academic supercomputer: the 300-petaflop Horizon system at the Texas Advanced Computing Center (TACC).&lt;/p&gt;
&lt;p&gt;Slated to be powered by NVIDIA GB200 NVL4 and NVIDIA Vera CPU servers, interconnected with NVIDIA Quantum-X800 InfiniBand networking, Horizon is set to accelerate breakthroughs in science and engineering when it comes online in 2026, offering the nation’s research community unprecedented computing capabilities for discovery and innovation.&lt;/p&gt;
&lt;p&gt;It’s the latest in a new wave of NVIDIA-accelerated supercomputers fueling global research by nations and private companies in areas such as healthcare, weather and climate modeling, robotics, manufacturing, quantum computing research and materials science.&lt;/p&gt;
&lt;p&gt;NVIDIA’s full-stack accelerated computing platform — spanning GPUs, CPUs, DPUs, NICs, scale-out switches, as well as CUDA-X libraries and NVIDIA AI Enterprise software — provides the unified architecture, scale and efficiency these systems need to advance science sustainably and at unprecedented speed.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Scientific Innovation on the Horizon for TACC&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;With 4,000 NVIDIA Blackwell GPUs, the Horizon supercomputer can deliver up to 80 exaflops of AI compute at FP4 precision. It was designed to support a specific set of scientific modeling and simulation applications, including:&amp;nbsp;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Simulating the mechanics of disease: &lt;/b&gt;Researchers plan to use molecular dynamics software and AI-enhanced simulations to study viruses.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Modeling stars and galaxies across the universe: &lt;/b&gt;Astrophysicists plan to explore how stars and galaxies form — and simulate distant galaxies uncovered by recent discoveries from the James Webb Space Telescope.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Investigating novel materials at atomic scale: &lt;/b&gt;Scientists plan to study turbulence, solids with complex crystal structures and the conductivity of quantum materials.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Mapping seismic waves to prepare for earthquakes: &lt;/b&gt;Researchers plan to improve seismic hazard maps and simulate how faults rupture during earthquakes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Horizon will enable our scientists to pursue ambitious scientific research at unprecedented scale,” said John Cazes, director of high-performance computing at TACC. “This new system will transform how the research community can pursue AI-driven initiatives to decipher the molecular dynamics of viral infections, explore data from distant galaxies and simulate seismic activity decades into the future.”&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Argonne,&lt;/b&gt; &lt;b&gt;Los Alamos National Laboratories &lt;/b&gt;&lt;b&gt;to House New AI Supercomputers&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The U.S. Department of Energy (DOE) recently announced a partnership with NVIDIA to build seven new AI supercomputers at Argonne National Laboratory (ANL) in Illinois and Los Alamos National Laboratory (LANL) in New Mexico.&lt;/p&gt;
&lt;p&gt;At ANL, two AI supercomputing systems featuring NVIDIA Blackwell GPUs and NVIDIA networking will connect with the DOE’s network of scientific instruments and data assets, enabling researchers to develop powerful AI models for science and energy applications.&lt;/p&gt;
&lt;p&gt;The largest system in the lab complex, Solstice, will feature 100,000 NVIDIA Blackwell GPUs. A system of that scale featuring NVIDIA GB200 NVL72 systems can reach a staggering 1,000 exaflops of AI training compute for training. That’s over 50% higher than the sum of AI training compute across the entire TOP500 list from June 2025, at around 650 exaflops.&lt;/p&gt;
&lt;p&gt;Another ANL system, called Equinox, will be powered by 10,000 NVIDIA Blackwell GPUs. Three more NVIDIA-accelerated systems at the lab — Minerva, Janus and Tara — will support AI inference and workforce development.&lt;/p&gt;
&lt;p&gt;At LANL, the Mission and Vision systems — to be built and delivered by HPE — will be powered by the NVIDIA Vera Rubin platform and the NVIDIA Quantum-X800 InfiniBand networking platform. Mission will run classified applications for the National Nuclear Security Administration, while Vision will power open science research, including foundation models and agentic AI.&lt;/p&gt;
&lt;p&gt;Both are expected to be operational in 2027.&lt;/p&gt;
&lt;p&gt;These seven DOE systems follow this year’s announcement with Lawrence Berkeley National Laboratory about Doudna — a supercomputer for scientific discovery set to launch in 2026. Doudna will be powered by the NVIDIA Vera Rubin architecture and NVIDIA Quantum-X800 InfiniBand, and is poised to support the work of over 11,000 researchers across fusion energy, materials science, drug discovery and astronomy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Europe’s Jülich Supercomputer Breaks Exaflop Barrier on Linpack Benchmark&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Across the Atlantic, NVIDIA-accelerated supercomputers in Europe — including systems at the Swiss National Supercomputing Centre and Italy’s CINECA supercomputing center — are fueling scientific research throughout the continent.&lt;/p&gt;
&lt;p&gt;In Germany, the Jülich Supercomputing Centre’s JUPITER system has achieved exaflop performance — calculating 1 quintillion floating point operations per second — on the HPL benchmark, which measures computing performance on double precision (FP64) math.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84476"&gt;&lt;img alt="alt" class="size-full wp-image-84476" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jupiter-featured-still-1280x680-1.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84476"&gt;View into a JUPITER rack with compute blades. Image courtesy of Forschungszentrum Jülich / Sascha Kreklau.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;JUPITER, inaugurated in September, is Europe’s first exascale computer, featuring 24,000 NVIDIA GH200 Grace Hopper Superchips interconnected with NVIDIA Quantum-2 InfiniBand. It’s already in use for applications including high-resolution global climate simulation.&lt;/p&gt;
&lt;p&gt;“With over 1 exaflop of computing power on JUPITER, our researchers can now run global simulations at kilometer-scale resolution,” said Thomas Lippert, director of the Jülich Supercomputing Centre. “This leap in compute capacity enables European researchers to run AI models and simulations across scientific disciplines at new levels of complexity, size and scale.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="An image of the Blue Lion supercomputer floating against a blue field." class="aligncenter size-full wp-image-81884" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/hpc-corp-blog-isc-blue-lion-supercomputer-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Other major European supercomputers unveiled in the past year include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blue Lion —&amp;nbsp; Slated to go online in early 2027, this system at Germany’s Leibniz Supercomputing Centre, LRZ, will be powered by the NVIDIA Vera Rubin platform to support researchers working on climate, turbulence, physics and machine learning.&lt;/li&gt;
&lt;li&gt;Gefion — Denmark’s first AI supercomputer, operated by DCAI, is an NVIDIA DGX SuperPOD providing sovereign AI capacity for the country’s innovators to advance research in areas including quantum computing, clean energy and biotechnology.&lt;/li&gt;
&lt;li&gt;Isambard-AI — The U.K.’s most powerful AI supercomputer, housed at the University of Bristol, is being used for projects including Nightingale AI, a multimodal foundation model trained on National Health Service data, and UK-LLM, an initiative to enable high-quality AI reasoning for Welsh and other U.K. languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_82024"&gt;&lt;img alt="alt" class="size-full wp-image-82024" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/quantum-computing-corp-blog-ansys-gefion-1280x680-1.png" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82024"&gt;Gefion is Denmark’s first AI supercomputer, consisting of an NVIDIA DGX SuperPOD interconnected with NVIDIA Quantum-2 InfiniBand networking. Image courtesy of DCAI.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Supercomputers in Japan, South Korea and Taiwan Fuel Research Across Industries&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Through sovereign AI investments and private-sector initiatives, NVIDIA-accelerated AI infrastructure is also supporting scientific research in Japan, South Korea and Taiwan.&lt;/p&gt;
&lt;p&gt;RIKEN, Japan’s top research institute, announced at SC25 that it is integrating NVIDIA GB200 NVL4 systems in two new supercomputers — a 1600-GPU system for AI for science and a 540-GPU system for quantum computing.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87463"&gt;&lt;img alt="alt" class="wp-image-87463 size-full" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/hpc-corp-blog-sc25-riken-pr-1280x680-2.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87463"&gt;RIKEN is integrating NVIDIA Blackwell with two new supercomputers in Japan — one built for AI for science and the other for quantum computing.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;RIKEN is also working with Fujitsu and NVIDIA to codesign FugakuNEXT (development code name), a supercomputer that will power earth systems modeling, drug discovery research and advanced manufacturing applications. It’ll feature FUJITSU-MONAKA-X CPUs, which can be paired with NVIDIA technologies using NVLink Fusion.&lt;/p&gt;
&lt;p&gt;Tokyo University of Technology has built an AI supercomputer with NVIDIA DGX B200 systems capable of achieving 2 exaflops of FP4 theoretical computing performance with under 100 GPUs. The system will be used to develop large language models and build digital twins to serve as core infrastructure for fostering the next generation of AI talent.&lt;/p&gt;
&lt;p&gt;Japan’s National Institute of Advanced Industrial Science and Technology recently launched ABCI-Q, the world’s largest research supercomputer dedicated to quantum computing, featuring over 2,000 NVIDIA H100 GPUs.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87458"&gt;&lt;img alt="alt" class="wp-image-87458 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/aist-quantum-research-supercomputer-1680x1120.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87458"&gt;NVIDIA powers ABCI-Q, the world’s largest research supercomputer dedicated to quantum computing. Image courtesy of AIST G-QuAT.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The South Korean government plans to deploy over 50,000 NVIDIA GPUs across sovereign clouds and AI factories. Industry leaders Samsung, SK Group and Hyundai Motor Group are also building AI factories with NVIDIA Blackwell GPUs to accelerate research and manufacturing.&lt;/p&gt;
&lt;p&gt;And in Taiwan, NVIDIA is working with Foxconn Hon Hai Technology group to build an AI factory supercomputer with 10,000 NVIDIA Blackwell GPUs to fuel innovation across researchers, startups and industries.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Read more about &lt;/i&gt;&lt;i&gt;NVIDIA-accelerated supercomputing&lt;/i&gt;&lt;i&gt; and watch the &lt;/i&gt;&lt;i&gt;SC25 fireside chat by Ian Buck&lt;/i&gt;&lt;i&gt;, vice president of hyperscale and high-performance computing at NVIDIA.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across quantum physics, digital biology and climate research, the world’s researchers are harnessing a universal scientific instrument to chart new frontiers of discovery: accelerated computing.&lt;/p&gt;
&lt;p&gt;At this week’s SC25 conference in St. Louis, Missouri, NVIDIA announced that over 80 new scientific systems powered by the NVIDIA accelerated computing platform have been unveiled around the globe in the last year, contributing to a combined total of 4,500 exaflops of AI performance.&lt;/p&gt;
&lt;p&gt;Newest among them is America’s largest academic supercomputer: the 300-petaflop Horizon system at the Texas Advanced Computing Center (TACC).&lt;/p&gt;
&lt;p&gt;Slated to be powered by NVIDIA GB200 NVL4 and NVIDIA Vera CPU servers, interconnected with NVIDIA Quantum-X800 InfiniBand networking, Horizon is set to accelerate breakthroughs in science and engineering when it comes online in 2026, offering the nation’s research community unprecedented computing capabilities for discovery and innovation.&lt;/p&gt;
&lt;p&gt;It’s the latest in a new wave of NVIDIA-accelerated supercomputers fueling global research by nations and private companies in areas such as healthcare, weather and climate modeling, robotics, manufacturing, quantum computing research and materials science.&lt;/p&gt;
&lt;p&gt;NVIDIA’s full-stack accelerated computing platform — spanning GPUs, CPUs, DPUs, NICs, scale-out switches, as well as CUDA-X libraries and NVIDIA AI Enterprise software — provides the unified architecture, scale and efficiency these systems need to advance science sustainably and at unprecedented speed.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Scientific Innovation on the Horizon for TACC&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;With 4,000 NVIDIA Blackwell GPUs, the Horizon supercomputer can deliver up to 80 exaflops of AI compute at FP4 precision. It was designed to support a specific set of scientific modeling and simulation applications, including:&amp;nbsp;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Simulating the mechanics of disease: &lt;/b&gt;Researchers plan to use molecular dynamics software and AI-enhanced simulations to study viruses.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Modeling stars and galaxies across the universe: &lt;/b&gt;Astrophysicists plan to explore how stars and galaxies form — and simulate distant galaxies uncovered by recent discoveries from the James Webb Space Telescope.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Investigating novel materials at atomic scale: &lt;/b&gt;Scientists plan to study turbulence, solids with complex crystal structures and the conductivity of quantum materials.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Mapping seismic waves to prepare for earthquakes: &lt;/b&gt;Researchers plan to improve seismic hazard maps and simulate how faults rupture during earthquakes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Horizon will enable our scientists to pursue ambitious scientific research at unprecedented scale,” said John Cazes, director of high-performance computing at TACC. “This new system will transform how the research community can pursue AI-driven initiatives to decipher the molecular dynamics of viral infections, explore data from distant galaxies and simulate seismic activity decades into the future.”&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Argonne,&lt;/b&gt; &lt;b&gt;Los Alamos National Laboratories &lt;/b&gt;&lt;b&gt;to House New AI Supercomputers&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The U.S. Department of Energy (DOE) recently announced a partnership with NVIDIA to build seven new AI supercomputers at Argonne National Laboratory (ANL) in Illinois and Los Alamos National Laboratory (LANL) in New Mexico.&lt;/p&gt;
&lt;p&gt;At ANL, two AI supercomputing systems featuring NVIDIA Blackwell GPUs and NVIDIA networking will connect with the DOE’s network of scientific instruments and data assets, enabling researchers to develop powerful AI models for science and energy applications.&lt;/p&gt;
&lt;p&gt;The largest system in the lab complex, Solstice, will feature 100,000 NVIDIA Blackwell GPUs. A system of that scale featuring NVIDIA GB200 NVL72 systems can reach a staggering 1,000 exaflops of AI training compute for training. That’s over 50% higher than the sum of AI training compute across the entire TOP500 list from June 2025, at around 650 exaflops.&lt;/p&gt;
&lt;p&gt;Another ANL system, called Equinox, will be powered by 10,000 NVIDIA Blackwell GPUs. Three more NVIDIA-accelerated systems at the lab — Minerva, Janus and Tara — will support AI inference and workforce development.&lt;/p&gt;
&lt;p&gt;At LANL, the Mission and Vision systems — to be built and delivered by HPE — will be powered by the NVIDIA Vera Rubin platform and the NVIDIA Quantum-X800 InfiniBand networking platform. Mission will run classified applications for the National Nuclear Security Administration, while Vision will power open science research, including foundation models and agentic AI.&lt;/p&gt;
&lt;p&gt;Both are expected to be operational in 2027.&lt;/p&gt;
&lt;p&gt;These seven DOE systems follow this year’s announcement with Lawrence Berkeley National Laboratory about Doudna — a supercomputer for scientific discovery set to launch in 2026. Doudna will be powered by the NVIDIA Vera Rubin architecture and NVIDIA Quantum-X800 InfiniBand, and is poised to support the work of over 11,000 researchers across fusion energy, materials science, drug discovery and astronomy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Europe’s Jülich Supercomputer Breaks Exaflop Barrier on Linpack Benchmark&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Across the Atlantic, NVIDIA-accelerated supercomputers in Europe — including systems at the Swiss National Supercomputing Centre and Italy’s CINECA supercomputing center — are fueling scientific research throughout the continent.&lt;/p&gt;
&lt;p&gt;In Germany, the Jülich Supercomputing Centre’s JUPITER system has achieved exaflop performance — calculating 1 quintillion floating point operations per second — on the HPL benchmark, which measures computing performance on double precision (FP64) math.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_84476"&gt;&lt;img alt="alt" class="size-full wp-image-84476" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/jupiter-featured-still-1280x680-1.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84476"&gt;View into a JUPITER rack with compute blades. Image courtesy of Forschungszentrum Jülich / Sascha Kreklau.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;JUPITER, inaugurated in September, is Europe’s first exascale computer, featuring 24,000 NVIDIA GH200 Grace Hopper Superchips interconnected with NVIDIA Quantum-2 InfiniBand. It’s already in use for applications including high-resolution global climate simulation.&lt;/p&gt;
&lt;p&gt;“With over 1 exaflop of computing power on JUPITER, our researchers can now run global simulations at kilometer-scale resolution,” said Thomas Lippert, director of the Jülich Supercomputing Centre. “This leap in compute capacity enables European researchers to run AI models and simulations across scientific disciplines at new levels of complexity, size and scale.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="An image of the Blue Lion supercomputer floating against a blue field." class="aligncenter size-full wp-image-81884" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/hpc-corp-blog-isc-blue-lion-supercomputer-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Other major European supercomputers unveiled in the past year include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blue Lion —&amp;nbsp; Slated to go online in early 2027, this system at Germany’s Leibniz Supercomputing Centre, LRZ, will be powered by the NVIDIA Vera Rubin platform to support researchers working on climate, turbulence, physics and machine learning.&lt;/li&gt;
&lt;li&gt;Gefion — Denmark’s first AI supercomputer, operated by DCAI, is an NVIDIA DGX SuperPOD providing sovereign AI capacity for the country’s innovators to advance research in areas including quantum computing, clean energy and biotechnology.&lt;/li&gt;
&lt;li&gt;Isambard-AI — The U.K.’s most powerful AI supercomputer, housed at the University of Bristol, is being used for projects including Nightingale AI, a multimodal foundation model trained on National Health Service data, and UK-LLM, an initiative to enable high-quality AI reasoning for Welsh and other U.K. languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_82024"&gt;&lt;img alt="alt" class="size-full wp-image-82024" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/quantum-computing-corp-blog-ansys-gefion-1280x680-1.png" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82024"&gt;Gefion is Denmark’s first AI supercomputer, consisting of an NVIDIA DGX SuperPOD interconnected with NVIDIA Quantum-2 InfiniBand networking. Image courtesy of DCAI.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Supercomputers in Japan, South Korea and Taiwan Fuel Research Across Industries&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Through sovereign AI investments and private-sector initiatives, NVIDIA-accelerated AI infrastructure is also supporting scientific research in Japan, South Korea and Taiwan.&lt;/p&gt;
&lt;p&gt;RIKEN, Japan’s top research institute, announced at SC25 that it is integrating NVIDIA GB200 NVL4 systems in two new supercomputers — a 1600-GPU system for AI for science and a 540-GPU system for quantum computing.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87463"&gt;&lt;img alt="alt" class="wp-image-87463 size-full" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/hpc-corp-blog-sc25-riken-pr-1280x680-2.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87463"&gt;RIKEN is integrating NVIDIA Blackwell with two new supercomputers in Japan — one built for AI for science and the other for quantum computing.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;RIKEN is also working with Fujitsu and NVIDIA to codesign FugakuNEXT (development code name), a supercomputer that will power earth systems modeling, drug discovery research and advanced manufacturing applications. It’ll feature FUJITSU-MONAKA-X CPUs, which can be paired with NVIDIA technologies using NVLink Fusion.&lt;/p&gt;
&lt;p&gt;Tokyo University of Technology has built an AI supercomputer with NVIDIA DGX B200 systems capable of achieving 2 exaflops of FP4 theoretical computing performance with under 100 GPUs. The system will be used to develop large language models and build digital twins to serve as core infrastructure for fostering the next generation of AI talent.&lt;/p&gt;
&lt;p&gt;Japan’s National Institute of Advanced Industrial Science and Technology recently launched ABCI-Q, the world’s largest research supercomputer dedicated to quantum computing, featuring over 2,000 NVIDIA H100 GPUs.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87458"&gt;&lt;img alt="alt" class="wp-image-87458 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/aist-quantum-research-supercomputer-1680x1120.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87458"&gt;NVIDIA powers ABCI-Q, the world’s largest research supercomputer dedicated to quantum computing. Image courtesy of AIST G-QuAT.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The South Korean government plans to deploy over 50,000 NVIDIA GPUs across sovereign clouds and AI factories. Industry leaders Samsung, SK Group and Hyundai Motor Group are also building AI factories with NVIDIA Blackwell GPUs to accelerate research and manufacturing.&lt;/p&gt;
&lt;p&gt;And in Taiwan, NVIDIA is working with Foxconn Hon Hai Technology group to build an AI factory supercomputer with 10,000 NVIDIA Blackwell GPUs to fuel innovation across researchers, startups and industries.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Read more about &lt;/i&gt;&lt;i&gt;NVIDIA-accelerated supercomputing&lt;/i&gt;&lt;i&gt; and watch the &lt;/i&gt;&lt;i&gt;SC25 fireside chat by Ian Buck&lt;/i&gt;&lt;i&gt;, vice president of hyperscale and high-performance computing at NVIDIA.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/sc25-new-science-systems-worldwide/</guid><pubDate>Mon, 17 Nov 2025 22:30:57 +0000</pubDate></item><item><title>Accelerated Computing, Networking Drive Supercomputing in Age of AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/accelerated-computing-networking-supercomputing-ai/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At SC25, NVIDIA unveiled advances across NVIDIA BlueField DPUs, next-generation networking, quantum computing, national research, AI physics and more — as accelerated systems drive the next chapter in AI supercomputing.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87508"&gt;&lt;img alt="alt" class="wp-image-87508 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-Fireside-Chat-DEBM5955-1680x1120.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87508"&gt;Ian Buck, vice president and general manager of accelerated computing at NVIDIA, delivered a special address at SC25.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA also highlighted storage innovations powered by the NVIDIA BlueField-4 data processing unit, part of the full-stack BlueField platform that accelerates gigascale AI infrastructure.&lt;/p&gt;
&lt;p&gt;More details also came on NVIDIA Quantum-X Photonics InfiniBand CPO networking switches — enabling AI factories to drastically reduce energy consumption and operational costs — including that TACC, Lambda and CoreWeave plan to integrate them.&lt;/p&gt;
&lt;p&gt;And NVIDIA founder and CEO Jensen Huang made a surprise appearance at the St. Louis event, making a few remarks about NVIDIA’s supercomputing news to the crowd at SC25.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-87600 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-DGX-Spark_Giveaway-DEB15704-1680x1120.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;“The big news this year is Grace Blackwell, and you might have seen the production of our second-generation Grace platform, called GB300, is going incredibly,” Huang said. “We are, basically, manufacturing supercomputers like chiclets.”&lt;/p&gt;
&lt;p&gt;He also came bearing gifts of the most compact supercomputers on the planet: NVIDIA DGX Spark AI supercomputers.&lt;/p&gt;
&lt;p&gt;“So this is the DGX Spark. And apparently several of you — 10 of you — are going to win one of these,” he said. “Tell me this isn’t gonna look great under a Christmas tree.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-87604" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-DGX-Spark-Giveaway-blog-1920x1080-4511950-02-1680x945.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Last month, NVIDIA began shipping DGX Spark, the world’s smallest AI supercomputer. DGX Spark packs a petaflop of AI performance and 128GB of unified memory into a desktop form factor, enabling developers to run inference on models up to 200 billion parameters and fine-tune models locally. Built on the Grace Blackwell architecture, it integrates NVIDIA GPUs, CPUs, networking, CUDA libraries and the full NVIDIA AI software stack.&lt;/p&gt;
&lt;p&gt;DGX Spark’s unified memory and NVIDIA NVLink-C2C deliver 5x the bandwidth of PCIe Gen5, enabling faster GPU-CPU data exchange. This boosts training efficiency for large models, reduces latency and supports seamless fine-tuning workflows — all within a desktop form factor.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Apollo Unveiled as Latest Open Model Family for AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA Apollo, a family of open models for AI Physics, was also introduced at SC25. Applied Materials, Cadence, LAM Research, Luminary Cloud, KLA, PhysicsX, Rescale, Siemens and Synopsys &amp;nbsp;are among the industry leaders adopting these open models to simulate and accelerate their design processes in a broad range of fields — electronic device automation and semiconductors, computational fluid dynamics, structural mechanics, electromagnetics, weather and more.&lt;/p&gt;
&lt;p&gt;The family of open models harness the latest developments in AI physics, incorporating best-in-class machine learning architectures, such as neural operators, transformers and diffusion methods, with domain-specific knowledge. Apollo will provide pretrained checkpoints and reference workflows for training, inference and benchmarking, allowing developers to integrate and customize the models for their specific needs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="size-medium wp-image-87397 aligncenter" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/industrial-manufacturing-social-cae-ai-physics-open-model-blog-1280x680.jpg-960x510.png" width="960" /&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading" id="warp"&gt;&lt;b&gt;NVIDIA Warp Supercharges Physics Simulations​ 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA Warp is a purpose-built open-source Python framework delivering GPU acceleration for computational physics and AI by up to 245x.&lt;/p&gt;
&lt;p&gt;NVIDIA Warp provides a structured approach for simulation, robotics and machine learning workloads, combining the accessibility of Python with performance comparable to native CUDA code.&lt;/p&gt;
&lt;p&gt;Warp supports the creation of GPU-accelerated 3D simulation workflows that integrate with ML pipelines in PyTorch, JAX, NVIDIA PhysicsNeMo and NVIDIA Omniverse. This allows developers to run complex simulation tasks and generate data at scale without leaving the Python programming environment.&lt;/p&gt;
&lt;p&gt;By offering CUDA-level performance with Python-level productivity, Warp simplifies the development of high-performance simulation workflows. It is designed to accelerate AI research and engineering by reducing barriers to GPU programming, making advanced simulation and data generation more efficient and widely accessible.&lt;/p&gt;
&lt;p&gt;Siemens, Neural Concept, Luminary Cloud, among others, are adopting NVIDIA Warp.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87400"&gt;&lt;img alt="NVIDIA BlueField-4 DPU powering the OS of AI factories " class="size-medium wp-image-87400" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/bluefield-corp-blog-bluefield-4-1280x680-4468150-960x510.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87400"&gt;NVIDIA BlueField-4 DPU: The Processor Powering the Operating System of AI Factories&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading" id="bluefield-4"&gt;&lt;b&gt;Showcasing BlueField-4 for Powering the OS of AI Factories 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Unveiled at GTC Washington, D.C., NVIDIA BlueField-4 DPUs are powering the operating system of AI factories. By offloading, accelerating and isolating critical data center functions — networking, storage and security — they free up CPUs and GPUs to focus entirely on compute-intensive workloads.&lt;/p&gt;
&lt;p&gt;BlueField-4, combining a 64-core NVIDIA Grace CPU and NVIDIA ConnectX-9 networking, unlocks unprecedented performance, efficiency and zero-trust security at scale. It supports multi-tenant environments, rapid data access, and real-time protection, with native integration of NVIDIA DOCA microservices for scalable, containerized AI operations. Together, they are transforming data centers into intelligent, software-defined engines for trillion-token AI and beyond.&lt;/p&gt;
&lt;p&gt;As AI factories and supercomputing centers continue to scale in size and capability, they require faster, more intelligent storage infrastructure to manage structured, unstructured and AI-native data for large-scale training and inference.&lt;/p&gt;
&lt;p&gt;Leading storage innovators — DDN, VAST Data and WEKA — are adopting BlueField-4 to redefine performance and efficiency for AI and scientific workloads.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DDN is building next-generation AI factories, accelerating data pipelines to maximize GPU utilization for AI and HPC workloads.&lt;/li&gt;
&lt;li&gt;VAST Data is advancing the AI pipeline with intelligent data movement and real-time efficiency across large-scale AI clusters.&lt;/li&gt;
&lt;li&gt;WEKA is launching its NeuralMesh architecture on BlueField-4, running storage services directly on the DPU to simplify and accelerate AI infrastructure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these HPC storage leaders are demonstrating how NVIDIA BlueField-4 transforms data movement and management — turning storage into a performance multiplier for the next era of supercomputing and AI infrastructure.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87404"&gt;&lt;img alt="NVIDIA ConnectX-9 SuperNIC" class="size-medium wp-image-87404" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/infiniband-corp-blog-connectx-9-supernic-c9180-1280x680-1-960x510.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87404"&gt;NVIDIA ConnectX-9 SuperNIC&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading" id="co-packaged-optics"&gt;&lt;b&gt;Adopting NVIDIA Co-Packaged Optics for Speed and Reliability​🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;TACC, Lambda and CoreWeave unveiled that they will integrate NVIDIA Quantum-X Photonics CPO switches into next generation systems as early as next year.&lt;/p&gt;
&lt;p&gt;NVIDIA Quantum-X Photonics networking switches enable AI factories and supercomputing centers to drastically reduce energy consumption and operational costs. NVIDIA has achieved this fusion of electronic circuits and optical communications at massive scale.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;As AI factories grow to unprecedented sizes, networks must evolve to keep pace. By eliminating traditional pluggable transceivers, a common cause of job runtime failures, NVIDIA Photonics switch systems not only deliver 3.5x better power efficiency, but also perform with 10x higher resiliency, enabling applications to run 5x longer without interruption.&lt;/p&gt;
&lt;p&gt;At GTC 2024 in Silicon Valley, NVIDIA unveiled NVIDIA Quantum-X800 InfiniBand switches, purpose-built to power trillion-parameter-scale generative AI models. These platforms deliver a staggering 800Gb/s end-to-end throughput — 2x the bandwidth and 9x the in-network compute of their predecessors — owing to such innovations as SHARPv4 and FP8 support.&lt;/p&gt;
&lt;p&gt;As NVIDIA Quantum‑X800 continues to be widely adopted to meet the demands of massive-scale AI, NVIDIA Quantum‑X Photonics, announced at GTC earlier this year, addresses the critical power, resiliency, and signal-integrity challenges of even larger deployments. By integrating optics directly on the switch, it eliminates failures caused by pluggable transceivers and link flaps, enabling workloads to run uninterrupted at scale and ensuring the infrastructure can support the next generation of compute-intensive applications up to 5x better than with pluggable transceivers.&lt;/p&gt;
&lt;p&gt;“NVIDIA Quantum‑X Photonics represents the next step in building high-performance, resilient AI networks,” said Maxx Garrison, product manager for cloud infrastructure at Lambda. “These advances in power efficiency, signal integrity and reliability, will be key to supporting efficient, large-scale workloads for our customers.”&lt;/p&gt;
&lt;p&gt;SHARPv4 enables in-network aggregation and reduction, minimizing GPU-to-GPU communication overhead. Combined with FP8 precision, it accelerates training of trillion-parameter models by reducing bandwidth and compute demands — delivering faster convergence and higher throughput and comes standard with NVIDIA Quantum‑X800 and Quantum‑X Photonics switches.&lt;/p&gt;
&lt;p&gt;“CoreWeave is building the Essential Cloud for AI,” said Peter Salanki, co-founder and chief technology officer at CoreWeave. “With NVIDIA Quantum-X Photonics, we’re advancing power efficiency, and further improving the reliability CoreWeave is known for in supporting massive AI workloads at scale, helping our customers unlock the full potential of next-generation AI.”&lt;/p&gt;
&lt;p&gt;The NVIDIA Quantum-X Photonics platform, anchored by the NVIDIA Quantum Q3450 CPO-based InfiniBand switch and ConnectX-8 SuperNIC, is engineered for the highest-performance environments that also require significantly lower power, higher resiliency and lower latency.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Supercomputing Centers Worldwide Adopting NVQLink&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-87520" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/NVIDIANVQLink.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;More than a dozen of the world’s top scientific computing centers are adopting NVQLink, a universal interconnect linking accelerated computing to quantum processors.&lt;/p&gt;
&lt;p&gt;“Here at Supercomputing, we’re announcing that we’ve been working with the supercomputing centers worldwide that are dedicated and interested in building the next generation of quantum GPU, CPU GPU supercomputers, and how to connect them to their particular research area or deployment platform for quantum computing,” said Ian Buck, vice president and general manager of accelerated computing at NVIDIA.&lt;/p&gt;
&lt;p&gt;NVQLink connects quantum processors with NVIDIA GPUs, enabling large‑scale workflows powered by the CUDA‑Q software platform. NVQLink’s open architecture provides the critical link supercomputing centers need to integrate diverse quantum processors while delivering 40 petaflops of AI performance at FP4 precision.&lt;/p&gt;
&lt;p&gt;In the future every supercomputer will draw on quantum processors to expand the problems they can solve and every quantum processor will depend on GPU supercomputers to run correctly.&lt;/p&gt;
&lt;p&gt;Quantum computing company Quantinuum’s new Helios QPU was integrated with NVIDIA GPUs through NVQLink, achieving the world’s first real‑time decoding of scalable qLDPC quantum error‑correction codes. The system maintained 99% fidelity compared with 95% without correction thanks to NVQLink’s microsecond low latencies.&lt;/p&gt;
&lt;p&gt;With NVQLink scientists and developers gain a universal bridge between quantum and classical hardware — making scalable error correction, hybrid applications and real‑time quantum‑GPU workflows practical.&lt;/p&gt;
&lt;p&gt;In the Asia‑Pacific region, Japan’s Global Research and Development Center for Business by Quantum-AI technology (G-QuAT) at the National Institute of Advanced Industrial Science and Technology (AIST) and RIKEN Center for Computational Science, Korea’s Korea Institute of Science and Technology Information (KISTI), Taiwan’s National Center for High-Performance Computing (NCHC), Singapore’s National Quantum Computing Hub (a joint initiative of Singapore’s Centre for Quantum Technologies, A*STAR Institute of High Performance Computing, and National Supercomputing Centre Singapore) — and Australia’s Pawsey Supercomputing Research Centre are among the early adopters.&lt;/p&gt;
&lt;p&gt;Across Europe and the Middle East, NVQLink is being embraced by CINECA, Denmark’s DCAI, operator of Denmark’s AI Supercomputer, France’s Grand Équipement National de Calcul Intensif (GENCI), the Czech Republic’s IT4Innovations National Supercomputing Center (IT4I), Germany’s Jülich Supercomputing Centre (JSC), Poland’s Poznań Supercomputing and Networking Center (PCSS), the Technology Innovation Institute (TII), UAE and Saudi Arabia’s King Abdullah University of Science and Technology (KAUST).&lt;/p&gt;
&lt;p&gt;In the United States, leading national laboratories including, Brookhaven National Laboratory, Fermi National Accelerator Laboratory, Lawrence Berkeley National Laboratory, Los Alamos National Laboratory, MIT Lincoln Laboratory, National Energy Research Scientific Computing Center, Oak Ridge National Laboratory, Pacific Northwest National Laboratory and Sandia National Laboratories are also adopting NVQLink to advance hybrid quantum‑classical research.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Developing Real‑World Hybrid Applications&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Quantinuum’s Helios QPU with NVQLink delivered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First real‑time decoding of qLDPC error‑correction codes&lt;/li&gt;
&lt;li&gt;~99% fidelity with NVQLink correction vs ~95% without&lt;/li&gt;
&lt;li&gt;Reaction time of 60 microseconds, exceeding Helios’ 1‑millisecond requirement by 16x&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVQLink unites quantum processors with GPU supercomputing for scalable error correction and hybrid applications. Scientists can gain a single programming environment through CUDA‑Q APIs. Developers can build and test quantum‑GPU workflows in real time&lt;/p&gt;
&lt;p&gt;With NVQLink the world’s supercomputing centers are laying the foundation for practical quantum‑classical systems, connecting diverse quantum processors to NVIDIA accelerated computing at unprecedented speed and scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA and &lt;/b&gt;&lt;b&gt;RIKEN&lt;/b&gt;&lt;b&gt; Advance Japan’s Scientific Frontiers&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-87463" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/hpc-corp-blog-sc25-riken-pr-1280x680-2.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA and RIKEN are building two new GPU‑accelerated supercomputers to expand Japan’s leadership in AI for science and quantum computing. Together the systems will feature 2,140 NVIDIA Blackwell GPUs connected through the GB200 NVL4 platform and NVIDIA Quantum‑X800 InfiniBand networking, strengthening Japan’s sovereign AI strategy and secure domestic infrastructure.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI for Science System: 1,600 Blackwell GPUs will power research in life sciences, materials science, climate and weather forecasting, manufacturing and laboratory automation.&lt;/li&gt;
&lt;li&gt;Quantum Computing System: 540 Blackwell GPUs will accelerate quantum algorithms, hybrid simulation and quantum‑classical methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The partnership builds on RIKEN’s collaboration with Fujitsu and NVIDIA to codesign FugakuNEXT, successor to the Fugaku supercomputer, expected to deliver 100x greater application performance and integrate production‑level quantum computers by 2030.&lt;/p&gt;
&lt;p&gt;The two new RIKEN systems are scheduled to be operational in spring 2026.&lt;/p&gt;
&lt;h2 class="wp-block-heading" id="arm"&gt;&lt;b&gt;Arm Adopting NVIDIA NVLink Fusion 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI is reshaping data centers in a once-in-a-generation architectural shift, where efficiency per watt defines success. At the center is Arm Neoverse, deployed in over a billion cores and projected to reach 50% hyperscaler market share by 2025. Every major provider — AWS, Google, Microsoft, Oracle and Meta — is building on Neoverse, underscoring its role in powering AI at scale.&lt;/p&gt;
&lt;p&gt;To meet surging demand, Arm is extending Neoverse with NVIDIA NVLink Fusion, the high-bandwidth, coherent interconnect first pioneered with Grace Blackwell. NVLink Fusion links CPUs, GPUs, and accelerators into one unified rack-scale architecture, removing memory and bandwidth bottlenecks that limit AI performance. Connected with Arm’s AMBA CHI C2C protocol, it ensures seamless data movement between Arm-based CPUs and partners’ preferred accelerators.&lt;/p&gt;
&lt;p&gt;Together, Arm and NVIDIA are setting a new standard for AI infrastructure, enabling ecosystem partners to build differentiated, energy-efficient systems that accelerate innovation across the AI era.&lt;/p&gt;
&lt;p&gt;“Folks building their own ARM CPU, or using an Arm IP can actually have access to NVLink Fusion, be able to connect that ARM CPU to an Nvidia GPU or to the rest of the NVLink ecosystem, and that’s happening at the racks and scale-up infrastructure,” said Buck.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Smarter Power for Accelerated Computing&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As AI factories scale, energy is becoming the new bottleneck. The NVIDIA Domain Power Service (DPS) flips that constraint into an opportunity — turning power into a dynamic, orchestrated resource. Running as a Kubernetes service, DPS models and manages energy use across the data center, from rack to room to facility. It enables operators to extract more performance per megawatt by constraining power intelligently, improving throughput without expanding infrastructure.&lt;/p&gt;
&lt;p&gt;DPS integrates tightly with the NVIDIA Omniverse DSX Blueprint, a platform for designing and operating next-generation data centers. It works alongside technologies like Power Reservation Steering to balance workloads across the facility and the Workload Power Profile Solution to tune GPU power to the needs of specific jobs. Together, they form DSX Boost — an energy-aware control layer that maximizes efficiency while meeting performance targets.&lt;/p&gt;
&lt;p&gt;DPS also extends beyond the data center. With grid-facing APIs, it supports automated load shedding and demand response, helping utilities stabilize the grid during peak events. The result is a resilient, grid-interactive AI factory that turns every watt into measurable progress.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At SC25, NVIDIA unveiled advances across NVIDIA BlueField DPUs, next-generation networking, quantum computing, national research, AI physics and more — as accelerated systems drive the next chapter in AI supercomputing.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87508"&gt;&lt;img alt="alt" class="wp-image-87508 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-Fireside-Chat-DEBM5955-1680x1120.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87508"&gt;Ian Buck, vice president and general manager of accelerated computing at NVIDIA, delivered a special address at SC25.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA also highlighted storage innovations powered by the NVIDIA BlueField-4 data processing unit, part of the full-stack BlueField platform that accelerates gigascale AI infrastructure.&lt;/p&gt;
&lt;p&gt;More details also came on NVIDIA Quantum-X Photonics InfiniBand CPO networking switches — enabling AI factories to drastically reduce energy consumption and operational costs — including that TACC, Lambda and CoreWeave plan to integrate them.&lt;/p&gt;
&lt;p&gt;And NVIDIA founder and CEO Jensen Huang made a surprise appearance at the St. Louis event, making a few remarks about NVIDIA’s supercomputing news to the crowd at SC25.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-87600 size-large" height="1120" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-DGX-Spark_Giveaway-DEB15704-1680x1120.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;“The big news this year is Grace Blackwell, and you might have seen the production of our second-generation Grace platform, called GB300, is going incredibly,” Huang said. “We are, basically, manufacturing supercomputers like chiclets.”&lt;/p&gt;
&lt;p&gt;He also came bearing gifts of the most compact supercomputers on the planet: NVIDIA DGX Spark AI supercomputers.&lt;/p&gt;
&lt;p&gt;“So this is the DGX Spark. And apparently several of you — 10 of you — are going to win one of these,” he said. “Tell me this isn’t gonna look great under a Christmas tree.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-87604" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/SC25-DGX-Spark-Giveaway-blog-1920x1080-4511950-02-1680x945.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Last month, NVIDIA began shipping DGX Spark, the world’s smallest AI supercomputer. DGX Spark packs a petaflop of AI performance and 128GB of unified memory into a desktop form factor, enabling developers to run inference on models up to 200 billion parameters and fine-tune models locally. Built on the Grace Blackwell architecture, it integrates NVIDIA GPUs, CPUs, networking, CUDA libraries and the full NVIDIA AI software stack.&lt;/p&gt;
&lt;p&gt;DGX Spark’s unified memory and NVIDIA NVLink-C2C deliver 5x the bandwidth of PCIe Gen5, enabling faster GPU-CPU data exchange. This boosts training efficiency for large models, reduces latency and supports seamless fine-tuning workflows — all within a desktop form factor.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Apollo Unveiled as Latest Open Model Family for AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA Apollo, a family of open models for AI Physics, was also introduced at SC25. Applied Materials, Cadence, LAM Research, Luminary Cloud, KLA, PhysicsX, Rescale, Siemens and Synopsys &amp;nbsp;are among the industry leaders adopting these open models to simulate and accelerate their design processes in a broad range of fields — electronic device automation and semiconductors, computational fluid dynamics, structural mechanics, electromagnetics, weather and more.&lt;/p&gt;
&lt;p&gt;The family of open models harness the latest developments in AI physics, incorporating best-in-class machine learning architectures, such as neural operators, transformers and diffusion methods, with domain-specific knowledge. Apollo will provide pretrained checkpoints and reference workflows for training, inference and benchmarking, allowing developers to integrate and customize the models for their specific needs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="size-medium wp-image-87397 aligncenter" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/industrial-manufacturing-social-cae-ai-physics-open-model-blog-1280x680.jpg-960x510.png" width="960" /&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading" id="warp"&gt;&lt;b&gt;NVIDIA Warp Supercharges Physics Simulations​ 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA Warp is a purpose-built open-source Python framework delivering GPU acceleration for computational physics and AI by up to 245x.&lt;/p&gt;
&lt;p&gt;NVIDIA Warp provides a structured approach for simulation, robotics and machine learning workloads, combining the accessibility of Python with performance comparable to native CUDA code.&lt;/p&gt;
&lt;p&gt;Warp supports the creation of GPU-accelerated 3D simulation workflows that integrate with ML pipelines in PyTorch, JAX, NVIDIA PhysicsNeMo and NVIDIA Omniverse. This allows developers to run complex simulation tasks and generate data at scale without leaving the Python programming environment.&lt;/p&gt;
&lt;p&gt;By offering CUDA-level performance with Python-level productivity, Warp simplifies the development of high-performance simulation workflows. It is designed to accelerate AI research and engineering by reducing barriers to GPU programming, making advanced simulation and data generation more efficient and widely accessible.&lt;/p&gt;
&lt;p&gt;Siemens, Neural Concept, Luminary Cloud, among others, are adopting NVIDIA Warp.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87400"&gt;&lt;img alt="NVIDIA BlueField-4 DPU powering the OS of AI factories " class="size-medium wp-image-87400" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/bluefield-corp-blog-bluefield-4-1280x680-4468150-960x510.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87400"&gt;NVIDIA BlueField-4 DPU: The Processor Powering the Operating System of AI Factories&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading" id="bluefield-4"&gt;&lt;b&gt;Showcasing BlueField-4 for Powering the OS of AI Factories 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Unveiled at GTC Washington, D.C., NVIDIA BlueField-4 DPUs are powering the operating system of AI factories. By offloading, accelerating and isolating critical data center functions — networking, storage and security — they free up CPUs and GPUs to focus entirely on compute-intensive workloads.&lt;/p&gt;
&lt;p&gt;BlueField-4, combining a 64-core NVIDIA Grace CPU and NVIDIA ConnectX-9 networking, unlocks unprecedented performance, efficiency and zero-trust security at scale. It supports multi-tenant environments, rapid data access, and real-time protection, with native integration of NVIDIA DOCA microservices for scalable, containerized AI operations. Together, they are transforming data centers into intelligent, software-defined engines for trillion-token AI and beyond.&lt;/p&gt;
&lt;p&gt;As AI factories and supercomputing centers continue to scale in size and capability, they require faster, more intelligent storage infrastructure to manage structured, unstructured and AI-native data for large-scale training and inference.&lt;/p&gt;
&lt;p&gt;Leading storage innovators — DDN, VAST Data and WEKA — are adopting BlueField-4 to redefine performance and efficiency for AI and scientific workloads.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DDN is building next-generation AI factories, accelerating data pipelines to maximize GPU utilization for AI and HPC workloads.&lt;/li&gt;
&lt;li&gt;VAST Data is advancing the AI pipeline with intelligent data movement and real-time efficiency across large-scale AI clusters.&lt;/li&gt;
&lt;li&gt;WEKA is launching its NeuralMesh architecture on BlueField-4, running storage services directly on the DPU to simplify and accelerate AI infrastructure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these HPC storage leaders are demonstrating how NVIDIA BlueField-4 transforms data movement and management — turning storage into a performance multiplier for the next era of supercomputing and AI infrastructure.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87404"&gt;&lt;img alt="NVIDIA ConnectX-9 SuperNIC" class="size-medium wp-image-87404" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/infiniband-corp-blog-connectx-9-supernic-c9180-1280x680-1-960x510.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87404"&gt;NVIDIA ConnectX-9 SuperNIC&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading" id="co-packaged-optics"&gt;&lt;b&gt;Adopting NVIDIA Co-Packaged Optics for Speed and Reliability​🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;TACC, Lambda and CoreWeave unveiled that they will integrate NVIDIA Quantum-X Photonics CPO switches into next generation systems as early as next year.&lt;/p&gt;
&lt;p&gt;NVIDIA Quantum-X Photonics networking switches enable AI factories and supercomputing centers to drastically reduce energy consumption and operational costs. NVIDIA has achieved this fusion of electronic circuits and optical communications at massive scale.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;As AI factories grow to unprecedented sizes, networks must evolve to keep pace. By eliminating traditional pluggable transceivers, a common cause of job runtime failures, NVIDIA Photonics switch systems not only deliver 3.5x better power efficiency, but also perform with 10x higher resiliency, enabling applications to run 5x longer without interruption.&lt;/p&gt;
&lt;p&gt;At GTC 2024 in Silicon Valley, NVIDIA unveiled NVIDIA Quantum-X800 InfiniBand switches, purpose-built to power trillion-parameter-scale generative AI models. These platforms deliver a staggering 800Gb/s end-to-end throughput — 2x the bandwidth and 9x the in-network compute of their predecessors — owing to such innovations as SHARPv4 and FP8 support.&lt;/p&gt;
&lt;p&gt;As NVIDIA Quantum‑X800 continues to be widely adopted to meet the demands of massive-scale AI, NVIDIA Quantum‑X Photonics, announced at GTC earlier this year, addresses the critical power, resiliency, and signal-integrity challenges of even larger deployments. By integrating optics directly on the switch, it eliminates failures caused by pluggable transceivers and link flaps, enabling workloads to run uninterrupted at scale and ensuring the infrastructure can support the next generation of compute-intensive applications up to 5x better than with pluggable transceivers.&lt;/p&gt;
&lt;p&gt;“NVIDIA Quantum‑X Photonics represents the next step in building high-performance, resilient AI networks,” said Maxx Garrison, product manager for cloud infrastructure at Lambda. “These advances in power efficiency, signal integrity and reliability, will be key to supporting efficient, large-scale workloads for our customers.”&lt;/p&gt;
&lt;p&gt;SHARPv4 enables in-network aggregation and reduction, minimizing GPU-to-GPU communication overhead. Combined with FP8 precision, it accelerates training of trillion-parameter models by reducing bandwidth and compute demands — delivering faster convergence and higher throughput and comes standard with NVIDIA Quantum‑X800 and Quantum‑X Photonics switches.&lt;/p&gt;
&lt;p&gt;“CoreWeave is building the Essential Cloud for AI,” said Peter Salanki, co-founder and chief technology officer at CoreWeave. “With NVIDIA Quantum-X Photonics, we’re advancing power efficiency, and further improving the reliability CoreWeave is known for in supporting massive AI workloads at scale, helping our customers unlock the full potential of next-generation AI.”&lt;/p&gt;
&lt;p&gt;The NVIDIA Quantum-X Photonics platform, anchored by the NVIDIA Quantum Q3450 CPO-based InfiniBand switch and ConnectX-8 SuperNIC, is engineered for the highest-performance environments that also require significantly lower power, higher resiliency and lower latency.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Supercomputing Centers Worldwide Adopting NVQLink&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-87520" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/NVIDIANVQLink.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;More than a dozen of the world’s top scientific computing centers are adopting NVQLink, a universal interconnect linking accelerated computing to quantum processors.&lt;/p&gt;
&lt;p&gt;“Here at Supercomputing, we’re announcing that we’ve been working with the supercomputing centers worldwide that are dedicated and interested in building the next generation of quantum GPU, CPU GPU supercomputers, and how to connect them to their particular research area or deployment platform for quantum computing,” said Ian Buck, vice president and general manager of accelerated computing at NVIDIA.&lt;/p&gt;
&lt;p&gt;NVQLink connects quantum processors with NVIDIA GPUs, enabling large‑scale workflows powered by the CUDA‑Q software platform. NVQLink’s open architecture provides the critical link supercomputing centers need to integrate diverse quantum processors while delivering 40 petaflops of AI performance at FP4 precision.&lt;/p&gt;
&lt;p&gt;In the future every supercomputer will draw on quantum processors to expand the problems they can solve and every quantum processor will depend on GPU supercomputers to run correctly.&lt;/p&gt;
&lt;p&gt;Quantum computing company Quantinuum’s new Helios QPU was integrated with NVIDIA GPUs through NVQLink, achieving the world’s first real‑time decoding of scalable qLDPC quantum error‑correction codes. The system maintained 99% fidelity compared with 95% without correction thanks to NVQLink’s microsecond low latencies.&lt;/p&gt;
&lt;p&gt;With NVQLink scientists and developers gain a universal bridge between quantum and classical hardware — making scalable error correction, hybrid applications and real‑time quantum‑GPU workflows practical.&lt;/p&gt;
&lt;p&gt;In the Asia‑Pacific region, Japan’s Global Research and Development Center for Business by Quantum-AI technology (G-QuAT) at the National Institute of Advanced Industrial Science and Technology (AIST) and RIKEN Center for Computational Science, Korea’s Korea Institute of Science and Technology Information (KISTI), Taiwan’s National Center for High-Performance Computing (NCHC), Singapore’s National Quantum Computing Hub (a joint initiative of Singapore’s Centre for Quantum Technologies, A*STAR Institute of High Performance Computing, and National Supercomputing Centre Singapore) — and Australia’s Pawsey Supercomputing Research Centre are among the early adopters.&lt;/p&gt;
&lt;p&gt;Across Europe and the Middle East, NVQLink is being embraced by CINECA, Denmark’s DCAI, operator of Denmark’s AI Supercomputer, France’s Grand Équipement National de Calcul Intensif (GENCI), the Czech Republic’s IT4Innovations National Supercomputing Center (IT4I), Germany’s Jülich Supercomputing Centre (JSC), Poland’s Poznań Supercomputing and Networking Center (PCSS), the Technology Innovation Institute (TII), UAE and Saudi Arabia’s King Abdullah University of Science and Technology (KAUST).&lt;/p&gt;
&lt;p&gt;In the United States, leading national laboratories including, Brookhaven National Laboratory, Fermi National Accelerator Laboratory, Lawrence Berkeley National Laboratory, Los Alamos National Laboratory, MIT Lincoln Laboratory, National Energy Research Scientific Computing Center, Oak Ridge National Laboratory, Pacific Northwest National Laboratory and Sandia National Laboratories are also adopting NVQLink to advance hybrid quantum‑classical research.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Developing Real‑World Hybrid Applications&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Quantinuum’s Helios QPU with NVQLink delivered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First real‑time decoding of qLDPC error‑correction codes&lt;/li&gt;
&lt;li&gt;~99% fidelity with NVQLink correction vs ~95% without&lt;/li&gt;
&lt;li&gt;Reaction time of 60 microseconds, exceeding Helios’ 1‑millisecond requirement by 16x&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVQLink unites quantum processors with GPU supercomputing for scalable error correction and hybrid applications. Scientists can gain a single programming environment through CUDA‑Q APIs. Developers can build and test quantum‑GPU workflows in real time&lt;/p&gt;
&lt;p&gt;With NVQLink the world’s supercomputing centers are laying the foundation for practical quantum‑classical systems, connecting diverse quantum processors to NVIDIA accelerated computing at unprecedented speed and scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA and &lt;/b&gt;&lt;b&gt;RIKEN&lt;/b&gt;&lt;b&gt; Advance Japan’s Scientific Frontiers&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-87463" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/hpc-corp-blog-sc25-riken-pr-1280x680-2.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA and RIKEN are building two new GPU‑accelerated supercomputers to expand Japan’s leadership in AI for science and quantum computing. Together the systems will feature 2,140 NVIDIA Blackwell GPUs connected through the GB200 NVL4 platform and NVIDIA Quantum‑X800 InfiniBand networking, strengthening Japan’s sovereign AI strategy and secure domestic infrastructure.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI for Science System: 1,600 Blackwell GPUs will power research in life sciences, materials science, climate and weather forecasting, manufacturing and laboratory automation.&lt;/li&gt;
&lt;li&gt;Quantum Computing System: 540 Blackwell GPUs will accelerate quantum algorithms, hybrid simulation and quantum‑classical methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The partnership builds on RIKEN’s collaboration with Fujitsu and NVIDIA to codesign FugakuNEXT, successor to the Fugaku supercomputer, expected to deliver 100x greater application performance and integrate production‑level quantum computers by 2030.&lt;/p&gt;
&lt;p&gt;The two new RIKEN systems are scheduled to be operational in spring 2026.&lt;/p&gt;
&lt;h2 class="wp-block-heading" id="arm"&gt;&lt;b&gt;Arm Adopting NVIDIA NVLink Fusion 🔗&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI is reshaping data centers in a once-in-a-generation architectural shift, where efficiency per watt defines success. At the center is Arm Neoverse, deployed in over a billion cores and projected to reach 50% hyperscaler market share by 2025. Every major provider — AWS, Google, Microsoft, Oracle and Meta — is building on Neoverse, underscoring its role in powering AI at scale.&lt;/p&gt;
&lt;p&gt;To meet surging demand, Arm is extending Neoverse with NVIDIA NVLink Fusion, the high-bandwidth, coherent interconnect first pioneered with Grace Blackwell. NVLink Fusion links CPUs, GPUs, and accelerators into one unified rack-scale architecture, removing memory and bandwidth bottlenecks that limit AI performance. Connected with Arm’s AMBA CHI C2C protocol, it ensures seamless data movement between Arm-based CPUs and partners’ preferred accelerators.&lt;/p&gt;
&lt;p&gt;Together, Arm and NVIDIA are setting a new standard for AI infrastructure, enabling ecosystem partners to build differentiated, energy-efficient systems that accelerate innovation across the AI era.&lt;/p&gt;
&lt;p&gt;“Folks building their own ARM CPU, or using an Arm IP can actually have access to NVLink Fusion, be able to connect that ARM CPU to an Nvidia GPU or to the rest of the NVLink ecosystem, and that’s happening at the racks and scale-up infrastructure,” said Buck.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Smarter Power for Accelerated Computing&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As AI factories scale, energy is becoming the new bottleneck. The NVIDIA Domain Power Service (DPS) flips that constraint into an opportunity — turning power into a dynamic, orchestrated resource. Running as a Kubernetes service, DPS models and manages energy use across the data center, from rack to room to facility. It enables operators to extract more performance per megawatt by constraining power intelligently, improving throughput without expanding infrastructure.&lt;/p&gt;
&lt;p&gt;DPS integrates tightly with the NVIDIA Omniverse DSX Blueprint, a platform for designing and operating next-generation data centers. It works alongside technologies like Power Reservation Steering to balance workloads across the facility and the Workload Power Profile Solution to tune GPU power to the needs of specific jobs. Together, they form DSX Boost — an energy-aware control layer that maximizes efficiency while meeting performance targets.&lt;/p&gt;
&lt;p&gt;DPS also extends beyond the data center. With grid-facing APIs, it supports automated load shedding and demand response, helping utilities stabilize the grid during peak events. The result is a resilient, grid-interactive AI factory that turns every watt into measurable progress.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/accelerated-computing-networking-supercomputing-ai/</guid><pubDate>Mon, 17 Nov 2025 22:31:55 +0000</pubDate></item><item><title>With a new company, Jeff Bezos will become a CEO again (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/11/with-a-new-company-jeff-bezos-will-become-a-ceo-again/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        He stepped down at Amazon in 2021 and doesn’t hold a CEO title at Blue Origin.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Jeff Bezos at a space conference, sitting in front of a picture of the stars in the night sky." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/09/getty-bezos-space-symposium-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Jeff Bezos at a space conference, sitting in front of a picture of the stars in the night sky." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/09/getty-bezos-space-symposium-scaled-1152x648-1763419085.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Amazon and Blue Origin founder Jeff Bezos at the 32nd Space Symposium in Colorado Springs, Colorado, on April 12, 2016. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Bloomberg

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Jeff Bezos is one of the world’s richest and most famous tech CEOs, but he hasn’t actually been a CEO of anything since 2021. That’s now changing as he takes on the role of co-CEO of a new AI company, according to a New York Times report citing three people familiar with the company.&lt;/p&gt;
&lt;p&gt;Grandiosely named Project Prometheus (and not to be confused with the NASA project of the same name), the company will focus on using AI to pursue breakthroughs in research, engineering, manufacturing, and other fields that are dubbed part of “the physical economy”—in contrast to the software applications that are likely the first thing most people in the general public think of when they hear “AI.”&lt;/p&gt;
&lt;p&gt;Bezos’ co-CEO will be Dr. Vik Bajaj, a chemist and physicist who previously led life sciences work at Google X, an Alphabet-backed research group that worked on speculative projects that could lead to more product categories. (For example, it developed technologies that would later underpin Google’s Waymo service.) Bajaj also worked at Verily, another Alphabet-backed research group focused on life sciences, and Foresite Labs, an incubator for new AI companies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is speculation, but Bajaj resume’s suggests he may lead the R&amp;amp;D efforts at Project Prometheus while Bezos focuses on the logistics and the business side.&lt;/p&gt;
&lt;p&gt;Project Prometheus already has nearly 100 employees, having poached researchers from the AI divisions at big tech firms like OpenAI and Meta. It appears it may compete directly with Periodic Labs and other companies in the physical and research AI space, but its chief distinction is its level of funding: Project Prometheus is launching with $6.2 billion in funding, at least partially from Bezos himself. That’s more than most of the companies it will compete with.&lt;/p&gt;
&lt;p&gt;Bezos founded Amazon in the ’90s and turned a website for ordering books into a sprawling, multi-industry company perhaps best known for its logistics dominance. Since then, he has attracted more public attention for his lavish personal life, though he has also held a leadership role at Blue Origin, a space company that competes with Elon Musk’s Space X. Bezos’ title at Blue Origin is founder but not CEO.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        He stepped down at Amazon in 2021 and doesn’t hold a CEO title at Blue Origin.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Jeff Bezos at a space conference, sitting in front of a picture of the stars in the night sky." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/09/getty-bezos-space-symposium-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Jeff Bezos at a space conference, sitting in front of a picture of the stars in the night sky." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/09/getty-bezos-space-symposium-scaled-1152x648-1763419085.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Amazon and Blue Origin founder Jeff Bezos at the 32nd Space Symposium in Colorado Springs, Colorado, on April 12, 2016. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | Bloomberg

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Jeff Bezos is one of the world’s richest and most famous tech CEOs, but he hasn’t actually been a CEO of anything since 2021. That’s now changing as he takes on the role of co-CEO of a new AI company, according to a New York Times report citing three people familiar with the company.&lt;/p&gt;
&lt;p&gt;Grandiosely named Project Prometheus (and not to be confused with the NASA project of the same name), the company will focus on using AI to pursue breakthroughs in research, engineering, manufacturing, and other fields that are dubbed part of “the physical economy”—in contrast to the software applications that are likely the first thing most people in the general public think of when they hear “AI.”&lt;/p&gt;
&lt;p&gt;Bezos’ co-CEO will be Dr. Vik Bajaj, a chemist and physicist who previously led life sciences work at Google X, an Alphabet-backed research group that worked on speculative projects that could lead to more product categories. (For example, it developed technologies that would later underpin Google’s Waymo service.) Bajaj also worked at Verily, another Alphabet-backed research group focused on life sciences, and Foresite Labs, an incubator for new AI companies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is speculation, but Bajaj resume’s suggests he may lead the R&amp;amp;D efforts at Project Prometheus while Bezos focuses on the logistics and the business side.&lt;/p&gt;
&lt;p&gt;Project Prometheus already has nearly 100 employees, having poached researchers from the AI divisions at big tech firms like OpenAI and Meta. It appears it may compete directly with Periodic Labs and other companies in the physical and research AI space, but its chief distinction is its level of funding: Project Prometheus is launching with $6.2 billion in funding, at least partially from Bezos himself. That’s more than most of the companies it will compete with.&lt;/p&gt;
&lt;p&gt;Bezos founded Amazon in the ’90s and turned a website for ordering books into a sprawling, multi-industry company perhaps best known for its logistics dominance. Since then, he has attracted more public attention for his lavish personal life, though he has also held a leadership role at Blue Origin, a space company that competes with Elon Musk’s Space X. Bezos’ title at Blue Origin is founder but not CEO.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/11/with-a-new-company-jeff-bezos-will-become-a-ceo-again/</guid><pubDate>Mon, 17 Nov 2025 22:50:21 +0000</pubDate></item><item><title>a16z-backed super PAC is targeting Alex Bores, sponsor of New York’s AI safety bill — he says bring it on (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/17/a16z-backed-super-pac-is-targeting-alex-bores-sponsor-of-new-yorks-ai-safety-bill-he-says-bring-it-on/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A pro-AI super PAC backed by Andreessen Horowitz and OpenAI President Greg Brockman has chosen New York Assembly member Alex Bores — and his congressional bid — as its first target.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The PAC, dubbed Leading the Future, formed in August with a more than $100 million commitment to support policymakers with a light-touch — or a no-touch — approach to AI regulation. And that means going after policymakers who want to regulate AI.&amp;nbsp;The super PAC has backing from a number of other prominent leaders in tech, including Palantir co-founder&amp;nbsp;and 8VC managing partner Joe Lonsdale as well as AI search engine Perplexity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I appreciate how straightforward they’re being about it,” Bores told a room of journalists Monday evening at a Journalism Workshop on AGI impacts and governance in Washington, D.C. “When they say, ‘Hey, we’re going to spend millions against Alex because he might regulate&lt;strong&gt; &lt;/strong&gt;Big Tech&lt;strong&gt; &lt;/strong&gt;and put basic guardrails on AI,’ I just basically forward that to my constituents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores, who’s running to represent the state’s 12th Congressional District, said AI anxieties are on the rise among his constituents, who worry about everything from data centers pushing up utility bills and worsening climate change to chatbots impacting kids’ mental health and automation transforming the job market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores is the chief sponsor of New York’s bipartisan RAISE Act, which requires large AI labs to have a safety plan in place to prevent critical harms, follow their own safety plan, and disclose critical safety incidents, like bad actors stealing an AI model. The bill also prohibits AI firms from releasing models with unreasonable risks of critical harm and imposes civil penalties of up to $30 million if companies fail to live up to these standards. The legislation is currently awaiting Gov. Kathy Hochul’s signature.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores said while drafting and redrafting the bill, he consulted with the large AI firms like OpenAI and Anthropic. Those negotiations led to the removal of provisions like third-party safety audits, which he says the industry refused to accept. Nevertheless, the RAISE Act, and Bores himself, appears to have incurred the ire of Silicon Valley.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zac Moffatt and Josh Vlasto, heads of Leading the Future, told Politico that they would work on a multibillion-dollar effort to sink Bores’ campaign.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement sent to TechCrunch, they accused Bores of advancing “ideological and politically motivated legislation that would handcuff not only New York’s, but the entire country’s ability to lead on AI jobs and innovation.” The pair said “bills like the RAISE Act threaten American competitiveness, limit economic growth, leave users exposed to foreign influence and manipulation, and undermine our national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The RAISE Act is a clear example of the patchwork, uninformed, and bureaucratic state laws that would slow American progress and open the door for China to win the global race for AI leadership,” Moffatt and Vlasto said in the  emailed statement. “America needs one clear and consistent national regulatory framework for AI that strengthens our economy, creates jobs for American workers, supports vibrant communities, and protects users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many in Silicon Valley have pushed to prohibit states from passing regulation that relates to AI. Earlier this year, a provision blocking state AI laws was slipped into the federal budget bill and was later removed. Now, lawmakers like Sen. Ted Cruz are seeking to resurrect it through other legislative avenues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bores said he is concerned such a movement could continue to gain legs at a time when the federal government has passed no meaningful AI regulation. Where federal government moves slow, states are like startups — they can function as policy laboratories and move fast to test what works.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The question should be, has Congress solved the problem?” Bores said. “If Congress solves the problem, then it can tell the states to get out of the way, but if they’re not going to pass a bill that’s actually addressing any of the problems…and then [saying that states can’t do anything] that just doesn’t make sense to me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores also noted he has been in contact with policymakers in other states to work on standardizing legislation, which could combat Silicon Valley’s “patchwork” objection. He also believes that lawmakers should ensure there are no redundancies with the EU AI Act.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores emphasized that AI regulation isn’t meant to limit innovation, and that he has rejected bills that he thinks would have unintended consequences for the industry.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having basic rules of the road, literal or metaphorical, is actually a very pro-innovation stance if done well,” Bores said. “I fundamentally believe that the AI that wins is going to be the AI that is trustworthy. And the pushback from industry to say that government has no role in establishing that trust is one that I think you’re seeing people reject at every level.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A pro-AI super PAC backed by Andreessen Horowitz and OpenAI President Greg Brockman has chosen New York Assembly member Alex Bores — and his congressional bid — as its first target.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The PAC, dubbed Leading the Future, formed in August with a more than $100 million commitment to support policymakers with a light-touch — or a no-touch — approach to AI regulation. And that means going after policymakers who want to regulate AI.&amp;nbsp;The super PAC has backing from a number of other prominent leaders in tech, including Palantir co-founder&amp;nbsp;and 8VC managing partner Joe Lonsdale as well as AI search engine Perplexity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I appreciate how straightforward they’re being about it,” Bores told a room of journalists Monday evening at a Journalism Workshop on AGI impacts and governance in Washington, D.C. “When they say, ‘Hey, we’re going to spend millions against Alex because he might regulate&lt;strong&gt; &lt;/strong&gt;Big Tech&lt;strong&gt; &lt;/strong&gt;and put basic guardrails on AI,’ I just basically forward that to my constituents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores, who’s running to represent the state’s 12th Congressional District, said AI anxieties are on the rise among his constituents, who worry about everything from data centers pushing up utility bills and worsening climate change to chatbots impacting kids’ mental health and automation transforming the job market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores is the chief sponsor of New York’s bipartisan RAISE Act, which requires large AI labs to have a safety plan in place to prevent critical harms, follow their own safety plan, and disclose critical safety incidents, like bad actors stealing an AI model. The bill also prohibits AI firms from releasing models with unreasonable risks of critical harm and imposes civil penalties of up to $30 million if companies fail to live up to these standards. The legislation is currently awaiting Gov. Kathy Hochul’s signature.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores said while drafting and redrafting the bill, he consulted with the large AI firms like OpenAI and Anthropic. Those negotiations led to the removal of provisions like third-party safety audits, which he says the industry refused to accept. Nevertheless, the RAISE Act, and Bores himself, appears to have incurred the ire of Silicon Valley.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zac Moffatt and Josh Vlasto, heads of Leading the Future, told Politico that they would work on a multibillion-dollar effort to sink Bores’ campaign.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement sent to TechCrunch, they accused Bores of advancing “ideological and politically motivated legislation that would handcuff not only New York’s, but the entire country’s ability to lead on AI jobs and innovation.” The pair said “bills like the RAISE Act threaten American competitiveness, limit economic growth, leave users exposed to foreign influence and manipulation, and undermine our national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The RAISE Act is a clear example of the patchwork, uninformed, and bureaucratic state laws that would slow American progress and open the door for China to win the global race for AI leadership,” Moffatt and Vlasto said in the  emailed statement. “America needs one clear and consistent national regulatory framework for AI that strengthens our economy, creates jobs for American workers, supports vibrant communities, and protects users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many in Silicon Valley have pushed to prohibit states from passing regulation that relates to AI. Earlier this year, a provision blocking state AI laws was slipped into the federal budget bill and was later removed. Now, lawmakers like Sen. Ted Cruz are seeking to resurrect it through other legislative avenues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bores said he is concerned such a movement could continue to gain legs at a time when the federal government has passed no meaningful AI regulation. Where federal government moves slow, states are like startups — they can function as policy laboratories and move fast to test what works.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The question should be, has Congress solved the problem?” Bores said. “If Congress solves the problem, then it can tell the states to get out of the way, but if they’re not going to pass a bill that’s actually addressing any of the problems…and then [saying that states can’t do anything] that just doesn’t make sense to me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores also noted he has been in contact with policymakers in other states to work on standardizing legislation, which could combat Silicon Valley’s “patchwork” objection. He also believes that lawmakers should ensure there are no redundancies with the EU AI Act.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores emphasized that AI regulation isn’t meant to limit innovation, and that he has rejected bills that he thinks would have unintended consequences for the industry.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having basic rules of the road, literal or metaphorical, is actually a very pro-innovation stance if done well,” Bores said. “I fundamentally believe that the AI that wins is going to be the AI that is trustworthy. And the pushback from industry to say that government has no role in establishing that trust is one that I think you’re seeing people reject at every level.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/17/a16z-backed-super-pac-is-targeting-alex-bores-sponsor-of-new-yorks-ai-safety-bill-he-says-bring-it-on/</guid><pubDate>Tue, 18 Nov 2025 00:32:50 +0000</pubDate></item><item><title>[NEW] The Great Flip: How Accelerated Computing Redefined Scientific Systems — and What Comes Next (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/accelerated-scientific-systems/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;It used to be that computing power trickled down from hulking supercomputers to the chips in our pockets.&lt;/p&gt;
&lt;p&gt;Over the past 15 years, innovation has changed course: GPUs, born from gaming and scaled through accelerated computing, have surged upstream to remake supercomputing and carry the AI revolution to scientific computing’s most rarefied systems.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="wp-image-87559 size-full aligncenter" height="1102" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/image-1.png" width="1816" /&gt;&lt;br /&gt;JUPITER at Forschungszentrum Jülich is the emblem of this new era.&lt;/p&gt;
&lt;p&gt;Not only is it among the most efficient supercomputers — producing 63.3 gigaflops per watt — but it’s also a powerhouse for AI, delivering 116 AI exaflops, up from 92 at ISC High Performance 2025.&lt;/p&gt;
&lt;p&gt;This is the “flip” in action. In 2019, nearly 70% of the TOP100 high-performance computing systems were CPU-only. Today, that number has plunged below 15%, with 88 of the TOP100 systems accelerated — and 80% of those powered by NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;Across the broader TOP500, 388 systems, 78%, now use NVIDIA technology, including 218 GPU-accelerated systems (up 34 systems year over year) and 362 systems connected by high-performance NVIDIA networking. The trend is unmistakable: accelerated computing has become the standard.&lt;/p&gt;
&lt;p&gt;But the real revolution is in AI performance. With architectures like NVIDIA Hopper and Blackwell and systems like JUPITER, researchers now have access to orders of magnitude more AI compute than ever.&lt;/p&gt;
&lt;p&gt;AI FLOPS have become the new yardstick, enabling breakthroughs in climate modeling, drug discovery and quantum simulation — problems that demand both scale and efficiency.&lt;/p&gt;
&lt;p&gt;At SC16, years before today’s generative AI wave, NVIDIA founder and CEO Jensen Huang saw what was coming. He predicted that AI would soon reshape the world’s most powerful computing systems.&lt;/p&gt;
&lt;p&gt;“Several years ago, deep learning came along, like Thor’s hammer falling from the sky, and gave us an incredibly powerful tool to solve some of the most difficult problems in the world,” Huang declared.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_87563"&gt;&lt;img alt="alt" class="wp-image-87563 size-full" height="312" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/Picture1.jpg" width="468" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87563"&gt;At SC16, Huang explained how AI would reshape the world’s most powerful scientific computing systems.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The math behind computing power consumption had already made the shift to GPUs inevitable.&lt;/p&gt;
&lt;p&gt;But it was the AI revolution, ignited by the NVIDIA CUDA-X computing platform built on those GPUs, that extended the capabilities of these machines dramatically.&lt;/p&gt;
&lt;p&gt;Suddenly, supercomputers could deliver meaningful science at double precision (FP64) as well as at mixed precision (FP32, FP16) and even at ultra-efficient formats like INT8 and beyond — the backbone of modern AI.&lt;/p&gt;
&lt;p&gt;This flexibility allowed researchers to stretch power budgets further than ever to run larger, more complex simulations and train deeper neural networks, all while maximizing performance per watt.&lt;/p&gt;
&lt;p&gt;But even before AI took hold, the raw numbers had already forced the issue. Power budgets don’t negotiate. Supercomputer researchers — inside NVIDIA and across the community — were coming to grips with the road ahead, and it was paved with GPUs.&lt;/p&gt;
&lt;p&gt;To reach exascale without a Hoover Dam‑sized electric bill, researchers needed acceleration. GPUs delivered far more operations per watt than CPUs. That was the pre‑AI tell of what was to come, and that’s why when the AI boom hit, large-scale GPU systems already had momentum.&lt;/p&gt;
&lt;p&gt;The seeds were planted with Titan in 2012 at the Oak Ridge National Laboratory, one of the first major U.S. systems to pair CPUs with GPUs at unprecedented scale — showing how hierarchical parallelism could unlock huge application gains.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;In Europe in 2013, Piz Daint set a new bar for both performance and efficiency, then proved the point where it matters: real applications like COSMO forecasting for weather prediction.&lt;/p&gt;
&lt;p&gt;By 2017, the inflection was undeniable. Summit at Oak Ridge National Laboratory and Sierra at Lawrence Livermore Laboratory ushered in a new standard for leadership‑class systems: acceleration first. They didn’t just run faster; they changed the questions science could ask for climate modeling, genomics, materials and more.&lt;/p&gt;
&lt;p&gt;These systems are able to do much more with much less. On the Green500 list of the most efficient systems, the top eight are NVIDIA‑accelerated, with NVIDIA Quantum InfiniBand connecting 7 of the Top 10.&lt;/p&gt;
&lt;p&gt;But the story behind these headline numbers is how AI capabilities have become the yardstick: JUPITER delivers 116 AI exaflops alongside 1 EF FP64 — a clear signal of how science now blends simulation and AI.&lt;br /&gt;Power efficiency didn’t just make exascale attainable; it made AI at exascale practical. And once science had AI at scale, the curve bent sharply upward.&lt;/p&gt;
&lt;h2&gt;What It Means Next&lt;/h2&gt;
&lt;p&gt;This isn’t just about benchmarks. It’s about real science:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster, more accurate weather and climate models&lt;/li&gt;
&lt;li&gt;Breakthroughs in drug discovery and genomics&lt;/li&gt;
&lt;li&gt;Simulations of fusion reactors and quantum systems&lt;/li&gt;
&lt;li&gt;New frontiers in AI-driven research across every discipline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The shift started as a power-efficiency imperative, became an architectural advantage and has matured into a scientific superpower: simulation and AI, together, at unprecedented scale.&lt;/p&gt;
&lt;p&gt;It starts with scientific computing. Now, the rest of computing will follow.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;It used to be that computing power trickled down from hulking supercomputers to the chips in our pockets.&lt;/p&gt;
&lt;p&gt;Over the past 15 years, innovation has changed course: GPUs, born from gaming and scaled through accelerated computing, have surged upstream to remake supercomputing and carry the AI revolution to scientific computing’s most rarefied systems.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="wp-image-87559 size-full aligncenter" height="1102" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/image-1.png" width="1816" /&gt;&lt;br /&gt;JUPITER at Forschungszentrum Jülich is the emblem of this new era.&lt;/p&gt;
&lt;p&gt;Not only is it among the most efficient supercomputers — producing 63.3 gigaflops per watt — but it’s also a powerhouse for AI, delivering 116 AI exaflops, up from 92 at ISC High Performance 2025.&lt;/p&gt;
&lt;p&gt;This is the “flip” in action. In 2019, nearly 70% of the TOP100 high-performance computing systems were CPU-only. Today, that number has plunged below 15%, with 88 of the TOP100 systems accelerated — and 80% of those powered by NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;Across the broader TOP500, 388 systems, 78%, now use NVIDIA technology, including 218 GPU-accelerated systems (up 34 systems year over year) and 362 systems connected by high-performance NVIDIA networking. The trend is unmistakable: accelerated computing has become the standard.&lt;/p&gt;
&lt;p&gt;But the real revolution is in AI performance. With architectures like NVIDIA Hopper and Blackwell and systems like JUPITER, researchers now have access to orders of magnitude more AI compute than ever.&lt;/p&gt;
&lt;p&gt;AI FLOPS have become the new yardstick, enabling breakthroughs in climate modeling, drug discovery and quantum simulation — problems that demand both scale and efficiency.&lt;/p&gt;
&lt;p&gt;At SC16, years before today’s generative AI wave, NVIDIA founder and CEO Jensen Huang saw what was coming. He predicted that AI would soon reshape the world’s most powerful computing systems.&lt;/p&gt;
&lt;p&gt;“Several years ago, deep learning came along, like Thor’s hammer falling from the sky, and gave us an incredibly powerful tool to solve some of the most difficult problems in the world,” Huang declared.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_87563"&gt;&lt;img alt="alt" class="wp-image-87563 size-full" height="312" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/Picture1.jpg" width="468" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87563"&gt;At SC16, Huang explained how AI would reshape the world’s most powerful scientific computing systems.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The math behind computing power consumption had already made the shift to GPUs inevitable.&lt;/p&gt;
&lt;p&gt;But it was the AI revolution, ignited by the NVIDIA CUDA-X computing platform built on those GPUs, that extended the capabilities of these machines dramatically.&lt;/p&gt;
&lt;p&gt;Suddenly, supercomputers could deliver meaningful science at double precision (FP64) as well as at mixed precision (FP32, FP16) and even at ultra-efficient formats like INT8 and beyond — the backbone of modern AI.&lt;/p&gt;
&lt;p&gt;This flexibility allowed researchers to stretch power budgets further than ever to run larger, more complex simulations and train deeper neural networks, all while maximizing performance per watt.&lt;/p&gt;
&lt;p&gt;But even before AI took hold, the raw numbers had already forced the issue. Power budgets don’t negotiate. Supercomputer researchers — inside NVIDIA and across the community — were coming to grips with the road ahead, and it was paved with GPUs.&lt;/p&gt;
&lt;p&gt;To reach exascale without a Hoover Dam‑sized electric bill, researchers needed acceleration. GPUs delivered far more operations per watt than CPUs. That was the pre‑AI tell of what was to come, and that’s why when the AI boom hit, large-scale GPU systems already had momentum.&lt;/p&gt;
&lt;p&gt;The seeds were planted with Titan in 2012 at the Oak Ridge National Laboratory, one of the first major U.S. systems to pair CPUs with GPUs at unprecedented scale — showing how hierarchical parallelism could unlock huge application gains.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;In Europe in 2013, Piz Daint set a new bar for both performance and efficiency, then proved the point where it matters: real applications like COSMO forecasting for weather prediction.&lt;/p&gt;
&lt;p&gt;By 2017, the inflection was undeniable. Summit at Oak Ridge National Laboratory and Sierra at Lawrence Livermore Laboratory ushered in a new standard for leadership‑class systems: acceleration first. They didn’t just run faster; they changed the questions science could ask for climate modeling, genomics, materials and more.&lt;/p&gt;
&lt;p&gt;These systems are able to do much more with much less. On the Green500 list of the most efficient systems, the top eight are NVIDIA‑accelerated, with NVIDIA Quantum InfiniBand connecting 7 of the Top 10.&lt;/p&gt;
&lt;p&gt;But the story behind these headline numbers is how AI capabilities have become the yardstick: JUPITER delivers 116 AI exaflops alongside 1 EF FP64 — a clear signal of how science now blends simulation and AI.&lt;br /&gt;Power efficiency didn’t just make exascale attainable; it made AI at exascale practical. And once science had AI at scale, the curve bent sharply upward.&lt;/p&gt;
&lt;h2&gt;What It Means Next&lt;/h2&gt;
&lt;p&gt;This isn’t just about benchmarks. It’s about real science:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster, more accurate weather and climate models&lt;/li&gt;
&lt;li&gt;Breakthroughs in drug discovery and genomics&lt;/li&gt;
&lt;li&gt;Simulations of fusion reactors and quantum systems&lt;/li&gt;
&lt;li&gt;New frontiers in AI-driven research across every discipline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The shift started as a power-efficiency imperative, became an architectural advantage and has matured into a scientific superpower: simulation and AI, together, at unprecedented scale.&lt;/p&gt;
&lt;p&gt;It starts with scientific computing. Now, the rest of computing will follow.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/accelerated-scientific-systems/</guid><pubDate>Tue, 18 Nov 2025 01:53:30 +0000</pubDate></item><item><title>[NEW] As consumers ditch Google for ChatGPT, Peec AI raises $21M to help brands adapt (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/17/as-consumers-ditch-google-for-chatgpt-peec-ai-raises-21m-to-help-brands-adapt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/a5fadec4-271b-4ce6-bdd2-504484c36964.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With consumers increasingly asking questions of ChatGPT — not Google — product discovery is changing. And the promise to give brands visibility and control over this fast-growing search channel has made Peec AI one of Europe’s hottest startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just four months after its Seed round led by 20VC, the Berlin-based startup has raised a $21 million Series A led by European VC firm Singular. CEO Marius Meiners declined to disclose the valuation, but said it had tripled and was now above $100 million.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This comes after Peec AI grew its annual recurring revenue to more than $4 million in only ten months since its launch, attracting 1,300 companies and agencies to its platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These customers use Peec AI to monitor how their brands appear in AI-powered searches. But beyond analytics on visibility and ranking, Peec AI also tracks sentiment — and which sources shape these answers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights are what make Generative Engine Optimization (GEO) possible — a way for marketing teams to optimize their brand’s presence in AI search results, similar to how SEO works for traditional search engines. With this promise, the startup says it is now adding some 300 customers a month, and its new funding will accelerate this growth while also supporting expansion plans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thanks to its new round, which was also backed by Antler, Combination VC, identity.vc, and S20, the startup plans to hire some 40 people in the next six months. These roles are mostly based in Berlin, where Meiners met his two cofounders in Antler’s Winter 2024 cohort: Tobias Siwonia is now Peec AI’s CTO, and Daniel Drabo is its CRO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Expanding fast and being visible may be key to winning in an emerging category that could soon become crowded, with competitors already including New York-based Profound and Austrian startup OtterlyAI.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To help attract more talent, the 20-person startup is currently advertising itself on large outdoor ads throughout Germany’s capital city. But beyond its Berlin plans, Meiners told TechCrunch that Peec AI also plans to open a sales-focused office in New York City in the second quarter of next year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As more GEO-focused tools become available, and SEO dashboards add AI tracking capabilities, Peec AI hopes to differentiate itself by offering marketing teams a dashboard that expands in scope while remaining simple to use, despite the fast-changing nature of AI searches.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of revolving around keywords like SEO tools, Peec AI’s dashboard centers on prompts for which brands would like to show up well in search results. Customers can track up to 25 prompts for €75 per month ($87), increasing to 100 prompts for €169 per month ($196). Both plans offer free trials, unlike its enterprise offering, which starts from €424 per month ($493).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To make these insights actionable, the dashboard also suggests actions that can improve visibility and positive sentiment. For instance, its home page suggests that a company that wants to be the answer to a query on “the best CRMs for fast-growing companies” may want to “join r/CRM subreddit discussions” on Reddit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This recommendation also relates to the “source insights” that are at the core of Peec AI and could guide the content strategy of its users. The startup observed that mentions in tier 1 media outlets don’t give more visibility than articles by lesser-known publications whose headlines are closer to the original question — for instance, on “the best healthcare investors in Berlin.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies that already use its tools include Axel Springer, Chanel, n8n, ElevenLabs, TUI, and more, as AI searches gain ground across sectors, both for B2C and for B2B searches. However, users also turn to ChatGPT and the like for many other tasks and requests, which means that the startup has to cut through noise behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve this, Peec AI bought raw datasets of these requests, but that’s just the beginning. &lt;em&gt;“&lt;/em&gt;We have to filter all these out to really get the questions that people ask around brands or purchases and products and services,” Meiners said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For all the simplicity on the outside, that proprietary data pipeline may be the key to Peec AI’s success. This also serves as a reminder that the AI value chain is not only about models and that the AI application layer and underlying data have become a prime territory for European startups, now including Peec AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/a5fadec4-271b-4ce6-bdd2-504484c36964.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With consumers increasingly asking questions of ChatGPT — not Google — product discovery is changing. And the promise to give brands visibility and control over this fast-growing search channel has made Peec AI one of Europe’s hottest startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just four months after its Seed round led by 20VC, the Berlin-based startup has raised a $21 million Series A led by European VC firm Singular. CEO Marius Meiners declined to disclose the valuation, but said it had tripled and was now above $100 million.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This comes after Peec AI grew its annual recurring revenue to more than $4 million in only ten months since its launch, attracting 1,300 companies and agencies to its platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These customers use Peec AI to monitor how their brands appear in AI-powered searches. But beyond analytics on visibility and ranking, Peec AI also tracks sentiment — and which sources shape these answers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights are what make Generative Engine Optimization (GEO) possible — a way for marketing teams to optimize their brand’s presence in AI search results, similar to how SEO works for traditional search engines. With this promise, the startup says it is now adding some 300 customers a month, and its new funding will accelerate this growth while also supporting expansion plans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thanks to its new round, which was also backed by Antler, Combination VC, identity.vc, and S20, the startup plans to hire some 40 people in the next six months. These roles are mostly based in Berlin, where Meiners met his two cofounders in Antler’s Winter 2024 cohort: Tobias Siwonia is now Peec AI’s CTO, and Daniel Drabo is its CRO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Expanding fast and being visible may be key to winning in an emerging category that could soon become crowded, with competitors already including New York-based Profound and Austrian startup OtterlyAI.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To help attract more talent, the 20-person startup is currently advertising itself on large outdoor ads throughout Germany’s capital city. But beyond its Berlin plans, Meiners told TechCrunch that Peec AI also plans to open a sales-focused office in New York City in the second quarter of next year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As more GEO-focused tools become available, and SEO dashboards add AI tracking capabilities, Peec AI hopes to differentiate itself by offering marketing teams a dashboard that expands in scope while remaining simple to use, despite the fast-changing nature of AI searches.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of revolving around keywords like SEO tools, Peec AI’s dashboard centers on prompts for which brands would like to show up well in search results. Customers can track up to 25 prompts for €75 per month ($87), increasing to 100 prompts for €169 per month ($196). Both plans offer free trials, unlike its enterprise offering, which starts from €424 per month ($493).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To make these insights actionable, the dashboard also suggests actions that can improve visibility and positive sentiment. For instance, its home page suggests that a company that wants to be the answer to a query on “the best CRMs for fast-growing companies” may want to “join r/CRM subreddit discussions” on Reddit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This recommendation also relates to the “source insights” that are at the core of Peec AI and could guide the content strategy of its users. The startup observed that mentions in tier 1 media outlets don’t give more visibility than articles by lesser-known publications whose headlines are closer to the original question — for instance, on “the best healthcare investors in Berlin.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies that already use its tools include Axel Springer, Chanel, n8n, ElevenLabs, TUI, and more, as AI searches gain ground across sectors, both for B2C and for B2B searches. However, users also turn to ChatGPT and the like for many other tasks and requests, which means that the startup has to cut through noise behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve this, Peec AI bought raw datasets of these requests, but that’s just the beginning. &lt;em&gt;“&lt;/em&gt;We have to filter all these out to really get the questions that people ask around brands or purchases and products and services,” Meiners said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For all the simplicity on the outside, that proprietary data pipeline may be the key to Peec AI’s success. This also serves as a reminder that the AI value chain is not only about models and that the AI application layer and underlying data have become a prime territory for European startups, now including Peec AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/17/as-consumers-ditch-google-for-chatgpt-peec-ai-raises-21m-to-help-brands-adapt/</guid><pubDate>Tue, 18 Nov 2025 05:10:17 +0000</pubDate></item></channel></rss>